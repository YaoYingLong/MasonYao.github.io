{"pages":[{"title":"Categories","date":"2019-06-27T09:26:09.601Z","path":"categories/index.html","text":""},{"title":"Welcome YingLong's Blog","date":"2017-11-21T16:00:00.000Z","path":"about/index.html","text":"前言首先需要说明的是，该博客系统使用的主题是Wikitten，这个主题是由一个很厉害的学弟写的。本来想自己搭建一个完全属于我自己的博客系统的，虽然会一些蹩脚的前端，真的要去做的话相信也能做出来，但是搭建这个很费时间和精力，由于现在工作了空余时间本来就少，而且我从事的是后台的开发工作，也比较喜欢做后台开发，所以不想本末倒置，再者这个主题我也比较喜欢，反正就是一大堆借口，最终使用了这个模板。 版面上之所以使用的是英文，不是为了装逼，恩~~，好吧，不仅仅是为了装逼。其实个人英语很烂，虽然在Nokia实习过半年，但还是改变不了英语烂的这个事实。虽然烂但是却一值想把这个东西学好，客观的讲对于编程来说这个东西真的很重要，很多有用的文档都是英文的，比如说Spring。我发现有很大一部分人英语很差的人，总是很害怕它。老实说我以前也害怕它，但是在Nokia的全英文环境中逐渐克服了。越畏惧就要越接触越差就要越去使用，这样才会有进步，所以说使用英文版面，仅仅是为了让自己尽量多的处于英文环境中，哪怕产生一丝丝潜移默化的影响那也是好的。 目的其实很早就有搭建一个博客系统的打算，先前也搭建过一个，但是觉得以前那个不怎么样，也没有怎么用了。最近看了一些书，但是总是很难融会贯通，仔细想了一下没有去对某个知识点进行深入得理解学习，或者说没有将书上的东西有效的串联起来，很零散。如果没有进行系统化的整理，你会发现很快这个东西在你的记忆力越来越模糊。 为了方便记录，为了方便将自己总结的东西管理起来，甚至说将自己的知识库管理起来。深有体会的一点就是，梳理前后那就不是一个量级的东西了，甚至更夸张的有可能给你的感觉那就不是一个东西。最重要的一点也是最主要的一个目的，就是为了督促自己去学习总结和提高，永远保持一个努力前行的心，坚定目标，尽可能的降低外界环境对自己的干扰。 虽奔放不羁，但也束缚自我，努力前行。"},{"title":"Tags","date":"2019-06-27T09:26:09.688Z","path":"tags/index.html","text":""}],"posts":[{"title":"经典算法","date":"2022-02-25T16:00:00.000Z","path":"Blog/算法/经典算法/","text":"链表反转123456789static class ListNode &#123; int val; ListNode next; public ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;&#125; 迭代1234567891011public static ListNode iterate(ListNode head) &#123; ListNode prev = null, curr, next; curr = head; while (curr != null) &#123; next = curr.next; // 将下一个节点指针保存到next变量 next = curr.next curr.next = prev; // 将下一个节点的指针指向prev，curr.next = prev prev = curr; // 准备处理下一个节点，将curr赋值给prev curr = next; // 将下一个节点赋值为curr，处理一个节点 &#125; return prev;&#125; 递归12345678910public static ListNode recursion(ListNode head) &#123; // 为了保证链不断，必须从最后一个元素开始 if (head == null || head.next == null) &#123; return head; &#125; ListNode newHead = recursion(head.next); head.next.next = head; head.next = null; return newHead;&#125; 素数暴力算法12345678910111213141516public int countPrimes(int n) &#123; int ans = 0; for (int i = 2; i &lt; n; ++i) &#123; ans += isPrime(i) ? 1 : 0; &#125; return ans;&#125;public boolean isPrime(int x) &#123; // i若能被x整除，则x/i肯定能被x整除，因此只需判断i和根号x之中较小的即可 for (int i = 2; i * i &lt;= x; ++i) &#123; if (x % i == 0) &#123; return false; &#125; &#125; return true;&#125; 埃氏筛12345678910111213141516public static int eratosthenes(int n) &#123; boolean[] isPrime = new boolean[n]; // false表示是一个素数，true表示合数 int ans = 0; for (int i = 2; i &lt; n; i++) &#123; if (!isPrime[i]) &#123; ans += 1; // 将合数标记为true，j = i * i 从 2 * i 优化而来，系数2会随着遍历递增（j += i，相当于递增了系数2）， // 每一个合数都会有两个比本身要小的因子(0,1除外)，2 * i必然会遍历到这两个因子，当2递增到大于根号n时， // 其实后面的已经无需再判断（或者只需判断后面一段），而2到根号n、实际上在 i 递增的过程中已经计算过了，i实际上就相当于根 for (int j = i * i; j &lt; n; j += i) &#123; isPrime[j] = true; &#125; &#125; &#125; return ans;&#125; 删除有序数组中重复项1234567891011public int removeDuplicates(int[] nums) &#123; if (nums.length == 0) return 0; int i = 0; for (int j = 1; j &lt; nums.length; j++) &#123; if (nums[j] != nums[i]) &#123; i++; nums[i] = nums[j]; &#125; &#125; return i + 1;&#125; 数组的中心索引12345678910111213// 数组中某一个下标，左右两边的元素之和相等，该下标即为中心索引public static int pivotIndex(int[] nums) &#123; int sum1 = Arrays.stream(nums).sum(); int sum2 = 0; for (int i = 0; i &lt; nums.length; i++) &#123; sum2 += nums[i]; if (sum1 == sum2) &#123; return i; &#125; sum1 = sum1 - nums[i]; &#125; return -1;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"Kubernetes基础","date":"2022-02-14T16:00:00.000Z","path":"Blog/云原生/Kubernetes基础/","text":"Kubernetes简称K8S，用于自动部署、扩展和管理容器化应用程序的开源系统。 核心特点; 服务发现与负载均衡：无需修改应用程序即可使用陌生的服务发现机制 存储编排：自动挂载所选存储系统，包括本地存储 Secret和配置管理：部署更新Secrets和应用程序的配置时不必重新构建容器镜像，且不必将软件堆栈配置中的秘密信息暴露出来 批量执行：除了服务外，Kubernetes还可管理批处理和CI工作负载，在期望时替换掉失效的容器 水平扩缩：使用一个简单的命令、一个UI或基于CPU使用情况自动对应用程序进行扩缩 自动化上线和回滚：Kubernetes会分步骤地将针对应用或其配置的更改上线，同时监视应用程序运行状况以确保不会同时终止所有实例 自动装箱：根据资源需求和其他约束自动放置容器，同时避免影响可用性 自我修复：重新启动失败的容器，在节点死亡时替换并重新调度容器，杀死不响应用户定义的健康检查的容器 K8S核心架构原理 K8S属于主从设备模型即Master-Slave架构，Master节点负责核心调度、管理和运维，Slave节点则执行用户程序，主节点一般被称为Master Node或Head Node，从节点被称为Worker Node或Node。 Master Node和Worker Node是分别安装了K8S的Master和Woker组件的实体服务器，每个Node都对应了一台实体服务器，虽然Master Node可和其中一个Worker Node安装在同一台服务器，但建议Master Node单独部，所有Master Node和Worker Node组成了K8S集群，同一个集群可能存在多个Master Node和Worker Node。 Master Node包含的组件 API Server：K8S请求入口服务，API Server负责接收K8S所有包括来自UI界面或CLI命令行工具的请求，然后根据用户具体请求，去通知其他组件干活 Scheduler：K8S所有Worker Node的调度器，当用户部署服务时，Scheduler会选择最合适的Worker Node服务器来部署服务 Controller Manager：K8S所有Worker Node的监控器，Controller Manager有很多具体的Controller， Node Controller、Service Controller、Volume Controller等。Controller负责监控和调整在Worker Node上部署的服务的状态，如用户要求A服务部署2个副本，若当其中一个服务挂了时，Controller会马上调整，让 Scheduler再选择一个Worker Node重新部署服务 etcd：K8S的存储服务，存储了K8S的关键配置和用户配置，仅API Server具备读写权限，其他组件必须通过API Server接口才能读写数据 Worker Node包含的组件 Kubelet：Worker Node监视器，与Master Node的通讯器，Kubelet是Master Node安插在Worker Node上的眼线，它会定期向Master Node汇报自己Node上运行的服务的状态，并接受来自Master Node的指示采取调整措施，负责控制所有容器的启动停止，保证节点工作正常 Kube-Proxy：K8S的网络代理，负责Node在K8S的网络通讯、以及对外部网络流量的负载均衡 Container Runtime：Worker Node的运行环境，即安装了容器化所需的软件环境确保容器化程序能够跑起来，如Docker Engine运行环境 协同工作流程用K8S部署Nginx的过程中，K8S内部各组件的协同工作流程，若在Master节点执行一条命令kubectl create deployment nginx --image=nginx要Master部署一个nginx应用 该命令首先发到Master节点的网关API Server API Server将命令请求交给Controller Mannager进行控制 Controller Mannager进行应用部署解析，生成一次部署信息，并通过API Server将信息存入etcd Scheduler调度器通过API Server从etcd存储中获取要部署的应用，开始调度看哪个节点有资源适合部署 Scheduler把计算出来的调度信息通过API Server再存入etcd中 每个Node节点的监控组件kubelet，随时和Master保持联系，给API Server发送请求不断获取最新数据，拿到Master节点存储在etcd中的部署信息 若node2的kubelet拿到部署信息，显示其自己节点要部署该nginx应用 kubelet监控组件就自己run一个应用在当前机器上，并随时给Master汇报当前应用的状态信息 Node和Master也是通过Master的API Server组件联系的 每个机器上的kube-proxy能知道集群的所有网络，只要Node访问别人或别人访问Node，Node上的kube-proxy网络代理自动计算进行流量转发 K8S核心概念DeploymentDeployment负责创建和更新应用程序的实例。创建Deployment后，Kubernetes Master将应用程序实例调度到集群中的各个节点上，若托管实例的节点关闭或被删除，Deployment控制器会将该实例替换为群集中另一个节点上的实例。这提供了一种自我修复机制来解决机器故障维护问题。 PodPod相当于逻辑主机的概念，负责托管应用实例，包括一个或多个应用程序容器如Docker，以及这些容器的一些共享资源，共享存储、网络、运行信息等。 ServiceService是一个抽象层，它定义了一组Pod的逻辑集，并为这些Pod支持外部流量暴露、负载平衡和服务发现。尽管每个Pod都有一个唯一的IP地址，但若没有Service，这些IP不会暴露在群集外部，Service允许应用程序接收流量。Service也可用在ServiceSpec标记type的方式暴露，type类型如下： ClusterIP：默认，在集群的内部IP上公开Service，这种类型使得Service只能从集群内访问 NodePort：使用NAT在集群中每个选定Node的相同端口上公开Service，使用&lt;NodeIP&gt;:&lt;NodePort&gt;从集群外部访问Service，是ClusterIP的超集 LoadBalancer：在当前云中创建一个外部负载均衡器若支持的话，并为Service分配一个固定的外部IP，是NodePort的超集 ExternalName：通过返回带有该名称的CNAME记录公开Service，不使用代理，使用任意名称，由spec中的externalName指定 Service是K8S服务的核心屏蔽了服务细节，统一对外暴露服务接口，如一个服务A部署了3个备份，即3个Pod，对于用户来说，只需要关注一个Service的入即可，而不需要操心究竟应该请求哪一个Pod。外部用户不需要感知因为Pod上服务的意外崩溃、K8S重新拉起Pod而造成的IP变更，外部用户也不需要感知因升级、变更服务带来的Pod替换而造成的IP变化。 Service还可以做流量负载均衡，主要负责K8S集群内部的网络拓扑，集群外部访问集群内部可通过Ingress来完成，Ingress是对集群中服务的外部访问进行管理的API对象，典型的访问方式是HTTP，Ingress可提供负载均衡、SSL终结和基于名称的虚拟托管，Ingress是整个K8S集群的接入层，负责集群内外通讯，Ingress和Service的网络拓扑关系图如下： K8S安装12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# 关闭防火墙systemctl stop firewalldsystemctl disable firewalld# 关闭selinuxsed -i 's/enforcing/disabled/' /etc/selinux/config # 永久关闭setenforce 0 # 临时关闭# 关闭swapswapoff -a # 临时关闭vim /etc/fstab # 永久关闭，注释掉/etc/fstab文件下面这行代码# /dev/mapper/centos‐swap swap swap defaults 0 0systemctl reboot # 重启生效free -m # 查看下swap交换区是否都为0，如果都为0则swap关闭成功# 给机器设置主机名hostnamectl set-hostname &lt;hostname&gt;# 给机器名称配置hostsvim /etc/hosts# 添加如下行192.168.0.180 eleven# 将桥接的IPv4流量传递到iptablesvim /etc/sysctl.d/k8s.conf# 添加下面两行配置net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1sysctl --system # 生效# 设置时间同步yum install ntpdate -yntpdate time.windows.com# 添加k8s yum源vim /etc/yum.repos.d/kubernetes.repo# 添加如下配置[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpghttps://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg# 若之前安装过k8s，先卸载旧版本yum remove -y kubelet kubeadm kubectl# 查看可以安装的版本yum list kubelet --showduplicates | sort -r# 安装kubelet、kubeadm、kubectl指定版本，这里使用kubeadm方式安装k8s集群yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0# 开机启动kubeletsystemctl enable kubeletsystemctl start kubelet# 在k8s的Master机器上执行初始化操作kubeadm init --apiserver-advertise-address=192.168.0.180 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16# 配置使用kubectl命令工具(类似docker这个命令)mkdir -p $HOME/.kubechmod 666 /etc/kubernetes/admin.confsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# 查看kubectl是否能正常使用，此时节点状态为NotReady，安装Pod网络插件后才会变为Ready状态kubectl get nodes# 安装Pod网络插件kubectl apply -f https://docs.projectcalico.org/manifests/calico.yamlkubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/canal/rbac.yaml# 若上面这个calico网络插件安装不成功可以试下下面这个# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kubeflannel.yml# 将node节点加入进Master节点的集群里，复制kubeadm init命令执行后的输出中的kubeadm join内容kubeadm join 192.168.65.160:6443 --token hbovty.6x82bkdlsk6dfy32 \\ --discovery-token-ca-cert-hash sha256:659511b431f276b2a5f47397677b1dff74838ae5eb18e24135e6dae1b8c45840# 将Master也当作Node使用，xxx-nodename表示节点名称，或主机IP，也可使用--all参数kubectl taint node xxx-nodename node-role.kubernetes.io/master-kubectl taint nodes --all node-role.kubernetes.io/master-# 将Master恢复成Master Only状态，xxx-nodename表示节点名称，或主机IPkubectl taint node xxx-nodename node-role.kubernetes.io/master=\"\":NoSchedule# 要删除k8s-node1节点，首先在master节点上依次执行以下两个命令kubectl drain k8s‐node1 --delete-local-data --force --ignore-daemonsetskubectl delete node k8s-node1# 在k8s-node1这个Node节点上执行如下命令，这样该节点即完全从k8s集群中脱离开来kubeadm reset 命令补全1234yum -y install bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bashrc K8S部署应用kubectl是API Server的客户端工具，工作在命令行下，能够连接API Server实现各种增删改查等操作 123456789101112131415161718192021222324252627282930313233343536# 创建一次deployment部署kubectl create deployment nginx --image=nginxkubectl expose deployment nginx --port=80 --type=NodePort# 查看Nginx的pod和service信息kubectl get pod,svc -o wide# my‐tomcat表示pod的名称 --image表示镜像的地址kubectl create deployment my-tomcat --image=tomcat:7.0.75-alpinekubectl get deploymentkubectl get pod -o wide# 查看Pod打印的日志kubectl logs my-tomcat-6d9cf656c4-45xk5# 使用exec可在Pod的容器中执行命令，使用env命令查看环境变量kubectl exec my-tomcat-6d9cf656c4-45xk5 -- env# 查看容器的根目录下面内容kubectl exec my-tomcat-6d9cf656c4-45xk5 -- ls /# 进入Pod容器内部并执行bash命令，若想退出容器可以使用exit命令kubectl exec -it my-tomcat-6d9cf656c4-45xk5 -- sh# 在集群外是无法访问Pod的，需要创建一个service服务，才能让外部客户端可访问Pod# --name指定service名称，若端口暴露类型为NodePort，可通过集群内任意一台主机加暴露端口进行访问kubectl expose deployment my-tomcat --name=tomcat --port=8080 --type=NodePort#查看service信息，port信息里冒号后面的端口号就是对集群外暴露的访问接口kubectl get svc -o wide# 查看pod信息，‐w意思是一直等待观察pod信息的变动kubectl get pod -w# 查看pod、deployment、service等所有信息kubectl get all -o wide# 删除刚刚创建的Pod，k8s会重新启动一个新的pod，这是k8s的服务自愈功能kubectl delete pod my-tomcat-6d9cf656c4-45xk5# 真正删除podkubectl delete deployment my-tomcat# 删除servicekubectl delete service tomcat 扩容缩容1234# 扩容到3个podkubectl scale --replicas=3 deployment my-tomcat# 缩容到2个podkubectl scale --replicas=2 deployment my-tomcat 滚动升级与回滚滚动升级并不是一次性将多个pod全部停掉升级，而是一个一个的滚动升级 1234567# 滚动升级将tomcat版本由tomcat:7.0.75-alpine升级到tomcat:8.0.41-jre8-alpinekubectl set image deployment my-tomcat tomcat=tomcat:8.0.41-jre8-alpine# 查看历史版本kubectl rollout history deploy my-tomcat# 回滚到上一个版本，也可通过--to-revision参数可指定回退的版本kubectl rollout undo deployment my-tomcat 标签通过给资源添加Label，可方便地管理资源，如Deployment、Pod、Service等 1234567891011121314# 查看Deployment中所包含的Label，该命令是查询deployment详细信息，该信息中包括Label信息kubectl describe deployment my-tomcat# 通过Label查询Podkubectl get pods -l app=my-tomcat# 通过Label查询serviceskubectl get services -l app=my-tomcat# 给Pod添加Labelkubectl label pod my-tomcat-6d9cf656c4-45xk5 version=v1# 查看Pod的详细信息，包括Label信息kubectl describe pods my-tomcat-6d9cf656c4-45xk5# 通过Label查询Podkubectl get pods -l version=v1# 通过Label删除服务kubectl delete service -l app=test-service 问题排查12345678910# 查看Pod内部某个container打印的日志kubectl log $&#123;POD_NAME&#125; -c $&#123;CONTAINER_NAME&#125;# 查看Pod打印的日志kubectl logs my-tomcat-6d9cf656c4-45xk5# 使用exec可在Pod的容器中执行命令，使用env命令查看环境变量kubectl exec my-tomcat-6d9cf656c4-45xk5 -- env# 查看容器的根目录下面内容kubectl exec my-tomcat-6d9cf656c4-45xk5 -- ls /# 进入Pod容器内部并执行bash命令，若想退出容器可以使用exit命令kubectl exec -it my-tomcat-6d9cf656c4-45xk5 -- sh K8S中的资源K8S中所有内容都抽象为资源， 资源实例化之后叫做对象，上面说的那些核心概念都是K8S中的资源： workload工作负载型资源：Pod、ReplicaSet、Deployment、StatefulSet、DaemonSet等等 ServiceDiscovery LoadBalance服务发现及负载均衡型资源：Service、Ingress等等 配置与存储型资源： Volume存储卷、CSI容器存储接口、可扩展各种各样的第三方存储卷 特殊类型的存储卷：ConfigMap当配置中心来使用的资源类型、Secret保存敏感数据、DownwardAPI把外部环境中的信息输出给容器 集群级资源：Namespace、Node、Role、ClusterRole、RoleBinding角色绑定、ClusterRoleBinding集群角色绑定 元数据型资源：HPA即Pod水平扩展、PodTemplate即Pod模板，用于让控制器创建Pod时使用的模板、LimitRange用来定义硬件资源限制 资源清单上面直接用命令创建deployment，pod，service这些资源，在k8s中一般都会使用yaml格式的文件来创建符合预期期望的资源，这样的yaml文件一般称为资源清单。 使用资源清单yaml来创建k8s的资源对象，用yaml创建deployment资源的对象，可用创建deployment的命令加上参数--dry-run -o yaml就可以输出这次部署的资源清单yaml 1kubectl create deployment my-tomcat --image=tomcat:7.0.75‐alpine --dry-run -o yaml 对上面的yaml适当的修改下保存为文件tomcat-deployment-demo.yaml 123456789101112131415161718192021222324apiVersion: apps/v1kind: Deploymentmetadata: creationTimestamp: null labels: app: my-tomcat-yaml name: my-tomcat-yaml #修改deployment的名称spec: replicas: 2 # 修改pod副本为两个 selector: matchLabels: app: my-tomcat-yaml strategy: &#123;&#125; template: metadata: creationTimestamp: null labels: app: my-tomcat-yaml spec: containers: - image: tomcat:7.0.75-alpine name: tomcat resources: &#123;&#125;status: &#123;&#125; 1234# 用yaml文件来创建这次部署kubectl apply -f tomcat-deployment-demo.yaml# 用yaml创建service资源的对象kubectl expose deployment my-tomcat-yaml --name=tomcat --port=8080 --type=NodePort --dry-run -o yaml 用yaml创建service资源的对象，保存为文件tomcat-service-demo.yaml 1234567891011121314151617apiVersion: v1kind: Servicemetadata: creationTimestamp: null labels: app: my-tomcat-yaml name: tomcat-service-yaml # 修改Service名称spec: ports: - port: 8081 # service虚拟ip对应的端口，在集群内网机器可用service的虚拟ip加该端口号访问服务 protocol: TCP targetPort: 8080 # pod暴露的端口，一般与pod内部容器暴露的端口一致 selector: app: my-tomcat-yaml type: NodePortstatus: loadBalancer: &#123;&#125; 123456# 用yaml文件来创建servicekubectl apply -f tomcat-service-demo.yaml# 针对已有资源输出资源清单yaml，使用-o参数加yaml，可将资源的配置以yaml的格式输出出来，也可使用json，输出为json格式kubectl get pod nginx-deploy-7db697dfbd-2qh7v -o yamlkubectl get service nginx -o yamlkubectl get deployment nginx -o yaml K8S高级特性K8S中还有一些高级特性如弹性扩缩应用、滚动更新、配置管理、存储卷、网关路由等。 ReplicaSetReplicaSet确保任何时间都有指定数量的Pod副本在运行，通常用来保证给定数量的、完全相同的Pod的可用性。建议使用Deployment来管理ReplicaSet，而不是直接使用ReplicaSet。 ConfigMapConfigMap是一种API对象，用来将非机密性的数据保存到键值对中。使用时Pod可将其用作环境变量、命令行参数或存储卷中的配置文件。使用ConfigMap可将配置数据和应用程序代码分开。 VolumeVolume指的是存储卷，包含可被Pod中容器访问的数据目录，容器中文件在磁盘上是临时存放，当容器崩溃时文件会丢失，同时无法在多个Pod中共享文件，通过使用存储卷可以解决这两个问题，常用存储卷： configMap：提供向Pod注入配置数据的方法，ConfigMap对象中存储的数据可被configMap类型的卷引用，然后被Pod中运行的容器化应用使用 emptyDir：emptyDir卷可用于存储缓存数据，当Pod分派到某个Node上时emptyDir卷会被创建，且Pod在该节点上运行期间卷一直存在，当Pod被从节点上删除时emptyDir卷中的数据也会被永久删除 hostPath：将主机节点文件系统上的文件或目录挂载到Pod中，在Minikube中的主机指的是Minikube所在虚拟机 local：代表某个被挂载的本地存储设备，如磁盘、分区或目录，local卷只能用作静态创建的持久卷，尚不支持动态配置 nfs：将NFS网络文件系统挂载到Pod中 persistentVolumeClaim：将持久卷PersistentVolume挂载到Pod中，持久卷是集群中的一块存储，可以由管理员事先供应，或使用存储类Storage Class来动态供应，持久卷是集群资源类似于节点 Ingress 通过Ingress资源可实现类似Nginx的基于域名访问，从而实现Pod的负载均衡访问，进入ingress-nginx将里面内容复制保存到k8s master机器上的ingress-controller.yaml文件中，修改镜像地址。 123456# 安装ingresskubectl apply -f ingress-controller.yaml# 查看是否安装成功kubectl get pods -n ingress-nginx -o wide# 查看日志kubectl logs -f nginx-ingress-controller-2dvwn -n ingress-nginx 配置ingress访问规则，类似配置nginx的代理转发配置，让ingress将域名tomcat.eleven.com转发给后端的tomcat-service-yaml服务，新建ingress-tomcat.yaml文件： 12345678910111213apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: web-ingressspec: rules: - host: tomcat.eleven.com # 转发域名 http: paths: - path: / backend: serviceName: tomcat-service-yaml # service名称 servicePort: 8081 # service的端口 123456789# 生效规则kubectl apply -f ingress-tomcat.yaml# 卸载资源kubectl delete -f ingress-tomcat.yaml# 查看生效的ingress规则kubectl get ing kubectl describe ing web-ingress# 在hosts中配置：192.168.0.180 tomcat.eleven.comecho \"192.168.0.180 tomcat.eleven.com\" &gt;&gt; /etc/hosts ConfigMapConfigMap允许将配置文件与镜像文件分离，将ConfigMap属性注入到Pod的环境变量中去，使容器化的应用程序具有可移植性。添加nginx-config.yaml配置文件用于创建ConfigMap，ConfigMap名称为nginx-config，配置信息存放在data节点下： 1234567apiVersion: v1kind: ConfigMapmetadata: name: nginx-config namespace: defaultdata: nginx-env: test 123456# 应用nginx-config.yaml文件创建ConfigMapkubectl create -f nginx-config.yaml# 获取所有ConfigMapkubectl get configmap# 通过yaml格式查看ConfigMap中的内容kubectl get configmaps nginx-config -o yaml 添加配置文件nginx-deployment.yaml用于创建Deployment，部署一个Nginx服务，在Nginx的环境变量中引用ConfigMap中的属性： 123456789101112131415161718192021222324252627apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.10 ports: - containerPort: 80 env: - name: NGINX_ENV # 在Nginx中设置环境变量 valueFrom: configMapKeyRef: name: nginx-config # 设置ConfigMap的名称 key: nginx-env # 需要取值的键 1234# 应用配置文件文件创建Deploymentkubectl apply -f nginx-deployment.yaml# 创建成功后查看Pod中的环境变量，发现NGINX_ENV变量已经被注入了kubectl exec nginx-deployment-7cf97748c4-tcq5v -- env 存储卷的使用通过存储卷可把外部数据挂载到容器中去，供容器中的应用访问，这样就算容器崩溃了，数据依然可以存在，使用Docker部署Nginx时，将Nginx的html、logs、conf目录从外部挂载到容器中： 12345docker run -p 80:80 --name nginx \\-v /data/nginx/html:/usr/share/nginx/html \\-v /data/nginx/logs:/var/log/nginx \\-v /data/nginx/conf:/etc/nginx \\-d nginx:1.10 Minikube可认为是一台虚拟机，可用Minikube的ssh命令来访问它 1234567minikube ssh# Minikube中默认有一个docker用户，我们先重置下它的密码sudo passwd docker# 在Minikube中创建data目录midir /home/docker/data# 把Nginx数据目录复制到Minikube中，才能实现目录的挂载，注意docker用户只能修改/home/docker目录中的文件，通过scp命令来复制文件scp -r /home/macro/data/nginx docker@192.168.0.180:/home/docker/data/nginx 添加nginx-volume-deployment.yaml配置文件用于创建Deployment 1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-volume-deployment labels: app: nginxspec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.10 ports: - containerPort: 80 volumeMounts: - mountPath: /usr/share/nginx/html name: html-volume - mountPath: /var/log/nginx name: logs-volume - mountPath: /etc/nginx name: conf-volume volumes: - name: html-volume hostPath: path: /home/docker/data/nginx/html type: Directory - name: logs-volume hostPath: path: /home/docker/data/nginx/logs type: Directory - name: conf-volume hostPath: path: /home/docker/data/nginx/conf type: Directory 1234# 应用配置文件创建Deploymentkubectl apply -f nginx-volume-deployment.yaml# 应用配置文件创建Servicekubectl apply -f nginx-service.yaml 添加nginx-service.yaml配置文件用于创建Service 1234567891011121314apiVersion: v1kind: Service metadata: name: nginx-servicespec: type: NodePort selector: app: nginx ports: - name: http protocol: TCP port: 80 targetPort: 80 nodePort: 30080 K8S与DockerDocker作为非常流行的容器技术，经常有文章说它被K8S弃用了，取而代之的是另一种容器技术containerd，containerd只是从Docker中分离出来的底层容器运行时，使用起来和Docker并没有什么区别，从Docker转型containerd非常简单，只要把之前Docker命令中的docker改为crictl基本就可以了用法一样。 K8S发布CRI即Container Runtime Interface统一了容器运行时接口，凡是支持CRI的容器运行时，皆可作为K8S的底层容器运行时，若K8S使用Docker作为K8S容器运行时的话，kubelet需要先要通过dockershim去调用Docker，再通过Docker去调用containerd，若使用containerd作为K8S容器运行时的话，由于containerd内置了CRI插件，kubelet可直接调用containerd，使用containerd不仅调用链变短了性能提高了，且资源占用也会变小，毕竟Docker不是一个纯粹的容器运行时，具有大量其他功能，未来Docker可能自己直接实现K8S的CRI接口来兼容K8S的底层使用。 实战Docker部署过的eureka应用为例，首先将镜像发布到镜像仓库中，然后创建用于创建Deployment的配置文件eureka-app-deployment.yaml 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: Deploymentmetadata: name: eureka-app-deployment labels: app: eureka-appspec: replicas: 1 selector: matchLabels: app: eureka-app template: metadata: labels: app: eureka-app spec: containers: - name: eureka-app # 指定Docker Hub中的镜像地址 image: 3120130802229/eleven-eureka-server:0.0.1 # Always总是拉取镜像，IfNotPresent(默认该值) 本地有则使用本地镜像，Never只使用本地镜像，从不拉取，即使本地没有镜像 imagePullPolicy: Always ports: - containerPort: 8761 env: - name: TZ value: Asia/Shanghai - name: LOG_FILE value: /var/logs volumeMounts: - mountPath: /var/logs name: log-volume volumes: - name: log-volume hostPath: path: /data/k8s-app/eureka/logs type: DirectoryOrCreate dnsPolicy: Default # 继承Pod所在宿主机的DNS设置，使pod能访问外网 创建用于创建Service的配置文件eureka-app-service.yaml 12345678910111213apiVersion: v1kind: Servicemetadata: name: eureka-app-servicespec: type: NodePort selector: app: eureka-app ports: - name: http protocol: TCP port: 8761 # service的端口 targetPort: 8761 # pod的端口，一般与pod内部容器的服务端口一致 1234# 通过应用配置文件来创建Deploymentkubectl apply -f eureka-app-deployment.yaml# 通过应用配置文件来创建Servicekubectl apply -f eureka-app-service.yaml","tags":[{"name":"k8s","slug":"k8s","permalink":"https://yaoyinglong.github.io/tags/k8s/"}],"categories":[{"name":"云原生","slug":"云原生","permalink":"https://yaoyinglong.github.io/categories/云原生/"}]},{"title":"Docker搭建Prometheus&Grafana","date":"2022-02-14T16:00:00.000Z","path":"Blog/云原生/Docker搭建Prometheus&Grafana/","text":"PrometheusPrometheus集成了数据的采集，处理，存储，展示，告警一系列流程，存储数据是使用多维数据模型即由度量名称和键值对标识的时间序列数据，通过灵活的查询语言PromSQL利用多维数据完成复杂查询，不依赖分布式存储，单个服务器节点可直接工作，基于HTTP的pull方式釆集时间序列数据，通过PushGateway组件支持推送时间序列数据，通过服务发现或静态配罝发现目标，通过Grafana支持多种图形模式及仪表盘。 Prometheus Server主要功能是收集指标和存储时间序列数据到TSDB，并提供查询接口，通过PushGateway短期存储指标数据用于临时性任务，Exporters采集已有的三方服务监控指标并暴露metrics，Alertmanager提供告警支持，Web UI提供简单的WEB控制台。 数据模型Prometheus将所有数据存储为时间序列，具有相同度量名称和标签属于同一指标，即Prometheus从数据源拿到数据后会存到内置的TSDB中，TSDB中存储的就是时间序列数据，它存储的数据会有一个度量名称，如监控一个nginx首先得起个名字，该名称即度量名，还会有N个标签，可理解名称为表名标签为字段，每个时间序列都由度量标准名称和一组键值对即标签唯一标识。 时间序列的格式&lt;metricename&gt; {&lt;labelname&gt;=&lt;labelvalue&gt;, ...}，metricename为度量标准名称，labelname为标签名，该标签可有多个，如jvm_memory_max_bytes{area=&quot;heap&quot;,id=&quot;Eden Space&quot;,}，还可以继续指定标签，指定的标签越多查询的维度就越多。 指标类型 类型名称 说明 Counter 递增计数器，适合收集接口请求次数 Guage 可任意变化的数值，适用CPU使用率 Histogram 对一段时间内数据进行采集，并对有所数值求和用于统计数量 Summary 与Histogram类型类似 任务&amp;实例实例即可抓取的目标target，会在Prometheus配置文件中体现，任务是具有相同目标的实例集合，可理解为一个组，如订单服务多台实例机器，可放入一个任务中，分多个实例target抓取。 Prometheus部署对于SpringBoot项目需要开启SpringBoot监控和增加Prometheus整合，添加如下依赖： 12345678910&lt;!-- 开启springboot的应用监控 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 增加prometheus整合 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; 还需要在具体的服务配置文件中增加开启SpringBoot Admin监控的配置： 12345678910management: # 开启SpringBoot Admin的监控 endpoints: promethus: enable: true web: exposure: include: '*' endpoint: health: show-details: always 通过Docker来安装，新建目录/data/docker/docker-prometheus，在里面创建文件docker-compose-app.yml： 123456789101112version: \"3\"services: prometheus: image: prom/prometheus:v2.4.3 container_name: 'prometheus' volumes: # 映射prometheus的配置文件 - /data/docker/docker-prometheus/prometheus/:/etc/prometheus/ # 同步容器与宿主机的时间，非常重要，若时间不一致，会导致prometheus抓不到数据 - /etc/localtime:/etc/localtime:ro ports: - '9090:9090' 创建Prometheus配置文件/data/docker/docker-prometheus/prometheus/prometheus.yml： 123456789101112131415161718192021global: # 全局配置 scrape_interval: 15s # 全局定时任务抓取性能数据间隔scrape_configs: # 抓取性能数据任务配置 # 抓取订单服务性能指标数据任务，一个job下可以配置多个抓取的targets，如订单服务多个实例机器 - job_name: 'mall-order' scrape_interval: 10s #每10s抓取一次 metrics_path: '/actuator/prometheus' # 抓取的数据url static_configs: - targets: ['192.168.0.180:8011'] # 抓取的服务器地址 labels: application: 'mall-order-label1' # 抓取任务标签 - targets: ['192.168.0.180:8012'] # 抓取的服务器地址 labels: application: 'mall-order-label2' # 抓取任务标签 # 抓取prometheus自身性能指标数据任务 - job_name: 'prometheus' scrape_interval: 5s static_configs: - targets: ['localhost:9090'] 12# 启动prometheusdocker-compose -f docker-compose-app.yml up -d Grafana部署在上面的docker-compose-app.yml配置文件中加入Grafana的安装配置 12345678910111213141516171819202122232425262728version: \"3\"services: prometheus: image: prom/prometheus:v2.4.3 container_name: 'prometheus' volumes: # 映射prometheus的配置文件 - /data/docker/docker-prometheus/prometheus/:/etc/prometheus/ # 同步容器与宿主机的时间，非常重要，若时间不一致，会导致prometheus抓不到数据 - /etc/localtime:/etc/localtime:ro ports: - '9090:9090' grafana: image: grafana/grafana:5.2.4 container_name: 'grafana' ports: - '3000:3000' volumes: # grafana报警邮件配置 - ./grafana/config/grafana.ini:/etc/grafana/grafana.ini # 配置grafana的prometheus数据源 - ./grafana/provisioning/:/etc/grafana/provisioning/ - /etc/localtime:/etc/localtime:ro env_file: - ./grafana/config.monitoring # grafana登录配置 depends_on: - prometheus # grafana需要在prometheus之后启动 在docker-prometheus目录下新增grafana目录，在grafana目录中创建config.monitoring配置文件 1234# grafana管理界面的登录用户密码，用户名是adminGF_SECURITY_ADMIN_PASSWORD=password# grafana管理界面是否允许注册，默认不允许GF_USERS_ALLOW_SIGN_UP=false 在grafana目录下创建provisioning目录，在provisioning目录中创建datasources目录，在datasources目录中新建datasource.yml配置文件 1234567891011121314151617# config file versionapiVersion: 1deleteDatasources: # 若之前存在name为Prometheus，orgId为1的数据源先删除 - name: Prometheus orgId: 1datasources: # 配置Prometheus的数据源 - name: Prometheus type: prometheus access: proxy orgId: 1 url: http://prometheus:9090 # 在相同的docker compose下，可直接用prometheus服务名直接访问 basicAuth: false isDefault: true version: 1 editable: true 在grafana目录下创建config目录，在config目录中创建grafana.ini配置文件 1234567891011121314#################################### SMTP / Emailing ########################### 配置邮件服务器[smtp]enabled = true# 发件服务器host = smtp.qq.com:465# smtp账号user = 906271196@qq.com# smtp 授权码password = test123# 发信邮箱from_address = 906271196@qq.com# 发信人from_name = eleven 监控MySQL性能指标在prometheus.yml文件末尾追加如下配置： 123456- job_name: 'mysql' scrape_interval: 5s static_configs: - targets: ['192.168.0.180:9104'] labels: instance: mysql 123456# 下载mysql客户端的exporter镜像docker pull prom/mysqld-exporter# 启动监控的数据库连接，容器创建时需指定docker run -d -p 9104:9104 -e DATA_SOURCE_NAME=\"root:password@(mysql服务器ip:3306)/databaseName\" prom/mysqld-exporter# 重新启动Prometheus镜像docker-compose up --force-recreate -d 导入Prometheus模板，添加mysql-dashboard.json格式模板，模板文件可到Grafana官网或github上下载 监控Redis性能指标在prometheus.yml文件末尾追加如下配置： 123456- job_name: 'redis' scrape_interval: 5s static_configs: - targets: ['192.168.0.180:9121'] labels: instance: redis 123456# 下载redis客户端的exporter镜像docker pull oliver006/redis_exporter# 启动监控的数据库连接，容器创建时需指定docker run -d -p 9121:9121 oliver006/redis_exporter --redis.addr redis://redis连接IP:6379# 重新启动Prometheus镜像docker-compose up --force-recreate -d 导入Prometheus模板，添加redis-dashboard.json格式模板，模板文件可到Grafana官网或github上下载 监控Linux服务器性能指标在prometheus.yml文件末尾追加如下配置： 123456789101112131415- job_name: linux scrape_interval: 10s static_configs: - targets: ['192.168.0.180:9100'] labels: instance: linux-180 - targets: ['192.168.0.181:9100'] labels: instance: linux-181 - targets: ['192.168.0.182:9100'] labels: instance: linux-182 - targets: ['192.168.0.183:9100'] labels: instance: linux-183 123456# 下载linux监控的exporter镜像docker pull prom/node-exporter# 启动监控的数据库连接，容器创建时需指定docker run -d -p 9100:9100 prom/node-exporter# 重新启动Prometheus镜像docker-compose up --force-recreate -d 导入Prometheus模板，添加linux-dashboard.json格式模板，模板文件可到Grafana官网或github上下载","tags":[{"name":"Docker","slug":"Docker","permalink":"https://yaoyinglong.github.io/tags/Docker/"}],"categories":[{"name":"云原生","slug":"云原生","permalink":"https://yaoyinglong.github.io/categories/云原生/"}]},{"title":"Docker Compose基础","date":"2022-02-13T16:00:00.000Z","path":"Blog/云原生/Docker Compose基础/","text":"使用微服务架构的应用系统一般包含若干个微服务，每个微服务一般都会部署多个实例，若每个微服务都要手动启停，效率很低、维护量很大。可使用Docker Compose来轻松、高效地管理容器。Docker Compose是一个用于定义和运行多容器的Docker应用的工具，使用Compose可在一个yaml格式的配置文件中配置应用服务，使用一个命令，即可创建并启动配置中引用的所有服务。 Docker Compose的安装有多种方式，可通过Shell安装、pip安装、作为容器安装等，以下是通过Shell安装： 1234# docker compose安装步骤sudo curl -L \"https://github.com/docker/compose/releases/download/1.28.6/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-composedocker-compose --version Docker Compose的使用只需要编写一个描述容器的配置docker-compose.yml配置文件，然后使用描述对容器的操作的docker-compose命令操作即可。 这里依然使用eureka-server-0.0.1-SNAPSHOT.jar，在该jar所在目录的上一级目录中创建docker-compose.yml配置文件文件，在该配置文件中配置如下： 12345678910version: '3.8'services: eureka: #指定服务名 image: eleven-eureka-server:0.0.1 #指定镜像名称 build: ./eureka #指定Dockfile所在路径 container_name: eleven-eureka-server #指定启动容器名称 ports: - \"8761:8761\" #指定端口映射 expose: - 8761 #声明容器对外暴露的端口 然后在docker-compose.yml配置文件文件所在路径执行docker-compose up启动服务，使用compose启动时会先创建一个默认的网络app_default，默认以compose所在文件目录名加_default命名，compose内的所有容器都会加入此网络，可用服务名相互访问，若镜像eleven-eureka-server:0.0.1不存在则先构建镜像，若镜像存在则不构建，加上--build参数可强制先构建镜像，若镜像之前构建过且构建文件没有变化或构建的内容没有变化，就算加上–build参数也不会重新构建，根据构建的镜像创建一个名称叫app_eureka_1的容器，app是docker-compose.yml配置文件文件所在目录，最后启动容器。 123# -d用于设置后台启动docker-compose up -ddocker-compose up -d --build Docker Compose将所管理的容器分为工程、服务、容器三层，Docker Compose运行目录下的所有文件包括docker-compose.yml、 extends文件或环境变量文件等组成一个工程，默认为docker-compose.yml所在目录的目录名称。一个工程可包含多个服务，每个服务中定义了容器运行的镜像、参数和依赖，一个服务可包括多个容器实例。 同一个docker compose内部的容器之间可用服务名相互访问，服务名就相当于hostname，可直接ping服务名，得到的就是服务对应容器的ip，若服务做了扩容一个服务对应了多个容器，则ping服务名会轮询访问服务对应的每台容器ip ，Docker底层用了LVS等技术实现该负载均衡。 docker-compose.yml常用指令可以参考docker-compose.yml文件官方文档 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# image指定镜像名称或镜像id，若该镜像在本地不存在，Compose会尝试pull下来image: java# 指定Dockerfile文件的路径build: ./dir# build也可以是一个对象，用以指定Dockerfile和参数build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1# 覆盖容器启动后默认执行的命令command: bundle exec thin -p 3000# command也可以是一个list，类似于Dockerfile中的CMD指令command: [bundle, exec, thin, -p, 3000]# links显示链接到其他服务中的容器，可指定服务名称和链接的别名使用SERVICE:ALIAS的形式，或者只指定服务名称links: - db - db:database - redis# 表示链接到docker-compose.yml外部的容器，甚至并非Compose管理的容器，特别是对于那些提供共享容器或共同服务external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql# 暴露端口信息，使用宿主端口:容器端口的格式，或者仅指定容器端口此时宿主机将会随机指定端口，类似于docker run -pports: - \"3000\" - \"3000-3005\" - \"8000:8000\" - \"9090-9091:8080-8081\" - \"49100:22\" - \"127.0.0.1:8001:8001\" - \"127.0.0.1:5000-5010:5000-5010\"# 暴露端口，只将端口暴露给连接的服务，而不暴露给宿主机expose: - \"3000\" - \"8000\" # 卷挂载路径设置，可设置宿主机路径HOST:CONTAINER或加上访问模式HOST:CONTAINER:rovolumes: # Just specify a path and let the Engine create a volume - /var/lib/mysql # Specify an absolute path mapping - /opt/data:/var/lib/mysql # Path on the host, relative to the Compose file - ./cache:/tmp/cache # User-relative path - ~/configs:/etc/configs/:ro # Named volume - datavolume:/var/lib/mysql# 从另一个服务或者容器挂载卷。可指定只读或可读写，若访问模式未指定，则默认是可读写volumes_from: - service_name - service_name:ro - container:container_name - container:container_name:rw# 设置环境变量，可使用数组或字典，只有一个key的环境变量可在运行Compose的机器上找到对应的值，这有助于加密的或特殊主机的值environment: RACK_ENV: development SHOW: 'true' SESSION_SECRET:environment: - RACK_ENV=development - SHOW=true - SESSION_SECRET# 从文件中获取环境变量，可为单独的文件路径或列表，若通过docker-compose -f FILE指定了模板文件，则env_file中路径会基于模板文件路径，若有变量名称与environment指令冲突，则以envirment为准env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env# extends继承另一个服务，基于已有的服务进行扩展# 设置网络模式net: \"bridge\"net: \"host\"net: \"none\"net: \"container:[service name or container name/id]\"# 配置dns服务器，可为一个值，也可为一个列表dns: 8.8.8.8dns: - 8.8.8.8 - 9.9.9.9# 配置DNS搜索域，可以是一个值，也可以是一个列表dns_search: example.comdns_search: - dc1.example.com - dc2.example.com 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144version: '3.8'services: mysql: image: mysql:5.7 container_name: mysql # 覆盖容器启动后默认执行的启动mysql命令 command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci restart: always # 关机或者重启机器时，docker同时重启容器，一般mysql服务可这么设置，保持服务一直都在 environment: MYSQL_ROOT_PASSWORD: root # 设置root帐号密码 ports: - 3306:3306 volumes: - /data/mysql/data/db:/var/lib/mysql # 数据文件挂载 - /data/mysql/data/conf:/etc/mysql/conf.d # 配置文件挂载 - /data/mysql/log:/var/log/mysql # 日志文件挂载 - /etc/localtime:/etc/localtime:ro #同步宿主机与容器时间，ro代表readonly只读 redis: image: redis:5.0 container_name: redis command: redis-server --appendonly yes volumes: - /data/redis/data:/data # 数据文件挂载 ports: - 6379:6379 rabbitmq: image: rabbitmq:3.7.25-management container_name: rabbitmq volumes: - /data/rabbitmq/data:/var/lib/rabbitmq # 数据文件挂载 - /data/rabbitmq/log:/var/log/rabbitmq # 日志文件挂载 ports: - 5672:5672 - 15672:15672 elasticsearch: image: elasticsearch:6.4.0 container_name: elasticsearch environment: - \"cluster.name=elasticsearch\" # 设置集群名称为elasticsearch - \"discovery.type=single-node\" # 单一节点模式启动 - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" # 置使用jvm内存大小，稍微配置大点，不然有可能启动不成功 volumes: - /data/elasticsearch/plugins:/usr/share/elasticsearch/plugins # 插件文件挂载 - /data/elasticsearch/data:/usr/share/elasticsearch/data # 数据文件挂载 ports: - 9200:9200 - 9300:9300 kibana: image: kibana:6.4.0 container_name: kibana # 一个compose文件管理的服务可直接用服务名访问，若给服务取别名则可用links实现，如下面的es就是elasticsearch服务别名 links: - elasticsearch:es # 用es这个域名访问elasticsearch服务 depends_on: - elasticsearch # kibana在elasticsearch启动之后再启动 environment: - \"elasticsearch.hosts=http://es:9200\" # 设置访问elasticsearch的地址 ports: - 5601:5601 logstash: image: logstash:6.4.0 container_name: logstash volumes: # 挂载logstash的配置文件，docker对单个文件的挂载需要先在宿主机建好对应文件才能挂载成功 - /data/logstash/logstash-springboot.conf:/usr/share/logstash/pipeline/logstash.conf depends_on: - elasticsearch # kibana在elasticsearch启动之后再启动 links: - elasticsearch:es # 可用es这个域名访问elasticsearch服务 ports: - 4560:4560 mongo: image: mongo:3.2 container_name: mongo volumes: - /data/mongo/db:/data/db # 数据文件挂载 ports: - 27017:27017 nacos: image: nacos/nacos-server:1.4.2 container_name: nacos environment: - MODE=standalone volumes: - /data/nacos/logs/:/home/nacos/logs ports: - \"8848:8848\" zookeeper: image: zookeeper:3.5 ports: - 2181:2181 volumes: - /data/zookeeper/data:/data - /data/zookeeper/conf:/conf rocketmq: image: rocketmqinc/rocketmq container_name: rocketmq restart: always ports: - 9876:9876 volumes: - /data/rocketmq/logs:/home/rocketmq/logs - /data/rocketmq/store:/home/rocketmq/store command: sh mqnamesrv broker: image: rocketmqinc/rocketmq container_name: rmqbroker restart: always ports: - 10909:10909 - 10911:10911 - 10912:10912 volumes: - /data/rocketmq/logs:/home/rocketmq/logs - /data/rocketmq/store:/home/rocketmq/store # 该配置需要先在宿主机对应目录放好broker.conf配置文件，文件内容参考下面文档 - /data/rocketmq/conf/broker.conf:/opt/rocketmq-4.4.0/conf/broker.conf command: sh mqbroker -n namesrv:9876 -c ../conf/broker.conf depends_on: - rocketmq environment: - JAVA_HOME=/usr/lib/jvm/jre console: image: styletang/rocketmq-console-ng container_name: rocketmq-console-ng restart: always ports: - 8076:8080 depends_on: - rocketmq environment: - JAVA_OPTS= -Dlogging.level.root=info -Drocketmq.namesrv.addr=rocketmq:9876 - Dcom.rocketmq.sendMessageWithVIPChannel=false 12345678brokerName = broker-abrokerId = 0deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSH# 宿主机IPbrokerIP1=192.168.65.42 docker-compose命令123456789101112131415161718# 查看compose内的容器docker-compose -f docker-compose-app.yml ps# 关闭或启动或重启compose内的某个容器docker-compose -f docker-compose-app.yml stop|start|restart &lt;服务名&gt;# 关闭或重启compose所有容器docker-compose -f docker-compose-app.yml stop|restart# 查看compose所有容器的运行日志docker-compose -f docker-compose-app.yml logs -f# 查看compose下某个容器的运行日志docker-compose -f docker-compose-app.yml logs -f &lt;服务名&gt;# 也可以把compose的容器日志输出到日志文件里去，然后用tail -f随时查看docker-compose -f docker-compose-app.yml logs -f &gt;&gt; myDockerCompose.log &amp;# 重新构建有变化的镜像并更新到容器再启动docker-compose -f docker-compose-app.yml up --build -d# 重新创建docker-compose.yml配置有变化的容器并启动docker-compose -f docker-compose-app.yml up --force-recreate -d# 停掉容器再删除容器docker-compose -f docker-compose-app.yml down 123456789101112131415161718192021222324252627282930313233343536373839version: '3.8'services: eleven-auth: # 指定服务名 image: eleven-auth:0.0.1 # 指定镜像名称 build: ./eleven # 指定Dockfile所在路径 container_name: eleven-auth # 指定启动容器名称 ports: - \"8888:8888\" # 指定端口映射 expose: - 8888 # 声明容器对外暴露的端口 environment: - JAVA_TOOL_OPTIONS=-Xmx1g -Xms1g -XX:MaxMetaspaceSize=512m -javaagent:/agent/skywalking-agent.jar -DSW_AGENT_NAME=eleven-auth -DSW_AGENT_COLLECTOR_BACKEND_SERVICES=192.168.0.180:11800 # 访问不在同一个compose文件管理的服务需要用external_links，前提是这些服务都在同一个网络下才能正常访问 external_links: - nacos:nacos # 可用nacos这个域名访问nacos服务 - mysql:db # 可用db这个域名访问mysql服务 cap_add: - SYS_PTRACE # 该参数让docker能支持在容器里能执行jdk自带的类似jinfo，jmap这些命令 eleven-user: # 指定服务名 image: eleven-user:0.0.1 # 指定镜像名称 build: ./eleven # 指定Dockfile所在路径 container_name: eleven-user # 指定启动容器名称 ports: - \"8877:8877\" # 指定端口映射 expose: - 8877 # 声明容器对外暴露的端口 environment: - JAVA_TOOL_OPTIONS=-Xmx1g -Xms1g -XX:MaxMetaspaceSize=512m -javaagent:/agent/skywalking-agent.jar -DSW_AGENT_NAME=eleven-user -DSW_AGENT_COLLECTOR_BACKEND_SERVICES=192.168.0.180:11800 # 访问不在同一个compose文件管理的服务需要用external_links，前提是这些服务都在同一个网络下才能正常访问 external_links: - nacos:nacos # 可用nacos这个域名访问nacos服务 - mysql:db # 可用db这个域名访问mysql服务 - mongo - redis - rabbitmq cap_add: - SYS_PTRACE # 该参数让docker能支持在容器里能执行jdk自带的类似jinfo，jmap这些命令 depends_on: - eleven-auth # authcenter启动之后再启动 有时需要扩容微服务，则需要将docker-compose.yml里的服务的端口映射和容器名称都注释掉，因为不可能两个服务的容器映射到宿主机的同一个端口： 1234567891011121314151617181920212223242526272829303132333435363738394041version: '3.8'services: eleven-auth: # 指定服务名 image: eleven-auth:0.0.1 # 指定镜像名称 build: ./eleven # 指定Dockfile所在路径 container_name: eleven-auth # 指定启动容器名称 ports: - \"8888:8888\" # 指定端口映射 expose: - 8888 # 声明容器对外暴露的端口 environment: - JAVA_TOOL_OPTIONS=-Xmx1g -Xms1g -XX:MaxMetaspaceSize=512m -javaagent:/agent/skywalking-agent.jar -DSW_AGENT_NAME=eleven-auth -DSW_AGENT_COLLECTOR_BACKEND_SERVICES=192.168.0.180:11800 # 访问不在同一个compose文件管理的服务需要用external_links，前提是这些服务都在同一个网络下才能正常访问 external_links: - nacos:nacos # 可用nacos这个域名访问nacos服务 - mysql:db # 可用db这个域名访问mysql服务 cap_add: - SYS_PTRACE # 该参数让docker能支持在容器里能执行jdk自带的类似jinfo，jmap这些命令 eleven-user: # 指定服务名 image: eleven-user:0.0.1 # 指定镜像名称 build: ./eleven # 指定Dockfile所在路径 # container_name: eleven-user # 指定启动容器名称 # ports: # - \"8877:8877\" # 指定端口映射 # expose: # - 8877 # 声明容器对外暴露的端口 environment: - JAVA_TOOL_OPTIONS=-Xmx1g -Xms1g -XX:MaxMetaspaceSize=512m -javaagent:/agent/skywalking-agent.jar -DSW_AGENT_NAME=eleven-user -DSW_AGENT_COLLECTOR_BACKEND_SERVICES=192.168.0.180:11800 # 访问不在同一个compose文件管理的服务需要用external_links，前提是这些服务都在同一个网络下才能正常访问 external_links: - nacos:nacos # 可用nacos这个域名访问nacos服务 - mysql:db # 可用db这个域名访问mysql服务 - mongo - redis - rabbitmq cap_add: - SYS_PTRACE # 该参数让docker能支持在容器里能执行jdk自带的类似jinfo，jmap这些命令 depends_on: - eleven-auth # authcenter启动之后再启动 deploy: replicas:2 执行如下扩容命令，服务一旦扩容对应了多个容器，则访问服务名docker会自动负载均衡去访问服务对应的每台容器，docker compose主要用在单物理机内扩容的情况，要做多机扩容还需自己在多个机器上做很多定制化配置，做多物理机扩容一般都会用docker swarm或kubernetes。 12345# 必须先正常编排微服务，然后才能动态扩容，文件有变动，需要重新创建容器docker-compose -f docker-compose-app.yml up --force-recreate -d docker-compose -f docker-compose-app.yml scale eleven-user=2# 如果要缩容执行如下操作docker-compose -f docker-compose-app.yml scale eleven-user=1","tags":[{"name":"Docker","slug":"Docker","permalink":"https://yaoyinglong.github.io/tags/Docker/"}],"categories":[{"name":"云原生","slug":"云原生","permalink":"https://yaoyinglong.github.io/categories/云原生/"}]},{"title":"模本","date":"2022-02-10T16:00:00.000Z","path":"Blog/模板/","text":"","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Docker基础","date":"2022-02-10T16:00:00.000Z","path":"Blog/云原生/Docker基础/","text":"Docker是一个开源的容器引擎，有助于更快地交付应用。 Docker可将应用程序和基础设施层隔离，且能将基础设施当作程序一样进行管理。使用Docker可更快地打包、测试以及部署应用程序，且可缩短从编写到部署运行代码的周期。Docker有如下优点： 简化程序：让开发者可打包应用以及依赖包到一个可移植的容器中，然后发布到任何流行Linux机器上，便可实现虚拟化。方便快捷是Docker最大优势，过去需要用数天乃至数周的任务，在Docker容器处理下只需要数秒就能完成。Docker镜像中包含了运行环境和配置，所以Docker可简化部署多种应用实例工作。 节省开支：云计算时代到来，使开发者不必为了追求效果而配置高额的硬件，Docker改变了高性能必然高价格的思维定势。Docker与云的结合，让云空间得到更充分的利用。不仅解决了硬件管理问题，也改变了虚拟化的方式。 Docker架构 Docker daemonDocker daemon是Docker守护进程是一个运行在宿主机DOCKER-HOST的后台进程，可通过Docker客户端与之通信。 ClientDocker客户端是Docker的用户界面，可接受用户命令和配置标识，并与Docker daemon通信。图中docker build等都是Docker的相关命令。 ImagesDocker镜像是一个只读模板，它包含创建Docker容器的说明，和系统安装光盘有点像，使用系统安装光盘可安装系统，同理使用Docker镜像可运行Docker镜像中的程序。 Container容器是镜像的可运行实例，镜像和容器的关系有点类似于面向对象中，类和对象的关系，可通过Docker API或CLI命令来启停、移动、删除容器。 RegistryDocker Registry是一个集中存储与分发镜像的服务，构建完Docker镜像后，可在当前宿主机上运行。若想要在其他机器上运行该镜像，需要手动复制。此时可借助Docker Registry来避免镜像的手动复制。 一个Docker Registry可包含多个Docker仓库，每个仓库可包含多个镜像标签，每个标签对应一个Docker镜像。这跟Maven的仓库有点类似，若把Docker Registry比作Maven仓库的话，则Docker仓库就可理解为某jar包的路径，而镜像标签则可理解为jar包的版本号。 Docker Registry可分为公有Docker Registry和私有Docker Registry，最常用的Docker Registry莫过于官方的默认的Docker Hub，Docker Hub上存放着⼤量优秀的镜像，可使用Docker命令下载并使用。 Docker虚拟化原理传统虚拟化技术是在硬件层面实现虚拟化，增加了系统调用链路的环节，有性能损耗；容器虚拟化技术以共享宿主机Kernel的方式实现，几乎没有性能损耗。 Docker利用的是宿主机的内核，而不需要Guest OS，当新建一个容器时，docker不需要和虚拟机一样重新加载一个操作系统内核，避免了寻址、加载操作系统内核这些比较费时费资源的过程。当新建一个虚拟机时，虚拟机软件需要加载Guest OS，该新建过程是分钟级别的。而Docker由于直接利用宿主机的操作系统，则省略了该过程，因此新建一个Docker容器只需要几秒钟。 Docker是使用联合文件系统将机器的资源进行隔离的，常见的联合文件系统有AUFS、Overlay、devicemapper、BTRFS和ZFS等。以Overlay2的架构图为例： Overlayfs在Linux主机上只有两层，一个目录在下层，用来保存镜像(docker)，另外一个目录在上层，用来存储容器信息。在Overlayfs中，底层的目录叫做lowerdir，顶层的目录称之为upperdir，对外提供统一的文件系统为merged。当需要修改一个文件时，使用COW(Copy-on-write)写时复制将文件从只读的Lower复制到可写的Upper进行修改，结果也保存在Upper层。在Docker中底下的只读层就是image，可写层就是Container。 写时复制技术所有驱动都用到写时复制技术，COW全称copy-on-write，表示只是在需要写时才去复制，这是针对已有文件的修改场景。如基于一个Image启动多个Container，若每个Container都去分配一个Image一样的文件系统，将会占用大量磁盘空间。而COW技术可让所有容器共享Image的文件系统，所有数据都从Image中读取，只有当要对文件进行写操作时，才从Image里把要写的文件复制到自己的文件系统进行修改。 无论有多少个容器共享一个Image，所做的写操作都是对从Image中复制到自己的文件系统的副本上进行，并不会修改Image源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个副本，每个容器修改的都是自己的副本，互相隔离互不影响。使用COW可有效的提高磁盘的利用率，故容器占用空间很少。 用时分配用时分配是针对原本没有该文件的场景，只有在要新写入一个文件时才分配空间，这样可提高存储资源的利用率。如启动一个容器，并不会因为该容器分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。 查看容器占用磁盘大小指令1234# 查看所有容器的大小cd /var/lib/docker/containers # 进入docker容器存储目录du -sh * # 查看所有容器的大小du -sh &lt;容器完整id&gt; #查看某一个容器的大小 镜像分层原理Docker使用共享技术减少镜像存储空间，所有镜像层和容器层都保存在宿主机的文件系统/var/lib/docker/中，由存储驱动进行管理，尽管存储方式不尽相同，但在所有版本的Docker中都可共享镜像层。在下载镜像时，Docker Daemon会检查镜像中的镜像层与宿主机文件系统中的镜像层进行对比，若存在则不下载，只下载不存在的镜像层，这样可非常节约存储空间。 Docker安装卸载123456789101112131415161718192021222324252627# 查看当前内核版本，Docker要求CentOS系统的内核版本高于3.10uname -r# 使用root权限登录Centos确保yum包更新到最新yum -y update# 若安装过Docker，卸载旧版本sudo yum remove -y docker*# 安装需要的软件包，yum-util提供yum-config-manager功能，另外两个是devicemapper驱动依赖的yum install -y yum-utils# 设置yum源，并更新yum包索引yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache fast# 查看所有仓库中所有docker版本，并选择特定版本安装yum list docker-ce --showduplicates | sort -r# 安装docker，且指定安装版本yum install -y docker-ce-3:19.03.9-3.el7.x86_64# 启动Dockersystemctl start docker# 将Docker启动加入开机启动systemctl enable docker# 验证安装是否成功：有client和service两部分表示docker安装启动都成功了docker version# Docker卸载yum remove -y docker*rm -rf /etc/systemd/system/docker.service.drm -rf /var/lib/dockerrm -rf /var/run/docker 镜像加速可借助阿里云的镜像加速器，登录阿里云，在配置daemon.json文件时，若JSON格式有问题会导致Docker启动失败。 123cd /etc/docker# 查看有没有daemon.json，docker默认的配置文件，若没有则新建，若有则修改vim daemon.json 123&#123; \"registry-mirrors\": [\"https://x0y2v4jf.mirror.aliyuncs.com\"]&#125; 123# 重启docker服务systemctl daemon-reloadsystemctl restart docker Docker常用命令12345678910111213# 使用docker search命令搜索存放在Docker Hub中的镜像，搜索含有java关键词的镜像仓库# NAME：镜像仓库名称# DESCRIPTION：镜像仓库描述# STARS：镜像仓库收藏数，表示该镜像仓库的受欢迎程度，类似于GitHub的stars0# OFFICAL：表示是否为官方仓库，该列标记为[0K]的镜像均由各软件的官方项目组创建和维护# AUTOMATED：表示是否是自动构建的镜像仓库docker search java# docker pull命令可从Docker Registry上下载镜像，执行该命令后，Docker会从Docker Hub中的nginx仓库下载最新版本的nginx镜像docker pull nginx# 若要下载指定版本则在java后面加冒号指定版本docker pull java:8# 列出已下载的镜像：REPOSITORY镜像所属仓库名称，TAG镜像标签默认是latest最新，IMAGE ID镜像ID镜像唯一标识，CREATED镜像创建时间，SIZE镜像大小docker images 删除本地镜像通过docker rmi命令删除镜像时，若不是latest版本，删除时需要加上版本号 1234567# 删除指定镜像docker rmi java# 删除指定版本即Tag的镜像docker rmi java:8docker rmi -f nginx# 删除所有镜像docker rmi $(docker images -q) 新建并启动容器使用docker run命令即可新建并启动一个容器，该命令会先检查本地是否存在指定镜像，若本地不存在该名称的镜像，Docker就会自动从Docker Hub下载镜像并启动一个 Docker容器，该命令常用选项： -d选项：表示后台运行 -P选项：随机端口映射 -p选项：指定端口映射，有以下四种格式 –ip:hostPort:containerPort –ip::containerPort –hostPort:containerPort –containerPort --net选项：指定网络模式，该选项有以下可选参数 –net=bridge：默认选项，表示连接到默认的网桥 –net=host：容器使用宿主机的网络 –net=container:NAME-or-ID：告诉Docker让新建的容器使用已有容器的网络配置 –net=none：不配置该容器的网络，用户可自定义网络配置 123456docker run -d -p 91:80 nginx# 通过--name指定容器名称为nginx_elevendocker run -d --name nginx_eleven -p 91:80 nginx# 启动已停止的容器，若容器已近被创建，但是被停止后不能创建相同名称的容器docker start nginx_elevendocker start 31dc1cff48b7 停止镜像1234567# 31dc1cff48b7是容器IDdocker stop 31dc1cff48b7# 使用docker stop容器名称来停止指定容器docker stop nginx_eleven# 发送SIGKILL信号来强制停止容器docker kill 31dc1cff48b7docker kill nginx_eleven 列出容器1234# 列出运行中的容器docker ps# 列出包括已停止的容器docker ps -a CONTAINER_ID表示容器ID，IMAGE表示镜像名称，COMMAND表示启动容器时运行的命令，CREATED表示容器创建时间，STATUS表示容器运行状态，UP表示运行中，Exited表示已停止，PORTS表示容器对外端口号，NAMES表示容器名称，该名称默认由Docker自动生成，也可使用docker run命令的--name选项自行指定。 查看容器信息1234567# 查看容器所有信息docker inspect 31dc1cff48b7docker inspect nginx_eleven# 查看容器日志docekr container logs nginx_eleven# 查看容器里的进程docker top nginx_eleven 进入容器使用docker exec命令用于进入一个正在运行的docker容器，若docker run命令运行容器时未使用-it参数，就要用该命令进入容器。一旦进入容器就可在容器的Shell执行命令 123# 使用exit命令退出容器docker exec -it 31dc1cff48b7 /bin/bashdocker exec -it nginx_eleven /bin/bash 容器与宿主机相互复制文件12345# 从容器里面拷文件到宿主机# docker cp 容器id或容器名称:要拷贝的文件在容器里面的路径 宿主机的相应路径 docker cp nginx_eleven:/etc/nginx/nginx.conf /mydata/nginx# docker cp 要拷贝的宿主机文件路径 容器id:要拷贝到容器里面对应的路径docker cp /data/nginx/test.txt nginx_eleven:/etc/nginx/ 在容器中安装软件1234567# 进入容器docker exec -it nginx_eleven /bin/bash# 在容器中执行以下命令apt-get updateapt-get install vim # 安装vimapt-get install iputils-ping # 安装pingapt-get install net-tools # 安装ifconfig 删除容器12345# 删除指定容器，只能删除已停止的容器，若需删除正在运行的容器，可使用-f参数docker rm 31dc1cff48b7docker rm nginx_eleven# 强制删除所有容器docker rm -f $(docker ps -a -q) 查看容器资源使用情况12docker stats # 返回容器资源的实时使用情况，1秒刷新一次docker stats --no-stream # 返回容器当时的资源使用情况 CONTAINER ID表示容器ID，CPU %表示CPU使用情况，MEM USAGE / LIMIT当前使用内存和最大可使用内存，MEM %以百分比的形式显示内存使用情况，NET I/O网络I/O数据，BLOCK I/O磁盘I/O数据，PIDS表示PID号。 Dockerfile可以使用Dockerfile构建Docker镜像，从而将微服务运行在docker上，Dockerfile是一个文本文件，其中包含了若干条指令，指令描述了构建镜像的细节。在/data/docker/nginx_eleven目录下创建一个名为Dockerfile的文件，在里面增加如下内容： 12FROM nginxRUN echo '&lt;h1&gt;This is Tuling Nginx!!!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html 其中的FROM、RUN都是Dockerfile的指令，FROM指令用于指定基础镜像，RUN指令用于执行命令，创建好Dockerfile后通过 docker build命令构建镜像 12# -t指定镜像名字，eleven表示打包的版本号，/data/docker/nginx_eleven为Dockerfile文件路径docker build -t nginx:eleven /data/docker/nginx_eleven Dockerfile常用指令 命令 用途 FROM 基础镜像文件 RUN 构建镜像阶段执行命令，执行结果会打包进入image文件，一个Dockerfile可包含多个RUN命令 ADD 添加文件，从src目录复制文件到容器的dest，其中src可Dockerfile所在目录相对路径，也可以是一个URL，还可是一个压缩包 COPY 拷贝文件，和ADD命令类似，但不支持URL和压缩包 CMD 容器启动后执行命令，一个Dockerfile只能包含一个CMD命令，指定了CMD命令以后，docker container run命令就不能附加命令了，如前面的/bin/bash，否则会覆盖CMD命令 EXPOSE 声明容器在运行时对外提供的服务端口 WORKDIR 指定容器工作路径 ENV 指定环境变量 ENTRYPINT 容器入口， ENTRYPOINT和CMD指令目的一样，都是指定Docker容器启动时执行的命令，可多次设置但只有最后一个有效 USER 该指令用于设置启动镜像时的用户或UID，写在该指令后的RUN、CMD、ENTRYPOINT指令都将使用该用户执行命令 VOLUME 指定挂载点，该指令使容器中的一个目录具有持久化存储的功能，该目录可被容器本身使用，也可共享给其他容器，当容器中的应用有持久化数据的需求时可在Dockerfile中使用该指令，格式为VOLUME[&quot;/data&quot;] 使用Dockerfile构建微服务镜像以eureka-server为例，将该微服务的可运行jar包构建成docker镜像，首先将该jar包上传到/data/docker/eureka目录，并在jar包所在目录创建名为Dockerfile的文件，文件内容如下： 12345678# 基于哪个镜像From java:8# 复制文件到容器ADD eureka-server-0.0.1-SNAPSHOT.jar /app.jar# 声明需要暴露的端口EXPOSE 8761# 配置容器启动后执行的命令ENTRYPOINT java $&#123;JAVA_OPTS&#125; -jar /app.jar 123456789# 使用docker build命令构建镜像docker build -t eleven-eureka-server:0.0.1 /data/docker/eureka# 启动镜像，加-d可在后台启动docker run -d -p 8761:8761 eleven-eureka-server:0.0.1# 使用-v可挂载一个主机上的目录到容器的目录docker run -d -p 8761:8761 -v /log:/container-log eleven-eureka-server:0.0.1# 加上JVM参数# 参数--cap-add=SYS_PTRACE是让docker能支持在容器里能执行jdk自带类似jinfo，jmap等命令，若不需要在容器里执行这些命令可不加docker run -e JAVA_OPTS='-Xms1028M -Xmx1028M -Xmn512M -Xss512K -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M' --cap-add=SYS_PTRACE -d -p 8761:8761 eleven-eureka-server:0.0.1 将微服务镜像发布到远程镜像仓库制作好微服务镜像，一般需要发布到镜像仓库供别人使用，可选择自建镜像仓库，也可直接使用docker官方镜像仓库，首先需要在docke官方镜像仓库里注册一个账号，然后在Linux服务器上用docker login命令登录镜像仓库，要把镜像推送到镜像仓库，需要将镜像前面加个分组名，一般为docker hub的账户名： 12345docker login# 修改镜像名字docker tag eleven-eureka-server:0.0.1 eleven/eleven-eureka-server:0.0.1# 将镜像推送到远程仓库docker push eleven/eleven-eureka-server:0.0.1","tags":[{"name":"云原生","slug":"云原生","permalink":"https://yaoyinglong.github.io/tags/云原生/"}],"categories":[{"name":"云原生","slug":"云原生","permalink":"https://yaoyinglong.github.io/categories/云原生/"}]},{"title":"模本","date":"2022-02-10T16:00:00.000Z","path":"Blog/大数据/Clickhouse基础/","text":"","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"分布式事务解决方案","date":"2022-02-08T16:00:00.000Z","path":"Blog/Cloud/分布式事务解决方案/","text":"大多数场景下应用都只需要操作单一数据库，该情况下的事务称之为本地事务(Local Transaction)。本地事务的ACID特性是数据库直接提供支持。在JDBC编程中通过java.sql.Connection对象来开启、关闭或提交事务。 12345678910Connection conn = ... ; //获取数据库连接conn.setAutoCommit(false); //开启事务try &#123; // 执行增删改查sql conn.commit(); // 提交事务&#125; catch (Exception e) &#123; conn.rollback(); // 事务回滚&#125; finally&#123; conn.close(); // 关闭链接&#125; 绝大部分公司都进行了数据库拆分和服务化，完成某一个业务功能可能需要横跨多个服务，操作多个数据库，需要操作的资源位于多个资源服务器上，分布式事务就是为了保证不同资源服务器的数据一致性。典型的分布式事务场景：垮库事务、分库分表、服务化。 DTP模型构成DTP模型的5个基本元素： AP应用程序Application Program：用于定义事务边界即定义事务的开始和结束，并在事务边界内对资源进行操作 RM资源管理器Resource Manager：如数据库、文件系统等，并提供访问资源的方式 TM事务管理器Transaction Manager：负责分配事务唯一标识，监控事务的执行进度，并负责事务的提交、回滚等 CRM通信资源管理器Communication Resource Manager：控制一个TM域内或者跨TM域的分布式应用之间的通信 CP通信协议Communication Protocol：提供CRM提供的分布式应用节点之间的底层通信服务 XA规范在DTP本地模型实例中，由AP应用程序、RMs资源管理器和TM事务管理器组成，不需要其他元素，AP、RM和TM之间彼此都需要进行交互。XA规范主要作用是定义了RM-TM的交互接口，还对两阶段提交协议进行了优化。 两阶段协议是在OSI TP标准中提出的，在DTP参考模型中，指定了全局事务的提交要使用两阶段提交协议；而XA规范只是定义了两阶段提交协议中需要使用到的接口，也就是上述提到的RM-TM交互的接口。 两阶段提交协议两阶段提交协议不是在XA规范中提出，但XA规范对其进行了优化，将提交过程划分为两个阶段。 第一阶段：TM通知各个RM准备提交它们的事务分支；若RM判断自己进行的工作可以被提交，则对工作内容进行持久化，再给TM肯定答复；若发生了其他情况则给TM的都是否定答复。在发送了否定答复并回滚了工作后，RM就可以丢弃该事务分支信息。 第二阶段：TM根据第一阶段各个RM prepare的结果，决定是提交还是回滚事务；若所有RM都prepare成功，则TM通知所有RM进行提交；若有RM prepare失败则TM通知所有RM回滚事务分支。 二阶段提交看起来确实能够提供原子性的操作，但二阶段提交还是有几个缺点： 同步阻塞问题：两阶段提交方案下全局事务的ACID特性是依赖于RM的，一个全局事务内部包含了多个独立的事务分支，这一组事务分支要不都成功要不都失败，各个事务分支的ACID特性共同构成了全局事务的ACID特性。可重复读隔离级别不足以保证分布式事务一致性，若使用MySQL来支持XA分布式事务最好将事务隔离级别设置为SERIALIZABLE，而SERIALIZABLE是四个事务隔离级别中最高且执行效率最低一个级别。 单点故障：由于协调者的重要性，一旦协调者TM发生故障，参与者RM会一直阻塞下去。尤其在第二阶段，协调者发生故障，所有参与者还都处于锁定事务资源状态中，而无法继续完成事务操作。若协调者挂掉，可重新选举一个协调者，但无法解决因为协调者宕机导致的参与者处于阻塞状态的问题 数据不一致：在第二阶段中当协调者向参与者发送commit请求之后，发生了局部网络异常或在发送commit请求过程中协调者发生故障，会导致只有一部分参与者接受到了commit请求，而在这部分参与者接到commit请求之后就会执行commit操作，但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。 JTA/XA规范实现针对实现了JDBC规范中规定的实现XADataSource接口的数据库连接池，典型的XADataSource实现包括： MySQL官方提供的com.mysql.jdbc.jdbc2.optional.MysqlXADataSource 阿里巴巴开源的druid连接池，对应的实现类为com.alibaba.druid.pool.xa.DruidXADataSource tomcat-jdbc连接池提供的org.apache.tomcat.jdbc.pool.XADataSource 123456&lt;!-- MySQL JDBC实现了XA规范 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// true表示打印XA语句,，用于调试boolean logXaCommands = true;// 获得资源管理器操作接口实例 RM1Connection conn1 = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/db_user\", \"root\", \"root\");XAConnection xaConn1 = new MysqlXAConnection((com.mysql.jdbc.Connection) conn1, logXaCommands);XAResource rm1 = xaConn1.getXAResource();// 获得资源管理器操作接口实例 RM2Connection conn2 = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/db_account\", \"root\", \"root\");XAConnection xaConn2 = new MysqlXAConnection((com.mysql.jdbc.Connection) conn2, logXaCommands);XAResource rm2 = xaConn2.getXAResource();// AP请求TM执行一个分布式事务，TM生成全局事务idbyte[] gtrid = \"g12345\".getBytes();int formatId = 1;try &#123; // ==============分别执行RM1和RM2上的事务分支==================== // TM生成rm1上的事务分支id byte[] bqual1 = \"b00001\".getBytes(); Xid xid1 = new MysqlXid(gtrid, bqual1, formatId); // 执行rm1上的事务分支 rm1.start(xid1, XAResource.TMNOFLAGS);// One of TMNOFLAGS, TMJOIN, or TMRESUME. PreparedStatement ps1 = conn1.prepareStatement(\"INSERT into user(name) VALUES ('Eleven')\"); ps1.execute(); rm1.end(xid1, XAResource.TMSUCCESS); // TM生成rm2上的事务分支id byte[] bqual2 = \"b00002\".getBytes(); Xid xid2 = new MysqlXid(gtrid, bqual2, formatId); // 执行rm2上的事务分支 rm2.start(xid2, XAResource.TMNOFLAGS); PreparedStatement ps2 = conn2.prepareStatement(\"INSERT into account(user_id, money) VALUES (1, 10000000)\"); ps2.execute(); rm2.end(xid2, XAResource.TMSUCCESS); // ===================两阶段提交================================ // phase1：询问所有的RM 准备提交事务分支 int rm1_prepare = rm1.prepare(xid1); int rm2_prepare = rm2.prepare(xid2); // phase2：提交所有事务分支 boolean onePhase = false; //TM判断有2个事务分支，所以不能优化为一阶段提交 if (rm1_prepare == XAResource.XA_OK &amp;&amp; rm2_prepare == XAResource.XA_OK) &#123; // 所有事务分支都prepare成功，提交所有事务分支 rm1.commit(xid1, onePhase); rm2.commit(xid2, onePhase); &#125; else &#123;// 如果有事务分支没有成功，则回滚 rm1.rollback(xid1); rm2.rollback(xid2); &#125;&#125; catch (XAException e) &#123; // 如果出现异常，也要进行回滚 e.printStackTrace();&#125; 开源框架Atomikos：TransactionEssentials开源的免费产品，ExtremeTransactions上商业版需要收费。 TransactionEssentials实现了JTA/XA规范中的事务管理器应该实现的相关接口，如UserTransaction实现了com.atomikos.icatch.jta.UserTransactionImp，用户只需要直接操作该类，TransactionManager实现了com.atomikos.icatch.jta.UserTransactionManager，Transaction实现了com.atomikos.icatch.jta.TransactionImp。 123456789101112&lt;!-- JTA规范扩展包 --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.transaction&lt;/groupId&gt; &lt;artifactId&gt;jta&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- atomikos JTA/XA全局事务 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.atomikos&lt;/groupId&gt; &lt;artifactId&gt;transactions-jdbc&lt;/artifactId&gt; &lt;version&gt;4.0.6&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465private static AtomikosDataSourceBean createAtomikosDataSourceBean(String dbName) &#123; // 连接池基本属性 Properties p = new Properties(); p.setProperty(\"url\", \"jdbc:mysql://localhost:3306/\" + dbName); p.setProperty(\"user\", \"root\"); p.setProperty(\"password\", \"root\"); // 使用AtomikosDataSourceBean封装com.mysql.jdbc.jdbc2.optional.MysqlXADataSource AtomikosDataSourceBean ds = new AtomikosDataSourceBean(); // 设置resourceName 唯一 ds.setUniqueResourceName(dbName); ds.setXaDataSourceClassName(\"com.mysql.jdbc.jdbc2.optional.MysqlXADataSource\"); ds.setXaProperties(p); return ds;&#125;public static void main(String[] args) &#123; AtomikosDataSourceBean ds1 = createAtomikosDataSourceBean(\"db_user\"); AtomikosDataSourceBean ds2 = createAtomikosDataSourceBean(\"db_account\"); Connection conn1 = null; Connection conn2 = null; PreparedStatement ps1 = null; PreparedStatement ps2 = null; UserTransaction userTransaction = new UserTransactionImp(); try &#123; // 开启事务 userTransaction.begin(); // 执行db1上的sql conn1 = ds1.getConnection(); ps1 = conn1.prepareStatement(\"INSERT into user(name) VALUES (?)\", Statement.RETURN_GENERATED_KEYS); ps1.setString(1, \"Eleven\"); ps1.executeUpdate(); ResultSet generatedKeys = ps1.getGeneratedKeys(); int userId = -1; while (generatedKeys.next()) &#123; // 获得自动生成的userId userId = generatedKeys.getInt(1); &#125; // 模拟异常 ，直接进入catch代码块，2个都不会提交 // int i=1/0; // 执行db2上的sql conn2 = ds2.getConnection(); ps2 = conn2.prepareStatement(\"INSERT into account(user_id,money) VALUES (?,?)\"); ps2.setInt(1, userId); ps2.setDouble(2, 10000000); ps2.executeUpdate(); // 两阶段提交 userTransaction.commit(); &#125; catch (Exception e) &#123; try &#123; e.printStackTrace(); userTransaction.rollback(); &#125; catch (SystemException e1) &#123; e1.printStackTrace(); &#125; &#125; finally &#123; try &#123; ps1.close(); ps2.close(); conn1.close(); conn2.close(); ds1.close(); ds2.close(); &#125; catch (Exception ignore) &#123; &#125; &#125;&#125; Seata AT模式Seata相比与其它分布式事务框架有以下几个优势: 应用层基于SQL解析实现了自动补偿，从而最大程度的降低业务侵入性 将分布式事务中TC事务协调者独立部署，负责事务的注册、回滚 通过全局锁实现了写隔离与读隔离 Seata提供了AT、TCC、SAGA和XA事务模式，AT模式是Seata首推模式，Seata有TC事务协调者、TM事务管理器、RM资源管理器三大角色，TC为单独部署的Server服务端，TM和RM为嵌入到应用中的Client客户端 TC事务协调者：维护全局和分支事务的状态驱动全局事务提交或回滚 TM事务管理器：定义全局事务的范围开始全局事务、提交或回滚全局事务 RM资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务状态，并驱动分支事务提交或回滚 TM请求TC开启一个全局事务，TC会生成一个XID作为该全局事务的编号，XID会在微服务的调用链路中传播，保证将多个微服务的子事务关联在一起；RM请求TC将本地事务注册为全局事务的分支事务，通过全局事务的XID进行关联；TM请求TC告诉XID对应的全局事务是进行提交还是回滚；TC驱动RM们将XID对应的自己的本地事务进行提交还是回滚。 AT模式的核心是对业务无侵入，是一种改进后的两阶段提交，前提是基于支持本地ACID事务的关系型数据库，Java应用通过JDBC访问数据库。通过两阶段提交： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源，本地事务提交前，需确保先拿到全局锁，否则不能提交本地事务，且拿全局锁的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务释放本地锁 二阶段：提交异步化非常快速地完成，回滚通过一阶段的回滚日志进行反向补偿 一阶段会解析SQL类型是更新删除还是新增、表名、条件等相关信息，根据解析得到的条件信息，生成查询语句定位数据生成前置镜像，然后执行业务SQL，根据前镜像的结果，通过主键定位数据得到后置镜像，把前置镜像和后置镜像数据以及业务SQL相关的信息组成一条回滚日志记录，插入到UNDO_LOG表中。提交前向TC注册分支申请目标表中，对应主键值的记录的全局锁，业务数据的更新和前面步骤中生成的UNDO LOG一并提交，将本地事务提交的结果上报给TC。 二阶段回滚，收到TC分支回滚请求，开启一个本地事务，通过XID和Branch ID查找到相应的UNDO LOG记录，拿 UNDO LOG中的后镜与当前数据进行比较，若有不同说明数据被当前全局事务之外的动作做了修改。该情况需要根据配置策略来做处理，根据UNDO LOG中前镜像和业务SQL相关信息生成并执行回滚的语句，提交本地事务并把本地事务的执行结果即分支事务回滚结果上报给TC事务协调者。 二阶段提交，即分布式事务操作成功，TC通知RM异步删除undolog，收到TC分支提交请求，把请求放入一个异步任务队列中，马上返回提交成功结果给TC，异步任务阶段的分支提交请求将异步和批量地删除相应UNDO LOG记录。 Seata AT模式存在的问题： 性能损耗：一条Update的SQL需要与TC通讯获取全局事务xid、before image解析SQL查询一次数据库、after image查询一次数据库、insert undo log写一次数据库、before commit与TC通讯判断锁冲突，这些操作都需要同步远程通讯RPC，且undo log写入时blob字段插入性能也不高。每条写SQL都会增加这么多开销，粗略估计会增加5倍响应时间 性价比：为了进行自动补偿，需要对所有交易生成前后镜像并持久化，在实际业务场景下分布式事务失败需要回滚的有多少比率，按照二八原则预估，为了20%的交易回滚，需要将80%的成功交易的响应时间增加5倍，这样的代价相比于让应用开发一个补偿交易是否是值得 全局锁：相比XA，Seata虽然在一阶段成功后会释放数据库锁，但一阶段在commit前全局锁的判定也拉长了对数据锁的占有时间，这个开销比XA的prepare低多少需要根据实际业务场景进行测试。全局锁的引入实现了隔离性，但带来的问题就是阻塞，降低并发性，尤其是热点数据，这个问题会更加严重。 回滚锁释放时间：Seata在回滚时，需要先删除各节点的undo log，然后才能释放TC内存中的锁，所以若第二阶段是回滚，释放锁的时间会更长 死锁问题：Seata的引入全局锁会额外增加死锁风险，若出现死锁会不断进行重试，最后靠等待全局锁超时，这种方式并不优雅，也延长了对数据库锁的占有时间 柔性事务TCCTCC是比较常用的一种柔性事务方案。开源的TCC框架：Tcc-Transaction、Hmily、ByteTCC、EasyTransaction、Seata TCC。 TCC两阶段提交与XA两阶段提交的区别是：XA是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁，TCC是业务层面的分布式事务，最终一致性，不会一直持有资源的锁。 TCC事务的优点是有效了的避免了XA两阶段提交占用资源锁时间过长导致的性能底下的问题。相对于AT模式，TCC模式对业务代码有一定的侵入性，但TCC模式无AT模式的全局行锁，TCC性能会比AT模式高很多。 TCC事务的缺点是主业务服务和从业务服务都需要进行改造，从业务方改造成本更高。原来只需要提供一个接口，现在需要改造成try、confirm、canel三个接口开发成本高。 空回滚在没有调用TCC资源Try方法的情况下，调用了二阶段的Cancel方法，Cancel方法需要识别出这是一个空回滚，然后直接返回成功，空回滚出现的原因是Try超时丢包，分布式事务回滚触发Cancel，出现未收到Try，收到Cancel的情况。 悬挂悬挂即Cancel比Try先执行，要运行空回滚，但要拒绝空回滚之后的Try操作，悬挂出现的原因是Try超时拥堵，分布式事务回滚触发Cancel，之后拥堵的Try到达。 幂等控制Try，Confirm，Cancel都需要保证幂等性，因为网络抖动或拥堵可能会超时，事务管理器会对资源进行重试操作，所以很可能一个业务操作会被重复调用，为了不因为重复调用而多次占用资源，需要对服务设计时进行幂等控制，通常可用事务xid或业务主键判重来控制。 TCC设计注意事项以扣钱场景为例，场景为A转账30元给B，A和B账户在不同的服务。在微服务架构下，很有可能出现网络超时、重发，机器宕机等一系列的异常，出现空回滚、幂等、悬挂的问题。 对于以下示例，都是先执行账户A的try方法，从而执行账户B的try方法，若成功则执行账户A的confirm方法，然后执行账户B的confirm方法，若失败则执行账户A的concel方法，然后再执行账户B的cancel方法。 方案A方案C优于方案B优于方案A 123456789101112131415# 账户Atry： 检查余额是否够30元 扣减30元confirm： 空cancel： 增加30元# 账户Btry： 增加30元 confirm： 空 cancel： 减少30元 方案B123456789101112131415# 账户Atry： 检查余额是否够30元 扣减30元confirm： 空 cancel： 增加30元# 账户Btry： 空 confirm： 增加30元 cancel： 空 方案C需要创建local_transaction_log日志表用于幂等性、空回滚、try悬挂处理时校验 1234567891011121314151617181920# 账户Atry： try幂等校验 try悬挂处理 检查余额是否够30元 扣减30元 confirm： 空 cancel： cancel幂等校验 cancel空回滚处理 增加可用余额30元# 账户Btry： 空confirm： confirm幂等校验 正式增加30元cancel： 空 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Service@Slf4jpublic class AccountServiceImpl implements AccountService &#123; @Autowired AccountMapper accountMapper; @Autowired Bank2FeignClient bank2FeignClient; // try方法执行逻辑：try幂等校验，try悬挂处理，检查余额是否足够扣减，扣减金额 // 只要标记@Hmily就是try方法，在注解中指定confirm、cancel两个方法的名字 @Transactional(timeout = 60) @Hmily(confirmMethod = \"commit\", cancelMethod = \"rollback\") @Override public void transfer(String fromAccountNo, String toAccountNo, Double amount) &#123; // 获取全局事务id String transId = HmilyTransactionContextLocal.getInstance().get().getTransId(); log.info(\"bank1 try begin 开始执行...xid:&#123;&#125;\", transId); // 幂等判断 判断local_transaction_log表中是否有try日志记录，如果有则不再执行 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.TRY.getValue()) &gt; 0) &#123; log.info(\"bank1 try 已经执行，无需重复执行,xid:&#123;&#125;\", transId); return; &#125; // try悬挂处理，如果cancel、confirm有一个已经执行了，try不再执行 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.CONFIRM.getValue()) &gt; 0 || accountMapper.isExistTransactionLogByType(transId, TransactionEnum.CANCEL.getValue()) &gt; 0) &#123; log.info(\"bank1 try悬挂处理 cancel或confirm已经执行，不允许执行try,xid:&#123;&#125;\", transId); return; &#125; // 扣减金额 if (accountMapper.subtractAccountBalance(fromAccountNo, amount) &lt;= 0) &#123; // 扣减失败 throw new RuntimeException(\"bank1 try 扣减金额失败,xid:\" + transId); &#125; // 插入try执行记录,用于幂等判断 accountMapper.addTransactionLog(transId, TransactionEnum.TRY.getValue()); // 转账,远程调用bank2 if (!bank2FeignClient.transferTo(toAccountNo, amount)) &#123; throw new RuntimeException(\"bank1 远程调用bank2微服务失败,xid:\" + transId); &#125; log.info(\"bank2 request end 结束执行...xid:&#123;&#125;\", transId); if (amount == 20) &#123; throw new RuntimeException(\"人为制造异常,xid:\" + transId); &#125; log.info(\"bank1 try end 结束执行...xid:&#123;&#125;\", transId); &#125; @Transactional public void commit(String fromAccountNo, String toAccountNo, Double amount) &#123; // 获取全局事务id String transId = HmilyTransactionContextLocal.getInstance().get().getTransId(); log.info(\"bank1 confirm begin 开始执行...xid:&#123;&#125;,accountNo:&#123;&#125;,amount:&#123;&#125;\", transId, fromAccountNo, amount); &#125; // cancel方法执行逻辑： 1.cancel幂等校验 2.cancel空回滚处理 3.增加可用余额 @Transactional(timeout = 60) public void rollback(String fromAccountNo, String toAccountNo, Double amount) &#123; // 获取全局事务id String transId = HmilyTransactionContextLocal.getInstance().get().getTransId(); log.info(\"bank1 cancel begin 开始执行...xid:&#123;&#125;\", transId); // cancel幂等校验 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.CANCEL.getValue()) &gt; 0) &#123; log.info(\"bank1 cancel 已经执行，无需重复执行,xid:&#123;&#125;\", transId); return; &#125; // cancel空回滚处理，如果try没有执行，cancel不允许执行 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.TRY.getValue()) &lt;= 0) &#123; log.info(\"bank1 空回滚处理，try没有执行，不允许cancel执行,xid:&#123;&#125;\", transId); return; &#125; // 增加可用余额 accountMapper.addAccountBalance(fromAccountNo, amount); //插入一条cancel的执行记录 accountMapper.addTransactionLog(transId, TransactionEnum.CANCEL.getValue()); log.info(\"bank1 cancel end 结束执行...xid:&#123;&#125;\", transId); &#125;&#125; 上面的设计并不能进行并发控制，即隔离性的保证，对业务模型进行优化，在业务模型中增加冻结金额字段，用来表示账户有多少金额处以冻结状态。 对于用户下单场景，整个业务逻辑由仓储服务、订单服务、帐户服务三个微服务构成，分别完成对给定的商品扣除库存数量、根据采购需求创建订单、从用户帐户中扣除余额。 柔性事务：可靠消息最终一致性方案实现本地消息表方案本地消息表这个方案最初是eBay提出的，此方案的核心是通过本地事务保证数据业务操作和消息的一致性，然后通过定时任务将消息发送至消息中间件，待确认消息发送给消费方成功再将消息删除。 Rocketmq事务消息实现 柔性事务：最大努力通知最大努力通知型是最简单的一种柔性事务，是分布式事务中对一致性要求最低的一种，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果不影响主动方的处理结果，典型的使用场景：银行通知、商户通知等。最大努力通知型的实现方案，一般符合以下特点，且需要实现消息重复通知机制、息校对机制： 不可靠消息：业务活动主动方，在完成业务处理之后，向业务活动的被动方发送消息，直到通知N次后不再通知，允许消息丢失 定期校对：业务活动的被动方，根据定时策略，向业务活动主动方查询，主动方提供查询接口，恢复丢失的业务消息","tags":[{"name":"分布式事务","slug":"分布式事务","permalink":"https://yaoyinglong.github.io/tags/分布式事务/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"}]},{"title":"Canal基础","date":"2022-02-07T16:00:00.000Z","path":"Blog/Cloud/Canal基础/","text":"Canal模拟MySQL Slave的交互协议伪装自己为MySQL Slave，向MySQL Master发送Dump协议MySQL Master收到Dump请求，开始推送Binary Log给Slave即Canal，Canal解析Binary Log对象，原始为byte流。 安装配置12345678910111213141516171819202122cd /usr/localmkdir canaltar -zxvf canal.deployer-1.1.5.tar.gzvim conf/example/instance.properties# 修改mysql配置vim /etc/my.cnflog-bin=mysql-bin # 添加这一行就ok binlog-format=ROW # 选择row模式 server-id=1 # 配置mysql replaction需要定义，不能和canal的slaveId重复binlog-do-db=micromall# 执行mysql 创建canal用户create user canal identified by 'canal';GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';FLUSH PRIVILEGES;# 查看是否授权成功select * from user where user='canal' # 启动canalcd bin./startup.sh 基础配置修改instance.properties配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859################################################### mysql serverId , v1.0.26+ will autoGen# canal.instance.mysql.slaveId=0# enable gtid use true/falsecanal.instance.gtidon=false# position infocanal.instance.master.address=127.0.0.1:3306canal.instance.master.journal.name=canal.instance.master.position=canal.instance.master.timestamp=canal.instance.master.gtid=# rds oss binlogcanal.instance.rds.accesskey=canal.instance.rds.secretkey=canal.instance.rds.instanceId=# table meta tsdb infocanal.instance.tsdb.enable=true#canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb#canal.instance.tsdb.dbUsername=canal#canal.instance.tsdb.dbPassword=canal#canal.instance.standby.address =#canal.instance.standby.journal.name =#canal.instance.standby.position =#canal.instance.standby.timestamp =#canal.instance.standby.gtid=# 数据库username/passwordcanal.instance.dbUsername=rootcanal.instance.dbPassword=rootcanal.instance.connectionCharset = UTF-8canal.instance.defaultDatabaseName=eleven# enable druid Decrypt database passwordcanal.instance.enableDruid=false#canal.instance.pwdPublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5/zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2/JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ==# table regex# canal.instance.filter.regex=.*\\\\..*# 配置表canal.instance.filter.regex=micromall.pms_product,micromall.sms_flash_promotion_product_relation# table black regexcanal.instance.filter.black.regex=mysql\\\\.slave_.*# table field filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)#canal.instance.filter.field=test1.t_product:id/subject/keywords,test2.t_company:id/name/contact/ch# table field black filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)#canal.instance.filter.black.field=test1.t_product:subject/product_image,test2.t_company:id/name/contact/ch# mq config# 消息队列Topiccanal.mq.topic=productDetailChange# dynamic topic route by schema or table regex#canal.mq.dynamicTopic=mytest1.user,mytest2\\\\..*,.*\\\\..*canal.mq.partition=0# hash partition config#canal.mq.partitionsNum=3#canal.mq.partitionHash=test.table:id^name,.*\\\\..*#canal.mq.dynamicTopicPartitionNum=test.*:4,mycanal:6 修改canal.properties配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174########################################################## common argument ############################################################### tcp bind ipcanal.ip =# register ip to zookeepercanal.register.ip =canal.port = 11111canal.metrics.pull.port = 11112# canal instance user/passwd# canal.user = canal# canal.passwd = E3619321C1A937C46A0D8BD1DAC39F93B27D4458# canal admin config#canal.admin.manager = 127.0.0.1:8089canal.admin.port = 11110canal.admin.user = admincanal.admin.passwd = 4ACFE3202A5FF5CF467898FC58AAB1D615029441# admin auto register#canal.admin.register.auto = true#canal.admin.register.cluster =#canal.admin.register.name =canal.zkServers =# flush data to zkcanal.zookeeper.flush.period = 1000canal.withoutNetty = false# tcp, kafka, rocketMQ, rabbitMQcanal.serverMode = tcp# flush meta cursor/parse position to filecanal.file.data.dir = $&#123;canal.conf.dir&#125;canal.file.flush.period = 1000## memory store RingBuffer size, should be Math.pow(2,n)canal.instance.memory.buffer.size = 16384## memory store RingBuffer used memory unit size , default 1kbcanal.instance.memory.buffer.memunit = 1024 ## meory store gets mode used MEMSIZE or ITEMSIZEcanal.instance.memory.batch.mode = MEMSIZEcanal.instance.memory.rawEntry = true## detecing configcanal.instance.detecting.enable = false#canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()canal.instance.detecting.sql = select 1canal.instance.detecting.interval.time = 3canal.instance.detecting.retry.threshold = 3canal.instance.detecting.heartbeatHaEnable = false# support maximum transaction size, more than the size of the transaction will be cut into multiple transactions deliverycanal.instance.transaction.size = 1024# mysql fallback connected to new master should fallback timescanal.instance.fallbackIntervalInSeconds = 60# network configcanal.instance.network.receiveBufferSize = 16384canal.instance.network.sendBufferSize = 16384canal.instance.network.soTimeout = 30# binlog filter configcanal.instance.filter.druid.ddl = truecanal.instance.filter.query.dcl = falsecanal.instance.filter.query.dml = falsecanal.instance.filter.query.ddl = falsecanal.instance.filter.table.error = falsecanal.instance.filter.rows = falsecanal.instance.filter.transaction.entry = falsecanal.instance.filter.dml.insert = falsecanal.instance.filter.dml.update = falsecanal.instance.filter.dml.delete = false# binlog format/image checkcanal.instance.binlog.format = ROW,STATEMENT,MIXED canal.instance.binlog.image = FULL,MINIMAL,NOBLOB# binlog ddl isolationcanal.instance.get.ddl.isolation = false# parallel parser configcanal.instance.parser.parallel = true## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()#canal.instance.parser.parallelThreadSize = 16## disruptor ringbuffer size, must be power of 2canal.instance.parser.parallelBufferSize = 256# table meta tsdb infocanal.instance.tsdb.enable = truecanal.instance.tsdb.dir = $&#123;canal.file.data.dir:../conf&#125;/$&#123;canal.instance.destination:&#125;canal.instance.tsdb.url = jdbc:h2:$&#123;canal.instance.tsdb.dir&#125;/h2;CACHE_SIZE=1000;MODE=MYSQL;canal.instance.tsdb.dbUsername = canalcanal.instance.tsdb.dbPassword = canal# dump snapshot interval, default 24 hourcanal.instance.tsdb.snapshot.interval = 24# purge snapshot expire , default 360 hour(15 days)canal.instance.tsdb.snapshot.expire = 360########################################################## destinations ##############################################################canal.destinations = example# conf root dircanal.conf.dir = ../conf# auto scan instance dir add/remove and start/stop instancecanal.auto.scan = truecanal.auto.scan.interval = 5# set this value to &apos;true&apos; means that when binlog pos not found, skip to latest.# WARN: pls keep &apos;false&apos; in production env, or if you know what you want.canal.auto.reset.latest.pos.mode = falsecanal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml#canal.instance.tsdb.spring.xml = classpath:spring/tsdb/mysql-tsdb.xmlcanal.instance.global.mode = springcanal.instance.global.lazy = falsecanal.instance.global.manager.address = $&#123;canal.admin.manager&#125;#canal.instance.global.spring.xml = classpath:spring/memory-instance.xmlcanal.instance.global.spring.xml = classpath:spring/file-instance.xml#canal.instance.global.spring.xml = classpath:spring/default-instance.xml########################################################### MQ Properties ################################################################ aliyun ak/sk , support rds/mqcanal.aliyun.accessKey =canal.aliyun.secretKey =canal.aliyun.uid=canal.mq.flatMessage = truecanal.mq.canalBatchSize = 50canal.mq.canalGetTimeout = 100# Set this value to &quot;cloud&quot;, if you want open message trace feature in aliyun.canal.mq.accessChannel = localcanal.mq.database.hash = truecanal.mq.send.thread.size = 30canal.mq.build.thread.size = 8########################################################### Kafka ###############################################################kafka.bootstrap.servers = 127.0.0.1:9092kafka.acks = allkafka.compression.type = nonekafka.batch.size = 16384kafka.linger.ms = 1kafka.max.request.size = 1048576kafka.buffer.memory = 33554432kafka.max.in.flight.requests.per.connection = 1kafka.retries = 0kafka.kerberos.enable = falsekafka.kerberos.krb5.file = &quot;../conf/kerberos/krb5.conf&quot;kafka.kerberos.jaas.file = &quot;../conf/kerberos/jaas.conf&quot;########################################################### RocketMQ ###############################################################rocketmq.producer.group = testrocketmq.enable.message.trace = falserocketmq.customized.trace.topic =rocketmq.namespace =rocketmq.namesrv.addr = 127.0.0.1:9876rocketmq.retry.times.when.send.failed = 0rocketmq.vip.channel.enabled = falserocketmq.tag = ########################################################### RabbitMQ ###############################################################rabbitmq.host =rabbitmq.virtual.host =rabbitmq.exchange =rabbitmq.username =rabbitmq.password =rabbitmq.deliveryMode = Canal内部原理Canal源码入口AbstractEventParser的start方法 server代表一个canal运行实例，对应于一个jvm instance对应于一个数据队列 （1个server对应1..n个instance) eventParser (数据源接入，模拟slave协议和master进行交互，协议解析) eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作) eventStore (数据存储) metaManager (增量订阅&amp;消费信息管理器) Canal集群高可用Canal的HA分为Canal Server和Canal Client两部分实现，整个HA机制的控制主要是依赖了Zookeeper的几个特性，watcher和EPHEMERAL节点和session生命周期绑定。 Canal Server：为了减少对MySQL Dump的请求，不同Server上的instance要求同一时间只能有一个处于Running，其他的处于Standby状态 Canal Client：为了保证有序性，一份instance同一时间只能由一个Canal Client进行get/ack/rollback操作，否则客户端接收无法保证有序 Canal Server要启动某个Canal instance时都先向Zookeeper进行一次尝试启动判断，创建EPHEMERAL临时节点，谁创建成功就允许谁启动 创建Zookeeper节点成功后，对应的Canal Server就启动对应的Canal instance，没有创建成功的Canal instance就会处于Standby状态 一旦Zookeeper发现Canal Server A创建的节点消失后，立即通知其他的Canal Server再次进行步骤1的操作，重新选出一个Canal Server启动instance. Canal Client每次进行connect时，会首先向Zookeeper询问当前是谁启动了Canal instance，然后和其建立链接，一旦链接不可用，会重新尝试connect. Canal Client的方式和Canal Server方式类似，也是利用Zookeeper的抢占EPHEMERAL节点的方式进行控制。 使用12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt; &lt;artifactId&gt;canal.client&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415@Component@RocketMQMessageListener(topic = \"$&#123;rocketmq.canal.topic&#125;\", consumerGroup = \"$&#123;rocketmq.canal.group&#125;\")public class RefreshCacheListener implements RocketMQListener&lt;FlatMessage&gt; &#123; @Autowired private RedisOpsUtil redisOpsUtil; private final static String PRODUCT = \"pms_product\"; private final static String SKU = \"pms_sku_stock\"; @Override public void onMessage(FlatMessage flatMessage) &#123; //修改后的新记录 List&lt;Map&lt;String, String&gt;&gt; records = flatMessage.getData(); //修改前的数据 List&lt;Map&lt;String, String&gt;&gt; old = flatMessage.getOld(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class SimpleCanalClientExample &#123; public static void main(String args[]) &#123; // 创建链接 CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(\"127.0.0.1\", 11111), \"example\", \"\", \"\"); int batchSize = 1000; int emptyCount = 0; try &#123; connector.connect(); connector.subscribe(\".*\\\\..*\"); connector.rollback(); int totalEmptyCount = 120; while (emptyCount &lt; totalEmptyCount) &#123; Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) &#123; emptyCount++; System.out.println(\"empty count : \" + emptyCount); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; else &#123; emptyCount = 0; // System.out.printf(\"message[batchId=%s,size=%s] \\n\", batchId, size); printEntry(message.getEntries()); &#125; connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 &#125; System.out.println(\"empty too many times, exit\"); &#125; finally &#123; connector.disconnect(); &#125; &#125; private static void printEntry(List&lt;Entry&gt; entrys) &#123; for (Entry entry : entrys) &#123; if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) &#123; continue; &#125; RowChange rowChage = null; try &#123; rowChage = RowChange.parseFrom(entry.getStoreValue()); &#125; catch (Exception e) &#123; throw new RuntimeException(\"ERROR ## parser of eromanga-event has an error , data:\" + entry.toString(), e); &#125; EventType eventType = rowChage.getEventType(); System.out.println(String.format(\"================&amp;gt; binlog[%s:%s] , name[%s,%s] , eventType : %s\", entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName(), eventType)); for (RowData rowData : rowChage.getRowDatasList()) &#123; if (eventType == EventType.DELETE) &#123; printColumn(rowData.getBeforeColumnsList()); &#125; else if (eventType == EventType.INSERT) &#123; printColumn(rowData.getAfterColumnsList()); &#125; else &#123; System.out.println(\"-------&amp;gt; before\"); printColumn(rowData.getBeforeColumnsList()); System.out.println(\"-------&amp;gt; after\"); printColumn(rowData.getAfterColumnsList()); &#125; &#125; &#125; &#125; private static void printColumn(List&lt;Column&gt; columns) &#123; for (Column column : columns) &#123; System.out.println(column.getName() + \" : \" + column.getValue() + \" update=\" + column.getUpdated()); &#125; &#125;&#125;","tags":[{"name":"Canal","slug":"Canal","permalink":"https://yaoyinglong.github.io/tags/Canal/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"}]},{"title":"秒杀问题及解决方案","date":"2022-02-07T16:00:00.000Z","path":"Blog/Cloud/秒杀问题及解决方案/","text":"秒杀业务特性秒杀具有瞬时高并发的特点，秒杀请求在时间上高度集中于某一特定的时间点（秒杀开始那一秒），就会导致一个特别高的流量峰值，它对资源的消耗是瞬时的。 但对秒杀场景来说，最终能够抢到商品的人数是固定的，也就是说100人和10000人发起请求的结果都是一样的，并发度越高，无效请求也越多。 但是从业务上来说，秒杀活动是希望更多的人来参与，开始之前希望有更多的人来刷页面，但是真正开始下单时，秒杀请求并不是越多越好。 流量削峰服务器处理资源是恒定的，用或者不用它的处理能力都是一样的，出现峰值很容易导致忙到处理不过来，闲的时候却又没有什么要处理。 流量削峰，一是可以让服务端处理变得更加平稳，二是可以节省服务器的资源成本。针对秒杀这一场景，削峰从本质上来说就是更多地延缓用户请求的发出，以便减少和过滤掉一些无效请求，它遵从请求数要尽量少的原则。流量削峰的比较常见的思路：排队、答题、分层过滤。 秒杀业务设计 营销工具：系统整理的促销工具，可以对某些特定的工具详细解释 营销活动：从营销工具中提出创建一个活动 营销活动订单：针对营销活动产生的订单 商品级优惠：限时促销、限时抢购、秒杀、商品包邮 订单级优惠：满就赠、满立减、送优惠券、折扣、Vip折扣、订单包邮 全站级促销优惠：优惠券、优化券补发、银行促销、支付红包、团购预售、微信砍价 秒杀技术特性单一职责、流量错峰、限流、熔断、降级、队列削峰、预热快速扣减、动静分离 一般下单流程分为下单确认和下单提交，核心点为价格计算和库存处理，在下单确认时首先做一些检查、然后获取会员、商品等信息计算金额生成商品信息。 信息检查：检查本地缓存售罄状态、校验token是否有权限购买、判断redis库存是否充足、检查是否正在排队中 调用会员服务获取会员信息 调用产品服务获取产品信息 验证秒杀时间是否超时 获取用户收获列表 构建商品信息 根据各种优惠计算订单金额 下单提交的核心流程为： 信息检查：检查本地缓存售罄状态、校验token是否有权限购买、判断redis库存是否充足、检查是否正在排队中 调用会员服务获取会员信息 调用产品服务获取产品信息 验证秒杀时间是否超时 预减库存（异步流程） 生成下单商品信息 库存处理 库存问题高并发下会出现超卖问题、何时扣减库存 超卖问题可通过数据库锁、redis特性、异步下单等解决方案来解决 数据库锁悲观锁，通过MySQL提供的select...for update实现的悲观锁方式，但select...for update语句执行中所有扫描过的行都会被锁上，因此在MySQL中用悲观锁务必须确定走索引，而不是全表扫描，否则将会将整个数据表锁住。 12345begin;select flash_promotion_count from sms_flash_promotion_product_relation where id = 43 for UPDATE;update sms_flash_promotion_product_relation set flash_promotion_count = flash_promotion_count - 1 where id = 43;--ROLLBACK;commit； 悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性，若加锁时间过长，其他用户长时间无法访问，影响了程序的并发访问性，同时这样对数据库性能开销影响很大，特别是对长事务而言，这样的开销往往无法承受，这时就需要乐观锁。 乐观锁，在数据进行提交更新时，才会正式对数据的冲突与否进行检测，若发现冲突则返回错误信息，让用户决定如何去做。版本号的实现有数据版本机制和时间催机制两种。 12345begin;select flash_promotion_count from sms_flash_promotion_product_relation where id = 43 ;update sms_flash_promotion_product_relation set flash_promotion_count = flash_promotion_count, version = version + 1 where id = 43 and version = #version#;-- ROLLBACK;Commit； 除了查询库存还需要更新库存，还有订单、订单日志、订单详情等需要插入数据库。库存更新没问题，但插入订单时失败了是否回滚，若不在一个事务就会出错。若在一个事务又涉及到事务过长甚至可能是跨库然后无法用本地事务来解决。 12345678910-- 扣减库存，防止库存超卖，若可以买多个，上面的SQL就有问题UPDATE sms_flash_promotion_product_relationSET flash_promotion_count = CASE WHEN flash_promotion_count &gt;= #&#123;stock&#125; THEN flash_promotion_count - #&#123;stock&#125; ELSE flash_promotion_count ENDWHEREid = #&#123;id&#125; 数据库锁的问题：若数据库只有10个商品，1000个人来抢，意味着990个请求没有意义，但这种方案1000个请求都会到数据库尝试扣减库存，大量请求会导致数据库超载。 Redis版本使用数据库锁方案数据库性能相对来说是有很大瓶颈，故可把库存放到redis中，秒杀下单时先从redis中获取库存数量，然后根据库存数量判断是否可进行下一步，若有库存就直接下单没有库存就不能下单。这样可拦截大部分流量进入到数据库中。需要将商品库存预先加载到Redis中。 12345// 从redis缓存当中取出当前要购买的商品库存Integer stock = redisOpsUtil.get(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, Integer.class);if (stock == null || stock &lt;= 0) &#123; return CommonResult.failed(\"商品已经售罄，请购买其它商品!\");&#125; 对于Redis来说还是有网络IO，当商品售罄时在本地缓存中设置该商品的售罄标志为true，从而减少Redis的网络IO。 1234567891011Boolean localcache = cache.getCache(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId);if (localcache != null &amp;&amp; localcache) &#123; return CommonResult.failed(\"商品已经售罄,请购买其它商品!\");&#125;// 从redis缓存当中取出当前要购买的商品库存Integer stock = redisOpsUtil.get(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, Integer.class);if (stock == null || stock &lt;= 0) &#123; // 设置标记，如果售罄了在本地cache中设置为true cache.setLocalCache(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, true); return CommonResult.failed(\"商品已经售罄,请购买其它商品!\");&#125; 虽然可通过增加本地缓存减少Redis网络IO，但会存在产品售罄标志同步问题，可通过Zookeeper的watcher机制来实现同步，给每个JVM都监听Zookeeper的某个节点，一旦数据有改变之后通知到其他节点上。还可以利用Redis的Channel机制实现的发布订阅模式来实现产品售罄标志同步。 1234567891011121314151617181920212223public class RedisOpsUtil &#123; public void publish(String channel,Object message)&#123; redisTemplate.convertAndSend(channel,message); &#125;&#125;public boolean shouldPublishCleanMsg(Long productId) &#123; Integer stock = redisOpsUtil.get(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, Integer.class); return (stock == null || stock &lt;= 0);&#125;//通知服务群,清除本地售罄标记缓存if (shouldPublishCleanMsg(productId)) &#123; redisOpsUtil.publish(\"cleanNoStockCache\", productId);&#125;public class RedisChannelListener implements MessageListener &#123; @Autowired private LocalCache localCache; @Override public void onMessage(Message message, @Nullable byte[] pattern) &#123; log.info(\"sub message :) channel[cleanNoStockCache] !\"); String productId = new String(message.getBody(), StandardCharsets.UTF_8); localCache.remove(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId); &#125;&#125; Zookeeper和Redis各有各的优缺点，Zookeeper是CP模式的可保证高可用，但吞吐量会比较低，Redis这种发布订阅模式没有Ack，发出去后不管是否收到，因为减少了通讯吞吐量相对来说会比较高。 异步下单前面的方案，下单时会插入很多张表， 异步下单可以分流、让服务器处理压力变小、数据库压力减少 解耦，业务更清晰 天然排队处理能力 消息中间件有很多特性可以利用，如订单取消 订单超时取消 定时任务：时间不准确，定时扫数据库的话消耗性能也很大，效率也会很低，对数据库压力太大，集群还需要保证处理的幂等性和分布式问题 消息队列异步取消：通过延时消息实现 何时扣减库存下单时扣减redis中的库存 支付时扣减数据库中的库存 扣减库存系统中的库存 秒杀总结尽量将请求拦截在系统上游，后续占据99%的请求，直接Nginx层面拦截掉 都多写少的场景多使用缓存，多级缓存保护好数据库 用消息中间件解决流量削峰，订单请求写入RocketMQ进行削峰，让RocketMQ轻松抗下高并发压力，让订单系统慢慢消费和处理下单操作 秒杀商品详细页架构解决方案将秒杀活动商品详情页做成静态化 提前从数据库中把该页面需要的数据都提取出来组装成一份静态数据放在别的地方，避免每次访问都要访问后端数据库，该方案不适用商品比较多的商城如京东，适合商品较少的如小米，因为一旦修改了模板需要全部进行改动。 CDN+Nginx+Redis多级缓存架构 第一级缓存：请求秒杀商品详情页数据时，从就近CND上加载，不需要每次请求都到某个机房 Nginx基于Lua脚本实现本地缓存：提前把秒杀商品详情页的数据放到Nginx中缓存，不需要把请求转发到商品系统上 第二级缓存：Nginx上存在缓存数据过期之类的问题，导致没有找到需要的数据，此时由Nginx中的Lua脚本发送请求到本地缓存 第三级缓存：若还没找到，把请求转发到Redis集群中加载提前放入的秒杀商品数据 秒杀下单TPS压力过大的解决方案 加数据库服务器方案 会导致公司服务器成本急剧飙升 库存超卖：乐观锁和悲观锁，都会影响性能 用答题、复杂验证码的方案避免作弊以及延时下单：在前端或客户端设置秒杀答题，错开大量人下单的时间，阻止作弊器刷单 为秒杀独立出一套订单系统，专门负责秒杀请求：若秒杀下单请求和普通下单请求都由一套订单系统来承载，可能导致秒杀下单请求耗尽订单系统资源，或导致系统不稳定，从而导致其他普通下单请求也出现问题。 基于Redis实现下单时精准扣减库存，一旦库存扣减完则秒杀结束：一般会将每个秒杀商品库存提前写入Redis，在下单请求来后直接对Redis中的库存进行扣减 抢购完毕后提前过滤无效请求，大幅度消减转发到后端的流量 在Redis中库存扣减完成后，说明后续其他请求没有必要发送到秒杀系统中了，因为商品已经被抢购完成了，此时可让Nginx接收到后续请求时直接把后续请求过滤掉 一旦商品抢购完毕，可在Redis或Zookeeper中写入一个秒杀完毕的标志位，然后反向通知Nginx中自己写的Lua脚本，通过Lua脚本将后续请求直接过滤掉 在网关层或Sentinel做流量控制 瞬时高并发下单请求进入RocketMQ进行削峰，订单系统慢慢拉取消息完成下单操作：若判断发现通过Redis完成了库存扣减，此时直接发送消息到RocketMQ即可，让普通订单系统从RocketMQ中消费秒杀成功的消息进行常规的流程处理即可，后续订单系统以每秒几千的速率慢慢处理，延迟可能几十秒，这些订单就能被处理完毕 前端验证问题针对前端验证问题，可通过提前发Token，在秒杀前设置一个预约活动，如一个秒杀活动有20W个商品，可预先准备200W个Token，用户进行预约时，只发放200W个Token，其他人也能预约成功，但是其实没有获得token，后面秒杀直接通过该Token就可过滤掉一大部分人，相当于没有Token的人都只预约了个寂寞。 针对超卖问题针对超卖问题，可使用Redis分布式锁防超卖，针对同一个商品ID，使用一把分布式锁，若同时有成千上万个商品要进行秒杀，那就意味着同一时间Redis上锁解锁的操作会要执行成千上万次，这对Redis的性能消耗是相当巨大的，Redis就有可能升级成为新的性能瓶颈。 可把秒杀超卖的问题从分布式降级到本地JVM中，来获取极限性能。将秒杀服务接入配置中心，然后在秒杀服务开始前，由配置中心给每个应用服务实例下发一个库存数量。然后每次下单，每个服务器只管自己的库存数量，与其他应用服务器完全不进行库存同步，在各自的内存里扣减库存，这样就不会有超卖的情况发生。减少了网络消耗，性能也能够进一步提升。 可能给某服务器上的库存很快消耗完了，而其他的服务器上仍有库存，整个服务就会表现为你抢不到商品，但是在你后面抢商品的人却能抢到商品，但是这在秒杀这种场景下，完全是可以接受的。 若某一个应用服务器挂了，给他分配的库存就会丢失，这时只需要统计好订单的数量，可通过MQ来统计，也可通过Redis统计，等秒杀活动30分钟等待支付期过去后，再将没卖出去的库存重新丢回库存池，与没有付款而被取消的订单商品一起返场售卖即可。 兜底方案之限流&amp;降级对于很多秒杀系统而言，在诸如双十一这样的大流量的迅猛冲击下，都曾经或多或少发生过宕机的情况。当一个系统面临持续的大流量时，它其实很难单靠自身调整来恢复状态，必须等待流量自然下降或人为地把流量切走才行，这无疑会严重影响用户的购物体验。 在系统达到不可用状态之前就做好流量限制，防止最坏情况的发生。针对秒杀系统，在遇到大流量时，更多考虑的是运行阶段如何保障系统的稳定运行，常用的手段：限流，降级，拒绝服务。 限流相对降级是一种更极端的保存措施，限流就是当系统容量达到瓶颈时，需要通过限制一部分流量来保护系统，并做到既可人工执行开关，也支持自动化保护的措施。 限流既可在客户端限流，也可在服务端限流。限流的实现方式既要支持URL以及方法级别的限流，也要支持基于 QPS和线程的限流。限流必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能fast fail（快速失败）而拖垮系统。 Nginx限流可使用ngx_http_limit_conn_module对于一些服务器流量异常、负载过大，甚至是大流量的恶意攻击访问等，进行并发数的限制；该模块可根据定义的键来限制每个键值的连接数，只有那些正在被处理的请求，这些请求的头信息已被完全读入，所在的连接才会被计数。 123456789101112# 限制连接数，客户端的IP地址作为键，# binary_remote_addr变量长度是固定4字节，在32位平台中占用32字节或64字节，在64位平台中占用64字节# 1M共享空间可以保存3.2万个32位的状态，1.6万个64位的状态# 若共享内存空间被耗尽，服务器将会对后续所有的请求返回503即Service Temporarily Unavailable错误limit_conn_zone $binary_remote_addr zone=addr:10m;server &#123; location /download/ &#123; # 指定每个给定键值的最大同时连接数，同一IP同一时间只允许有1个连接 limit_conn addr 1; &#125;&#125;# 缺点：前端做LVS或反向代理，会出现大量的503错误，需要设置白名单对某些ip不做限制 通过ngx_http_limit_req_module模块可通过定义的键值来限制请求处理的频率。特别的可限制来自单个IP地址的请求处理频率。限制的方法如同漏斗，每秒固定处理请求数，推迟过多请求。 123456789101112http &#123; # 区域名称为one，大小为10m，平均处理的请求频率不能超过每秒一次。键值是客户端IP limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; ... server &#123; ... location /search/ &#123; # 允许超出频率限制的请求数为5，默认会被延迟处理，如果不希望延迟处理，可以使用nodelay参数 limit_req zone=one burst=5 nodelay; &#125; &#125;&#125; OpenResty利用Lua限流 网关接入Sentinel控制台Route维度限流API维度限流应用层限流系统第一次上线启动，或系统在Redis故障情况下重新启动，这时在高并发的场景下就会出现所有的流量都打到数据库上，导致数据库崩溃。因此需要通过缓存预热的方案，提前给Redis灌入部分数据后再提供服务。 可在流控规则中配置关联模式，将数据库资源加入限流资源中，当对数据库访问达到阈值，可对商品详情请求限流。","tags":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/tags/Cloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"}]},{"title":"基础算法","date":"2021-12-31T16:00:00.000Z","path":"Blog/算法/基础算法/","text":"斐波那契递归优化： 使用非递归：所有递归代码理论上一定可转换成非递归 加入缓存：把中间运算结果保存起来，这样就可把递归降至为o(n) 尾递归：调用函数一定出现在末尾，没有任何其他操作，编译器在编译代码时，若发现函数末尾已经没有操作了，这时候就不会创建新的栈，且覆盖到前面去。倒着算，每次会把中间结果带下去，不需要再回溯 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public static int fab(int n) &#123; // 时间复杂度和空间复杂度都是：O(2^n) if (n &lt;= 2) &#123; return 1; // 递归的终止条件 &#125; return fab(n - 1) + fab(n - 2); // 继续递归的过程&#125;public static int noFab(int n) &#123; // 不用递归 O(n) if (n &lt;= 2) return 1; int a = 1; int b = 1; int c = 0; for (int i = 3; i &lt;= n; i++) &#123; // 循环 c = a + b; a = b; b = c; &#125; return c;&#125;public static int fab2(int n) &#123; // 用数组来做缓存，时间复杂度降为O(n)，空间也降至为O(n) if (n &lt;= 2) return 1; // 递归的终止条件 if (data[n] &gt; 0) &#123; return data[n]; &#125; int res = fab2(n - 1) + fab2(n - 2); // 继续递归的过程 data[n] = res; return res;&#125;/** * n - 是肯定有的 * res - 上一次运算出来结果 * pre - 上上一次运算出来的结果 */public static int tailfab(int pre, int res, int n) &#123; // 时间复杂度和空间复杂度都是：O(n) if (n &lt;= 2) &#123; return res; // 递归的终止条件 &#125; return tailfab(res, pre + res, n - 1); // JDK源码&#125;public static int fac(int n) &#123; // 求N的阶乘 用普通递归怎么写 5=5*4*3*2*1=&gt; f(n) = if (n &lt;= 1) &#123; return 1; &#125; return n * fac(n - 1);&#125;public static int tailFac(int n, int res) &#123; // 尾递归 传结果，res就是我们每次保存的结果 System.out.println(n + \":\" + res); // 这个地方打印出来的值是怎么样的？ if (n &lt;= 1) &#123; return res; &#125; return tailFac(n - 1, n * res); //倒着算&#125; 2的整数次幂12345678910111213141516171819// 获取数据二进制的最高位，低位全部置0，获取小于等于i的最接近的2的整数次幂的数public static int highestOneBit(int i) &#123; i |= (i &gt;&gt; 1); i |= (i &gt;&gt; 2); i |= (i &gt;&gt; 4); i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1);&#125;// 获取大于等于cap的最接近的2的幂的数作为数组的容量static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; HashHash应用加密如MD5哈希算法、判断数据重复MD5、相似性检测如论文检测、指纹算法，把每个论文计算出一个指纹，使用汉明距离，负载均衡策略如Nginx可根据ip计算hash值，分布式系统数据分库分表问题。一致性Hash即哈希环。 开放寻址开放寻址法核心思想是，若出现散列冲突就重新探测一个空闲位置将其插入，当往散列表中插入数据时，若某个数据经过散列函数散列之后，存储位置已经被占用了，就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。 缺点：删除需要特殊处理，若插入数据过多会导致散列表很多冲突查找可能会退化成遍历 链路地址使用链表，链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多，在散列表中，每个key会对应一条链表，所有散列值相同的元素都放到相同槽位对应的链表中。 常用hash算法以下三个Hash散列算法，可将算出的Hash值比较均匀分布到不同的段 123456789101112131415161718192021222324252627282930313233public int hash_1(String key) &#123; int hash = 0; int i; for (i = 0; i &lt; key.length(); ++i) &#123; hash = 33 * hash + key.charAt(i); &#125; return Math.abs(hash) % size;&#125;public int hash_2(String key) &#123; final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i &lt; key.length(); i++) &#123; hash = (hash ^ key.charAt(i)) * p; &#125; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; return Math.abs(hash) % size;&#125;public int hash_3(String key) &#123; int hash, i; for (hash = 0, i = 0; i &lt; key.length(); ++i) &#123; hash += key.charAt(i); hash += hash &lt;&lt; 10; hash ^= hash &gt;&gt; 6; &#125; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 11; hash += hash &lt;&lt; 15; return Math.abs(hash) % size;&#125; JDK8中ConcurrentHashMap中因为数组大小限制导致高位在索引计算中一直用不到，故在spread方法中将hash的高16位利用起来进行异或转换，最后与HASH_BITS相与的目的是让得到的hash值总是正数，保证正数的目的是，因为hash值为-1表示哈希表正在扩容中，该哈希桶已经被迁移到了新的临时hash表，此时节点为ForwardingNode类型。 1234static final int HASH_BITS = 0x7fffffff;static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; BitMap123456789101112131415161718192021222324252627282930313233343536373839404142434445public class BitMap &#123; byte[] bits; // 若为byte那就一个只能存8个数 int max; // 表示最大的那个数 public BitMap(int max) &#123; this.max = max; bits = new byte[(max &gt;&gt; 3) + 1]; //max/8 + 1 &#125; public void add(int n) &#123; // 往bitmap里面添加数字 if (n &gt; max) &#123; throw new IllegalArgumentException(); &#125; int bitsIndex = n &gt;&gt; 3; // 除以8就可知道byte数组下标 int loc = n &amp; 7; // 用&amp;运算，获取bit位 bits[bitsIndex] |= 1 &lt;&lt; loc; // 把bit数组中bisIndex下标的byte里面第loc个bit位置为1 &#125; public boolean find(int n) &#123; if (n &gt; max) &#123; throw new IllegalArgumentException(); &#125; int bitsIndex = n &gt;&gt; 3; // 除以8就可知道byte数组下标 int loc = n &amp; 7; // 这里其实还可以用&amp;运算 int flag = bits[bitsIndex] &amp; 1 &lt;&lt; loc; // 若原来那个位置是0 那肯定就是0 只有那个位置是1 才行 return flag != 0; &#125; public void delete(int n) &#123; if (n &gt; max) &#123; throw new IllegalArgumentException(); &#125; int index = n &gt;&gt; 3; // 除以8就可知道byte数组下标 int loc = n &amp; 7; // 这里其实还可以用&amp;运算 bits[index] &amp;= ~(1 &lt;&lt; loc); &#125; public static void main(String[] args) &#123; BitMap bitMap = new BitMap(200000001); // 10亿 bitMap.add(2); bitMap.add(3); bitMap.add(4); bitMap.add(63); bitMap.add(65); System.out.println(bitMap.find(3)); System.out.println(bitMap.find(64)); bitMap.delete(3); System.out.println(bitMap.find(3)); &#125;&#125; BloomFilter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class BloomFilter &#123; int size; BitSet bits; // bit数组,bitMap long /64 %34 // 00000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111 public BloomFilter(int size) &#123; this.size = size; bits = new BitSet(size); &#125; public void add(String key) &#123; // O(1) int hash1 = hash_1(key); int hash2 = hash_2(key); int hash3 = hash_3(key); bits.set(hash1, true); bits.set(hash2, true); bits.set(hash3, true); &#125; public boolean find(String key) &#123; int hash1 = hash_1(key); if (!bits.get(hash1)) &#123; return false; &#125; int hash2 = hash_2(key); if (!bits.get(hash2)) &#123; return false; &#125; int hash3 = hash_3(key); if (!bits.get(hash3)) &#123; return false; &#125; return true; &#125; public int hash_1(String key) &#123; int hash = 0; int i; for (i = 0; i &lt; key.length(); ++i) &#123; hash = 33 * hash + key.charAt(i); &#125; return Math.abs(hash) % size; &#125; public int hash_2(String key) &#123; final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i &lt; key.length(); i++) &#123; hash = (hash ^ key.charAt(i)) * p; &#125; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; return Math.abs(hash) % size; &#125; public int hash_3(String key) &#123; int hash, i; for (hash = 0, i = 0; i &lt; key.length(); ++i) &#123; hash += key.charAt(i); hash += hash &lt;&lt; 10; hash ^= hash &gt;&gt; 6; &#125; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 11; hash += hash &lt;&lt; 15; return Math.abs(hash) % size; &#125; public static void main(String... args) &#123; // O(1000000000) 8bit= 1byte BloomFilter bloomFilter = new BloomFilter(Integer.MAX_VALUE); // 21亿 System.out.println(bloomFilter.hash_1(\"1\")); System.out.println(bloomFilter.hash_2(\"1\")); System.out.println(bloomFilter.hash_3(\"1\")); bloomFilter.add(\"1111\"); bloomFilter.add(\"1123\"); bloomFilter.add(\"11323\"); System.out.println(bloomFilter.find(\"1\")); System.out.println(bloomFilter.find(\"1123\")); &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"PriorityQueue源码","date":"2021-12-30T16:00:00.000Z","path":"Blog/Java/基础/PriorityQueue源码/","text":"对于PriorityQueue优先队列最核心的就是其添加元素删除元素后维持元素的顺序的逻辑，其实用的算法其实就是堆排序。堆其实是一种特殊的树，堆是一颗完全二叉树，且堆树又分为大顶堆和小顶堆。 数组是完全二叉树最佳存储结构，因为完全二叉树有特殊的属性，可直接利用数组下标表示左右节点，数组下标为K的元素对应的完全二叉树中左右子节点在数组中的位置分别为2*K + 1、2*K+2。 不论大顶堆还是小顶堆，都是从完全二叉数中最后一个元素的父节点开始堆化，将最大或最小的元素排到堆顶，然后遍历整棵树，每一次将堆顶的元素，和未排序的最后一个元素交换，再进行一次堆化，这样就将数据排好序了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class HeapSort &#123; public void heapSortAsc(Integer[] arr) &#123; int len = arr.length; // len / 2 - 1表示的是从完全二叉数中最后一个元素的父节点开始堆化 for (int start = len / 2 - 1; start &gt;= 0; start--) &#123; maxHeapDown(arr, start, len); // 将树中最大的元素排到堆顶 &#125; // 上面的循环只是将最大的元素排到了堆顶，但是整棵树即数组中的元素不是有序的 // 每一次将对顶的元素即最大的元素，和未排序的最后一个元素交换，再进行一次堆化，这样就将数据从小到大排序了 for (int index = len - 1; index &gt; 0; index--) &#123; int temp = arr[0]; arr[0] = arr[index]; arr[index] = temp; maxHeapDown(arr, 0, index); // len~i已经排好序了 &#125; &#125; /** * 将完全二叉树中最大的元素放到堆顶，end表示最多建到的点 */ public void maxHeapDown(Integer[] arr, int start, int end) &#123; int parent = start; int left = parent * 2 + 1; // 找到当前节点的左子节点位置 while (left &lt; end) &#123; int max = left; // max表示左右节点大的那一个在数组中的位置 if (left + 1 &lt; end &amp;&amp; arr[left] &lt; arr[left + 1]) &#123; // 比较左右节点和父节点的大小 max = left + 1; // 若右节点比左节点大，则将父节点和右节点交换 &#125; // 若左节点比右节点大，则将父节点和左节点交换 if (arr[parent] &gt; arr[max]) &#123; // 若父节点大于子节点中最大的那一个，则退出 return; &#125; else &#123; // 若父节点小于子节点中最大的那一个，则交换 int tmp = arr[parent]; arr[parent] = arr[max]; arr[max] = tmp; parent = max; // 还原指针，交换数据后，max指向的是被交换下来的父节点，还需要往下遍历，故需要将parent指向需要遍历的数据 left = parent * 2 + 1; // 找到之前左右节点大的节点的左子节点在数组中的索引位置 &#125; &#125; &#125; public void heapSortDesc(Integer[] arr) &#123; int len = arr.length; for (int start = len / 2 - 1; start &gt;= 0; start--) &#123; minHeapDown(arr, start, len); &#125; for (int index = len - 1; index &gt; 0; index--) &#123; int tmp = arr[0]; arr[0] = arr[index]; arr[index] = tmp; minHeapDown(arr, 0, index); &#125; &#125; /** * 将完全二叉树中最小的元素放到堆顶，end表示最多建到的点 */ public void minHeapDown(Integer[] arr, int start, int end) &#123; int parent = start; int left = 2 * start + 1; // 找到当前节点的左子节点位置 while (left &lt; end) &#123; int min = left; // min表示左右节点小的那一个在数组中的位置 if (left + 1 &lt; end &amp;&amp; arr[left] &gt; arr[left + 1]) &#123; min = left + 1; &#125; if (arr[min] &gt; arr[parent]) &#123; // 比较左右节点中小的那一个和父节点的大小 break; // 若小的那个节点都比父节点大，说明不需要再遍历了 &#125; int tmp = arr[min]; arr[min] = arr[parent]; arr[parent] = tmp; parent = min; // 还原指针，交换数据后，min指向的是被交换下来的父节点，还需要往下遍历，故需要将parent指向需要遍历的数据 left = 2 * parent + 1; // 找到之前左右节点小的节点的左子节点在数组中的索引位置 &#125; &#125; @Test public void InsertSortTest() &#123; &#123; Integer[] arr = new Integer[]&#123;8, 6, 4, 9, 74, 25, 1, 3, 5, 28, 35, 0, 22, 2, 7, 10, 26, 29&#125;; heapSortAsc(arr); System.err.println(\" after:\" + Arrays.asList(arr)); &#125; &#123; Integer[] arr = new Integer[]&#123;8, 6, 4, 9, 74, 25, 1, 3, 5, 28, 35, 0, 22, 2, 7, 10, 26, 29&#125;; heapSortDesc(arr); System.err.println(\" after:\" + Arrays.asList(arr)); &#125; &#125;&#125; 若传入的集合是一个排序好的集合，则直接将数据拷贝到PriorityQueue的内部数组queue中，若传入结合本身就是一个PriorityQueue，则直接赋值queue。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class PriorityQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements java.io.Serializable &#123; private static final int DEFAULT_INITIAL_CAPACITY = 11; transient Object[] queue; private int size = 0; private final Comparator&lt;? super E&gt; comparator; public PriorityQueue(Collection&lt;? extends E&gt; c) &#123; if (c instanceof SortedSet&lt;?&gt;) &#123; SortedSet&lt;? extends E&gt; ss = (SortedSet&lt;? extends E&gt;) c; this.comparator = (Comparator&lt;? super E&gt;) ss.comparator(); initElementsFromCollection(ss); // 直接将数据拷贝到queue中 &#125; else if (c instanceof PriorityQueue&lt;?&gt;) &#123; PriorityQueue&lt;? extends E&gt; pq = (PriorityQueue&lt;? extends E&gt;) c; this.comparator = (Comparator&lt;? super E&gt;) pq.comparator(); initFromPriorityQueue(pq); &#125; else &#123; this.comparator = null; initFromCollection(c); &#125; &#125; private void initElementsFromCollection(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); // If c.toArray incorrectly doesn't return Object[], copy it. if (a.getClass() != Object[].class) a = Arrays.copyOf(a, a.length, Object[].class); int len = a.length; if (len == 1 || this.comparator != null) for (int i = 0; i &lt; len; i++) if (a[i] == null) throw new NullPointerException(); this.queue = a; this.size = a.length; &#125; private void initFromPriorityQueue(PriorityQueue&lt;? extends E&gt; c) &#123; if (c.getClass() == PriorityQueue.class) &#123; this.queue = c.toArray(); this.size = c.size(); &#125; else &#123; initFromCollection(c); &#125; &#125;&#125; 堆化的关键代码，和上面的堆排序的例子一样，这里是使用的小顶堆 12345678910111213141516171819202122232425262728293031323334353637383940414243444546private void initFromCollection(Collection&lt;? extends E&gt; c) &#123; initElementsFromCollection(c); heapify();&#125;private void heapify() &#123; // 从完全二叉数中最后一个元素的父节点开始堆化，之所以右移再减一，是因为数组下标是从0开始的 for (int i = (size &gt;&gt;&gt; 1) - 1; i &gt;= 0; i--) siftDown(i, (E) queue[i]);&#125;private void siftDown(int k, E x) &#123; if (comparator != null) // 若传入的comparator不为空则使用传入的 siftDownUsingComparator(k, x); else siftDownComparable(k, x);&#125;private void siftDownUsingComparator(int k, E x) &#123; int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; // 传入的K必须要小于堆元素个数的一半，因为堆化最多就循环half次 int child = (k &lt;&lt; 1) + 1; // 找到K节点的左子节点 Object c = queue[child]; // 获取K节点的左子节点值 int right = child + 1; // 找到K节点的右子节点 if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; // 若K的左子节点值小于右子节点值，则将C置为右子节点的值 if (comparator.compare(x, (E) c) &lt;= 0) // 将目标对象X与K的左右子节点中最小的比较 break; // 若目标对象X比K的左右子节点最小的值还小，则不用交换直接退出 queue[k] = c; // 若X比K的左右子节点最小的值还大，则将K对应的值与子节点中最小的值交换 k = child; // 将K指针恢复，因为上一步做了交换，K指向的交换后的c &#125; queue[k] = x; // 将目标值赋值给K&#125;private void siftDownComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;)x; int half = size &gt;&gt;&gt; 1; // loop while a non-leaf while (k &lt; half) &#123; // 传入的K必须要小于堆元素个数的一半，因为堆化最多就循环half次 int child = (k &lt;&lt; 1) + 1; // 找到K节点的左子节点 Object c = queue[child]; // 获取K节点的左子节点值 int right = child + 1; // 找到K节点的右子节点 if (right &lt; size &amp;&amp; ((Comparable&lt;? super E&gt;) c).compareTo((E) queue[right]) &gt; 0) c = queue[child = right]; // 若K的左子节点值小于右子节点值，则将C置为右子节点的值 if (key.compareTo((E) c) &lt;= 0) // 将目标对象X与K的左右子节点中最小的比较 break; // 若目标对象X比K的左右子节点最小的值还小，则不用交换直接退出 queue[k] = c; // 若X比K的左右子节点最小的值还大，则将K对应的值与子节点中最小的值交换 k = child; // 将K指针恢复，因为上一步做了交换，K指向的交换后的c &#125; queue[k] = key; // 将目标值赋值给K&#125; 添加元素，若元素个数已经大于等于数组长度了，则进行扩容，若旧的容量小于64，则每次扩容为旧容量的一倍加2，否则扩容旧容量的一半。然后siftUp进行小顶堆插入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public boolean add(E e) &#123; return offer(e);&#125;public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); modCount++; int i = size; if (i &gt;= queue.length) grow(i + 1); size = i + 1; if (i == 0) queue[0] = e; else siftUp(i, e); return true;&#125;private void grow(int minCapacity) &#123; int oldCapacity = queue.length; // Double size if small; else grow by 50% int newCapacity = oldCapacity + ((oldCapacity &lt; 64) ? (oldCapacity + 2) : (oldCapacity &gt;&gt; 1)); // overflow-conscious code if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); queue = Arrays.copyOf(queue, newCapacity);&#125;private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125;private void siftUp(int k, E x) &#123; if (comparator != null) siftUpUsingComparator(k, x); else siftUpComparable(k, x);&#125;private void siftUpUsingComparator(int k, E x) &#123; while (k &gt; 0) &#123; // 将插入值从堆尾，的父节点一直比较，直到找到其该放置的位置，退出 int parent = (k - 1) &gt;&gt;&gt; 1; // 找到K的父节点 Object e = queue[parent]; if (comparator.compare(x, (E) e) &gt;= 0) break; // 若父节点值小于目标节点直接退出循环，将目标值直接复制给K queue[k] = e; // 若父节点值大于目标节点，则交换父子节点的额值 k = parent; &#125; queue[k] = x;&#125; 删除元素，若队列中无元素则直接返回null，然后获取第0个元素和最后一个元素，然后删除最后一个元素，这里其实就是删除第0个元素，然后将最后一个元素与第0个元素交换，然后再进行一次堆化。 123456789101112131415161718192021222324252627282930313233public E poll() &#123; if (size == 0) // 若队列元素为null直接返回null return null; int s = --size; modCount++; E result = (E) queue[0]; // 获取第0个元素 E x = (E) queue[s]; // 获取最后一个元素 queue[s] = null;// 将最后一个元素置空 if (s != 0) siftDown(0, x); return result;&#125;private void siftDown(int k, E x) &#123; if (comparator != null) siftDownUsingComparator(k, x); else siftDownComparable(k, x);&#125;private void siftDownUsingComparator(int k, E x) &#123; int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; // 传入的K必须要小于堆元素个数的一半，因为堆化最多就循环half次 int child = (k &lt;&lt; 1) + 1; // 找到K节点的左子节点 Object c = queue[child]; // 获取K节点的左子节点值 int right = child + 1; // 找到K节点的右子节点 if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; // 若K的左子节点值小于右子节点值，则将C置为右子节点的值 if (comparator.compare(x, (E) c) &lt;= 0) // 将目标对象X与K的左右子节点中最小的比较 break; // 若目标对象X比K的左右子节点最小的值还小，则不用交换直接退出 queue[k] = c; // 若X比K的左右子节点最小的值还大，则将K对应的值与子节点中最小的值交换 k = child; // 将K指针恢复，因为上一步做了交换，K指向的交换后的c &#125; queue[k] = x; // 将目标值赋值给K&#125;","tags":[{"name":"PriorityQueue","slug":"PriorityQueue","permalink":"https://yaoyinglong.github.io/tags/PriorityQueue/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"布隆过滤器","date":"2021-12-30T16:00:00.000Z","path":"Blog/Java/工具/布隆过滤器/","text":"","tags":[{"name":"BitMap","slug":"BitMap","permalink":"https://yaoyinglong.github.io/tags/BitMap/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"ElasticSearch实战","date":"2021-12-26T16:00:00.000Z","path":"Blog/Cloud/ELK/ElasticSearch实战/","text":"12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.6.1&lt;/version&gt;&lt;/dependency&gt; 使用Java API来操作ES集群初始化连接，基于RestClient.builder方法来构建RestClientBuilder，使用RestHighLevelClient去连接ES集群，用HttpHost来添加ES的节点。 123456789// 建立与ES的连接// 1. 使用RestHighLevelClient构建客户端连接。// 2. 基于RestClient.builder方法来构建RestClientBuilder// 3. 用HttpHost来添加ES的节点RestClientBuilder restClientBuilder = RestClient.builder( new HttpHost(\"192.168.21.130\", 9200, \"http\") , new HttpHost(\"192.168.21.131\", 9200, \"http\") , new HttpHost(\"192.168.21.132\", 9200, \"http\"));RestHighLevelClient restHighLevelClient = new RestHighLevelClient(restClientBuilder); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public void add(JobDetail jobDetail) throws IOException &#123; // 构建IndexRequest对象，用来描述ES发起请求的数据 IndexRequest indexRequest = new IndexRequest(JOB_IDX); // 设置文档ID indexRequest.id(String.valueOf(jobDetail.getId())); // 使用FastJSON将实体类对象转换为JSON String json = JSONObject.toJSONString(jobDetail); // 使用IndexRequest.source方法设置文档数据，并设置请求的数据为JSON格式 indexRequest.source(json, XContentType.JSON); // 使用ES RestHighLevelClient调用index方法发起请求，将一个文档添加到索引中 restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);&#125;public JobDetail findById(long id) throws IOException &#123; GetRequest getRequest = new GetRequest(JOB_IDX, id + \"\"); // 构建GetRequest请求 // 使用RestHighLevelClient.get发送GetRequest请求，并获取到ES服务器的响应。 GetResponse getResponse = restHighLevelClient.get(getRequest, RequestOptions.DEFAULT); String json = getResponse.getSourceAsString();// 将ES响应的数据转换为JSON字符串 // 并使用FastJSON将JSON字符串转换为JobDetail类对象 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); jobDetail.setId(id);// 单独设置ID return jobDetail;&#125;public void update(JobDetail jobDetail) throws IOException &#123; // 判断对应ID的文档是否存在，构建GetRequest GetRequest getRequest = new GetRequest(JOB_IDX, jobDetail.getId() + \"\"); // 执行client的exists方法，发起请求，判断是否存在 boolean exists = restHighLevelClient.exists(getRequest, RequestOptions.DEFAULT); if(exists) &#123; // 构建UpdateRequest请求 UpdateRequest updateRequest = new UpdateRequest(JOB_IDX, jobDetail.getId() + \"\"); // 设置UpdateRequest的文档，并配置为JSON格式 updateRequest.doc(JSONObject.toJSONString(jobDetail), XContentType.JSON); // 执行client发起update请求 restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT); &#125;&#125;public void deleteById(long id) throws IOException &#123; DeleteRequest deleteRequest = new DeleteRequest(JOB_IDX, id + \"\");// 构建delete请求 restHighLevelClient.delete(deleteRequest, RequestOptions.DEFAULT);// 使用RestHighLevelClient执行delete请求&#125;public List&lt;JobDetail&gt; searchByKeywords(String keywords) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, \"title\", \"jd\"); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; return jobDetailArrayList;&#125;public Map&lt;String, Object&gt; searchByPage(String keywords, int pageNum, int pageSize) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, \"title\", \"jd\"); searchSourceBuilder.query(multiMatchQueryBuilder); // 将查询条件设置到查询请求构建器中 searchSourceBuilder.size(pageSize);// 每页显示多少条 searchSourceBuilder.from((pageNum - 1) * pageSize);// 设置从第几条开始查询 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; // 将结果封装到Map结构中（带有分页信息） long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put(\"total\", totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 resultMap.put(\"content\", jobDetailArrayList); content -&gt; 当前分页中的数据 return resultMap;&#125;public Map&lt;String, Object&gt; searchByScrollPage(String keywords, String scrollId, int pageSize) throws IOException &#123; SearchResponse searchResponse = null; if(scrollId == null) &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, \"title\", \"jd\"); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置高亮 highlightBuilder.field(\"title\"); highlightBuilder.field(\"jd\"); highlightBuilder.preTags(\"&lt;font color='red'&gt;\"); highlightBuilder.postTags(\"&lt;/font&gt;\"); searchSourceBuilder.highlighter(highlightBuilder); // 给请求设置高亮 searchSourceBuilder.size(pageSize); // 每页显示多少条 searchRequest.source(searchSourceBuilder); // 调用SearchRequest.source将查询条件设置到检索请求 searchRequest.scroll(TimeValue.timeValueMinutes(5)); // 设置scroll查询 // 执行RestHighLevelClient.search发起请求 searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); &#125; else &#123; // 第二次查询的时候，直接通过scroll id查询数据 SearchScrollRequest searchScrollRequest = new SearchScrollRequest(scrollId); searchScrollRequest.scroll(TimeValue.timeValueMinutes(5)); // 使用RestHighLevelClient发送scroll请求 searchResponse = restHighLevelClient.scroll(searchScrollRequest, RequestOptions.DEFAULT); &#125; SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123; // 遍历结果，迭代ES响应的数据 String json = documentFields.getSourceAsString(); // 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); // 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId())); // 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); // 设置高亮的一些文本到实体类中 封装了高亮 Map&lt;String, HighlightField&gt; highlightFieldMap = documentFields.getHighlightFields(); HighlightField titleHL = highlightFieldMap.get(\"title\"); HighlightField jdHL = highlightFieldMap.get(\"jd\"); if(titleHL != null) &#123; Text[] fragments = titleHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123; // 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setTitle(builder.toString()); // 设置到实体类中 &#125; if(jdHL != null) &#123; Text[] fragments = jdHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123;// 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setJd(builder.toString()); // 设置到实体类中 &#125; &#125; // 将结果封装到Map结构中，带有分页信息 long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; hashMap = new HashMap&lt;&gt;(); hashMap.put(\"scroll_id\", searchResponse.getScrollId()); hashMap.put(\"content\", jobDetailArrayList); // content -&gt; 当前分页中的数据 hashMap.put(\"total_num\", totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 return hashMap;&#125;public void close() throws IOException &#123; restHighLevelClient.close();&#125; 京东商城搜索效果实现ES索引库表结构分析 1234567891011121314151617181920212223242526272829303132333435363738PUT product_db // 创建索引库&#123;\"mappings\":&#123;\"properties\":&#123;\"id\":&#123;\"type\":\"long\"&#125;,\"name\":&#123;\"type\":\"text\",\"analyzer\":\"ik_max_word\"&#125;,\"keywords\":&#123;\"type\":\"text\",\"analyzer\":\"ik_max_word\"&#125;,\"subTitle\":&#123;\"type\":\"text\",\"analyzer\":\"ik_max_word\"&#125;,\"salecount\":&#123;\"type\":\"long\"&#125;,\"putawayDate\":&#123;\"type\":\"date\"&#125;,\"price\":&#123;\"type\":\"double\"&#125;,\"promotionPrice\":&#123;\"type\":\"keyword\"&#125;,\"originalPrice\":&#123;\"type\":\"keyword\"&#125;,\"pic\":&#123;\"type\":\"keyword\"&#125;,\"sale\":&#123;\"type\":\"long\"&#125;,\"hasStock\":&#123;\"type\":\"boolean\"&#125;,\"brandId\":&#123;\"type\":\"long\"&#125;,\"brandName\":&#123;\"type\":\"keyword\"&#125;,\"brandImg\":&#123;\"type\":\"keyword\"&#125;,\"categoryId\":&#123;\"type\":\"long\"&#125;,\"categoryName\":&#123;\"type\":\"keyword\"&#125;,\"attrs\":&#123;\"type\":\"nested\",\"properties\":&#123;\"attrId\":&#123;\"type\":\"long\"&#125;,\"attrName\":&#123;\"type\":\"keyword\"&#125;,\"attrValue\":&#123;\"type\":\"keyword\"&#125;&#125;&#125;&#125;&#125;&#125;// 索引数据准备PUT /product_db/_doc/1&#123;\"id\":\"26\",\"name\":\"小米 11 手机\",\"keywords\":\"小米手机\",\"subTitle\":\"AI智慧全面屏 6GB +64GB 亮黑色 全网通版 移动联通电信4G手机 双卡双待 双卡双待\",\"price\":\"3999\",\"promotionPrice\":\"2999\",\"originalPrice\":\"5999\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":999,\"putawayDate\":\"2021-04-01\",\"brandId\":6,\"brandName\":\"小米\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":1,\"attrName\":\"cpu\",\"attrValue\":\"2核\"&#125;,&#123;\"attrId\":2,\"attrName\":\"颜色\",\"attrValue\":\"黑色\"&#125;]&#125;PUT /product_db/_doc/2&#123;\"id\":\"27\",\"name\":\"小米 10 手机\",\"keywords\":\"小米手机\",\"subTitle\":\"AI智慧全面屏 4GB +64GB 亮白色 全网通版 移动联通电信4G手机 双卡双待 双卡双待\",\"price\":\"2999\",\"promotionPrice\":\"1999\",\"originalPrice\":\"3999\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg\",\"sale\":999,\"hasStock\":false,\"salecount\":99,\"putawayDate\":\"2021-04-02\",\"brandId\":6,\"brandName\":\"小米\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":1,\"attrName\":\"cpu\",\"attrValue\":\"4核\"&#125;,&#123;\"attrId\":2,\"attrName\":\"颜色\",\"attrValue\":\"白色\"&#125;]&#125;PUT /product_db/_doc/3&#123;\"id\":\"28\",\"name\":\"小米 手机\",\"keywords\":\"小米手机\",\"subTitle\":\"AI智慧全面屏 4GB +64GB 亮蓝色 全网通版 移动联通电信4G手机 双卡双待 双卡双待\",\"price\":\"2999\",\"promotionPrice\":\"1999\",\"originalPrice\":\"3999\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":199,\"putawayDate\":\"2021-04-03\",\"brandId\":6,\"brandName\":\"小米\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":1,\"attrName\":\"cpu\",\"attrValue\":\"2核\"&#125;,&#123;\"attrId\":2,\"attrName\":\"颜色\",\"attrValue\":\"蓝色\"&#125;]&#125;PUT /product_db/_doc/4&#123;\"id\":\"29\",\"name\":\"Apple iPhone 8 Plus 64GB 金色特别版 移动联通电信4G手机\",\"keywords\":\"苹果手机\",\"subTitle\":\"苹果手机 Apple产品年中狂欢节，好物尽享，美在智慧！速来 &gt;&gt; 勾选[保障服务][原厂保2年]，获得AppleCare+全方位服务计划，原厂延保售后无忧。\",\"price\":\"5999\",\"promotionPrice\":\"4999\",\"originalPrice\":\"7999\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5acc5248N6a5f81cd.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":1199,\"putawayDate\":\"2021-04-04\",\"brandId\":51,\"brandName\":\"苹果\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/timg.jpg\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":1,\"attrName\":\"cpu\",\"attrValue\":\"4核\"&#125;,&#123;\"attrId\":2,\"attrName\":\"颜色\",\"attrValue\":\"金色\"&#125;]&#125;PUT /product_db/_doc/5&#123;\"id\":\"30\",\"name\":\"HLA海澜之家简约动物印花短袖T恤\",\"keywords\":\"海澜之家衣服\",\"subTitle\":\"HLA海澜之家短袖T恤\",\"price\":\"199\",\"promotionPrice\":\"99\",\"originalPrice\":\"299\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ad83a4fN6ff67ecd.jpg!cc_350x449.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":19,\"putawayDate\":\"2021-04-05\",\"brandId\":50,\"brandName\":\"海澜之家\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg\",\"categoryId\":8,\"categoryName\":\"T恤\",\"attrs\":[&#123;\"attrId\":3,\"attrName\":\"尺寸\",\"attrValue\":\"M\"&#125;,&#123;\"attrId\":4,\"attrName\":\"颜色\",\"attrValue\":\"黑色\"&#125;]&#125;PUT /product_db/_doc/6&#123;\"id\":\"31\",\"name\":\"HLA海澜之家蓝灰花纹圆领针织布短袖T恤\",\"keywords\":\"海澜之家衣服\",\"subTitle\":\"HLA海澜之家短袖T恤\",\"price\":\"299\",\"promotionPrice\":\"199\",\"originalPrice\":\"299\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ac98b64N70acd82f.jpg!cc_350x449.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":399,\"putawayDate\":\"2021-04-06\",\"brandId\":50,\"brandName\":\"海澜之家\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg\",\"categoryId\":8,\"categoryName\":\"T恤\",\"attrs\":[&#123;\"attrId\":3,\"attrName\":\"尺寸\",\"attrValue\":\"X\"&#125;,&#123;\"attrId\":4,\"attrName\":\"颜色\",\"attrValue\":\"蓝灰\"&#125;]&#125;PUT /product_db/_doc/7&#123;\"id\":\"32\",\"name\":\"HLA海澜之家短袖T恤男基础款\",\"keywords\":\"海澜之家衣服\",\"subTitle\":\"HLA海澜之家短袖T恤\",\"price\":\"269\",\"promotionPrice\":\"169\",\"originalPrice\":\"399\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5a51eb88Na4797877.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":399,\"putawayDate\":\"2021-04-07\",\"brandId\":50,\"brandName\":\"海澜之家\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg\",\"categoryId\":8,\"categoryName\":\"T恤\",\"attrs\":[&#123;\"attrId\":3,\"attrName\":\"尺寸\",\"attrValue\":\"L\"&#125;,&#123;\"attrId\":4,\"attrName\":\"颜色\",\"attrValue\":\"蓝色\"&#125;]&#125;PUT /product_db/_doc/8&#123;\"id\":\"33\",\"name\":\"小米（MI）小米电视4A \",\"keywords\":\"小米电视机家用电器\",\"subTitle\":\"小米（MI）小米电视4A 55英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视\",\"price\":\"2269\",\"promotionPrice\":\"2169\",\"originalPrice\":\"2399\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b02804dN66004d73.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":132,\"putawayDate\":\"2021-04-09\",\"brandId\":6,\"brandName\":\"小米\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png\",\"categoryId\":35,\"categoryName\":\"手机数码\",\"attrs\":[&#123;\"attrId\":5,\"attrName\":\"屏幕尺寸\",\"attrValue\":\"52\"&#125;,&#123;\"attrId\":6,\"attrName\":\"机身颜色\",\"attrValue\":\"黑色\"&#125;]&#125;PUT /product_db/_doc/9&#123;\"id\":\"34\",\"name\":\"小米（MI）小米电视4A 65英寸\",\"keywords\":\"小米电视机家用电器\",\"subTitle\":\"小米（MI）小米电视4A 65英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视\",\"price\":\"3269\",\"promotionPrice\":\"3169\",\"originalPrice\":\"3399\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b028530N51eee7d4.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":999,\"putawayDate\":\"2021-04-10\",\"brandId\":6,\"brandName\":\"小米\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png\",\"categoryId\":35,\"categoryName\":\"手机数码\",\"attrs\":[&#123;\"attrId\":5,\"attrName\":\"屏幕尺寸\",\"attrValue\":\"65\"&#125;,&#123;\"attrId\":6,\"attrName\":\"机身颜色\",\"attrValue\":\"金色\"&#125;]&#125;PUT /product_db/_doc/10&#123;\"id\":\"35\",\"name\":\"耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码\",\"keywords\":\"耐克运动鞋 鞋子\",\"subTitle\":\"耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码\",\"price\":\"569\",\"promotionPrice\":\"369\",\"originalPrice\":\"899\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b235bb9Nf606460b.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":399,\"putawayDate\":\"2021-04-11\",\"brandId\":58,\"brandName\":\"NIKE\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg\",\"categoryId\":29,\"categoryName\":\"男鞋\",\"attrs\":[&#123;\"attrId\":7,\"attrName\":\"尺码\",\"attrValue\":\"42\"&#125;,&#123;\"attrId\":8,\"attrName\":\"颜色\",\"attrValue\":\"黑色\"&#125;]&#125;PUT /product_db/_doc/11&#123;\"id\":\"36\",\"name\":\"耐克NIKE 男子 气垫 休闲鞋 AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色41码\",\"keywords\":\"耐克运动鞋 鞋子\",\"subTitle\":\"AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色\",\"price\":\"769\",\"promotionPrice\":\"469\",\"originalPrice\":\"999\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b19403eN9f0b3cb8.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":499,\"putawayDate\":\"2021-04-13\",\"brandId\":58,\"brandName\":\"NIKE\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg\",\"categoryId\":29,\"categoryName\":\"男鞋\",\"attrs\":[&#123;\"attrId\":7,\"attrName\":\"尺码\",\"attrValue\":\"44\"&#125;,&#123;\"attrId\":8,\"attrName\":\"颜色\",\"attrValue\":\"白色\"&#125;]&#125;PUT /product_db/_doc/12&#123;\"id\":\"37\",\"name\":\"(华为)HUAWEI MateBook X Pro 2019款 13.9英寸3K触控全面屏 轻薄笔记本\",\"keywords\":\"轻薄笔记本华为 笔记本电脑\",\"subTitle\":\"轻薄华为笔记本 电脑\",\"price\":\"4769\",\"promotionPrice\":\"4469\",\"originalPrice\":\"4999\",\"pic\":\"http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200317/800_800_1555752016264mp.png\",\"sale\":999,\"hasStock\":true,\"salecount\":699,\"putawayDate\":\"2021-04-14\",\"brandId\":3,\"brandName\":\"华为\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":9,\"attrName\":\"容量\",\"attrValue\":\"16G\"&#125;,&#123;\"attrId\":10,\"attrName\":\"网络\",\"attrValue\":\"4G\"&#125;]&#125;PUT /product_db/_doc/13&#123;\"id\":\"38\",\"name\":\"华为nova6se 手机 绮境森林 全网通（8G+128G)\",\"keywords\":\"轻薄笔记本华为 手机\",\"subTitle\":\"华为nova6se 手机\",\"price\":\"6769\",\"promotionPrice\":\"6469\",\"originalPrice\":\"6999\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":899,\"putawayDate\":\"2021-04-15\",\"brandId\":3,\"brandName\":\"华为\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":9,\"attrName\":\"容量\",\"attrValue\":\"64G\"&#125;,&#123;\"attrId\":10,\"attrName\":\"网络\",\"attrValue\":\"5G\"&#125;]&#125;PUT /product_db/_doc/14&#123;\"id\":\"39\",\"name\":\"iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜\",\"keywords\":\"手机膜\",\"subTitle\":\"iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜\",\"price\":\"29\",\"promotionPrice\":\"39\",\"originalPrice\":\"49\",\"pic\":\"http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/6df99dab78bb2014.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":799,\"putawayDate\":\"2021-04-16\",\"brandId\":51,\"brandName\":\"苹果\",\"brandImg\":\"http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png\",\"categoryId\":30,\"categoryName\":\"手机配件\",\"attrs\":[&#123;\"attrId\":11,\"attrName\":\"手机膜-材料\",\"attrValue\":\"钢化\"&#125;,&#123;\"attrId\":12,\"attrName\":\"手机膜-颜色\",\"attrValue\":\"白色\"&#125;]&#125;PUT /product_db/_doc/15&#123;\"id\":\"40\",\"name\":\"七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装\",\"keywords\":\"七匹狼服装 衣服\",\"subTitle\":\"七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装\",\"price\":\"129\",\"promotionPrice\":\"139\",\"originalPrice\":\"149\",\"pic\":\"http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/19e846e727dff337.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":199,\"putawayDate\":\"2021-04-20\",\"brandId\":49,\"brandName\":\"七匹狼\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/18d8bc3eb13533fab466d702a0d3fd1f40345bcd.jpg\",\"categoryId\":8,\"categoryName\":\"T恤\",\"attrs\":[&#123;\"attrId\":3,\"attrName\":\"尺寸\",\"attrValue\":\"M\"&#125;,&#123;\"attrId\":4,\"attrName\":\"颜色\",\"attrValue\":\"白色\"&#125;]&#125;PUT /product_db/_doc/16&#123;\"id\":\"41\",\"name\":\"华为P40 Pro手机\",\"keywords\":\"华为手机\",\"subTitle\":\"华为P40 Pro手机\",\"price\":\"2129\",\"promotionPrice\":\"2139\",\"originalPrice\":\"2149\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":199,\"putawayDate\":\"2021-05-03\",\"brandId\":3,\"brandName\":\"华为\",\"brandImg\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":9,\"attrName\":\"容量\",\"attrValue\":\"128G\"&#125;,&#123;\"attrId\":10,\"attrName\":\"网络\",\"attrValue\":\"5G\"&#125;]&#125;PUT /product_db/_doc/17&#123;\"id\":\"42\",\"name\":\"朵唯智能手机 4G全网通 老人学生双卡双待手机\",\"keywords\":\"朵唯手机\",\"subTitle\":\"朵唯手机后置双摄，国产虎贲芯片！优化散热结构！浅薄机身！朵唯4月特惠！\",\"price\":\"3129\",\"promotionPrice\":\"3139\",\"originalPrice\":\"3249\",\"pic\":\"http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg\",\"sale\":999,\"hasStock\":true,\"salecount\":1199,\"putawayDate\":\"2021-06-01\",\"brandId\":59,\"brandName\":\"朵唯\",\"brandImg\":\"http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png\",\"categoryId\":19,\"categoryName\":\"手机通讯\",\"attrs\":[&#123;\"attrId\":9,\"attrName\":\"容量\",\"attrValue\":\"32G\"&#125;,&#123;\"attrId\":10,\"attrName\":\"网络\",\"attrValue\":\"4G\"&#125;]&#125; 检索DSL语句构建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST /product_db/_doc/_search&#123; \"from\": 0, \"size\": 8, \"query\": &#123; \"bool\": &#123; \"must\": [&#123;\"match\": &#123;\"name\": &#123;\"query\": \"手机\"&#125;&#125;&#125;], \"filter\": [ &#123;\"term\": &#123;\"hasStock\": &#123;\"value\": true&#125;&#125;&#125;, &#123;\"range\": &#123;\"price\": &#123;\"from\": \"1\",\"to\": \"5000\"&#125;&#125;&#125; ] &#125; &#125;, \"sort\": [&#123;\"salecount\": &#123;\"order\": \"asc\"&#125;&#125;], \"aggregations\": &#123; \"brand_agg\": &#123; \"terms\": &#123;\"field\": \"brandId\",\"size\": 50&#125;, \"aggregations\": &#123; \"brand_name_agg\": &#123;\"terms\": &#123;\"field\": \"brandName\"&#125;&#125;, \"brand_img_agg\": &#123;\"terms\": &#123;\"field\": \"brandImg\"&#125;&#125; &#125; &#125;, \"category_agg\": &#123; \"terms\": &#123;\"field\": \"categoryId\",\"size\": 50,\"min_doc_count\": 1&#125;, \"aggregations\": &#123; \"category_name_agg\": &#123;\"terms\": &#123;\"field\": \"categoryName\"&#125;&#125; &#125; &#125;, \"attr_agg\": &#123; \"nested\": &#123;\"path\": \"attrs\"&#125;, \"aggregations\": &#123; \"attr_id_agg\": &#123; \"terms\": &#123;\"field\": \"attrs.attrId\"&#125;, \"aggregations\": &#123; \"attr_name_agg\": &#123;\"terms\": &#123;\"field\": \"attrs.attrName\"&#125;&#125;, \"attr_value_agg\": &#123;\"terms\": &#123;\"field\": \"attrs.attrValue\"&#125;&#125; &#125; &#125; &#125; &#125; &#125;, \"highlight\": &#123; \"pre_tags\": [\"&lt;b style='color:red'&gt;\"], \"post_tags\": [\"&lt;/b&gt;\"], \"fields\": &#123;\"name\": &#123;&#125;&#125; &#125;&#125; Java代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228@ResponseBody@RequestMapping(value = \"/searchList\")public CommonResult&lt;ESResponseResult&gt; listPage(ESRequestParam param, HttpServletRequest request) &#123; // 根据传递来的页面的查询参数，去es中检索商品 ESResponseResult searchResult = tulingMallSearchService.search(param); return CommonResult.success(searchResult);&#125;@Overridepublic ESResponseResult search(ESRequestParam param) &#123; try &#123; // 构建检索对象-封装请求相关参数信息 SearchRequest searchRequest = startBuildRequestParam(param); // 进行检索操作 SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT); // 分析响应数据，封装成指定的格式 ESResponseResult responseResult = startBuildResponseResult(response, param); return responseResult; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125;/** * 封装请求参数信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private SearchRequest startBuildRequestParam(ESRequestParam param) &#123; SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); if (!StringUtils.isEmpty(param.getKeyword())) &#123; //单字段查询 boolQueryBuilder.must(QueryBuilders.matchQuery(\"name\", param.getKeyword())); //多字段查询 boolQueryBuilder.must(QueryBuilders.multiMatchQuery(param.getKeyword(),\"name\",\"keywords\",\"subTitle\")); &#125; // 根据类目ID进行过滤 if (null != param.getCategoryId()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"categoryId\", param.getCategoryId())); &#125; // 根据品牌ID进行过滤 if (null != param.getBrandId() &amp;&amp; param.getBrandId().size() &gt; 0) &#123; boolQueryBuilder.filter(QueryBuilders.termsQuery(\"brandId\", param.getBrandId())); &#125; // 根据属性进行相关过滤 if (param.getAttrs() != null &amp;&amp; param.getAttrs().size() &gt; 0) &#123; param.getAttrs().forEach(item -&gt; &#123; //attrs=1_白色&amp;2_4核 BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); //attrs=1_64G String[] s = item.split(\"_\"); String attrId = s[0]; String[] attrValues = s[1].split(\":\");//这个属性检索用的值 boolQuery.must(QueryBuilders.termQuery(\"attrs.attrId\", attrId)); boolQuery.must(QueryBuilders.termsQuery(\"attrs.attrValue\", attrValues)); NestedQueryBuilder nestedQueryBuilder = QueryBuilders.nestedQuery(\"attrs\", boolQuery, ScoreMode.None); boolQueryBuilder.filter(nestedQueryBuilder); &#125;); &#125; // 是否有库存 if (null != param.getHasStock()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"hasStock\", param.getHasStock() == 1)); &#125; // 根据价格过滤 if (!StringUtils.isEmpty(param.getPrice())) &#123; // 价格的输入形式为：10-100（起始价格和最终价格）或-100（不指定起始价格）或10-（不限制最终价格） RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(\"price\"); String[] price = param.getPrice().split(\"_\"); if (price.length == 2) &#123; rangeQueryBuilder.gte(price[0]).lte(price[1]); &#125; else if (price.length == 1) &#123; if (param.getPrice().startsWith(\"_\")) &#123; rangeQueryBuilder.lte(price[1]); &#125; if (param.getPrice().endsWith(\"_\")) &#123; rangeQueryBuilder.gte(price[0]); &#125; &#125; boolQueryBuilder.filter(rangeQueryBuilder); &#125; // 封装所有查询条件 searchSourceBuilder.query(boolQueryBuilder); //实现排序、高亮、分页操作，排序，页面传入的参数值形式 sort=price_asc/desc if (!StringUtils.isEmpty(param.getSort())) &#123; String sort = param.getSort(); String[] sortFileds = sort.split(\"_\"); System.out.println(\"sortFileds:\"+sortFileds.length); if(!StringUtils.isEmpty(sortFileds[0]))&#123; SortOrder sortOrder = \"asc\".equalsIgnoreCase(sortFileds[1]) ? SortOrder.ASC : SortOrder.DESC; searchSourceBuilder.sort(sortFileds[0], sortOrder); &#125; &#125; // 分页查询 searchSourceBuilder.from((param.getPageNum() - 1) * SearchConstant.PAGE_SIZE); searchSourceBuilder.size(SearchConstant.PAGE_SIZE); // 高亮显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.field(\"name\"); highlightBuilder.preTags(\"&lt;b style='color:red'&gt;\"); highlightBuilder.postTags(\"&lt;/b&gt;\"); searchSourceBuilder.highlighter(highlightBuilder); &#125; // 对品牌、分类信息、属性信息进行聚合分析，按照品牌进行聚合 TermsAggregationBuilder brand_agg = AggregationBuilders.terms(\"brand_agg\"); brand_agg.field(\"brandId\").size(50); // 品牌的子聚合-品牌名聚合 brand_agg.subAggregation(AggregationBuilders.terms(\"brand_name_agg\").field(\"brandName\").size(1)); // 品牌的子聚合-品牌图片聚合 brand_agg.subAggregation(AggregationBuilders.terms(\"brand_img_agg\").field(\"brandImg\").size(1)); searchSourceBuilder.aggregation(brand_agg); // 按照分类信息进行聚合 TermsAggregationBuilder category_agg = AggregationBuilders.terms(\"category_agg\"); category_agg.field(\"categoryId\").size(50); category_agg.subAggregation(AggregationBuilders.terms(\"category_name_agg\").field(\"categoryName\").size(1)); searchSourceBuilder.aggregation(category_agg); // 按照属性信息进行聚合 NestedAggregationBuilder attr_agg = AggregationBuilders.nested(\"attr_agg\", \"attrs\"); // 按照属性ID进行聚合 TermsAggregationBuilder attr_id_agg = AggregationBuilders.terms(\"attr_id_agg\").field(\"attrs.attrId\"); attr_agg.subAggregation(attr_id_agg); // 在每个属性ID下，按照属性名进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(\"attr_name_agg\").field(\"attrs.attrName\").size(1)); // 在每个属性ID下，按照属性值进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(\"attr_value_agg\").field(\"attrs.attrValue\").size(50)); searchSourceBuilder.aggregation(attr_agg); System.out.println(\"构建的DSL语句 &#123;&#125;:\"+ searchSourceBuilder.toString()); SearchRequest searchRequest = new SearchRequest(new String[]&#123;SearchConstant.INDEX_NAME&#125;, searchSourceBuilder); return searchRequest;&#125;/** * 封装查询到的结果信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private ESResponseResult startBuildResponseResult(SearchResponse response, ESRequestParam param) &#123; ESResponseResult result = new ESResponseResult(); // 获取查询到的商品信息 SearchHits hits = response.getHits(); List&lt;EsProduct&gt; esModels = new ArrayList&lt;&gt;(); // 遍历所有商品信息 if (hits.getHits() != null &amp;&amp; hits.getHits().length &gt; 0) &#123; for (SearchHit hit : hits.getHits()) &#123; String sourceAsString = hit.getSourceAsString(); EsProduct esModel = JSON.parseObject(sourceAsString, EsProduct.class); // 判断是否按关键字检索，若是就显示高亮，否则不显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; // 拿到高亮信息显示标题 HighlightField name = hit.getHighlightFields().get(\"name\"); // 判断name中是否含有查询的关键字(因为是多字段查询，因此可能不包含指定的关键字，假设不包含则显示原始name字段的信息) String nameValue = name!=null ? name.getFragments()[0].string() : esModel.getName(); esModel.setName(nameValue); &#125; esModels.add(esModel); &#125; &#125; result.setProducts(esModels); // 当前商品涉及到的所有品牌信息，小米手机和小米电脑都属于小米品牌，过滤重复品牌信息 Set&lt;ESResponseResult.BrandVo&gt; brandVos = new LinkedHashSet&lt;&gt;(); // 获取到品牌的聚合 ParsedLongTerms brandAgg = response.getAggregations().get(\"brand_agg\"); for (Terms.Bucket bucket : brandAgg.getBuckets()) &#123; ESResponseResult.BrandVo brandVo = new ESResponseResult.BrandVo(); // 获取品牌的id long brandId = bucket.getKeyAsNumber().longValue(); brandVo.setBrandId(brandId); // 获取品牌的名字 ParsedStringTerms brandNameAgg = bucket.getAggregations().get(\"brand_name_agg\"); String brandName = brandNameAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandName(brandName); // 获取品牌的LOGO ParsedStringTerms brandImgAgg = bucket.getAggregations().get(\"brand_img_agg\"); String brandImg = brandImgAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandImg(brandImg); System.out.println(\"brandId:\"+brandId+\"brandName:\"+brandName+\"brandImg\"); brandVos.add(brandVo); &#125; System.out.println(\"brandVos.size:\"+brandVos.size()); result.setBrands(brandVos); // 当前商品相关的所有类目信息，获取到分类的聚合 List&lt;ESResponseResult.categoryVo&gt; categoryVos = new ArrayList&lt;&gt;(); ParsedLongTerms categoryAgg = response.getAggregations().get(\"category_agg\"); for (Terms.Bucket bucket : categoryAgg.getBuckets()) &#123; ESResponseResult.categoryVo categoryVo = new ESResponseResult.categoryVo(); // 获取分类id String keyAsString = bucket.getKeyAsString(); categoryVo.setCategoryId(Long.parseLong(keyAsString)); // 获取分类名 ParsedStringTerms categoryNameAgg = bucket.getAggregations().get(\"category_name_agg\"); String categoryName = categoryNameAgg.getBuckets().get(0).getKeyAsString(); categoryVo.setCategoryName(categoryName); categoryVos.add(categoryVo); &#125; result.setCategorys(categoryVos); // 获取商品相关的所有属性信息 List&lt;ESResponseResult.AttrVo&gt; attrVos = new ArrayList&lt;&gt;(); // 获取属性信息的聚合 ParsedNested attrsAgg = response.getAggregations().get(\"attr_agg\"); ParsedLongTerms attrIdAgg = attrsAgg.getAggregations().get(\"attr_id_agg\"); for (Terms.Bucket bucket : attrIdAgg.getBuckets()) &#123; ESResponseResult.AttrVo attrVo = new ESResponseResult.AttrVo(); // 获取属性ID值 long attrId = bucket.getKeyAsNumber().longValue(); attrVo.setAttrId(attrId); // 获取属性的名字 ParsedStringTerms attrNameAgg = bucket.getAggregations().get(\"attr_name_agg\"); String attrName = attrNameAgg.getBuckets().get(0).getKeyAsString(); attrVo.setAttrName(attrName); // 获取属性的值 ParsedStringTerms attrValueAgg = bucket.getAggregations().get(\"attr_value_agg\"); List&lt;String&gt; attrValues = attrValueAgg.getBuckets().stream().map(item -&gt; item.getKeyAsString()).collect(Collectors.toList()); attrVo.setAttrValue(attrValues); attrVos.add(attrVo); &#125; result.setAttrs(attrVos); // 进行分页操作 result.setPageNum(param.getPageNum()); // 获取总记录数 long total = hits.getTotalHits().value; result.setTotal(total); // 计算总页码 int totalPages = (int) total % SearchConstant.PAGE_SIZE == 0 ? (int) total / SearchConstant.PAGE_SIZE : ((int) total / SearchConstant.PAGE_SIZE + 1); result.setTotalPages(totalPages); List&lt;Integer&gt; pageNavs = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;= totalPages; i++) &#123; pageNavs.add(i); &#125; result.setPageNavs(pageNavs); return result;&#125;","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://yaoyinglong.github.io/tags/ElasticSearch/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"ELK","slug":"Cloud/ELK","permalink":"https://yaoyinglong.github.io/categories/Cloud/ELK/"}]},{"title":"ElasticSearch进阶","date":"2021-12-25T16:00:00.000Z","path":"Blog/Cloud/ELK/ElasticSearch进阶/","text":"分值计算首先根据用户query条件，过滤出包含指定term的doc，Field-length norm即field长度越长相关度越弱。 123query \"hello world\" --&gt; hello / world / hello &amp; worldbool --&gt; must/must not/should --&gt; 过滤 --&gt; 包含 / 不包含 / 可能包含doc --&gt; 不打分数 --&gt; 正或反 true or false --&gt; 为了减少后续要计算的doc的数量，提升性能 relevance score算法：计算出一个索引中文本与搜索文本之间关联匹配程度，ES使用term frequency/inverse document frequency算法简称为TF/IDF算法。Term frequency即搜索文本中各个词条在field文本中出现次数，次数越多越相关。Inverse document frequency即搜索文本中各个词条在整个索引所有文档中出现次数，出现次数越多越不相关。 向量空间模型vector space model向量空间模型，多个term对一个doc的总分数，es会根据查询字符串在所有doc中的评分情况，计算出一个query vector即query向量，会给每一个doc，拿每个term计算出一个分数来。每个doc vector计算出对query vector的弧度，最后基于该弧度给出一个doc相对于query中多个term的总分数，弧度越大分数越低，弧度越小分数越高。若是多个term，那么就是线性代数来计算，无法用图表示。 若查询条件字符串为hello world，hello这个term，给的基于所有doc的一个评分就是3，world这个term，给的基于所有doc的一个评分就是6，则query向量为[3, 6]，若3个doc一个包含hello，一个包含world，一个包含hello和world，doc向量分别为[3, 0]、[0, 6]、[3, 6]。 分词器工作流程首先进行normalization切分词语，将目标文本拆分成单个单词，同时对每个单词进行normalization时态转换单复数转换、分词器recall、搜索时召回率、增加能搜索到的结果的数量。分词器将文本进行各种处理，最后处理好的结果才会用来建立倒排索引。 123character filter：在一段文本进行分词之前，先进行预处理，如过滤html标签（&lt;span&gt;hello&lt;span&gt; --&gt; hello），&amp; --&gt; and (I&amp;you --&gt; I and you)tokenizer：分词，hello you and me --&gt; hello, you, and, metoken filter：lowercase，stop word，synonymom，liked --&gt; like，Tom --&gt; tom，a/the/an --&gt; 干掉，small --&gt; little 对于默认的standard分词器： standard tokenizer：以单词边界进行切分 standard token filter：什么都不做 lowercase token filter：将所有字母转换为小写 stop token filer：默认被禁用，移除停用词，比如a the it等等1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST _analyze&#123; \"analyzer\": \"standard\", \"text\": \"Set the shape to semi-transparent by calling set_trans(5)\"&#125;PUT /my_index&#123; \"settings\": &#123; \"analysis\": &#123; \"analyzer\": &#123; \"es_std\": &#123; \"type\": \"standard\", \"stopwords\": \"_english_\" // 启用english停用词token filter &#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; \"analyzer\": \"standard\", \"text\": \"a dog is in the house\"&#125;GET /my_index/_analyze&#123; \"analyzer\": \"es_std\", \"text\":\"a dog is in the house\"&#125;PUT /my_index // 定制化分词器&#123; \"settings\": &#123; \"analysis\": &#123; \"char_filter\": &#123;\"&amp;_to_and\": &#123;\"type\": \"mapping\",\"mappings\": [\"&amp;=&gt; and\"]&#125;&#125;, \"filter\": &#123;\"my_stopwords\": &#123;\"type\": \"stop\",\"stopwords\": [\"the\",\"a\"]&#125; &#125;, \"analyzer\": &#123; \"my_analyzer\": &#123;\"type\": \"custom\",\"char_filter\": [\"html_strip\",\"&amp;_to_and\"],\"tokenizer\": \"standard\",\"filter\": [\"lowercase\",\"my_stopwords\"]&#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; \"text\": \"tom&amp;jerry are a friend in the house, &lt;a&gt;, HAHA!!\", \"analyzer\": \"my_analyzer\"&#125; IK分词器IK分词器配置文件地址为es/plugins/ik/config，ik原生最重要的是main.dic和stopword.dic两个配置文件 IKAnalyzer.cfg.xml：用来配置自定义词库 main.dic：ik原生内置中文词库，总共有27万多条，会按照该文件中的词语去分词 quantifier.dic：单位相关的词 suffix.dic：后缀相关的词 surname.dic：中国姓氏 stopword.dic：英文停用词，停用词会在分词时被干掉，不会建立在倒排索引中 可通过在IKAnalyzer.cfg.xml配置文件中通过修改&lt;entry key=&quot;ext_dict&quot;&gt;&lt;/entry&gt;配置内容扩展自己的词库，需重启es才能生效，还可以通过修改&lt;entry key=&quot;ext_stopwords&quot;&gt;&lt;/entry&gt;配置扩展停用词。 每次在es扩展词典中，手动添加新词语，添加完都要重启es才能生效，非常麻烦，且es是分布式的，可能有数百个节点，不能每次都一个一个节点上面去修改。IKAnalyzer.cfg.xml配置文件中可通过&lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt;和&lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt;配置支持远程扩展字典。 高亮显示搜索中经常需要对搜索关键字做高亮显示，ES默认通过添加&lt;em&gt;&lt;/em&gt;标签，在HTML中会变成红色，指定的field中若包含了搜索词，就会在那个field文本中，对搜索词进行红色高亮显示。highlight中的field必须跟query中field一一对齐。 123456789101112131415161718192021222324252627282930PUT /news_website/_doc/1&#123; \"title\": \"这是我写的第一篇文章\", \"content\": \"大家好，这是我写的第一篇文章，特别喜欢这个文章门户网站！！！\"&#125;GET /news_website/_doc/_search&#123; \"query\": &#123; \"match\": &#123;\"title\": \"文章\"&#125; &#125;, \"highlight\": &#123; \"fields\": &#123;\"title\": &#123;&#125;&#125; &#125;&#125;GET /news_website/_doc/_search&#123; \"query\": &#123; \"bool\": &#123; \"should\": [ &#123;\"match\": &#123;\"title\": \"文章\"&#125;&#125;, &#123;\"match\": &#123;\"content\": \"文章\"&#125;&#125; ] &#125; &#125;, \"highlight\": &#123; \"fields\": &#123;\"title\": &#123;&#125;,\"content\": &#123;&#125; &#125; &#125;&#125; 默认的highlight为plain highlight即lucene highlight，在mapping中设置index_options为offsets使用posting highlight。在mapping中设置term_vector为term_vector使用fast verctor highlight，对大于1mb的field性能更高。也可通过在查询时强制使用某种highlighter。 一般情况下用plain highlight也就足够了，不需要做其他额外设置，若对高亮性能要求很高，可尝试启用posting highlight，若field值特别大超过了1M，则可用fast vector highlight。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455PUT /news_website&#123; \"mappings\": &#123; \"properties\": &#123; \"title\": &#123;\"type\": \"text\",\"analyzer\": \"ik_max_word\"&#125;, \"content\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"index_options\": \"offsets\" &#125; &#125; &#125;&#125;PUT /news_website&#123; \"mappings\": &#123; \"properties\": &#123; \"title\": &#123;\"type\": \"text\",\"analyzer\": \"ik_max_word\"&#125;, \"content\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"term_vector\": \"with_positions_offsets\" &#125; &#125; &#125;&#125;GET /news_website/_doc/_search&#123; \"query\": &#123;\"match\": &#123;\"content\": \"文章\"&#125;&#125;, \"highlight\": &#123; \"fields\": &#123;\"content\": &#123;\"type\": \"plain\"&#125;&#125; &#125;&#125;GET /news_website/_doc/_search&#123; \"query\": &#123;\"match\": &#123;\"content\": \"文章\"&#125;&#125;, \"highlight\": &#123; // 设置高亮html标签，默认是&lt;em&gt;标签 \"pre_tags\": [\"&lt;span color='red'&gt;\"], \"post_tags\": [\"&lt;/span&gt;\"], \"fields\": &#123;\"content\": &#123;\"type\": \"plain\"&#125;&#125; &#125;&#125;GET /_search&#123; \"query\": &#123;\"match\": &#123;\"content\": \"文章\"&#125;&#125;, \"highlight\": &#123; \"fields\": &#123; \"content\": &#123; \"fragment_size\": 150, // 设置要显示出来的fragment文本长度，默认100 \"number_of_fragments\": 3 // 指定显示高亮fragment文本片段个数 &#125; &#125; &#125;&#125;用一个大家容易理解的SQL语法来解释，如：select count(*) from table group by column。那么group by column分组后的每组数据就是bucket。对每个分组执行的count(*)就是metric。 聚合搜索bucket就是一个聚合搜索时的数据分组，metric就是对一个bucket数据执行的统计分析，metric有求和，最大值，最小值，平均值等多种统计。如select count(*) from table group by column其中group by column分组后的每组数据就是bucket，每个分组执行的count(*)就是metric。 1234567891011121314151617181920PUT /cars&#123;\"mappings\":&#123;\"properties\":&#123;\"price\":&#123;\"type\":\"long\"&#125;,\"color\":&#123;\"type\":\"keyword\"&#125;,\"brand\":&#123;\"type\":\"keyword\"&#125;,\"model\":&#123;\"type\":\"keyword\"&#125;,\"sold_date\":&#123;\"type\":\"date\"&#125;,\"remark\":&#123;\"type\":\"text\",\"analyzer\":\"ik_max_word\"&#125;&#125;&#125;&#125;POST /cars/_bulk&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":258000,\"color\":\"金色\",\"brand\":\"大众\",\"model\":\"大众迈腾\",\"sold_date\":\"2021-10-28\",\"remark\":\"大众中档车\"&#125;&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":123000,\"color\":\"金色\",\"brand\":\"大众\",\"model\":\"大众速腾\",\"sold_date\":\"2021-11-05\",\"remark\":\"大众神车\"&#125;&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":239800,\"color\":\"白色\",\"brand\":\"标志\",\"model\":\"标志508\",\"sold_date\":\"2021-05-18\",\"remark\":\"标志品牌全球上市车型\"&#125;&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":148800,\"color\":\"白色\",\"brand\":\"标志\",\"model\":\"标志408\",\"sold_date\":\"2021-07-02\",\"remark\":\"比较大的紧凑型车\"&#125;&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":1998000,\"color\":\"黑色\",\"brand\":\"大众\",\"model\":\"大众辉腾\",\"sold_date\":\"2021-08-19\",\"remark\":\"大众最让人肝疼的车\"&#125;&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":218000,\"color\":\"红色\",\"brand\":\"奥迪\",\"model\":\"奥迪A4\",\"sold_date\":\"2021-11-05\",\"remark\":\"小资车型\"&#125;&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":489000,\"color\":\"黑色\",\"brand\":\"奥迪\",\"model\":\"奥迪A6\",\"sold_date\":\"2022-01-01\",\"remark\":\"政府专用？\"&#125;&#123;\"index\":&#123;&#125;&#125;&#123;\"price\":1899000,\"color\":\"黑色\",\"brand\":\"奥迪\",\"model\":\"奥迪A 8\",\"sold_date\":\"2022-02-12\",\"remark\":\"很贵的大A6。。。\"&#125; 根据color分组统计销售数量，只执行聚合分组，ES中最基础的聚合为terms，相当于SQL中的count，ES中默认为分组数据做排序，使用的是doc_count数据执行降序排列。可使用_key元数据根据分组后的字段数据执行不同的排序方案，也可根据_count元数据，根据分组后的统计值执行不同的排序方案。 1234567891011GET /cars/_search&#123; \"aggs\": &#123; \"group_by_color\": &#123; \"terms\": &#123; \"field\": \"color\", \"order\": &#123;\"_count\": \"desc\"&#125; &#125; &#125; &#125;&#125; 先根据color执行聚合分组，在此分组的基础上，对组内数据执行聚合统计，组内数据的聚合统计就是metric，同样可执行排序，因为组内有聚合统计，且对统计数据给予了命名avg_by_price，所以可根据该聚合统计数据字段名执行排序逻辑。size可设置为0，表示不返回文档只返回聚合之后的数据，提高查询速度，若需要这些文档也可按照实际情况进行设置。对聚合统计数据进行排序，若有多层aggs执行下钻聚合时也可根据最内层聚合数据执行排序。 1234567891011121314151617181920212223242526272829GET /cars/_search&#123; \"aggs\": &#123; \"group_by_color\": &#123; \"terms\": &#123; \"field\": \"color\", \"order\": &#123;\"avg_by_price\": \"asc\"&#125; &#125;, \"aggs\": &#123; \"avg_by_price\": &#123;\"avg\": &#123;\"field\": \"price\"&#125;&#125; &#125; &#125; &#125;&#125;GET /cars/_search&#123; \"size\": 0, \"aggs\": &#123; \"group_by_color\": &#123; \"terms\": &#123;\"field\": \"color\"&#125;, \"aggs\": &#123; \"group_by_brand\": &#123; \"terms\": &#123;\"field\": \"brand\",\"order\": &#123;\"avg_by_price\": \"desc\"&#125;&#125;, \"aggs\": &#123;\"avg_by_price\": &#123;\"avg\": &#123;\"field\": \"price\"&#125;&#125;&#125; &#125; &#125; &#125; &#125;&#125; 先根据color聚合分组，在组内根据brand再次聚合分组，这种操作可称为下钻分析，aggs若定义比较多，则会感觉语法格式混乱，aggs语法格式有一个相对固定的结构，aggs可嵌套定义也可水平定义。嵌套定义称为下钻分析，水平定义就是平铺多个分组方式。 123456789101112131415GET /index_name/type_name/_search&#123; \"aggs\": &#123; \"定义分组名称\": &#123; \"分组策略如：terms、avg、sum\": &#123; \"field\": \"根据哪一个字段分组\", \"其他参数\": \"\" &#125;, \"aggs\": &#123; \"分组名称1\": &#123;&#125;, \"分组名称2\": &#123;&#125; &#125; &#125; &#125;&#125; 统计不同color中的最大和最小价格、总价，聚合分析最常用的种类就是统计数量，最大，最小，平均，总计等 12345678910111213141516171819202122232425262728293031GET /cars/_search&#123; \"aggs\": &#123; \"group_by_color\": &#123; \"terms\": &#123;\"field\": \"color\"&#125;, \"aggs\": &#123; \"max_price\": &#123;\"max\": &#123;\"field\": \"price\"&#125;&#125;, \"min_price\": &#123;\"min\": &#123;\"field\": \"price\"&#125;&#125;, \"sum_price\": &#123;\"sum\": &#123;\"field\": \"price\"&#125;&#125; &#125; &#125; &#125;&#125;GET cars/_search // 统计不同品牌汽车中价格排名最高的车型&#123; \"size\": 0, \"aggs\": &#123; \"group_by_brand\": &#123; \"terms\": &#123;\"field\": \"brand\"&#125;, \"aggs\": &#123; \"top_car\": &#123; \"top_hits\": &#123; \"size\": 1, // 取组内多少条数据，默认为10 \"sort\": [&#123;\"price\": &#123;\"order\": \"desc\"&#125;&#125;], // 组内使用什么字段什么规则排序，默认使用_doc的asc规则排序 \"_source\": &#123;\"includes\": [\"model\",\"price\"]&#125; // 结果中包含document中的哪些字段，默认包含全部字段 &#125; &#125; &#125; &#125; &#125;&#125; histogram区间统计类似terms，也是用于bucket分组操作，是根据一个field实现数据区间分组。如以100万为一个范围，统计不同范围内车辆销售量和平均价格。使用histogram聚合时field指定价格字段price，区间范围是100万，此时ES会将price价格区间划分为： [0, 1000000), [1000000, 2000000), [2000000, 3000000)等依次类推。在划分区间同时histogram会类似terms进行数据数量统计，可通过嵌套aggs对聚合分组后的组内数据做再次聚合分析。 123456789101112GET /cars/_search&#123; \"aggs\": &#123; \"histogram_by_price\": &#123; \"histogram\": &#123; \"field\": \"price\", \"interval\": 1000000 &#125;, \"aggs\": &#123;\"avg_by_price\": &#123;\"avg\": &#123;\"field\": \"price\"&#125;&#125;&#125; &#125; &#125;&#125; date_histogram区间分组可对date类型的field执行区间聚合分组，若以月为单位，统计不同月份汽车销售数量及销售总金额。此时可使用date_histogram实现聚合分组，其中field来指定用于聚合分组的字段，interval指定区间范围，可选值有year、quarter、month、week、day、hour、minute、second，format指定日期格式化，min_doc_count指定每个区间最少document，若不指定默认为0，当区间范围内没有document时，也会显示bucket分组，extended_bounds指定起始时间和结束时间，若不指定默认使用字段中日期最小值和最大值作为起始和结束时间。 123456789101112131415GET /cars/_search&#123; \"aggs\": &#123; \"histogram_by_date\": &#123; \"date_histogram\": &#123; \"field\": \"sold_date\", \"interval\": \"month\", // 7.X之后使用calendar_interval，指定区间范围 \"format\": \"yyyy-MM-dd\", // 指定日期格式化 \"min_doc_count\": 1, \"extended_bounds\": &#123;\"min\": \"2021-01-01\",\"max\": \"2022-12-31\"&#125; &#125;, \"aggs\": &#123;\"sum_by_price\": &#123;\"sum\": &#123;\"field\": \"price\"&#125;&#125;&#125; &#125; &#125;&#125; 聚合统计数据时，有时需要对比部分数据和总体数据，如统计某品牌车辆平均价格和所有车辆平均价格。global是用于定义一个全局bucket，该bucket会忽略query的条件，检索所有document进行对应的聚合统计。 123456789101112GET /cars/_search&#123; \"size\": 0, \"query\": &#123;\"match\": &#123;\"brand\": \"大众\"&#125;&#125;, \"aggs\": &#123; \"volkswagen_of_avg_price\": &#123;\"avg\": &#123;\"field\": \"price\"&#125;&#125;, // 统计某品牌车辆平均价格 \"all_avg_price\": &#123; // 所有车辆平均价格 \"global\": &#123;&#125;, \"aggs\": &#123;\"all_of_price\": &#123;\"avg\": &#123;\"field\": \"price\"&#125;&#125;&#125; &#125; &#125;&#125; filter也可和aggs组合使用，实现相对复杂的过滤聚合分析，filter的范围决定了其过滤的范围，将filter放在aggs内部，代表该过滤器只对query搜索得到的结果执行filter过滤。若filter放在aggs外部，过滤器则会过滤所有数据。 12345678910111213141516171819GET /cars/_search // filter和aggs组合使用，实现相对复杂的过滤聚合分析&#123; \"query\": &#123; \"constant_score\": &#123; \"filter\": &#123;\"range\": &#123;\"price\": &#123;\"gte\": 100000,\"lte\": 500000&#125;&#125;&#125; &#125; &#125;, \"aggs\": &#123;\"avg_by_price\": &#123;\"avg\": &#123;\"field\": \"price\"&#125;&#125;&#125;&#125;GET /cars/_search&#123; \"query\": &#123;\"match\": &#123;\"brand\": \"大众\"&#125;&#125;, \"aggs\": &#123; \"count_last_year\": &#123; // 12M/M表示12个月，1y/y表示1年，d表示天 \"filter\": &#123;\"range\": &#123;\"sold_date\": &#123;\"gte\": \"now-12M\"&#125;&#125;&#125;, \"aggs\": &#123;\"sum_of_price_last_year\": &#123;\"sum\": &#123;\"field\": \"price\"&#125;&#125;&#125; &#125; &#125;&#125; 数据建模如下设计一个用户document数据类型，其中包含一个地址数据的数组，该设计方式相对复杂，但在管理数据时更加的灵活。但也有明显的缺陷，针对地址数据做数据搜索时，经常会搜索出不必要的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445PUT /user_index&#123; \"mappings\": &#123; \"properties\": &#123; \"login_name\": &#123;\"type\": \"keyword\"&#125;, \"age \": &#123;\"type\": \"short\"&#125;, \"address\": &#123; \"properties\": &#123; \"province\": &#123;\"type\": \"keyword\"&#125;, \"city\": &#123;\"type\": \"keyword\"&#125;, \"street\": &#123;\"type\": \"keyword\"&#125; &#125; &#125; &#125; &#125;&#125;PUT /user_index/_doc/1&#123; \"login_name\": \"jack\", \"age\": 25, \"address\": [ &#123;\"province\": \"北京\",\"city\": \"北京\",\"street\": \"枫林三路\"&#125;, &#123;\"province\": \"天津\",\"city\": \"天津\",\"street\": \"华夏路\"&#125; ]&#125;PUT /user_index/_doc/2&#123; \"login_name\": \"rose\", \"age\": 21, \"address\": [ &#123;\"province\": \"河北\",\"city\": \"廊坊\",\"street\": \"燕郊经济开发区\"&#125;, &#123;\"province\": \"天津\",\"city\": \"天津\",\"street\": \"华夏路\"&#125; ]&#125;GET /user_index/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123;\"match\": &#123;\"address.province\": \"北京\"&#125;&#125;, &#123;\"match\": &#123;\"address.city\": \"天津\"&#125;&#125; ] &#125; &#125;&#125; 可使用nested object作为地址数组的集体类型可解决上述问题，且搜索时需要使用nested对应的搜索语法 123456789101112131415161718192021222324252627282930PUT /user_index&#123; \"mappings\": &#123; \"properties\": &#123; \"login_name\": &#123;\"type\": \"keyword\"&#125;, \"age \": &#123;\"type\": \"short\"&#125;, \"address\": &#123; \"type\": \"nested\", \"properties\": &#123; \"province\": &#123;\"type\": \"keyword\"&#125;, \"city\": &#123;\"type\": \"keyword\"&#125;, \"street\": &#123;\"type\": \"keyword\"&#125; &#125; &#125; &#125; &#125;&#125;GET /user_index/_search&#123; \"query\": &#123;\"bool\": &#123;\"must\": [ &#123;\"nested\": &#123;\"path\": \"address\", \"query\": &#123; \"bool\": &#123;\"must\": [ &#123;\"match\": &#123;\"address.province\": \"北京\"&#125;&#125;, &#123;\"match\": &#123;\"address.city\": \"北京\"&#125;&#125; ]&#125; &#125;&#125; &#125;] &#125;&#125;&#125; 普通数组数据在ES中会被扁平化处理，nested object数据类型ES在保存时不会扁平化处理 1234567891011121314151617181920&#123; // 普通数组 \"login_name\" : \"jack\", \"address.province\" : [ \"北京\", \"天津\" ], \"address.city\" : [ \"北京\", \"天津\" ] \"address.street\" : [ \"枫林三路\", \"华夏路\" ]&#125;// nested数据&#123; \"login_name\" : \"jack\"&#125;&#123; \"address.province\" : \"北京\", \"address.city\" : \"北京\"， \"address.street\" : \"枫林三路\"&#125;&#123; \"address.province\" : \"天津\", \"address.city\" : \"天津\", \"address.street\" : \"华夏路\",&#125; nested object建模缺点是采取的是类似冗余数据的方式，将多个数据放在一起，维护成本比较高，每次更新需要重新索引整个对象，包括根对象和嵌套对象。ES提供类似关系型数据库中Join的实现，使用Join数据类型实现父子关系，从而分离两个文档对象。 更新父文档无需重新索引整个子文档，子文档被新增，更改和删除也不会影响到父文档和其他子文档，父子关系元数据映射，用于确保查询时高性能，但是有一个限制父子数据包括映射其关联关系的元数据必须存在于一个shard中 ，搜索父子关系数据时，不用跨分片性能高。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495PUT my_blogs&#123; \"mappings\": &#123; \"properties\": &#123; \"blog_comments_relation\": &#123; \"type\": \"join\", // 指明join类型 \"relations\": &#123; // 声明父子关系 \"blog\": \"comment\" // blog为父文档名称，comment为子文档名称 &#125; &#125;, \"content\": &#123;\"type\": \"text\"&#125;, \"title\": &#123;\"type\": \"keyword\"&#125; &#125; &#125;&#125;PUT my_blogs/_doc/blog1 // blog1为父文档id&#123; \"title\": \"Learning Elasticsearch\", \"content\": \"learning ELK is happy\", \"blog_comments_relation\": &#123; // 声明文档类型 \"name\": \"blog\" &#125;&#125;PUT my_blogs/_doc/blog2 // blog2为父文档id&#123; \"title\": \"Learning Hadoop\", \"content\": \"learning Hadoop\", \"blog_comments_relation\": &#123; // 声明文档类型 \"name\": \"blog\" &#125;&#125;// 父文档和子文档必须存在相同的分片上, 当指定文档时候，必须指定它的父文档IDPUT my_blogs/_doc/comment1?routing=blog1 // 使用route参数来保证，分配到相同分片&#123; \"comment\": \"I am learning ELK\", \"username\": \"Jack\", \"blog_comments_relation\": &#123; \"name\": \"comment\", \"parent\": \"blog1\" &#125;&#125;PUT my_blogs/_doc/comment2?routing=blog2 // comment2为子文档id，blog2为父文档id&#123; \"comment\": \"I like Hadoop!!!!!\", \"username\": \"Jack\", \"blog_comments_relation\": &#123; \"name\": \"comment\", \"parent\": \"blog2\" &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2&#123; \"comment\": \"Hello Hadoop\", \"username\": \"Bob\", \"blog_comments_relation\": &#123; \"name\": \"comment\", \"parent\": \"blog2\" &#125;&#125;POST my_blogs/_search // 查询所有文档&#123;&#125;GET my_blogs/_doc/blog2 // 根据父文档ID查看POST my_blogs/_search // parent_id查询，返回所有相关子文档&#123; \"query\": &#123; \"parent_id\": &#123;\"type\": \"comment\",\"id\": \"blog2\"&#125; &#125;&#125;POST my_blogs/_search // has_child查询，返回父文档&#123; \"query\": &#123; \"has_child\": &#123; \"type\": \"comment\", \"query\": &#123;\"match\": &#123;\"username\": \"Jack\"&#125;&#125; &#125; &#125;&#125;POST my_blogs/_search // has_parent查询，返回相关的子文档&#123; \"query\": &#123; \"has_parent\": &#123; \"parent_type\": \"blog\", \"query\": &#123;\"match\": &#123;\"title\": \"Learning Hadoop\"&#125;&#125; &#125; &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2 //更新子文档不会影响到父文档&#123; \"comment\": \"Hello Hadoop??\", \"blog_comments_relation\": &#123; \"name\": \"comment\", \"parent\": \"blog2\" &#125;&#125; 文件系统数据若需要使用文件路径搜索内容，只需要为其中的字段定义一个特殊的path_hierarchy分词器 123456789101112131415161718192021222324252627282930313233343536373839404142PUT /codes&#123; \"settings\": &#123;\"analysis\": &#123;\"analyzer\": &#123;\"path_analyzer\": &#123;\"tokenizer\": \"path_hierarchy\"&#125;&#125;&#125;&#125;, \"mappings\": &#123; \"properties\": &#123; \"fileName\": &#123;\"type\": \"keyword\"&#125;, \"path\": &#123; \"type\": \"text\", \"analyzer\": \"path_analyzer\", \"fields\": &#123;\"keyword\": &#123;\"type\": \"text\",\"analyzer\": \"standard\"&#125;&#125; &#125;, \"content\": &#123;\"type\": \"text\",\"analyzer\": \"standard\"&#125; &#125; &#125;&#125;PUT /codes/_doc/1&#123; \"fileName\": \"HelloWorld.java\", \"path\": \"/com/eleven/first\", \"content\": \"package com.eleven.first; public class HelloWorld &#123; // some code... &#125;\"&#125;GET /codes/_search&#123; \"query\": &#123;\"match\": &#123;\"path\": \"/com\"&#125;&#125;&#125;GET /codes/_analyze&#123; \"text\": \"/a/b/c/d\", \"field\": \"path\"&#125;GET /codes/_search&#123; \"query\": &#123;\"match\": &#123;\"path.keyword\": \"/com\"&#125;&#125;&#125;GET /codes/_search&#123; \"query\": &#123;\"bool\": &#123;\"should\": [ &#123;\"match\": &#123;\"path\": \"/com\"&#125;&#125;, &#123;\"match\": &#123;\"path.keyword\": \"/com/eleven\"&#125;&#125; ]&#125;&#125;&#125; Scroll分页使用from和size方式查询1W以内的数据都OK，但若数据比较多时会出现性能问题。ES做了一个限制不允许查询1W条以后的数据。若要查询1W条以后的数据，可使用ES中提供的scroll游标来查询。 在进行大量分页时，每次分页都需要将要查询数据进行重新排序，这样非常浪费性能。使用scroll游标是将要用的数据一次性排序好，然后分批取出。性能要比from + size好得多，使用scroll查询后，排序后的数据会保持一定的时间，后续分页查询都从该快照取数据。响应结果中会返回_scroll_id，第二次查询直接使用_scroll_id来查询。 1234567891011121314GET /es_db/_search?scroll=1m // 让排序的数据保持1分钟&#123; \"query\": &#123; \"multi_match\": &#123; \"query\": \"广州长沙张三\", \"fields\": [\"address\",\"name\"] &#125; &#125;, \"size\": 100&#125;GET _search/scroll?scroll=1m&#123; \"scroll_id\": \"FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFnJKUnZmX1pIVGVpM05TWDBQX0JJeXcAAAAAAAaeghZDUkdZN1FJNVIwYUJhYUxvNWVxd1Rn\"&#125; SQL支持ES SQL允许执行类SQL查询，REST接口、命令行或JDBC等都可使用SQL来进行数据检索和数据聚合。特点： 本地集成：ES SQL是专门为ES构建的，每个SQL查询都根据底层存储对相关节点有效执行 无额外要求：不依赖其他硬件、进程、运行时库，可直接运行在ES集群上 轻量且高效：像SQL那样简洁、高效地完成查询 12345678SELECT select_expr [, ...][ FROM table_name ][ WHERE condition ][ GROUP BY grouping_element [, ...] ][ HAVING condition][ ORDER BY expression [ ASC | DESC ] [, ...] ][ LIMIT [ count ] ][ PIVOT ( aggregation_expr FOR column IN ( value [ [ AS ] alias ] [, ...] ) ) ] 目前FROM只支持单表，不支持JOIN、不支持较复杂的子查询，format表示指定返回数据类型，支持的类型有逗号分隔csv、json、制表符分隔符tsv、txt、yaml。 12345678910111213141516GET /_sql?format=json&#123; \"query\": \"SELECT * FROM es_db limit 1\"&#125;GET /_sql/translate // 将SQL转换为DSL&#123; \"query\": \"SELECT * FROM es_db limit 1\"&#125;GET /_sql?format=json // field_exp匹配字段，constant_exp匹配常量表达式，&#123; // 检索address包含广州和name中包含张三的用户 \"query\": \"select * from es_db where MATCH(address, '广州') or MATCH(name, '张三') limit 10\"&#125;GET /_sql?format=txt // 统计分组&#123; \"query\": \"select age, count(*) as age_cnt from es_db group by age\"&#125; 模本搜索模板搜索可将一些搜索进行模板化，每次执行该搜索就直接调用模板，传入一些参数即可。 123456789101112131415161718192021222324252627282930GET /cars/_search/template // 简单定义参数并传递&#123; \"source\": &#123; \"query\": &#123;\"match\": &#123;\"remark\": \"&#123;&#123;kw&#125;&#125;\"&#125;&#125;, \"size\": \"&#123;&#123;size&#125;&#125;\" &#125;, \"params\": &#123;\"kw\": \"大众\",\"size\": 2&#125;&#125;GET cars/_search/template // toJson方式传递参数&#123; \"source\": \"\"\"&#123; \"query\": &#123; \"match\": &#123;&#123;#toJson&#125;&#125;parameter&#123;&#123;/toJson&#125;&#125; &#125;&#125;\"\"\", \"params\": &#123; \"parameter\": &#123;\"remark\": \"大众\"&#125; &#125;&#125;GET cars/_search/template // json方式传递参数&#123; \"source\": &#123;\"query\": &#123;\"match\": &#123; \"remark\": \"&#123;&#123;#join delimiter=' '&#125;&#125;kw&#123;&#123;/join delimiter=' '&#125;&#125;\" &#125;&#125;&#125;, \"params\": &#123;\"kw\": [\"大众\",\"标致\"]&#125;&#125;GET cars/_search/template&#123; \"source\": &#123;\"query\": &#123;\"range\": &#123;\"price\": &#123; \"gte\": \"&#123;&#123;start&#125;&#125;\", \"lte\": \"&#123;&#123;end&#125;&#125;&#123;&#123;^end&#125;&#125;200000&#123;&#123;/end&#125;&#125;\" // 默认值定义 &#125;&#125;&#125;&#125;, \"params\": &#123;\"start\": 100000,\"end\": 140000&#125;&#125; 记录template实现重复调用可使用Mustache语言作为搜索请求预处理，它提供模板通过键值对来替换模板中的变量。把脚本存储在本地磁盘中，默认位置为elasticsearch\\config\\scripts，通过引用脚本名称进行使用 12345678910111213POST _scripts/test // test为脚本id&#123; \"script\": &#123; \"lang\": \"mustache\", // 指定mustache语言 \"source\": &#123;\"query\": &#123;\"match\": &#123;\"remark\": \"&#123;&#123;kw&#125;&#125;\"&#125;&#125;&#125; &#125;&#125;GET cars/_search/template&#123; \"id\": \"test\", // 指定调用脚本的id \"params\": &#123;\"kw\": \"大众\"&#125;&#125;DELETE _scripts/test // 删除脚本id为test的脚本 suggest searchsuggest search(completion suggest)即建议搜索或搜索建议，也可叫做自动完成，类似百度中搜索联想提示功能。ES实现suggest时性能非常高，其构建的不是倒排索引也不是正排索引，是纯粹用于前缀搜索的一种特殊数据结构，且会全部放在内存中，所以suggest search进行前缀搜索提示性能是非常高。需要使用suggest时候，必须在定义index时为其mapping指定开启suggest。 12345678910111213141516171819202122232425262728293031323334PUT /movie&#123; \"mappings\": &#123; \"properties\": &#123;\"title\": &#123;\"type\": \"text\",\"analyzer\": \"ik_max_word\", \"fields\": &#123;\"suggest\": &#123;\"type\": \"completion\",\"analyzer\": \"ik_max_word\"&#125;&#125; &#125;, \"content\": &#123;\"type\": \"text\",\"analyzer\": \"ik_max_word\"&#125; &#125; &#125;&#125;PUT /movie/_doc/1&#123; \"title\": \"西游记电影系列\", \"content\": \"西游记之月光宝盒将与2021年进行......\"&#125;PUT /movie/_doc/2&#123; \"title\": \"西游记文学系列\", \"content\": \"某知名网络小说作家已经完成了大话西游同名小说的出版\"&#125;PUT /movie/_doc/3&#123; \"title\": \"西游记之大话西游手游\", \"content\": \"网易游戏近日出品了大话西游经典IP的手游，正在火爆内测中\"&#125;GET /movie/_search&#123; \"suggest\": &#123; \"my-suggest\": &#123; \"prefix\": \"西游记\", \"completion\": &#123;\"field\": \"title.suggest\"&#125; &#125; &#125;&#125; 地理位置搜索ES支持地理位置搜索和聚合分析，可实现在指定区域内搜索数据、搜索指定地点附近的数据、聚合分析指定地点附近的数据等操作。ES中若使用地理位置搜索，必须提供一个特殊的字段类型geo_point，用于指定地理位置坐标点。 新增一个基于geo_point类型数据，可使用多种方式。多种类型描述geo_point类型字段时，在搜索数据时显示格式和录入格式是统一的。任何数据描述的geo_point类型字段，都适用地理位置搜索。 数据范围要求纬度范围是-90~90之间，经度范围是-180~180之间，经纬度数据都是浮点数或数字串，最大精度为小数点后7位。latitude：纬度、longitude：经度。 123456789101112131415161718192021222324PUT /hotel_app&#123; \"mappings\": &#123; \"properties\": &#123; \"pin\": &#123;\"type\": \"geo_point\"&#125;, \"name\": &#123;\"type\": \"text\",\"analyzer\": \"ik_max_word\"&#125; &#125; &#125;&#125;PUT /hotel_app/_doc/1&#123; \"name\": \"七天连锁酒店\", \"pin\": &#123;\"lat\": 40.12,\"lon\": -71.34&#125;&#125;PUT /hotel_app/_doc/2&#123; \"name\": \"维多利亚大酒店\", \"pin\": \"40.99, -70.81\"&#125;PUT /hotel_app/_doc/3&#123; \"name\": \" 红树林宾馆\", \"pin\": [40,-73.81] // 基于数组：依次定义经度、纬度，不推荐使用&#125; 矩形范围搜索传入top_left和bottom_right坐标点是有固定要求的，top_left即从西北向东南，Bottom_right即从东南向西北，且top_left纬度应大于bottom_right，top_left经度应小于bottom_right。多边形范围搜索对传入若干点坐标顺序没有任何要求，只要传入若干地理位置坐标点，即可形成多边形。 12345678910111213141516171819202122232425GET /hotel_app/_doc/_search // 矩形搜索&#123; \"query\": &#123; \"geo_bounding_box\": &#123; \"pin\": &#123; \"top_left\": &#123;\"lat\": 41.73,\"lon\": -74.1&#125;, \"bottom_right\": &#123;\"lat\": 40.01,\"lon\": -70.12&#125; &#125; &#125; &#125;&#125;GET /hotel_app/_doc/_search // 多边形搜索&#123; \"query\": &#123; \"geo_polygon\": &#123; \"pin\": &#123; \"points\": [ &#123;\"lat\": 40.73,\"lon\": -74.1&#125;, &#123;\"lat\": 40.01,\"lon\": -71.12&#125;, &#123;\"lat\": 50.56,\"lon\": -90.58&#125; ] &#125; &#125; &#125;&#125; Distance距离的单位，常用米m和千米km，建议使用filter来过滤geo_point数据，因为geo_point数据相关度评分计算比较耗时。使用query来搜索geo_point数据效率相对会慢一些。 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; \"query\": &#123; \"bool\": &#123; \"filter\": &#123; \"geo_distance\": &#123;\"distance\": \"200km\",\"pin\": &#123;\"lat\": 40,\"lon\": -70&#125;&#125; &#125; &#125; &#125;&#125;GET hotel_app/_search&#123; \"query\": &#123; \"geo_distance\": &#123; \"distance\": \"90km\", \"pin\": &#123;\"lat\": 40.55,\"lon\": -71.12&#125; &#125; &#125;&#125; 聚合统计某位置附近区域内的数据，unit是距离单位，常用单位有米m，千米km，英里mi，distance_type是统计算法：sloppy_arc默认算法、arc最高精度、plane最高效率 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; \"size\": 0, \"aggs\": &#123; \"agg_by_pin\": &#123; \"geo_distance\": &#123; \"distance_type\": \"arc\", \"field\": \"pin\", \"origin\": &#123;\"lat\": 40,\"lon\": -70&#125;, \"unit\": \"mi\", \"ranges\": [ // 聚合统计分别距离某位置80英里，300英里，1000英里范围内的数据数量 &#123;\"to\": 80&#125;, &#123;\"from\": 80,\"to\": 300&#125;, &#123;\"from\": 300,\"to\": 1000&#125; ] &#125; &#125; &#125;&#125;","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://yaoyinglong.github.io/tags/ElasticSearch/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"ELK","slug":"Cloud/ELK","permalink":"https://yaoyinglong.github.io/categories/Cloud/ELK/"}]},{"title":"ElasticSearch基础","date":"2021-12-21T16:00:00.000Z","path":"Blog/Cloud/ELK/ElasticSearch基础/","text":"Elasticsearch是用Java开发的当前最流行的开源的企业级搜索引擎，能够达到实时搜索，稳定，可靠，快速，安装使用方便。Elasticsearch是基于Lucene的，Lucene可被认为是迄今为止最先进、性能最好、功能最全的搜索引擎框架。 Lucene是一个全文检索框架，通过程序扫描文本中每个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现次数。用户查询时通过之前建立好的索引来查询，将索引中单词对应文本位置、出现次数返给用户，有了具体文本位置，则可将具体内容读取出来。 Lucene基于倒排索引，对于使用的数据库主键索引是通过主键定位到某条数据，而倒排索引刚好相反，是通过数据对应到主键。 但想要使用Lucene，必须使用Java来作为开发语言并将其直接集成到应用中，且Lucene配置及使用非常复杂，需要深入了解检索相关知识来理解其工作原理。 只能在Java项目中使用，且要以jar包方式直接集成项目中 使用非常复杂，创建索引和搜索索引代码繁杂 不支持集群环境，索引数据不同步，不支持大型项目 索引数据不能太多，索引库和应用所在同一个服务器，共同占用硬盘，共用空间少 ES与Solr对比单纯对已有数据进行搜索时Solr更快，当实时建立索引时Solr会产生IO阻塞，查询性能较差，该情况下Elasticsearch具有明显优势。 Solr利用Zookeeper进行分布式管理，而Elasticsearch自带分布式协调管理功能 Solr支持更多格式数据，如JSON、XML、CSV，而Elasticsearch仅支持JSON文件格式 Solr在传统搜索应用中表现好于Elasticsearch，但在处理实时搜索应用时效率明显低于Elasticsearch Solr是传统搜索应用的有力解决方案，但Elasticsearch更适用于新兴实时搜索应用。 ES与关系型数据库 关系型数据库 Database数据库 Table表 ROW行 Column列 Elasticsearch Index索引库 Type类型 Document文档 Field字段 ES核心概念索引index一个索引就是一个拥有几分相似特征的文档集合，相当于关系型数据库中的database，一个索引由一个名字来标识，必须全部是小写字母，且当要对对应于该索引中的文档进行索引搜索、更新和删除时，都要使用该名字。 Mapping映射ElasticSearch中的Mapping映射用来定义一个文档，Mapping是处理数据的方式和规则方面做一些限制，如某个字段的数据类型、默认值、分词器、是否被索引等，这都是映射里面可设置的。 Field字段相当于是数据表的字段或列 Type字段类型每个字段都应该有一个对应的类型，如Text、Keyword、Byte等 Document文档一个文档是一个可被索引的基础信息单元，类似一条记录，文档以JSON格式来表示 Cluster集群一个集群由一个或多个节点组织在一起，共同持有整个数据，并一起提供索引和搜索功能 Node节点一个节点即集群中一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能，一个节点可通过配置集群名称的方式来加入一个指定的集群。默认每个节点都会被安排加入到一个叫做elasticsearch的集群中。 一个集群中可拥有任意多个节点，且若当前网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做elasticsearch的集群。 分片一个索引可存储超出单个结点硬件限制的大量数据，如一个具有10亿文档的索引占据1TB磁盘空间，而任一节点都没有这样大的磁盘空间，或者单个节点处理搜索请求，响应太慢，为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，每一份就是一个分片。 当创建索引时可指定分片数量，每个分片本身也是一个功能完善且独立的索引，该分片可被放置到集群中任何节点上，分片允许水平分割扩展内容容量，允许在分片之上进行分布式并行操作，进而提高性能和吞吐量，每个分片怎样分布，文档怎样聚合回搜索请求，完全由Elasticsearch管理，对于用户透明。 副本在一个网络环境中，失败随时都可能发生，在某个分片或节点处于离线状态，或由于任何原因消失，该情况下有一个故障转移机制是非常有用且强烈推荐。为此Elasticsearch允许创建分片的一份或多份拷贝，这些拷贝叫做副本分片或直接叫副本。 扩展搜索量和吞吐量，搜索可在所有的副本上并行运行，每个索引可被分成多个分片，一个索引有零个或者多个副本， 一旦设置了副本，每个索引就有了主分片和副本分片，分片和副本数量可在索引创建时指定，在索引创建后，可在任何时候动态地改变副本数量，但不能改变分片数量。 ES安装ES不能使用root用户来启动，必须使用普通用户来安装启动 12345678910groupadd elasticsearch # 创建elasticsearch用户组useradd eleven # 创建eleven用户passwd eleven # 给eleven用户设置密码为elevenusermod -G elasticsearch eleven # 将用户eleven添加到elasticsearch用户组mkdir -p /usr/local/es # 创建es文件夹chown -R eleven /usr/local/es/elasticsearch-7.6.1 # 修改owner为eleven用户visudo # 使用root用户执行visudo命令然后为es用户添加权限eleven ALL=(ALL) ALL # 在root ALL=(ALL) ALL 一行下面添加eleven用户 修改elasticsearch.yml，可通过修改jvm.options配置文件调整JVM参数。 123456789101112cluster.name: eleven-es # 集群名称node.name: node1 # 节点名称path.data: /usr/local/es/elasticsearch-7.6.1/data # 数据目录path.logs: /usr/local/es/elasticsearch-7.6.1/log # 日志目录network.host: 0.0.0.0http.port: 9200discovery.seed_hosts: [\"IP1\", \"IP2\", \"IP3\"]cluster.initial_master_nodes: [\"节点1名称\", \"节点2名称\", \"节点3名称\"]bootstrap.system_call_filter: falsebootstrap.memory_lock: falsehttp.cors.enabled: truehttp.cors.allow-origin: \"*\" ES需要大量创建索引文件，需要大量打开系统文件，所以需要解除linux系统当中打开文件最大数目限制，不然ES启动会抛错：max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536] 12345sudo vim /etc/security/limits.conf* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 若出现max number of threads [1024] for user [es] likely too low, increase to at least [4096]错误信息，是由于普通用户启动线程数限制最大可创建线程数太小，无法创建本地线程问题。 安装IK分词器使用Elasticsearch来进行中文分词，需要单独给Elasticsearch安装IK分词器插件， 123mkdir -p /usr/local/es/elasticsearch-7.6.1/plugins/ikcd /usr/local/es/elasticsearch-7.6.1/plugins/ikunzip elasticsearch-analysis-ik-7.6.1.zip ES的默认分词设置是standard单字拆分，可使用IK分词器的ik_smart和ik_max_word分词方式，ik_smart会做最粗粒度拆分，ik_max_word会将文本做最细粒度拆分。修改默认分词方法，修改eleven_index索引的默认分词为ik_max_word 1234567891011121314151617181920212223PUT /school_index&#123; \"settings\": &#123; \"index\": &#123; \"analysis.analyzer.default.type\": \"ik_max_word\" &#125; &#125;&#125;POST _analyze&#123; \"analyzer\": \"standard\", \"text\": \"中华人民共和国\"&#125;POST _analyze&#123; \"analyzer\": \"ik_smart\", \"text\": \"中华人民共和国\"&#125;POST _analyze&#123; \"analyzer\": \"ik_max_word\", \"text\": \"中华人民共和国\"&#125; ES基础ES是面向文档Document的，使用JSON作为文档序列化格式，这其可存储整个对象或文档Document，不仅仅是存储，还会索引index每个文档内容使之可被搜索。ES中可对文档而非成行成列的数据进行索引、搜索、排序、过滤。 条件查询：GET /索引名称/类型/_search?q=字段1:字段值，字段2:字段值，条件之间是通过逗号分隔多个条件，如分页、排序、输出指定字段等通过&amp;符号分隔。 123456789101112131415161718192021222324252627GET _cat/nodes?v // 查看集群节点状态GET _cat/health?v // 查看集群健康状态GET /es_db // 查询索引：GET /索引名称PUT /es_db // 创建索引：PUT /索引名称DELETE /es_db // 删除索引：DELETE /索引名称PUT /es_db/_doc/1 // 添加文档：PUT /索引名称/类型/id&#123; \"name\": \"张三\", \"sex\": 1, \"age\": 25, \"address\": \"广州天河公园\", \"remark\": \"java developer\"&#125;GET /es_db/_doc/1 // 查询文档：GET /索引名称/类型/idDELETE /es_db/_doc/1 // 删除文档：DELETE /索引名称/类型/idGET /es_db/_doc/_search // 查询当前类型中的所有文档：GET /索引名称/类型/_searchGET /es_db/_doc/_search?q=age:28 // 条件查询：GET /索引名称/类型/_search?q=*:***GET /es_db/_doc/_search?q=age[25 TO 26] // 范围查询：GET /索引名称/类型/_search?q=***[** TO **]GET /es_db/_doc/_mget // 根据多个ID进行批量查询：GET /索引名称/类型/_mget&#123;\"ids\":[\"1\",\"2\"]&#125;GET /es_db/_doc/_search?q=age:&lt;=28 // 查询小于等于：GET /索引名称/类型/_search?q=age:&lt;=**GET /es_db/_doc/_search?q=age:&gt;=28 // 查询大于等于：GET /索引名称/类型/_search?q=age:&gt;=**GET /es_db/_doc/_search?q=age[25 TO 26]&amp;from=0&amp;size=1 // 分页查询：from=*&amp;size=*GET /es_db/_doc/_search?_source=name,age // 对查询结果只输出某些字段：_search?_source=字段,字段GET /es_db/_doc/_search?q=age[25 TO 26],sex:0 // 多条件查询GET /es_db/_doc/_search?sort=age:desc // 对查询结果排序sort=字段:desc/asc ES是基于Restful API和所有客户端交互都是使用JSON格式数据，其他所有程序语言都可使用RESTful API，通过9200端口的与ES进行通信，GET查询、PUT添加、POST修改、DELETE删除，POST和PUT都能起到创建/更新的作用： PUT需要对一个具体的资源进行操作，也就是要确定id才能进行更新/创建，而POST可针对整个资源集合进行操作，若不写id则由ES生成一个唯一id进行创建新文档，过填了id则针对该id文档进行创建/更新 PUT会将JSON数据都进行替换，POST只会更新相同字段的值 PUT与DELETE都是幂等性操作，不论操作多少次结果都一样 文档批量操作通过_mget的API来实现批量操作多个文档，可通过_id批量获取不同index和type的数据，若查询的是同一个文档可将index和type放到URL上。且可通过_source指定查询字段。 1234567891011121314151617181920212223242526GET _mget&#123; \"docs\": [ &#123; \"_index\": \"es_db_1\", \"_type\": \"_doc\", \"_id\": 1, &#125;, &#123; \"_index\": \"es_db\", \"_type\": \"_doc\", \"_id\": 2 &#125; ]&#125;GET /es_db/_doc/_mget?_source=age,name&#123; \"docs\": [ &#123; \"_id\": 1 &#125;, &#123; \"_id\": 2 &#125; ]&#125; 批量对文档进行写操作是通过_bulk的API来实现的，通过_bulk写操作文档，一般至少有两行参数，第一行参数为指定操作的类型及操作的对象如index、type、id，第二行参数为操作的数据。actionName表示操作类型，主要有create、index、delete、update。 1234567891011&#123; \"actionName\": &#123; \"_index\": \"indexName\", \"_type\": \"typeName\", \"_id\": \"id\" &#125;&#125;&#123; \"field1\": \"value1\", \"field2\": \"value2\"&#125; 123456789101112131415161718192021POST _bulk // 批量创建文档&#123;\"create\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":3&#125;&#125;&#123;\"id\":3,\"title\":\"eleven 1\",\"content\":\"eleven 666\",\"tags\":[\"java\",\"面向对象\"],\"create_time\":1554015482530&#125;&#123;\"create\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":4&#125;&#125;&#123;\"id\":4,\"title\":\"eleven 2\",\"content\":\"eleven NB\",\"tags\":[\"java\",\"面向对象\"],\"create_time\":1554015482530&#125;POST _bulk // 普通创建或全量替换index，若原文档不存在则创建，若存在则替换&#123;\"index\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":3&#125;&#125;&#123;\"id\":3,\"title\":\"eleven 3\",\"content\":\"eleven3 666\",\"tags\":[\"java\",\"面向对象\"],\"create_time\":1554015482530&#125;&#123;\"index\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":4&#125;&#125;&#123;\"id\":4,\"title\":\"eleven 4\",\"content\":\"eleven4 NB\",\"tags\":[\"java\",\"面向对象\"],\"create_time\":1554015482530&#125;POST _bulk // 批量修改update&#123;\"update\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":3&#125;&#125;&#123;\"doc\":&#123;\"title\":\"ES大法必修内功\"&#125;&#125;&#123;\"update\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":4&#125;&#125;&#123;\"doc\":&#123;\"create_time\":1554018421008&#125;&#125;POST _bulk // 批量删除delete&#123;\"delete\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":3&#125;&#125;&#123;\"delete\":&#123;\"_index\":\"article\",\"_type\":\"_doc\",\"_id\":4&#125;&#125; 乐观并发控制在数据库领域中，有悲观并发控制和乐观并发控制两种方法来确保并发更新不丢失数据，悲观并发控制被关系型数据库广泛使用，阻塞访问资源以防止冲突；ES使用乐观并发控制，若源数据在读写当中被修改，更新将会失败。 12345678PUT /db_index/_doc/1?if_seq_no=1&amp;if_primary_term=1&#123; \"name\": \"Jack\", \"sex\": 1, \"age\": 25, \"book\": \"Spring Boot 入门到精通2\", \"remark\": \"hello world2\"&#125; ES老版本是使用version字段来乐观并发控制，新版本7.x使用if_seq_no=文档版本号&amp;if_primary_term=文档位置来乐观并发控制。每当Primary Shard发生重新分配时如重启、Primary选举等，_primary_term会递增1，_primary_term主要是用来恢复数据时处理当多个文档的_seq_no一样时的冲突。如当一个shard宕机了，raplica需要用到最新的数据，就会根据_primary_term和_seq_no两个值来拿到最新的document。 文档映射ES中映射可以分为动态映射和静态映射，在关系数据库中，需要事先在数据库下创建数据表，并创建表字段、类型、长度、主键等，最后才能基于表插入数据。而Elasticsearch中不需要定义Mapping映射，在文档写入ES时，会根据文档字段自动识别类型，该机制为动态映射；也可事先定义好映射，包含文档的各字段类型、分词器等，该方式为静态映射。 字符串：string类型包含text和keyword text：该类型被用来索引长文本，创建索引前会将文本进行分词，转化为词的组合，建立索引；允许es来检索这些词，不能用来排序和聚合 keyword：该类型不能分词，可被用来检索过滤、排序和聚合，不可用text进行分词模糊检索 数值型：long、integer、short、byte、double、float 日期型：date 布尔型：boolean 123456789101112131415161718192021222324252627282930313233343536GET /es_db/_mapping // 获取文档映射 PUT /es_db2 // 创建索引且设置文档映射&#123; \"mappings\": &#123; \"properties\": &#123; \"name\": &#123; \"type\": \"keyword\", \"index\": true, \"store\": true &#125;, \"sex\": &#123; \"type\": \"integer\", \"index\": true, \"store\": true &#125;, \"age\": &#123; \"type\": \"integer\", \"index\": true, \"store\": true &#125;, \"book\": &#123; \"type\": \"text\", \"index\": true, \"store\": true, \"analyzer\": \"ik_smart\", // 指定text类型的ik分词器 \"search_analyzer\": \"ik_smart\" // 指定text类型的ik分词器 &#125;, \"address\": &#123; \"type\": \"text\", \"index\": true, \"store\": true &#125; &#125; &#125;&#125; 若要推倒现有的映射，得重新建立一个静态索引，然后把之前索引里的数据导入到新的索引里，删除原创建的索引，为新索引起个别名，为原索引名。 1234567891011POST _reindex // 把之前索引里的数据导入到新的索引里&#123; \"source\": &#123; \"index\": \"db_index\" &#125;, \"dest\": &#123; \"index\": \"db_index_2\" &#125;&#125;DELETE /db_index // 删除原创建的索引PUT /db_index_2/_alias/db_index // 为新索引起个别名, 为原索引名 3）删除原创建的索引 4）为新索引起个别名, 为原索引名 DSL高级查询Domain Specific Language领域专用语言，由叶子查询子句和复合查询子句两种子句组成。DSL查询语言又分为查询DSL和过滤DSL。ES中索引的数据都会存储一个_score分值，分值越高就代表越匹配，查询上下文中不仅要判断查询条件与文档是否匹配，且还要关心相关度即_score分值，需要根据分值排序；过滤器上下文中值关心查询条件与文档是否匹配，不计算_score分值，不关心排序问题，经常使用过滤器，ES会自动缓存过滤器内容。 12GET /es_db/_doc/_search // 无查询条件是查询所有，默认查询所有，或使用match_all表示所有&#123;\"query\":&#123;\"match_all\":&#123;&#125;&#125;&#125; 叶子查询模糊匹配模糊匹配主要是针对文本类型的字段，文本类型的字段会对内容进行分词，查询时也会对搜索条件进行分词，然后通过倒排索引查找到匹配数据，模糊匹配主要通过match等参数来实现 match：通过match关键词模糊匹配条件内容，需指定字段名，会进行分词 query：指定匹配的值 operator：匹配条件类型 and：条件分词后都要匹配 or：条件分词后有一个匹配即可，默认为or minmum_should_match：指定最小匹配数量 query_string：和match类似，可不指定字段即所有字段中搜索，范围更广泛 match_phase：会对输入做分词，但结果中也包含所有分词，且顺序一样 prefix：前缀匹配 regexp：通过正则表达式来匹配数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566POST /es_db/_doc/_search&#123; \"from\": 0, \"size\": 2, \"query\": &#123; \"match\": &#123; // match会根据该字段的分词器，进行分词查询 \"address\": \"广州\" &#125; &#125;&#125;POST /es_db/_doc/_search&#123; \"query\": &#123; \"multi_match\": &#123; // 多字段模糊匹配查询 \"query\": \"长沙\", \"fields\": [\"address\", \"name\"] // address或name字段中匹配到“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; \"query\": &#123; \"query_string\": &#123; // 未指定字段条件查询query_string, 含AND与OR条件 \"query\": \"广州 OR 长沙\" // 所有的字段中只要包含“广州”或“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; \"query\": &#123; \"query_string\": &#123; // 指定字段条件查询query_string \"query\": \"admin AND 长沙\", \"fields\": [\"name\", \"address\"] // name或address匹配admin和长沙 &#125; &#125;&#125;GET /es_db/_search&#123; \"query\": &#123; // ES执行搜索时，默认operator为or \"match\": &#123; // remark字段包含java或developer词组，则符合搜索条件。 \"remark\": \"java developer\" &#125; &#125;&#125;GET /es_db/_search&#123; \"query\": &#123; \"match\": &#123; \"remark\": &#123; // remark字段包含java和developer词组 \"query\": \"java developer\", \"operator\": \"and\" &#125; &#125; &#125;&#125;GET /es_db/_search&#123; \"query\": &#123; \"match\": &#123; \"remark\": &#123; // 需要remark字段中包含多个搜索词条中的一定比例 \"query\": \"java architect assistant\", \"minimum_should_match\": \"50%\" // minimum_should_match可使用百分比或固定数字 &#125; &#125; &#125;&#125; match_phrase短语搜索，使用短语搜索时和match类似，首先对搜索条件进行分词，ES在做分词时除了将数据切分外，还会保留一个词在整个数据中的下标position。当ES执行match phrase短语搜索时，首先将搜索条件分词，然后在倒排索引中检索数据，若搜索条件分词数据在某个document某个field出现时，则检查匹配到的单词的position是否连续，若不连续则匹配失败。 ES对match phrase短语搜索提供了slop参数，可实现数据在所有匹配结果中，多个单词距离越近相关度评分越高排序越靠前，若当slop移动次数使用完毕还没有匹配成功则无搜索结果。 12345678910111213141516171819GET _search&#123; \"query\": &#123; \"match_phrase\": &#123; // 短语搜索，搜索条件不分词 \"remark\": \"java assistant\" &#125; &#125;&#125;GET /es_db/_search&#123; \"query\": &#123; \"match_phrase\": &#123; \"remark\": &#123; \"query\": \"java assistant\", \"slop\": 1 &#125; &#125; &#125;&#125; 前缀搜索通常针对keyword类型字段即不分词字段，keyword类型字段数据大小写敏感，前缀搜索效率比较低，且不计算相关度分数，前缀越短效率越低。若使用前缀搜索，建议使用长前缀，因为前缀搜索需要扫描完整索引内容，所以前缀越长相对效率越高。 12345678GET /test_a/_search&#123; \"query\": &#123; \"prefix\": &#123; \"f.keyword\": &#123;\"value\": \"Jav\"&#125; &#125; &#125;&#125; 通配符搜索通配符可在倒排索引中使用，也可在keyword类型字段中使用。?问号匹配一个任意字符，*星号匹配0到n个任意字符。性能也很低，也需要扫描完整索引。 12345678GET /test_a/_search&#123; \"query\": &#123; \"wildcard\": &#123; \"f.keyword\": &#123; \"value\": \"?e*o*\" &#125; &#125; &#125;&#125; 正则搜索可在倒排索引或keyword类型字段中使用，性能很低需要扫描完整索引。 123456GET /test_a/_search&#123; \"query\": &#123; \"regexp\": &#123;\"f.keyword\": \"[A-z].+\"&#125; &#125;&#125; 搜索推荐其原理和match phrase类似，先使用match匹配term数据即示例中的java，然后在指定slop移动次数范围内前缀匹配示例数据sp，max_expansions是用于指定prefix最多匹配多少个term，超过该数量就不再匹配了。该语法限制只有最后一个term会执行前缀搜索。执行性能很差，最后一个term需要扫描所有符合slop要求的倒排索引的term。若必须使用一定要使用参数max_expansions。 12345678GET /test_a/_search&#123; \"query\": &#123; \"match_phrase_prefix\": &#123; \"f\": &#123;\"query\": \"java sp\",\"slop\": 10,\"max_expansions\": 10&#125; &#125; &#125;&#125; 模糊搜索搜索时可能搜索条件文本输入错误，fuzzy技术就是用于解决错误拼写的，英文中很有效但中文中几乎无效，其中fuzziness代表value值word可修改多少个字母来进行拼写错误纠正，修改字母数量包含字母变更，增加或减少字母。 12345678GET /test_a/_search&#123; \"query\": &#123; \"fuzzy\": &#123; \"f\": &#123;\"value\": \"word\",\"fuzziness\": 2&#125; &#125; &#125;&#125; 精确匹配 term：单个条件相等，查询字段映射类型属于为keyword，不会被分词 terms：单个字段属于某个值数组内的值 range：字段属于某个范围内的值 gte：大于等于 lte：小于等于 gt：大于 lt：小于 now：当前时间 exists：某个字段的值是否存在 ids：通过ID批量查询 12345678910111213141516171819202122232425262728POST /es_db/_doc/_search&#123; \"query\": &#123; \"term\": &#123; // term查询不会对字段进行分词查询，会采用精确匹配 \"name\": \"admin\" &#125; &#125;&#125;POST /es_db/_doc/_search&#123; \"query\": &#123; \"range\": &#123; // 范围查询 \"age\": &#123;\"gte\": 25,\"lte\": 28&#125; &#125; &#125;&#125;POST /es_db/_doc/_search // 范围、分页、输出字段、综合查询&#123; \"query\": &#123; \"range\": &#123; // 范围查询 \"age\": &#123;\"gte\": 25,\"lte\": 28&#125; &#125; &#125;, \"from\": 0, // 分页 \"size\": 2, \"_source\": [\"name\", \"age\", \"book\"], // 指定输出字段 \"sort\": &#123;\"age\": \"desc\"&#125;// 排序&#125; 组合查询组合条件查询是将叶子条件查询语句进行组合而形成的一个完整的查询条件，must、filter、shoud、must_not等子条件是通过term、terms、range、ids、exists、match等叶子条件为参数，当只有一个搜索条件时，must等对应的是一个对象，当多个条件时，对应的是一个数组。 bool：各条件之间有and，or或not关系 must：各个条件都必须满足，即各条件是and关系 should：各个条件有一个满足即可，即各条件是or关系 must_not：不满足所有条件，即各条件是not关系 filter：不计算相关度评分，即不计算_score，不对结果排序，效率更高，查询结果可被缓存 constant_score：不计算相关度评分 1234567891011121314151617181920212223POST /es_db/_doc/_search&#123; \"query\": &#123; \"bool\": &#123; \"filter\": &#123; // 对数据进行过滤 \"term\": &#123;\"age\": 25&#125; &#125; &#125; &#125;&#125; GET /es_db/_search&#123; \"query\": &#123; // 使用should+bool搜索，控制搜索条件的匹配度 \"bool\": &#123; \"should\": [ // 必须匹配java、developer、assistant三个词条中的至少2个 &#123;\"match\": &#123;\"remark\": \"java\"&#125;&#125;, &#123;\"match\": &#123;\"remark\": \"developer\"&#125;&#125;, &#123;\"match\": &#123;\"remark\": \"assistant\"&#125;&#125; ], \"minimum_should_match\": 2 // 控制搜索条件的匹配度 &#125; &#125;&#125; ES中执行match搜索时，ES底层通常会对搜索条件进行底层转换，来实现最终的搜索结果，若不怕麻烦，尽量使用转换后的语法执行搜索，效率更高。 1234567891011121314GET /es_db/_search // 转换前&#123;\"query\":&#123;\"match\":&#123;\"remark\":\"java developer\"&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;\"query\":&#123;\"bool\":&#123;\"should\":[&#123;\"term\":&#123;\"remark\":\"java\"&#125;&#125;,&#123;\"term\":&#123;\"remark\":&#123;\"value\":\"developer\"&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;\"query\":&#123;\"match\":&#123;\"remark\":&#123;\"query\":\"java developer\",\"operator\":\"and\"&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;\"query\":&#123;\"bool\":&#123;\"must\":[&#123;\"term\":&#123;\"remark\":\"java\"&#125;&#125;,&#123;\"term\":&#123;\"remark\":&#123;\"value\":\"developer\"&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;\"query\":&#123;\"match\":&#123;\"remark\":&#123;\"query\":\"java architect assistant\",\"minimum_should_match\":\"68%\"&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;\"query\":&#123;\"bool\":&#123;\"should\":[&#123;\"term\":&#123;\"remark\":\"java\"&#125;&#125;,&#123;\"term\":&#123;\"remark\":\"architect\"&#125;&#125;,&#123;\"term\":&#123;\"remark\":\"assistant\"&#125;&#125;],\"minimum_should_match\":2&#125;&#125;&#125; boost权重控制boost权重控制一般用于搜索时相关度排序使用，将某字段数据匹配时相关度分数增加 123456789101112GET /es_db/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": [&#123;\"match\": &#123;\"remark\": \"java\"&#125;&#125;], \"should\": [ &#123;\"match\": &#123;\"remark\": &#123;\"query\": \"developer\",\"boost\": 3&#125;&#125;&#125;, &#123;\"match\": &#123;\"remark\": &#123;\"query\": \"architect\",\"boost\": 1&#125;&#125;&#125; ] &#125; &#125;&#125; dis_maxdis_max语法是直接获取搜索多条件中单条件query相关度分数最高的数据，以该数据做相关度排序。基于dis_max实现best fields策略进行多字段搜索，best fields策略是搜索document中某个field，尽可能多的匹配搜索条件。与之相反的是most fields策略即尽可能多的字段匹配到搜索条件。 best fields策略优点是精确匹配的数据可尽可能排列在最前端，且可通过minimum_should_match去除长尾数据，避免长尾数据字段对排序结果的影响。缺点相对排序不均匀。 1234567891011GET /es_db/_search&#123; \"query\": &#123; \"dis_max\": &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 \"queries\": [ &#123;\"match\": &#123;\"name\": \"rod\"&#125;&#125;, &#123;\"match\": &#123;\"remark\": \"java developer\"&#125;&#125; ] &#125; &#125;&#125; dis_max是将多个搜索query条件中相关度分数最高的用于结果排序，忽略其他query分数，在某些情况下需要其他query条件中相关度介入最终结果排序，此时可使用tie_breaker参数来优化dis_max搜索。tie_breaker参数表示将其他query搜索条件相关度分数乘以参数值再参与结果排序。若不定义tie_breaker参数相当于参数值为0，故其他query条件的相关度分数被忽略。 123456789101112GET /es_db/_search&#123; \"query\": &#123; \"dis_max\": &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 \"queries\": [ &#123;\"match\": &#123;\"name\": \"rod\"&#125;&#125;, &#123;\"match\": &#123;\"remark\": \"java developer\"&#125;&#125; ], \"tie_breaker\": 0.5 &#125; &#125;&#125; 使用multi_match简化dis_max+tie_breaker，ES中相同结果搜索也可使用不同语法语句来实现。 123456789101112131415161718192021222324252627GET /es_db/_search&#123; \"query\": &#123; \"dis_max\": &#123; \"queries\": [ &#123;\"match\": &#123;\"name\": \"rod\"&#125;&#125;, &#123;\"match\": &#123;\"remark\": &#123;\"query\": \"java assistant\",\"boost\": 2&#125;&#125;&#125; ], \"tie_breaker\": 0.5 &#125; &#125;&#125;GET /es_db/_search&#123; \"query\": &#123; \"multi_match\": &#123; \"query\": \"rod java developer\", \"fields\": [ \"name\", \"remark^2\" // ^n代表权重，相当于\"boost\":n ], \"type\": \"best_fields\", // 其中type常用的有best_fields和most_fields \"tie_breaker\": 0.5, \"minimum_should_match\": \"50%\" &#125; &#125;&#125; cross fields是一个唯一标识，且分部在多个fields中，使用该唯一标识搜索数据即cross fields搜索。如人名可分为姓和名，地址可分为省、市、区县、街道等。使用人名或地址来搜索document，就称为cross fields搜索。 实现这种搜索，一般都是使用most fields搜索策略，因为这就是多个field问题。Cross fields搜索策略是从多个字段中搜索条件数据，默认和most fields搜索逻辑一致但计算相关度分数和best fields策略一致。一般若使用cross fields搜索策略，都会携带operator额外参数，用来标记搜索条件如何在多个字段中匹配。 1234567891011GET /es_db/_search&#123; \"query\": &#123; \"multi_match\": &#123; // 搜索条件中java必须在name或remark字段中匹配，developer也必须在name或remark字段中匹配 \"query\": \"java developer\", \"fields\": [\"name\", \"remark\"], \"type\": \"cross_fields\", \"operator\": \"and\" &#125; &#125;&#125; most fields策略是尽可能匹配更多字段，会导致精确搜索结果排序问题，又因为cross fields搜索，不能使用minimum_should_match来去除长尾数据。故在使用most fields和cross fields策略搜索数据时，都有不同缺陷，商业项目开发中都推荐使用best fields策略实现搜索。 可通过copy_to解决cross fields搜索问题，copy_to就是将多个字段复制到一个字段中实现一个多字段组合，在商业项目中，也用于解决搜索条件默认字段问题。若需要使用copy_to语法，则需要在定义index时手工指定mapping映射策略。 123456789PUT /es_db/_mapping&#123; \"properties\": &#123; \"provice\": &#123;\"type\": \"text\",\"analyzer\": \"standard\",\"copy_to\": \"address\"&#125;, \"city\": &#123;\"type\": \"text\",\"copy_to\": \"address\"&#125;, \"street\": &#123;\"type\": \"text\",\"analyzer\": \"standard\",\"copy_to\": \"address\"&#125;, \"address\": &#123;\"type\": \"text\",\"analyzer\": \"standard\"&#125; &#125;&#125; 在mapping定义中新增provice、city、street、address等字段，其中provice、city、street三个字段值会自动复制到address字段中，实现一个字段组合。在搜索地址时可在address字段中做条件匹配，从而避免most fields策略导致的问题。在维护数据时不需对address字段特殊维护，ES会自动维护组合字段。在存储时物理上不一定存在但逻辑上存在，因为address由3个物理存在属性province、city、street组成。 使用match和proximity search实现召回率和精准度平衡，若搜索时只使用match phrase语法，会导致召回率低下，若只使用match语法，会导致精准度低下，因为搜索结果排序是根据相关度分数算法计算得到。若需要在结果中兼顾召回率和精准度，就需要将match和proximity search混合使用。 召回率：搜索结果比率，如索引A中有100个document，搜索时返回多少个document 精准度：搜索结果准确率，如搜索条件为hello java，搜索结果中尽可能让短语匹配和hello java离的近的结果排序靠前 1234567891011121314151617181920POST /test_a/_doc/3&#123;\"f\":\"hello, java is very good, spark is also very good\"&#125;POST /test_a/_doc/4&#123;\"f\":\"java and spark, development language \"&#125;POST /test_a/_doc/5&#123;\"f\":\"Java Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.\"&#125;POST /test_a/_doc/6&#123;\"f\":\"java spark and, development language \"&#125;GET /test_a/_search&#123;\"query\":&#123;\"match\":&#123;\"f\":\"java spark\"&#125;&#125;&#125;GET /test_a/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": [&#123;\"match\": &#123;\"f\": \"java spark\"&#125;&#125;], \"should\": [&#123;\"match_phrase\": &#123;\"f\": &#123;\"query\": \"java spark\",\"slop\": 50&#125;&#125;&#125;] &#125; &#125;&#125; 连接查询 父子文档查询：parent/child 嵌套文档查询：nested ES架构原理在ES中主要分成Master和DataNode两类节点，ES启动时会选举出一个Master节点，当某个节点启动后，使用Zen Discovery机制找到集群中的其他节点并建立连接，并从候选主节点中选举出一个主节点。一个ES集群中只有一个Master节点，但会有N个DataNode节点，在生产环境中内存可相对小一点但机器要稳定。 Master：管理索引即创建、删除索引，分配分片，维护元数据，管理集群节点状态，不负责数据写入和查询，比较轻量级 DataNode：数据写入，数据检索，大部分ES压力都在DataNode节点上 分片ShardES是一个分布式搜索引擎，索引数据也分成若干部分，分布在不同服务器节点中，分布在不同服务器节点中的索引数据，就是Shard分片。Elasticsearch会自动管理分片，若发现分片分布不均衡，会自动迁移一个索引index由多个shard分片组成，分片是分布在不同的服务器上。 副本为了对ES分片进行容错，假设某个节点不可用，会导致整个索引库都将不可用。故需要对分片进行副本容错，每个分片都会有对应的副本。默认创建索引为1个分片、每个分片有1个主分片和1个副本分片。 每个分片都会有一个Primary Shard主分片，也会有若干个Replica Shard副本分片，Primary Shard和Replica Shard不在同一个节点上。 12345678910111213141516PUT /job_idx_shard_temp // 创建指定分片数量、副本数量的索引&#123; \"mappings\": &#123; \"properties\": &#123; \"id\": &#123;\"type\": \"long\",\"store\": true&#125;, \"area\": &#123;\"type\": \"keyword\",\"store\": true&#125;, \"edu\": &#123;\"type\": \"keyword\",\"store\": true&#125; &#125; &#125;, \"settings\": &#123; \"number_of_shards\": 3, // 指定分片数量 \"number_of_replicas\": 2 // 指定副本数量 &#125;&#125;GET /_cat/indices?v // 查看分片、主分片、副本分片 文档写入原理 选择任意一个DataNode发送请求如node2，此时node2就成为一个coordinating node协调节点，通过协调节点计算得到文档要写入的分片shard = hash(routing) % number_of_primary_shards，其中routing是一个可变值，默认为文档_id，然后协调节点会进行路由，将请求转发给对应primary shard主分片所在的DataNode，假设primary shard主分片在node1、replica shard副分片在node2，node1节点上的Primary Shard处理请求，写入数据到索引库中，并将数据同步到Replica shard副分片，Primary Shard和Replica Shard都保存好了文档则返回Client。 检索原理 Client发起查询请求某个DataNode接收到请求后，该DataNode就成为Coordinating Node协调节点，协调节点将查询请求广播到每一个数据节点，这些数据节点的分片会处理该查询请求，每个分片进行数据查询，将符合条件的数据放在一个优先队列中，并将这些数据的文档ID、节点信息、分片信息返回给协调节点，协调节点将所有结果进行汇总并全局排序，协调节点向包含这些文档ID的分片发送get请求，对应的分片将文档数据返回给协调节点，最后协调节点将数据返回给客户端。 准实时索引 当数据写入到ES分片时会首先写入到内存中，然后通过内存buffer生成一个Segment，并刷到文件系统缓存中而不是直接刷到磁盘，数据可被检索，ES中默认1秒refresh一次。数据在写入内存的同时，也会记录Translog日志，若在refresh期间出现异常，会根据Translog来进行数据恢复，等到文件系统缓存中的Segment数据都刷到磁盘中，则清空Translog文件，ES默认每隔30分钟会将文件系统缓存的数据刷入到磁盘。Segment太多时ES定期会将多个Segment合并成为大的Segment，减少索引查询时IO开销，此阶段ES会真正的物理删除之前执行过delete的数据。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://yaoyinglong.github.io/tags/ElasticSearch/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"ELK","slug":"Cloud/ELK","permalink":"https://yaoyinglong.github.io/categories/Cloud/ELK/"}]},{"title":"Zookeeper客户端之ZAB","date":"2021-12-20T16:00:00.000Z","path":"Blog/Cloud/Zookeeper/Zookeeper客户端之ZAB/","text":"整个Zookeeper就是一个多节点分布式一致性算法的实现，底层采用的实现协议是ZAB，即Zookeeper Atomic Broadcast原子广播协议。ZAB协议是为分布式协调服务Zookeeper专门设计的一种支持崩溃恢复和原子广播的协议。 ZAB协议消息广播过程使用的是一个原子广播协议，类似一个两阶段提交过程。对于客户端发送的写请求，全部由 Leader接收，Leader将请求封装成一个事务Proposal，将其发送给所有Follower，然后根据所有Follwer的反馈，若含Leader自己超过半数成功响应，则执行commit操作。 Leader在收到客户端请求之后，会将该请求封装成一个事务，并给该事务分配一个全局递增的唯一ID，称为事务ZXID，ZAB协议需要保证事务的顺序，因此必须将每一个事务按照ZXID进行先后排序然后处理，主要通过消息队列实现 在Leader和Follwer之间还有一个消息队列，用来解耦他们之间的耦合，解除同步阻塞 Zookeeper集群中为保证任何所有进程能够有序的顺序执行，只能是Leader服务器接受写请求，即使是 Follower服务器接受到客户端的写请求，也会转发到Leader服务器进行处理，Follower只处理读请求 ZAB协议规定了若一个事务在一台机器上被处理Commit成功，则应该在所有机器上都被处理成功，哪怕机器出现故障崩溃 当崩溃恢复之后，需要在正式接收客户端请求之前，Leader服务器首先确认事务是否都已经被过半的Follwer提交了，即是否完成了数据同步。目的是为了保持数据一致。 当Follwer服务器成功同步之后，Leader会将这些服务器加入到可用服务器列表中，Leader服务器处理或丢弃事务都是依赖着ZXID。 实际上，Leader 服务器处理或丢弃事务都是依赖着 ZXID 的，那么这个 ZXID 如何生成呢？ 在ZAB协议的事务编号ZXID设计中，ZXID是一个64位的数字，其中低32位可看作是一个简单的递增的计数器，针对客户端的每一个事务请求，Leader都会产生一个新的事务Proposal并对该计数器进行+1操作。高32位则代表Leader服务器上取出本地日志中最大事务Proposal的ZXID，并从该ZXID中解析出对应Leader选举周期epoch值，当一轮新的选举结束后，会对该值加一且事务id又从0开始自增。 高32位代表了每代Leader的唯一性，低32代表了每代Leader中事务的唯一性。同时也能让Follwer通过高32位识别不同的Leader，简化数据恢复流程。基于这样的策略，当Follower连接上Leader后，Leader服务器会根据自己服务器上最后被提交的ZXID和Follower上的ZXID进行比对，比对结果要么回滚，要么和Leader同步。 1234567891011121314151617181920public class ZkServiceProviderV implements Watcher &#123; private static CountDownLatch countDownLatch = new CountDownLatch(1); private static ZooKeeper zk = null; private static String rootPath = \"/GroupMembers\"; public static void main(String[] args) throws IOException, InterruptedException, KeeperException &#123; zk = new ZooKeeper(\"localhost:2181\", 5000, new ZkServiceProviderV()); countDownLatch.await(); zk.create(rootPath + \"/test\", \"test carete\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); System.out.println(\"创建集群节点test：\" + rootPath + \"test\"); Thread.sleep(Integer.MAX_VALUE); &#125; @Override public void process(WatchedEvent event) &#123; if (Event.KeeperState.SyncConnected == event.getState()) &#123; if (Event.EventType.None == event.getType() &amp;&amp; event.getPath() == null) &#123; countDownLatch.countDown(); &#125; &#125; &#125;&#125; 通过ZooKeeper的构造方法创建ZooKeeper时，首先通过defaultWatchManager创建一个ZKWatchManager对象，且将传入的Watcher赋值给其defaultWatcher属性。然后通过ClientCnxn构造方法创建连接，且在ClientCnxn构造方法中创建了SendThread和EventThread两个重要的线程。且在ZooKeeper构造方法中调用ClientCnxn的start方法启动了这两个线程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class ZooKeeper implements AutoCloseable &#123; public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher) throws IOException &#123; this(connectString, sessionTimeout, watcher, false); &#125; public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly) throws IOException &#123; this(connectString, sessionTimeout, watcher, canBeReadOnly, createDefaultHostProvider(connectString)); &#125; public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly, HostProvider aHostProvider) throws IOException &#123; this(connectString, sessionTimeout, watcher, canBeReadOnly, aHostProvider, null); &#125; public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly, HostProvider aHostProvider, ZKClientConfig clientConfig) throws IOException &#123; if (clientConfig == null) &#123; clientConfig = new ZKClientConfig(); &#125; this.clientConfig = clientConfig; watchManager = defaultWatchManager(); watchManager.defaultWatcher = watcher; ConnectStringParser connectStringParser = new ConnectStringParser(connectString); hostProvider = aHostProvider; cnxn = createConnection(connectStringParser.getChrootPath(), hostProvider, sessionTimeout, this, watchManager, getClientCnxnSocket(), canBeReadOnly); cnxn.start(); &#125; protected ClientCnxn createConnection(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, boolean canBeReadOnly) throws IOException &#123; return new ClientCnxn(chrootPath, hostProvider, sessionTimeout, this, watchManager, clientCnxnSocket, canBeReadOnly); &#125; static class ZKWatchManager implements ClientWatchManager &#123; private final Map&lt;String, Set&lt;Watcher&gt;&gt; dataWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private final Map&lt;String, Set&lt;Watcher&gt;&gt; existWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private final Map&lt;String, Set&lt;Watcher&gt;&gt; childWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private boolean disableAutoWatchReset; protected volatile Watcher defaultWatcher; ZKWatchManager(boolean disableAutoWatchReset) &#123; this.disableAutoWatchReset = disableAutoWatchReset; &#125; &#125;&#125;public class ClientCnxn &#123; public ClientCnxn(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, boolean canBeReadOnly) throws IOException &#123; this(chrootPath, hostProvider, sessionTimeout, zooKeeper, watcher, clientCnxnSocket, 0, new byte[16], canBeReadOnly); &#125; public ClientCnxn(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) &#123; this.zooKeeper = zooKeeper; this.watcher = watcher; this.sessionId = sessionId; this.sessionPasswd = sessionPasswd; this.sessionTimeout = sessionTimeout; this.hostProvider = hostProvider; this.chrootPath = chrootPath; connectTimeout = sessionTimeout / hostProvider.size(); readTimeout = sessionTimeout * 2 / 3; readOnly = canBeReadOnly; sendThread = new SendThread(clientCnxnSocket); eventThread = new EventThread(); this.clientConfig = zooKeeper.getClientConfig(); initRequestTimeout(); &#125; public void start() &#123; sendThread.start(); eventThread.start(); &#125;&#125; SendThreadSendThread主要跟服务端建立连接，且监听读写事件并处理。首先在ClientCnxn的startConnect方法中调用ClientCnxnSocketNIO的connect方法，创建SocketChannel并注册到Selector中。在ClientCnxnSocketNIO的doTransport方法中监听读写事件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158class SendThread extends ZooKeeperThread &#123; public void run() &#123; clientCnxnSocket.introduce(this, sessionId, outgoingQueue); clientCnxnSocket.updateNow(); clientCnxnSocket.updateLastSendAndHeard(); int to; long lastPingRwServer = Time.currentElapsedTime(); final int MAX_SEND_PING_INTERVAL = 10000; //10 seconds InetSocketAddress serverAddress = null; while (state.isAlive()) &#123; try &#123; if (!clientCnxnSocket.isConnected()) &#123; if (closing) &#123; break; &#125; if (rwServerAddress != null) &#123; serverAddress = rwServerAddress; rwServerAddress = null; &#125; else &#123; serverAddress = hostProvider.next(1000); &#125; startConnect(serverAddress); clientCnxnSocket.updateLastSendAndHeard(); &#125; if (state.isConnected()) &#123;// determine whether we need to send an AuthFailed event. if (zooKeeperSaslClient != null) &#123; boolean sendAuthEvent = false; if (zooKeeperSaslClient.getSaslState() == ZooKeeperSaslClient.SaslState.INITIAL) &#123; try &#123; zooKeeperSaslClient.initialize(ClientCnxn.this); &#125; catch (SaslException e) &#123; state = States.AUTH_FAILED; sendAuthEvent = true; &#125; &#125; KeeperState authState = zooKeeperSaslClient.getKeeperState(); if (authState != null) &#123; if (authState == KeeperState.AuthFailed) &#123; state = States.AUTH_FAILED; sendAuthEvent = true; &#125; else &#123; if (authState == KeeperState.SaslAuthenticated) &#123; sendAuthEvent = true; &#125; &#125; &#125; if (sendAuthEvent) &#123; eventThread.queueEvent(new WatchedEvent(Watcher.Event.EventType.None, authState, null)); if (state == States.AUTH_FAILED) &#123; eventThread.queueEventOfDeath(); &#125; &#125; &#125; to = readTimeout - clientCnxnSocket.getIdleRecv(); &#125; else &#123; to = connectTimeout - clientCnxnSocket.getIdleRecv(); &#125; if (to &lt;= 0) &#123; throw new SessionTimeoutException(warnInfo); &#125; if (state.isConnected()) &#123; int timeToNextPing = readTimeout / 2 - clientCnxnSocket.getIdleSend() - ((clientCnxnSocket.getIdleSend() &gt; 1000) ? 1000 : 0); if (timeToNextPing &lt;= 0 || clientCnxnSocket.getIdleSend() &gt; MAX_SEND_PING_INTERVAL) &#123; sendPing(); clientCnxnSocket.updateLastSend(); &#125; else &#123; if (timeToNextPing &lt; to) &#123; to = timeToNextPing; &#125; &#125; &#125; if (state == States.CONNECTEDREADONLY) &#123; // 只读模式处理 long now = Time.currentElapsedTime(); int idlePingRwServer = (int) (now - lastPingRwServer); if (idlePingRwServer &gt;= pingRwTimeout) &#123; lastPingRwServer = now; idlePingRwServer = 0; pingRwTimeout = Math.min(2 * pingRwTimeout, maxPingRwTimeout); pingRwServer(); &#125; to = Math.min(to, pingRwTimeout - idlePingRwServer); &#125; clientCnxnSocket.doTransport(to, pendingQueue, ClientCnxn.this); &#125; catch (Throwable e) &#123; if (closing) &#123; break; &#125; else &#123;// this is ugly, you have a better way speak up cleanAndNotifyState(); &#125; &#125; &#125; synchronized (state) &#123;// When it comes to this point, it guarantees that later queued packet to outgoingQueue will be notified of death. cleanup(); &#125; clientCnxnSocket.close(); if (state.isAlive()) &#123; eventThread.queueEvent(new WatchedEvent(Event.EventType.None, Event.KeeperState.Disconnected, null)); &#125; eventThread.queueEvent(new WatchedEvent(Event.EventType.None, Event.KeeperState.Closed, null)); &#125;&#125;public class ClientCnxn &#123; private void startConnect(InetSocketAddress addr) throws IOException &#123;// initializing it for new connection saslLoginFailed = false; if (!isFirstConnect) &#123; try &#123; Thread.sleep(r.nextInt(1000)); &#125; catch (InterruptedException e) &#123; &#125; &#125; state = States.CONNECTING; String hostPort = addr.getHostString() + \":\" + addr.getPort(); MDC.put(\"myid\", hostPort); setName(getName().replaceAll(\"\\\\(.*\\\\)\", \"(\" + hostPort + \")\")); if (clientConfig.isSaslClientEnabled()) &#123; try &#123; if (zooKeeperSaslClient != null) &#123; zooKeeperSaslClient.shutdown(); &#125; zooKeeperSaslClient = new ZooKeeperSaslClient(SaslServerPrincipal.getServerPrincipal(addr, clientConfig), clientConfig); &#125; catch (LoginException e) &#123; eventThread.queueEvent(new WatchedEvent(Watcher.Event.EventType.None, Watcher.Event.KeeperState.AuthFailed, null)); saslLoginFailed = true; &#125; &#125; clientCnxnSocket.connect(addr); &#125;&#125;public class ClientCnxnSocketNIO extends ClientCnxnSocket &#123; void connect(InetSocketAddress addr) throws IOException &#123; SocketChannel sock = createSock(); try &#123; registerAndConnect(sock, addr); &#125; catch (IOException e) &#123; sock.close(); throw e; &#125; initialized = false; lenBuffer.clear(); incomingBuffer = lenBuffer; &#125; SocketChannel createSock() throws IOException &#123; SocketChannel sock; sock = SocketChannel.open(); sock.configureBlocking(false); sock.socket().setSoLinger(false, -1); sock.socket().setTcpNoDelay(true); return sock; &#125; void registerAndConnect(SocketChannel sock, InetSocketAddress addr) throws IOException &#123; sockKey = sock.register(selector, SelectionKey.OP_CONNECT); boolean immediateConnect = sock.connect(addr); if (immediateConnect) &#123; sendThread.primeConnection(); &#125; &#125;&#125; 在SendThread中通过startConnect方法与服务端建立好连接后，调用ClientCnxnSocketNIO的doTransport监听读写事件，当接收到读写事件后调用doIO方法对读写逻辑分别处理。对于写事件通过从outgoingQueue队列中取出命令包，最终调用ClientCnxn的createBB方法将数据发送给服务端，服务端最终通过CnxnChannelHandler的channelRead方法处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class ClientCnxnSocketNIO extends ClientCnxnSocket &#123; void doTransport(int waitTimeOut, List&lt;Packet&gt; pendingQueue, ClientCnxn cnxn) throws IOException, InterruptedException &#123; selector.select(waitTimeOut); Set&lt;SelectionKey&gt; selected; synchronized (this) &#123; selected = selector.selectedKeys(); &#125; updateNow(); for (SelectionKey k : selected) &#123; SocketChannel sc = ((SocketChannel) k.channel()); if ((k.readyOps() &amp; SelectionKey.OP_CONNECT) != 0) &#123; if (sc.finishConnect()) &#123; updateLastSendAndHeard(); // 更新最后发送以及心跳时间 updateSocketAddresses(); sendThread.primeConnection(); // 处理会话、之前的监听器、身份验证 &#125; &#125; else if ((k.readyOps() &amp; (SelectionKey.OP_READ | SelectionKey.OP_WRITE)) != 0) &#123; doIO(pendingQueue, cnxn); // 有NIO读写事件发生 &#125; &#125; if (sendThread.getZkState().isConnected()) &#123; if (findSendablePacket(outgoingQueue, sendThread.tunnelAuthInProgress()) != null) &#123; enableWrite(); &#125; &#125; selected.clear(); &#125; void doIO(List&lt;Packet&gt; pendingQueue, ClientCnxn cnxn) throws InterruptedException, IOException &#123; SocketChannel sock = (SocketChannel) sockKey.channel(); if (sock == null) &#123; throw new IOException(\"Socket is null!\"); &#125; if (sockKey.isReadable()) &#123; // 处理服务端响应信息 int rc = sock.read(incomingBuffer); if (rc &lt; 0) &#123; // 未读取到数据抛出异常 throw new EndOfStreamException(\"Unable to read additional data from server sessionid 0x\" + Long.toHexString(sessionId) + \", likely server has closed socket\"); &#125; if (!incomingBuffer.hasRemaining()) &#123; incomingBuffer.flip(); if (incomingBuffer == lenBuffer) &#123; recvCount.getAndIncrement(); readLength(); &#125; else if (!initialized) &#123; readConnectResult(); enableRead(); if (findSendablePacket(outgoingQueue, sendThread.tunnelAuthInProgress()) != null) &#123; enableWrite(); &#125; lenBuffer.clear(); incomingBuffer = lenBuffer; updateLastHeard(); initialized = true; &#125; else &#123; sendThread.readResponse(incomingBuffer); lenBuffer.clear(); incomingBuffer = lenBuffer; updateLastHeard(); &#125; &#125; &#125; if (sockKey.isWritable()) &#123; // 向服务端发送消息 Packet p = findSendablePacket(outgoingQueue, sendThread.tunnelAuthInProgress()); // 从outgoingQueue队列中取出命令包 if (p != null) &#123; updateLastSend(); if (p.bb == null) &#123; if ((p.requestHeader != null) &amp;&amp; (p.requestHeader.getType() != OpCode.ping) &amp;&amp; (p.requestHeader.getType() != OpCode.auth)) &#123; p.requestHeader.setXid(cnxn.getXid()); &#125; p.createBB(); // 将待发送数据通过jute序列化后封装到ByteBuffer中去 &#125; sock.write(p.bb); // 将数据发送给服务端，服务端通过SocketChannel接收客户端请求命令 if (!p.bb.hasRemaining()) &#123; sentCount.getAndIncrement(); outgoingQueue.removeFirstOccurrence(p); if (p.requestHeader != null &amp;&amp; p.requestHeader.getType() != OpCode.ping &amp;&amp; p.requestHeader.getType() != OpCode.auth) &#123; synchronized (pendingQueue) &#123; pendingQueue.add(p); &#125; &#125; &#125; &#125; if (outgoingQueue.isEmpty()) &#123; disableWrite(); &#125; else if (!initialized &amp;&amp; p != null &amp;&amp; !p.bb.hasRemaining()) &#123; disableWrite(); &#125; else &#123; // Just in case enableWrite(); &#125; &#125; &#125;&#125;public class ClientCnxn &#123; public void createBB() &#123; try &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); boa.writeInt(-1, \"len\"); // We'll fill this in later if (requestHeader != null) &#123; requestHeader.serialize(boa, \"header\"); &#125; if (request instanceof ConnectRequest) &#123; request.serialize(boa, \"connect\"); boa.writeBool(readOnly, \"readOnly\"); &#125; else if (request != null) &#123; request.serialize(boa, \"request\"); &#125; baos.close(); this.bb = ByteBuffer.wrap(baos.toByteArray()); this.bb.putInt(this.bb.capacity() - 4); this.bb.rewind(); &#125; catch (IOException e) &#123;&#125; &#125;&#125; 对于读事件若收到服务端数据变动返回事件，首先反序列化服务端响应数据为WatcherEvent，然后从服务端路径转换为客户端路径，最后将监听事件添加到EventThread的waitingEvents阻塞队列中异步处理，在finally中调用finishPacket中判断若getData方法watch若为true，则将Watcher加入到path对应的Watcher集合中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class SendThread extends ZooKeeperThread &#123; void readResponse(ByteBuffer incomingBuffer) throws IOException &#123; ByteBufferInputStream bbis = new ByteBufferInputStream(incomingBuffer); BinaryInputArchive bbia = BinaryInputArchive.getArchive(bbis); ReplyHeader replyHdr = new ReplyHeader(); replyHdr.deserialize(bbia, \"header\"); if (replyHdr.getXid() == -2) &#123; // -2 is the xid for pings 处理Ping return; &#125; if (replyHdr.getXid() == -4) &#123; // -4 is the xid for AuthPacket if (replyHdr.getErr() == KeeperException.Code.AUTHFAILED.intValue()) &#123; state = States.AUTH_FAILED; eventThread.queueEvent(new WatchedEvent(Watcher.Event.EventType.None, Watcher.Event.KeeperState.AuthFailed, null)); eventThread.queueEventOfDeath(); &#125; return; &#125; if (replyHdr.getXid() == -1) &#123; // 收到服务端数据变动返回事件 WatcherEvent event = new WatcherEvent(); event.deserialize(bbia, \"response\"); if (chrootPath != null) &#123; // 从服务端路径转换为客户端路径 String serverPath = event.getPath(); if (serverPath.compareTo(chrootPath) == 0) event.setPath(\"/\"); else if (serverPath.length() &gt; chrootPath.length()) event.setPath(serverPath.substring(chrootPath.length())); &#125; WatchedEvent we = new WatchedEvent(event); eventThread.queueEvent(we); return; &#125; if (tunnelAuthInProgress()) &#123; GetSASLRequest request = new GetSASLRequest(); request.deserialize(bbia, \"token\"); zooKeeperSaslClient.respondToServer(request.getToken(), ClientCnxn.this); return; &#125; Packet packet; synchronized (pendingQueue) &#123; if (pendingQueue.size() == 0) &#123; throw new IOException(\"Nothing in the queue, but got \" + replyHdr.getXid()); &#125; packet = pendingQueue.remove(); &#125; try &#123; if (packet.requestHeader.getXid() != replyHdr.getXid()) &#123; packet.replyHeader.setErr(KeeperException.Code.CONNECTIONLOSS.intValue()); throw new IOException(\"Xid out of order. Got Xid \" + replyHdr.getXid() + \" with err \" + +replyHdr.getErr() + \" expected Xid \" + packet.requestHeader.getXid() + \" for a packet with details: \" + packet); &#125; packet.replyHeader.setXid(replyHdr.getXid()); packet.replyHeader.setErr(replyHdr.getErr()); packet.replyHeader.setZxid(replyHdr.getZxid()); if (replyHdr.getZxid() &gt; 0) &#123; lastZxid = replyHdr.getZxid(); &#125; if (packet.response != null &amp;&amp; replyHdr.getErr() == 0) &#123; packet.response.deserialize(bbia, \"response\"); &#125; &#125; finally &#123; finishPacket(packet); // 收到服务端命令执行完毕返回事件 &#125; &#125;&#125;public class ClientCnxn &#123; protected void finishPacket(Packet p) &#123; int err = p.replyHeader.getErr(); if (p.watchRegistration != null) &#123; // getData方法watch若为true则执行该逻辑 p.watchRegistration.register(err); // 初始化watchRegistration，将watcher加入到path对应的watcher集合中取 &#125; if (p.watchDeregistration != null) &#123; Map&lt;EventType, Set&lt;Watcher&gt;&gt; materializedWatchers = null; try &#123; materializedWatchers = p.watchDeregistration.unregister(err); for (Entry&lt;EventType, Set&lt;Watcher&gt;&gt; entry : materializedWatchers.entrySet()) &#123; Set&lt;Watcher&gt; watchers = entry.getValue(); if (watchers.size() &gt; 0) &#123; queueEvent(p.watchDeregistration.getClientPath(), err, watchers, entry.getKey()); p.replyHeader.setErr(Code.OK.intValue()); &#125; &#125; &#125; catch (KeeperException.NoWatcherException nwe) &#123; p.replyHeader.setErr(nwe.code().intValue()); &#125; catch (KeeperException ke) &#123; p.replyHeader.setErr(ke.code().intValue()); &#125; &#125; if (p.cb == null) &#123; synchronized (p) &#123; p.finished = true; p.notifyAll(); // 唤醒客户端等待 &#125; &#125; else &#123; p.finished = true; eventThread.queuePacket(p); &#125; &#125;&#125; EventThreadEventThread只要完成监听事件的异步执行，通过queueEvent方法将监听事件添加到waitingEvents阻塞队列中，通过processEvent方法执行具体的监听器的回调方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158class EventThread extends ZooKeeperThread &#123; private final LinkedBlockingQueue&lt;Object&gt; waitingEvents = new LinkedBlockingQueue&lt;Object&gt;(); public void queueEvent(WatchedEvent event) &#123; queueEvent(event, null); &#125; private void queueEvent(WatchedEvent event, Set&lt;Watcher&gt; materializedWatchers) &#123; if (event.getType() == EventType.None &amp;&amp; sessionState == event.getState()) &#123; return; &#125; sessionState = event.getState(); final Set&lt;Watcher&gt; watchers; if (materializedWatchers == null) &#123;// materialize the watchers based on the event watchers = watcher.materialize(event.getState(), event.getType(), event.getPath()); &#125; else &#123; watchers = new HashSet&lt;Watcher&gt;(); watchers.addAll(materializedWatchers); &#125; WatcherSetEventPair pair = new WatcherSetEventPair(watchers, event); waitingEvents.add(pair); &#125; public void run() &#123; try &#123; isRunning = true; while (true) &#123; Object event = waitingEvents.take(); if (event == eventOfDeath) &#123; wasKilled = true; &#125; else &#123; processEvent(event); &#125; if (wasKilled) synchronized (waitingEvents) &#123; if (waitingEvents.isEmpty()) &#123; isRunning = false; break; &#125; &#125; &#125; &#125; catch (InterruptedException e) &#123;&#125; &#125; private void processEvent(Object event) &#123; try &#123; if (event instanceof WatcherSetEventPair) &#123;// each watcher will process the event WatcherSetEventPair pair = (WatcherSetEventPair) event; for (Watcher watcher : pair.watchers) &#123; try &#123; watcher.process(pair.event); // 执行具体Watcher的process方法 &#125; catch (Throwable t) &#123;&#125; &#125; &#125; else if (event instanceof LocalCallback) &#123; LocalCallback lcb = (LocalCallback) event; if (lcb.cb instanceof StatCallback) &#123; ((StatCallback) lcb.cb).processResult(lcb.rc, lcb.path, lcb.ctx, null); &#125; else if (lcb.cb instanceof DataCallback) &#123; ((DataCallback) lcb.cb).processResult(lcb.rc, lcb.path, lcb.ctx, null, null); &#125; else if (lcb.cb instanceof ACLCallback) &#123; ((ACLCallback) lcb.cb).processResult(lcb.rc, lcb.path, lcb.ctx, null, null); &#125; else if (lcb.cb instanceof ChildrenCallback) &#123; ((ChildrenCallback) lcb.cb).processResult(lcb.rc, lcb.path, lcb.ctx, null); &#125; else if (lcb.cb instanceof Children2Callback) &#123; ((Children2Callback) lcb.cb).processResult(lcb.rc, lcb.path, lcb.ctx, null, null); &#125; else if (lcb.cb instanceof StringCallback) &#123; ((StringCallback) lcb.cb).processResult(lcb.rc, lcb.path, lcb.ctx, null); &#125; else &#123; ((VoidCallback) lcb.cb).processResult(lcb.rc, lcb.path, lcb.ctx); &#125; &#125; else &#123; Packet p = (Packet) event; int rc = 0; String clientPath = p.clientPath; if (p.replyHeader.getErr() != 0) &#123; rc = p.replyHeader.getErr(); &#125; if (p.cb == null) &#123; &#125; else if (p.response instanceof ExistsResponse || p.response instanceof SetDataResponse || p.response instanceof SetACLResponse) &#123; StatCallback cb = (StatCallback) p.cb; if (rc == 0) &#123; if (p.response instanceof ExistsResponse) &#123; cb.processResult(rc, clientPath, p.ctx, ((ExistsResponse) p.response).getStat()); &#125; else if (p.response instanceof SetDataResponse) &#123; cb.processResult(rc, clientPath, p.ctx, ((SetDataResponse) p.response).getStat()); &#125; else if (p.response instanceof SetACLResponse) &#123; cb.processResult(rc, clientPath, p.ctx, ((SetACLResponse) p.response).getStat()); &#125; &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null); &#125; &#125; else if (p.response instanceof GetDataResponse) &#123; DataCallback cb = (DataCallback) p.cb; GetDataResponse rsp = (GetDataResponse) p.response; if (rc == 0) &#123; cb.processResult(rc, clientPath, p.ctx, rsp.getData(), rsp.getStat()); &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null, null); &#125; &#125; else if (p.response instanceof GetACLResponse) &#123; ACLCallback cb = (ACLCallback) p.cb; GetACLResponse rsp = (GetACLResponse) p.response; if (rc == 0) &#123; cb.processResult(rc, clientPath, p.ctx, rsp.getAcl(), rsp.getStat()); &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null, null); &#125; &#125; else if (p.response instanceof GetChildrenResponse) &#123; ChildrenCallback cb = (ChildrenCallback) p.cb; GetChildrenResponse rsp = (GetChildrenResponse) p.response; if (rc == 0) &#123; cb.processResult(rc, clientPath, p.ctx, rsp.getChildren()); &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null); &#125; &#125; else if (p.response instanceof GetChildren2Response) &#123; Children2Callback cb = (Children2Callback) p.cb; GetChildren2Response rsp = (GetChildren2Response) p.response; if (rc == 0) &#123; cb.processResult(rc, clientPath, p.ctx, rsp.getChildren(), rsp.getStat()); &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null, null); &#125; &#125; else if (p.response instanceof CreateResponse) &#123; StringCallback cb = (StringCallback) p.cb; CreateResponse rsp = (CreateResponse) p.response; if (rc == 0) &#123; cb.processResult(rc, clientPath, p.ctx, (chrootPath == null ? rsp.getPath() : rsp.getPath().substring(chrootPath.length()))); &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null); &#125; &#125; else if (p.response instanceof Create2Response) &#123; Create2Callback cb = (Create2Callback) p.cb; Create2Response rsp = (Create2Response) p.response; if (rc == 0) &#123; cb.processResult(rc, clientPath, p.ctx, (chrootPath == null ? rsp.getPath() : rsp.getPath().substring(chrootPath.length())), rsp.getStat()); &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null, null); &#125; &#125; else if (p.response instanceof MultiResponse) &#123; MultiCallback cb = (MultiCallback) p.cb; MultiResponse rsp = (MultiResponse) p.response; if (rc == 0) &#123; List&lt;OpResult&gt; results = rsp.getResultList(); int newRc = rc; for (OpResult result : results) &#123; if (result instanceof ErrorResult &amp;&amp; KeeperException.Code.OK.intValue() != (newRc = ((ErrorResult) result).getErr())) &#123; break; &#125; &#125; cb.processResult(newRc, clientPath, p.ctx, results); &#125; else &#123; cb.processResult(rc, clientPath, p.ctx, null); &#125; &#125; else if (p.cb instanceof VoidCallback) &#123; VoidCallback cb = (VoidCallback) p.cb; cb.processResult(rc, clientPath, p.ctx); &#125; &#125; &#125; catch (Throwable t) &#123;&#125; &#125;&#125; Create对于创建节点将数据和serverPath等数据封装到CreateRequest中，调用ClientCnxn的submitRequest方法，将Request封装到packet中，将packet放入发送队列outgoingQueue阻塞队列中等待发送，然后调用ClientCnxnSocketNIO的packetAdded方法唤醒阻塞在selector的select方法上的线程，将待发送队列outgoingQueue中的命令数据发给服务端。然后调用Packet的wait方法阻塞等待Server返回，最终被SendThread的doIO的isReadable逻辑中执行finishPacket方法中调用Packet的notifyAll方法唤醒。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class ZooKeeper implements AutoCloseable &#123; public String create(final String path, byte data[], List&lt;ACL&gt; acl, CreateMode createMode) throws KeeperException, InterruptedException &#123; final String clientPath = path; PathUtils.validatePath(clientPath, createMode.isSequential()); EphemeralType.validateTTL(createMode, -1); final String serverPath = prependChroot(clientPath); RequestHeader h = new RequestHeader(); h.setType(createMode.isContainer() ? ZooDefs.OpCode.createContainer : ZooDefs.OpCode.create); CreateRequest request = new CreateRequest(); CreateResponse response = new CreateResponse(); request.setData(data); request.setFlags(createMode.toFlag()); request.setPath(serverPath); if (acl != null &amp;&amp; acl.size() == 0) &#123; throw new KeeperException.InvalidACLException(); &#125; request.setAcl(acl); ReplyHeader r = cnxn.submitRequest(h, request, response, null); if (r.getErr() != 0) &#123; throw KeeperException.create(KeeperException.Code.get(r.getErr()), clientPath); &#125; if (cnxn.chrootPath == null) &#123; return response.getPath(); &#125; else &#123; return response.getPath().substring(cnxn.chrootPath.length()); &#125; &#125;&#125;public class ClientCnxn &#123; public ReplyHeader submitRequest(RequestHeader h, Record request, Record response, WatchRegistration watchRegistration) throws InterruptedException &#123; return submitRequest(h, request, response, watchRegistration, null); &#125; public ReplyHeader submitRequest(RequestHeader h, Record request, Record response, WatchRegistration watchRegistration, WatchDeregistration watchDeregistration) throws InterruptedException &#123; ReplyHeader r = new ReplyHeader(); // 将Request封装到packet中，将packet放入发送队列outgoingQueue中等待发送 Packet packet = queuePacket(h, r, request, response, null, null, null, null, watchRegistration, watchDeregistration); synchronized (packet) &#123; if (requestTimeout &gt; 0) &#123; // Wait for request completion with timeout waitForPacketFinish(r, packet); &#125; else &#123; // Wait for request completion infinitely while (!packet.finished) &#123; packet.wait(); // 等待Server返回，最终会被SendThread的doIO的isReadable逻辑中执行finishPacket方法唤醒 &#125; &#125; &#125; if (r.getErr() == Code.REQUESTTIMEOUT.intValue()) &#123; sendThread.cleanAndNotifyState(); &#125; return r; &#125; public Packet queuePacket(RequestHeader h, ReplyHeader r, Record request, Record response, AsyncCallback cb, String clientPath, String serverPath, Object ctx, WatchRegistration watchRegistration, WatchDeregistration watchDeregistration) &#123; Packet packet = null; // request中有一个是否监听的watch属性传到服务端，服务端根据该属性做对应监听处理 packet = new Packet(h, r, request, response, watchRegistration); packet.cb = cb; packet.ctx = ctx; packet.clientPath = clientPath; packet.serverPath = serverPath; packet.watchDeregistration = watchDeregistration; synchronized (state) &#123; if (!state.isAlive() || closing) &#123; conLossPacket(packet); &#125; else &#123; if (h.getType() == OpCode.closeSession) &#123; closing = true; &#125; outgoingQueue.add(packet); // 将发送数据包放入outgoingQueue阻塞队列 &#125; &#125; // 用于唤醒阻塞在select方法上的线程，为了出发写事件，底层会往管道中写一个字节，写事件出发后会将待发送队列中的命令数据发给服务端 sendThread.getClientCnxnSocket().packetAdded(); return packet; &#125;&#125; getData1234567891011121314151617181920212223242526272829public class ZooKeeper implements AutoCloseable &#123; public byte[] getData(String path, boolean watch, Stat stat) throws KeeperException, InterruptedException &#123; return getData(path, watch ? watchManager.defaultWatcher : null, stat); &#125; public byte[] getData(final String path, Watcher watcher, Stat stat) throws KeeperException, InterruptedException &#123; final String clientPath = path; PathUtils.validatePath(clientPath); // the watch contains the un-chroot path WatchRegistration wcb = null; if (watcher != null) &#123; wcb = new DataWatchRegistration(watcher, clientPath); &#125; final String serverPath = prependChroot(clientPath); RequestHeader h = new RequestHeader(); h.setType(ZooDefs.OpCode.getData); GetDataRequest request = new GetDataRequest(); request.setPath(serverPath); request.setWatch(watcher != null); // 是否注册监听器 GetDataResponse response = new GetDataResponse(); ReplyHeader r = cnxn.submitRequest(h, request, response, wcb); if (r.getErr() != 0) &#123; throw KeeperException.create(KeeperException.Code.get(r.getErr()), clientPath); &#125; if (stat != null) &#123; DataTree.copyStat(response.getStat(), stat); &#125; return response.getData(); &#125;&#125; 服务端最终通过FinalRequestProcessor的processRequest调用ZKDatabase的getData方法获取数据，若客户端请求时watch为true，则Watcher不为null则将其添加到dataWatches中。若发生数据变更时则调用WatchManager的triggerWatch方法触发监听机制。 12345678910111213141516171819202122232425262728293031323334353637public class ZKDatabase &#123; public byte[] getData(String path, Stat stat, Watcher watcher) throws KeeperException.NoNodeException &#123; return dataTree.getData(path, stat, watcher); &#125;&#125;public class DataTree &#123; public byte[] getData(String path, Stat stat, Watcher watcher) throws KeeperException.NoNodeException &#123; DataNode n = nodes.get(path); if (n == null) &#123; throw new KeeperException.NoNodeException(); &#125; synchronized (n) &#123; n.copyStat(stat); if (watcher != null) &#123; dataWatches.addWatch(path, watcher); &#125; return n.data; &#125; &#125;&#125;class WatchManager &#123; synchronized void addWatch(String path, Watcher watcher) &#123; HashSet&lt;Watcher&gt; list = watchTable.get(path); if (list == null) &#123; list = new HashSet&lt;Watcher&gt;(4); watchTable.put(path, list); &#125; list.add(watcher); HashSet&lt;String&gt; paths = watch2Paths.get(watcher); if (paths == null) &#123; paths = new HashSet&lt;String&gt;(); watch2Paths.put(watcher, paths); &#125; paths.add(path); &#125;&#125; triggerWatch触发监听机制首先将该路径对应的监听器移除，然后调用每个监听器对应客户端对应的NettyServerCnxn的process方法通知客户端节点变更，客户端收到通知会触发监听回调方法。监听的回调方法并没有注册到服务端，只是将监听路径注册到了服务端，当服务端发生数据变更时，遍历监听的路径回发给客户端，客户端通过路径匹配到对应的监听器回调方法完成回调。 12345678910111213141516171819202122232425262728293031323334353637383940class WatchManager &#123; Set&lt;Watcher&gt; triggerWatch(String path, EventType type) &#123; return triggerWatch(path, type, null); &#125; Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) &#123; WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); HashSet&lt;Watcher&gt; watchers; synchronized (this) &#123; watchers = watchTable.remove(path); // 一次性监听体现 if (watchers == null || watchers.isEmpty()) &#123; return null; &#125; for (Watcher w : watchers) &#123; HashSet&lt;String&gt; paths = watch2Paths.get(w); if (paths != null) &#123; paths.remove(path); &#125; &#125; &#125; for (Watcher w : watchers) &#123; if (supress != null &amp;&amp; supress.contains(w)) &#123; continue; &#125; w.process(e); // 调用NettyServerCnxn的process方法节点变更通知客户端，客户端收到通知会触发监听回调方法调用 &#125; return watchers; &#125;&#125;public class NettyServerCnxn extends ServerCnxn &#123; public void process(WatchedEvent event) &#123; ReplyHeader h = new ReplyHeader(-1, -1L, 0); // Convert WatchedEvent to a type that can be sent over the wire WatcherEvent e = event.getWrapper(); try &#123; sendResponse(h, e, \"notification\"); &#125; catch (IOException e1) &#123; close(); &#125; &#125;&#125;","tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://yaoyinglong.github.io/tags/Zookeeper/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Zookeeper","slug":"Cloud/Zookeeper","permalink":"https://yaoyinglong.github.io/categories/Cloud/Zookeeper/"}]},{"title":"Zookeeper服务端之ZAB","date":"2021-12-19T16:00:00.000Z","path":"Blog/Cloud/Zookeeper/Zookeeper服务端之ZAB/","text":"服务端处理客户端的请求入口是通过NettyServerCnxnFactory无产构造函数中启动Netty服务端时绑定的CnxnChannelHandler的channelRead方法。该构造方法是集群启动时通过QuorumPeerMain的runFromConfig中调用ServerCnxnFactory.createFactory()反射调用。 当收到客户端请求后CnxnChannelHandler的channelRead方法中调用NettyServerCnxn的processMessage方法从而调用receiveMessage方法，将数据读到ByteBuffer中，然后调用ZooKeeperServer的processPacket处理数据包，最终在submitRequest方法中通过执行firstProcessor的processRequest方法执行请求处理链。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220public class NettyServerCnxnFactory extends ServerCnxnFactory &#123; CnxnChannelHandler channelHandler = new CnxnChannelHandler(); NettyServerCnxnFactory() &#123; x509Util = new ClientX509Util(); boolean usePortUnification = Boolean.getBoolean(PORT_UNIFICATION_KEY); if (usePortUnification) &#123; try &#123; QuorumPeerConfig.configureSSLAuth(); &#125; catch (QuorumPeerConfig.ConfigException e) &#123; usePortUnification = false; &#125; &#125; this.shouldUsePortUnification = usePortUnification; // 初始化Netty线程组 EventLoopGroup bossGroup = NettyUtils.newNioOrEpollEventLoopGroup(NettyUtils.getClientReachableLocalInetAddressCount()); EventLoopGroup workerGroup = NettyUtils.newNioOrEpollEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap() .group(bossGroup, workerGroup) .channel(NettyUtils.nioOrEpollServerSocketChannel()) .option(ChannelOption.SO_REUSEADDR, true) // parent channel options .childOption(ChannelOption.TCP_NODELAY, true) // child channels options .childOption(ChannelOption.SO_LINGER, -1) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); if (secure) &#123; initSSL(pipeline, false); &#125; else if (shouldUsePortUnification) &#123; initSSL(pipeline, true); &#125; pipeline.addLast(\"servercnxnfactory\", channelHandler); // 绑定业务处理CnxnChannelHandler &#125; &#125;); this.bootstrap = configureBootstrapAllocator(bootstrap); this.bootstrap.validate(); &#125;&#125;class CnxnChannelHandler extends ChannelDuplexHandler &#123; public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; try &#123; try &#123; NettyServerCnxn cnxn = ctx.channel().attr(CONNECTION_ATTRIBUTE).get(); if (cnxn == null) &#123; &#125; else &#123; cnxn.processMessage((ByteBuf) msg); // 客户端执行命令最终调用该方法 &#125; &#125; catch (Exception ex) &#123; throw ex; &#125; &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125;&#125;public class NettyServerCnxn extends ServerCnxn &#123; void processMessage(ByteBuf buf) &#123; checkIsInEventLoop(\"processMessage\"); if (throttled.get()) &#123; if (queuedBuffer == null) &#123; queuedBuffer = channel.alloc().compositeBuffer(); &#125; appendToQueuedBuffer(buf.retainedDuplicate()); &#125; else &#123; if (queuedBuffer != null) &#123; appendToQueuedBuffer(buf.retainedDuplicate()); processQueuedBuffer(); &#125; else &#123; receiveMessage(buf); // 处理客户端命令 if (!closingChannel &amp;&amp; buf.isReadable()) &#123; if (queuedBuffer == null) &#123; queuedBuffer = channel.alloc().compositeBuffer(); &#125; appendToQueuedBuffer(buf.retainedSlice(buf.readerIndex(), buf.readableBytes())); &#125; &#125; &#125; &#125; private void receiveMessage(ByteBuf message) &#123; try &#123; while(message.isReadable() &amp;&amp; !throttled.get()) &#123; if (bb != null) &#123; if (LOG.isTraceEnabled()) &#123; ByteBuffer dat = bb.duplicate(); dat.flip(); &#125; if (bb.remaining() &gt; message.readableBytes()) &#123; int newLimit = bb.position() + message.readableBytes(); bb.limit(newLimit); &#125; message.readBytes(bb); bb.limit(bb.capacity()); if (LOG.isTraceEnabled()) &#123; ByteBuffer dat = bb.duplicate(); dat.flip(); &#125; if (bb.remaining() == 0) &#123; packetReceived(); bb.flip(); ZooKeeperServer zks = this.zkServer; if (zks == null || !zks.isRunning()) &#123; throw new IOException(\"ZK down\"); &#125; if (initialized) &#123; zks.processPacket(this, bb); if (zks.shouldThrottle(outstandingCount.incrementAndGet())) &#123; disableRecvNoWait(); &#125; &#125; else &#123; zks.processConnectRequest(this, bb); initialized = true; &#125; bb = null; &#125; &#125; else &#123; if (LOG.isTraceEnabled()) &#123; ByteBuffer dat = bbLen.duplicate(); dat.flip(); &#125; if (message.readableBytes() &lt; bbLen.remaining()) &#123; bbLen.limit(bbLen.position() + message.readableBytes()); &#125; message.readBytes(bbLen); bbLen.limit(bbLen.capacity()); if (bbLen.remaining() == 0) &#123; bbLen.flip(); int len = bbLen.getInt(); bbLen.clear(); if (!initialized) &#123; if (checkFourLetterWord(channel, message, len)) &#123; return; &#125; &#125; if (len &lt; 0 || len &gt; BinaryInputArchive.maxBuffer) &#123; throw new IOException(\"Len error \" + len); &#125; bb = ByteBuffer.allocate(len); &#125; &#125; &#125; &#125; catch(IOException e) &#123; close(); &#125; &#125;&#125;public class ZooKeeperServer implements SessionExpirer, ServerStats.Provider &#123; public void processPacket(ServerCnxn cnxn, ByteBuffer incomingBuffer) throws IOException &#123; InputStream bais = new ByteBufferInputStream(incomingBuffer); BinaryInputArchive bia = BinaryInputArchive.getArchive(bais); RequestHeader h = new RequestHeader(); h.deserialize(bia, \"header\"); incomingBuffer = incomingBuffer.slice(); if (h.getType() == OpCode.auth) &#123; AuthPacket authPacket = new AuthPacket(); ByteBufferInputStream.byteBuffer2Record(incomingBuffer, authPacket); String scheme = authPacket.getScheme(); AuthenticationProvider ap = ProviderRegistry.getProvider(scheme); Code authReturn = KeeperException.Code.AUTHFAILED; if (ap != null) &#123; try &#123; authReturn = ap.handleAuthentication(cnxn, authPacket.getAuth()); &#125; catch (RuntimeException e) &#123; authReturn = KeeperException.Code.AUTHFAILED; &#125; &#125; if (authReturn == KeeperException.Code.OK) &#123; ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.OK.intValue()); cnxn.sendResponse(rh, null, null); &#125; else &#123; ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.AUTHFAILED.intValue()); cnxn.sendResponse(rh, null, null); cnxn.sendBuffer(ServerCnxnFactory.closeConn); cnxn.disableRecv(); &#125; return; &#125; else &#123; if (h.getType() == OpCode.sasl) &#123; Record rsp = processSasl(incomingBuffer, cnxn); ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.OK.intValue()); cnxn.sendResponse(rh, rsp, \"response\"); // not sure about 3rd arg..what is it? return; &#125; else &#123; Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(), h.getType(), incomingBuffer, cnxn.getAuthInfo()); si.setOwner(ServerCnxn.me); setLocalSessionFlag(si); submitRequest(si); &#125; &#125; cnxn.incrOutstandingRequests(h); &#125; public void submitRequest(Request si) &#123; if (firstProcessor == null) &#123; synchronized (this) &#123; try &#123; while (state == State.INITIAL) &#123; wait(1000); &#125; &#125; catch (InterruptedException e) &#123; &#125; if (firstProcessor == null || state != State.RUNNING) &#123; throw new RuntimeException(\"Not started\"); &#125; &#125; &#125; try &#123; touch(si.cnxn); boolean validpacket = Request.isValid(si.type); if (validpacket) &#123; firstProcessor.processRequest(si); if (si.cnxn != null) &#123; incInProcess(); &#125; &#125; else &#123; new UnimplementedRequestProcessor().processRequest(si); &#125; &#125; catch (MissingSessionException e) &#123; &#125; catch (RequestProcessorException e) &#123; &#125; &#125;&#125; 若是单机则是通过ZooKeeperServerMain的runFromConfig中调用ServerCnxnFactory的startup方法，最终调用子类NettyServerCnxnFactory的startup方法从而调用ZooKeeperServer子类LeaderZooKeeperServer的startup方法从而调用其setupRequestProcessors方法完成Leader请求处理链加载。若为集群则是在Leader选举出来后通过Leader的lead方法中调用startZkServer从而调用ZooKeeperServer子类LeaderZooKeeperServer的startup方法从而调用其setupRequestProcessors方法完成Leader请求处理链加载。 最终产生的请求处理链为LeaderRequestProcessor、PrepRequestProcessor、ProposalRequestProcessor、CommitProcessor、ToBeAppliedRequestProcessor、FinalRequestProcessor。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Leader &#123; private synchronized void startZkServer() &#123; lastCommitted = zk.getZxid(); QuorumVerifier newQV = self.getLastSeenQuorumVerifier(); Long designatedLeader = getDesignatedLeader(newLeaderProposal, zk.getZxid()); self.processReconfig(newQV, designatedLeader, zk.getZxid(), true); if (designatedLeader != self.getId()) &#123; allowedToCommit = false; &#125; zk.startup(); // 加载 self.updateElectionVote(getEpoch()); zk.getZKDatabase().setlastProcessedZxid(zk.getZxid()); &#125;&#125;public class LeaderZooKeeperServer extends QuorumZooKeeperServer &#123; public synchronized void startup() &#123; super.startup(); if (containerManager != null) &#123; containerManager.start(); &#125; &#125; protected void setupRequestProcessors() &#123; RequestProcessor finalProcessor = new FinalRequestProcessor(this); RequestProcessor toBeAppliedProcessor = new Leader.ToBeAppliedRequestProcessor(finalProcessor, getLeader()); commitProcessor = new CommitProcessor(toBeAppliedProcessor, Long.toString(getServerId()), false, getZooKeeperServerListener()); commitProcessor.start(); ProposalRequestProcessor proposalProcessor = new ProposalRequestProcessor(this, commitProcessor); proposalProcessor.initialize(); prepRequestProcessor = new PrepRequestProcessor(this, proposalProcessor); prepRequestProcessor.start(); firstProcessor = new LeaderRequestProcessor(this, prepRequestProcessor); setupContainerManager(); &#125;&#125;public class ZooKeeperServer implements SessionExpirer, ServerStats.Provider &#123; public synchronized void startup() &#123; if (sessionTracker == null) &#123; createSessionTracker(); &#125; startSessionTracker(); setupRequestProcessors(); // 回调子类LeaderZooKeeperServer的setupRequestProcessors方法 registerJMX(); setState(State.RUNNING); notifyAll(); &#125;&#125; LeaderRequestProcessor首先执行LeaderRequestProcessor的processRequest方法完成检查处理Session，然后继续调用PrepRequestProcessor。 12345678910111213141516171819public class LeaderRequestProcessor implements RequestProcessor &#123; public void processRequest(Request request) throws RequestProcessorException &#123; Request upgradeRequest = null; try &#123; upgradeRequest = lzks.checkUpgradeSession(request); // 检查处理Session &#125; catch (KeeperException ke) &#123; if (request.getHdr() != null) &#123; request.getHdr().setType(OpCode.error); request.setTxn(new ErrorTxn(ke.code().intValue())); &#125; request.setException(ke); &#125; catch (IOException ie) &#123; &#125; if (upgradeRequest != null) &#123; nextProcessor.processRequest(upgradeRequest); &#125; nextProcessor.processRequest(request); &#125;&#125; PrepRequestProcessor调用PrepRequestProcessor的processRequest方法只是将请求任务放入submittedRequests阻塞队列中，PrepRequestProcessor本身是一个线程类，在LeaderZooKeeperServer中创建时就被启动，当队列中有数据时通过pRequest方法根据OpCode执行对应的逻辑，主要是做一些校验，若有变化则将其其添加到ZooKeeperServer的outstandingChanges队列中，然后调用下一个处理器ProposalRequestProcessor，生成事务zxid处理客户端命令逻辑是单线程从队列中拿数据处理保证事务处理的顺序一致性，且只在主节点调用ZooKeeperServer的getNextZxid方法通过AtomicLong自增得到事务zxid。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public class PrepRequestProcessor extends ZooKeeperCriticalThread implements RequestProcessor &#123; LinkedBlockingQueue&lt;Request&gt; submittedRequests = new LinkedBlockingQueue&lt;Request&gt;(); public void processRequest(Request request) &#123; submittedRequests.add(request); &#125; public void run() &#123; try &#123; while (true) &#123; // 单线程处理 Request request = submittedRequests.take(); long traceMask = ZooTrace.CLIENT_REQUEST_TRACE_MASK; if (request.type == OpCode.ping) &#123; traceMask = ZooTrace.CLIENT_PING_TRACE_MASK; &#125; if (Request.requestOfDeath == request) &#123; break; &#125; pRequest(request); &#125; &#125; catch (RequestProcessorException e) &#123; handleException(this.getName(), e); &#125; catch (Exception e) &#123; handleException(this.getName(), e); &#125; &#125; protected void pRequest(Request request) throws RequestProcessorException &#123; request.setHdr(null); request.setTxn(null); try &#123; switch (request.type) &#123; case OpCode.createContainer: case OpCode.create: case OpCode.create2: CreateRequest create2Request = new CreateRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, create2Request, true); break; case OpCode.createTTL: CreateTTLRequest createTtlRequest = new CreateTTLRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, createTtlRequest, true); break; case OpCode.deleteContainer: case OpCode.delete: DeleteRequest deleteRequest = new DeleteRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, deleteRequest, true); break; case OpCode.setData: SetDataRequest setDataRequest = new SetDataRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, setDataRequest, true); break; case OpCode.reconfig: ReconfigRequest reconfigRequest = new ReconfigRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, reconfigRequest); pRequest2Txn(request.type, zks.getNextZxid(), request, reconfigRequest, true); break; case OpCode.setACL: SetACLRequest setAclRequest = new SetACLRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, setAclRequest, true); break; case OpCode.check: CheckVersionRequest checkRequest = new CheckVersionRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, checkRequest, true); break; case OpCode.multi: MultiTransactionRecord multiRequest = new MultiTransactionRecord(); try &#123; ByteBufferInputStream.byteBuffer2Record(request.request, multiRequest); &#125; catch(IOException e) &#123; request.setHdr(new TxnHeader(request.sessionId, request.cxid, zks.getNextZxid(), Time.currentWallTime(), OpCode.multi)); throw e; &#125; List&lt;Txn&gt; txns = new ArrayList&lt;Txn&gt;(); long zxid = zks.getNextZxid(); KeeperException ke = null; Map&lt;String, ChangeRecord&gt; pendingChanges = getPendingChanges(multiRequest); for(Op op: multiRequest) &#123; Record subrequest = op.toRequestRecord(); int type; Record txn; if (ke != null) &#123; type = OpCode.error; txn = new ErrorTxn(Code.RUNTIMEINCONSISTENCY.intValue()); &#125; else &#123; /* Prep the request and convert to a Txn */ try &#123; pRequest2Txn(op.getType(), zxid, request, subrequest, false); type = request.getHdr().getType(); txn = request.getTxn(); &#125; catch (KeeperException e) &#123; ke = e; type = OpCode.error; txn = new ErrorTxn(e.code().intValue()); request.setException(e); rollbackPendingChanges(zxid, pendingChanges); &#125; &#125; ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); txn.serialize(boa, \"request\") ; ByteBuffer bb = ByteBuffer.wrap(baos.toByteArray()); txns.add(new Txn(type, bb.array())); &#125; request.setHdr(new TxnHeader(request.sessionId, request.cxid, zxid, Time.currentWallTime(), request.type)); request.setTxn(new MultiTxn(txns)); break; case OpCode.createSession: case OpCode.closeSession: if (!request.isLocalSession()) &#123; pRequest2Txn(request.type, zks.getNextZxid(), request, null, true); &#125; break; case OpCode.sync: case OpCode.exists: case OpCode.getData: case OpCode.getACL: case OpCode.getChildren: case OpCode.getChildren2: case OpCode.ping: case OpCode.setWatches: case OpCode.checkWatches: case OpCode.removeWatches: zks.sessionTracker.checkSession(request.sessionId, request.getOwner()); break; default: break; &#125; &#125; catch (KeeperException e) &#123; if (request.getHdr() != null) &#123; request.getHdr().setType(OpCode.error); request.setTxn(new ErrorTxn(e.code().intValue())); &#125; request.setException(e); &#125; catch (Exception e) &#123; StringBuilder sb = new StringBuilder(); ByteBuffer bb = request.request; if(bb != null)&#123; bb.rewind(); while (bb.hasRemaining()) &#123; sb.append(Integer.toHexString(bb.get() &amp; 0xff)); &#125; &#125; else &#123; sb.append(\"request buffer is null\"); &#125; if (request.getHdr() != null) &#123; request.getHdr().setType(OpCode.error); request.setTxn(new ErrorTxn(Code.MARSHALLINGERROR.intValue())); &#125; &#125; request.zxid = zks.getZxid(); nextProcessor.processRequest(request); &#125;&#125;public class ZooKeeperServer implements SessionExpirer, ServerStats.Provider &#123; private final AtomicLong hzxid = new AtomicLong(0); long getNextZxid() &#123; return hzxid.incrementAndGet(); &#125;&#125; ProposalRequestProcessorProposalRequestProcessor主要完成三件事，首先调用CommitProcessor，然后给所有follower发送proposal，最后将数据存储到本机日志文件中。若是getData等不涉及事务变更的请求，则其Request的hdr属性为空，则直接跳过给follower发送proposal以及将数据保存到本机日志文件中的步骤。 给所有follower发送proposal是通过调用Leader的propose方法，首先封装要发送给follower的proposal，然后遍历所有follower发送packet，实际是将packet放入各自follower对应LearnerHandler的queuedPackets阻塞队列中。队列中的数据最终被各自的LearnerHandler线程中调用startSendingPackets方法启动一个新线程完成队列的消费从而给follower发送proposal。LearnerHandler线程是在选举完成后Leader的lead方法中LearnerCnxAcceptor线程启动中启动。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class ProposalRequestProcessor implements RequestProcessor &#123; public ProposalRequestProcessor(LeaderZooKeeperServer zks, RequestProcessor nextProcessor) &#123; this.zks = zks; this.nextProcessor = nextProcessor; AckRequestProcessor ackProcessor = new AckRequestProcessor(zks.getLeader()); syncProcessor = new SyncRequestProcessor(zks, ackProcessor); &#125; public void initialize() &#123; syncProcessor.start(); &#125; public void processRequest(Request request) throws RequestProcessorException &#123; if (request instanceof LearnerSyncRequest)&#123; zks.getLeader().processSync((LearnerSyncRequest)request); &#125; else &#123; nextProcessor.processRequest(request); // 调用CommitProcessor if (request.getHdr() != null) &#123; // 若为getData等不需要同步数据的请求则跳过以下两步 try &#123; zks.getLeader().propose(request); // 给所有follower发送propose &#125; catch (XidRolloverException e) &#123; throw new RequestProcessorException(e.getMessage(), e); &#125; syncProcessor.processRequest(request); // 将数据存储到本机日志文件中，ACK处理 &#125; &#125; &#125;&#125;public class Leader &#123; public Proposal propose(Request request) throws XidRolloverException &#123; if ((request.zxid &amp; 0xffffffffL) == 0xffffffffL) &#123; String msg = \"zxid lower 32 bits have rolled over, forcing re-election, and therefore new epoch start\"; shutdown(msg); throw new XidRolloverException(msg); &#125; byte[] data = SerializeUtils.serializeRequest(request); proposalStats.setLastBufferSize(data.length); QuorumPacket pp = new QuorumPacket(Leader.PROPOSAL, request.zxid, data, null); Proposal p = new Proposal(); p.packet = pp; p.request = request; synchronized(this) &#123; p.addQuorumVerifier(self.getQuorumVerifier()); if (request.getHdr().getType() == OpCode.reconfig)&#123; self.setLastSeenQuorumVerifier(request.qv, true); &#125; if (self.getQuorumVerifier().getVersion()&lt;self.getLastSeenQuorumVerifier().getVersion()) &#123; p.addQuorumVerifier(self.getLastSeenQuorumVerifier()); &#125; lastProposed = p.packet.getZxid(); outstandingProposals.put(lastProposed, p); sendPacket(pp); // 遍历follower放入其对应的阻塞队列中 &#125; return p; &#125; void sendPacket(QuorumPacket qp) &#123; synchronized (forwardingFollowers) &#123; for (LearnerHandler f : forwardingFollowers) &#123; f.queuePacket(qp); // 将Proposal放入对应阻塞队列中 &#125; &#125; &#125;&#125;public class LearnerHandler extends ZooKeeperThread &#123; protected void startSendingPackets() &#123; if (!sendingThreadStarted) &#123; // Start sending packets new Thread() &#123; public void run() &#123; Thread.currentThread().setName(\"Sender-\" + sock.getRemoteSocketAddress()); try &#123; sendPackets(); // 从队列中取出Proposal发送给对应的follower &#125; catch (InterruptedException e) &#123;&#125; &#125; &#125;.start(); sendingThreadStarted = true; &#125; &#125; private void sendPackets() throws InterruptedException &#123; long traceMask = ZooTrace.SERVER_PACKET_TRACE_MASK; while (true) &#123; try &#123; QuorumPacket p; p = queuedPackets.poll(); // 从队列中拿packet发给follower if (p == null) &#123; bufferedOutput.flush(); p = queuedPackets.take(); &#125; if (p == proposalOfDeath) &#123;// Packet of death! break; &#125; if (p.getType() == Leader.PING) &#123; traceMask = ZooTrace.SERVER_PING_TRACE_MASK; &#125; if (p.getType() == Leader.PROPOSAL) &#123; syncLimitCheck.updateProposal(p.getZxid(), System.nanoTime()); &#125; if (LOG.isTraceEnabled()) &#123; ZooTrace.logQuorumPacket(LOG, traceMask, 'o', p); &#125; oa.writeRecord(p, \"packet\"); // 使用jute序列化方式发给follower &#125; catch (IOException e) &#123; if (!sock.isClosed()) &#123; try &#123; sock.close(); &#125; catch(IOException ie) &#123; &#125; &#125; break; &#125; &#125; &#125;&#125; 将数据存储到本机日志文件中是通过在ProposalRequestProcessor构造方法中创建的SyncRequestProcessor和AckRequestProcessor来完成。SyncRequestProcessor也是线程类通过ProposalRequestProcessor的initialize方法启动。 调用SyncRequestProcessor的processRequest方法只是将Request放入到阻塞队列中。通过其run方法异步处理，将其更新到事务日志文件中，若是Leader则调用AckRequestProcessor从而调用Leader的processAck方法，通过addAck方法将当前节点ACK放入qvAcksetPairs中，然后调用tryToCommit方法判断收到的ACK是否超过半数，若未超过则退出，若超过则向所有follower发送commit命令且向Observer发送proposal，最后唤醒CommitProcessor线程的wait等待。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169public class SyncRequestProcessor extends ZooKeeperCriticalThread implements RequestProcessor &#123; public void processRequest(Request request) &#123; queuedRequests.add(request); &#125; public void run() &#123; try &#123; int logCount = 0; int randRoll = r.nextInt(snapCount/2); while (true) &#123; Request si = null; if (toFlush.isEmpty()) &#123; si = queuedRequests.take(); &#125; else &#123; si = queuedRequests.poll(); if (si == null) &#123; flush(toFlush); continue; &#125; &#125; if (si == requestOfDeath) &#123; // 若为失效请求则直接退出 break; &#125; if (si != null) &#123;// track the number of records written to the log if (zks.getZKDatabase().append(si)) &#123;// 添加到事务日志文件中 logCount++; if (logCount &gt; (snapCount / 2 + randRoll)) &#123; randRoll = r.nextInt(snapCount/2); zks.getZKDatabase().rollLog(); // roll the log if (snapInProcess != null &amp;&amp; snapInProcess.isAlive()) &#123; // take a snapshot &#125; else &#123; snapInProcess = new ZooKeeperThread(\"Snapshot Thread\") &#123; public void run() &#123; try &#123; zks.takeSnapshot(); &#125; catch(Exception e) &#123;&#125; &#125; &#125;; snapInProcess.start(); &#125; logCount = 0; &#125; &#125; else if (toFlush.isEmpty()) &#123; if (nextProcessor != null) &#123; nextProcessor.processRequest(si); if (nextProcessor instanceof Flushable) &#123; ((Flushable)nextProcessor).flush(); &#125; &#125; continue; &#125; toFlush.add(si); if (toFlush.size() &gt; 1000) &#123; flush(toFlush); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; handleException(this.getName(), t); &#125; finally&#123; running = false; &#125; &#125; private void flush(LinkedList&lt;Request&gt; toFlush) throws IOException, RequestProcessorException &#123; if (toFlush.isEmpty()) return; zks.getZKDatabase().commit(); while (!toFlush.isEmpty()) &#123; Request i = toFlush.remove(); if (nextProcessor != null) &#123; nextProcessor.processRequest(i); &#125; &#125; if (nextProcessor != null &amp;&amp; nextProcessor instanceof Flushable) &#123; ((Flushable) nextProcessor).flush(); &#125; &#125;&#125;class AckRequestProcessor implements RequestProcessor &#123; public void processRequest(Request request) &#123; QuorumPeer self = leader.self; if(self != null) leader.processAck(self.getId(), request.zxid, null); &#125;&#125;public class Leader &#123; synchronized public void processAck(long sid, long zxid, SocketAddress followerAddr) &#123; // 在LearnerHandler中当Leader接收到Follower的ACK时也会调用该方法 if (!allowedToCommit) return; // last op committed was a leader change - from now on if ((zxid &amp; 0xffffffffL) == 0) &#123; return; &#125; if (outstandingProposals.size() == 0) &#123; return; &#125; if (lastCommitted &gt;= zxid) &#123; // The proposal has already been committed return; &#125; Proposal p = outstandingProposals.get(zxid); // 在ProposalRequestProcessor中给给follower发送propose之前放入 if (p == null) &#123; return; &#125; p.addAck(sid); // leader节点直接将ack放入qvAcksetPairs中 boolean hasCommitted = tryToCommit(p, zxid, followerAddr); if (hasCommitted &amp;&amp; p.request != null &amp;&amp; p.request.getHdr().getType() == OpCode.reconfig) &#123; long curZxid = zxid; while (allowedToCommit &amp;&amp; hasCommitted &amp;&amp; p != null) &#123; curZxid++; p = outstandingProposals.get(curZxid); if (p != null) hasCommitted = tryToCommit(p, curZxid, null); &#125; &#125; &#125; synchronized public boolean tryToCommit(Proposal p, long zxid, SocketAddress followerAddr) &#123; if (outstandingProposals.containsKey(zxid - 1)) return false; if (!p.hasAllQuorums()) &#123; return false; // 若ACK未超过半数则直接返回false &#125; outstandingProposals.remove(zxid); if (p.request != null) &#123; toBeApplied.add(p); &#125; if (p.request == null) &#123; &#125; else if (p.request.getHdr().getType() == OpCode.reconfig) &#123; Long designatedLeader = getDesignatedLeader(p, zxid); QuorumVerifier newQV = p.qvAcksetPairs.get(p.qvAcksetPairs.size() - 1).getQuorumVerifier(); self.processReconfig(newQV, designatedLeader, zk.getZxid(), true); if (designatedLeader != self.getId()) &#123; allowedToCommit = false; &#125; commitAndActivate(zxid, designatedLeader); informAndActivate(p, designatedLeader); &#125; else &#123; commit(zxid); // 向follower发送commit命令 inform(p); // 向Observer同步发送proposal &#125; zk.commitProcessor.commit(p.request); // 唤醒CommitProcessor线程的wait等待 if (pendingSyncs.containsKey(zxid)) &#123; for (LearnerSyncRequest r : pendingSyncs.remove(zxid)) &#123; sendSync(r); &#125; &#125; return true; &#125; public void commit(long zxid) &#123; synchronized (this) &#123; lastCommitted = zxid; &#125; QuorumPacket qp = new QuorumPacket(Leader.COMMIT, zxid, null, null); sendPacket(qp); // 给所有follower发送COMMIT命令 &#125; public void inform(Proposal proposal) &#123; QuorumPacket qp = new QuorumPacket(Leader.INFORM, proposal.request.zxid, proposal.packet.getData(), null); sendObserverPacket(qp); &#125; void sendObserverPacket(QuorumPacket qp) &#123; for (LearnerHandler f : getObservingLearners()) &#123; f.queuePacket(qp); &#125; &#125;&#125;public class SyncedLearnerTracker &#123; public boolean addAck(Long sid) &#123; boolean change = false; for (QuorumVerifierAcksetPair qvAckset : qvAcksetPairs) &#123; if (qvAckset.getQuorumVerifier().getVotingMembers().containsKey(sid)) &#123; qvAckset.getAckset().add(sid); change = true; &#125; &#125; return change; &#125;&#125; CommitProcessor当调用CommitProcessor的processRequest方法时会将Request添加到queuedRequests阻塞队列中，通过run方法异步处理，首先明显queuedRequests不为null，正在等待提交的请求为null，正在提交的请求为null，故不会执行wait方法，若Request不需要commit如getData等命令，则直接往下执行下一个RequestProcessor，否则将其放入nextPending中，然后执行processCommitted方法时由于committedRequests为空则什么都不做，当再次执行while时，明显正在等待提交的请求不为null且committedRequests为空，则现场会被wait住。 当Leader收到的选票超过半数时在tryToCommit中调用CommitProcessor的commit方法将request放入committedRequests阻塞队列中且会唤醒CommitProcessor线程，然后执行processCommitted方法从而执行sendToNextProcessor，在CommitWorkRequest的doWork方法中调用下一个请求处理器ToBeAppliedRequestProcessor，且清除当前正在提交的请求。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class CommitProcessor extends ZooKeeperCriticalThread implements RequestProcessor &#123; // 在提交到来之前一直持有的请求 protected final LinkedBlockingQueue&lt;Request&gt; queuedRequests = new LinkedBlockingQueue&lt;Request&gt;(); // 已提交的请求 protected final LinkedBlockingQueue&lt;Request&gt; committedRequests = new LinkedBlockingQueue&lt;Request&gt;(); // 目前正在等待提交的请求 protected final AtomicReference&lt;Request&gt; nextPending = new AtomicReference&lt;Request&gt;(); // 当前正在提交的请求（即发送到下一个处理器） private final AtomicReference&lt;Request&gt; currentlyCommitting = new AtomicReference&lt;Request&gt;(); // 当前正在处理的请求数 protected AtomicInteger numRequestsProcessing = new AtomicInteger(0); public void processRequest(Request request) &#123; if (stopped) &#123; return; &#125; queuedRequests.add(request); if (!isWaitingForCommit()) &#123; wakeup(); // 目前正在等待提交的请求为null &#125; &#125; public void commit(Request request) &#123; // 被Leader的tryToCommit调用或被LearnerZooKeeperServer的commit方法调用 if (stopped || request == null) &#123; return; &#125; committedRequests.add(request); if (!isProcessingCommit()) &#123; // 正在提交的请求为null wakeup(); // 唤醒CommitProcessor线程的wait等待 &#125; &#125; public void run() &#123; Request request; try &#123; while (!stopped) &#123; synchronized (this) &#123; while (!stopped &amp;&amp; ((queuedRequests.isEmpty() || isWaitingForCommit() || isProcessingCommit()) &amp;&amp; (committedRequests.isEmpty() || isProcessingRequest()))) &#123; wait();// (提交的请求为空 | 正在等待提交的请求不为null | 正在提交的请求数不为null) &amp;&amp; (已提交的请求为null || 正在处理的请求数不为0) &#125; &#125; // 正在等待提交的请求为null &amp;&amp; 正在提交的请求为null &amp;&amp; 提交的请求不为null，queuedRequests是阻塞队列没有数据poll会被阻塞 while (!stopped &amp;&amp; !isWaitingForCommit() &amp;&amp; !isProcessingCommit() &amp;&amp; (request = queuedRequests.poll()) != null) &#123; if (needCommit(request)) &#123; nextPending.set(request); // 放入等待提交请求队列 &#125; else &#123; // 若是不需要执行commit的getData等命令直接往下走 sendToNextProcessor(request); &#125; &#125; processCommitted(); // 等待线程被唤醒后返回客户端结果以及写内存数据 &#125; &#125; catch (Throwable e) &#123; handleException(this.getName(), e); &#125; &#125; private void sendToNextProcessor(Request request) &#123; numRequestsProcessing.incrementAndGet(); // 当前正在处理的请求数加一 workerPool.schedule(new CommitWorkRequest(request), request.sessionId); &#125; protected void processCommitted() &#123; Request request; if (!stopped &amp;&amp; !isProcessingRequest() &amp;&amp; (committedRequests.peek() != null)) &#123; // 当前正在处理的请求数为0，且被提交的请求不为null if (!isWaitingForCommit() &amp;&amp; !queuedRequests.isEmpty()) &#123; return; // 正在等待提交的请求为null或queuedRequests中有新请求等待 &#125; request = committedRequests.poll(); // 与nextPending匹配，以便可以在提交时移动到下一个请求。还想使用nextPending，因为它正确设置了cnxn成员。 Request pending = nextPending.get(); if (pending != null &amp;&amp; pending.sessionId == request.sessionId &amp;&amp; pending.cxid == request.cxid) &#123; pending.setHdr(request.getHdr()); pending.setTxn(request.getTxn()); pending.zxid = request.zxid; currentlyCommitting.set(pending); nextPending.set(null); sendToNextProcessor(pending); &#125; else &#123; // 若请求来自其他人则只发送提交数据包 currentlyCommitting.set(request); sendToNextProcessor(request); &#125; &#125; &#125; private class CommitWorkRequest extends WorkerService.WorkRequest &#123; public void doWork() throws RequestProcessorException &#123; try &#123; nextProcessor.processRequest(request); // 调用下一个请求处理器ToBeAppliedRequestProcessor &#125; finally &#123; currentlyCommitting.compareAndSet(request, null); // 若此请求是阻塞处理器提交请求，则清除当前正在提交的请求 if (numRequestsProcessing.decrementAndGet() == 0) &#123; // 正在处理的请求数减一 if (!queuedRequests.isEmpty() || !committedRequests.isEmpty()) &#123; wakeup(); // 减少处理的请求计数，处理器目前可能被阻塞，因为它正在等待管道排空，该情况下若有待处理请求，则将其唤醒 &#125; &#125; &#125; &#125; &#125;&#125; ToBeAppliedRequestProcessorToBeAppliedRequestProcessor的下一个RequestProcessor必须是FinalRequestProcessor，其本身没有做什么事，将在请求从toBeApplied中移除，调用FinalRequestProcessor。 1234567891011121314151617181920212223static class ToBeAppliedRequestProcessor implements RequestProcessor &#123; ToBeAppliedRequestProcessor(RequestProcessor next, Leader leader) &#123; if (!(next instanceof FinalRequestProcessor)) &#123; throw new RuntimeException(ToBeAppliedRequestProcessor.class.getName() + \" must be connected to \" + FinalRequestProcessor.class.getName() + \" not \" + next.getClass().getName()); &#125; this.leader = leader; this.next = next; &#125; public void processRequest(Request request) throws RequestProcessorException &#123; next.processRequest(request);// 调用下一个请求处理器FinalRequestProcessor if (request.getHdr() != null) &#123; long zxid = request.getHdr().getZxid(); Iterator&lt;Proposal&gt; iter = leader.toBeApplied.iterator(); if (iter.hasNext()) &#123; Proposal p = iter.next(); if (p.request != null &amp;&amp; p.request.zxid == zxid) &#123; iter.remove(); // 将在请求从toBeApplied中移除 return; &#125; &#125; &#125; &#125;&#125; FinalRequestProcessorFinalRequestProcessor会将数据写入到内存中，这时客户端才可以真正查到该数据，当调用ZKDatabase的processTxn从而根据请求类型调用具体的方法将数据更新到DataTree时，会触发设置的监听器，最后将结果响应给客户端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327public class FinalRequestProcessor implements RequestProcessor &#123; public void processRequest(Request request) &#123; long traceMask = ZooTrace.CLIENT_REQUEST_TRACE_MASK; if (request.type == OpCode.ping) &#123; traceMask = ZooTrace.SERVER_PING_TRACE_MASK; &#125; ProcessTxnResult rc = null; synchronized (zks.outstandingChanges) &#123; // outstandingChanges数据是在PrepRequestProcessor中添加 rc = zks.processTxn(request); // 写数据到内存中，这这之后客户端节点才可以操作该数据 if (request.getHdr() != null) &#123; // request.hdr是为写请求设置的，这是唯一添加到outstandingChanges的请求 TxnHeader hdr = request.getHdr(); Record txn = request.getTxn(); long zxid = hdr.getZxid(); while (!zks.outstandingChanges.isEmpty() &amp;&amp; zks.outstandingChanges.peek().zxid &lt;= zxid) &#123; ChangeRecord cr = zks.outstandingChanges.remove(); if (zks.outstandingChangesForPath.get(cr.path) == cr) &#123; zks.outstandingChangesForPath.remove(cr.path); &#125; &#125; &#125; if (request.isQuorum()) &#123; // do not add non quorum packets to the queue. zks.getZKDatabase().addCommittedProposal(request); &#125; &#125; if (request.type == OpCode.closeSession &amp;&amp; connClosedByClient(request)) &#123; if (closeSession(zks.serverCnxnFactory, request.sessionId) || closeSession(zks.secureServerCnxnFactory, request.sessionId)) &#123; return; &#125; &#125; if (request.cnxn == null) &#123; return; &#125; ServerCnxn cnxn = request.cnxn; String lastOp = \"NA\"; zks.decInProcess(); Code err = Code.OK; Record rsp = null; try &#123; if (request.getHdr() != null &amp;&amp; request.getHdr().getType() == OpCode.error) &#123; if (request.getException() != null) &#123; throw request.getException(); &#125; else &#123; throw KeeperException.create(KeeperException.Code.get(((ErrorTxn) request.getTxn()).getErr())); &#125; &#125; KeeperException ke = request.getException(); if (ke != null &amp;&amp; request.type != OpCode.multi) &#123; throw ke; &#125; switch (request.type) &#123; // 根据request.type生成对应的rsp case OpCode.ping: &#123; zks.serverStats().updateLatency(request.createTime); lastOp = \"PING\"; cnxn.updateStatsForResponse(request.cxid, request.zxid, lastOp, request.createTime, Time.currentElapsedTime()); cnxn.sendResponse(new ReplyHeader(-2, zks.getZKDatabase().getDataTreeLastProcessedZxid(), 0), null, \"response\"); return; &#125; case OpCode.createSession: &#123; zks.serverStats().updateLatency(request.createTime); lastOp = \"SESS\"; cnxn.updateStatsForResponse(request.cxid, request.zxid, lastOp, request.createTime, Time.currentElapsedTime()); zks.finishSessionInit(request.cnxn, true); return; &#125; case OpCode.create: &#123; lastOp = \"CREA\"; rsp = new CreateResponse(rc.path); err = Code.get(rc.err); break; &#125; case OpCode.create2: case OpCode.createTTL: case OpCode.createContainer: &#123; lastOp = \"CREA\"; rsp = new Create2Response(rc.path, rc.stat); err = Code.get(rc.err); break; &#125; case OpCode.delete: case OpCode.deleteContainer: &#123; lastOp = \"DELE\"; err = Code.get(rc.err); break; &#125; case OpCode.setData: &#123; lastOp = \"SETD\"; rsp = new SetDataResponse(rc.stat); err = Code.get(rc.err); break; &#125; case OpCode.sync: &#123; lastOp = \"SYNC\"; SyncRequest syncRequest = new SyncRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, syncRequest); rsp = new SyncResponse(syncRequest.getPath()); break; &#125; case OpCode.getData: &#123; lastOp = \"GETD\"; GetDataRequest getDataRequest = new GetDataRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, getDataRequest); DataNode n = zks.getZKDatabase().getNode(getDataRequest.getPath()); if (n == null) &#123; throw new KeeperException.NoNodeException(); &#125; PrepRequestProcessor.checkACL(zks, zks.getZKDatabase().aclForNode(n), ZooDefs.Perms.READ, request.authInfo); Stat stat = new Stat(); byte b[] = zks.getZKDatabase().getData(getDataRequest.getPath(), stat, getDataRequest.getWatch() ? cnxn : null); rsp = new GetDataResponse(b, stat); break; &#125; case OpCode.setWatches: &#123; lastOp = \"SETW\"; SetWatches setWatches = new SetWatches(); // XXX We really should NOT need this!!!! request.request.rewind(); ByteBufferInputStream.byteBuffer2Record(request.request, setWatches); long relativeZxid = setWatches.getRelativeZxid(); zks.getZKDatabase().setWatches(relativeZxid, setWatches.getDataWatches(), setWatches.getExistWatches(), setWatches.getChildWatches(), cnxn); break; &#125; case OpCode.getChildren: &#123; lastOp = \"GETC\"; GetChildrenRequest getChildrenRequest = new GetChildrenRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, getChildrenRequest); DataNode n = zks.getZKDatabase().getNode(getChildrenRequest.getPath()); if (n == null) &#123; throw new KeeperException.NoNodeException(); &#125; PrepRequestProcessor.checkACL(zks, zks.getZKDatabase().aclForNode(n), ZooDefs.Perms.READ, request.authInfo); List&lt;String&gt; children = zks.getZKDatabase().getChildren(getChildrenRequest.getPath(), null, getChildrenRequest.getWatch() ? cnxn : null); rsp = new GetChildrenResponse(children); break; &#125; &#125; &#125; long lastZxid = zks.getZKDatabase().getDataTreeLastProcessedZxid(); ReplyHeader hdr = new ReplyHeader(request.cxid, lastZxid, err.intValue()); zks.serverStats().updateLatency(request.createTime); cnxn.updateStatsForResponse(request.cxid, lastZxid, lastOp, request.createTime, Time.currentElapsedTime()); try &#123; cnxn.sendResponse(hdr, rsp, \"response\"); // 响应客户端 if (request.type == OpCode.closeSession) &#123; cnxn.sendCloseSession(); &#125; &#125; catch (IOException e) &#123;&#125; &#125;&#125;public class ZooKeeperServer implements SessionExpirer, ServerStats.Provider &#123; public ProcessTxnResult processTxn(Request request) &#123; return processTxn(request, request.getHdr(), request.getTxn()); &#125; private ProcessTxnResult processTxn(Request request, TxnHeader hdr, Record txn) &#123; ProcessTxnResult rc; int opCode = request != null ? request.type : hdr.getType(); long sessionId = request != null ? request.sessionId : hdr.getClientId(); if (hdr != null) &#123; rc = getZKDatabase().processTxn(hdr, txn); // 写数据到内存中 &#125; else &#123; rc = new ProcessTxnResult(); &#125; if (opCode == OpCode.createSession) &#123; if (hdr != null &amp;&amp; txn instanceof CreateSessionTxn) &#123; CreateSessionTxn cst = (CreateSessionTxn) txn; sessionTracker.addGlobalSession(sessionId, cst.getTimeOut()); &#125; else if (request != null &amp;&amp; request.isLocalSession()) &#123; request.request.rewind(); int timeout = request.request.getInt(); request.request.rewind(); sessionTracker.addSession(request.sessionId, timeout); &#125; &#125; else if (opCode == OpCode.closeSession) &#123; sessionTracker.removeSession(sessionId); &#125; return rc; &#125;&#125;public class ZKDatabase &#123; public ProcessTxnResult processTxn(TxnHeader hdr, Record txn) &#123; return dataTree.processTxn(hdr, txn); &#125; public ProcessTxnResult processTxn(TxnHeader header, Record txn) &#123; return this.processTxn(header, txn, false); &#125; public ProcessTxnResult processTxn(TxnHeader header, Record txn, boolean isSubTxn) &#123; ProcessTxnResult rc = new ProcessTxnResult(); try &#123; rc.clientId = header.getClientId(); rc.cxid = header.getCxid(); rc.zxid = header.getZxid(); rc.type = header.getType(); rc.err = 0; rc.multiResult = null; switch (header.getType()) &#123; case OpCode.create: CreateTxn createTxn = (CreateTxn) txn; rc.path = createTxn.getPath(); createNode(createTxn.getPath(), createTxn.getData(), createTxn.getAcl(), createTxn.getEphemeral() ? header.getClientId() : 0, createTxn.getParentCVersion(), header.getZxid(), header.getTime(), null); break; case OpCode.create2: CreateTxn create2Txn = (CreateTxn) txn; rc.path = create2Txn.getPath(); Stat stat = new Stat(); createNode(create2Txn.getPath(), create2Txn.getData(), create2Txn.getAcl(), create2Txn.getEphemeral() ? header.getClientId() : 0, create2Txn.getParentCVersion(), header.getZxid(), header.getTime(), stat); rc.stat = stat; break; case OpCode.createTTL: CreateTTLTxn createTtlTxn = (CreateTTLTxn) txn; rc.path = createTtlTxn.getPath(); stat = new Stat(); createNode(createTtlTxn.getPath(), createTtlTxn.getData(), createTtlTxn.getAcl(), EphemeralType.TTL.toEphemeralOwner(createTtlTxn.getTtl()), createTtlTxn.getParentCVersion(), header.getZxid(), header.getTime(), stat); rc.stat = stat; break; case OpCode.createContainer: CreateContainerTxn createContainerTxn = (CreateContainerTxn) txn; rc.path = createContainerTxn.getPath(); stat = new Stat(); createNode(createContainerTxn.getPath(), createContainerTxn.getData(), createContainerTxn.getAcl(), EphemeralType.CONTAINER_EPHEMERAL_OWNER, createContainerTxn.getParentCVersion(), header.getZxid(), header.getTime(), stat); rc.stat = stat; break; case OpCode.delete: case OpCode.deleteContainer: DeleteTxn deleteTxn = (DeleteTxn) txn; rc.path = deleteTxn.getPath(); deleteNode(deleteTxn.getPath(), header.getZxid()); break; case OpCode.reconfig: case OpCode.setData: SetDataTxn setDataTxn = (SetDataTxn) txn; rc.path = setDataTxn.getPath(); rc.stat = setData(setDataTxn.getPath(), setDataTxn.getData(), setDataTxn.getVersion(), header.getZxid(), header.getTime()); break; case OpCode.closeSession: killSession(header.getClientId(), header.getZxid()); break; &#125; &#125; catch (KeeperException e) &#123; rc.err = e.code().intValue(); &#125; catch (IOException e) &#123;&#125; if (!isSubTxn) &#123; if (rc.zxid &gt; lastProcessedZxid) &#123; lastProcessedZxid = rc.zxid; &#125; &#125; if (header.getType() == OpCode.create &amp;&amp; rc.err == Code.NODEEXISTS.intValue()) &#123; int lastSlash = rc.path.lastIndexOf('/'); String parentName = rc.path.substring(0, lastSlash); CreateTxn cTxn = (CreateTxn)txn; try &#123; setCversionPzxid(parentName, cTxn.getParentCVersion(), header.getZxid()); &#125; catch (KeeperException.NoNodeException e) &#123; rc.err = e.code().intValue(); &#125; &#125; return rc; &#125;&#125;public class DataTree &#123; public void createNode(final String path, byte data[], List&lt;ACL&gt; acl, long ephemeralOwner, int parentCVersion, long zxid, long time, Stat outputStat) throws KeeperException.NoNodeException, KeeperException.NodeExistsException &#123; int lastSlash = path.lastIndexOf('/'); String parentName = path.substring(0, lastSlash); String childName = path.substring(lastSlash + 1); StatPersisted stat = new StatPersisted(); stat.setCtime(time); stat.setMtime(time); stat.setCzxid(zxid); stat.setMzxid(zxid); stat.setPzxid(zxid); stat.setVersion(0); stat.setAversion(0); stat.setEphemeralOwner(ephemeralOwner); DataNode parent = nodes.get(parentName); if (parent == null) &#123; throw new KeeperException.NoNodeException(); &#125; synchronized (parent) &#123; Set&lt;String&gt; children = parent.getChildren(); if (children.contains(childName)) &#123; throw new KeeperException.NodeExistsException(); &#125; if (parentCVersion == -1) &#123; parentCVersion = parent.stat.getCversion(); parentCVersion++; &#125; parent.stat.setCversion(parentCVersion); parent.stat.setPzxid(zxid); Long longval = aclCache.convertAcls(acl); DataNode child = new DataNode(data, longval, stat); parent.addChild(childName); nodes.put(path, child); EphemeralType ephemeralType = EphemeralType.get(ephemeralOwner); if (ephemeralType == EphemeralType.CONTAINER) &#123; containers.add(path); &#125; else if (ephemeralType == EphemeralType.TTL) &#123; ttls.add(path); &#125; else if (ephemeralOwner != 0) &#123; HashSet&lt;String&gt; list = ephemerals.get(ephemeralOwner); if (list == null) &#123; list = new HashSet&lt;String&gt;(); ephemerals.put(ephemeralOwner, list); &#125; synchronized (list) &#123; list.add(path); &#125; &#125; if (outputStat != null) &#123; child.copyStat(outputStat); &#125; &#125; if (parentName.startsWith(quotaZookeeper)) &#123; if (Quotas.limitNode.equals(childName)) &#123; pTrie.addPath(parentName.substring(quotaZookeeper.length())); &#125; if (Quotas.statNode.equals(childName)) &#123; updateQuotaForPath(parentName.substring(quotaZookeeper.length())); &#125; &#125; String lastPrefix = getMaxPrefixWithQuota(path); if(lastPrefix != null) &#123; // ok we have some match and need to update updateCount(lastPrefix, 1); updateBytes(lastPrefix, data == null ? 0 : data.length); &#125; dataWatches.triggerWatch(path, Event.EventType.NodeCreated); childWatches.triggerWatch(parentName.equals(\"\") ? \"/\" : parentName, Event.EventType.NodeChildrenChanged); &#125;&#125; 与Follower交互在LearnerHandler的run方法中会死循环接收从节点发来的数据，然后根据请求类型做响应的逻辑，当收到ACK请求时，将调用Leader的processAck方法收集ACK投票，当票数超过一半时唤醒CommitProcessor线程的wait等待。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154public class LearnerHandler extends ZooKeeperThread &#123; public void run() &#123; try &#123; leader.addLearnerHandler(this); tickOfNextAckDeadline = leader.self.tick.get() + leader.self.initLimit + leader.self.syncLimit; ia = BinaryInputArchive.getArchive(bufferedInput); bufferedOutput = new BufferedOutputStream(sock.getOutputStream()); oa = BinaryOutputArchive.getArchive(bufferedOutput); QuorumPacket qp = new QuorumPacket(); ia.readRecord(qp, \"packet\"); if (qp.getType() != Leader.FOLLOWERINFO &amp;&amp; qp.getType() != Leader.OBSERVERINFO) &#123; return; &#125; byte learnerInfoData[] = qp.getData(); if (learnerInfoData != null) &#123; ByteBuffer bbsid = ByteBuffer.wrap(learnerInfoData); if (learnerInfoData.length &gt;= 8) &#123; this.sid = bbsid.getLong(); &#125; if (learnerInfoData.length &gt;= 12) &#123; this.version = bbsid.getInt(); // protocolVersion &#125; if (learnerInfoData.length &gt;= 20) &#123; long configVersion = bbsid.getLong(); if (configVersion &gt; leader.self.getQuorumVerifier().getVersion()) &#123; throw new IOException(\"Follower is ahead of the leader (has a later activated configuration)\"); &#125; &#125; &#125; else &#123; this.sid = leader.followerCounter.getAndDecrement(); &#125; if (qp.getType() == Leader.OBSERVERINFO) &#123; learnerType = LearnerType.OBSERVER; &#125; long lastAcceptedEpoch = ZxidUtils.getEpochFromZxid(qp.getZxid()); long peerLastZxid; StateSummary ss = null; long zxid = qp.getZxid(); long newEpoch = leader.getEpochToPropose(this.getSid(), lastAcceptedEpoch); long newLeaderZxid = ZxidUtils.makeZxid(newEpoch, 0); if (this.getVersion() &lt; 0x10000) &#123; long epoch = ZxidUtils.getEpochFromZxid(zxid); ss = new StateSummary(epoch, zxid); leader.waitForEpochAck(this.getSid(), ss); &#125; else &#123; byte ver[] = new byte[4]; ByteBuffer.wrap(ver).putInt(0x10000); QuorumPacket newEpochPacket = new QuorumPacket(Leader.LEADERINFO, newLeaderZxid, ver, null); oa.writeRecord(newEpochPacket, \"packet\"); bufferedOutput.flush(); QuorumPacket ackEpochPacket = new QuorumPacket(); ia.readRecord(ackEpochPacket, \"packet\"); if (ackEpochPacket.getType() != Leader.ACKEPOCH) &#123; return; &#125; ByteBuffer bbepoch = ByteBuffer.wrap(ackEpochPacket.getData()); ss = new StateSummary(bbepoch.getInt(), ackEpochPacket.getZxid()); leader.waitForEpochAck(this.getSid(), ss); &#125; peerLastZxid = ss.getLastZxid(); boolean needSnap = syncFollower(peerLastZxid, leader.zk.getZKDatabase(), leader); if (needSnap) &#123; boolean exemptFromThrottle = getLearnerType() != LearnerType.OBSERVER; LearnerSnapshot snapshot = leader.getLearnerSnapshotThrottler().beginSnapshot(exemptFromThrottle); try &#123; long zxidToSend = leader.zk.getZKDatabase().getDataTreeLastProcessedZxid(); oa.writeRecord(new QuorumPacket(Leader.SNAP, zxidToSend, null, null), \"packet\"); bufferedOutput.flush(); leader.zk.getZKDatabase().serializeSnapshot(oa); oa.writeString(\"BenWasHere\", \"signature\"); bufferedOutput.flush(); &#125; finally &#123; snapshot.close(); &#125; &#125; if (getVersion() &lt; 0x10000) &#123; QuorumPacket newLeaderQP = new QuorumPacket(Leader.NEWLEADER, newLeaderZxid, null, null); oa.writeRecord(newLeaderQP, \"packet\"); &#125; else &#123; QuorumPacket newLeaderQP = new QuorumPacket(Leader.NEWLEADER, newLeaderZxid, leader.self.getLastSeenQuorumVerifier().toString().getBytes(), null); queuedPackets.add(newLeaderQP); &#125; bufferedOutput.flush(); startSendingPackets(); // 启动线程将队列中的数据包发送给Follower qp = new QuorumPacket(); ia.readRecord(qp, \"packet\"); if (qp.getType() != Leader.ACK) &#123; return; &#125; leader.waitForNewLeaderAck(getSid(), qp.getZxid()); syncLimitCheck.start(); sock.setSoTimeout(leader.self.tickTime * leader.self.syncLimit); synchronized (leader.zk) &#123; while (!leader.zk.isRunning() &amp;&amp; !this.isInterrupted()) &#123; leader.zk.wait(20); &#125; &#125; queuedPackets.add(new QuorumPacket(Leader.UPTODATE, -1, null, null)); while (true) &#123; qp = new QuorumPacket(); ia.readRecord(qp, \"packet\"); long traceMask = ZooTrace.SERVER_PACKET_TRACE_MASK; if (qp.getType() == Leader.PING) &#123; traceMask = ZooTrace.SERVER_PING_TRACE_MASK; &#125; tickOfNextAckDeadline = leader.self.tick.get() + leader.self.syncLimit; ByteBuffer bb; long sessionId; int cxid; int type; switch (qp.getType()) &#123; case Leader.ACK: // 处理Follower发送给Leader的ACK syncLimitCheck.updateAck(qp.getZxid()); leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress()); break; case Leader.PING:// Process the touches ByteArrayInputStream bis = new ByteArrayInputStream(qp.getData()); DataInputStream dis = new DataInputStream(bis); while (dis.available() &gt; 0) &#123; long sess = dis.readLong(); int to = dis.readInt(); leader.zk.touch(sess, to); &#125; break; case Leader.REQUEST: bb = ByteBuffer.wrap(qp.getData()); sessionId = bb.getLong(); cxid = bb.getInt(); type = bb.getInt(); bb = bb.slice(); Request si; if (type == OpCode.sync) &#123; si = new LearnerSyncRequest(this, sessionId, cxid, type, bb, qp.getAuthinfo()); &#125; else &#123; si = new Request(null, sessionId, cxid, type, bb, qp.getAuthinfo()); &#125; si.setOwner(this); leader.zk.submitLearnerRequest(si); break; default: break; &#125; &#125; &#125; catch (IOException e) &#123; if (sock != null &amp;&amp; !sock.isClosed()) &#123; try &#123; //close the socket to make sure the other side can see it being close sock.close(); &#125; &#125; &#125; finally &#123; shutdown(); &#125; &#125;&#125; 在LearnerHandler的run方法中通过startSendingPackets方法，启动了一个线程从阻塞队列queuedPackets中poll请求数据包，发送给follower。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class LearnerHandler extends ZooKeeperThread &#123; protected void startSendingPackets() &#123; if (!sendingThreadStarted) &#123;// Start sending packets new Thread() &#123; public void run() &#123; Thread.currentThread().setName(\"Sender-\" + sock.getRemoteSocketAddress()); try &#123; sendPackets(); &#125; catch (InterruptedException e) &#123;&#125; &#125; &#125;.start(); sendingThreadStarted = true; &#125; &#125; private void sendPackets() throws InterruptedException &#123; long traceMask = ZooTrace.SERVER_PACKET_TRACE_MASK; while (true) &#123; try &#123; QuorumPacket p; p = queuedPackets.poll(); if (p == null) &#123; bufferedOutput.flush(); p = queuedPackets.take(); &#125; if (p == proposalOfDeath) &#123;// Packet of death! break; &#125; if (p.getType() == Leader.PING) &#123; traceMask = ZooTrace.SERVER_PING_TRACE_MASK; &#125; if (p.getType() == Leader.PROPOSAL) &#123; syncLimitCheck.updateProposal(p.getZxid(), System.nanoTime()); &#125; if (LOG.isTraceEnabled()) &#123; ZooTrace.logQuorumPacket(LOG, traceMask, 'o', p); &#125; oa.writeRecord(p, \"packet\"); &#125; catch (IOException e) &#123; if (!sock.isClosed()) &#123; try &#123;// this will cause everything to shutdown on this learner handler and will help notify the learner/observer instantaneously sock.close(); &#125; catch (IOException ie) &#123;&#125; &#125; break; &#125; &#125; &#125;&#125; 从节点对于从节点当选举完成后会调用Follower的followLeader方法中通过syncWithLeader调用ZooKeeperServer的子类FollowerZooKeeperServer的setupRequestProcessors方法加载请求处理链FollowerRequestProcessor、CommitProcessor、FinalRequestProcessor和SyncRequestProcessor、SendAckRequestProcessor。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Follower extends Learner&#123; void followLeader() throws InterruptedException &#123; self.end_fle = Time.currentElapsedTime(); long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); self.start_fle = 0; self.end_fle = 0; fzk.registerJMX(new FollowerBean(this, zk), self.jmxLocalPeerBean); try &#123; QuorumServer leaderServer = findLeader(); // 获取leader server try &#123; connectToLeader(leaderServer.addr, leaderServer.hostname); // 主动向leader发起socket连接 long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); // 注册自己到Leader if (self.isReconfigStateChange()) throw new Exception(\"learned about role change\"); long newEpoch = ZxidUtils.getEpochFromZxid(newEpochZxid); if (newEpoch &lt; self.getAcceptedEpoch()) &#123; throw new IOException(\"Error: Epoch of leader is lower\"); &#125; syncWithLeader(newEpochZxid); // 同步leader数据 QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) &#123; // while死循环接收leader同步的数据 readPacket(qp); // 若leader挂了，这里从leader取数据时会抛出异常退出循环 processPacket(qp); &#125; &#125; catch (Exception e) &#123; try &#123; sock.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; pendingRevalidations.clear(); &#125; &#125; finally &#123; zk.unregisterJMX((Learner)this); &#125; &#125;&#125;public class FollowerZooKeeperServer extends LearnerZooKeeperServer &#123; protected void setupRequestProcessors() &#123; RequestProcessor finalProcessor = new FinalRequestProcessor(this); commitProcessor = new CommitProcessor(finalProcessor, Long.toString(getServerId()), true, getZooKeeperServerListener()); commitProcessor.start(); firstProcessor = new FollowerRequestProcessor(this, commitProcessor); ((FollowerRequestProcessor) firstProcessor).start(); syncProcessor = new SyncRequestProcessor(this, new SendAckRequestProcessor((Learner)getFollower())); syncProcessor.start(); &#125;&#125; 当接收到Leader发送的数据时调用首先调用readPacket使用jute序列化从输入流中拿数据，然后调用processPacket根据请求类型调用具体的方法处理请求数据。对于Leader.PROPOSAL类型的请求调用FollowerZooKeeperServer的logRequest方法，从而异步执行SyncRequestProcessor将数据更新到事务日志文件中。 对于Follower来说，SyncRequestProcessor的nextProcessor为SendAckRequestProcessor，故当将数据同步到事务日志文件中后，则执行SendAckRequestProcessor给Leader回复ACK命令，当Leader收到的ACK票数超过一半时执行Commit操作，且给Follower发送Commit命令。当收到Leader的Commit命令后调用FollowerZooKeeperServer的commit方法执行CommitProcessor的commit关键方法，然后执行FinalRequestProcessor将数据同步到内存中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class Learner &#123; void readPacket(QuorumPacket pp) throws IOException &#123; synchronized (leaderIs) &#123; leaderIs.readRecord(pp, \"packet\"); // 调用QuorumPacket的deserialize方法，使用jute序列化从输入流中拿数据，jute类似protobuf &#125; &#125;&#125;public class Follower extends Learner&#123; protected void processPacket(QuorumPacket qp) throws Exception&#123; switch (qp.getType()) &#123; case Leader.PING: ping(qp); break; case Leader.PROPOSAL: TxnHeader hdr = new TxnHeader(); Record txn = SerializeUtils.deserializeTxn(qp.getData(), hdr); lastQueued = hdr.getZxid(); if (hdr.getType() == OpCode.reconfig)&#123; SetDataTxn setDataTxn = (SetDataTxn) txn; QuorumVerifier qv = self.configFromString(new String(setDataTxn.getData())); self.setLastSeenQuorumVerifier(qv, true); &#125; fzk.logRequest(hdr, txn); break; case Leader.COMMIT: fzk.commit(qp.getZxid()); break; case Leader.COMMITANDACTIVATE: Request request = fzk.pendingTxns.element(); SetDataTxn setDataTxn = (SetDataTxn) request.getTxn(); QuorumVerifier qv = self.configFromString(new String(setDataTxn.getData())); ByteBuffer buffer = ByteBuffer.wrap(qp.getData()); long suggestedLeaderId = buffer.getLong(); boolean majorChange = self.processReconfig(qv, suggestedLeaderId, qp.getZxid(), true); fzk.commit(qp.getZxid()); if (majorChange) &#123; throw new Exception(\"changes proposed in reconfig\"); &#125; break; case Leader.UPTODATE: break; case Leader.REVALIDATE: revalidate(qp); break; case Leader.SYNC: fzk.sync(); break; default: break; &#125; &#125;&#125;public class FollowerZooKeeperServer extends LearnerZooKeeperServer &#123; public void logRequest(TxnHeader hdr, Record txn) &#123; Request request = new Request(hdr.getClientId(), hdr.getCxid(), hdr.getType(), hdr, txn, hdr.getZxid()); if ((request.zxid &amp; 0xffffffffL) != 0) &#123; pendingTxns.add(request); &#125; syncProcessor.processRequest(request); &#125; public void commit(long zxid) &#123; if (pendingTxns.size() == 0) &#123; return; &#125; long firstElementZxid = pendingTxns.element().zxid; if (firstElementZxid != zxid) &#123; System.exit(12); &#125; Request request = pendingTxns.remove(); commitProcessor.commit(request); &#125;&#125;public class SendAckRequestProcessor implements RequestProcessor, Flushable &#123; public void processRequest(Request si) &#123; if(si.type != OpCode.sync)&#123; QuorumPacket qp = new QuorumPacket(Leader.ACK, si.getHdr().getZxid(), null, null); try &#123; learner.writePacket(qp, false); // 向Leader发送构建的ACK的packet，被LearnerHandler.run接收到执行Leader的processAck方法 &#125; catch (IOException e) &#123; try &#123; if (!learner.sock.isClosed()) &#123; learner.sock.close(); &#125; &#125; catch (IOException e1) &#123;&#125; &#125; &#125; &#125;&#125;","tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://yaoyinglong.github.io/tags/Zookeeper/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Zookeeper","slug":"Cloud/Zookeeper","permalink":"https://yaoyinglong.github.io/categories/Cloud/Zookeeper/"}]},{"title":"Dubbo服务调用","date":"2021-12-16T16:00:00.000Z","path":"Blog/Cloud/Dubbo/Dubbo服务调用/","text":"客户端客户端调用Dubbo方法时首先通过InvokerInvocationHandler调用MockClusterInvoker首先判断Mock逻辑，若未配置Mock则直接往下调用，若配置了force强制Mock，则直接本地通过配置构造返回结果，若配置了Mock则调用远程服务失败才通过doMockInvoke走本地Mock逻辑，且在走本地Mock逻辑时会先判断异常是否为业务异常，若为业务异常直接抛出异常。 然后通过AbstractClusterInvoker调用Directory的list方法最终调用RegistryDirectory的doList方法执行路由链依次执行MockInvokersSelector、TagRouter、AppRouter、ServiceRouter的route方法过滤出符合路由条件的invokers。然后通过Invoker的URL信息通过SPI机制获取负载均衡器，默认为RandomLoadBalance。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class InvokerInvocationHandler implements InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(invoker, args); &#125; if (\"toString\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.toString(); &#125; if (\"hashCode\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.hashCode(); &#125; if (\"equals\".equals(methodName) &amp;&amp; parameterTypes.length == 1) &#123; return invoker.equals(args[0]); &#125; // recreate方法会调用AppResponse的recreate方法，若AppResponse对象中存在exception信息，则此方法中会throw该异常 return invoker.invoke(new RpcInvocation(method, args)).recreate(); &#125;&#125;public class AppResponse extends AbstractResult implements Serializable &#123; public Object recreate() throws Throwable &#123; if (exception != null) &#123; try &#123;// get Throwable class Class clazz = exception.getClass(); while (!clazz.getName().equals(Throwable.class.getName())) &#123; clazz = clazz.getSuperclass(); &#125; Field stackTraceField = clazz.getDeclaredField(\"stackTrace\"); // get stackTrace value stackTraceField.setAccessible(true); Object stackTrace = stackTraceField.get(exception); if (stackTrace == null) &#123; exception.setStackTrace(new StackTraceElement[0]); &#125; &#125; catch (Exception e) &#123;// ignore &#125; throw exception; &#125; return result; &#125;&#125;public class MockClusterInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(Invocation invocation) throws RpcException &#123; Result result = null; String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), MOCK_KEY, Boolean.FALSE.toString()).trim(); if (value.length() == 0 || \"false\".equalsIgnoreCase(value)) &#123; result = this.invoker.invoke(invocation); // 未配置Mock &#125; else if (value.startsWith(\"force\")) &#123; // 若强制走Mock result = doMockInvoke(invocation, null); //force:direct mock &#125; else &#123;// 若配置了Mock，只有调用远程服务失败才通过doMockInvoke走Mock逻辑 try &#123; result = this.invoker.invoke(invocation); if (result.getException() != null &amp;&amp; result.getException() instanceof RpcException) &#123; // 若直接返回的是一个异常对象 RpcException rpcException = (RpcException) result.getException(); if (rpcException.isBiz()) &#123; // 若为业务异常直接抛出异常不走Mock逻辑 throw rpcException; &#125; else &#123; result = doMockInvoke(invocation, rpcException); &#125; &#125; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; // 若为业务异常直接抛出异常不走Mock逻辑 throw e; &#125; result = doMockInvoke(invocation, e); // 返回Mock值 &#125; &#125; return result; &#125;&#125;public abstract class AbstractClusterInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(final Invocation invocation) throws RpcException &#123; checkWhetherDestroyed(); Map&lt;String, String&gt; contextAttachments = RpcContext.getContext().getAttachments(); if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) &#123; ((RpcInvocation) invocation).addAttachments(contextAttachments); &#125; List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); // 先路由过滤出符合路由条件的invokers LoadBalance loadbalance = initLoadBalance(invokers, invocation); // 通过Invoker的URL信息通过SPI机制获取负载均衡器 RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance); &#125; protected List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; return directory.list(invocation); &#125;&#125;public abstract class AbstractDirectory&lt;T&gt; implements Directory&lt;T&gt; &#123; public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; if (destroyed) &#123; throw new RpcException(\"Directory already destroyed .url: \" + getUrl()); &#125; return doList(invocation); &#125;&#125;public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener &#123; public List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) &#123; if (forbidden) &#123;// 无服务提供者或服务提供者被禁用 throw new RpcException(RpcException.FORBIDDEN_EXCEPTION, \"No provider available from registry \" + getUrl().getAddress() + \" for service \" + getConsumerUrl().getServiceKey() + \" on consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please check status of providers(disabled, not registered or in blacklist).\"); &#125; if (multiGroup) &#123; return this.invokers == null ? Collections.emptyList() : this.invokers; &#125; List&lt;Invoker&lt;T&gt;&gt; invokers = null; try &#123;// 执行路由过滤器链 invokers = routerChain.route(getConsumerUrl(), invocation); &#125; catch (Throwable t) &#123; &#125; return invokers == null ? Collections.emptyList() : invokers; &#125;&#125;public class RouterChain&lt;T&gt; &#123; public List&lt;Invoker&lt;T&gt;&gt; route(URL url, Invocation invocation) &#123; List&lt;Invoker&lt;T&gt;&gt; finalInvokers = invokers; for (Router router : routers) &#123; // 使用路由对服务提供者进行过滤 finalInvokers = router.route(finalInvokers, url, invocation); &#125; return finalInvokers; &#125;&#125; 首先调用FailoverClusterInvoker的doInvoke，首先获取重试次数，若重试次数小于等于0，则将重试次数置为1，然后遍历重试次数，调用负载均衡策略选择具体的Invoker。若选出的invoker在selected中或invoker不可用且availablecheck为真则重新选择。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110public class FailoverClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyInvokers = invokers; checkInvokers(copyInvokers, invocation); String methodName = RpcUtils.getMethodName(invocation); int len = getUrl().getMethodParameter(methodName, RETRIES_KEY, DEFAULT_RETRIES) + 1; if (len &lt;= 0) &#123; // 若重试次数小于等于0，则将重试次数置为1 len = 1; &#125; RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyInvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) &#123; if (i &gt; 0) &#123; checkWhetherDestroyed(); copyInvokers = list(invocation); checkInvokers(copyInvokers, invocation); &#125; Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyInvokers, invoked); // 调用负载均衡策略选择具体的Invoker invoked.add(invoker); RpcContext.getContext().setInvokers((List) invoked); try &#123; Result result = invoker.invoke(invocation); return result; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; // biz exception. throw e; &#125; le = e; &#125; catch (Throwable e) &#123; le = new RpcException(e.getMessage(), e); &#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(le.getCode(), \"Failed to invoke the method \" + methodName + \" in the service \" + getInterface().getName()); &#125;&#125;public abstract class AbstractClusterInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; protected Invoker&lt;T&gt; select(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (CollectionUtils.isEmpty(invokers)) &#123; return null; &#125; String methodName = invocation == null ? StringUtils.EMPTY : invocation.getMethodName(); boolean sticky = invokers.get(0).getUrl().getMethodParameter(methodName, CLUSTER_STICKY_KEY, DEFAULT_CLUSTER_STICKY); if (stickyInvoker != null &amp;&amp; !invokers.contains(stickyInvoker)) &#123; stickyInvoker = null; // 忽略重载方法 &#125; if (sticky &amp;&amp; stickyInvoker != null &amp;&amp; (selected == null || !selected.contains(stickyInvoker))) &#123; if (availablecheck &amp;&amp; stickyInvoker.isAvailable()) &#123; return stickyInvoker; &#125; &#125; Invoker&lt;T&gt; invoker = doSelect(loadbalance, invocation, invokers, selected); if (sticky) &#123; stickyInvoker = invoker; &#125; return invoker; &#125; private Invoker&lt;T&gt; doSelect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (CollectionUtils.isEmpty(invokers)) &#123; return null; &#125; if (invokers.size() == 1) &#123; // 若只有一个则直接返回 return invokers.get(0); &#125; Invoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation); // 调用具体负载均衡器的方法 if ((selected != null &amp;&amp; selected.contains(invoker)) || (!invoker.isAvailable() &amp;&amp; getUrl() != null &amp;&amp; availablecheck)) &#123; try &#123; // 若选出的invoker在selected中或invoker不可用&amp;&amp;availablecheck为真，则重新选择 Invoker&lt;T&gt; rInvoker = reselect(loadbalance, invocation, invokers, selected, availablecheck); if (rInvoker != null) &#123; invoker = rInvoker; &#125; else &#123; // 查看当前选中的调用者的索引，若不是最后一个，选择索引+1的那个 int index = invokers.indexOf(invoker); try &#123;//Avoid collision 避免碰撞 invoker = invokers.get((index + 1) % invokers.size()); &#125; catch (Exception e) &#123; &#125; &#125; &#125; catch (Throwable t) &#123; &#125; &#125; return invoker; &#125; private Invoker&lt;T&gt; reselect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected, boolean availablecheck) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; reselectInvokers = new ArrayList&lt;&gt;(invokers.size() &gt; 1 ? (invokers.size() - 1) : invokers.size()); for (Invoker&lt;T&gt; invoker : invokers) &#123; // 尝试选择不在selected中的调用者 if (availablecheck &amp;&amp; !invoker.isAvailable()) &#123; continue; &#125; if (selected == null || !selected.contains(invoker)) &#123; reselectInvokers.add(invoker); &#125; &#125; if (!reselectInvokers.isEmpty()) &#123; return loadbalance.select(reselectInvokers, getUrl(), invocation); &#125; if (selected != null) &#123; // 使用负载平衡策略选择一个可用的调用程序 for (Invoker&lt;T&gt; invoker : selected) &#123; if ((invoker.isAvailable()) &amp;&amp; !reselectInvokers.contains(invoker)) &#123; reselectInvokers.add(invoker); &#125; &#125; &#125; if (!reselectInvokers.isEmpty()) &#123; return loadbalance.select(reselectInvokers, getUrl(), invocation); &#125; return null; &#125;&#125; 选出具体的Invoker后通过InvokerWrapper然后调用ListenerInvokerWrapper，从而调用ProtocolFilterWrapper的CallbackRegistrationInvoker的invoke方法，首先调用buildInvokerChain中构造的过滤器链。首先执行ConsumerContextFilter设置RpcContext参数，然后执行FutureFilter若当前方法为回调方法则执行回调方法，调用MonitorFilter，最终通过AsyncToSyncInvoker掉到DubboInvoker。若请求是同步请求会在AsyncToSyncInvoker异步转同步同步获取请求结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188public class InvokerWrapper&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation); &#125;&#125;public class ListenerInvokerWrapper&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation); // AsyncToSyncInvoker &#125;&#125;public class ProtocolFilterWrapper implements Protocol &#123; static class CallbackRegistrationInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; private final Invoker&lt;T&gt; filterInvoker; private final List&lt;Filter&gt; filters; public CallbackRegistrationInvoker(Invoker&lt;T&gt; filterInvoker, List&lt;Filter&gt; filters) &#123; this.filterInvoker = filterInvoker; this.filters = filters; &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult = filterInvoker.invoke(invocation); // 执行过滤器链 // 过滤器都执行完了之后，回调每个ListenableFilter过滤器的onResponse或onError方法 asyncResult = asyncResult.whenCompleteWithContext((r, t) -&gt; &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; Filter filter = filters.get(i); if (filter instanceof ListenableFilter) &#123; // onResponse callback Filter.Listener listener = ((ListenableFilter) filter).listener(); if (listener != null) &#123; if (t == null) &#123; listener.onResponse(r, filterInvoker, invocation); &#125; else &#123; listener.onError(t, filterInvoker, invocation); &#125; &#125; &#125; else &#123; filter.onResponse(r, filterInvoker, invocation); &#125; &#125; &#125;); return asyncResult; &#125; &#125; private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; // 根据url获取filter，根据url中的parameters取key为key的value所对应的filter，但是还会匹配group List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (!filters.isEmpty()) &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult; try &#123;// 得到一个异步结果 asyncResult = filter.invoke(next, invocation); &#125; catch (Exception e) &#123; if (filter instanceof ListenableFilter) &#123; Filter.Listener listener = ((ListenableFilter) filter).listener(); if (listener != null) &#123; listener.onError(e, invoker, invocation); &#125; &#125; throw e; &#125; return asyncResult; &#125; &#125;; &#125; &#125; return new CallbackRegistrationInvoker&lt;&gt;(last, filters); &#125;&#125;public class ConsumerContextFilter extends ListenableFilter &#123; public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 设置RpcContext参数 RpcContext.getContext().setInvoker(invoker).setInvocation(invocation).setLocalAddress(NetUtils.getLocalHost(), 0) .setRemoteAddress(invoker.getUrl().getHost(), invoker.getUrl().getPort()) .setRemoteApplicationName(invoker.getUrl().getParameter(REMOTE_APPLICATION_KEY)) .setAttachment(REMOTE_APPLICATION_KEY, invoker.getUrl().getParameter(APPLICATION_KEY)); if (invocation instanceof RpcInvocation) &#123; ((RpcInvocation) invocation).setInvoker(invoker); &#125; try &#123; RpcContext.removeServerContext(); return invoker.invoke(invocation); &#125; finally &#123; RpcContext.removeContext(); &#125; &#125;&#125;public class FutureFilter extends ListenableFilter &#123; public Result invoke(final Invoker&lt;?&gt; invoker, final Invocation invocation) throws RpcException &#123; fireInvokeCallback(invoker, invocation); return invoker.invoke(invocation); &#125; private void fireInvokeCallback(final Invoker&lt;?&gt; invoker, final Invocation invocation) &#123;// 当前调用的方法是不是有callback final ConsumerMethodModel.AsyncMethodInfo asyncMethodInfo = getAsyncMethodInfo(invoker, invocation); if (asyncMethodInfo == null) &#123; return; &#125; final Method onInvokeMethod = asyncMethodInfo.getOninvokeMethod(); final Object onInvokeInst = asyncMethodInfo.getOninvokeInstance(); if (onInvokeMethod == null &amp;&amp; onInvokeInst == null) &#123; return; &#125; if (onInvokeMethod == null || onInvokeInst == null) &#123; throw new IllegalStateException(\"service:\" + invoker.getUrl().getServiceKey() + \" has a oninvoke callback config , but no such \" + (onInvokeMethod == null ? \"method\" : \"instance\") + \" found. url:\" + invoker.getUrl()); &#125; if (!onInvokeMethod.isAccessible()) &#123; onInvokeMethod.setAccessible(true); &#125; Object[] params = invocation.getArguments(); try &#123; onInvokeMethod.invoke(onInvokeInst, params); &#125; catch (InvocationTargetException e) &#123; fireThrowCallback(invoker, invocation, e.getTargetException()); &#125; catch (Throwable e) &#123; fireThrowCallback(invoker, invocation, e); &#125; &#125;&#125;public class MonitorFilter extends ListenableFilter &#123; public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; if (invoker.getUrl().hasParameter(MONITOR_KEY)) &#123; invocation.setAttachment(MONITOR_FILTER_START_TIME, String.valueOf(System.currentTimeMillis())); getConcurrent(invoker, invocation).incrementAndGet(); // 方法的执行次数+1 &#125; return invoker.invoke(invocation); // proceed invocation chain &#125;&#125;public class AsyncToSyncInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(Invocation invocation) throws RpcException &#123;// 异步转同步 Result asyncResult = invoker.invoke(invocation); // AsyncRpcResult---&gt;CompletableFuture---&gt;DefaultFuure try &#123;// 如果invocation指定是同步的，则阻塞等待结果 if (InvokeMode.SYNC == ((RpcInvocation) invocation).getInvokeMode()) &#123; asyncResult.get(Integer.MAX_VALUE, TimeUnit.MILLISECONDS); &#125; &#125; catch (InterruptedException e) &#123; throw new RpcException(\"Interrupted unexpectedly while waiting for remoting result to return! method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; catch (ExecutionException e) &#123; Throwable t = e.getCause(); if (t instanceof TimeoutException) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; else if (t instanceof RemotingException) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; catch (Throwable e) &#123; throw new RpcException(e.getMessage(), e); &#125; return asyncResult; &#125;&#125;public abstract class AbstractInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(Invocation inv) throws RpcException &#123; RpcInvocation invocation = (RpcInvocation) inv; invocation.setInvoker(this); if (CollectionUtils.isNotEmptyMap(attachment)) &#123; invocation.addAttachmentsIfAbsent(attachment); &#125; Map&lt;String, String&gt; contextAttachments = RpcContext.getContext().getAttachments(); if (CollectionUtils.isNotEmptyMap(contextAttachments)) &#123; invocation.addAttachments(contextAttachments); &#125; invocation.setInvokeMode(RpcUtils.getInvokeMode(url, invocation)); RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); try &#123; return doInvoke(invocation); &#125; catch (InvocationTargetException e) &#123; // biz exception Throwable te = e.getTargetException(); if (te == null) &#123; return AsyncRpcResult.newDefaultAsyncResult(null, e, invocation); &#125; else &#123; if (te instanceof RpcException) &#123; ((RpcException) te).setCode(RpcException.BIZ_EXCEPTION); &#125; return AsyncRpcResult.newDefaultAsyncResult(null, te, invocation); &#125; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; return AsyncRpcResult.newDefaultAsyncResult(null, e, invocation); &#125; else &#123; throw e; &#125; &#125; catch (Throwable e) &#123; return AsyncRpcResult.newDefaultAsyncResult(null, e, invocation); &#125; &#125;&#125; 最终请求发送到服务端是通过DubboInvoker的doInvoke方法完成的，一个DubboInvoker对象可能并发同时调用某个服务，故单独一次调用都需要一个单独client去发送请求。然后依次调用ReferenceCountExchangeClient、HeaderExchangeClient，HeaderExchangeChannel中会构造一个Request对象且会构造一个DefaultFuture对象来阻塞timeout等待结果，在构造DefaultFuture对象时会把DefaultFuture对象和req的id存入FUTURES中，当HeaderExchangeHandler接收到结果时，会从FUTURES中根据id获取到DefaultFuture对象，然后返回Response。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163public class DubboInvoker&lt;T&gt; extends AbstractInvoker&lt;T&gt; &#123; protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; final String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(PATH_KEY, getUrl().getPath()); inv.setAttachment(VERSION_KEY, version); // 一个DubboInvoker对象可能并发同时调用某个服务，故单独一次调用都需要一个单独client去发送请求，这里会去选择使用本次调用该使用哪个client ExchangeClient currentClient; if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123;// 轮询使用clients currentClient = clients[index.getAndIncrement() % clients.length]; &#125; try &#123; boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); // isOneway为true，表示请求不需要拿结果 // 拿当前方法的所配置的超时时间，默认为1000，即1秒 int timeout = getUrl().getMethodPositiveParameter(methodName, TIMEOUT_KEY, DEFAULT_TIMEOUT); if (isOneway) &#123; // 若不需要获取请求结果 boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); // 通过NettyClient发送请求 return AsyncRpcResult.newDefaultAsyncResult(invocation); // 生成一个默认的值的结果，value=null &#125; else &#123; // 需要获取请求结果 AsyncRpcResult asyncRpcResult = new AsyncRpcResult(inv); CompletableFuture&lt;Object&gt; responseFuture = currentClient.request(inv, timeout); // 异步去请求，得到一个CompletableFuture // responseFuture会完成后会调用asyncRpcResult中的方法，这里并不会阻塞，若要达到阻塞的效果在外层使用asyncRpcResult去控制 asyncRpcResult.subscribeTo(responseFuture); FutureContext.getContext().setCompatibleFuture(responseFuture); return asyncRpcResult; &#125; &#125; catch (TimeoutException e) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; catch (RemotingException e) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125;&#125;final class ReferenceCountExchangeClient implements ExchangeClient &#123; public CompletableFuture&lt;Object&gt; request(Object request, int timeout) throws RemotingException &#123; return client.request(request, timeout); &#125;&#125;public class HeaderExchangeClient implements ExchangeClient &#123; public CompletableFuture&lt;Object&gt; request(Object request, int timeout) throws RemotingException &#123; return channel.request(request, timeout); &#125;&#125;final class HeaderExchangeChannel implements ExchangeChannel &#123; public CompletableFuture&lt;Object&gt; request(Object request, int timeout) throws RemotingException &#123; if (closed) &#123; throw new RemotingException(this.getLocalAddress(), null, \"Failed to send request \" + request + \", cause: The channel \" + this + \" is closed!\"); &#125; Request req = new Request(); // create request. req.setVersion(Version.getProtocolVersion()); req.setTwoWay(true); req.setData(request); DefaultFuture future = DefaultFuture.newFuture(channel, req, timeout); try &#123; channel.send(req); &#125; catch (RemotingException e) &#123; future.cancel(); throw e; &#125; return future; &#125;&#125;public class DefaultFuture extends CompletableFuture&lt;Object&gt; &#123; private DefaultFuture(Channel channel, Request request, int timeout) &#123; this.channel = channel; this.request = request; this.id = request.getId(); this.timeout = timeout &gt; 0 ? timeout : channel.getUrl().getPositiveParameter(TIMEOUT_KEY, DEFAULT_TIMEOUT); FUTURES.put(id, this); // put into waiting map. CHANNELS.put(id, channel); &#125; public static DefaultFuture newFuture(Channel channel, Request request, int timeout) &#123; final DefaultFuture future = new DefaultFuture(channel, request, timeout); timeoutCheck(future); // timeout check return future; &#125; public static void received(Channel channel, Response response, boolean timeout) &#123; try &#123;// response的id， DefaultFuture future = FUTURES.remove(response.getId()); if (future != null) &#123; Timeout t = future.timeoutCheckTask; if (!timeout) &#123;// decrease Time t.cancel(); &#125; future.doReceived(response); &#125; &#125; finally &#123; CHANNELS.remove(response.getId()); &#125; &#125; private void doReceived(Response res) &#123; if (res == null) &#123; throw new IllegalStateException(\"response cannot be null\"); &#125; if (res.getStatus() == Response.OK) &#123; this.complete(res.getResult()); &#125; else if (res.getStatus() == Response.CLIENT_TIMEOUT || res.getStatus() == Response.SERVER_TIMEOUT) &#123; this.completeExceptionally(new TimeoutException(res.getStatus() == Response.SERVER_TIMEOUT, channel, res.getErrorMessage())); &#125; else &#123; this.completeExceptionally(new RemotingException(channel, res.getErrorMessage())); &#125; &#125; private static void timeoutCheck(DefaultFuture future) &#123; TimeoutCheckTask task = new TimeoutCheckTask(future.getId()); future.timeoutCheckTask = TIME_OUT_TIMER.newTimeout(task, future.getTimeout(), TimeUnit.MILLISECONDS); &#125; private static class TimeoutCheckTask implements TimerTask &#123; public void run(Timeout timeout) &#123; DefaultFuture future = DefaultFuture.getFuture(requestID); if (future == null || future.isDone()) &#123; return; &#125; Response timeoutResponse = new Response(future.getId()); // create exception response. timeoutResponse.setStatus(future.isSent() ? Response.SERVER_TIMEOUT : Response.CLIENT_TIMEOUT); // set timeout status. timeoutResponse.setErrorMessage(future.getTimeoutMessage(true)); DefaultFuture.received(future.getChannel(), timeoutResponse, true); // handle response. &#125; &#125;&#125;public abstract class AbstractPeer implements Endpoint, ChannelHandler &#123; public void send(Object message) throws RemotingException &#123; send(message, url.getParameter(Constants.SENT_KEY, false)); &#125;&#125;public abstract class AbstractClient extends AbstractEndpoint implements Client &#123; public void send(Object message, boolean sent) throws RemotingException &#123; if (needReconnect &amp;&amp; !isConnected()) &#123; connect(); &#125; Channel channel = getChannel(); if (channel == null || !channel.isConnected()) &#123; throw new RemotingException(this, \"message can not send, because channel is closed . url:\" + getUrl()); &#125; channel.send(message, sent); &#125;&#125;final class NettyChannel extends AbstractChannel &#123; public void send(Object message, boolean sent) throws RemotingException &#123; super.send(message, sent); // whether the channel is closed boolean success = true; int timeout = 0; try &#123; ChannelFuture future = channel.writeAndFlush(message); // sent为true等待消息发出，消息发送失败将抛出异常。sent为false不等待消息发出，将消息放入IO队列即刻返回 if (sent) &#123; // wait timeout ms timeout = getUrl().getPositiveParameter(TIMEOUT_KEY, DEFAULT_TIMEOUT); success = future.await(timeout); // await会阻塞得到结果，这就是消费者端的timeout &#125; Throwable cause = future.cause(); if (cause != null) &#123; throw cause; &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \", cause: \" + e.getMessage(), e); &#125; if (!success) &#123; throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \"in timeout(\" + timeout + \"ms) limit\"); &#125; &#125;&#125; 处理响应结果客户端收到服务端响应数据结果处理的入口为NettyClientHandler，后续处理逻辑和服务端收到客户端请求处理一样同样经过MultiMessageHandler、HeartbeatHandler最终通过ChannelEventRunnable异步处理任务，然后同样是调用DecodeHandler的received方法，只不过这里的message是Response，和服务端一样同样调用HeaderExchangeHandler，但走的是处理Response的逻辑handleResponse，从而在AsyncToSyncInvoker就能获取到结果了。 123456789101112131415161718192021222324252627282930313233343536public class NettyClientHandler extends ChannelDuplexHandler &#123; public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.received(channel, msg); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125;&#125;public class HeaderExchangeHandler implements ChannelHandlerDelegate &#123; static void handleResponse(Channel channel, Response response) throws RemotingException &#123; if (response != null &amp;&amp; !response.isHeartbeat()) &#123; DefaultFuture.received(channel, response); &#125; &#125;&#125;public class DefaultFuture extends CompletableFuture&lt;Object&gt; &#123; public static void received(Channel channel, Response response) &#123; received(channel, response, false); &#125; public static void received(Channel channel, Response response, boolean timeout) &#123; try &#123;// response的id， DefaultFuture future = FUTURES.remove(response.getId()); if (future != null) &#123; Timeout t = future.timeoutCheckTask; if (!timeout) &#123;// decrease Time t.cancel(); &#125; future.doReceived(response); &#125; &#125; finally &#123; CHANNELS.remove(response.getId()); &#125; &#125;&#125; 服务端服务端是接收数据的入口为NettyServerHandler，然后调用MultiMessageHandler判断接收到数据是否为MultiMessage，若是则获取MultiMessage中单个Message传递给HeartbeatHandler进行处理。HeartbeatHandler判断否心跳消息，若不是则把Message传递给AllChannelHandler。AllChannelHandler将接收到的Message封装为一个ChannelEventRunnable对象通过线程池异步处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class NettyServerHandler extends ChannelDuplexHandler &#123; public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); // 接收到数据 try &#123; handler.received(channel, msg); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125;&#125;public abstract class AbstractPeer implements Endpoint, ChannelHandler &#123; public void received(Channel ch, Object msg) throws RemotingException &#123; if (closed) &#123; return; &#125; handler.received(ch, msg); &#125;&#125;public class MultiMessageHandler extends AbstractChannelHandlerDelegate &#123; public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof MultiMessage) &#123; MultiMessage list = (MultiMessage) message; for (Object obj : list) &#123; handler.received(channel, obj); &#125; &#125; else &#123; handler.received(channel, message); &#125; &#125;&#125;public class HeartbeatHandler extends AbstractChannelHandlerDelegate &#123; public void received(Channel channel, Object message) throws RemotingException &#123; setReadTimestamp(channel); if (isHeartbeatRequest(message)) &#123; // 若是一个心跳请求 Request req = (Request) message; if (req.isTwoWay()) &#123; Response res = new Response(req.getId(), req.getVersion()); res.setEvent(Response.HEARTBEAT_EVENT); channel.send(res); &#125; return; &#125; if (isHeartbeatResponse(message)) &#123; return; // 若是一个心跳响应直接返回 &#125; handler.received(channel, message); &#125;&#125;public class AllChannelHandler extends WrappedChannelHandler &#123; public void received(Channel channel, Object message) throws RemotingException &#123; ExecutorService executor = getExecutorService(); try &#123; // 交给线程池去处理message executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; throw new ExecutionException(message, channel, getClass() + \" error when process received event .\", t); &#125; &#125;&#125; run方法中会调用DecodeHandler按Dubbo协议的数据格式，解析当前请求Message的path，version，方法，方法参数等，然后把解析好的请求交给HeaderExchangeHandler处理Request数据，首先构造一个Response对象，然后调用ExchangeHandlerAdapter得到一个CompletionStage，然后给future通过whenComplete绑定一个回调函数，当future执行完后可从回调函数中得到ExchangeHandlerAdapter执行结果，并把执行结果设置给Response对象，通过channel发送出去。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public class ChannelEventRunnable implements Runnable &#123; public void run() &#123; if (state == ChannelState.RECEIVED) &#123; try &#123; handler.received(channel, message); &#125; catch (Exception e) &#123;&#125; &#125; else &#123; switch (state) &#123; case CONNECTED: try &#123; handler.connected(channel); &#125; catch (Exception e) &#123;&#125; break; case DISCONNECTED: try &#123; handler.disconnected(channel); &#125; catch (Exception e) &#123;&#125; break; case SENT: try &#123; handler.sent(channel, message); &#125; catch (Exception e) &#123;&#125; break; case CAUGHT: try &#123; handler.caught(channel, exception); &#125; catch (Exception e) &#123;&#125; break; default: &#125; &#125; &#125;&#125;public class DecodeHandler extends AbstractChannelHandlerDelegate &#123; public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof Decodeable) &#123; decode(message); &#125; if (message instanceof Request) &#123; decode(((Request) message).getData()); &#125; if (message instanceof Response) &#123; decode(((Response) message).getResult()); &#125; handler.received(channel, message); &#125; private void decode(Object message) &#123; if (message instanceof Decodeable) &#123; try &#123; ((Decodeable) message).decode(); &#125; catch (Throwable e) &#123;&#125; // ~ end of catch &#125; // ~ end of if &#125; // ~ end of method decode&#125;public class HeaderExchangeHandler implements ChannelHandlerDelegate &#123; public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); final ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; if (message instanceof Request) &#123;// handle request. Request request = (Request) message; if (request.isEvent()) &#123; handlerEvent(channel, request); &#125; else &#123; if (request.isTwoWay()) &#123;// 如果是双向通行，则需要返回调用结果 handleRequest(exchangeChannel, request); &#125; else &#123;// 如果是单向通信，仅向后调用指定服务即可，无需返回调用结果 handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123;// 客户端接收到服务响应结果 handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception e = new Exception(\"Dubbo client can not supported string message: \" + message + \" in channel: \" + channel + \", url: \" + channel.getUrl()); logger.error(e.getMessage(), e); &#125; else &#123; String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125; &#125; void handleRequest(final ExchangeChannel channel, Request req) throws RemotingException &#123; Response res = new Response(req.getId(), req.getVersion()); // 请求id，请求版本 if (req.isBroken()) &#123;// 请求处理失败 Object data = req.getData(); String msg; if (data == null) &#123; msg = null; &#125; else if (data instanceof Throwable) &#123; msg = StringUtils.toString((Throwable) data); &#125; else &#123; msg = data.toString(); &#125; res.setErrorMessage(\"Fail to decode request due to: \" + msg); res.setStatus(Response.BAD_REQUEST); // 设置 BAD_REQUEST 状态 channel.send(res); return; &#125; // find handler by message class. 获取data字段值，也就是RpcInvocation对象，表示请求内容 Object msg = req.getData(); try &#123;// 继续向下调用，分异步调用和同步调用，若是同步则会阻塞，若是异步则不会阻塞 CompletionStage&lt;Object&gt; future = handler.reply(channel, msg); // 异步执行服务 // 若是同步调用则直接拿到结果，并发送到channel中去，若是异步调用则会监听，直到拿到服务执行结果，然后发送到channel中去 future.whenComplete((appResult, t) -&gt; &#123; try &#123; if (t == null) &#123; res.setStatus(Response.OK); res.setResult(appResult); &#125; else &#123;// 服务执行过程中出现了异常，则把Throwable转成字符串，发送给channel中，也就是发送给客户端 res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(t)); &#125; channel.send(res); &#125; catch (RemotingException e) &#123;&#125; &#125;); &#125; catch (Throwable e) &#123; res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(e)); channel.send(res); &#125; &#125;&#125; 从本机已导出的Exporter中根据当前Request所对应的服务key获取Exporter对象，从Exporter中得到Invoker然后执行invoke方法，此Invoker为ProtocolFilterWrapper$CallbackRegistrationInvoker。完成执行过滤器链，且在执行完后回调每个过滤器的onResponse或onError方法： EchoFilter：断当前请求是否为回声测试，若是则不继续执行过滤器链 ClassLoaderFilter：设置当前线程classloader为当前要执行服务接口所对应的classloader GenericFilter：把泛化调用发送过来的信息包装为RpcInvocation对象 ContextFilter：设置RpcContext.getContext参数 TraceFilter：先执行下一个invoker的invoke方法，调用成功后录调用信息 TimeoutFilter：调用时没有特别处理只记录一下当前时间，当整个filter链执行完后回调TimeoutFilter的onResponse方法判断本次调用是否超过timeout MonitorFilter：记录当前服务的执行次数 ExceptionFilter：调用时没有特别处理，回调onResponse方法时对不同异常进行处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public class DubboProtocol extends AbstractProtocol &#123; private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123; @Override public CompletableFuture&lt;Object&gt; reply(ExchangeChannel channel, Object message) throws RemotingException &#123; if (!(message instanceof Invocation)) &#123; throw new RemotingException(channel, \"Unsupported request: \" + (message == null ? null : (message.getClass().getName() + \": \" + message)) + \", channel: consumer: \" + channel.getRemoteAddress() + \" --&gt; provider: \" + channel.getLocalAddress()); &#125; Invocation inv = (Invocation) message; // 转成Invocation对象，要开始用反射执行方法了 Invoker&lt;?&gt; invoker = getInvoker(channel, inv); // 服务实现者 if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE))) &#123; String methodsStr = invoker.getUrl().getParameters().get(\"methods\"); boolean hasMethod = false; if (methodsStr == null || !methodsStr.contains(\",\")) &#123; hasMethod = inv.getMethodName().equals(methodsStr); &#125; else &#123; String[] methods = methodsStr.split(\",\"); for (String method : methods) &#123; if (inv.getMethodName().equals(method)) &#123; hasMethod = true; break; &#125; &#125; &#125; if (!hasMethod) &#123; return null; &#125; &#125; RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress());// 这里设置了，service中才能拿到remoteAddress Result result = invoker.invoke(inv);// 执行服务，得到结果 return result.completionFuture().thenApply(Function.identity()); // 返回一个CompletableFuture &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof Invocation) &#123; reply((ExchangeChannel) channel, message); // 这是服务端接收到Invocation时的处理逻辑 &#125; else &#123; super.received(channel, message); &#125; &#125; @Override public void connected(Channel channel) throws RemotingException &#123; invoke(channel, ON_CONNECT_KEY); &#125; @Override public void disconnected(Channel channel) throws RemotingException &#123; invoke(channel, ON_DISCONNECT_KEY); &#125; private void invoke(Channel channel, String methodKey) &#123; Invocation invocation = createInvocation(channel, channel.getUrl(), methodKey); if (invocation != null) &#123; try &#123; received(channel, invocation); &#125; catch (Throwable t) &#123;&#125; &#125; &#125; private Invocation createInvocation(Channel channel, URL url, String methodKey) &#123; String method = url.getParameter(methodKey); if (method == null || method.length() == 0) &#123; return null; &#125; RpcInvocation invocation = new RpcInvocation(method, new Class&lt;?&gt;[0], new Object[0]); invocation.setAttachment(PATH_KEY, url.getPath()); invocation.setAttachment(GROUP_KEY, url.getParameter(GROUP_KEY)); invocation.setAttachment(INTERFACE_KEY, url.getParameter(INTERFACE_KEY)); invocation.setAttachment(VERSION_KEY, url.getParameter(VERSION_KEY)); if (url.getParameter(STUB_EVENT_KEY, false)) &#123; invocation.setAttachment(STUB_EVENT_KEY, Boolean.TRUE.toString()); &#125; return invocation; &#125; &#125;; Invoker&lt;?&gt; getInvoker(Channel channel, Invocation inv) throws RemotingException &#123; boolean isCallBackServiceInvoke = false; boolean isStubServiceInvoke = false; int port = channel.getLocalAddress().getPort(); String path = inv.getAttachments().get(PATH_KEY); isStubServiceInvoke = Boolean.TRUE.toString().equals(inv.getAttachments().get(STUB_EVENT_KEY)); if (isStubServiceInvoke) &#123; port = channel.getRemoteAddress().getPort(); &#125; isCallBackServiceInvoke = isClientSide(channel) &amp;&amp; !isStubServiceInvoke; //callback if (isCallBackServiceInvoke) &#123; path += \".\" + inv.getAttachments().get(CALLBACK_SERVICE_KEY); inv.getAttachments().put(IS_CALLBACK_SERVICE_INVOKE, Boolean.TRUE.toString()); &#125; // 从请求中拿到serviceKey，从exporterMap中拿到已经导出了的服务 String serviceKey = serviceKey(port, path, inv.getAttachments().get(VERSION_KEY), inv.getAttachments().get(GROUP_KEY)); DubboExporter&lt;?&gt; exporter = (DubboExporter&lt;?&gt;) exporterMap.get(serviceKey); if (exporter == null) &#123; throw new RemotingException(channel, \"Not found exported service: \" + serviceKey + \" in \" + exporterMap.keySet() + \", may be version or group mismatch , channel: consumer: \" + channel.getRemoteAddress() + \" --&gt; provider: \" + channel.getLocalAddress() + \", message:\" + inv); &#125; return exporter.getInvoker(); // 拿到服务对应的Invoker &#125;&#125;public class ProtocolFilterWrapper implements Protocol &#123; static class CallbackRegistrationInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult = filterInvoker.invoke(invocation); // 执行过滤器链 // 过滤器都执行完了之后，回调每个ListenableFilter过滤器的onResponse或onError方法 asyncResult = asyncResult.whenCompleteWithContext((r, t) -&gt; &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; Filter filter = filters.get(i); if (filter instanceof ListenableFilter) &#123; // onResponse callback Filter.Listener listener = ((ListenableFilter) filter).listener(); if (listener != null) &#123; if (t == null) &#123; listener.onResponse(r, filterInvoker, invocation); &#125; else &#123; listener.onError(t, filterInvoker, invocation); &#125; &#125; &#125; else &#123; filter.onResponse(r, filterInvoker, invocation); &#125; &#125; &#125;); return asyncResult; &#125; &#125;&#125; 执行完过滤器链后，通过InvokerWrapper到DelegateProviderMetaDataInvoker调用AbstractProxyInvoker，在服务导出时根据服务接口服务实现类对象生成，其invoke方法调用JavassistProxyFactory的doInvoke方法真正执行服务实现类对象方法得到结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class InvokerWrapper&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation); &#125;&#125;public class DelegateProviderMetaDataInvoker&lt;T&gt; implements Invoker &#123; public Result invoke(Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation); &#125;&#125;public abstract class AbstractProxyInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; // 执行服务，得到一个接口，可能是一个CompletableFuture(表示异步调用)，可能是一个正常的服务执行结果（同步调用） Object value = doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()); CompletableFuture&lt;Object&gt; future = wrapWithFuture(value, invocation); // 将同步调用的服务执行结果封装为CompletableFuture类型 AsyncRpcResult asyncRpcResult = new AsyncRpcResult(invocation); // 异步RPC结果 future.whenComplete((obj, t) -&gt; &#123; //设置一个回调，若是异步调用，则服务执行完成后将执行这里的回调 // 当服务执行完后，将结果或异常设置到AsyncRpcResult中，若是异步服务，则服务之后的异常会在此处封装到AppResponse中然后返回，若是同步服务出异常了，则会在下面将异常封装到AsyncRpcResult中 AppResponse result = new AppResponse(); if (t != null) &#123; if (t instanceof CompletionException) &#123; result.setException(t.getCause()); &#125; else &#123; result.setException(t); &#125; &#125; else &#123; result.setValue(obj); &#125; asyncRpcResult.complete(result); // 将服务执行完之后的结果设置到异步RPC结果对象中 &#125;); return asyncRpcResult;// 返回异步RPC结果 &#125; catch (InvocationTargetException e) &#123;// 假设抛的NullPointException，那么会把这个异常包装为一个Result对象 // 同步服务执行时如何出异常了，会在此处将异常信息封装为一个AsyncRpcResult然后返回 return AsyncRpcResult.newDefaultAsyncResult(null, e.getTargetException(), invocation); &#125; catch (Throwable e) &#123;// 执行服务后的所有异常都会包装为RpcException进行抛出 throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125;&#125;public class JavassistProxyFactory extends AbstractProxyFactory &#123; @Override public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // 若现在被代理对象proxy本身就是一个已经被代理过的对象，则取代理类的Wrapper，否则取type接口的Wrapper // Wrapper是针对某个类或某个接口的包装类，通过wrapper对象可以更方便的去执行某个类或某个接口的方法 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123;// proxy是服务实现类 type是服务接口 url是一个注册中心url @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; // 执行proxy的method方法，执行的proxy实例的方法，若没有wrapper，则要通过原生的反射技术去获取Method对象，然后执行 return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125;&#125; 异常处理当服务消费者在调用一个服务时，服务提供者在执行服务逻辑时可能会出现异常，服务消费者需要在消费端抛出该异常。 服务提供者在执行服务时若出现了异常，框架会把异常捕获，捕获异常的逻辑在AbstractProxyInvoker中，捕获到异常后，把异常信息包装为正常的AppResponse对象，其value属性为null，exception属性有值。 然后服务提供者会把该AppResponse对象发送给服务消费端，服务消费端是在InvokerInvocationHandler中调用AppResponse的recreate方法重新得到一个结果，在recreate方法中会去判断AppResponse对象是否正常，即是否存在exception信息，若存在则直接throw该exception，从而做到服务执行时出现的异常，在服务消费端抛出。 若服务提供者抛出的异常类消费者端不存在，消费者也就抛不出该异常，则需要服务提供者端ExceptionFilter过滤器，其主要是在服务提供者执行完服务后会去识别异常： 若为需要开发人员捕获的异常，则忽略直接把该异常返回给消费者 若当前所执行的方法签名上有声明，则忽略直接把该异常返回给消费者 若抛出异常不需要开发人员捕获，或方法上没有申明，则服务端记录一个error日志 若异常类和接口类在同一Jar包里，则忽略直接把该异常返回给消费者 若异常类是JDK自带异常，则忽略直接把该异常返回给消费者 若异常类是Dubbo自带异常，则忽略直接把该异常返回给消费者 若不是以上情况，则把异常信息包装成RuntimeException，并覆盖AppResponse对象中的exception属性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ExceptionFilter extends ListenableFilter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation); &#125; static class ExceptionListener implements Listener &#123; private Logger logger = LoggerFactory.getLogger(ExceptionListener.class); @Override public void onResponse(Result appResponse, Invoker&lt;?&gt; invoker, Invocation invocation) &#123; if (appResponse.hasException() &amp;&amp; GenericService.class != invoker.getInterface()) &#123; try &#123; Throwable exception = appResponse.getException(); if (!(exception instanceof RuntimeException) &amp;&amp; (exception instanceof Exception)) &#123; return; // 如果是checked异常，直接抛出 &#125; try &#123; // 在方法签名上有声明，直接抛出 Method method = invoker.getInterface().getMethod(invocation.getMethodName(), invocation.getParameterTypes()); Class&lt;?&gt;[] exceptionClassses = method.getExceptionTypes(); for (Class&lt;?&gt; exceptionClass : exceptionClassses) &#123; if (exception.getClass().equals(exceptionClass)) &#123; return; &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; return; &#125; // 未在方法签名上定义的异常，在服务器端打印ERROR日志 logger.error(\"Got unchecked and undeclared exception which called by \" + RpcContext.getContext().getRemoteHost() + \". service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", exception: \" + exception.getClass().getName() + \": \" + exception.getMessage(), exception); String serviceFile = ReflectUtils.getCodeBase(invoker.getInterface()); String exceptionFile = ReflectUtils.getCodeBase(exception.getClass()); if (serviceFile == null || exceptionFile == null || serviceFile.equals(exceptionFile)) &#123; return; // 异常类和接口类在同一jar包里，直接抛出 &#125; String className = exception.getClass().getName(); if (className.startsWith(\"java.\") || className.startsWith(\"javax.\")) &#123; return; // 是JDK自带的异常，直接抛出 &#125; if (exception instanceof RpcException) &#123; return; // 是Dubbo本身的异常，直接抛出 &#125; appResponse.setException(new RuntimeException(StringUtils.toString(exception))); // 否则，包装成RuntimeException抛给客户端 return; &#125; catch (Throwable e) &#123; return; &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://yaoyinglong.github.io/tags/Dubbo/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Dubbo","slug":"Cloud/Dubbo","permalink":"https://yaoyinglong.github.io/categories/Cloud/Dubbo/"}]},{"title":"Dubbo服务引入","date":"2021-12-15T16:00:00.000Z","path":"Blog/Cloud/Dubbo/Dubbo服务引入/","text":"Spring启动过程中会将@Reference注解标注的属性赋值，赋值对象为ReferenceBean中get()方法所返回的代理对象。ReferenceBean实现了FactoryBean接口，在其getObject方法中调用的get方法。ReferenceBean跟ServiceBean类似也实现了ApplicationContextAware接口，在setApplicationContext方法中同样将applicationContext添加到SpringExtensionFactory中。 12345678910111213141516public class ReferenceBean&lt;T&gt; extends ReferenceConfig&lt;T&gt; implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean &#123; private transient ApplicationContext applicationContext; public void setApplicationContext(ApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; SpringExtensionFactory.addApplicationContext(applicationContext); &#125; public Object getObject() &#123; return get(); // 调用超类ReferenceConfig的get方法 &#125; public void afterPropertiesSet() throws Exception &#123;// 该方法给ReferenceBean对象的属性赋值 // 此处省略了一些列属性填充代码 if (shouldInit()) &#123; getObject(); &#125; &#125;&#125; 调用超类ReferenceConfig的get方法时跟服务导出类似同样先调用checkAndUpdateSubConfigs检查和更新参数，将ReferenceBean中的属性值更新为优先级最高的参数值，然后调用init方法成代理对象ref。在init方法中首先将消费者所引入服务设置的参数解析到一个map中，后续会根据该map中的参数从注册中心查找服务。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class ReferenceConfig&lt;T&gt; extends AbstractReferenceConfig &#123; public synchronized T get() &#123; checkAndUpdateSubConfigs(); if (destroyed) &#123; throw new IllegalStateException(\"The invoker of ReferenceConfig(\" + url + \") has already destroyed!\"); &#125; if (ref == null) &#123;// 入口 init(); &#125; return ref; // Invoke代理 &#125; public void checkAndUpdateSubConfigs() &#123; if (StringUtils.isEmpty(interfaceName)) &#123; throw new IllegalStateException(\"&lt;dubbo:reference interface=\\\"\\\" /&gt; interface not allow null!\"); &#125; completeCompoundConfigs(); // 填充ReferenceConfig对象中的属性 startConfigCenter(); // 开启配置中心 checkDefault(); // get consumer's global configuration this.refresh(); // 刷新ReferenceConfig对象的属性值 if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123; // 设置泛化 setGeneric(getConsumer().getGeneric()); &#125; if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; &#125; else &#123; try &#123; interfaceClass = Class.forName(interfaceName, true, Thread.currentThread().getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; checkInterfaceAndMethods(interfaceClass, methods); &#125; resolveFile(); checkApplication(); checkMetadataReport(); &#125; private void init() &#123; if (initialized) &#123; return; &#125; checkStubAndLocal(interfaceClass); checkMock(interfaceClass); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(SIDE_KEY, CONSUMER_SIDE); appendRuntimeParameters(map); if (!ProtocolUtils.isGeneric(getGeneric())) &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put(REVISION_KEY, revision); &#125; // 通过接口对应的Wrapper，拿到接口中所有的方法名字 String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) &#123; map.put(METHODS_KEY, ANY_VALUE); &#125; else &#123; map.put(METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), COMMA_SEPARATOR)); &#125; &#125; map.put(INTERFACE_KEY, interfaceName); appendParameters(map, metrics); // 监控中心参数 appendParameters(map, application); // 应用相关参数 appendParameters(map, module); // 模块相关参数 appendParameters(map, consumer); // 提供者相关参数 appendParameters(map, this); // 服务本身相关参数 Map&lt;String, Object&gt; attributes = null; if (CollectionUtils.isNotEmpty(methods)) &#123; // 方法参数：@Reference(methods = &#123;@Method(name = \"say\", timeout = 3000)&#125;) attributes = new HashMap&lt;String, Object&gt;(); for (MethodConfig methodConfig : methods) &#123; appendParameters(map, methodConfig, methodConfig.getName()); String retryKey = methodConfig.getName() + \".retry\"; if (map.containsKey(retryKey)) &#123; // 若某个方法配置存在xx.retry=false，则改成xx.retry=0 String retryValue = map.remove(retryKey); if (\"false\".equals(retryValue)) &#123; map.put(methodConfig.getName() + \".retries\", \"0\"); &#125; &#125; attributes.put(methodConfig.getName(), convertMethodConfig2AsyncInfo(methodConfig)); &#125; &#125; String hostToRegistry = ConfigUtils.getSystemProperty(DUBBO_IP_TO_REGISTRY); if (StringUtils.isEmpty(hostToRegistry)) &#123; hostToRegistry = NetUtils.getLocalHost(); &#125; else if (isInvalidLocalHost(hostToRegistry)) &#123; throw new IllegalArgumentException(\"Specified invalid registry ip from property:\" + DUBBO_IP_TO_REGISTRY + \", value:\" + hostToRegistry); &#125; map.put(REGISTER_IP_KEY, hostToRegistry); ref = createProxy(map); // 根据map中的参数创建代理对象 String serviceKey = URL.buildKey(interfaceName, group, version); ApplicationModel.initConsumerModel(serviceKey, buildConsumerModel(serviceKey, attributes)); initialized = true; &#125;&#125; 若为本地调用则生成一个本地URL，然后调用Protocol的refer方法得到一个Invoker对象，若为远程调用首先判断@Reference注解中url属性指定的注册中心地址是否存在，若存在则解析出注册中心的地址列表暂存到urls属性中，解析url判断若为注册中心地址，则在url中添加一个refer参数，将map中存储的消费端参数设置到refer中，若为服务地址，可能url中配置了参数，则需要将服务端的参数合并补全到消费端参数。若@Reference注解中url属性未设置，则加载注册中心地址列表，然后遍历加载到的地址，将消费端参数添加到注册中心地址URL中的REFER_KEY中。 解析得到urls后，若只有一个注册中心地址则直接refer得到一个invoker，若有多个注册中心地址，则遍历每个注册中心，分别调用refer方法得到Invoker且添加到invokers中，然后把invokers调用CLUSTER.join封装所有invokers得到一个invoker，CLUSTER为一个SPI扩展接口Cluster，CLUSTER默认实现为FailoverCluster。最终将得到的invoker对象调用PROXY_FACTORY.getProxy得到一个代理对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class ReferenceConfig&lt;T&gt; extends AbstractReferenceConfig &#123; private T createProxy(Map&lt;String, String&gt; map) &#123; if (shouldJvmRefer(map)) &#123; // 若是本地调用即以injvm://开头的协议 URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map); invoker = REF_PROTOCOL.refer(interfaceClass, url); &#125; else &#123;// 之所以有urls，因为可在@Reference的url属性中配置多个url，可以是点对点的服务地址，也可以是注册中心的地址 urls.clear(); // reference retry init will add url to urls, lead to OOM if (url != null &amp;&amp; url.length() &gt; 0) &#123; // @Reference中指定了url属性 String[] us = SEMICOLON_SPLIT_PATTERN.split(url); // 用;号切分 if (us != null &amp;&amp; us.length &gt; 0) &#123; for (String u : us) &#123; URL url = URL.valueOf(u); if (StringUtils.isEmpty(url.getPath())) &#123; url = url.setPath(interfaceName); &#125; if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; // 若是注册中心地址，则在url中添加一个refer参数 urls.add(url.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); // map表示消费者端配置的参数 &#125; else &#123;// 若是服务地址，有可能url中配置了参数，map中表示的服务消费者消费服务时的参数，所以需要合并 urls.add(ClusterUtils.mergeUrl(url, map)); &#125; &#125; &#125; &#125; else &#123; // @Reference中的protocol属性表示使用哪个协议调用服务，若不是本地调用协议injvm://，则把注册中心地址找出来，对于injvm://协议已经在之前的逻辑中就已经生成invoke了 if (!LOCAL_PROTOCOL.equalsIgnoreCase(getProtocol())) &#123; checkRegistry(); List&lt;URL&gt; us = loadRegistries(false); // 加载注册中心地址 if (CollectionUtils.isNotEmpty(us)) &#123; for (URL u : us) &#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &#123; map.put(MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; urls.add(u.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); // 对于注册中心地址都添加REFER_KEY &#125; &#125; if (urls.isEmpty()) &#123; throw new IllegalStateException(\"No such any registry to reference \" + interfaceName + \" on the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please config &lt;dubbo:registry address=\\\"...\\\" /&gt; to your spring config.\"); &#125; &#125; &#125; if (urls.size() == 1) &#123; // 若只有一个url则直接refer得到一个invoker invoker = REF_PROTOCOL.refer(interfaceClass, urls.get(0)); // RegistryProtocol.refer() 或 DubboProtocol.refer() // MockClusterInvoker--&gt;FailoverClusterInvoker--&gt;RegistryDirectory // ---&gt;RegistryDirectory$InvokerDelegate--&gt;ListenerInvokerWrapper--&gt;ProtocolFilterWrapper$CallbackRegistrationInvoker--&gt;ConsumerContextFilter--&gt;FutureFilter--&gt;MonitorFilter--&gt;AsyncToSyncInvoker--&gt;DubboInvoker // ---&gt;RegistryDirectory$InvokerDelegate--&gt;ListenerInvokerWrapper--&gt;ProtocolFilterWrapper$CallbackRegistrationInvoker--&gt;ConsumerContextFilter--&gt;FutureFilter--&gt;MonitorFilter--&gt;AsyncToSyncInvoker--&gt;DubboInvoker &#125; else &#123;// 若这多个urls中不存在注册中心url，则把所有invoker整合为FailoverCluster // 若有多个url根据每个url，refer得到对应的invoker，若这多个urls中存在注册中心url，则把所有invoker整合为RegistryAwareClusterInvoker，该Invoker在调用时，会查看所有Invoker中是否有默认的，若有则使用默认Invoker，若没有则使用第一个Invoker List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; // 用来记录urls中最后一个注册中心url for (URL url : urls) &#123; invokers.add(REF_PROTOCOL.refer(interfaceClass, url)); if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; // use last registry url &#125; &#125; if (registryURL != null) &#123; // registry url is available use RegistryAwareCluster only when register's CLUSTER is available URL u = registryURL.addParameter(CLUSTER_KEY, RegistryAwareCluster.NAME); // 若存在注册中心地址 // The invoker wrap relation would be: RegistryAwareClusterInvoker(StaticDirectory) -&gt; FailoverClusterInvoker(RegistryDirectory, will execute route) -&gt; Invoker invoker = CLUSTER.join(new StaticDirectory(u, invokers));// StaticDirectory表示静态服务目录，里面的invokers是不会变的, 生成一个RegistryAwareCluster &#125; else &#123; // not a registry url, must be direct invoke. invoker = CLUSTER.join(new StaticDirectory(invokers)); // 若不存在注册中心地址, 生成一个FailoverClusterInvoker &#125; &#125; &#125; if (shouldCheck() &amp;&amp; !invoker.isAvailable()) &#123; throw new IllegalStateException(\"Failed to check the status of the service \" + interfaceName + \". No provider available for the service \" + (group == null ? \"\" : group + \"/\") + interfaceName + (version == null ? \"\" : \":\" + version) + \" from the url \" + invoker.getUrl() + \" to the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion()); &#125; MetadataReportService metadataReportService = null; if ((metadataReportService = getMetadataReportService()) != null) &#123; URL consumerURL = new URL(CONSUMER_PROTOCOL, map.remove(REGISTER_IP_KEY), 0, map.get(INTERFACE_KEY), map); metadataReportService.publishConsumer(consumerURL); &#125; return (T) PROXY_FACTORY.getProxy(invoker);// create service proxy &#125;&#125; 和服务导出一样这里的Protocol会有ProtocolListenerWrapper和ProtocolFilterWrapper两个Wrapper，但这两个Wrapper没有做什么事，最终掉到RegistryProtocol，首先根据URL获取Registry，然后在doRefer中根据URL和接口生成RegistryDirectory动态服务目录，然后将消费者注册到注册中心。然后通过RegistryDirectory的buildRouterChain构造路由链，然后订阅服务当前应用对应的服务提供者目录、动态配置目录、路由器目录。然后将生成的RegistryDirectory作为参数调用Cluster的MockClusterWrapper子类的join方法将具体的Invoker包装成MockClusterInvoker。若消费者引入了多个group中的服务则生成MergeableClusterInvoker否则生成FailoverClusterInvoker。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ProtocolListenerWrapper implements Protocol &#123; public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; // dubbo:// return protocol.refer(type, url); &#125; return new ListenerInvokerWrapper&lt;T&gt;(protocol.refer(type, url), Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(InvokerListener.class).getActivateExtension(url, INVOKER_LISTENER_KEY))); &#125;&#125;public class ProtocolFilterWrapper implements Protocol &#123; public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; // dubbo:// return protocol.refer(type, url); &#125; return buildInvokerChain(protocol.refer(type, url), REFERENCE_FILTER_KEY, CommonConstants.CONSUMER); &#125;&#125;public class RegistryProtocol implements Protocol &#123; public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 从registry://的url中获取对应的注册中心，如zookeeper，默认为dubbo，dubbo提供了自带的注册中心实现，url由registry://改变为---&gt;zookeeper:// url = URLBuilder.from(url).setProtocol(url.getParameter(REGISTRY_KEY, DEFAULT_REGISTRY)).removeParameter(REGISTRY_KEY).build(); Registry registry = registryFactory.getRegistry(url); // 拿到注册中心实现，ZookeeperRegistry if (RegistryService.class.equals(type)) &#123; // 用来解决SimpleRegistry不可用的问题 return proxyFactory.getInvoker((T) registry, type, url); &#125; // qs表示queryString, 表示url中的参数，表示消费者引入服务时所配置的参数 Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(REFER_KEY)); // group=\"a,b\" or group=\"*\" // https://dubbo.apache.org/zh/docs/v2.7/user/examples/group-merger/ String group = qs.get(GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0) &#123; if ((COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || \"*\".equals(group)) &#123; return doRefer(getMergeableCluster(), registry, type, url); // group有多个值，这里的cluster为MergeableCluster &#125; &#125; return doRefer(cluster, registry, type, url); // 这里的cluster是cluster的Adaptive对象,扩展点 &#125; private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; // RegistryDirectory表示动态服务目录，会和注册中心的数据保持同步，type表示一个服务对应一个RegistryDirectory，url表示注册中心地址 RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); // 在消费端，最核心的就是RegistryDirectory directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY 引入服务所配置的参数 Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters()); // 消费者url URL subscribeUrl = new URL(CONSUMER_PROTOCOL, parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters); if (!ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(REGISTER_KEY, true)) &#123; directory.setRegisteredConsumerUrl(getRegisteredConsumerUrl(subscribeUrl, url)); registry.register(directory.getRegisteredConsumerUrl()); // 注册消费者，注册简化后的消费url &#125; // 构造路由链,路由链会在引入服务时按路由条件进行过滤，路由链是动态服务目录中的一个属性，通过路由链可以过滤某些服务提供者 directory.buildRouterChain(subscribeUrl); // 服务目录需要订阅的几个路径 // 当前应用所对应的动态配置目录：/dubbo/config/dubbo/dubbo-demo-consumer-application.configurators // 当前所引入的服务的动态配置目录：/dubbo/config/dubbo/org.apache.dubbo.demo.DemoService:1.1.1:g1.configurators // 当前所引入的服务的提供者目录：/dubbo/org.apache.dubbo.demo.DemoService/providers // 当前所引入的服务的老版本动态配置目录：/dubbo/org.apache.dubbo.demo.DemoService/configurators // 当前所引入的服务的老版本路由器目录：/dubbo/org.apache.dubbo.demo.DemoService/routers directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY, PROVIDERS_CATEGORY + \",\" + CONFIGURATORS_CATEGORY + \",\" + ROUTERS_CATEGORY)); Invoker invoker = cluster.join(directory); // 利用传进来的cluster，join得到invoker, MockClusterWrapper ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker; &#125;&#125; 上面调用RegistryFactory的getRegistry方法实际调到AbstractRegistryFactory中，最终通过ZookeeperRegistryFactory创建一个ZookeeperRegistry实例，在doRefer方法中实际注册消费端到注册中心时最终调用ZookeeperRegistry的doRegister方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public abstract class AbstractRegistryFactory implements RegistryFactory &#123; public Registry getRegistry(URL url) &#123; url = URLBuilder.from(url).setPath(RegistryService.class.getName()).addParameter(INTERFACE_KEY, RegistryService.class.getName()).removeParameters(EXPORT_KEY, REFER_KEY).build(); String key = url.toServiceStringWithoutResolving(); LOCK.lock(); // Lock the registry access process to ensure a single instance of the registry try &#123; Registry registry = REGISTRIES.get(key); if (registry != null) &#123; return registry; &#125; registry = createRegistry(url); //create registry by spi/ioc if (registry == null) &#123; throw new IllegalStateException(\"Can not create registry \" + url); &#125; REGISTRIES.put(key, registry); return registry; &#125; finally &#123; LOCK.unlock(); // Release the lock &#125; &#125;&#125;public class ZookeeperRegistryFactory extends AbstractRegistryFactory &#123; public Registry createRegistry(URL url) &#123; return new ZookeeperRegistry(url, zookeeperTransporter); &#125;&#125;public abstract class FailbackRegistry extends AbstractRegistry &#123; public void register(URL url) &#123; super.register(url); removeFailedRegistered(url); removeFailedUnregistered(url); try &#123;// Sending a registration request to the server side doRegister(url); &#125; catch (Exception e) &#123; Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(\"Failed to register \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); &#125; // Record a failed registration request to a failed list, retry regularly addFailedRegistered(url); &#125; &#125;&#125;public class ZookeeperRegistry extends FailbackRegistry &#123; public void doRegister(URL url) &#123; try &#123; zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125;&#125; 路由链构造在获得路由链时就要根据URL参数去匹配得到符合当前的服务的Router，最终可以拿到MockRouterFactory、TagRouterFactory、AppRouterFactory、ServiceRouterFactory四个路由工厂。遍历每个RouterFactory调用其getRouter方法得到Router并存到routers中进行排序处理。 12345678910111213141516171819202122232425262728public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener &#123; public void buildRouterChain(URL url) &#123; this.setRouterChain(RouterChain.buildChain(url)); &#125;&#125;public class RouterChain&lt;T&gt; &#123; public static &lt;T&gt; RouterChain&lt;T&gt; buildChain(URL url) &#123; return new RouterChain&lt;&gt;(url); &#125; private RouterChain(URL url) &#123; // 拿到RouterFactory接口有哪些扩展实现类，比如默认情况下就有四个： // 0 = &#123;MockRouterFactory@2880&#125; // 1 = &#123;TagRouterFactory@2881&#125; // 标签路由 // 2 = &#123;AppRouterFactory@2882&#125; // 应用条件路由 // 3 = &#123;ServiceRouterFactory@2883&#125; // 服务条件路由 List&lt;RouterFactory&gt; extensionFactories = ExtensionLoader.getExtensionLoader(RouterFactory.class).getActivateExtension(url, (String[]) null); // 然后利用RouterFactory根据url生成各个类型的Router，这里生产的routers已经是真实可用的了，但是有个比较特殊的： // 对于应用条件路由和服务条件路由对应的Router对象，对象内部已经有真实可用的数据了，数据已经从配置中心得到了 // 但是对于标签路由则没有，它暂时还相当于一个没有内容的对象，还没有从配置中心获取标签路由的数据 List&lt;Router&gt; routers = extensionFactories.stream().map(factory -&gt; factory.getRouter(url)).collect(Collectors.toList()); initWithRouters(routers); // 把routers按priority进行排序 &#125; public void initWithRouters(List&lt;Router&gt; builtinRouters) &#123; this.builtinRouters = builtinRouters; this.routers = new ArrayList&lt;&gt;(builtinRouters); this.sort(); &#125;&#125; AppRouter和ServiceRouter是非常类似，他们的父类都是ListenableRouter，在创建AppRouter和ServiceRouter时会绑定一个监听器，然后主动去获取一下对应节点所配置的路由规则，然后解析得到ConditionRouterRule，再调用generateConditions方法解析出一个或多个ConditionRouter，并存入到conditionRouters中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139public class AppRouterFactory implements RouterFactory &#123; public static final String NAME = \"app\"; private volatile Router router; @Override public Router getRouter(URL url) &#123; if (router != null) &#123; return router; &#125; synchronized (this) &#123; if (router == null) &#123; router = createRouter(url); &#125; &#125; return router; &#125; private Router createRouter(URL url) &#123;// 内部会进行初始化 return new AppRouter(DynamicConfiguration.getDynamicConfiguration(), url); &#125;&#125;public interface DynamicConfiguration extends Configuration &#123; static DynamicConfiguration getDynamicConfiguration() &#123; Optional&lt;Configuration&gt; optional = Environment.getInstance().getDynamicConfiguration(); return (DynamicConfiguration) optional.orElseGet(() -&gt; getExtensionLoader(DynamicConfigurationFactory.class).getDefaultExtension().getDynamicConfiguration(null)); &#125;&#125;public class ZookeeperDynamicConfigurationFactory extends AbstractDynamicConfigurationFactory &#123; protected DynamicConfiguration createDynamicConfiguration(URL url) &#123; return new ZookeeperDynamicConfiguration(url, zookeeperTransporter); &#125;&#125;public class ZookeeperDynamicConfiguration implements DynamicConfiguration &#123; ZookeeperDynamicConfiguration(URL url, ZookeeperTransporter zookeeperTransporter) &#123; this.url = url; rootPath = PATH_SEPARATOR + url.getParameter(CONFIG_NAMESPACE_KEY, DEFAULT_GROUP) + \"/config\"; initializedLatch = new CountDownLatch(1); this.cacheListener = new CacheListener(rootPath, initializedLatch); this.executor = Executors.newFixedThreadPool(1, new NamedThreadFactory(this.getClass().getSimpleName(), true)); zkClient = zookeeperTransporter.connect(url); zkClient.addDataListener(rootPath, cacheListener, executor); try &#123;// Wait for connection long timeout = url.getParameter(\"init.timeout\", 5000); boolean isCountDown = this.initializedLatch.await(timeout, TimeUnit.MILLISECONDS); if (!isCountDown) &#123; throw new IllegalStateException(\"Failed to receive INITIALIZED event from zookeeper, pls. check if url \" + url + \" is correct\"); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125;public class CacheListener implements DataListener &#123; public void dataChanged(String path, Object value, EventType eventType) &#123; if (eventType == null) &#123; return; &#125; if (eventType == EventType.INITIALIZED) &#123; initializedLatch.countDown(); return; &#125; if (path == null || (value == null &amp;&amp; eventType != EventType.NodeDeleted)) &#123; return; &#125; if (path.split(\"/\").length &gt;= MIN_PATH_DEPTH) &#123; String key = pathToKey(path); ConfigChangeType changeType; switch (eventType) &#123; case NodeCreated: changeType = ConfigChangeType.ADDED; break; case NodeDeleted: changeType = ConfigChangeType.DELETED; break; case NodeDataChanged: changeType = ConfigChangeType.MODIFIED; break; default: return; &#125; ConfigChangeEvent configChangeEvent = new ConfigChangeEvent(key, (String) value, changeType); Set&lt;ConfigurationListener&gt; listeners = keyListeners.get(path); if (CollectionUtils.isNotEmpty(listeners)) &#123; listeners.forEach(listener -&gt; listener.process(configChangeEvent)); &#125; &#125; &#125;&#125;public class AppRouter extends ListenableRouter &#123; public static final String NAME = \"APP_ROUTER\"; private static final int APP_ROUTER_DEFAULT_PRIORITY = 150; public AppRouter(DynamicConfiguration configuration, URL url) &#123;// 拿到应用名 super(configuration, url, url.getParameter(CommonConstants.APPLICATION_KEY)); this.priority = APP_ROUTER_DEFAULT_PRIORITY; &#125;&#125;public class ServiceRouterFactory extends CacheableRouterFactory &#123; public static final String NAME = \"service\"; @Override protected Router createRouter(URL url) &#123; return new ServiceRouter(DynamicConfiguration.getDynamicConfiguration(), url); &#125;&#125;public class ServiceRouter extends ListenableRouter &#123; public ServiceRouter(DynamicConfiguration configuration, URL url) &#123; // 得到服务名 super(configuration, url, DynamicConfiguration.getRuleKey(url)); this.priority = SERVICE_ROUTER_DEFAULT_PRIORITY; &#125;&#125;public abstract class ListenableRouter extends AbstractRouter implements ConfigurationListener &#123; public ListenableRouter(DynamicConfiguration configuration, URL url, String ruleKey) &#123; super(configuration, url); this.force = false; // ruleKey为服务名或应用名,初始化，会绑定一个监听器，负责监听配置中心条件路由的修改，并且会主动从配置中心获取一下当前条件路由的数据并做解析 this.init(ruleKey); &#125; private synchronized void init(String ruleKey) &#123; if (StringUtils.isEmpty(ruleKey)) &#123; return; &#125; String routerKey = ruleKey + RULE_SUFFIX; // 服务名+\".condition-router\"，或 应用名+\".condition-router\" configuration.addListener(routerKey, this); // 绑定一个监听器去监听routerKey对应的路径，当前类ListenableRouter就自带了一个监听器 // 绑定完监听器后，主动的从配置中心获取一下当前服务或消费者应用的对应的路由配置 String rule = configuration.getRule(routerKey, DynamicConfiguration.DEFAULT_GROUP); if (StringUtils.isNotEmpty(rule)) &#123;// 手动调用监听器处理事件的方法process() this.process(new ConfigChangeEvent(routerKey, rule)); &#125; &#125; public synchronized void process(ConfigChangeEvent event) &#123; if (event.getChangeType().equals(ConfigChangeType.DELETED)) &#123; // 若是一个删除时间，则清空当前Router中的conditionRouters属性，表示当前Router对象中没有路由规则 routerRule = null; conditionRouters = Collections.emptyList(); &#125; else &#123; try &#123; routerRule = ConditionRuleParser.parse(event.getValue()); // 解析路由规则 generateConditions(routerRule); // 根据路由规则，生成ConditionRouter-条件路由对象，并赋值给当前Router对象的conditionRouters属性 &#125; catch (Exception e) &#123; &#125; &#125; &#125;&#125; TagRouter比较特殊，首先标签路由是用在当消费者在调用某个服务时，通过在请求中设置标签，然后根据所设置的标签获得可用的服务提供者地址，目前TagRouter只支持应用级别的配置。 对服务消费者而言在引用某个服务时，需知道提供该服务的应用名，然后去监听该应用名对应的.tag-router节点内容，需要先获取到当前所引入服务的服务提供者URL，从服务提供者URL中得到服务提供者应用名，拿到应用名后才能去应用名对应的.tag-router节点去绑定监听器。 AppRouter监听的是本消费者应用的路由规则，ServiceRouter监听的是所引入服务的路由规则，TagRouter是在引入服务时获取服务提供者URL之后，才监听.tag-router节点中的内容，并手动获取一次节点中的内容，设置TagRouter对象中tagRouterRule属性表示标签路由规则。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128public class TagRouterFactory extends CacheableRouterFactory &#123; public static final String NAME = \"tag\"; @Override protected Router createRouter(URL url) &#123; return new TagRouter(DynamicConfiguration.getDynamicConfiguration(), url); &#125;&#125;public class TagRouter extends AbstractRouter implements ConfigurationListener &#123; public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException &#123; if (CollectionUtils.isEmpty(invokers)) &#123; return invokers; &#125; final TagRouterRule tagRouterRuleCopy = tagRouterRule; // since the rule can be changed by config center, we should copy one to use. if (tagRouterRuleCopy == null || !tagRouterRuleCopy.isValid() || !tagRouterRuleCopy.isEnabled()) &#123; return filterUsingStaticTag(invokers, url, invocation); &#125; List&lt;Invoker&lt;T&gt;&gt; result = invokers; // 获取调用对象invocation中所设置的tag String tag = StringUtils.isEmpty(invocation.getAttachment(Constants.TAG_KEY)) ? url.getParameter(Constants.TAG_KEY) : invocation.getAttachment(Constants.TAG_KEY); if (StringUtils.isNotEmpty(tag)) &#123; // 若请求具有特定标签的提供者 List&lt;String&gt; addresses = tagRouterRuleCopy.getTagnameToAddresses().get(tag); // 获取对应tag所设置的服务提供者address if (CollectionUtils.isNotEmpty(addresses)) &#123; // 首先按动态标签组过过滤 // 根据tag所对应的address对所有服务提供者invokers进行过滤 result = filterInvoker(invokers, invoker -&gt; addressMatches(invoker.getUrl(), addresses)); // 若过滤之后还有结果，那就用过滤之后的结果，若没有结果，但是此标签路由是要强制使用的，那么则会把空结果返回(没有此tag所对应的服务提供者可用) if (CollectionUtils.isNotEmpty(result) || tagRouterRuleCopy.isForce()) &#123; return result; &#125; &#125; else &#123;// 动态标签组没有关于请求的应用程序的任何项目或它在过滤后为空，动态标签组但force=false，检查静态标签 result = filterInvoker(invokers, invoker -&gt; tag.equals(invoker.getUrl().getParameter(Constants.TAG_KEY))); &#125; // 若没有可匹配当前标记请求的标记提供者，force.tag默认为false，这意味着它将调用任何没有标记的提供程序，除非它被明确禁止 if (CollectionUtils.isNotEmpty(result) || isForceUseTag(invocation)) &#123; return result; &#125; else &#123; // FAILOVER：返回没有任何标签的所有提供者。 List&lt;Invoker&lt;T&gt;&gt; tmp = filterInvoker(invokers, invoker -&gt; addressNotMatches(invoker.getUrl(), tagRouterRuleCopy.getAddresses())); return filterInvoker(tmp, invoker -&gt; StringUtils.isEmpty(invoker.getUrl().getParameter(Constants.TAG_KEY))); &#125; &#125; else &#123; // List&lt;String&gt; addresses = tagRouterRule.filter(providerApp); List&lt;String&gt; addresses = tagRouterRuleCopy.getAddresses(); // 返回动态标签组中的所有地址 if (CollectionUtils.isNotEmpty(addresses)) &#123; result = filterInvoker(invokers, invoker -&gt; addressNotMatches(invoker.getUrl(), addresses)); if (CollectionUtils.isEmpty(result)) &#123; return result; // 所有地址都在动态标签组中，返回空列表 &#125; // 如果有一些地址不在任何动态标签组中，则继续使用 &#125; return filterInvoker(result, invoker -&gt; &#123; String localTag = invoker.getUrl().getParameter(Constants.TAG_KEY); return StringUtils.isEmpty(localTag) || !tagRouterRuleCopy.getTagNames().contains(localTag); &#125;); &#125; &#125; private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; filterUsingStaticTag(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; List&lt;Invoker&lt;T&gt;&gt; result = invokers; String tag = StringUtils.isEmpty(invocation.getAttachment(Constants.TAG_KEY)) ? url.getParameter(Constants.TAG_KEY) : invocation.getAttachment(Constants.TAG_KEY); if (!StringUtils.isEmpty(tag)) &#123; // Tag request result = filterInvoker(invokers, invoker -&gt; tag.equals(invoker.getUrl().getParameter(TAG_KEY))); if (CollectionUtils.isEmpty(result) &amp;&amp; !isForceUseTag(invocation)) &#123; result = filterInvoker(invokers, invoker -&gt; StringUtils.isEmpty(invoker.getUrl().getParameter(TAG_KEY))); &#125; &#125; else &#123; result = filterInvoker(invokers, invoker -&gt; StringUtils.isEmpty(invoker.getUrl().getParameter(TAG_KEY))); &#125; return result; &#125;&#125;public class MockRouterFactory implements RouterFactory &#123; public static final String NAME = \"mock\"; @Override public Router getRouter(URL url) &#123; return new MockInvokersSelector(); &#125;&#125;public class MockInvokersSelector extends AbstractRouter &#123; public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(final List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, final Invocation invocation) throws RpcException &#123; if (CollectionUtils.isEmpty(invokers)) &#123; return invokers; &#125; if (invocation.getAttachments() == null) &#123; return getNormalInvokers(invokers); &#125; else &#123; String value = invocation.getAttachments().get(INVOCATION_NEED_MOCK); if (value == null) &#123; return getNormalInvokers(invokers); &#125; else if (Boolean.TRUE.toString().equalsIgnoreCase(value)) &#123; return getMockedInvokers(invokers); &#125; &#125; return invokers; &#125; private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; getMockedInvokers(final List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; if (!hasMockProviders(invokers)) &#123; return null; &#125; List&lt;Invoker&lt;T&gt;&gt; sInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(1); for (Invoker&lt;T&gt; invoker : invokers) &#123; if (invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) &#123; sInvokers.add(invoker); &#125; &#125; return sInvokers; &#125; private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; getNormalInvokers(final List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; if (!hasMockProviders(invokers)) &#123; return invokers; &#125; else &#123; List&lt;Invoker&lt;T&gt;&gt; sInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(invokers.size()); for (Invoker&lt;T&gt; invoker : invokers) &#123; if (!invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) &#123; sInvokers.add(invoker); &#125; &#125; return sInvokers; &#125; &#125; private &lt;T&gt; boolean hasMockProviders(final List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; boolean hasMockProvider = false; for (Invoker&lt;T&gt; invoker : invokers) &#123; if (invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) &#123; hasMockProvider = true; break; &#125; &#125; return hasMockProvider; &#125;&#125; 服务目录 消费端每个服务对应一个服务目录RegistryDirectory，一个服务目录中包含serviceType服务接口、serviceKey引入的服务key即serviceclass+version+group、queryMap引入服务参数配置、configurators动态配置、routerChain路由链、invokers服务目录当前缓存的服务提供者Invoker、ConsumerConfigurationListener监听本应用的动态配置、ReferenceConfigurationListener监听所引入的服务的动态配置。 当ConsumerConfigurationListener接收到消费者应用动态配置数据变化后，调用当前消费者应用中所有RegistryDirectory的refreshInvoker方法，刷新消费者应用中引入的每个服务对应的Invoker。当ReferenceConfigurationListener接收到某个服务动态配置数据变化后，调用该服务对应的RegistryDirectory的refreshInvoker方法，刷新该服务对应的Invoker。 在refreshInvoker方法中会从注册中心获取到的providers节点下的服务URL，然后调用toInvokers方法得到Invoker，先按Protocol进行过滤且调用DubboProtocol.refer方法得到Invoker，将得到的invokers设置到RouterChain上，且调用RouterChain上所有的routers的notify方法，实际只有TagRouter的notify方法有用，再把属于同一个group中的invoker合并起来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener &#123; private static final ConsumerConfigurationListener CONSUMER_CONFIGURATION_LISTENER = new ConsumerConfigurationListener(); private ReferenceConfigurationListener serviceConfigurationListener; public void subscribe(URL url) &#123; setConsumerUrl(url); CONSUMER_CONFIGURATION_LISTENER.addNotifyListener(this); // 监听consumer应用 serviceConfigurationListener = new ReferenceConfigurationListener(this, url); // 监听所引入的服务的动态配置 registry.subscribe(url, this); &#125; private void refreshInvoker(List&lt;URL&gt; invokerUrls) &#123; //http:// dubbo:// Assert.notNull(invokerUrls, \"invokerUrls should not be null\"); if (invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123; this.forbidden = true; // Forbid to access this.invokers = Collections.emptyList(); routerChain.setInvokers(this.invokers); destroyAllInvokers(); // Close all invokers &#125; else &#123; this.forbidden = false; // Allow to access Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference if (invokerUrls == Collections.&lt;URL&gt;emptyList()) &#123; invokerUrls = new ArrayList&lt;&gt;(); &#125; if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) &#123; invokerUrls.addAll(this.cachedInvokerUrls); &#125; else &#123; this.cachedInvokerUrls = new HashSet&lt;&gt;(); this.cachedInvokerUrls.addAll(invokerUrls);//Cached invoker urls, convenient for comparison &#125; if (invokerUrls.isEmpty()) &#123; return; &#125; // 这里会先按Protocol进行过滤，并且调用DubboProtocol.refer方法得到DubboInvoker Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map if (CollectionUtils.isEmptyMap(newUrlInvokerMap)) &#123; return; &#125; List&lt;Invoker&lt;T&gt;&gt; newInvokers = Collections.unmodifiableList(new ArrayList&lt;&gt;(newUrlInvokerMap.values())); routerChain.setInvokers(newInvokers); // 得到了所引入的服务Invoker之后，把它们设置到路由链中去，在调用时使用，并且会调用TagRouter的notify方法 this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers; this.urlInvokerMap = newUrlInvokerMap; try &#123; destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker &#125; catch (Exception e) &#123; &#125; &#125; &#125; private Map&lt;String, Invoker&lt;T&gt;&gt; toInvokers(List&lt;URL&gt; urls) &#123; Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = new HashMap&lt;&gt;(); if (urls == null || urls.isEmpty()) &#123; return newUrlInvokerMap; &#125; Set&lt;String&gt; keys = new HashSet&lt;&gt;(); String queryProtocols = this.queryMap.get(PROTOCOL_KEY); for (URL providerUrl : urls) &#123; // 遍历当前服务所有的服务提供者URL if (queryProtocols != null &amp;&amp; queryProtocols.length() &gt; 0) &#123; boolean accept = false; String[] acceptProtocols = queryProtocols.split(\",\"); for (String acceptProtocol : acceptProtocols) &#123; // 当前消费者如果手动配置了Protocol，那么则进行匹配 if (providerUrl.getProtocol().equals(acceptProtocol)) &#123; accept = true; break; &#125; &#125; if (!accept) &#123; continue; &#125; &#125; if (EMPTY_PROTOCOL.equals(providerUrl.getProtocol())) &#123; continue; &#125; // 当前Protocol是否在应用中存在对应的扩展点 if (!ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(providerUrl.getProtocol())) &#123; continue; &#125; URL url = mergeUrl(providerUrl); String key = url.toFullString(); // The parameter urls are sorted if (keys.contains(key)) &#123; // Repeated url continue; &#125; keys.add(key); Map&lt;String, Invoker&lt;T&gt;&gt; localUrlInvokerMap = this.urlInvokerMap; // local reference Invoker&lt;T&gt; invoker = localUrlInvokerMap == null ? null : localUrlInvokerMap.get(key); if (invoker == null) &#123; // Not in the cache, refer again try &#123; // 如果当前服务提供者URL没有生产过Invoker boolean enabled = true; if (url.hasParameter(DISABLED_KEY)) &#123; enabled = !url.getParameter(DISABLED_KEY, false); &#125; else &#123; enabled = url.getParameter(ENABLED_KEY, true); &#125; if (enabled) &#123;// 调用Protocol的refer方法得到一个Invoker DubboProtocol.refer() invoker = new InvokerDelegate&lt;&gt;(protocol.refer(serviceType, url), url, providerUrl); &#125; &#125; catch (Throwable t) &#123; &#125; if (invoker != null) &#123; // Put new invoker in cache newUrlInvokerMap.put(key, invoker); &#125; &#125; else &#123; newUrlInvokerMap.put(key, invoker); &#125; &#125; keys.clear(); return newUrlInvokerMap; &#125; private void destroyUnusedInvokers(Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap, Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap) &#123; if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) &#123; destroyAllInvokers(); return; &#125; List&lt;String&gt; deleted = null; if (oldUrlInvokerMap != null) &#123; Collection&lt;Invoker&lt;T&gt;&gt; newInvokers = newUrlInvokerMap.values(); for (Map.Entry&lt;String, Invoker&lt;T&gt;&gt; entry : oldUrlInvokerMap.entrySet()) &#123; if (!newInvokers.contains(entry.getValue())) &#123; if (deleted == null) &#123; deleted = new ArrayList&lt;&gt;(); &#125; deleted.add(entry.getKey()); &#125; &#125; &#125; if (deleted != null) &#123; for (String url : deleted) &#123; if (url != null) &#123; Invoker&lt;T&gt; invoker = oldUrlInvokerMap.remove(url); if (invoker != null) &#123; try &#123; invoker.destroy(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; &#125; &#125; &#125;&#125;private static class ConsumerConfigurationListener extends AbstractConfiguratorListener &#123; List&lt;RegistryDirectory&gt; listeners = new ArrayList&lt;&gt;(); ConsumerConfigurationListener() &#123; this.initWith(ApplicationModel.getApplication() + CONFIGURATORS_SUFFIX); &#125; void addNotifyListener(RegistryDirectory listener) &#123; this.listeners.add(listener); &#125; @Override protected void notifyOverrides() &#123;// 调用RegistryDirectory的refreshInvoker方法 listeners.forEach(listener -&gt; listener.refreshInvoker(Collections.emptyList())); &#125;&#125;private static class ReferenceConfigurationListener extends AbstractConfiguratorListener &#123; private RegistryDirectory directory; private URL url; ReferenceConfigurationListener(RegistryDirectory directory, URL url) &#123; this.directory = directory; this.url = url; this.initWith(DynamicConfiguration.getRuleKey(url) + CONFIGURATORS_SUFFIX); &#125; @Override protected void notifyOverrides() &#123; directory.refreshInvoker(Collections.emptyList()); &#125;&#125;public abstract class AbstractConfiguratorListener implements ConfigurationListener &#123; protected final void initWith(String key) &#123; DynamicConfiguration dynamicConfiguration = DynamicConfiguration.getDynamicConfiguration(); dynamicConfiguration.addListener(key, this); // 添加Listener,进行了订阅 // 从配置中心ConfigCenter获取属于当前应用的动态配置数据，从zk中拿到原始数据(主动从配置中心获取数据) String rawConfig = dynamicConfiguration.getRule(key, DynamicConfiguration.DEFAULT_GROUP); if (!StringUtils.isEmpty(rawConfig)) &#123; // 如果存在应用配置信息则根据配置信息生成Configurator genConfiguratorsFromRawRule(rawConfig); &#125; &#125; private boolean genConfiguratorsFromRawRule(String rawConfig) &#123; boolean parseSuccess = true; try &#123; // 先把应用或服务配置转成url，再根据url生成对应的Configurator configurators = Configurator.toConfigurators(ConfigParser.parseConfigurators(rawConfig)).orElse(configurators); &#125; catch (Exception e) &#123; parseSuccess = false; &#125; return parseSuccess; &#125;&#125; 当RegistryDirectory接收到providers节点数据变化后，会调用refreshOverrideAndInvoker方法，该方法用来针对每个服务提供者来生成Invoker。refreshOverrideAndInvoker方法中首先调用overrideDirectoryUrl方法利用Configurators重写目录地址，在注册中心URL基础上把当前引入服务的参数作为URL的Parameters，所以该地址既包括了注册中心信息，也包括了当前引入服务的信息，重写往目录地址后，调用refreshInvoker方法去刷新Invoker。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener &#123; public synchronized void notify(List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; categoryUrls = urls.stream().filter(Objects::nonNull).filter(this::isValidCategory).filter(this::isNotCompatibleFor26x) .collect(Collectors.groupingBy(url -&gt; &#123; if (UrlUtils.isConfigurator(url)) &#123; return CONFIGURATORS_CATEGORY; &#125; else if (UrlUtils.isRoute(url)) &#123; return ROUTERS_CATEGORY; &#125; else if (UrlUtils.isProvider(url)) &#123; return PROVIDERS_CATEGORY; &#125; return \"\"; &#125;)); // 获取动态配置URL，生成configurators List&lt;URL&gt; configuratorURLs = categoryUrls.getOrDefault(CONFIGURATORS_CATEGORY, Collections.emptyList()); this.configurators = Configurator.toConfigurators(configuratorURLs).orElse(this.configurators); // 获取老版本路由URL，生成Router，并添加到路由链中 List&lt;URL&gt; routerURLs = categoryUrls.getOrDefault(ROUTERS_CATEGORY, Collections.emptyList()); toRouters(routerURLs).ifPresent(this::addRouters); // 获取服务提供者URL List&lt;URL&gt; providerURLs = categoryUrls.getOrDefault(PROVIDERS_CATEGORY, Collections.emptyList()); refreshOverrideAndInvoker(providerURLs); &#125; private void refreshOverrideAndInvoker(List&lt;URL&gt; urls) &#123; // mock zookeeper://xxx?mock=return null overrideDirectoryUrl(); refreshInvoker(urls); &#125; private void overrideDirectoryUrl() &#123; // merge override parameters this.overrideDirectoryUrl = directoryUrl; List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference doOverrideUrl(localConfigurators); List&lt;Configurator&gt; localAppDynamicConfigurators = CONSUMER_CONFIGURATION_LISTENER.getConfigurators(); // local reference doOverrideUrl(localAppDynamicConfigurators); if (serviceConfigurationListener != null) &#123; List&lt;Configurator&gt; localDynamicConfigurators = serviceConfigurationListener.getConfigurators(); // local reference doOverrideUrl(localDynamicConfigurators); &#125; &#125; private void doOverrideUrl(List&lt;Configurator&gt; configurators) &#123; if (CollectionUtils.isNotEmpty(configurators)) &#123; for (Configurator configurator : configurators) &#123; this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl); &#125; &#125; &#125;&#125; 服务引入调用Protocol的refer方法首先超类AbstractProtocol的refer方法，然后调用DubboProtocol的protocolBindingRefer方法，该方法中主要是通过getClients获取client列表，为了提高效率一个DubboInvoker会有多个client，每个client和server之间都会有一个socket，多个client连的是同一个server，在DubboInvoker发送请求时会轮询clients去发送数据。 在获取Client时首先判断配置的连接数connections，若未配置则使用共享socket连配置shareConnectionsStr默认为1，非共享连接若消费者应用引用了两个服务A和B，这两个服务都部署在了应用C上，若connections为2则消费者应用会与应用C建立4个Socket连接，若为共享连接且shareConnectionsStr为2，那么消费者应用会与应用C建立2个Socket连接。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172public abstract class AbstractProtocol implements Protocol &#123; public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 异步转同步Invoker, type是接口，url是服务地址，DubboInvoker是异步的，而AsyncToSyncInvoker会封装为同步的 return new AsyncToSyncInvoker&lt;&gt;(protocolBindingRefer(type, url)); &#125;&#125;public class DubboProtocol extends AbstractProtocol &#123; public &lt;T&gt; Invoker&lt;T&gt; protocolBindingRefer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; optimizeSerialization(url); // clients很重要，为了提高效率一个DubboInvoker会有多个clients，因为每个client和server之间都会有一个socket, 多个client连的是同一个server // 在DubboInvoker发送请求时会轮询clients去发送数据 DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker; &#125; private ExchangeClient[] getClients(URL url) &#123; boolean useShareConnect = false; // connections表示对当前服务提供者建立connections个socket连接 // 消费者应用引用了两个服务A和B，这两个服务都部署在了应用C上，如果connections为2，那么消费者应用会与应用C建立4个Socket连接 int connections = url.getParameter(CONNECTIONS_KEY, 0); List&lt;ReferenceCountExchangeClient&gt; shareClients = null; // 如果没有配置connections，那么则取shareConnectionsStr（默认为1），表示共享socket连接个数 // 消费者应用引用了两个服务A和B，这两个服务都部署在了应用C上，如果shareConnectionsStr为2，那么消费者应用会与应用C建立2个Socket连接 if (connections == 0) &#123; useShareConnect = true; String shareConnectionsStr = url.getParameter(SHARE_CONNECTIONS_KEY, (String) null); connections = Integer.parseInt(StringUtils.isBlank(shareConnectionsStr) ? ConfigUtils.getProperty(SHARE_CONNECTIONS_KEY, DEFAULT_SHARE_CONNECTIONS) : shareConnectionsStr); shareClients = getSharedClient(url, connections); &#125; ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) &#123; if (useShareConnect) &#123; // 如果使用共享的，则利用shareClients clients[i] = shareClients.get(i); &#125; else &#123; // 不然就初始化，在初始化client时会去连接服务端 clients[i] = initClient(url); &#125; &#125; return clients; &#125; private List&lt;ReferenceCountExchangeClient&gt; getSharedClient(URL url, int connectNum) &#123; // 这个方法返回的是可以共享的client，要么已经生成过了，要么需要重新生成 String key = url.getAddress(); // 对于已经生成过的client,都会存在referenceClientMap中，key为所调用的服务IP+PORT List&lt;ReferenceCountExchangeClient&gt; clients = referenceClientMap.get(key); // 根据当前引入的服务对应的ip+port，看看是否已经存在clients了， if (checkClientCanUse(clients)) &#123;// 如果每个client都可用，那就对每个client的计数+1，表示这些client被引用了多少次 batchClientRefIncr(clients); return clients; &#125; locks.putIfAbsent(key, new Object()); synchronized (locks.get(key)) &#123; clients = referenceClientMap.get(key); if (checkClientCanUse(clients)) &#123; // dubbo check batchClientRefIncr(clients); return clients; &#125; connectNum = Math.max(connectNum, 1); // 至少一个 if (CollectionUtils.isEmpty(clients)) &#123;// 如果clients为空，则按指定的connectNum生成client clients = buildReferenceCountExchangeClientList(url, connectNum); referenceClientMap.put(key, clients); &#125; else &#123;// 如果clients不为空，则遍历这些client，对于不可用的client，则重新生成一个client for (int i = 0; i &lt; clients.size(); i++) &#123; ReferenceCountExchangeClient referenceCountExchangeClient = clients.get(i); if (referenceCountExchangeClient == null || referenceCountExchangeClient.isClosed()) &#123; clients.set(i, buildReferenceCountExchangeClient(url)); continue; &#125; referenceCountExchangeClient.incrementAndGetCount(); &#125; &#125; locks.remove(key); return clients; &#125; &#125; private ReferenceCountExchangeClient buildReferenceCountExchangeClient(URL url) &#123; ExchangeClient exchangeClient = initClient(url); // 生成一个ExchangeClient return new ReferenceCountExchangeClient(exchangeClient); // 包装成ReferenceCountExchangeClient &#125; private ExchangeClient initClient(URL url) &#123; // 拿设置的client，默认为netty String str = url.getParameter(CLIENT_KEY, url.getParameter(SERVER_KEY, DEFAULT_REMOTING_CLIENT)); // 编码方式 url = url.addParameter(CODEC_KEY, DubboCodec.NAME); // 心跳， 默认60 * 1000,60秒一个心跳 url = url.addParameterIfAbsent(HEARTBEAT_KEY, String.valueOf(DEFAULT_HEARTBEAT)); // 如果没有指定的client扩展，则抛异常 if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123; throw new RpcException(\"Unsupported client type: \" + str + \", supported client type is \" + StringUtils.join(ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(), \" \")); &#125; ExchangeClient client; try &#123; if (url.getParameter(LAZY_CONNECT_KEY, false)) &#123; // connection should be lazy client = new LazyConnectExchangeClient(url, requestHandler); &#125; else &#123; client = Exchangers.connect(url, requestHandler); // 建立连接 &#125; &#125; catch (RemotingException e) &#123; throw new RpcException(\"Fail to create remoting client for service(\" + url + \"): \" + e.getMessage(), e); &#125; return client; &#125; private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123; @Override public CompletableFuture&lt;Object&gt; reply(ExchangeChannel channel, Object message) throws RemotingException &#123; if (!(message instanceof Invocation)) &#123; throw new RemotingException(channel, \"Unsupported request: \" + (message == null ? null : (message.getClass().getName() + \": \" + message)) + \", channel: consumer: \" + channel.getRemoteAddress() + \" --&gt; provider: \" + channel.getLocalAddress()); &#125; Invocation inv = (Invocation) message; // 转成Invocation对象，要开始用反射执行方法了 Invoker&lt;?&gt; invoker = getInvoker(channel, inv); // 服务实现者 if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE))) &#123; String methodsStr = invoker.getUrl().getParameters().get(\"methods\"); boolean hasMethod = false; if (methodsStr == null || !methodsStr.contains(\",\")) &#123; hasMethod = inv.getMethodName().equals(methodsStr); &#125; else &#123; String[] methods = methodsStr.split(\",\"); for (String method : methods) &#123; if (inv.getMethodName().equals(method)) &#123; hasMethod = true; break; &#125; &#125; &#125; if (!hasMethod) &#123; return null; &#125; &#125; RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress());// 这里设置了，service中才能拿到remoteAddress Result result = invoker.invoke(inv);// 执行服务，得到结果 return result.completionFuture().thenApply(Function.identity()); // 返回一个CompletableFuture &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof Invocation) &#123; reply((ExchangeChannel) channel, message); // 这是服务端接收到Invocation时的处理逻辑 &#125; else &#123; super.received(channel, message); &#125; &#125; @Override public void connected(Channel channel) throws RemotingException &#123; invoke(channel, ON_CONNECT_KEY); &#125; @Override public void disconnected(Channel channel) throws RemotingException &#123; invoke(channel, ON_DISCONNECT_KEY); &#125; private void invoke(Channel channel, String methodKey) &#123; Invocation invocation = createInvocation(channel, channel.getUrl(), methodKey); if (invocation != null) &#123; try &#123; received(channel, invocation); &#125; catch (Throwable t) &#123; &#125; &#125; &#125; private Invocation createInvocation(Channel channel, URL url, String methodKey) &#123; String method = url.getParameter(methodKey); if (method == null || method.length() == 0) &#123; return null; &#125; RpcInvocation invocation = new RpcInvocation(method, new Class&lt;?&gt;[0], new Object[0]); invocation.setAttachment(PATH_KEY, url.getPath()); invocation.setAttachment(GROUP_KEY, url.getParameter(GROUP_KEY)); invocation.setAttachment(INTERFACE_KEY, url.getParameter(INTERFACE_KEY)); invocation.setAttachment(VERSION_KEY, url.getParameter(VERSION_KEY)); if (url.getParameter(STUB_EVENT_KEY, false)) &#123; invocation.setAttachment(STUB_EVENT_KEY, Boolean.TRUE.toString()); &#125; return invocation; &#125; &#125;;&#125; 客户端的启动和服务端的启动类似，在connect方法中调用HeaderExchanger的connect方法去建立socket连接并得到一个HeaderExchangeClient，构造HeaderExchangeClient时先执行Transporters.*connect*()方法得到一个Client，从而调用调用NettyTransporter的connect方法构造一个NettyClient，构造NettyClient的过程中会初始化Netty客户端，然后连接Server端建立一个Socket连接。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147public class Exchangers &#123; public static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); return getExchanger(url).connect(url, handler); // 得到一个HeaderExchanger去connect &#125;&#125;public class HeaderExchanger implements Exchanger &#123; @Override public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; // 利用NettyTransporter去connect，为什么在connect和bind时都是DecodeHandler，解码解的是把InputStream解析成AppResponse对象 return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true); &#125;&#125;public class Transporters &#123; public static Client connect(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; ChannelHandler handler; if (handlers == null || handlers.length == 0) &#123; handler = new ChannelHandlerAdapter(); &#125; else if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; handler = new ChannelHandlerDispatcher(handlers); &#125; return getTransporter().connect(url, handler); // NettyTransporter &#125;&#125;public class NettyTransporter implements Transporter &#123; public Client connect(URL url, ChannelHandler listener) throws RemotingException &#123; return new NettyClient(url, listener); // 生成一个NettyClient, 这个内部会去进行连接 &#125;&#125;public class NettyClient extends AbstractClient &#123; public NettyClient(final URL url, final ChannelHandler handler) throws RemotingException &#123; super(url, wrapChannelHandler(url, handler)); &#125; protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); bootstrap = new ClientBootstrap(CHANNEL_FACTORY); // config @see org.jboss.netty.channel.socket.SocketChannelConfig bootstrap.setOption(\"keepAlive\", true); bootstrap.setOption(\"tcpNoDelay\", true); bootstrap.setOption(\"connectTimeoutMillis\", getConnectTimeout()); final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; @Override public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyClient.this); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(\"decoder\", adapter.getDecoder()); pipeline.addLast(\"encoder\", adapter.getEncoder()); pipeline.addLast(\"handler\", nettyHandler); return pipeline; &#125; &#125;); &#125; protected void doConnect() throws Throwable &#123; long start = System.currentTimeMillis(); ChannelFuture future = bootstrap.connect(getConnectAddress()); try &#123; boolean ret = future.awaitUninterruptibly(getConnectTimeout(), TimeUnit.MILLISECONDS); if (ret &amp;&amp; future.isSuccess()) &#123; Channel newChannel = future.getChannel(); newChannel.setInterestOps(Channel.OP_READ_WRITE); try &#123;// Close old channel Channel oldChannel = NettyClient.this.channel; // copy reference if (oldChannel != null) &#123; try &#123; oldChannel.close(); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(oldChannel); &#125; &#125; &#125; finally &#123; if (NettyClient.this.isClosed()) &#123; try &#123; newChannel.close(); &#125; finally &#123; NettyClient.this.channel = null; NettyChannel.removeChannelIfDisconnected(newChannel); &#125; &#125; else &#123; NettyClient.this.channel = newChannel; &#125; &#125; &#125; else if (future.getCause() != null) &#123; throw new RemotingException(this, \"client(url: \" + getUrl() + \") failed to connect to server \" + getRemoteAddress() + \", error message is:\" + future.getCause().getMessage(), future.getCause()); &#125; else &#123; throw new RemotingException(this, \"client(url: \" + getUrl() + \") failed to connect to server \" + getRemoteAddress() + \" client-side timeout \" + getConnectTimeout() + \"ms (elapsed: \" + (System.currentTimeMillis() - start) + \"ms) from netty client \" + NetUtils.getLocalHost() + \" using dubbo version \" + Version.getVersion()); &#125; &#125; finally &#123; if (!isConnected()) &#123; future.cancel(); &#125; &#125; &#125;&#125;public abstract class AbstractClient extends AbstractEndpoint implements Client &#123; public AbstractClient(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); needReconnect = url.getParameter(Constants.SEND_RECONNECT_KEY, false); try &#123; doOpen(); &#125; catch (Throwable t) &#123; close(); throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to start \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalAddress() + \" connect to the server \" + getRemoteAddress() + \", cause: \" + t.getMessage(), t); &#125; try &#123;// connect. connect(); &#125; catch (RemotingException t) &#123; if (url.getParameter(Constants.CHECK_KEY, true)) &#123; close(); throw t; &#125; &#125; catch (Throwable t) &#123; close(); throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to start \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalAddress() + \" connect to the server \" + getRemoteAddress() + \", cause: \" + t.getMessage(), t); &#125; // 得到消费端的线程池 executor = (ExecutorService) ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension().get(CONSUMER_SIDE, Integer.toString(url.getPort())); ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension().remove(CONSUMER_SIDE, Integer.toString(url.getPort())); &#125; protected static ChannelHandler wrapChannelHandler(URL url, ChannelHandler handler) &#123; url = ExecutorUtil.setThreadName(url, CLIENT_THREAD_POOL_NAME); url = url.addParameterIfAbsent(THREADPOOL_KEY, DEFAULT_CLIENT_THREADPOOL); return ChannelHandlers.wrap(handler, url); &#125;&#125;public class ChannelHandlers &#123; public static ChannelHandler wrap(ChannelHandler handler, URL url) &#123; return ChannelHandlers.getInstance().wrapInternal(handler, url); &#125; protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) &#123; // 先通过ExtensionLoader.getExtensionLoader(Dispatcher.class).getAdaptiveExtension().dispatch(handler, url) // 得到一个AllChannelHandler(handler, url)把AllChannelHandler包装成HeartbeatHandler，HeartbeatHandler包装成MultiMessageHandler // 当Netty接收到一个数据时，会经历MultiMessageHandler---&gt;HeartbeatHandler----&gt;AllChannelHandler，而AllChannelHandler会调用handler return new MultiMessageHandler(new HeartbeatHandler(ExtensionLoader.getExtensionLoader(Dispatcher.class).getAdaptiveExtension().dispatch(handler, url))); &#125;&#125; 创建代理最终创建好Invoker对象后会通过ProxyFactory给Invoker创建代理对象，ProxyFactory是通过SPI机制加载的默认为JavassistProxyFactory。最终创建代理对象InvokerInvocationHandler即为最终ReferenceBean的getObject方法返回对象，在发起服务调用时首先执行InvokerInvocationHandler的invoke方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class JavassistProxyFactory extends AbstractProxyFactory &#123; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); &#125; @Override public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' // 若现在被代理对象proxy本身就是一个已经被代理过的对象，则取代理类的Wrapper，否则取type接口的Wrapper // Wrapper是针对某个类或某个接口的包装类，通过wrapper对象可以更方便的去执行某个类或某个接口的方法 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123;// proxy是服务实现类 type是服务接口 url是一个注册中心url @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; // 执行proxy的method方法，执行的proxy实例的方法，若没有wrapper，则要通过原生的反射技术去获取Method对象，然后执行 return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125;&#125;public class InvokerInvocationHandler implements InvocationHandler &#123; private final Invoker&lt;?&gt; invoker; public InvokerInvocationHandler(Invoker&lt;?&gt; handler) &#123; this.invoker = handler; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(invoker, args); &#125; if (\"toString\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.toString(); &#125; if (\"hashCode\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.hashCode(); &#125; if (\"equals\".equals(methodName) &amp;&amp; parameterTypes.length == 1) &#123; return invoker.equals(args[0]); &#125; // recreate方法会调用AppResponse的recreate方法，若AppResponse对象中存在exception信息，则此方法中会throw该异常 return invoker.invoke(new RpcInvocation(method, args)).recreate(); &#125;&#125; Invoker调用链12@Reference(url = \"dubbo://ip:20881/package.DemoService;registry://ip:2181/package.RegistryService?registry=zookeeper\")private DemoService demoService; 最复杂情况下Invoker链在@Reference注解中设置URL，且指定服务提供者URL为dubbo://ip:20881/package.DemoService，注册中心URL为registry://ip:2181/package.RegistryService?registry=zookeeper，最终refer处理的invoker链路为： MockClusterInvoker invoker=RegistryAwareClusterInvoker directory=StaticDirectory 0=ProtocolFilterWrapper$CallbackRegistrationInvoke子流程 1=MockClusterInvoker FailoverClusterInvoker RegistryDirectory invokers=UnmodifiableRandomAccessListsize=1 0=RegistryDirectory$InvokerDelegat ProtocolFilterWrapper$CallbackRegistrationInvoke子流程 filterInvoker=ProtocolFilterWrapper$1 filter=ConsumerContextFilter next=ProtocolFilterWrapper$1 filter=FutureFilter next=ProtocolFilterWrapper$1 filter=MonitorFilter next=ListenerInvokerWrapper invoker=AsyncToSyncInvoker invoker=DubboInvoker","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://yaoyinglong.github.io/tags/Dubbo/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Dubbo","slug":"Cloud/Dubbo","permalink":"https://yaoyinglong.github.io/categories/Cloud/Dubbo/"}]},{"title":"Dubbo服务导出","date":"2021-12-14T16:00:00.000Z","path":"Blog/Cloud/Dubbo/Dubbo服务导出/","text":"服务导出首先确定服务参数，确定服务支持的协议，构造服务最终的URL，将服务URL注册到注册中心且向注册中心注册监听器，监听Dubbo的中的动态配置信息变更，主要根据服务支持的不同协议启动不同的Server用来接收和处理请求如netty、tomcat、jetty等。 服务的参数除了可以在@Service注解中配置AbstractConfig，还会继承Dubbo服务所属应用Application上的配置，还可在配置中心配置且分为应用配置AppExternalConfiguration和全局配置ExternalConfiguration，JVM环境变量中去配置某个服务的参数SystemConfiguration，还可以通过dubbo.properties文件配置PropertiesConfiguration。优先级从高到低为SystemConfiguration、AppExternalConfiguration、ExternalConfiguration、AbstractConfig、PropertiesConfiguration。 服务导出入口为ServiceBean的export方法，ServiceBean继承了ApplicationContextAware，在setApplicationContext方法中会把applicationContext添加到SpringExtensionFactory中便于Dubbo的SPI机制引入的类中完成Spring容器中Bean的注入，且ServiceBean继承了ApplicationListener接口，将ServiceBean作为监听器注册到Spring监听器列表中。当Spring启动完之后通过接收ContextRefreshedEvent事件从而调用onApplicationEvent来触发export方法的执行。且若注册监听器失败在afterPropertiesSet完成一系列属性填充后，将直接调用export方法来完成导出。 1234567891011121314151617181920212223242526272829public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware, ApplicationEventPublisherAware &#123; public void setApplicationContext(ApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; // 若某一个Service是通过Spring暴露的，则当需要获取该服务时就要从Spring容器中进行获取，所以需要把applicationContext添加到SpringExtensionFactory中去 SpringExtensionFactory.addApplicationContext(applicationContext); // 一定要有这一步，不然ServiceBean将接收不到ContextRefreshedEvent事件 supportedApplicationListener = addApplicationListener(applicationContext, this); &#125; public void onApplicationEvent(ContextRefreshedEvent event) &#123; if (!isExported() &amp;&amp; !isUnexported()) &#123; // 当前服务没有被导出并且没有卸载，才导出服务 export(); // 服务导出（服务注册） &#125; &#125; public void export() &#123; super.export(); // Publish ServiceBeanExportedEvent，Spring启动完发布ContextRefreshedEvent事件---&gt;服务导出---&gt;发布ServiceBeanExportedEvent，可通过Spring中的ApplicationListener来监听服务导出是否完成 publishExportEvent(); &#125; private void publishExportEvent() &#123; ServiceBeanExportedEvent exportEvent = new ServiceBeanExportedEvent(this); applicationEventPublisher.publishEvent(exportEvent); &#125; public void afterPropertiesSet() throws Exception &#123; // 此处省略了一些列属性填充代码 if (!supportedApplicationListener) &#123; // 在setApplicationContext方法中添加监听器成功，则该参数会被置为true export(); &#125; &#125;&#125; 最终调用超类ServiceConfig中的export方法，首先调用checkAndUpdateSubConfigs完成参数补全刷新等操作，刷新完后会检查stub、local、mock等参数是否配置正确。 若ServiceConfig中某些属性为空，则从ProviderConfig、ModuleConfig、ApplicationConfig中获取，补全ServiceConfig属性，从配置中心获取配置，包括应用配置和全局配置，把获取到的配置放入到Environment中的externalConfigurationMap和appExternalConfigurationMap中，并刷新所有除开ServiceConfig的XxConfig的属性，即将配置中心的配置覆盖XxConfig中的属性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; public synchronized void export() &#123; checkAndUpdateSubConfigs(); if (!shouldExport()) &#123; // 检查服务是否需要导出 return; &#125; if (shouldDelay()) &#123; // 检查是否需要延迟发布 DELAY_EXPORT_EXECUTOR.schedule(this::doExport, getDelay(), TimeUnit.MILLISECONDS); &#125; else &#123; doExport(); // 导出服务 &#125; &#125; public void checkAndUpdateSubConfigs() &#123; // ServiceConfig中的某些属性如果是空的，那么就从ProviderConfig、ModuleConfig、ApplicationConfig中获取，补全ServiceConfig中的属性 completeCompoundConfigs(); // 从配置中心获取配置，包括应用配置和全局配置，把获取到的配置放入到Environment中的externalConfigurationMap和appExternalConfigurationMap中 // 并刷新所有除开ServiceConfig的XxConfig的属性，即将配置中心的配置覆盖XxConfig中的属性 startConfigCenter(); checkDefault(); checkProtocol(); checkApplication(); if (!isOnlyInJvm()) &#123; checkRegistry();// 如果protocol不是只有injvm协议，表示服务调用不是只在本机jvm里面调用，那就需要用到注册中心 &#125; this.refresh(); // 刷新ServiceConfig checkMetadataReport(); // 如果配了metadataReportConfig，那么就刷新配置 if (StringUtils.isEmpty(interfaceName)) &#123; throw new IllegalStateException(\"&lt;dubbo:service interface=\\\"\\\" /&gt; interface not allow null!\"); &#125; if (ref instanceof GenericService) &#123; // 当前服务对应的实现类是一个GenericService，表示没有特定的接口 interfaceClass = GenericService.class; if (StringUtils.isEmpty(generic)) &#123; generic = Boolean.TRUE.toString(); &#125; &#125; else &#123; try &#123; // 加载接口 interfaceClass = Class.forName(interfaceName, true, Thread.currentThread().getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; checkInterfaceAndMethods(interfaceClass, methods); // 刷新MethodConfig，并判断MethodConfig中对应的方法在接口中是否存在 checkRef(); // 实现类是不是该接口类型 generic = Boolean.FALSE.toString(); &#125; if (local != null) &#123; // local和stub一样，不建议使用了 if (Boolean.TRUE.toString().equals(local)) &#123; // 如果本地存根为true，则存根类为interfaceName + \"Local\" local = interfaceName + \"Local\"; &#125; Class&lt;?&gt; localClass; // 加载本地存根类 try &#123; localClass = ClassUtils.forNameWithThreadContextClassLoader(local); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; if (!interfaceClass.isAssignableFrom(localClass)) &#123; throw new IllegalStateException(\"The local implementation class \" + localClass.getName() + \" not implement interface \" + interfaceName); &#125; &#125; if (stub != null) &#123; // 本地存根 if (Boolean.TRUE.toString().equals(stub)) &#123; stub = interfaceName + \"Stub\"; // 若本地存根为true，则存根类为interfaceName + \"Stub\" &#125; Class&lt;?&gt; stubClass; try &#123; stubClass = ClassUtils.forNameWithThreadContextClassLoader(stub); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; if (!interfaceClass.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException(\"The stub implementation class \" + stubClass.getName() + \" not implement interface \" + interfaceName); &#125; &#125; checkStubAndLocal(interfaceClass); // 检查local和stub checkMock(interfaceClass); // 检查mock &#125; private void completeCompoundConfigs() &#123; if (provider != null) &#123; // 如果配置了provider，那么则从provider中获取信息赋值其他属性，在这些属性为空的情况下 if (application == null) &#123; setApplication(provider.getApplication()); &#125; if (module == null) &#123; setModule(provider.getModule()); &#125; if (registries == null) &#123; setRegistries(provider.getRegistries()); &#125; if (monitor == null) &#123; setMonitor(provider.getMonitor()); &#125; if (protocols == null) &#123; setProtocols(provider.getProtocols()); &#125; if (configCenter == null) &#123; setConfigCenter(provider.getConfigCenter()); &#125; &#125; if (module != null) &#123; // 如果配置了module，那么则从module中获取信息赋值其他属性，在这些属性为空的情况下 if (registries == null) &#123; setRegistries(module.getRegistries()); &#125; if (monitor == null) &#123; setMonitor(module.getMonitor()); &#125; &#125; if (application != null) &#123; // 如果配置了application，那么则从application中获取信息赋值其他属性，在这些属性为空的情况下 if (registries == null) &#123; setRegistries(application.getRegistries()); &#125; if (monitor == null) &#123; setMonitor(application.getMonitor()); &#125; &#125; &#125;&#125;public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123; void startConfigCenter() &#123; if (configCenter == null) &#123; ConfigManager.getInstance().getConfigCenter().ifPresent(cc -&gt; this.configCenter = cc); &#125; if (this.configCenter != null) &#123; // 如果配置了ConfigCenter this.configCenter.refresh(); // 从其他位置获取配置中心的相关属性信息，比如配置中心地址 prepareEnvironment(); // 属性更新后，从远程配置中心获取数据(应用配置，全局配置) &#125; ConfigManager.getInstance().refreshAll(); // 从配置中心取到配置数据后，刷新所有的XxConfig中的属性，除开ServiceConfig &#125;&#125;public abstract class AbstractConfig implements Serializable &#123; public void refresh() &#123; try &#123; CompositeConfiguration compositeConfiguration = Environment.getInstance().getConfiguration(getPrefix(), getId()); // 表示XxConfig对象本身- AbstractConfig Configuration config = new ConfigConfigurationAdapter(this); // ServiceConfig if (Environment.getInstance().isConfigCenterFirst()) &#123; // The sequence would be: SystemConfiguration -&gt; AppExternalConfiguration -&gt; ExternalConfiguration -&gt; AbstractConfig -&gt; PropertiesConfiguration compositeConfiguration.addConfiguration(4, config); &#125; else &#123; // The sequence would be: SystemConfiguration -&gt; AbstractConfig -&gt; AppExternalConfiguration -&gt; ExternalConfiguration -&gt; PropertiesConfiguration compositeConfiguration.addConfiguration(2, config); &#125; // loop methods, get override value and set the new value back to method Method[] methods = getClass().getMethods(); //ServiceBean for (Method method : methods) &#123; if (MethodUtils.isSetter(method)) &#123; // 是不是setXX()方法 // 获取xx配置项的value String value = StringUtils.trim(compositeConfiguration.getString(extractPropertyName(getClass(), method))); // isTypeMatch() is called to avoid duplicate and incorrect update, for example, we have two 'setGeneric' methods in ReferenceConfig. if (StringUtils.isNotEmpty(value) &amp;&amp; ClassUtils.isTypeMatch(method.getParameterTypes()[0], value)) &#123; method.invoke(this, ClassUtils.convertPrimitive(method.getParameterTypes()[0], value)); &#125; &#125; else if (isParametersSetter(method)) &#123; // 是不是setParameters()方法 // 获取parameter配置项的value String value = StringUtils.trim(compositeConfiguration.getString(extractPropertyName(getClass(), method))); if (StringUtils.isNotEmpty(value)) &#123; Map&lt;String, String&gt; map = invokeGetParameters(getClass(), this); map = map == null ? new HashMap&lt;&gt;() : map; map.putAll(convert(StringUtils.parseParameters(value), \"\")); invokeSetParameters(getClass(), this, map); &#125; &#125; &#125; &#125; &#125;&#125;public class ConfigManager &#123; public void refreshAll() &#123; getApplication().ifPresent(ApplicationConfig::refresh); getMonitor().ifPresent(MonitorConfig::refresh); getModule().ifPresent(ModuleConfig::refresh); getProtocols().values().forEach(ProtocolConfig::refresh); getRegistries().values().forEach(RegistryConfig::refresh); getProviders().values().forEach(ProviderConfig::refresh); getConsumers().values().forEach(ConsumerConfig::refresh); &#125;&#125; 通过loadRegistries方法获得所配置的注册中心URL，可配多个配置中心且当前导出服务需注册到每个配置中心去，注册中心类型、地址、端口和配置参数等，都会存在以registry://开头的URL上。 遍历当前服务所有的ProtocolConfig，且针对每个ProtocolConfig生成一个服务名称pathKey，然后将通过ProviderModel封装服务提供者访问路径，实现类，接口，以及接口中的各个方法对应的ProviderMethodModel，然后将解析好的ProviderModel与服务名称映射放入PROVIDED_SERVICES。然后调用doExportUrlsFor1Protocol方法把当前服务按每个协议每个注册中心分别导出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; protected synchronized void doExport() &#123; if (unexported) &#123; throw new IllegalStateException(\"The service \" + interfaceClass.getName() + \" has already unexported!\"); &#125; if (exported) &#123; // 已经导出了，就不再导出了 return; &#125; exported = true; if (StringUtils.isEmpty(path)) &#123; path = interfaceName; &#125; doExportUrls(); &#125; private void doExportUrls() &#123; List&lt;URL&gt; registryURLs = loadRegistries(true); // registryURL 表示一个注册中心 for (ProtocolConfig protocolConfig : protocols) &#123; // pathKey = group/contextpath/path:version String pathKey = URL.buildKey(getContextPath(protocolConfig).map(p -&gt; p + \"/\" + path).orElse(path), group, version); // ProviderModel中存在服务提供者访问路径，实现类，接口，以及接口中的各个方法对应的ProviderMethodModel，ProviderMethodModel表示某一个方法，方法名，所属的服务的， ProviderModel providerModel = new ProviderModel(pathKey, ref, interfaceClass); // ApplicationModel表示应用中有哪些服务提供者和引用了哪些服务 ApplicationModel.initProviderModel(pathKey, providerModel); doExportUrlsFor1Protocol(protocolConfig, registryURLs); // 重点 &#125; &#125;&#125;public class ProviderModel &#123; private final String serviceName; private final Object serviceInstance; private final Class&lt;?&gt; serviceInterfaceClass; private final Map&lt;String, List&lt;ProviderMethodModel&gt;&gt; methods = new HashMap&lt;String, List&lt;ProviderMethodModel&gt;&gt;(); public ProviderModel(String serviceName, Object serviceInstance, Class&lt;?&gt; serviceInterfaceClass) &#123; if (null == serviceInstance) &#123; throw new IllegalArgumentException(\"Service[\" + serviceName + \"]Target is NULL.\"); &#125; this.serviceName = serviceName; this.serviceInstance = serviceInstance; this.serviceInterfaceClass = serviceInterfaceClass; initMethod(); &#125; private void initMethod() &#123; Method[] methodsToExport = this.serviceInterfaceClass.getMethods(); for (Method method : methodsToExport) &#123; // 遍历接口所有的方法 method.setAccessible(true); // methods表示是某个方法对应的ProviderMethodModel，method.getName返回的仅仅只有方法名，不包括方法参数列表，有可能存在重载 List&lt;ProviderMethodModel&gt; methodModels = methods.get(method.getName()); if (methodModels == null) &#123; methodModels = new ArrayList&lt;ProviderMethodModel&gt;(1); methods.put(method.getName(), methodModels); &#125; methodModels.add(new ProviderMethodModel(method, serviceName)); &#125; &#125;&#125;public class ApplicationModel &#123; private static final ConcurrentMap&lt;String, ProviderModel&gt; PROVIDED_SERVICES = new ConcurrentHashMap&lt;&gt;(); public static void initProviderModel(String serviceName, ProviderModel providerModel) &#123; if (PROVIDED_SERVICES.putIfAbsent(serviceName, providerModel) != null) &#123; &#125; &#125;&#125; 首先从ProtocolConfig中获取协议名称，默认为dubbo协议，然后通过一系列的appendParameters方法将服务参数转存到Map中，若@Service注解中配置了methods参数，则遍历解析methods参数配置且补充到Map中。然后解析出提供的方法列表以及Token，然后通过所有的参数最终构造一个服务的URL，再根据scope执行本地导出和远程导出。 把服务URL作为参数添加到registryURL中，然后把registryURL、服务接口、当前服务实现类ref调用ProxyFactory的getInvoker方法，使用代理生成一个当前服务接口即服务提供者的代理对象Invoker，再把该代理对象Invoker和当前ServiceConfig对象包装成一个DelegateProviderMetaDataInvoker对象。 最后通过具体Protocol的export方法对服务进行导出，这里的协议为RegistryProtocol，导出成功后得到一个Exporter，RegistryProtocol中进行服务注册，注册完之后使用DubboProtocol进行导出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; String name = protocolConfig.getName(); // protocolConfig表示某个协议，registryURLs表示所有的注册中心 if (StringUtils.isEmpty(name)) &#123; name = DUBBO; // 若配置的某个协议没有配置name，则默认为dubbo &#125; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 表示服务url参数 map.put(SIDE_KEY, PROVIDER_SIDE); appendRuntimeParameters(map); appendParameters(map, metrics); // 监控中心参数 appendParameters(map, application); // 应用相关参数 appendParameters(map, module); // 模块相关参数 appendParameters(map, provider); // 提供者相关参数 appendParameters(map, protocolConfig); // 协议相关参数 appendParameters(map, this); // 服务本身相关参数 if (CollectionUtils.isNotEmpty(methods)) &#123; // 服务中某些方法参数：@Service(methods = &#123;@Method(name = \"say\", timeout = 3000)&#125;) for (MethodConfig method : methods) &#123; appendParameters(map, method, method.getName()); // 某个方法的配置参数，注意有prefix String retryKey = method.getName() + \".retry\"; if (map.containsKey(retryKey)) &#123; // 如果某个方法配置存在xx.retry=false，则改成xx.retry=0 String retryValue = map.remove(retryKey); if (Boolean.FALSE.toString().equals(retryValue)) &#123; map.put(method.getName() + \".retries\", \"0\"); &#125; &#125; List&lt;ArgumentConfig&gt; arguments = method.getArguments(); if (CollectionUtils.isNotEmpty(arguments)) &#123;// 遍历当前方法配置中的参数配置 for (ArgumentConfig argument : arguments) &#123; // 若配置了type，则遍历当前接口的所有方法，找到方法名和当前方法名相等的方法，可能存在多个 // 若配置了index，则看index对应位置的参数类型是否等于type,若相等，则向map中存入argument对象中的参数 // 若没有配置index，那么则遍历方法所有的参数类型，等于type则向map中存入argument对象中的参数 // 若没有配置type，但配置了index,则把对应位置的argument放入map // convert argument type if (argument.getType() != null &amp;&amp; argument.getType().length() &gt; 0) &#123; Method[] methods = interfaceClass.getMethods(); if (methods != null &amp;&amp; methods.length &gt; 0) &#123; // visit all methods for (int i = 0; i &lt; methods.length; i++) &#123; String methodName = methods[i].getName(); if (methodName.equals(method.getName())) &#123; // target the method, and get its signature Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes(); if (argument.getIndex() != -1) &#123; // one callback in the method if (argtypes[argument.getIndex()].getName().equals(argument.getType())) &#123; appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException(\"Argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); &#125; &#125; else &#123;// multiple callbacks in the method for (int j = 0; j &lt; argtypes.length; j++) &#123; Class&lt;?&gt; argclazz = argtypes[j]; if (argclazz.getName().equals(argument.getType())) &#123; appendParameters(map, argument, method.getName() + \".\" + j); if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j) &#123; throw new IllegalArgumentException(\"Argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; else if (argument.getIndex() != -1) &#123; appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException(\"Argument config must set index or type attribute.eg: &lt;dubbo:argument index='0' .../&gt; or &lt;dubbo:argument type=xxx .../&gt;\"); &#125; &#125; &#125; &#125; // end of methods for &#125; if (ProtocolUtils.isGeneric(generic)) &#123; map.put(GENERIC_KEY, generic); map.put(METHODS_KEY, ANY_VALUE); &#125; else &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put(REVISION_KEY, revision); &#125; // 通过接口对应的Wrapper，拿到接口中所有的方法名字 String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) &#123; map.put(METHODS_KEY, ANY_VALUE); &#125; else &#123; map.put(METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), \",\")); &#125; &#125; if (!ConfigUtils.isEmpty(token)) &#123; // Token是为了防止服务被消费者直接调用（伪造http请求） if (ConfigUtils.isDefault(token)) &#123; map.put(TOKEN_KEY, UUID.randomUUID().toString()); &#125; else &#123; map.put(TOKEN_KEY, token); &#125; &#125; // export service通过该host和port访问该服务 String host = this.findConfigedHosts(protocolConfig, registryURLs, map); Integer port = this.findConfigedPorts(protocolConfig, name, map); URL url = new URL(name, host, port, getContextPath(protocolConfig).map(p -&gt; p + \"/\" + path).orElse(path), map); // 服务url // 可通过ConfiguratorFactory，对服务url再次进行配置 if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class).hasExtension(url.getProtocol())) &#123; url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class).getExtension(url.getProtocol()).getConfigurator(url).configure(url); &#125; String scope = url.getParameter(SCOPE_KEY); // scope可能为null，remote, local，none if (!SCOPE_NONE.equalsIgnoreCase(scope)) &#123;// don't export when none is configured // 若scope为none则不会进行任何的服务导出，既不会远程，也不会本地 if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) &#123; exportLocal(url); // 如果scope不是remote，则会进行本地导出，会把当前url的protocol改为injvm，然后进行导出 &#125; if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) &#123;// 如果scope不是local则会进行远程导出 if (CollectionUtils.isNotEmpty(registryURLs)) &#123;// 如果有注册中心，则将服务注册到注册中心 for (URL registryURL : registryURLs) &#123; if (LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; continue;// 如果是injvm，则不需要进行注册中心注册 &#125; // 该服务是否是动态，对应zookeeper上表示是否是临时节点，对应dubbo中的功能就是静态服务 url = url.addParameterIfAbsent(DYNAMIC_KEY, registryURL.getParameter(DYNAMIC_KEY)); URL monitorUrl = loadMonitor(registryURL); // 拿到监控中心地址 if (monitorUrl != null) &#123; // 当前服务连接哪个监控中心 url = url.addParameterAndEncoded(MONITOR_KEY, monitorUrl.toFullString()); &#125; String proxy = url.getParameter(PROXY_KEY); // 服务使用的动态代理机制，如果为空则使用javassit if (StringUtils.isNotEmpty(proxy)) &#123; registryURL = registryURL.addParameter(PROXY_KEY, proxy); &#125; // 使用代理生成一个当前服务接口即服务提供者的代理对象Invoker，Invoker中包括了服务实现者、服务接口类、服务的注册地址，可以使用Invoker的invoke方法执行服务，同时此invoker也可用来导出 Invoker&lt;?&gt; invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString())); // invoker.invoke(Invocation) DelegateProviderMetaDataInvoker也表示服务提供者，包括了Invoker和服务的配置 DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); // 使用特定的协议来对服务进行导出，这里的协议为RegistryProtocol，导出成功后得到一个Exporter // 1. 先使用RegistryProtocol进行服务注册 // 2. 注册完了之后，使用DubboProtocol进行导出 // 到此为止完成了ServiceBean.export()--&gt;刷新ServiceBean的参数--&gt;得到注册中心URL和协议URL--&gt;遍历每个协议URL--&gt;组成服务URL--&gt;生成可执行服务Invoker--&gt;导出服务 Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; &#125; else &#123;// 没有配置注册中心时，也会导出服务 Invoker&lt;?&gt; invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; MetadataReportService metadataReportService = null; if ((metadataReportService = getMetadataReportService()) != null) &#123; metadataReportService.publishProvider(url); // 根据服务url，讲服务的元信息存入元数据中心 &#125; &#125; &#125; this.urls.add(url); &#125;&#125; 默认使用ProxyFactory的JavassistProxyFactory子类生成Invoker的代理对象，若被代理对象proxy本身就是一个已经被代理过的对象，则取代理类的Wrapper，否则取type接口的Wrapper，Wrapper是针对某个类或某个接口的包装类，通过wrapper对象可更方便的去执行某个类或某个接口的方法，最终封装为AbstractProxyInvoker对象。 12345678910111213public class JavassistProxyFactory extends AbstractProxyFactory &#123; public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // 若现在被代理对象proxy本身就是一个已经被代理过的对象，则取代理类的Wrapper，否则取type接口的Wrapper // Wrapper是针对某个类或某个接口的包装类，通过wrapper对象可以更方便的去执行某个类或某个接口的方法 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123;// proxy是服务实现类 type是服务接口 url是一个注册中心url @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; // 执行proxy的method方法，执行的proxy实例的方法，若没有wrapper，则要通过原生的反射技术去获取Method对象，然后执行 return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125;&#125; protocol是Protocol接口的一个Adaptive对象，故会根据wrapperInvoker的genUrl方法得到一个url，根据此url协议找到对应RegistryProtocol扩展点，而Protocol接口有ProtocolFilterWrapper和ProtocolListenerWrapper两个包装类，实际在调用export方法时会经过这两个包装类的export方法。 RegistryProtocol中首先获取到服务提供者URL和注册中心URL，然后给服务提供者生成并绑定监听器OverrideListener，监听动态配置中心此服务的参数数据的变化，一旦监听到变化则重写服务URL；在服务导出时先重写一次服务URL，然后通过doLocalExport调用DubboProtocol进行导出服务，导出成功后将得到一个ExporterChangeableWrapper；然后将其注册到注册中心。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147public class ProtocolListenerWrapper implements Protocol &#123; private final Protocol protocol; public ProtocolListenerWrapper(Protocol protocol) &#123; if (protocol == null) &#123; throw new IllegalArgumentException(\"protocol == null\"); &#125; this.protocol = protocol; &#125; @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; // 导出了一个服务之后，调用ExporterListener return new ListenerExporterWrapper&lt;T&gt;(protocol.export(invoker), // 得到ExporterListener接口中能用的扩展点，根据url和EXPORTER_LISTENER_KEY进行筛选 Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), EXPORTER_LISTENER_KEY))); &#125;&#125;public class ListenerExporterWrapper&lt;T&gt; implements Exporter&lt;T&gt; &#123; public ListenerExporterWrapper(Exporter&lt;T&gt; exporter, List&lt;ExporterListener&gt; listeners) &#123; if (exporter == null) &#123; throw new IllegalArgumentException(\"exporter == null\"); &#125; this.exporter = exporter; this.listeners = listeners; if (CollectionUtils.isNotEmpty(listeners)) &#123; RuntimeException exception = null; for (ExporterListener listener : listeners) &#123; if (listener != null) &#123; try &#123; listener.exported(this); &#125; catch (RuntimeException t) &#123; logger.error(t.getMessage(), t); exception = t; &#125; &#125; &#125; if (exception != null) &#123; throw exception; &#125; &#125; &#125;&#125;public class ProtocolFilterWrapper implements Protocol &#123; public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; return protocol.export(buildInvokerChain(invoker, SERVICE_FILTER_KEY, CommonConstants.PROVIDER)); &#125; private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; // 根据url获取filter，根据url中的parameters取key为key的value所对应的filter，但是还会匹配group List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (!filters.isEmpty()) &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; @Override public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; @Override public URL getUrl() &#123; return invoker.getUrl(); &#125; @Override public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult; try &#123;// 得到一个异步结果 asyncResult = filter.invoke(next, invocation); &#125; catch (Exception e) &#123; // onError callback if (filter instanceof ListenableFilter) &#123; Filter.Listener listener = ((ListenableFilter) filter).listener(); if (listener != null) &#123; listener.onError(e, invoker, invocation); &#125; &#125; throw e; &#125; return asyncResult; &#125; @Override public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return new CallbackRegistrationInvoker&lt;&gt;(last, filters); &#125;&#125;public class RegistryProtocol implements Protocol &#123; public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; // 导出服务registry://对应RegistryProtocol，zookeeper://对应ZookeeperRegistry，dubbo://对应DubboProtocol URL registryUrl = getRegistryUrl(originInvoker); // registry://xxx?xx=xx&amp;registry=zookeeper---&gt;zookeeper://xxx?xx=xx 表示注册中心 URL providerUrl = getProviderUrl(originInvoker); // 得到服务提供者url，表示服务提供者 // overrideSubscribeUrl是老版本的动态配置监听url，表示了需要监听的服务以及监听的类型，configurators是老版本上的动态配置 // 在服务提供者url的基础上，生成一个overrideSubscribeUrl，协议为provider://，增加参数category=configurators&amp;check=false final URL overrideSubscribeUrl = getSubscribedOverrideUrl(providerUrl); // 一个overrideSubscribeUrl对应一个OverrideListener，用来监听变化事件，监听到overrideSubscribeUrl的变化后，OverrideListener就会根据变化进行相应处理，具体处理逻辑看OverrideListener的实现 final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); // 在该方法里会利用providerConfigurationListener和serviceConfigurationListener去重写providerUrl // providerConfigurationListener表示应用级别的动态配置监听器，providerConfigurationListener是RegistyProtocol的一个属性 // serviceConfigurationListener表示服务级别的动态配置监听器，serviceConfigurationListener是在每暴露一个服务时就会生成一个 // 这两个监听器都是新版本中的监听器，新版本监听的zk路径是： // 服务：/dubbo/config/dubbo/org.apache.dubbo.demo.DemoService.configurators节点的内容 // 应用：/dubbo/config/dubbo/dubbo-demo-provider-application.configurators节点的内容 // 注意，要和配置中心的路径区分开来，配置中心的路径是： // 应用：/dubbo/config/dubbo/org.apache.dubbo.demo.DemoService/dubbo.properties节点的内容 // 全局：/dubbo/config/dubbo/dubbo.properties节点的内容 providerUrl = overrideUrlWithConfig(providerUrl, overrideSubscribeListener); // export invoker，根据动态配置重写了providerUrl之后，就会调用DubboProtocol或HttpProtocol去进行导出服务了 final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker, providerUrl); final Registry registry = getRegistry(originInvoker); // url to registry，得到注册中心-ZookeeperRegistry // 得到存入到注册中心去的providerUrl，会对服务提供者url中的参数进行简化 final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); // 将当前服务提供者Invoker，以及该服务对应的注册中心地址，以及简化后的服务url存入ProviderConsumerRegTable ProviderInvokerWrapper&lt;T&gt; providerInvokerWrapper = ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); //to judge if we need to delay publish 是否需要注册到注册中心 boolean register = providerUrl.getParameter(REGISTER_KEY, true); if (register) &#123;// 注册服务，把简化后的服务提供者url注册到registryUrl中去 register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); &#125; // 针对老版本的动态配置，需要把overrideSubscribeListener绑定到overrideSubscribeUrl上去进行监听，兼容老版本的配置修改，利用overrideSubscribeListener去监听旧版本的动态配置变化 // 老版本监听的zk路径是：/dubbo/org.apache.dubbo.demo.DemoService/configurators/override://0.0.0.0/org.apache.dubbo.demo.DemoService?category=configurators&amp;compatible_config=true&amp;dynamic=false&amp;enabled=true&amp;timeout=6000 // 监听的是路径的内容，不是节点的内容 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); exporter.setRegisterUrl(registeredProviderUrl); exporter.setSubscribeUrl(overrideSubscribeUrl); return new DestroyableExporter&lt;&gt;(exporter);//Ensure that a new exporter instance is returned every time export &#125;&#125; 通过DubboProtocol导出服务主要是启动NettyServer且层层封装处理数据的RequestHandler，通过url绑定端口和对应的请求处理器RequestHandler类型为ExchangeHandler，以便在接收到请求时能依次被这些RequestHandler所处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145public class RegistryProtocol implements Protocol &#123; private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker, URL providerUrl) &#123; String key = getCacheKey(originInvoker); return (ExporterChangeableWrapper&lt;T&gt;) bounds.computeIfAbsent(key, s -&gt; &#123; Invoker&lt;?&gt; invokerDelegate = new InvokerDelegate&lt;&gt;(originInvoker, providerUrl); // protocol属性的值是哪来的，是在SPI中注入进来的，是一个代理类，这里实际利用的就是DubboProtocol或HttpProtocol去export，使用ExporterChangeableWrapper是为了方便注销已经被导出的服务 return new ExporterChangeableWrapper&lt;&gt;((Exporter&lt;T&gt;) protocol.export(invokerDelegate), originInvoker); &#125;); &#125;&#125;public class DubboProtocol extends AbstractProtocol &#123; public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; URL url = invoker.getUrl(); String key = serviceKey(url); // export service. DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); // 构造一个Exporter进行服务导出 exporterMap.put(key, exporter); Boolean isStubSupportEvent = url.getParameter(STUB_EVENT_KEY, DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice) &#123; //export an stub service for dispatching event String stubServiceMethods = url.getParameter(STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) &#123; &#125; else &#123;// 服务的stub方法 stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125; openServer(url); // 开启NettyServer请求---&gt;invocation---&gt;服务key---&gt;exporterMap.get(key)---&gt;exporter---&gt;invoker---&gt;invoker.invoke(invocation)--&gt;执行服务 optimizeSerialization(url); // 特殊的一些序列化机制，比如kryo提供了注册机制来注册类，提高序列化和反序列化的速度 return exporter; &#125; private void openServer(URL url) &#123; String key = url.getAddress(); // find server.获得ip地址和port：192.168.40.17:20880 boolean isServer = url.getParameter(IS_SERVER_KEY, true); if (isServer) &#123; ExchangeServer server = serverMap.get(key);// 缓存Server对象 if (server == null) &#123;// DCL，Double Check Lock synchronized (this) &#123; server = serverMap.get(key); if (server == null) &#123; serverMap.put(key, createServer(url)); // 创建Server，并进行缓存 &#125; &#125; &#125; else &#123;// server supports reset, use together with override server.reset(url); // 服务重新导出时，就会走这里 &#125; &#125; &#125; private ExchangeServer createServer(URL url) &#123; url = URLBuilder.from(url)// send readonly event when server closes, it's enabled by default .addParameterIfAbsent(CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()) .addParameterIfAbsent(HEARTBEAT_KEY, String.valueOf(DEFAULT_HEARTBEAT))// enable heartbeat by default .addParameter(CODEC_KEY, DubboCodec.NAME) .build(); // 协议的服务器端实现类型，如：dubbo协议的mina,netty等，http协议的jetty,servlet等，默认为netty String str = url.getParameter(SERVER_KEY, DEFAULT_REMOTING_SERVER); if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123; throw new RpcException(\"Unsupported server type: \" + str + \", url: \" + url); &#125; ExchangeServer server; try &#123;// 通过url绑定端口，和对应的请求处理器，requestHandler是请求处理器，类型为ExchangeHandler，表示从url的端口接收到请求后，requestHandler来进行处理 server = Exchangers.bind(url, requestHandler); &#125; catch (RemotingException e) &#123; throw new RpcException(\"Fail to start server(url: \" + url + \") \" + e.getMessage(), e); &#125; str = url.getParameter(CLIENT_KEY); // 协议的客户端实现类型，比如：dubbo协议的mina,netty等 if (str != null &amp;&amp; str.length() &gt; 0) &#123; Set&lt;String&gt; supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); if (!supportedTypes.contains(str)) &#123; throw new RpcException(\"Unsupported client type: \" + str); &#125; &#125; return server; &#125; private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123; @Override public CompletableFuture&lt;Object&gt; reply(ExchangeChannel channel, Object message) throws RemotingException &#123; if (!(message instanceof Invocation)) &#123; throw new RemotingException(channel, \"Unsupported request: \" + (message == null ? null : (message.getClass().getName() + \": \" + message)) + \", channel: consumer: \" + channel.getRemoteAddress() + \" --&gt; provider: \" + channel.getLocalAddress()); &#125; Invocation inv = (Invocation) message; // 转成Invocation对象，要开始用反射执行方法了 Invoker&lt;?&gt; invoker = getInvoker(channel, inv); // 服务实现者 if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE))) &#123; String methodsStr = invoker.getUrl().getParameters().get(\"methods\"); boolean hasMethod = false; if (methodsStr == null || !methodsStr.contains(\",\")) &#123; hasMethod = inv.getMethodName().equals(methodsStr); &#125; else &#123; String[] methods = methodsStr.split(\",\"); for (String method : methods) &#123; if (inv.getMethodName().equals(method)) &#123; hasMethod = true; break; &#125; &#125; &#125; if (!hasMethod) &#123; return null; &#125; &#125; RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress());// 这里设置了，service中才能拿到remoteAddress Result result = invoker.invoke(inv);// 执行服务，得到结果 return result.completionFuture().thenApply(Function.identity()); // 返回一个CompletableFuture &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof Invocation) &#123; reply((ExchangeChannel) channel, message); // 这是服务端接收到Invocation时的处理逻辑 &#125; else &#123; super.received(channel, message); &#125; &#125; @Override public void connected(Channel channel) throws RemotingException &#123; invoke(channel, ON_CONNECT_KEY); &#125; @Override public void disconnected(Channel channel) throws RemotingException &#123; invoke(channel, ON_DISCONNECT_KEY); &#125; private void invoke(Channel channel, String methodKey) &#123; Invocation invocation = createInvocation(channel, channel.getUrl(), methodKey); if (invocation != null) &#123; try &#123; received(channel, invocation); &#125; catch (Throwable t) &#123; &#125; &#125; &#125; private Invocation createInvocation(Channel channel, URL url, String methodKey) &#123; String method = url.getParameter(methodKey); if (method == null || method.length() == 0) &#123; return null; &#125; RpcInvocation invocation = new RpcInvocation(method, new Class&lt;?&gt;[0], new Object[0]); invocation.setAttachment(PATH_KEY, url.getPath()); invocation.setAttachment(GROUP_KEY, url.getParameter(GROUP_KEY)); invocation.setAttachment(INTERFACE_KEY, url.getParameter(INTERFACE_KEY)); invocation.setAttachment(VERSION_KEY, url.getParameter(VERSION_KEY)); if (url.getParameter(STUB_EVENT_KEY, false)) &#123; invocation.setAttachment(STUB_EVENT_KEY, Boolean.TRUE.toString()); &#125; return invocation; &#125; &#125;;&#125; Netty启动最终在Exchangers中调用HeaderExchanger的bind方法最终调用NettyTransporter去启动NettyServer，在调用NettyServer构造方法时会调用超类AbstractServer构造方法，从而调用NettyServer的doOpen启动NettyServer。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class Exchangers &#123; public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\");// codec表示协议编码方式 return getExchanger(url).bind(url, handler);// 通过url得到HeaderExchanger，利用HeaderExchanger进行bind，将得到一个HeaderExchangeServer &#125;&#125;public class HeaderExchanger implements Exchanger &#123; public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; // 去启动Netty对handler包装了两层，表示当处理一个请求时，每层Handler负责不同的处理逻辑，在connect和bind时都是DecodeHandler，解码解的是把InputStream解析成RpcInvocation对象 return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler)))); &#125;&#125;public class Transporters &#123; public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handlers == null || handlers.length == 0) &#123; throw new IllegalArgumentException(\"handlers == null\"); &#125; // 如果bind了多个handler，那么当有一个连接过来时，会循环每个handler去处理连接 ChannelHandler handler; if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; handler = new ChannelHandlerDispatcher(handlers); &#125; return getTransporter().bind(url, handler);// 调用NettyTransporter去绑定，Transporter表示网络传输层 &#125;&#125;public class NettyTransporter implements Transporter &#123; public Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; return new NettyServer(url, listener); &#125;&#125;public class NettyServer extends AbstractServer implements Server &#123; public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; // 设置线程名，wrap方法会返回一个MultiMessageHandler，该Handler会被设置到AbstractPeer的handler属性上 // 当netty接收到数据时，会调用AbstractPeer的handler属性的received方法，所以MultiMessageHandler就是负责处理请求 super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME))); &#125; protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); // boss线程，主要监听端口和分配socketChannel给worker线程 ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerBoss\", true)); // worker线程负责数据读写 ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerWorker\", true)); // iothreads就是读写数据的线程 ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap = new ServerBootstrap(channelFactory); // 连接处理器，建立连接、连接断开、接收到数据、返回数据的逻辑都在这个Handler里面，this表示的是NettyServer，在它的父类AbstractServer final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); channels = nettyHandler.getChannels(); // final Timer timer = new HashedWheelTimer(new NamedThreadFactory(\"NettyIdleTimer\", true)); bootstrap.setOption(\"child.tcpNoDelay\", true); bootstrap.setOption(\"backlog\", getUrl().getPositiveParameter(BACKLOG_KEY, Constants.DEFAULT_BACKLOG)); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; @Override public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(\"decoder\", adapter.getDecoder()); pipeline.addLast(\"encoder\", adapter.getEncoder()); pipeline.addLast(\"handler\", nettyHandler); return pipeline; &#125; &#125;); // bind channel = bootstrap.bind(getBindAddress()); &#125;&#125;public abstract class AbstractServer extends AbstractEndpoint implements Server &#123; public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); localAddress = getUrl().toInetSocketAddress(); String bindIp = getUrl().getParameter(Constants.BIND_IP_KEY, getUrl().getHost()); int bindPort = getUrl().getParameter(Constants.BIND_PORT_KEY, getUrl().getPort()); if (url.getParameter(ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(bindIp)) &#123; bindIp = ANYHOST_VALUE; &#125; bindAddress = new InetSocketAddress(bindIp, bindPort); this.accepts = url.getParameter(ACCEPTS_KEY, DEFAULT_ACCEPTS); this.idleTimeout = url.getParameter(IDLE_TIMEOUT_KEY, DEFAULT_IDLE_TIMEOUT); try &#123; doOpen(); &#125; catch (Throwable t) &#123; throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to bind \" + getClass().getSimpleName() + \" on \" + getLocalAddress() + \", cause: \" + t.getMessage(), t); &#125; DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); executor = (ExecutorService) dataStore.get(Constants.EXECUTOR_SERVICE_COMPONENT_KEY, Integer.toString(url.getPort())); &#125;&#125; 服务注册首先从originInvoker中获取注册中心的实现类ZookeeperRegistry，将重写后的服务URL简化，把不用存到注册中心去的参数去除，将简化后的服务URL调用ZookeeperRegistry.registry()方法注册到注册中心去，首先会先调用ZookeeperRegistry超类FailbackRegistry的register方法，然后调用ZookeeperRegistry的doRegister正则将服务注册到Zookeeper上，最后将ExporterChangeableWrapper封装为DestroyableExporter对象返回完成服务导出。 12345678910111213141516171819202122232425262728293031323334353637383940public class RegistryProtocol implements Protocol &#123; public void register(URL registryUrl, URL registeredProviderUrl) &#123; Registry registry = registryFactory.getRegistry(registryUrl); registry.register(registeredProviderUrl); // 调用ZookeeperRegistry的register方法 &#125;&#125;public abstract class FailbackRegistry extends AbstractRegistry &#123; public void register(URL url) &#123; super.register(url); removeFailedRegistered(url); removeFailedUnregistered(url); try &#123;// Sending a registration request to the server side doRegister(url); &#125; catch (Exception e) &#123; Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(\"Failed to register \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); &#125; // Record a failed registration request to a failed list, retry regularly addFailedRegistered(url); &#125; &#125;&#125;public class ZookeeperRegistry extends FailbackRegistry &#123; public void doRegister(URL url) &#123; try &#123; zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125;&#125; Exporter架构一个服务导出成功后，会生成对应的Exporter，Exporter嵌套结构由外到内依次为： DestroyableExporter：Exporter的最外层包装类，该类的主要作用是可用来unexporter对应的服务 ExporterChangeableWrapper：该类主要负责在unexport对应服务之前，把服务URL从注册中心中移除，且把该服务对应的动态配置监听器移除 ListenerExporterWrapper：该类主要负责在unexport对应服务之后，把服务导出监听器移除 DubboExporter：该类中保存了对应服务的Invoker对象和当前服务唯一标志，当NettyServer接收到请求后，会根据请求中的服务信息，找到服务对应的DubboExporter对象，然后从对象中得到Invoker对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081private static class DestroyableExporter&lt;T&gt; implements Exporter&lt;T&gt; &#123; private Exporter&lt;T&gt; exporter; public DestroyableExporter(Exporter&lt;T&gt; exporter) &#123; this.exporter = exporter; &#125; @Override public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; @Override public void unexport() &#123; exporter.unexport(); &#125;&#125;private class ExporterChangeableWrapper&lt;T&gt; implements Exporter&lt;T&gt; &#123; public void unexport() &#123; String key = getCacheKey(this.originInvoker); bounds.remove(key); Registry registry = RegistryProtocol.INSTANCE.getRegistry(originInvoker); // 从注册中心删除服务URL try &#123; registry.unregister(registerUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123;// 解绑当前服务的Listener NotifyListener listener = RegistryProtocol.INSTANCE.overrideListeners.remove(subscribeUrl); registry.unsubscribe(subscribeUrl, listener); DynamicConfiguration.getDynamicConfiguration().removeListener(subscribeUrl.getServiceKey() + CONFIGURATORS_SUFFIX, serviceConfigurationListeners.get(subscribeUrl.getServiceKey())); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; executor.submit(() -&gt; &#123; try &#123; int timeout = ConfigurationUtils.getServerShutdownTimeout(); if (timeout &gt; 0) &#123; Thread.sleep(timeout); &#125; exporter.unexport(); &#125; catch (Throwable t) &#123; &#125; &#125;); &#125;&#125;public class ListenerExporterWrapper&lt;T&gt; implements Exporter&lt;T&gt; &#123; public void unexport() &#123; try &#123; exporter.unexport(); &#125; finally &#123; if (CollectionUtils.isNotEmpty(listeners)) &#123; RuntimeException exception = null; for (ExporterListener listener : listeners) &#123; if (listener != null) &#123; try &#123; listener.unexported(this); &#125; catch (RuntimeException t) &#123; logger.error(t.getMessage(), t); exception = t; &#125; &#125; &#125; if (exception != null) &#123; throw exception; &#125; &#125; &#125; &#125;&#125;public class DubboExporter&lt;T&gt; extends AbstractExporter&lt;T&gt; &#123; private final String key; private final Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap; public DubboExporter(Invoker&lt;T&gt; invoker, String key, Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap) &#123; super(invoker); this.key = key; this.exporterMap = exporterMap; &#125; @Override public void unexport() &#123; super.unexport(); exporterMap.remove(key); &#125;&#125; Invoker架构Invoker嵌套结构由外到内依次为： ProtocolFilterWrapper$CallbackRegistrationInvoker：会去调用下层Invoker，下层Invoker执行完之后会遍历过滤器，查看是否有过滤器实现了ListenableFilter接口，若有则回调对应onResponse方法如TimeoutFilter，当调用完下层Invoker后会计算服务执行时间 ProtocolFilterWrapper$1：ProtocolFilterWrapper中的过滤器组成的Invoker，利用该Invoker可执行服务端的过滤器，执行完过滤器之后，调用下层Invoker RegistryProtocol$InvokerDelegate：服务委托类，包含了DelegateProviderMetaDataInvoker对象和服务对应的providerUrl，执行时直接调用下层Invoker DelegateProviderMetaDataInvoker：服务委托类，包含了AbstractProxyInvoker对象和ServiceConfig对象，执行时直接调用下层Invoker AbstractProxyInvoker：服务接口代理类，绑定了对应的实现类，执行时会利用反射调用服务实现类实例的具体方法并得到结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public class ProtocolFilterWrapper implements Protocol &#123; static class CallbackRegistrationInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; private final Invoker&lt;T&gt; filterInvoker; private final List&lt;Filter&gt; filters; public CallbackRegistrationInvoker(Invoker&lt;T&gt; filterInvoker, List&lt;Filter&gt; filters) &#123; this.filterInvoker = filterInvoker; this.filters = filters; &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult = filterInvoker.invoke(invocation); // 执行过滤器链 // 过滤器都执行完了之后，回调每个ListenableFilter过滤器的onResponse或onError方法 asyncResult = asyncResult.whenCompleteWithContext((r, t) -&gt; &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; Filter filter = filters.get(i); if (filter instanceof ListenableFilter) &#123; // onResponse callback Filter.Listener listener = ((ListenableFilter) filter).listener(); if (listener != null) &#123; if (t == null) &#123; listener.onResponse(r, filterInvoker, invocation); &#125; else &#123; listener.onError(t, filterInvoker, invocation); &#125; &#125; &#125; else &#123; filter.onResponse(r, filterInvoker, invocation); &#125; &#125; &#125;); return asyncResult; &#125; &#125;&#125;public class ProtocolFilterWrapper implements Protocol &#123; private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; // 根据url获取filter，根据url中的parameters取key为key的value所对应的filter，但是还会匹配group List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (!filters.isEmpty()) &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult; try &#123;// 得到一个异步结果 asyncResult = filter.invoke(next, invocation); &#125; catch (Exception e) &#123; // onError callback if (filter instanceof ListenableFilter) &#123; Filter.Listener listener = ((ListenableFilter) filter).listener(); if (listener != null) &#123; listener.onError(e, invoker, invocation); &#125; &#125; throw e; &#125; return asyncResult; &#125; &#125;; &#125; &#125; return new CallbackRegistrationInvoker&lt;&gt;(last, filters); &#125;&#125;public static class InvokerDelegate&lt;T&gt; extends InvokerWrapper&lt;T&gt; &#123; private final Invoker&lt;T&gt; invoker; public InvokerDelegate(Invoker&lt;T&gt; invoker, URL url) &#123; super(invoker, url); this.invoker = invoker; &#125; public Invoker&lt;T&gt; getInvoker() &#123; if (invoker instanceof InvokerDelegate) &#123; return ((InvokerDelegate&lt;T&gt;) invoker).getInvoker(); &#125; else &#123; return invoker; &#125; &#125;&#125;public class DelegateProviderMetaDataInvoker&lt;T&gt; implements Invoker &#123; protected final Invoker&lt;T&gt; invoker; private ServiceConfig metadata; public DelegateProviderMetaDataInvoker(Invoker&lt;T&gt; invoker, ServiceConfig metadata) &#123; this.invoker = invoker; this.metadata = metadata; &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation); &#125; @Override public void destroy() &#123; invoker.destroy(); &#125; public ServiceConfig getMetadata() &#123; return metadata; &#125;&#125;public abstract class AbstractProxyInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; private final T proxy; private final Class&lt;T&gt; type; private final URL url; public AbstractProxyInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; if (proxy == null) &#123; throw new IllegalArgumentException(\"proxy == null\"); &#125; if (type == null) &#123; throw new IllegalArgumentException(\"interface == null\"); &#125; if (!type.isInstance(proxy)) &#123; throw new IllegalArgumentException(proxy.getClass().getName() + \" not implement interface \" + type); &#125; this.proxy = proxy; this.type = type; this.url = url; &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; // 执行服务，得到一个接口，可能是一个CompletableFuture(表示异步调用)，可能是一个正常的服务执行结果（同步调用） Object value = doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()); CompletableFuture&lt;Object&gt; future = wrapWithFuture(value, invocation); // 将同步调用的服务执行结果封装为CompletableFuture类型 AsyncRpcResult asyncRpcResult = new AsyncRpcResult(invocation); // 异步RPC结果 future.whenComplete((obj, t) -&gt; &#123; //设置一个回调，若是异步调用，则服务执行完成后将执行这里的回调 // 当服务执行完后，将结果或异常设置到AsyncRpcResult中，若是异步服务，则服务之后的异常会在此处封装到AppResponse中然后返回，若是同步服务出异常了，则会在下面将异常封装到AsyncRpcResult中 AppResponse result = new AppResponse(); if (t != null) &#123; if (t instanceof CompletionException) &#123; result.setException(t.getCause()); &#125; else &#123; result.setException(t); &#125; &#125; else &#123; result.setValue(obj); &#125; asyncRpcResult.complete(result); // 将服务执行完之后的结果设置到异步RPC结果对象中 &#125;); return asyncRpcResult;// 返回异步RPC结果 &#125; catch (InvocationTargetException e) &#123;// 假设抛的NullPointException，那么会把这个异常包装为一个Result对象 // 同步服务执行时如何出异常了，会在此处将异常信息封装为一个AsyncRpcResult然后返回 return AsyncRpcResult.newDefaultAsyncResult(null, e.getTargetException(), invocation); &#125; catch (Throwable e) &#123;// 执行服务后的所有异常都会包装为RpcException进行抛出 throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; private CompletableFuture&lt;Object&gt; wrapWithFuture(Object value, Invocation invocation) &#123; if (RpcContext.getContext().isAsyncStarted()) &#123; return ((AsyncContextImpl) (RpcContext.getContext().getAsyncContext())).getInternalFuture(); &#125; else if (value instanceof CompletableFuture) &#123; return (CompletableFuture&lt;Object&gt;) value; &#125; return CompletableFuture.completedFuture(value); &#125; protected abstract Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable;&#125; 服务监听器服务在导出的过程中需要向动态配置中心的数据进行订阅，以便当管理人员修改了动态配置中心中对应服务的参数后，服务提供者能及时做出变化。Dubbo2.7之前仅支持对某个服务动态配置，Dubbo2.7之后不仅支持对单个服务动态配置，也支持对某个应用动态配置，是利用Zookeeper的Watcher机制。 在服务提供者端给当前服务生成一个对应监听器实例OverrideListener，它负责监听对应服务的动态配置变化，且根据动态配置中心的参数重写服务URL。 ProviderConfigurationListener：监听应用动态配置数据修改，是在RegistryProtocol类中的一个属性，且是随着RegistryProtocol实例化而实例化一个应用中只有一个 ServiceConfigurationListener：监听服务动态配置数据修改和OverrideListener类似，在每个服务进行导出时都会生成一个，实际上其内部有一个OverrideListener属性，当其监听数据发生变化时把配置中心最新数据交给OverrideListener去重写服务URL。 同时在RegistryProtocol类中保存了所有服务所对应的OverrideListener，当ProviderConfigurationListener监听到数据发生变化时，会把它所得到的最新数据依次调用每个OverrideListener去重写服务对应的服务URL。 ProviderConfigurationListener会监听/dubbo/config/dubbo/应用.configurators节点，ServiceConfigurationListener会监听/dubbo/config/dubbo/服务.configurators节点。 修改服务动态配置，底层会修改Zookeeper中的数据，ServiceConfigurationListener监听到节点内容变化触发ServiceConfigurationListener的父类AbstractConfiguratorListener的process(ConfigChangeEvent event)方法，ConfigChangeEvent表示一个事件，事件中有事件类型ADDED、MODIFIED、DELETED，还有事件内容即节点内容，以及触发该事件的节点名字，事件类型有三个，当接收到一个ConfigChangeEvent事件后，会根据事件类型做对应的处理 ADDED、MODIFIED：根据节点内容去生成override://协议的URL，然后根据URL去生成Configurator配置器，根据配置器可去重写URL DELETED：删除ServiceConfigurationListener内所有Configurator配置器 生成了Configurator后，调用notifyOverrides()方法对服务URL进行重写，每次重写并不仅仅只是用到上面所生成的Configurator，而是包括本服务的Configurator，也包括本应用的Configurator，也包括老版本管理台的Configurator，重写URL的逻辑如下： 从exporter中获取目前已经导出了的服务URL即currentUrl，根据老版本管理台的Configurator重写服务URL，根据providerConfigurationListener中的Configurator重写服务URL，根据serviceConfigurationListeners中对应的服务的Configurator重写服务URL。 若重写之后newUrl和currentUrl不相等，则需要进行服务重新导出，根据newUrl调用DubboProtocol的export进行导出，再次启动NettyServer，将newUrl进行简化为registeredProviderUrl，调用RegistryProtocol的unregister()方法，把当前服务之前的服务提供URL从注册中心删掉，调用RegistryProtocol的register()方法，把新的registeredProviderUrl注册到注册中心 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586private class OverrideListener implements NotifyListener &#123;// 当subscribeUrl对应的数据发生了改变，OverrideListener将收到通知 private final URL subscribeUrl; private final Invoker originInvoker; private List&lt;Configurator&gt; configurators; public OverrideListener(URL subscribeUrl, Invoker originalInvoker) &#123; this.subscribeUrl = subscribeUrl; this.originInvoker = originalInvoker; &#125; @Override public synchronized void notify(List&lt;URL&gt; urls) &#123; List&lt;URL&gt; matchedUrls = getMatchedUrls(urls, subscribeUrl.addParameter(CATEGORY_KEY, CONFIGURATORS_CATEGORY)); if (matchedUrls.isEmpty()) &#123; // No matching results return; &#125; // 对发生了变化的url进行过滤，只取url是override协议，或者参数category等于configurators的url this.configurators = Configurator.toConfigurators(classifyUrls(matchedUrls, UrlUtils::isConfigurator)).orElse(configurators); doOverrideIfNecessary(); // 根据Override协议修改 &#125; public synchronized void doOverrideIfNecessary() &#123; final Invoker&lt;?&gt; invoker; if (originInvoker instanceof InvokerDelegate) &#123; invoker = ((InvokerDelegate&lt;?&gt;) originInvoker).getInvoker(); &#125; else &#123; invoker = originInvoker; &#125; URL originUrl = RegistryProtocol.this.getProviderUrl(invoker); //The origin invoker 当前服务的原始服务提供者url String key = getCacheKey(originInvoker); ExporterChangeableWrapper&lt;?&gt; exporter = bounds.get(key); if (exporter == null) &#123; return; &#125; //The current, may have been merged many times，当前服务被导出的url URL currentUrl = exporter.getInvoker().getUrl(); //根据configurators修改url，configurators是全量的，并不是某个新增的或删除的，所以是基于原始的url进行修改，并不是基于currentUrl //Merged with this configuration URL newUrl = getConfigedInvokerUrl(configurators, originUrl); newUrl = getConfigedInvokerUrl(providerConfigurationListener.getConfigurators(), newUrl); newUrl = getConfigedInvokerUrl(serviceConfigurationListeners.get(originUrl.getServiceKey()).getConfigurators(), newUrl); if (!currentUrl.equals(newUrl)) &#123; // 修改过的url如果和目前的url不相同，则重新按newUrl导出 RegistryProtocol.this.reExport(originInvoker, newUrl); &#125; &#125; private List&lt;URL&gt; getMatchedUrls(List&lt;URL&gt; configuratorUrls, URL currentSubscribe) &#123; List&lt;URL&gt; result = new ArrayList&lt;URL&gt;(); for (URL url : configuratorUrls) &#123; URL overrideUrl = url; // Compatible with the old version if (url.getParameter(CATEGORY_KEY) == null &amp;&amp; OVERRIDE_PROTOCOL.equals(url.getProtocol())) &#123; overrideUrl = url.addParameter(CATEGORY_KEY, CONFIGURATORS_CATEGORY); &#125; // Check whether url is to be applied to the current service if (UrlUtils.isMatch(currentSubscribe, overrideUrl)) &#123; result.add(url); &#125; &#125; return result; &#125;&#125;private class ServiceConfigurationListener extends AbstractConfiguratorListener &#123; private URL providerUrl; private OverrideListener notifyListener; public ServiceConfigurationListener(URL providerUrl, OverrideListener notifyListener) &#123; this.providerUrl = providerUrl; this.notifyListener = notifyListener; this.initWith(DynamicConfiguration.getRuleKey(providerUrl) + CONFIGURATORS_SUFFIX); // 订阅 服务接口名+group+version+\".configurators\" &#125; private &lt;T&gt; URL overrideUrl(URL providerUrl) &#123; return RegistryProtocol.getConfigedInvokerUrl(configurators, providerUrl); &#125; @Override protected void notifyOverrides() &#123; notifyListener.doOverrideIfNecessary(); &#125;&#125;private class ProviderConfigurationListener extends AbstractConfiguratorListener &#123; public ProviderConfigurationListener() &#123;// // 订阅 应用名+\".configurators\" this.initWith(ApplicationModel.getApplication() + CONFIGURATORS_SUFFIX); &#125; private &lt;T&gt; URL overrideUrl(URL providerUrl) &#123;// 通过configurators去修改/装配providerUrl return RegistryProtocol.getConfigedInvokerUrl(configurators, providerUrl); &#125; @Override protected void notifyOverrides() &#123; overrideListeners.values().forEach(listener -&gt; ((OverrideListener) listener).doOverrideIfNecessary()); &#125;&#125;","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://yaoyinglong.github.io/tags/Dubbo/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Dubbo","slug":"Cloud/Dubbo","permalink":"https://yaoyinglong.github.io/categories/Cloud/Dubbo/"}]},{"title":"Dubbo与Spring集成原理","date":"2021-12-13T16:00:00.000Z","path":"Blog/Cloud/Dubbo/Dubbo与Spring集成原理/","text":"Dubbo与Spring的集成主要完成propertie文件解析处理、@Service注解解析、@Reference注解解析。主要是通过@EnableDubbo注解来完成的，且在该注解上指定扫描的包，完成@Service与@Reference注解的扫描并且进行处理。 12345@Configuration@EnableDubbo(scanBasePackages = \"org.apache.dubbo.demo.provider\")@PropertySource(\"classpath:/spring/dubbo-provider.properties\")static class ProviderConfiguration &#123;&#125; @EnableDubboConfig注解用来将properties文件中的配置项转化为对应的Bean，@DubboComponentScan注解用来扫描@Service与@Reference注解标注的类和属性且进行相关的处理。 12345678910111213141516@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@EnableDubboConfig@DubboComponentScanpublic @interface EnableDubbo &#123; @AliasFor(annotation = DubboComponentScan.class, attribute = \"basePackages\") String[] scanBasePackages() default &#123;&#125;; @AliasFor(annotation = DubboComponentScan.class, attribute = \"basePackageClasses\") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;; @AliasFor(annotation = EnableDubboConfig.class, attribute = \"multiple\") boolean multipleConfig() default true;&#125; 配置文件解析@EnableDubboConfig导入了DubboConfigConfigurationRegistrar配置类，该配置类通过AnnotatedBeanDefinitionRegistryUtils将DubboConfigConfiguration的Single和Multiple类注册到Spring中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@Import(DubboConfigConfigurationRegistrar.class)public @interface EnableDubboConfig &#123; boolean multiple() default true;&#125;public class DubboConfigConfigurationRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(EnableDubboConfig.class.getName())); boolean multiple = attributes.getBoolean(\"multiple\"); //true registerBeans(registry, DubboConfigConfiguration.Single.class); // Single Config Bindings if (multiple) &#123; // 默认为true registerBeans(registry, DubboConfigConfiguration.Multiple.class); &#125; &#125;&#125;public class DubboConfigConfiguration &#123; @EnableDubboConfigBindings(&#123; @EnableDubboConfigBinding(prefix = \"dubbo.application\", type = ApplicationConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.module\", type = ModuleConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.registry\", type = RegistryConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.protocol\", type = ProtocolConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.monitor\", type = MonitorConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.provider\", type = ProviderConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.consumer\", type = ConsumerConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.config-center\", type = ConfigCenterBean.class), @EnableDubboConfigBinding(prefix = \"dubbo.metadata-report\", type = MetadataReportConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.metrics\", type = MetricsConfig.class) &#125;) public static class Single &#123; &#125; @EnableDubboConfigBindings(&#123; @EnableDubboConfigBinding(prefix = \"dubbo.applications\", type = ApplicationConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.modules\", type = ModuleConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.registries\", type = RegistryConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.protocols\", type = ProtocolConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.monitors\", type = MonitorConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.providers\", type = ProviderConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.consumers\", type = ConsumerConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.config-centers\", type = ConfigCenterBean.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.metadata-reports\", type = MetadataReportConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.metricses\", type = MetricsConfig.class, multiple = true) &#125;) public static class Multiple &#123; &#125;&#125;public abstract class AnnotatedBeanDefinitionRegistryUtils &#123; public static void registerBeans(BeanDefinitionRegistry registry, Class&lt;?&gt;... annotatedClasses) &#123; if (ObjectUtils.isEmpty(annotatedClasses)) &#123; return; &#125; Iterator&lt;Class&lt;?&gt;&gt; iterator = new ArrayList&lt;&gt;(asList(annotatedClasses)).iterator(); while (iterator.hasNext()) &#123; Class&lt;?&gt; annotatedClass = iterator.next(); if (isPresentBean(registry, annotatedClass)) &#123; iterator.remove(); &#125; &#125; AnnotatedBeanDefinitionReader reader = new AnnotatedBeanDefinitionReader(registry); // 利用Spring中的AnnotatedBeanDefinitionReader来解析annotatedClasses会解析该类上的注解，然后进行处理 reader.register(annotatedClasses); &#125;&#125; @EnableDubboConfigBindings注解中导入了DubboConfigBindingsRegistrar配置类，该配置类中会获取并遍历注解中配置的@EnableDubboConfigBinding列表，调用DubboConfigBindingRegistrar的registerBeanDefinitions方法将生成对应的配置类注册到Spring容器中，且给每一个配置类注册一个DubboConfigBindingBeanPostProcessor后置处理器，且注册了一个NamePropertyDefaultValueDubboConfigBeanCustomizer的Bean，用来把XxConfig配置类所对应的beanName设置到name属性中去。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(DubboConfigBindingsRegistrar.class)public @interface EnableDubboConfigBindings &#123; EnableDubboConfigBinding[] value();&#125;@Target(&#123;ElementType.TYPE, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(EnableDubboConfigBindings.class)@Import(DubboConfigBindingRegistrar.class)public @interface EnableDubboConfigBinding &#123; String prefix(); Class&lt;? extends AbstractConfig&gt; type(); boolean multiple() default false;&#125;public class DubboConfigBindingsRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(EnableDubboConfigBindings.class.getName())); AnnotationAttributes[] annotationAttributes = attributes.getAnnotationArray(\"value\"); // 拿到多个@EnableDubboConfigBinding注解 DubboConfigBindingRegistrar registrar = new DubboConfigBindingRegistrar(); registrar.setEnvironment(environment); for (AnnotationAttributes element : annotationAttributes) &#123; registrar.registerBeanDefinitions(element, registry); // 逐个解析@EnableDubboConfigBinding注解 &#125; &#125;&#125;public class DubboConfigBindingRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(EnableDubboConfigBinding.class.getName())); registerBeanDefinitions(attributes, registry); &#125; protected void registerBeanDefinitions(AnnotationAttributes attributes, BeanDefinitionRegistry registry) &#123; String prefix = environment.resolvePlaceholders(attributes.getString(\"prefix\")); // prefix = \"dubbo.application\" Class&lt;? extends AbstractConfig&gt; configClass = attributes.getClass(\"type\"); // type = ApplicationConfig.class boolean multiple = attributes.getBoolean(\"multiple\"); registerDubboConfigBeans(prefix, configClass, multiple, registry); &#125; private void registerDubboConfigBeans(String prefix, Class&lt;? extends AbstractConfig&gt; configClass, boolean multiple, BeanDefinitionRegistry registry) &#123; // 从properties文件中根据前缀拿对应的配置项，比如根据dubbo.application前缀 Map&lt;String, Object&gt; properties = getSubProperties(environment.getPropertySources(), prefix); if (CollectionUtils.isEmpty(properties)) &#123; return; // 如果没有相关的配置项，则不需要注册BeanDefinition &#125; Set&lt;String&gt; beanNames = multiple ? resolveMultipleBeanNames(properties) : Collections.singleton(resolveSingleBeanName(properties, configClass, registry)); for (String beanName : beanNames) &#123; registerDubboConfigBean(beanName, configClass, registry); // 为每个beanName,注册一个空的BeanDefinition // 为每个bean注册一个DubboConfigBindingBeanPostProcessor的Bean后置处理器 registerDubboConfigBindingBeanPostProcessor(prefix, beanName, multiple, registry); &#125; // 注册一个NamePropertyDefaultValueDubboConfigBeanCustomizer的bean，用来把某个XxConfig所对应的beanName设置到name属性中去 registerDubboConfigBeanCustomizers(registry); &#125; private Set&lt;String&gt; resolveMultipleBeanNames(Map&lt;String, Object&gt; properties) &#123; Set&lt;String&gt; beanNames = new LinkedHashSet&lt;String&gt;(); // 比如dubbo.protocols.p1.name=dubbo的propertyName为p1.name for (String propertyName : properties.keySet()) &#123; int index = propertyName.indexOf(\".\"); // propertyName为p1.name if (index &gt; 0) &#123; String beanName = propertyName.substring(0, index); // 截取beanName名字为p1 beanNames.add(beanName); &#125; &#125; return beanNames; &#125; private void registerDubboConfigBean(String beanName, Class&lt;? extends AbstractConfig&gt; configClass, BeanDefinitionRegistry registry) &#123; BeanDefinitionBuilder builder = rootBeanDefinition(configClass); AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); registry.registerBeanDefinition(beanName, beanDefinition); // ApplicatinoConfig对象 &#125; private void registerDubboConfigBindingBeanPostProcessor(String prefix, String beanName, boolean multiple, BeanDefinitionRegistry registry) &#123; // 为每个XxConfig的Bean对应一个DubboConfigBindingBeanPostProcessor的Bean Class&lt;?&gt; processorClass = DubboConfigBindingBeanPostProcessor.class; BeanDefinitionBuilder builder = rootBeanDefinition(processorClass); // 真实的前缀，比如dubbo.registries.r2 String actualPrefix = multiple ? normalizePrefix(prefix) + beanName : prefix; // 添加两个构造方法参数值，所以会调用DubboConfigBindingBeanPostProcessor的两个参数的构造方法 builder.addConstructorArgValue(actualPrefix).addConstructorArgValue(beanName); AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registerWithGeneratedName(beanDefinition, registry); &#125; private void registerDubboConfigBeanCustomizers(BeanDefinitionRegistry registry) &#123; registerInfrastructureBean(registry, BEAN_NAME, NamePropertyDefaultValueDubboConfigBeanCustomizer.class); &#125;&#125; DubboConfigBindingBeanPostProcessor是一个BeanPostProcessor，且实现了InitializingBean接口，在其afterPropertiesSet方法中会对DubboConfigBinder属性初始化，且获取到上面注册的NamePropertyDefaultValueDubboConfigBeanCustomizer对象。在postProcessBeforeInitialization方法中从properties文件中获取值，并设置到对应的Config文件对象中，然后调用NamePropertyDefaultValueDubboConfigBeanCustomizer的customize方法将beanName设置到name属性中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class DubboConfigBindingBeanPostProcessor implements BeanPostProcessor, ApplicationContextAware, InitializingBean, BeanDefinitionRegistryPostProcessor &#123; public void afterPropertiesSet() throws Exception &#123; initDubboConfigBinder(); // 创建DefaultDubboConfigBinder initConfigBeanCustomizers(); &#125; private void initDubboConfigBinder() &#123; if (dubboConfigBinder == null) &#123; try &#123;// 先从Spring容器中获取DubboConfigBinder，默认获取不到 dubboConfigBinder = applicationContext.getBean(DubboConfigBinder.class); &#125; catch (BeansException ignored) &#123; // Use Default implementation 生成一个默认的 dubboConfigBinder = createDubboConfigBinder(applicationContext.getEnvironment()); &#125; &#125; dubboConfigBinder.setIgnoreUnknownFields(ignoreUnknownFields); dubboConfigBinder.setIgnoreInvalidFields(ignoreInvalidFields); &#125; private void initConfigBeanCustomizers() &#123; // 得到之前创建了的NamePropertyDefaultValueDubboConfigBeanCustomizer Collection&lt;DubboConfigBeanCustomizer&gt; configBeanCustomizers = beansOfTypeIncludingAncestors(applicationContext, DubboConfigBeanCustomizer.class).values(); this.configBeanCustomizers = new ArrayList&lt;&gt;(configBeanCustomizers); AnnotationAwareOrderComparator.sort(this.configBeanCustomizers); &#125; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // 每个XxConfig对应一个BeanPostProcessor，所以每个DubboConfigBindingBeanPostProcessor只处理对应的beanName if (this.beanName.equals(beanName) &amp;&amp; bean instanceof AbstractConfig) &#123; AbstractConfig dubboConfig = (AbstractConfig) bean; bind(prefix, dubboConfig); // 从properties文件中获取值，并设置到dubboConfig对象中 customize(beanName, dubboConfig); // 设置dubboConfig对象的name属性，设置为beanName &#125; return bean; &#125; private void bind(String prefix, AbstractConfig dubboConfig) &#123; dubboConfigBinder.bind(prefix, dubboConfig); &#125; private void customize(String beanName, AbstractConfig dubboConfig) &#123; for (DubboConfigBeanCustomizer customizer : configBeanCustomizers) &#123; customizer.customize(beanName, dubboConfig); &#125; &#125;&#125;public class NamePropertyDefaultValueDubboConfigBeanCustomizer implements DubboConfigBeanCustomizer &#123; public void customize(String beanName, AbstractConfig dubboConfigBean) &#123; // 查看XxConfig中是否存在name属性 PropertyDescriptor propertyDescriptor = getPropertyDescriptor(dubboConfigBean.getClass(), PROPERTY_NAME); if (propertyDescriptor != null) &#123; // \"name\" property is present Method getNameMethod = propertyDescriptor.getReadMethod(); // 看是否存在getName方法 if (getNameMethod == null) &#123; // if \"getName\" method is absent return; &#125; Object propertyValue = ReflectionUtils.invokeMethod(getNameMethod, dubboConfigBean); // 执行getName得到值 if (propertyValue != null) &#123; // If The return value of \"getName\" method is not null return; &#125; Method setNameMethod = propertyDescriptor.getWriteMethod(); // 获取setName方法 if (setNameMethod != null) &#123; // \"setName\" and \"getName\" methods are present if (Arrays.equals(of(String.class), setNameMethod.getParameterTypes())) &#123; // the param type is String ReflectionUtils.invokeMethod(setNameMethod, dubboConfigBean, beanName); // 这是name属性为beanName &#125; &#125; &#125; &#125;&#125; Bean扫描在@DubboComponentScan注解中导入了DubboComponentScanRegistrar配置类，该类registerBeanDefinitions方法获取@DubboComponentScan注解中配置包路径，创建扫描@Service注解的后置处理器ServiceAnnotationBeanPostProcessor以及扫描@Reference注解的后置处理器ReferenceAnnotationBeanPostProcessor且设置获取到的扫描包路径。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(DubboComponentScanRegistrar.class)public @interface DubboComponentScan &#123; String[] value() default &#123;&#125;; String[] basePackages() default &#123;&#125;; Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;&#125;public class DubboComponentScanRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 拿到DubboComponentScan注解所定义的包路径，扫描该package下的类 Set&lt;String&gt; packagesToScan = getPackagesToScan(importingClassMetadata); // 注册ServiceAnnotationBeanPostProcessor后置处理器，扫描@Service注解的类生成BeanDefinition，会生成两个一个普通的bean一个ServiceBean // 在ServiceBean中会监听ContextRefreshedEvent事件，一旦Spring启动完后，就会进行服务导出 registerServiceAnnotationBeanPostProcessor(packagesToScan, registry); // 注册ReferenceAnnotationBeanPostProcessor，在对属性进行注入时会调用postProcessPropertyValues方法，按照@Reference注解的信息去生成一个RefrenceBean对象 registerReferenceAnnotationBeanPostProcessor(registry); &#125; private Set&lt;String&gt; getPackagesToScan(AnnotationMetadata metadata) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(DubboComponentScan.class.getName())); String[] basePackages = attributes.getStringArray(\"basePackages\"); Class&lt;?&gt;[] basePackageClasses = attributes.getClassArray(\"basePackageClasses\"); String[] value = attributes.getStringArray(\"value\"); Set&lt;String&gt; packagesToScan = new LinkedHashSet&lt;String&gt;(Arrays.asList(value)); // Appends value array attributes packagesToScan.addAll(Arrays.asList(basePackages)); for (Class&lt;?&gt; basePackageClass : basePackageClasses) &#123; packagesToScan.add(ClassUtils.getPackageName(basePackageClass)); &#125; if (packagesToScan.isEmpty()) &#123; return Collections.singleton(ClassUtils.getPackageName(metadata.getClassName())); &#125; return packagesToScan; &#125; private void registerServiceAnnotationBeanPostProcessor(Set&lt;String&gt; packagesToScan, BeanDefinitionRegistry registry) &#123; // 生成一个RootBeanDefinition，对应的beanClass为ServiceAnnotationBeanPostProcessor.class BeanDefinitionBuilder builder = rootBeanDefinition(ServiceAnnotationBeanPostProcessor.class); // 将包路径作为在构造ServiceAnnotationBeanPostProcessor时调用构造方法时的传入参数 builder.addConstructorArgValue(packagesToScan); builder.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); BeanDefinitionReaderUtils.registerWithGeneratedName(beanDefinition, registry); &#125; private void registerReferenceAnnotationBeanPostProcessor(BeanDefinitionRegistry registry) &#123; // 注册一个ReferenceAnnotationBeanPostProcessor做为bean，ReferenceAnnotationBeanPostProcessor是一个BeanPostProcessor BeanRegistrar.registerInfrastructureBean(registry, ReferenceAnnotationBeanPostProcessor.BEAN_NAME, ReferenceAnnotationBeanPostProcessor.class); &#125;&#125; ServiceAnnotationBeanPostProcessor后置处理器主要作用是通过DubboClassPathBeanDefinitionScanner扫描被Dubbo的@Service注解标注的类，首先将这些被@Service注解标注的类注册到Spring容器中，然后解析@Service注解上服务参数信息，针对原始Bean额外生成一个类型为ServiceBean名称为ServiceBean:实际类全限定名:version:group的Bean对象，且在构建ServiceBean时将Spring中对应的Bean赋值给ServiceBean的ref属性，以及实际的接口等信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class ServiceAnnotationBeanPostProcessor implements BeanDefinitionRegistryPostProcessor, EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware &#123; public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; Set&lt;String&gt; resolvedPackagesToScan = resolvePackagesToScan(packagesToScan); if (!CollectionUtils.isEmpty(resolvedPackagesToScan)) &#123; registerServiceBeans(resolvedPackagesToScan, registry); // 扫描包，进行Bean注册 &#125; &#125; private void registerServiceBeans(Set&lt;String&gt; packagesToScan, BeanDefinitionRegistry registry) &#123; DubboClassPathBeanDefinitionScanner scanner = new DubboClassPathBeanDefinitionScanner(registry, environment, resourceLoader); BeanNameGenerator beanNameGenerator = resolveBeanNameGenerator(registry); scanner.setBeanNameGenerator(beanNameGenerator); scanner.addIncludeFilter(new AnnotationTypeFilter(Service.class)); // 扫描被Service注解标注的类 scanner.addIncludeFilter(new AnnotationTypeFilter(com.alibaba.dubbo.config.annotation.Service.class)); for (String packageToScan : packagesToScan) &#123; scanner.scan(packageToScan); // 扫描Dubbo自定义的@Service注解 // 查找被@Service注解的类的BeanDefinition，无论该类是否被@ComponentScan注解标注 Set&lt;BeanDefinitionHolder&gt; beanDefinitionHolders = findServiceBeanDefinitionHolders(scanner, packageToScan, registry, beanNameGenerator); if (!CollectionUtils.isEmpty(beanDefinitionHolders)) &#123; for (BeanDefinitionHolder beanDefinitionHolder : beanDefinitionHolders) &#123; registerServiceBean(beanDefinitionHolder, registry, scanner); // 扫描到BeanDefinition开始处理它 &#125; &#125; &#125; &#125; private void registerServiceBean(BeanDefinitionHolder beanDefinitionHolder, BeanDefinitionRegistry registry, DubboClassPathBeanDefinitionScanner scanner) &#123; Class&lt;?&gt; beanClass = resolveClass(beanDefinitionHolder); // 服务实现类 Annotation service = findServiceAnnotation(beanClass); // @Service注解 /** * The &#123;@link AnnotationAttributes&#125; of @Service annotation */ AnnotationAttributes serviceAnnotationAttributes = getAnnotationAttributes(service, false, false); // @Service注解上的信息 Class&lt;?&gt; interfaceClass = resolveServiceInterfaceClass(serviceAnnotationAttributes, beanClass); // 服务实现类对应的接口 // 服务实现类对应的bean的名字，比如：demoServiceImpl String annotatedServiceBeanName = beanDefinitionHolder.getBeanName(); // 生成一个ServiceBean AbstractBeanDefinition serviceBeanDefinition = buildServiceBeanDefinition(service, serviceAnnotationAttributes, interfaceClass, annotatedServiceBeanName); String beanName = generateServiceBeanName(serviceAnnotationAttributes, interfaceClass); // ServiceBean Bean name if (scanner.checkCandidate(beanName, serviceBeanDefinition)) &#123; // check duplicated candidate bean // 把ServiceBean注册进去，对应的beanName为ServiceBean:org.apache.dubbo.demo.DemoService registry.registerBeanDefinition(beanName, serviceBeanDefinition); &#125; &#125; private AbstractBeanDefinition buildServiceBeanDefinition(Annotation serviceAnnotation, AnnotationAttributes serviceAnnotationAttributes, Class&lt;?&gt; interfaceClass, String annotatedServiceBeanName) &#123; BeanDefinitionBuilder builder = rootBeanDefinition(ServiceBean.class); // 生成一个ServiceBean对应的BeanDefinition AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); MutablePropertyValues propertyValues = beanDefinition.getPropertyValues(); String[] ignoreAttributeNames = of(\"provider\", \"monitor\", \"application\", \"module\", \"registry\", \"protocol\", \"interface\", \"interfaceName\", \"parameters\"); // 把serviceAnnotation中的参数值赋值给ServiceBean的属性 propertyValues.addPropertyValues(new AnnotationPropertyValuesAdapter(serviceAnnotation, environment, ignoreAttributeNames)); // ref属性赋值为另外一个bean, 对应的就是被@Service注解的服务实现类对应的bean addPropertyReference(builder, \"ref\", annotatedServiceBeanName); builder.addPropertyValue(\"interface\", interfaceClass.getName()); builder.addPropertyValue(\"parameters\", convertParameters(serviceAnnotationAttributes.getStringArray(\"parameters\"))); // 配置了methods属性，则给ServiceBean对应的methods属性赋值 List&lt;MethodConfig&gt; methodConfigs = convertMethodConfigs(serviceAnnotationAttributes.get(\"methods\")); if (!methodConfigs.isEmpty()) &#123; builder.addPropertyValue(\"methods\", methodConfigs); &#125; String providerConfigBeanName = serviceAnnotationAttributes.getString(\"provider\"); if (StringUtils.hasText(providerConfigBeanName)) &#123; addPropertyReference(builder, \"provider\", providerConfigBeanName); &#125; String monitorConfigBeanName = serviceAnnotationAttributes.getString(\"monitor\"); if (StringUtils.hasText(monitorConfigBeanName)) &#123; addPropertyReference(builder, \"monitor\", monitorConfigBeanName); &#125; String applicationConfigBeanName = serviceAnnotationAttributes.getString(\"application\"); if (StringUtils.hasText(applicationConfigBeanName)) &#123; addPropertyReference(builder, \"application\", applicationConfigBeanName); &#125; String moduleConfigBeanName = serviceAnnotationAttributes.getString(\"module\"); if (StringUtils.hasText(moduleConfigBeanName)) &#123; addPropertyReference(builder, \"module\", moduleConfigBeanName); &#125; // 获取注解上配置的注册中心的beanName String[] registryConfigBeanNames = serviceAnnotationAttributes.getStringArray(\"registry\"); List&lt;RuntimeBeanReference&gt; registryRuntimeBeanReferences = toRuntimeBeanReferences(registryConfigBeanNames); if (!registryRuntimeBeanReferences.isEmpty()) &#123; builder.addPropertyValue(\"registries\", registryRuntimeBeanReferences); &#125; String[] protocolConfigBeanNames = serviceAnnotationAttributes.getStringArray(\"protocol\"); List&lt;RuntimeBeanReference&gt; protocolRuntimeBeanReferences = toRuntimeBeanReferences(protocolConfigBeanNames); if (!protocolRuntimeBeanReferences.isEmpty()) &#123; builder.addPropertyValue(\"protocols\", protocolRuntimeBeanReferences); &#125; return builder.getBeanDefinition(); &#125; private ManagedList&lt;RuntimeBeanReference&gt; toRuntimeBeanReferences(String... beanNames) &#123; ManagedList&lt;RuntimeBeanReference&gt; runtimeBeanReferences = new ManagedList&lt;&gt;(); if (!ObjectUtils.isEmpty(beanNames)) &#123; for (String beanName : beanNames) &#123; String resolvedBeanName = environment.resolvePlaceholders(beanName); runtimeBeanReferences.add(new RuntimeBeanReference(resolvedBeanName)); &#125; &#125; return runtimeBeanReferences; &#125; private String generateServiceBeanName(AnnotationAttributes serviceAnnotationAttributes, Class&lt;?&gt; interfaceClass) &#123; ServiceBeanNameBuilder builder = create(interfaceClass, environment) .group(serviceAnnotationAttributes.getString(\"group\")) .version(serviceAnnotationAttributes.getString(\"version\")); return builder.build(); &#125; private Annotation findServiceAnnotation(Class&lt;?&gt; beanClass) &#123; Annotation service = findMergedAnnotation(beanClass, Service.class); if (service == null) &#123; service = findMergedAnnotation(beanClass, com.alibaba.dubbo.config.annotation.Service.class); &#125; return service; &#125;&#125; 通过ReferenceAnnotationBeanPostProcessor后置处理器处理@Reference注解，在该后置处理器的构造方法中调用了超类AnnotationInjectedBeanPostProcessor的构造方法传入了需要处理的注解类型。而AnnotationInjectedBeanPostProcessor又是InstantiationAwareBeanPostProcessorAdapter的子类，在属性赋值阶段会调用其postProcessPropertyValues方法，在该方法中通过调用findInjectionMetadata先从缓存中获取，获取不到再通过buildAnnotatedMetadata方法中调用findFieldAnnotationMetadata和findAnnotatedMethodMetadata方法遍历筛选出该BeanClass中的所有被@Reference注解标注的属性和方法，将其分别封装到AnnotatedFieldElement和AnnotatedMethodElement中。 再将所有的信息封装到InjectionMetadata的子类AnnotatedInjectionMetadata中，然后调用InjectionMetadata的inject方法完成属性的注入，该方法中会遍历调用AnnotatedFieldElement和AnnotatedMethodElement中的inject方法，然后调用getInjectedObject方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132public class ReferenceAnnotationBeanPostProcessor extends AnnotationInjectedBeanPostProcessor implements ApplicationContextAware, ApplicationListener &#123; public ReferenceAnnotationBeanPostProcessor() &#123; super(Reference.class, com.alibaba.dubbo.config.annotation.Reference.class); &#125;&#125;public abstract class AnnotationInjectedBeanPostProcessor extends InstantiationAwareBeanPostProcessorAdapter implements MergedBeanDefinitionPostProcessor, PriorityOrdered, BeanFactoryAware, BeanClassLoaderAware, EnvironmentAware, DisposableBean &#123; public AnnotationInjectedBeanPostProcessor(Class&lt;? extends Annotation&gt;... annotationTypes) &#123; this.annotationTypes = annotationTypes; &#125; public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeanCreationException &#123; InjectionMetadata metadata = findInjectionMetadata(beanName, bean.getClass(), pvs); // 寻找需要注入的属性即被@Reference标注的Field try &#123; metadata.inject(bean, beanName, pvs); &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"Injection of @\" + getAnnotationType().getSimpleName() + \" dependencies is failed\", ex); &#125; return pvs; &#125; private InjectionMetadata findInjectionMetadata(String beanName, Class&lt;?&gt; clazz, PropertyValues pvs) &#123; String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName()); AnnotationInjectedBeanPostProcessor.AnnotatedInjectionMetadata metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; synchronized (this.injectionMetadataCache) &#123; metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; if (metadata != null) &#123; metadata.clear(pvs); &#125; try &#123; metadata = buildAnnotatedMetadata(clazz); this.injectionMetadataCache.put(cacheKey, metadata); &#125; catch (NoClassDefFoundError err) &#123; throw new IllegalStateException(\"Failed to introspect object class [\" + clazz.getName() + \"] for annotation metadata: could not find class that it depends on\", err); &#125; &#125; &#125; &#125; return metadata; &#125; private AnnotationInjectedBeanPostProcessor.AnnotatedInjectionMetadata buildAnnotatedMetadata(final Class&lt;?&gt; beanClass) &#123; // 获取beanClass中Filed上有@Reference注解Field列表 Collection&lt;AnnotationInjectedBeanPostProcessor.AnnotatedFieldElement&gt; fieldElements = findFieldAnnotationMetadata(beanClass); // 获取beanClass中方法上有@Reference注解方法列表 Collection&lt;AnnotationInjectedBeanPostProcessor.AnnotatedMethodElement&gt; methodElements = findAnnotatedMethodMetadata(beanClass); // 返回的是Dubbo定义的AnnotatedInjectionMetadata，接下来就会使用这个类去进行属性注入 return new AnnotationInjectedBeanPostProcessor.AnnotatedInjectionMetadata(beanClass, fieldElements, methodElements); &#125; private List&lt;AnnotationInjectedBeanPostProcessor.AnnotatedFieldElement&gt; findFieldAnnotationMetadata(final Class&lt;?&gt; beanClass) &#123; final List&lt;AnnotationInjectedBeanPostProcessor.AnnotatedFieldElement&gt; elements = new LinkedList&lt;AnnotationInjectedBeanPostProcessor.AnnotatedFieldElement&gt;(); ReflectionUtils.doWithFields(beanClass, field -&gt; &#123; // 遍历beanClass的所有属性 for (Class&lt;? extends Annotation&gt; annotationType : getAnnotationTypes()) &#123; // 遍历注解列表：Reference.class, com.alibaba.dubbo.config.annotation.Reference.class AnnotationAttributes attributes = getMergedAttributes(field, annotationType, getEnvironment(), true); if (attributes != null) &#123; // 若该属性上目标注解属性存在 if (Modifier.isStatic(field.getModifiers())) &#123; return; // 若为static方法直接跳过 &#125; elements.add(new AnnotatedFieldElement(field, attributes)); &#125; &#125; &#125;); return elements; &#125; private List&lt;AnnotationInjectedBeanPostProcessor.AnnotatedMethodElement&gt; findAnnotatedMethodMetadata(final Class&lt;?&gt; beanClass) &#123; final List&lt;AnnotationInjectedBeanPostProcessor.AnnotatedMethodElement&gt; elements = new LinkedList&lt;AnnotationInjectedBeanPostProcessor.AnnotatedMethodElement&gt;(); ReflectionUtils.doWithMethods(beanClass, method -&gt; &#123; Method bridgedMethod = findBridgedMethod(method); if (!isVisibilityBridgeMethodPair(method, bridgedMethod)) &#123; return; &#125; for (Class&lt;? extends Annotation&gt; annotationType : getAnnotationTypes()) &#123; AnnotationAttributes attributes = getMergedAttributes(bridgedMethod, annotationType, getEnvironment(), true); if (attributes != null &amp;&amp; method.equals(ClassUtils.getMostSpecificMethod(method, beanClass))) &#123; if (Modifier.isStatic(method.getModifiers())) &#123; return; &#125; // 找到set方法所对应的属性 PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, beanClass); elements.add(new AnnotatedMethodElement(method, pd, attributes)); &#125; &#125; &#125;); return elements; &#125; protected Object getInjectedObject(AnnotationAttributes attributes, Object bean, String beanName, Class&lt;?&gt; injectedType, InjectionMetadata.InjectedElement injectedElement) throws Exception &#123; // 哪个Service应用了哪个类型的服务，通过什么方式引入的 String cacheKey = buildInjectedObjectCacheKey(attributes, bean, beanName, injectedType, injectedElement); // cacheKey很鸡肋，属性名不一样的时候，cacheKey不一样，导致不能缓存， 在一个Service中@Reference两次同一个服务缓存不到 Object injectedObject = injectedObjectsCache.get(cacheKey); if (injectedObject == null) &#123; injectedObject = doGetInjectedBean(attributes, bean, beanName, injectedType, injectedElement); // 生成Bean injectedObjectsCache.putIfAbsent(cacheKey, injectedObject); &#125; return injectedObject; &#125;&#125;private class AnnotatedMethodElement extends InjectionMetadata.InjectedElement &#123; private final Method method; private final AnnotationAttributes attributes; private volatile Object object; protected AnnotatedMethodElement(Method method, PropertyDescriptor pd, AnnotationAttributes attributes) &#123; super(method, pd); this.method = method; this.attributes = attributes; &#125; @Override protected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable &#123; // set方法对应的属性的类型 Class&lt;?&gt; injectedType = pd.getPropertyType(); // 从Spring容器中获取一个Bean（注意，这个方法内部会生成Bean而且会缓存，就像Spring中的getBean一样） Object injectedObject = getInjectedObject(attributes, bean, beanName, injectedType, this); ReflectionUtils.makeAccessible(method); method.invoke(bean, injectedObject); // 调用set方法 &#125;&#125;public class AnnotatedFieldElement extends InjectionMetadata.InjectedElement &#123; private final Field field; private final AnnotationAttributes attributes; private volatile Object bean; protected AnnotatedFieldElement(Field field, AnnotationAttributes attributes) &#123; super(field, null); this.field = field; this.attributes = attributes; &#125; @Override protected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable &#123;// 给bean对象进行属性赋值 Class&lt;?&gt; injectedType = field.getType(); Object injectedObject = getInjectedObject(attributes, bean, beanName, injectedType, this); // 获取对象，然后进行注入 ReflectionUtils.makeAccessible(field); field.set(bean, injectedObject); // 字段赋值，injectedObject就是值 &#125;&#125; 最终调用ReferenceAnnotationBeanPostProcessor的doGetInjectedBean方法，首先构建一个ReferenceBean对象并对其属性赋值等操作，然后将其注册到Spring容器中，若容器中已存在则注册一个别名，最后通过getOrCreateProxy方法判断当前调用的Dubbo服务是本地服务还是远程服务，若是本地服务则通过newProxyInstance创建代理对象，若是远程服务则调用ReferenceBean的get方法创建代理对象。 ReferenceBean对象的构建及其属性赋值是通过AnnotatedInterfaceConfigBeanBuilder的build方法来完成的，将各种配置项包括@Reference注解中的配置项赋值给ReferenceBean对应属性，然后调用ReferenceBean的afterPropertiesSet方法完成属性进一步赋值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143public class ReferenceAnnotationBeanPostProcessor extends AnnotationInjectedBeanPostProcessor implements ApplicationContextAware, ApplicationListener &#123; protected String buildInjectedObjectCacheKey(AnnotationAttributes attributes, Object bean, String beanName, Class&lt;?&gt; injectedType, InjectionMetadata.InjectedElement injectedElement) &#123; return buildReferencedBeanName(attributes, injectedType) + \"#source=\" + (injectedElement.getMember()) + \"#attributes=\" + AnnotationUtils.resolvePlaceholders(attributes, getEnvironment()); &#125; protected Object doGetInjectedBean(AnnotationAttributes attributes, Object bean, String beanName, Class&lt;?&gt; injectedType, InjectionMetadata.InjectedElement injectedElement) throws Exception &#123; // 按ServiceBean的beanName生成规则来生成referencedBeanName，规则为ServiceBean:interfaceClassName:version:group String referencedBeanName = buildReferencedBeanName(attributes, injectedType); // @Reference(methods=[Lorg.apache.dubbo.config.annotation.Method;@39b43d60) org.apache.dubbo.demo.DemoService String referenceBeanName = getReferenceBeanName(attributes, injectedType); // 根据@Reference注解的信息生成referenceBeanName ReferenceBean referenceBean = buildReferenceBeanIfAbsent(referenceBeanName, attributes, injectedType); // 生成一个ReferenceBean对象 registerReferenceBean(referencedBeanName, referenceBean, attributes, injectedType); // 把referenceBean添加到Spring容器中去 cacheInjectedReferenceBean(referenceBean, injectedElement); // 创建一个代理对象，Service中的属性被注入的就是这个代理对象，内部会调用referenceBean.get(); return getOrCreateProxy(referencedBeanName, referenceBeanName, referenceBean, injectedType); &#125; private ReferenceBean buildReferenceBeanIfAbsent(String referenceBeanName, AnnotationAttributes attributes, Class&lt;?&gt; referencedType) throws Exception &#123; ReferenceBean&lt;?&gt; referenceBean = referenceBeanCache.get(referenceBeanName); if (referenceBean == null) &#123;// 生成了一个ReferenceBean对象，attributes是@Reference注解的参数值 ReferenceBeanBuilder beanBuilder = ReferenceBeanBuilder.create(attributes, applicationContext).interfaceClass(referencedType); referenceBean = beanBuilder.build(); // 构建ReferenceBean对象并对属性赋值 referenceBeanCache.put(referenceBeanName, referenceBean); &#125; else if (!referencedType.isAssignableFrom(referenceBean.getInterfaceClass())) &#123; throw new IllegalArgumentException(\"reference bean name \" + referenceBeanName + \" has been duplicated, but interfaceClass \" + referenceBean.getInterfaceClass().getName() + \" cannot be assigned to \" + referencedType.getName()); &#125; return referenceBean; &#125; private void registerReferenceBean(String referencedBeanName, ReferenceBean referenceBean, AnnotationAttributes attributes, Class&lt;?&gt; interfaceClass) &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); String beanName = getReferenceBeanName(attributes, interfaceClass); // 就是referenceBeanName // 当前Spring容器中是否存在referencedBeanName if (existsServiceBean(referencedBeanName)) &#123; // If @Service bean is local one AbstractBeanDefinition beanDefinition = (AbstractBeanDefinition) beanFactory.getBeanDefinition(referencedBeanName); RuntimeBeanReference runtimeBeanReference = (RuntimeBeanReference) beanDefinition.getPropertyValues().get(\"ref\"); // ServiceBean --- ref String serviceBeanName = runtimeBeanReference.getBeanName(); // DemoServiceImpl对应的beanName beanFactory.registerAlias(serviceBeanName, beanName); // DemoServiceImpl多了一个别名，比如 demoServiceImpl和 &#125; else &#123; // Remote @Service Bean if (!beanFactory.containsBean(beanName)) &#123; beanFactory.registerSingleton(beanName, referenceBean); &#125; &#125; &#125; private Object getOrCreateProxy(String referencedBeanName, String referenceBeanName, ReferenceBean referenceBean, Class&lt;?&gt; serviceInterfaceType) &#123; if (existsServiceBean(referencedBeanName)) &#123; // If the local @Service Bean exists, build a proxy of ReferenceBean return newProxyInstance(getClassLoader(), new Class[]&#123;serviceInterfaceType&#125;, wrapInvocationHandler(referenceBeanName, referenceBean)); &#125; else &#123; // ReferenceBean should be initialized and get immediately return referenceBean.get(); // 重点 &#125; &#125;&#125;public abstract class AnnotatedInterfaceConfigBeanBuilder&lt;C extends AbstractInterfaceConfig&gt; &#123; public final C build() throws Exception &#123; checkDependencies(); C configBean = doBuild(); // 创建一个ReferenceBean对象 configureBean(configBean); // 给ReferenceBean对象的属性赋值 return configBean; &#125; protected void configureBean(C configBean) throws Exception &#123; preConfigureBean(attributes, configBean); // 把@Reference注解中的配置项赋值给configBean configureRegistryConfigs(configBean); // 把注册中心配置项赋值给configBean configureMonitorConfig(configBean);// 把监控中心配置项赋值给configBean configureApplicationConfig(configBean);// 把应用配置项赋值给configBean configureModuleConfig(configBean); // 设置applicationContext、interfaceName、consumer、methods属性，并调用ReferenceBean对象的afterPropertiesSet方法 postConfigureBean(attributes, configBean); &#125; private void configureRegistryConfigs(C configBean) &#123; String[] registryConfigBeanIds = resolveRegistryConfigBeanNames(attributes); // 解析@Refrence注解中配置的registry属性 // 获得注册中心对应的RegistryConfig对象 List&lt;RegistryConfig&gt; registryConfigs = getBeans(applicationContext, registryConfigBeanIds, RegistryConfig.class); configBean.setRegistries(registryConfigs); // 设置registryConfigs属性值 &#125; private void configureMonitorConfig(C configBean) &#123; String monitorBeanName = resolveMonitorConfigBeanName(attributes); // 从Spring容器获取MonitorConfig的bean对象 MonitorConfig monitorConfig = getOptionalBean(applicationContext, monitorBeanName, MonitorConfig.class); configBean.setMonitor(monitorConfig); &#125; private void configureApplicationConfig(C configBean) &#123; String applicationConfigBeanName = resolveApplicationConfigBeanName(attributes); ApplicationConfig applicationConfig = getOptionalBean(applicationContext, applicationConfigBeanName, ApplicationConfig.class); configBean.setApplication(applicationConfig); &#125; private void configureModuleConfig(C configBean) &#123; String moduleConfigBeanName = resolveModuleConfigBeanName(attributes); ModuleConfig moduleConfig = getOptionalBean(applicationContext, moduleConfigBeanName, ModuleConfig.class); configBean.setModule(moduleConfig); &#125;&#125;class ReferenceBeanBuilder extends AnnotatedInterfaceConfigBeanBuilder&lt;ReferenceBean&gt; &#123; protected ReferenceBean doBuild() &#123; return new ReferenceBean&lt;Object&gt;(); &#125; protected void preConfigureBean(AnnotationAttributes attributes, ReferenceBean referenceBean) &#123; Assert.notNull(interfaceClass, \"The interface class must set first!\"); DataBinder dataBinder = new DataBinder(referenceBean); dataBinder.registerCustomEditor(String.class, \"filter\", new StringTrimmerEditor(true)); dataBinder.registerCustomEditor(String.class, \"listener\", new StringTrimmerEditor(true)); // 最终都会转变为Map设置到referenceBean中的parameters，@Reference(parameters = &#123;\"text=123\"&#125;)或@Reference(parameters = &#123;\"text:123\"&#125;)两种配置方式 dataBinder.registerCustomEditor(Map.class, \"parameters\", new PropertyEditorSupport() &#123; @Override public void setAsText(String text) throws java.lang.IllegalArgumentException &#123; String content = StringUtils.trimAllWhitespace(text); // Trim all whitespace if (!StringUtils.hasText(content)) &#123; // No content , ignore directly return; &#125; content = StringUtils.replace(content, \"=\", \",\");// replace \"=\" to \",\" content = StringUtils.replace(content, \":\", \",\"); // replace \":\" to \",\" Map&lt;String, String&gt; parameters = CollectionUtils.toStringMap(commaDelimitedListToStringArray(content)); setValue(parameters); &#125; &#125;); dataBinder.bind(new AnnotationPropertyValuesAdapter(attributes, applicationContext.getEnvironment(), IGNORE_FIELD_NAMES)); &#125; protected void postConfigureBean(AnnotationAttributes attributes, ReferenceBean bean) throws Exception &#123; bean.setApplicationContext(applicationContext); configureInterface(attributes, bean); configureConsumerConfig(attributes, bean); configureMethodConfig(attributes, bean); bean.afterPropertiesSet(); &#125; private void configureInterface(AnnotationAttributes attributes, ReferenceBean referenceBean) &#123; Boolean generic = getAttribute(attributes, \"generic\"); if (generic != null &amp;&amp; generic) &#123; // 泛化接口处理 String interfaceClassName = getAttribute(attributes, \"interfaceName\"); referenceBean.setInterface(interfaceClassName); return; &#125; Class&lt;?&gt; serviceInterfaceClass = resolveServiceInterfaceClass(attributes, interfaceClass); referenceBean.setInterface(serviceInterfaceClass); &#125; private void configureConsumerConfig(AnnotationAttributes attributes, ReferenceBean&lt;?&gt; referenceBean) &#123; String consumerBeanName = getAttribute(attributes, \"consumer\"); ConsumerConfig consumerConfig = getOptionalBean(applicationContext, consumerBeanName, ConsumerConfig.class); referenceBean.setConsumer(consumerConfig); &#125; void configureMethodConfig(AnnotationAttributes attributes, ReferenceBean&lt;?&gt; referenceBean) &#123; Method[] methods = (Method[]) attributes.get(\"methods\"); List&lt;MethodConfig&gt; methodConfigs = MethodConfig.constructMethodConfig(methods); if (!methodConfigs.isEmpty()) &#123; referenceBean.setMethods(methodConfigs); &#125; &#125;&#125; ReferenceBean是ReferenceConfig的子类，首先通过checkAndUpdateSubConfigs检查和更新配置，首先通过completeCompoundConfigs方法拿consumer、module、application中配置的属性去填充ReferenceConfig相同属性，然后通过startConfigCenter方法若配置了配置中心则开启配置中心，然后从配置中心获取配置数据刷新所有除开ServiceConfig的XxConfig中的属性。 配置填充补全后在get方法中若ref为null，则调用init初始化方法，首先将所有参数解析到Map中，根据Map中的参数通过Protocol创建具体的Invoker对象，然后通过ProxyFactory的getProxy方法给Invoker创建代理对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208public class ReferenceConfig&lt;T&gt; extends AbstractReferenceConfig &#123; public synchronized T get() &#123; checkAndUpdateSubConfigs(); if (destroyed) &#123; throw new IllegalStateException(\"The invoker of ReferenceConfig(\" + url + \") has already destroyed!\"); &#125; if (ref == null) &#123;// 入口 init(); &#125; return ref; // Invoke代理 &#125; public void checkAndUpdateSubConfigs() &#123; if (StringUtils.isEmpty(interfaceName)) &#123; throw new IllegalStateException(\"&lt;dubbo:reference interface=\\\"\\\" /&gt; interface not allow null!\"); &#125; completeCompoundConfigs(); // 填充ReferenceConfig对象中的属性 startConfigCenter(); // 开启配置中心， checkDefault(); // get consumer's global configuration this.refresh(); // 刷新ReferenceConfig对象的属性值 if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123; // 设置泛化 setGeneric(getConsumer().getGeneric()); &#125; if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; &#125; else &#123; try &#123; interfaceClass = Class.forName(interfaceName, true, Thread.currentThread().getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; checkInterfaceAndMethods(interfaceClass, methods); &#125; resolveFile(); checkApplication(); checkMetadataReport(); &#125; private void init() &#123; if (initialized) &#123; return; &#125; checkStubAndLocal(interfaceClass); checkMock(interfaceClass); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(SIDE_KEY, CONSUMER_SIDE); appendRuntimeParameters(map); if (!ProtocolUtils.isGeneric(getGeneric())) &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put(REVISION_KEY, revision); &#125; String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) &#123; map.put(METHODS_KEY, ANY_VALUE); &#125; else &#123; map.put(METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), COMMA_SEPARATOR)); &#125; &#125; map.put(INTERFACE_KEY, interfaceName); appendParameters(map, metrics); appendParameters(map, application); appendParameters(map, module); appendParameters(map, consumer); appendParameters(map, this); Map&lt;String, Object&gt; attributes = null; if (CollectionUtils.isNotEmpty(methods)) &#123; attributes = new HashMap&lt;String, Object&gt;(); for (MethodConfig methodConfig : methods) &#123; appendParameters(map, methodConfig, methodConfig.getName()); String retryKey = methodConfig.getName() + \".retry\"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); if (\"false\".equals(retryValue)) &#123; map.put(methodConfig.getName() + \".retries\", \"0\"); &#125; &#125; attributes.put(methodConfig.getName(), convertMethodConfig2AsyncInfo(methodConfig)); &#125; &#125; String hostToRegistry = ConfigUtils.getSystemProperty(DUBBO_IP_TO_REGISTRY); if (StringUtils.isEmpty(hostToRegistry)) &#123; hostToRegistry = NetUtils.getLocalHost(); &#125; else if (isInvalidLocalHost(hostToRegistry)) &#123; throw new IllegalArgumentException(\"Specified invalid registry ip from property:\" + DUBBO_IP_TO_REGISTRY + \", value:\" + hostToRegistry); &#125; map.put(REGISTER_IP_KEY, hostToRegistry); ref = createProxy(map); // 根据 String serviceKey = URL.buildKey(interfaceName, group, version); ApplicationModel.initConsumerModel(serviceKey, buildConsumerModel(serviceKey, attributes)); initialized = true; &#125; private T createProxy(Map&lt;String, String&gt; map) &#123; if (shouldJvmRefer(map)) &#123; // 若是本地调用 // injvm:// URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map); invoker = REF_PROTOCOL.refer(interfaceClass, url); if (logger.isInfoEnabled()) &#123; logger.info(\"Using injvm service \" + interfaceClass.getName()); &#125; &#125; else &#123;// 为什么会有urls，因为可以在@Reference的url属性中配置多个url，可以是点对点的服务地址，也可以是注册中心的地址 urls.clear(); // reference retry init will add url to urls, lead to OOM if (url != null &amp;&amp; url.length() &gt; 0) &#123; // @Reference中指定了url属性 String[] us = SEMICOLON_SPLIT_PATTERN.split(url); // 用;号切分 if (us != null &amp;&amp; us.length &gt; 0) &#123; for (String u : us) &#123; URL url = URL.valueOf(u); if (StringUtils.isEmpty(url.getPath())) &#123; url = url.setPath(interfaceName); &#125; if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; // 如果是注册中心地址，则在url中添加一个refer参数 urls.add(url.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); // map表示消费者端配置的参数 &#125; else &#123;// 如果是服务地址，有可能url中配置了参数，map中表示的服务消费者消费服务时的参数，所以需要合并 urls.add(ClusterUtils.mergeUrl(url, map)); &#125; &#125; &#125; &#125; else &#123; // @Reference中的protocol属性表示使用哪个协议调用服务，如果不是本地调用协议injvm://，则把注册中心地址找出来，对于injvm://协议已经在之前的逻辑中就已经生成invoke了 if (!LOCAL_PROTOCOL.equalsIgnoreCase(getProtocol())) &#123; checkRegistry(); List&lt;URL&gt; us = loadRegistries(false); // 加载注册中心地址 if (CollectionUtils.isNotEmpty(us)) &#123; for (URL u : us) &#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &#123; map.put(MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; urls.add(u.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); // 对于注册中心地址都添加REFER_KEY &#125; &#125; if (urls.isEmpty()) &#123; throw new IllegalStateException(\"No such any registry to reference \" + interfaceName + \" on the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please config &lt;dubbo:registry address=\\\"...\\\" /&gt; to your spring config.\"); &#125; &#125; &#125; if (urls.size() == 1) &#123; // 如果只有一个url则直接refer得到一个invoker // RegistryProtocol.refer() 或者 DubboProtocol.refer() invoker = REF_PROTOCOL.refer(interfaceClass, urls.get(0)); // MockClusterInvoker--&gt;FailoverClusterInvoker--&gt;RegistryDirectory // ---&gt;RegistryDirectory$InvokerDelegate--&gt;ListenerInvokerWrapper--&gt;ProtocolFilterWrapper$CallbackRegistrationInvoker--&gt;ConsumerContextFilter--&gt;FutureFilter--&gt;MonitorFilter--&gt;AsyncToSyncInvoker--&gt;DubboInvoker // ---&gt;RegistryDirectory$InvokerDelegate--&gt;ListenerInvokerWrapper--&gt;ProtocolFilterWrapper$CallbackRegistrationInvoker--&gt;ConsumerContextFilter--&gt;FutureFilter--&gt;MonitorFilter--&gt;AsyncToSyncInvoker--&gt;DubboInvoker &#125; else &#123; // 如果有多个url根据每个url，refer得到对应的invoker // 若这多个urls中存在注册中心url，则把所有invoker整合为RegistryAwareClusterInvoker，该Invoker在调用时，会查看所有Invoker中是否有默认的，如果有则使用默认的Invoker，如果没有，则使用第一个Invoker // 若这多个urls中不存在注册中心url，则把所有invoker整合为FailoverCluster List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; // 用来记录urls中最后一个注册中心url for (URL url : urls) &#123; invokers.add(REF_PROTOCOL.refer(interfaceClass, url)); if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; // use last registry url &#125; &#125; if (registryURL != null) &#123; // registry url is available 如果存在注册中心地址 // use RegistryAwareCluster only when register's CLUSTER is available URL u = registryURL.addParameter(CLUSTER_KEY, RegistryAwareCluster.NAME); // StaticDirectory表示静态服务目录，里面的invokers是不会变的, 生成一个RegistryAwareCluster // The invoker wrap relation would be: RegistryAwareClusterInvoker(StaticDirectory) -&gt; FailoverClusterInvoker(RegistryDirectory, will execute route) -&gt; Invoker invoker = CLUSTER.join(new StaticDirectory(u, invokers)); &#125; else &#123; // not a registry url, must be direct invoke. // 如果不存在注册中心地址, 生成一个FailoverClusterInvoker invoker = CLUSTER.join(new StaticDirectory(invokers)); &#125; &#125; &#125; if (shouldCheck() &amp;&amp; !invoker.isAvailable()) &#123; throw new IllegalStateException(\"Failed to check the status of the service \" + interfaceName + \". No provider available for the service \" + (group == null ? \"\" : group + \"/\") + interfaceName + (version == null ? \"\" : \":\" + version) + \" from the url \" + invoker.getUrl() + \" to the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion()); &#125; MetadataReportService metadataReportService = null; if ((metadataReportService = getMetadataReportService()) != null) &#123; URL consumerURL = new URL(CONSUMER_PROTOCOL, map.remove(REGISTER_IP_KEY), 0, map.get(INTERFACE_KEY), map); metadataReportService.publishConsumer(consumerURL); &#125; return (T) PROXY_FACTORY.getProxy(invoker); // create service proxy &#125;&#125;public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123; protected List&lt;URL&gt; loadRegistries(boolean provider) &#123;// check &amp;&amp; override if necessary List&lt;URL&gt; registryList = new ArrayList&lt;URL&gt;(); if (CollectionUtils.isNotEmpty(registries)) &#123; for (RegistryConfig config : registries) &#123; String address = config.getAddress(); if (StringUtils.isEmpty(address)) &#123; // 如果注册中心没有配地址，则地址为0.0.0.0 address = ANYHOST_VALUE; &#125; if (!RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(address)) &#123; // 如果注册中心的地址不是\"N/A\" Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); appendParameters(map, application); // 把application中的参数放入map中，注意，map中的key是没有prefix的 appendParameters(map, config); // 把config中的参数放入map中，注意，map中的key是没有prefix的config是RegistryConfig，表示注册中心 map.put(PATH_KEY, RegistryService.class.getName());// 此处path值固定为RegistryService.class.getName()，因为现在是在加载注册中心 appendRuntimeParameters(map); // 把dubbo的版本信息和pid放入map中 if (!map.containsKey(PROTOCOL_KEY)) &#123; // 如果map中如果没有protocol，那么默认为dubbo map.put(PROTOCOL_KEY, DUBBO_PROTOCOL); &#125; List&lt;URL&gt; urls = UrlUtils.parseURLs(address, map); // 构造注册中心url，地址+参数 for (URL url : urls) &#123; url = URLBuilder.from(url).addParameter(REGISTRY_KEY, url.getProtocol()).setProtocol(REGISTRY_PROTOCOL).build(); // 到此为止，url的内容大概为：registry://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?application=dubbo-demo-annotation-provider&amp;dubbo=2.0.2&amp;pid=269936&amp;registry=zookeeper&amp;timestamp=1584886077813 // 该url表示：使用registry协议调用org.apache.dubbo.registry.RegistryService服务，参数为application=dubbo-demo-annotation-provider&amp;dubbo=2.0.2&amp;pid=269936&amp;registry=zookeeper&amp;timestamp=1584886077813 // 若是服务提供者，获取register的值，如果为false，表示该服务不注册到注册中心，若是服务消费者，获取subscribe的值，如果为false，表示该引入的服务不订阅注册中心中的数据 if ((provider &amp;&amp; url.getParameter(REGISTER_KEY, true)) || (!provider &amp;&amp; url.getParameter(SUBSCRIBE_KEY, true))) &#123; registryList.add(url); &#125; &#125; &#125; &#125; &#125; return registryList; &#125;&#125;","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://yaoyinglong.github.io/tags/Dubbo/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Dubbo","slug":"Cloud/Dubbo","permalink":"https://yaoyinglong.github.io/categories/Cloud/Dubbo/"}]},{"title":"SPI机制源码","date":"2021-12-13T16:00:00.000Z","path":"Blog/Cloud/Dubbo/SPI机制源码/","text":"Dubbo常见SPI写法，表示获取black对应的Person接口扩展点，然后通过URL参数动态指定具体Person实现类中注入的Car的具体实例。12345ExtensionLoader&lt;Person&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Person.class);Person person = extensionLoader.getExtension(\"black\"); // BlackPersonURL url = new URL(null, null, -1);url = url.addParameter(\"car\", \"black\");System.out.println(person.getCar().getCarName(url)); // 代理逻辑 调用ExtensionLoader的getExtensionLoader方法时，首先从缓存中获取，若获取不到再通过传入的类创建一个新的ExtensionLoader且放入缓存中，在ExtensionLoader的构造方法中会通过getAdaptiveExtension将ExtensionFactory中被@Adaptive注解标注的子类AdaptiveExtensionFactory作为objectFactory对象工厂，该工厂的作用是对SPI扩展类中有SPI扩展类作为属性或Spring Bean作为属性的字段进行赋值，相当于Spring中的依赖注入。 在getExtension方法中首先创建一个Holder类用于持有SPI实例，且使用其作为锁，防止两个线程同时获取同一个name扩展点对象的并发问题，且Holder会被放入cachedInstances缓存中。 然后调用createExtension方法创建扩展点实例对象，首先通过getExtensionClasses获取扩展类接口的所有实现类，然后根据名称获取具体的类，然后再通过injectExtension完成依赖注入，最后若该接口存在Wrapper类，则遍历Wrapper类调用其构造方法传入当前实例，然后对Wrapper类进行依赖注入。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class ExtensionLoader&lt;T&gt; &#123; private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;&gt;(); private final Class&lt;?&gt; type; // 当前ExtensionLoader实例是哪个接口的扩展点加载器 private final ExtensionFactory objectFactory; // 扩展点工厂（对象工厂），可以获得某个对象 public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; if (type == null) &#123; throw new IllegalArgumentException(\"Extension type == null\"); &#125; if (!type.isInterface()) &#123; throw new IllegalArgumentException(\"Extension type (\" + type + \") is not an interface!\"); &#125; if (!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException(\"Extension type (\" + type + \") is not an extension, because it is NOT annotated with @\" + SPI.class.getSimpleName() + \"!\"); &#125; ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) &#123; EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader; &#125; private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; // objectFactory表示当前ExtensionLoader内部的一个对象工厂，可以用来获取对象AdaptiveExtensionFactory objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()); &#125; public T getExtension(String name) &#123; if (StringUtils.isEmpty(name)) &#123; throw new IllegalArgumentException(\"Extension name == null\"); &#125; if (\"true\".equals(name)) &#123; // 获取默认扩展类 return getDefaultExtension(); &#125; final Holder&lt;Object&gt; holder = getOrCreateHolder(name); Object instance = holder.get(); if (instance == null) &#123; // 如果有两个线程同时来获取同一个name的扩展点对象，那只会有一个线程会进行创建 synchronized (holder) &#123; // 一个name对应一把锁 instance = holder.get(); if (instance == null) &#123; // 创建扩展点实例对象 instance = createExtension(name); // 创建扩展点对象 holder.set(instance); &#125; &#125; &#125; return (T) instance; &#125; private Holder&lt;Object&gt; getOrCreateHolder(String name) &#123; Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;&gt;()); holder = cachedInstances.get(name); &#125; return holder; &#125; private T createExtension(String name) &#123; Class&lt;?&gt; clazz = getExtensionClasses().get(name); // 获取扩展类接口的所有实现类，然后根据名称获取具体的类 if (clazz == null) &#123; throw findException(name); // 找不到该名称对应的SPI扩展则抛异常 &#125; try &#123; T instance = (T) EXTENSION_INSTANCES.get(clazz); // 实例缓存 if (instance == null) &#123; // 创建实例 EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; injectExtension(instance); // 依赖注入 IOC Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; // AOP，cachedWrapperClasses无序 if (CollectionUtils.isNotEmpty(wrapperClasses)) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException(\"Extension instance (name: \" + name + \", class: \" + type + \") couldn't be instantiated: \" + t.getMessage(), t); &#125; &#125;&#125; 加载解析SPI文件加载当前ExtensionLoader对象中指定的接口的所有扩展，首先还是从缓存中获取，若缓存中没有则再调用loadExtensionClasses方法加载到缓存中。首先通过cacheDefaultExtensionName方法获取SPI接口类上的@SPI注解，若该注解上设置了value属性，则将value属性中配置的值作为默认名称设置到cachedDefaultName属性中。 然后调用loadDirectory方法正则的加载SPI配置文件中的内容，加载顺序为META-INF/dubbo/internal/、META-INF/dubbo/、META-INF/services/但同一个接口在多个目录下配置了会被后面的补全覆盖。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class ExtensionLoader&lt;T&gt; &#123; private static final String SERVICES_DIRECTORY = \"META-INF/services/\"; private static final String DUBBO_DIRECTORY = \"META-INF/dubbo/\"; private static final String DUBBO_INTERNAL_DIRECTORY = DUBBO_DIRECTORY + \"internal/\"; private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; // cachedClasses是一个Holder对象，持有的就是一个Map&lt;String, Class&lt;?&gt;&gt;是为了解决并发，Holder对象用来作为锁 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; classes = loadExtensionClasses(); // 加载、解析文件Map cachedClasses.set(classes); &#125; &#125; &#125; return classes; &#125; private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; cacheDefaultExtensionName(); // cache接口默认的扩展类，给cachedDefaultName属性赋值 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;&gt;(); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName()); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); return extensionClasses; &#125; private void cacheDefaultExtensionName() &#123; final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation == null) &#123; return; // 若SPI接口上没有@SPI注解则直接跳过 &#125; String value = defaultAnnotation.value(); if ((value = value.trim()).length() &gt; 0) &#123; String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) &#123; throw new IllegalStateException(\"More than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names)); &#125; if (names.length == 1) &#123; cachedDefaultName = names[0]; &#125; &#125; &#125;&#125; 根据目录+SPI接口全限定名获取到具体的SPI配置文件URL列表，然后遍历按行读取文件内容，接忽略被#注释的部分，然后将名称和具体的实现类拆分开，反射得到具体的实现了的Class对象，首先若该实现类没有实现该指定的接口则抛出异常，然后判断若该实现类被@Adaptive注解标注，则将其设置到cachedAdaptiveClass缓存中，且有且只能有一个实现类被@Adaptive注解标注否则抛出异常。 然后判断当前类是否有该接口作为唯一入参的构造方法，以此判断是否为该接口的一个Wrapper类，若为Wrapper类将其加入到cachedWrapperClasses缓存中。 若该类既没有被@Adaptive注解标注也不是一个Wrapper类，则是一个普通的扩展类，首先通过findAnnotationName方法判断若该类被@Extension注解标注，则获取该注解的value属性配置的值作为实现类名称，若未被@Extension注解标注，获取当前加载类名称，若类名包含接口名则将接口名截掉后转为小写最终作为实现类名称。最后将类和名称缓存到cachedNames和extensionClasses中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type) &#123; String fileName = dir + type; try &#123;// 根据文件中的内容得到urls， 每个url表示一个扩展，如http=org.apache.dubbo.rpc.protocol.http.HttpProtocol Enumeration&lt;java.net.URL&gt; urls; ClassLoader classLoader = findClassLoader(); if (classLoader != null) &#123; urls = classLoader.getResources(fileName); &#125; else &#123; urls = ClassLoader.getSystemResources(fileName); &#125; if (urls != null) &#123; while (urls.hasMoreElements()) &#123; // 遍历url进行加载,把扩展类添加到extensionClasses中 java.net.URL resourceURL = urls.nextElement(); loadResource(extensionClasses, classLoader, resourceURL); &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(\"Exception occurred when loading extension class (interface: \" + type + \", description file: \" + fileName + \").\", t); &#125;&#125;private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL) &#123; try &#123; try (BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), StandardCharsets.UTF_8))) &#123; String line; while ((line = reader.readLine()) != null) &#123; final int ci = line.indexOf('#'); if (ci &gt;= 0) &#123; line = line.substring(0, ci); // 截掉文件中的注释 &#125; line = line.trim(); if (line.length() &gt; 0) &#123; try &#123; String name = null; int i = line.indexOf('='); if (i &gt; 0) &#123; name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); &#125; if (line.length() &gt; 0) &#123; // 加载类，并添加到extensionClasses中 loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name); &#125; &#125; catch (Throwable t) &#123; IllegalStateException e = new IllegalStateException(\"Failed to load extension class (interface: \" + type + \", class line: \" + line + \") in \" + resourceURL + \", cause: \" + t.getMessage(), t); exceptions.put(line, e); &#125; &#125; &#125; &#125; &#125; catch (Throwable t) &#123; &#125;&#125;private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name) throws NoSuchMethodException &#123; if (!type.isAssignableFrom(clazz)) &#123; // 判断加载的类是否为当前type对应接口的实现类 throw new IllegalStateException(\"Error occurred when loading extension class (interface: \" + type + \", class line: \" + clazz.getName() + \"), class \" + clazz.getName() + \" is not subtype of interface.\"); &#125; if (clazz.isAnnotationPresent(Adaptive.class)) &#123; // 判断当前类是否被@Adaptive注解标注 cacheAdaptiveClass(clazz); // 当前接口手动指定了Adaptive类 &#125; else if (isWrapperClass(clazz)) &#123;// 是一个Wrapper类 cacheWrapperClass(clazz); // 将当前类放入cachedWrapperClasses缓存中 &#125; else &#123; // 需要有无参的构造方法 clazz.getConstructor(); // 在文件中没有name，但是在类上指定了Extension的注解上指定了name if (StringUtils.isEmpty(name)) &#123; name = findAnnotationName(clazz); if (name.length() == 0) &#123; // 若name未指定则抛异常 throw new IllegalStateException(\"No such extension name for the class \" + clazz.getName() + \" in the config \" + resourceURL); &#125; &#125; String[] names = NAME_SEPARATOR.split(name); if (ArrayUtils.isNotEmpty(names)) &#123; cacheActivateClass(clazz, names[0]); // 缓存一下被Activate注解了的类 for (String n : names) &#123; // 有多个名字 cacheName(clazz, n); // clazz: name放入cachedNames saveInExtensionClass(extensionClasses, clazz, n); // name: clazz放入extensionClasses &#125; &#125; &#125;&#125;private void cacheAdaptiveClass(Class&lt;?&gt; clazz) &#123; if (cachedAdaptiveClass == null) &#123; cachedAdaptiveClass = clazz; &#125; else if (!cachedAdaptiveClass.equals(clazz)) &#123; throw new IllegalStateException(\"More than 1 adaptive class found: \" + cachedAdaptiveClass.getName() + \", \" + clazz.getName()); &#125;&#125;private boolean isWrapperClass(Class&lt;?&gt; clazz) &#123; try &#123; // 通过该类是否有改接口的构造方法判断是否为一个Wrapper类 clazz.getConstructor(type); return true; &#125; catch (NoSuchMethodException e) &#123; return false; &#125;&#125;private void cacheWrapperClass(Class&lt;?&gt; clazz) &#123; if (cachedWrapperClasses == null) &#123; cachedWrapperClasses = new ConcurrentHashSet&lt;&gt;(); &#125; cachedWrapperClasses.add(clazz);&#125;private String findAnnotationName(Class&lt;?&gt; clazz) &#123; org.apache.dubbo.common.Extension extension = clazz.getAnnotation(org.apache.dubbo.common.Extension.class); if (extension != null) &#123; return extension.value(); &#125; String name = clazz.getSimpleName(); if (name.endsWith(type.getSimpleName())) &#123; // 若未被@Extension注解标注，获取当前加载类名称，若类名包含接口名则将接口名截掉 name = name.substring(0, name.length() - type.getSimpleName().length()); &#125; return name.toLowerCase(); // 转换为小写&#125;private void cacheName(Class&lt;?&gt; clazz, String name) &#123; if (!cachedNames.containsKey(clazz)) &#123; cachedNames.put(clazz, name); &#125;&#125;private void saveInExtensionClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, Class&lt;?&gt; clazz, String name) &#123; Class&lt;?&gt; c = extensionClasses.get(name); if (c == null) &#123; extensionClasses.put(name, clazz); &#125; else if (c != clazz) &#123; String duplicateMsg = \"Duplicate extension \" + type.getName() + \" name \" + name + \" on \" + c.getName() + \" and \" + clazz.getName(); throw new IllegalStateException(duplicateMsg); &#125;&#125;private void cacheActivateClass(Class&lt;?&gt; clazz, String name) &#123; Activate activate = clazz.getAnnotation(Activate.class); // 类上Activate注解 if (activate != null) &#123; cachedActivates.put(name, activate); &#125; else &#123;// support com.alibaba.dubbo.common.extension.Activate com.alibaba.dubbo.common.extension.Activate oldActivate = clazz.getAnnotation(com.alibaba.dubbo.common.extension.Activate.class); if (oldActivate != null) &#123; cachedActivates.put(name, oldActivate); &#125; &#125;&#125; 依赖注入依赖注入首先判断方法若不是setter方法直接跳过，若不想被依赖注入可在setter方法上通过@DisableInject注解标注，且若当前方法是Void、Boolean、Byte、Integer等基本数据类型、String、Number的子类、Date的子类等则不需要做依赖注入直接跳过，然后解析setter方法获取到需要依赖注入的属性的属性名，然后通过在构造方法中得到的AdaptiveExtensionFactory工厂获取具体的属性值。通过反射注入到实例中。 123456789101112131415161718192021222324252627282930313233343536373839private T injectExtension(T instance) &#123; if (objectFactory == null) &#123; return instance; &#125; try &#123; for (Method method : instance.getClass().getMethods()) &#123; if (!isSetter(method)) &#123; continue; // 若不是setter方法直接跳过 &#125; if (method.getAnnotation(DisableInject.class) != null) &#123; // 利用set方法注入 continue; // 若该方法被@DisableInject注解标注则跳过 &#125; // set方法中的参数类型 Class&lt;?&gt; pt = method.getParameterTypes()[0]; // Person接口 if (ReflectUtils.isPrimitives(pt)) &#123; continue; // 若当前方法是9种基本数据类型、String、Number的之类、Date的子类等则不需要做依赖注入，直接跳过 &#125; try &#123; String property = getSetterProperty(method); // 得到setXxx中的xxx // 根据参数类型或属性名，从objectFactory中获取到对象，然后调用set方法进行注入，AdaptiveExtensionFactory Object object = objectFactory.getExtension(pt, property); // User.class, user if (object != null) &#123; method.invoke(instance, object); // 反射调用setter方法赋值 &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; catch (Exception e) &#123; &#125; return instance;&#125;private String getSetterProperty(Method method) &#123; return method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\";&#125;private boolean isSetter(Method method) &#123; return method.getName().startsWith(\"set\") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers());&#125; 在实力化AdaptiveExtensionFactory时通过构造方法将所以未被@Adaptive注解标注的类加载到factories中，Dubbo内置就SpiExtensionFactory和SpringExtensionFactory分别用于注入SPI扩展实例和Spring中的Bean，当然也可以通过SPI机制扩展ExtensionFactory，在getExtension方法中遍历这些扩展类获取到具体的实例对象。 1234567891011121314151617181920212223@Adaptivepublic class AdaptiveExtensionFactory implements ExtensionFactory &#123; private final List&lt;ExtensionFactory&gt; factories; public AdaptiveExtensionFactory() &#123; // 支持哪些ExtensionFactory (Spi, SPring) ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); for (String name : loader.getSupportedExtensions()) &#123; // spi, spring list.add(loader.getExtension(name)); &#125; factories = Collections.unmodifiableList(list); &#125; @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; // 遍历两个ExtensionFactory，从ExtensionFactory中得到实例，只要从某个ExtensionFactory中获取到对象实例就可以了 for (ExtensionFactory factory : factories) &#123; T extension = factory.getExtension(type, name); // SpringExtensionFactory，SpiExtensionFactory if (extension != null) &#123; return extension; &#125; &#125; return null; &#125;&#125; SPI机制若type类被@Adaptive注解标记则直接返回该类，否则通过AdaptiveClassCodeGenerator给当前类创建一个代理类代码，然后编译成一个Class对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class SpiExtensionFactory implements ExtensionFactory &#123; @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; // 接口上存在SPI注解 if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) &#123; ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type); if (!loader.getSupportedExtensions().isEmpty()) &#123; return loader.getAdaptiveExtension(); // 接口的Adaptive类（代理对象） &#125; &#125; return null; &#125;&#125;public class ExtensionLoader&lt;T&gt; &#123; public T getAdaptiveExtension() &#123; Object instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; if (createAdaptiveInstanceError != null) &#123; throw new IllegalStateException(\"Failed to create adaptive instance: \" + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); &#125; synchronized (cachedAdaptiveInstance) &#123; instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; instance = createAdaptiveExtension(); cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123; createAdaptiveInstanceError = t; throw new IllegalStateException(\"Failed to create adaptive instance: \" + t.toString(), t); &#125; &#125; &#125; &#125; return (T) instance; &#125; private T createAdaptiveExtension() &#123; try &#123; // 首先获取到该实例的代理对象，然后给代理对象依赖注入 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123; throw new IllegalStateException(\"Can't create adaptive extension \" + type + \", cause: \" + e.getMessage(), e); &#125; &#125; private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; getExtensionClasses(); // 获取当前接口的所有扩展类 if (cachedAdaptiveClass != null) &#123; // 缓存了@Adaptive注解标记的类 return cachedAdaptiveClass; &#125; // 如果某个接口没有手动指定一个Adaptive类，那么就自动生成一个Adaptive类 return cachedAdaptiveClass = createAdaptiveExtensionClass(); &#125; rivate Class&lt;?&gt; createAdaptiveExtensionClass() &#123; // cachedDefaultName表示接口默认的扩展类 String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); ClassLoader classLoader = findClassLoader(); org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader); &#125;&#125; 类中没有被@Adaptive注解标注的方法则直接抛出异常，并不是所有的方法都会生成代理，只有方法上被@Adaptive注解标注了才会生成代理，未被@Adaptive注解标注方法生成的方法中直接抛出一个异常，在通过generateExtNameAssignment构建方法代码时在会生成通过URL做相应处理的内容，所以被@Adaptive标注的方法必须有一个URL参数或对应的参数类中存在getUrl方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class AdaptiveClassCodeGenerator &#123; private boolean hasAdaptiveMethod() &#123; return Arrays.stream(type.getMethods()).anyMatch(m -&gt; m.isAnnotationPresent(Adaptive.class)); &#125; public String generate() &#123; if (!hasAdaptiveMethod()) &#123; throw new IllegalStateException(\"No adaptive method exist on extension \" + type.getName() + \", refuse to create the adaptive class!\"); &#125; StringBuilder code = new StringBuilder(); code.append(generatePackageInfo()); code.append(generateImports()); code.append(generateClassDeclaration()); Method[] methods = type.getMethods(); for (Method method : methods) &#123; // 遍历接口中的方法，生成代理方法 code.append(generateMethod(method)); &#125; code.append(\"&#125;\"); return code.toString(); &#125; private String generateMethod(Method method) &#123; String methodReturnType = method.getReturnType().getCanonicalName(); String methodName = method.getName(); String methodContent = generateMethodContent(method); String methodArgs = generateMethodArguments(method); String methodThrows = generateMethodThrows(method); return String.format(CODE_METHOD_DECLARATION, methodReturnType, methodName, methodArgs, methodThrows, methodContent); &#125; private String generateMethodContent(Method method) &#123; // 方法上存在Adaptive注解才进行代理 Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class); StringBuilder code = new StringBuilder(512); if (adaptiveAnnotation == null) &#123; return generateUnsupported(method); // 方法内直接抛出异常 &#125; else &#123; // 方法中URL类型参数的下标 int urlTypeIndex = getUrlTypeIndex(method); // 寻找URL：1.如果当前方法中有URl类型的参数，那么url就是该参数值 // 2.如果当前方法中没有URL类型的参数，但是当前方法中有某个类型中的get方法返回了URl类型，那么就调用那个get方法得到一个url对象 if (urlTypeIndex != -1) &#123;// Null Point check code.append(generateUrlNullCheck(urlTypeIndex)); &#125; else &#123;// did not find parameter in URL type code.append(generateUrlAssignmentIndirectly(method)); &#125; String[] value = getMethodAdaptiveValue(adaptiveAnnotation); // 根据这个value去找具体的扩展类 boolean hasInvocation = hasInvocationArgument(method); // 方法中有Invocation类型的参数 code.append(generateInvocationArgumentNullCheck(method)); code.append(generateExtNameAssignment(value, hasInvocation)); code.append(generateExtNameNullCheck(value)); // check extName == null? code.append(generateExtensionAssignment()); code.append(generateReturnAndInvocation(method)); // return statement &#125; return code.toString(); &#125; private String generateExtNameAssignment(String[] value, boolean hasInvocation) &#123; // TODO: refactor it String getNameCode = null; for (int i = value.length - 1; i &gt;= 0; --i) &#123; if (i == value.length - 1) &#123; if (null != defaultExtName) &#123; if (!\"protocol\".equals(value[i])) &#123; if (hasInvocation) &#123; getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; else &#123; getNameCode = String.format(\"url.getParameter(\\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; &#125; else &#123; getNameCode = String.format(\"( url.getProtocol() == null ? \\\"%s\\\" : url.getProtocol() )\", defaultExtName); &#125; &#125; else &#123; if (!\"protocol\".equals(value[i])) &#123; if (hasInvocation) &#123; getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; else &#123; getNameCode = String.format(\"url.getParameter(\\\"%s\\\")\", value[i]); &#125; &#125; else &#123; getNameCode = \"url.getProtocol()\"; &#125; &#125; &#125; else &#123; if (!\"protocol\".equals(value[i])) &#123; if (hasInvocation) &#123; getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; else &#123; getNameCode = String.format(\"url.getParameter(\\\"%s\\\", %s)\", value[i], getNameCode); &#125; &#125; else &#123; getNameCode = String.format(\"url.getProtocol() == null ? (%s) : url.getProtocol()\", getNameCode); &#125; &#125; &#125; return String.format(CODE_EXT_NAME_ASSIGNMENT, getNameCode); &#125;&#125; 生成的代理对象代码示例如下，很明显在代理方法中也是通过SPI加载机制来获取实例，可以通过传入URL参数且通过其addParameter方法给URL对象设置参数来动态选择实例对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package org.apache.dubbo.rpc;import org.apache.dubbo.common.extension.ExtensionLoader;public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol &#123; public void destroy() &#123; throw new UnsupportedOperationException(\"The method public abstract void org.apache.dubbo.rpc.Protocol.destroy() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(\"The method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &#125; public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException &#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url (\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException &#123; if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url (\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125;&#125;package com.eleven.icode;import org.apache.dubbo.common.extension.ExtensionLoader;public class Car$Adaptive implements com.eleven.icode.Car &#123; public java.lang.String getCarName(org.apache.dubbo.common.URL arg0) &#123; if (arg0 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg0; String extName = url.getParameter(\"car\"); if(extName == null) throw new IllegalStateException(\"Failed to get extension (com.eleven.icode.Car) name from url (\" + url.toString() + \") use keys([car])\"); com.eleven.icode.Car extension = (com.eleven.icode.Car)ExtensionLoader.getExtensionLoader(com.eleven.icode.Car.class).getExtension(extName); return extension.getCarName(arg0); &#125; public java.lang.String sayHell() &#123; throw new UnsupportedOperationException(\"The method public abstract java.lang.String com.eleven.icode.Car.sayHell() of interface com.eleven.icode.Car is not adaptive method!\"); &#125;&#125; 对于Spring的依赖注入优先通过Bean的名称从Spring容器中获取具体的Bean，若通过名称未找到则再通过类型从Spring容器中获取实例。 1234567891011121314151617181920212223242526public class SpringExtensionFactory implements ExtensionFactory &#123; public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) &#123; return null; // 若接口上存在SPI注解，就不从Spring中获取对象实例了 &#125; for (ApplicationContext context : CONTEXTS) &#123; if (context.containsBean(name)) &#123; Object bean = context.getBean(name); // 从ApplicationContext中获取bean, byname if (type.isInstance(bean)) &#123; return (T) bean; &#125; &#125; &#125; if (Object.class == type) &#123; return null; &#125; for (ApplicationContext context : CONTEXTS) &#123; try &#123; return context.getBean(type); // byType &#125; catch (NoUniqueBeanDefinitionException multiBeanExe) &#123; &#125; catch (NoSuchBeanDefinitionException noBeanExe) &#123; &#125; &#125; return null; &#125;&#125; 若不想使用Dubbo通过代码生成的Adaptive类也可以自定义一个Adaptive类，即实现接口且在该类上加上@Adaptive注解 1234567891011121314@Adaptivepublic class AdaptiveCar implements Car &#123; public Car getExtension(Class&lt;Car&gt; type, String name) &#123; return new RedCar(); &#125; @Override public String getCarName(URL url) &#123; return \"这是一个Adaptive标注的类\"; &#125; @Override public String sayHell() &#123; return null; &#125;&#125;","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://yaoyinglong.github.io/tags/Dubbo/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Dubbo","slug":"Cloud/Dubbo","permalink":"https://yaoyinglong.github.io/categories/Cloud/Dubbo/"}]},{"title":"Dubbo基础","date":"2021-12-12T16:00:00.000Z","path":"Blog/Cloud/Dubbo/Dubbo基础/","text":"12345678910111213141516171819202122232425# Spring boot applicationspring.application.name=dubbo-provider-demoserver.port=8081# Base packages to scan Dubbo Component: @org.apache.dubbo.config.annotation.Servicedubbo.scan.base-packages=com.eleven.icode.servicedubbo.application.name=$&#123;spring.application.name&#125;## Dubbo Registrydubbo.registry.address=zookeeper://127.0.0.1:2181dubbo.protocols.p1.id=dubbo1dubbo.protocols.p1.name=dubbodubbo.protocols.p1.port=20881dubbo.protocols.p1.host=0.0.0.0dubbo.protocols.p2.id=dubbo2dubbo.protocols.p2.name=dubbodubbo.protocols.p2.port=20882dubbo.protocols.p2.host=0.0.0.0dubbo.protocols.p3.id=dubbo3dubbo.protocols.p3.name=dubbodubbo.protocols.p3.port=20883dubbo.protocols.p3.host=0.0.0.0 负载均衡在集群负载均衡时Dubbo提供了Random、RoundRobin、LeastActive、ConsistentHash四种均衡策略缺省为random随机调用。若消费端和服务端都配置了负载均衡策略以消费端为准。 Random：随机，按权重设置随机概率，在一个截面上碰撞的概率高，但调用量越大分布越均匀，且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin：轮询，按公约后的权重设置轮询比率，存在慢提供者累积请求问题 LeastActive：基于消费端的最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差，使慢的提供者收到更少请求，越慢的提供者的调用前后计数差会越大 ConsistentHash：相同参数的请求总是发到同一提供者 12345678910111213// 服务端@Service(version = \"default\")public class DefaultDemoService implements DemoService &#123; @Override public String sayHello(String name) &#123; System.out.println(\"执行了服务\" + name); URL url = RpcContext.getContext().getUrl(); return String.format(\"%s：%s, Hello, %s\", url.getProtocol(), url.getPort(), name); &#125;&#125;// 消费端：random、roundrobin、leastactive、consistenthash@Reference(version = \"default\", loadbalance = \"leastactive\")private DemoService demoService; 服务超时在服务提供者和服务消费者上都可配置服务超时时间，若在服务端和消费端只在其中一方配置了timeout，则表示消费端调用服务的超时时间，消费端若超过时间没有收到响应结果，则消费端会抛超时异常，但服务端不会抛异常，服务端在执行服务后，会检查执行该服务的时间，若超过timeout，则会打印一个超时日志，服务会正常执行完。且若请求失败默认重试两次。 12345678910111213141516171819// 服务端@Service(version = \"timeout\", timeout = 6000)public class TimeoutDemoService implements DemoService &#123; @Override public String sayHello(String name) &#123; System.out.println(\"执行了timeout服务\" + name); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"执行结束\" + name); URL url = RpcContext.getContext().getUrl(); return String.format(\"%s：%s, Hello, %s\", url.getProtocol(), url.getPort(), name); &#125;&#125;// 消费端：请求失败默认重试2次@Reference(version = \"timeout\", timeout = 6000)private DemoService demoService; 集群容错 Invoker：Provider的一个可调用Service的抽象，封装了Provider地址及Service接口信息 Directory：代表多个Invoker，可把它看成List&lt;Invoker&gt; ，但与List不同的是，它的值可能是动态变化的，如注册中心推送变更 Cluster：将Directory中的多个Invoker伪装成一个Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个 Router：负责从多个Invoker中按路由规则选出子集，比如读写分离，应用隔离等 LoadBalance：负责从多个Invoker中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后需要重选 集群容错表示服务消费者在调用某个服务时，该服务有多个服务提供者，在经过负载均衡后选出其中一个服务提供者之后进行调用，调用报错后Dubbo所采取的后续处理策略。在集群调用失败时，Dubbo提供多种容错方案，缺省为failover重试。 failover：失败自动切换，当出现失败重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过retries=2来设置重试次数，不含第一次 failfast：快速失败，只发起一次调用，失败立即报错，通常用于非幂等性的写操作，比如新增记录 failsafe：失败安全，出现异常时，直接忽略，通常用于写入审计日志等操作 failback：失败自动恢复，后台记录失败请求，定时重发，通常用于消息通知操作，默认三次 forking：并行调用多个服务器，只要一个成功即返回，通常用于实时性要求较高的读操作，但需浪费更多服务资源，可通过forks=2来设置最大并行数 broadcast：广播逐个调用所有提供者，任意一台报错则报错，通常用于通知所有提供者更新缓存或日志等本地资源信息 12@Reference(version = \"timeout\", timeout = 1000, cluster = \"failback\")private DemoService demoService; 服务降级通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略，与集群容错的区别在于，集群容错是整个集群范围内的容错，服务降级是单个服务提供者的自身容错。 mock=force:return+null：表示消费方对该服务的方法调用都直接返回null值，不发起远程调用，用来屏蔽不重要服务不可用时对调用方的影响 mock=fail:return+null：表示消费方对该服务方法调用失败后再返回null值不抛异常，依然会失败重试，用来容忍不重要服务不稳定时对调用方的影响 12@Reference(version = \"timeout\", timeout = 1000, mock = \"force: return 123\")private DemoService demoService; 本地存根本地存根就是一段逻辑，这段逻辑是在服务消费端执行的，这段逻辑一般都是由服务提供者提供，服务提供者可利用这种机制在服务消费者远程调用服务提供者之前或之后再做一些其他事情，比如结果缓存，请求参数验证等。 Stub必须有可传入Proxy的构造函数，在interface旁边放一个Stub实现，它实现BarService接口，并有一个传入远程BarService实例的构造函数。 1234567891011121314151617181920public class DemoServiceStub implements DemoService &#123; private final DemoService demoService; public DemoServiceStub(DemoService demoService)&#123; this.demoService = demoService; // 构造函数传入真正的远程代理对象 &#125; @Override public String sayHello(String name) &#123; // 此代码在客户端执行, 可在客户端做ThreadLocal本地缓存，或预先验证参数是否合法等等 try &#123; return demoService.sayHello(name); // safe null &#125; catch (Exception e) &#123; // 可以容错，可以做任何AOP拦截事项 return \"容错数据\"; &#125; &#125;&#125;@Reference(version = \"timeout\", timeout = 1000, stub = \"true\")private DemoService demoService;@Reference(version = \"timeout\", timeout = 1000, stub = \"com.eleven.icode.DemoServiceStub\")private DemoService demoService; 本地伪装本地伪装就是Mock，相对于本地存根更简单一点，Mock其实就是Dubbo中的服务容错的解决方案，通常用于服务降级。使用throw当调用出错时默认抛出RPCException，使用return来返回一个字符串表示的对象，作为Mock返回值。合法的字符串可以是： empty：代表空，基本类型的默认值，或者集合类的空值 null：null true：true false：false JSON格式：反序列化JSON所得到的对象 1234567891011121314@Reference(version = \"timeout\", timeout = 1000, mock = \"throw\")private DemoService demoService;public class DemoServiceMock implements DemoService &#123; @Override public String sayHello(String name) &#123; return \"出现Rpc异常，进行了mock\"; &#125;&#125;@Reference(version = \"timeout\", mock = \"true\")private DemoService demoService;@Reference(version = \"timeout\", timeout = 1000, mock = \"force: return 123\")private DemoService demoService; 参数回调对于某个服务接口中的某个方法，若想支持消费者在调用该方法时能设置回调逻辑，则该方法就需要提供一个入参用来表示回调逻辑。因为Dubbo协议是基于长连接的，故消费端在两次调用同一个方法时想指定不同的回调逻辑，则需要在调用时在指定一定key进行区分。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public interface DemoServiceListener &#123; void changed(String msg);&#125;// 服务端// DemoService的sayHello方法的index=1的参数是回调对象，服务消费者可以调用addListener方法来添加回调对象，服务提供者一旦执行回调对象的方法就会通知给服务消费者@Service(version = \"callback\", methods = &#123;@Method(name = \"sayHello\", arguments = &#123;@Argument(index = 2, callback = true)&#125;)&#125;, callbacks = 3)public class CallBackDemoService implements DemoService &#123; private final Map&lt;String, DemoServiceListener&gt; listeners = new ConcurrentHashMap&lt;String, DemoServiceListener&gt;(); public CallBackDemoService() &#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; while (true) &#123; for (Map.Entry&lt;String, DemoServiceListener&gt; entry : listeners.entrySet()) &#123; entry.getValue().changed(getChanged(entry.getKey())); &#125; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;); t.start(); &#125; private String getChanged(String key) &#123; return \"Changed: \" + new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date()); &#125; @Override public String sayHello(String name) &#123; return null; &#125; @Override public String sayHello(String name, String key, DemoServiceListener callback) &#123; System.out.println(\"执行了回调服务\" + name); listeners.put(key, callback); URL url = RpcContext.getContext().getUrl(); return String.format(\"%s：%s, Hello, %s\", url.getProtocol(), url.getPort(), name); &#125;&#125;// 客户端public class DemoServiceListenerImpl implements DemoServiceListener &#123; @Override public void changed(String msg) &#123; System.out.println(\"被回调了：\" + msg); &#125;&#125;@Reference(version = \"callback\")private DemoService demoService;System.out.println(demoService.sayHello(\"eleven\", \"d1\", new DemoServiceListenerImpl())); System.out.println(demoService.sayHello(\"eleven\", \"d2\", new DemoServiceListenerImpl())); System.out.println(demoService.sayHello(\"eleven\", \"d3\", new DemoServiceListenerImpl())); 异步调用Dubbo所有异步编程接口开始以CompletableFuture为基础，基于NIO的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小。 12345678910111213141516171819202122232425262728@Service(version = \"async\")public class AsyncDemoService implements DemoService &#123; @Override public String sayHello(String name) &#123; System.out.println(\"执行了同步服务\" + name); URL url = RpcContext.getContext().getUrl(); return String.format(\"%s：%s, Hello, %s\", url.getProtocol(), url.getPort(), name); // 正常访问 &#125; @Override public CompletableFuture&lt;String&gt; sayHelloAsync(String name) &#123; System.out.println(\"执行了异步服务\" + name); return CompletableFuture.supplyAsync(() -&gt; &#123; URL url = RpcContext.getContext().getUrl(); return String.format(\"%s：%s, Hello, %s\", url.getProtocol(), url.getPort(), name); // 正常访问 &#125;); &#125;&#125;@Reference(version = \"async\")private DemoService demoService;CompletableFuture&lt;String&gt; future = demoService.sayHelloAsync(\"异步调用\"); // 5future.whenComplete((v, t) -&gt; &#123; if (t != null) &#123; t.printStackTrace(); &#125; else &#123; System.out.println(\"Response: \" + v); &#125;&#125;); 泛化调用泛化调用可以用来做服务测试，某个服务想要支持泛化调用，可将该服务的generic属性设置为true，对于服务消费者来说，就可以不用依赖该服务的接口，直接利用GenericService接口来进行服务调用。 123456789101112131415// 方式一，通过服务消费者@Reference(id = \"demoService\", version = \"default\", interfaceName = \"com.eleven.icode.DemoService\", generic = true)private GenericService genericService;// 方式二，通过服务提供者@Service(interfaceName = \"com.eleven.icode.DemoService\", version = \"generic\")public class GenericDemoService implements GenericService &#123; @Override public Object $invoke(String s, String[] strings, Object[] objects) throws GenericException &#123; System.out.println(\"执行了generic服务\"); return \"执行的方法是\" + s; &#125;&#125;@Reference(version = \"generic\")private DemoService demoService; REST服务12dubbo.protocol.name=restdubbo.protocol.port=20880 12345678910111213@Service(version = \"rest\")@Path(value = \"demo\")public class RestDemoService implements DemoService &#123; @GET @Path(value = \"say\") @Produces(&#123;ContentType.APPLICATION_JSON_UTF_8, ContentType.TEXT_XML_UTF_8&#125;) @Override public String sayHello(@QueryParam(\"name\") String name) &#123; System.out.println(\"执行了rest服务\" + name); URL url = RpcContext.getContext().getUrl(); return String.format(\"%s: %s, Hello, %s\", url.getProtocol(), url.getPort(), name); // 正常访问 &#125;&#125;","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://yaoyinglong.github.io/tags/Dubbo/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Dubbo","slug":"Cloud/Dubbo","permalink":"https://yaoyinglong.github.io/categories/Cloud/Dubbo/"}]},{"title":"Netty进阶","date":"2021-12-10T16:00:00.000Z","path":"Blog/Cloud/Netty/Netty进阶/","text":"无锁串行化大多数场景下并行多线程处理可提升系统并发性能，但若对于共享资源并发访问处理不当，会带来严重锁竞争，最终会导致性能下降。为了尽可能避免锁竞争带来的性能损耗，可通过串行化设计，即消息处理尽可能在同一个线程内完成，期间不进行线程切换，就避免了多线程竞争和同步锁。NIO多路复用就是一种无锁串行化的设计思想。 为了尽可能提升性能，Netty采用了串行无锁化设计，在IO线程内部进行串行操作，避免多线程竞争导致的性能下降，表面上看串行化设计似乎CPU利用率不高并发程度不够。但通过调整NIO线程池的线程参数，可同时启动多个串行化线程并行运行，这种局部无锁化的串行线程设计相比一个队列多个工作线程模型性能更优。 Netty的NioEventLoop读取到消息后，直接调用ChannelPipeline的fireChannelRead(Object msg)，只要用户不主动切换线程，一直会由NioEventLoop调用到用户的Handler，期间不进行线程切换，这种串行化处理方式避免了多线程操作导致的锁的竞争，从性能角度看是最优的。 直接内存Direct Memory直接内存即堆外内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，某些情况下这部分内存也会被频繁使用，且也可能导致OutOfMemoryError异常出现，Java用DirectByteBuffer可分配一块直接内存，元空间对应的内存也叫作直接内存，它们对应的都是机器的物理内存。 运行程序可以很明显看出直接内存申请相对堆内存储较慢但访问效率高，Java虚拟机实现上，本地IO一般会直接操作直接内存，直接内存-&gt;系统调用-&gt;硬盘/网卡，而非直接内存则需要二次拷贝，堆内存-&gt;直接内存-&gt;系统调用-&gt;硬盘/网卡。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class DirectMemoryTest &#123; public static void heapAccess() &#123; long startTime = System.currentTimeMillis(); ByteBuffer buffer = ByteBuffer.allocate(1000); //分配堆内存 for (int i = 0; i &lt; 100000; i++) &#123; for (int j = 0; j &lt; 200; j++) &#123; buffer.putInt(j); &#125; buffer.flip(); for (int j = 0; j &lt; 200; j++) &#123; buffer.getInt(); &#125; buffer.clear(); &#125; long endTime = System.currentTimeMillis(); System.out.println(\"堆内存访问:\" + (endTime - startTime) + \"ms\"); &#125; public static void directAccess() &#123; long startTime = System.currentTimeMillis(); ByteBuffer buffer = ByteBuffer.allocateDirect(1000); //分配直接内存 for (int i = 0; i &lt; 100000; i++) &#123; for (int j = 0; j &lt; 200; j++) &#123; buffer.putInt(j); &#125; buffer.flip(); for (int j = 0; j &lt; 200; j++) &#123; buffer.getInt(); &#125; buffer.clear(); &#125; long endTime = System.currentTimeMillis(); System.out.println(\"直接内存访问:\" + (endTime - startTime) + \"ms\"); &#125; public static void heapAllocate() &#123; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; 100000; i++) &#123; ByteBuffer.allocate(100); &#125; long endTime = System.currentTimeMillis(); System.out.println(\"堆内存申请:\" + (endTime - startTime) + \"ms\"); &#125; public static void directAllocate() &#123; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; 100000; i++) &#123; ByteBuffer.allocateDirect(100); &#125; long endTime = System.currentTimeMillis(); System.out.println(\"直接内存申请:\" + (endTime - startTime) + \"ms\"); &#125; public static void main(String args[]) &#123; for (int i = 0; i &lt; 10; i++) &#123; heapAccess(); directAccess(); &#125; System.out.println(); for (int i = 0; i &lt; 10; i++) &#123; heapAllocate(); directAllocate(); &#125; &#125;&#125; Bits.reserveMemory判断是否有足够的直接内存空间分配，可通过-XX:MaxDirectMemorySize=&lt;size&gt;参数指定直接内存最大可分配空间，若不指定默认为最大堆内存大小，在分配直接内存时若发现空间不够会显示调用System.gc()触发一次full gc回收掉一部分无用的直接内存的引用对象，同时直接内存也会被释放掉，若释放完分配空间还是不够则抛出异常java.lang.OutOfMemoryError。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class DirectByteBuffer extends MappedByteBuffer implements DirectBuffer &#123; DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; // 调用unsafe本地方法分配直接内存 base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; // 使用Cleaner机制注册内存回收处理函数，当直接内存引用对象被GC清理掉时，会提前调用这里注册的释放直接内存的Deallocator线程对象的run方法 cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null; &#125;&#125;// 申请一块本地内存。内存空间是未初始化的，其内容是无法预期的，使用freeMemory释放内存，使用reallocateMemory修改内存大小public native long allocateMemory(long bytes);// openjdk8/hotspot/src/share/vm/prims/unsafe.cppUNSAFE_ENTRY(jlong, Unsafe_AllocateMemory(JNIEnv *env, jobject unsafe, jlong size)) UnsafeWrapper(\"Unsafe_AllocateMemory\"); size_t sz = (size_t)size; if (sz != (julong)size || size &lt; 0) &#123; THROW_0(vmSymbols::java_lang_IllegalArgumentException()); &#125; if (sz == 0) &#123; return 0; &#125; sz = round_to(sz, HeapWordSize); // 调用os::malloc申请内存，内部使用malloc这个C标准库的函数申请内存 void* x = os::malloc(sz, mtInternal); if (x == NULL) &#123; THROW_0(vmSymbols::java_lang_OutOfMemoryError()); &#125; //Copy::fill_to_words((HeapWord*)x, sz / HeapWordSize); return addr_to_java(x);UNSAFE_END 使用直接内存不会占用堆内空间，减少了发生GC的可能，Java虚拟机实现上本地IO会直接操作直接内存，而非直接内存则需要二次拷贝，但直接内存初始化会比较慢，没有JVM直接帮助管理内存，容易发生内存溢出。为了避免一直没有FULL GC，最终导致直接内存把物理内存耗完,可通过-XX:MaxDirectMemorySize指定直接内存的最大值，当达到阈值时调用system.gc来进行一次FULL GC，间接把没有被使用的直接内存回收。 Netty零拷贝 Netty接收和发送ByteBuf采用PooledUnsafeDirectByteBuf，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区二次拷贝。若使用JVM堆内存PooledUnsafeHeapByteBuf或UnpooledUnsafeHeapByteBuf进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中然后才能写入Socket中。JVM堆内存的数据是不能直接写入Socket中的。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 随着JVM虚拟机和JIT即时编译技术的发展，对象的分配和回收是个非常轻量级的工作。但缓冲区Buffer特别是堆外直接内存的分配和回收是一件耗时的操作。为了尽量重用缓冲区Netty提供了基于ByteBuf内存池缓冲区重用机制。需要的时候直接从缓冲池中获取ByteBuf使用即可，使用完毕之后就重新放回缓冲池。 客户端的发送数据事件最终调用AbstractNioByteChannel的NioByteUnsafe的read方法，通过MaxMessageHandle给ByteBuf分配内存，然后调用AbstractByteBufAllocator的directBuffer方法，最终在PooledByteBufAllocator的newDirectBuffer方法中通过PoolArena的子类DirectArena实现的缓冲区分配，最终执行PooledUnsafeDirectByteBuf的newInstance方法，通过RECYCLER的get方法循环使用ByteBuf对象，若为非内存池实现则直接创建一个新的ByteBuf对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108protected class NioByteUnsafe extends AbstractNioUnsafe &#123; public final void read() &#123; ChannelConfig config = AbstractNioByteChannel.this.config(); if (AbstractNioByteChannel.this.shouldBreakReadReady(config)) &#123; AbstractNioByteChannel.this.clearReadPending(); &#125; else &#123; ChannelPipeline pipeline = AbstractNioByteChannel.this.pipeline(); ByteBufAllocator allocator = config.getAllocator(); Handle allocHandle = this.recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try &#123; do &#123; byteBuf = allocHandle.allocate(allocator); // 分配内存 allocHandle.lastBytesRead(AbstractNioByteChannel.this.doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) &#123; byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; if (close) &#123; AbstractNioByteChannel.this.readPending = false; &#125; break; &#125; allocHandle.incMessagesRead(1); AbstractNioByteChannel.this.readPending = false; pipeline.fireChannelRead(byteBuf); byteBuf = null; &#125; while(allocHandle.continueReading()); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (close) &#123; this.closeOnRead(pipeline); &#125; &#125; catch (Throwable var11) &#123; this.handleReadException(pipeline, byteBuf, var11, close, allocHandle); &#125; finally &#123; if (!AbstractNioByteChannel.this.readPending &amp;&amp; !config.isAutoRead()) &#123; this.removeReadOp(); &#125; &#125; &#125; &#125;&#125;public abstract class MaxMessageHandle implements ExtendedHandle &#123; public ByteBuf allocate(ByteBufAllocator alloc) &#123; return alloc.ioBuffer(this.guess()); &#125;&#125;public abstract class AbstractByteBufAllocator implements ByteBufAllocator &#123; public ByteBuf ioBuffer(int initialCapacity) &#123; return PlatformDependent.hasUnsafe() ? this.directBuffer(initialCapacity) : this.heapBuffer(initialCapacity); &#125; public ByteBuf directBuffer(int initialCapacity) &#123; return this.directBuffer(initialCapacity, 2147483647); &#125; public ByteBuf directBuffer(int initialCapacity, int maxCapacity) &#123; if (initialCapacity == 0 &amp;&amp; maxCapacity == 0) &#123; return this.emptyBuf; &#125; else &#123; validate(initialCapacity, maxCapacity); return this.newDirectBuffer(initialCapacity, maxCapacity); &#125; &#125;&#125;public class PooledByteBufAllocator extends AbstractByteBufAllocator implements ByteBufAllocatorMetricProvider &#123; protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &#123; PoolThreadCache cache = (PoolThreadCache)this.threadCache.get(); PoolArena&lt;ByteBuffer&gt; directArena = cache.directArena; Object buf; if (directArena != null) &#123; buf = directArena.allocate(cache, initialCapacity, maxCapacity); &#125; else &#123; buf = PlatformDependent.hasUnsafe() ? UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) : new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); &#125; return toLeakAwareBuffer((ByteBuf)buf); &#125;&#125;abstract class PoolArena&lt;T&gt; implements PoolArenaMetric &#123; PooledByteBuf&lt;T&gt; allocate(PoolThreadCache cache, int reqCapacity, int maxCapacity) &#123; PooledByteBuf&lt;T&gt; buf = this.newByteBuf(maxCapacity); this.allocate(cache, buf, reqCapacity); return buf; &#125; static final class DirectArena extends PoolArena&lt;ByteBuffer&gt; &#123; protected PooledByteBuf&lt;ByteBuffer&gt; newByteBuf(int maxCapacity) &#123; return (PooledByteBuf)(HAS_UNSAFE ? PooledUnsafeDirectByteBuf.newInstance(maxCapacity) : PooledDirectByteBuf.newInstance(maxCapacity)); &#125; &#125;&#125;final class PooledDirectByteBuf extends PooledByteBuf&lt;ByteBuffer&gt; &#123; private static final Recycler&lt;PooledDirectByteBuf&gt; RECYCLER = new Recycler&lt;PooledDirectByteBuf&gt;() &#123; protected PooledDirectByteBuf newObject(Handle&lt;PooledDirectByteBuf&gt; handle) &#123; return new PooledDirectByteBuf(handle, 0); &#125; &#125;; static PooledDirectByteBuf newInstance(int maxCapacity) &#123; // 通过RECYCLER的get方法循环使用ByteBuf对象 PooledDirectByteBuf buf = (PooledDirectByteBuf)RECYCLER.get(); buf.reuse(maxCapacity); return buf; &#125; private PooledDirectByteBuf(Handle&lt;PooledDirectByteBuf&gt; recyclerHandle, int maxCapacity) &#123; super(recyclerHandle, maxCapacity); &#125;&#125; 灵活的TCP参数配置能力合理设置TCP参数在某些场景下对于性能的提升可以起到显著效果，如接收缓冲区SO_RCVBUF和发送缓冲区SO_SNDBUF若设置不当，对性能影响非常大，通常建议值为128K或256K。Netty在启动辅助类ChannelOption中可灵活的配置TCP参数，满足不同的用户场景。 ByteBuf扩容机制minNewCapacity表用户需要写入的值大小，threshold阈值为Bytebuf内部设定容量的最大值，maxCapacity为Netty最大能接受的容量大小一般为Integer的最大值。 Netty的ByteBuf需要动态扩容来满足需要，默认阈值为4MB，当需要的容量等于阈值，使用阈值作为新的缓存区容量，若大于阈值，采用每次步进4MB的方式进行内存扩张即(需要扩容值/4MB)*4MB，扩张后需要和最大内存maxCapacity进行比较，大于maxCapacity的z则用maxCapacity，否则使用扩容值，若小于阈值，采用倍增方式，以64字节作为基本数值，每次翻倍增长64-&gt;128-&gt;256，直到倍增后的结果大于或等于需要的容量值。 心跳检测机制在TCP长连接中客户端和服务器之间定期发送的一种特殊的数据包，通知对方自己还在线以确保TCP连接的有效性，Netty中实现心跳机制的关键是IdleStateHandler， readerIdleTimeSeconds：读超时即当在指定的时间间隔内没有从Channel读取到数据时，会触发一个READER_IDLE的IdleStateEvent事件 writerIdleTimeSeconds：写超时即当在指定的时间间隔内没有数据写入到Channel时，会触发一个WRITER_IDLE的IdleStateEvent事件 allIdleTimeSeconds：读/写超时即当在指定的时间间隔内没有读或写操作时，会触发一个ALL_IDLE的IdleStateEvent事件 1234567891011121314151617181920212223242526public class IdleStateHandler extends ChannelDuplexHandler &#123; public IdleStateHandler(int readerIdleTimeSeconds, int writerIdleTimeSeconds, int allIdleTimeSeconds) &#123; this(readerIdleTimeSeconds, writerIdleTimeSeconds, allIdleTimeSeconds, TimeUnit.SECONDS); &#125; public IdleStateHandler(boolean observeOutput, long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) &#123; if (unit == null) &#123; throw new NullPointerException(\"unit\"); &#125; this.observeOutput = observeOutput; if (readerIdleTime &lt;= 0) &#123; readerIdleTimeNanos = 0; &#125; else &#123; readerIdleTimeNanos = Math.max(unit.toNanos(readerIdleTime), MIN_TIMEOUT_NANOS); &#125; if (writerIdleTime &lt;= 0) &#123; writerIdleTimeNanos = 0; &#125; else &#123; writerIdleTimeNanos = Math.max(unit.toNanos(writerIdleTime), MIN_TIMEOUT_NANOS); &#125; if (allIdleTime &lt;= 0) &#123; allIdleTimeNanos = 0; &#125; else &#123; allIdleTimeNanos = Math.max(unit.toNanos(allIdleTime), MIN_TIMEOUT_NANOS); &#125; &#125;&#125; 要实现Netty服务端心跳检测机制需要在服务器端的ChannelInitializer中将IdleStateHandler添加到ChannelPipeline。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// 服务端EventLoopGroup boss = new NioEventLoopGroup();EventLoopGroup worker = new NioEventLoopGroup();try &#123; ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(boss, worker) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new IdleStateHandler(3, 0, 0, TimeUnit.SECONDS)); pipeline.addLast(new HeartBeatServerHandler()); &#125; &#125;); ChannelFuture future = bootstrap.bind(9000).sync(); future.channel().closeFuture().sync();&#125; catch (Exception e) &#123; e.printStackTrace();&#125; finally &#123; worker.shutdownGracefully(); boss.shutdownGracefully();&#125;public class HeartBeatServerHandler extends SimpleChannelInboundHandler&lt;String&gt; &#123; int readIdleTimes = 0; @Override protected void channelRead0(ChannelHandlerContext ctx, String s) throws Exception &#123; System.out.println(\" ====== &gt; [server] message received : \" + s); if (\"Heartbeat Packet\".equals(s)) &#123; ctx.channel().writeAndFlush(\"ok\"); &#125; else &#123; System.out.println(\" 其他信息处理 ... \"); &#125; &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; IdleStateEvent event = (IdleStateEvent) evt; String eventType = null; switch (event.state()) &#123; case READER_IDLE: eventType = \"读空闲\"; readIdleTimes++; // 读空闲的计数加1 break; case WRITER_IDLE: // 不处理 eventType = \"写空闲\"; break; case ALL_IDLE: // 不处理 eventType = \"读写空闲\"; break; &#125; System.out.println(ctx.channel().remoteAddress() + \"超时事件：\" + eventType); if (readIdleTimes &gt; 3) &#123; System.out.println(\" [server]读空闲超过3次，关闭连接，释放更多资源\"); ctx.channel().writeAndFlush(\"idle close\"); ctx.channel().close(); &#125; &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.err.println(\"=== \" + ctx.channel().remoteAddress() + \" is active ===\"); &#125;&#125;// 客户端EventLoopGroup eventLoopGroup = new NioEventLoopGroup();try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup).channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new HeartBeatClientHandler()); &#125; &#125;); Channel channel = bootstrap.connect(\"127.0.0.1\", 9000).sync().channel(); Random random = new Random(); while (channel.isActive()) &#123; int num = random.nextInt(8); Thread.sleep(num * 1000); channel.writeAndFlush(\"Heartbeat Packet\"); &#125;&#125; catch (Exception e) &#123; e.printStackTrace();&#125; finally &#123; eventLoopGroup.shutdownGracefully();&#125;static class HeartBeatClientHandler extends SimpleChannelInboundHandler&lt;String&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123; System.out.println(\" client received :\" + msg); if (msg != null &amp;&amp; msg.equals(\"idle close\")) &#123; System.out.println(\" 服务端关闭连接，客户端也关闭\"); ctx.channel().closeFuture(); &#125; &#125;&#125; channel准备就绪后就会调用IdleStateHandler的channelActive方法，然后调用initialize方法将对应读超时、写超时、或读写超时监听异步任务添加到延时线程池中。在channelRead读取数据时将reading置为true，数据读取完成后在channelReadComplete方法中将reading置为false，在ReaderIdleTimeoutTask中可以很明显看出若再读取中，则将任务直接放入延迟线程池中，否则计算是否超时，若超时则触发下一个handler的userEventTriggered方法，且将任务放会延迟线程池中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class IdleStateHandler extends ChannelDuplexHandler &#123; private byte state; // 0 - none, 1 - initialized, 2 - destroyed public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; initialize(ctx); super.channelActive(ctx); &#125; public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (readerIdleTimeNanos &gt; 0 || allIdleTimeNanos &gt; 0) &#123; // 配置了读超时或读写超时 reading = true; firstReaderIdleEvent = firstAllIdleEvent = true; &#125; ctx.fireChannelRead(msg); // 透传，不做任何业务逻辑处理 &#125; public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; if ((readerIdleTimeNanos &gt; 0 || allIdleTimeNanos &gt; 0) &amp;&amp; reading) &#123; lastReadTime = ticksInNanos(); // 获取当前系统时间 reading = false; &#125; ctx.fireChannelReadComplete(); &#125; public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; destroy(); super.channelInactive(ctx); &#125; private void initialize(ChannelHandlerContext ctx) &#123; switch (state) &#123; case 1: case 2: return; &#125; state = 1; initOutputChanged(ctx); lastReadTime = lastWriteTime = ticksInNanos(); if (readerIdleTimeNanos &gt; 0) &#123; // 若配置了读超时 readerIdleTimeout = schedule(ctx, new ReaderIdleTimeoutTask(ctx), readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (writerIdleTimeNanos &gt; 0) &#123; // 若配置了写超时 writerIdleTimeout = schedule(ctx, new WriterIdleTimeoutTask(ctx), writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (allIdleTimeNanos &gt; 0) &#123; // 若配置了读写超时 allIdleTimeout = schedule(ctx, new AllIdleTimeoutTask(ctx), allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; &#125; private final class ReaderIdleTimeoutTask extends AbstractIdleTask &#123; ReaderIdleTimeoutTask(ChannelHandlerContext ctx) &#123; super(ctx); &#125; @Override protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = readerIdleTimeNanos; if (!reading) &#123; // 当前时间减去最后一次channelRead方法调用的时间 nextDelay -= ticksInNanos() - lastReadTime; &#125; if (nextDelay &lt;= 0) &#123; // 若读取超时 readerIdleTimeout = schedule(ctx, this, readerIdleTimeNanos, TimeUnit.NANOSECONDS); boolean first = firstReaderIdleEvent; firstReaderIdleEvent = false; try &#123; IdleStateEvent event = newIdleStateEvent(IdleState.READER_IDLE, first); channelIdle(ctx, event); // 触发下一个handler的userEventTriggered方法 &#125; catch (Throwable t) &#123; ctx.fireExceptionCaught(t); &#125; &#125; else &#123; // Read occurred before the timeout - set a new timeout with shorter delay. readerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125; &#125; &#125; protected void channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt) throws Exception &#123; ctx.fireUserEventTriggered(evt); // 触发下一个handler的userEventTriggered方法 &#125; protected IdleStateEvent newIdleStateEvent(IdleState state, boolean first) &#123; switch (state) &#123; case ALL_IDLE: return first ? IdleStateEvent.FIRST_ALL_IDLE_STATE_EVENT : IdleStateEvent.ALL_IDLE_STATE_EVENT; case READER_IDLE: return first ? IdleStateEvent.FIRST_READER_IDLE_STATE_EVENT : IdleStateEvent.READER_IDLE_STATE_EVENT; case WRITER_IDLE: return first ? IdleStateEvent.FIRST_WRITER_IDLE_STATE_EVENT : IdleStateEvent.WRITER_IDLE_STATE_EVENT; default: throw new IllegalArgumentException(\"Unhandled: state=\" + state + \", first=\" + first); &#125; &#125; private void destroy() &#123; state = 2; if (readerIdleTimeout != null) &#123; readerIdleTimeout.cancel(false); readerIdleTimeout = null; &#125; if (writerIdleTimeout != null) &#123; writerIdleTimeout.cancel(false); writerIdleTimeout = null; &#125; if (allIdleTimeout != null) &#123; allIdleTimeout.cancel(false); allIdleTimeout = null; &#125; &#125;&#125;","tags":[{"name":"Netty","slug":"Netty","permalink":"https://yaoyinglong.github.io/tags/Netty/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Netty","slug":"Cloud/Netty","permalink":"https://yaoyinglong.github.io/categories/Cloud/Netty/"}]},{"title":"Netty源码","date":"2021-12-09T16:00:00.000Z","path":"Blog/Cloud/Netty/Netty源码/","text":"NioEventLoopGroup初始化NioEventLoopGroup时若未传入线程数，在调用超类MultithreadEventLoopGroup构造方法时使用CPU核数的两倍作为线程数。根据线程数创建EventExecutor数组，然后调用子类NioEventLoopGroup的newChild方法从而调用NioEventLoop的构造方法对EventExecutor数组中的每个元素实例化，在NioEventLoop的构造方法中调用openSelector()方法创建Selector，相当于NIO中Selector.open()。且在NioEventLoop超类SingleThreadEventExecutor中实例化了taskQueue任务队列。 对于chooser选择器的生成是调用的DefaultEventExecutorChooserFactory.INSTANCE的newChooser方法，通过isPowerOfTwo方法判断工作组的数量即Selector是否为2的整数次幂，然后创建具体的选择器，其实PowerOfTwoEventExecutorChooser和GenericEventExecutorChooser实现的逻辑其实是一样的都是将工作组当成一个环形依次取区中的元素，前者由于是2的整数次幂使用的是取模的方式，后者使用的是取余的方式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class NioEventLoopGroup extends MultithreadEventLoopGroup &#123; public NioEventLoopGroup() &#123; this(0); &#125; public NioEventLoopGroup(int nThreads) &#123; this(nThreads, (Executor) null); &#125; public NioEventLoopGroup(int nThreads, Executor executor) &#123; this(nThreads, executor, SelectorProvider.provider()); &#125; public NioEventLoopGroup(int nThreads, Executor executor, final SelectorProvider selectorProvider) &#123; this(nThreads, executor, selectorProvider, DefaultSelectStrategyFactory.INSTANCE); &#125; protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123; return new NioEventLoop(this, executor, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]); &#125;&#125;public abstract class MultithreadEventLoopGroup extends MultithreadEventExecutorGroup implements EventLoopGroup &#123; private static final int DEFAULT_EVENT_LOOP_THREADS; static &#123; // DEFAULT_EVENT_LOOP_THREADS默认为CPU核数的两倍 DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt(\"io.netty.eventLoopThreads\", NettyRuntime.availableProcessors() * 2)); &#125; protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) &#123; super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args); &#125;&#125;public abstract class MultithreadEventExecutorGroup extends AbstractEventExecutorGroup &#123; protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123; checkPositive(nThreads, \"nThreads\"); if (executor == null) &#123; executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); &#125; children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) &#123; boolean success = false; try &#123; children[i] = newChild(executor, args); success = true; &#125; catch (Exception e) &#123; throw new IllegalStateException(\"failed to create a child event loop\", e); &#125; &#125; chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() &#123; @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception &#123; if (terminatedChildren.incrementAndGet() == children.length) &#123; terminationFuture.setSuccess(null); &#125; &#125; &#125;; for (EventExecutor e: children) &#123; e.terminationFuture().addListener(terminationListener); &#125; Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); &#125;&#125;public final class NioEventLoop extends SingleThreadEventLoop &#123; NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); if (selectorProvider == null) &#123; throw new NullPointerException(\"selectorProvider\"); &#125; if (strategy == null) &#123; throw new NullPointerException(\"selectStrategy\"); &#125; provider = selectorProvider; final SelectorTuple selectorTuple = openSelector(); // 创建一个选择器selector，相当于NIO中的Selector.open() selector = selectorTuple.selector; unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy; &#125;&#125; ServerBootstrap使用时首先创建两个EventLoopGroup，然后创建一个ServerBootstrap通过channel方法设置NioServerSocketChannel作为服务器的通道实现，然后通过childHandler方法给ChannelPipeline添加Handler，最后调用bind方法绑定端口。 1234567891011121314EventLoopGroup bossGroup = new NioEventLoopGroup(3);EventLoopGroup workerGroup = new NioEventLoopGroup(8);ServerBootstrap bootstrap = new ServerBootstrap(); // 创建服务器端的启动对象// 使用链式编程来配置参数bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) // 使用NioServerSocketChannel作为服务器的通道实现 .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;//创建通道初始化对象，设置初始化参数，在SocketChannel建立起来之前执行 @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyServerHandler()); // 对workerGroup的SocketChannel设置处理器 &#125; &#125;);ChannelFuture cf = bootstrap.bind(9000).sync(); 调用ServerBootstrap的channel方法最终调用超类AbstractBootstrap的channel，在该方法中将传入的NioServerSocketChannel封装到ReflectiveChannelFactory中，在将该对象设置给channelFactory属性，后续使用时直接调用ReflectiveChannelFactory的newChannel方法从而调用NioServerSocketChannel的构造方法实例化。 NioServerSocketChannel构造方法中首先调用newSocket方法，调用SelectorProvider的openServerSocketChannel方法创建一个在本地端口进行监听的服务Socket通道，相当于NIO中调用ServerSocketChannel.open()方法。然后调用超类的构造方法初始化ChannelPipeline，且将NIO的ServerSocketChannel设置为非阻塞模式，且设置readInterestOp为对客户端accept连接操作感兴趣。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable &#123; public B channel(Class&lt;? extends C&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException(\"channelClass\"); &#125; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass)); &#125; public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) &#123; if (channelFactory == null) &#123; throw new NullPointerException(\"channelFactory\"); &#125; if (this.channelFactory != null) &#123; throw new IllegalStateException(\"channelFactory set already\"); &#125; this.channelFactory = channelFactory; return self(); &#125;&#125;public class ReflectiveChannelFactory&lt;T extends Channel&gt; implements ChannelFactory&lt;T&gt; &#123; private final Constructor&lt;? extends T&gt; constructor; public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) &#123; ObjectUtil.checkNotNull(clazz, \"clazz\"); try &#123; this.constructor = clazz.getConstructor(); &#125; catch (NoSuchMethodException e) &#123; throw new IllegalArgumentException(\"Class \" + StringUtil.simpleClassName(clazz) + \" does not have a public non-arg constructor\", e); &#125; &#125; @Override public T newChannel() &#123; try &#123; return constructor.newInstance(); &#125; catch (Throwable t) &#123; throw new ChannelException(\"Unable to create Channel from class \" + constructor.getDeclaringClass(), t); &#125; &#125;&#125;public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel &#123; private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); public NioServerSocketChannel() &#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER)); &#125; private static ServerSocketChannel newSocket(SelectorProvider provider) &#123; try &#123; // 调用NIO的ServerSocketChannel.open()方法，创建一个在本地端口进行监听的服务Socket通道 return provider.openServerSocketChannel(); &#125; catch (IOException e) &#123; throw new ChannelException(\"Failed to open a server socket.\", e); &#125; &#125; public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); // 对客户端accept连接操作感兴趣 config = new NioServerSocketChannelConfig(this, javaChannel().socket()); &#125;&#125;public abstract class AbstractNioMessageChannel extends AbstractNioChannel &#123; protected AbstractNioMessageChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent, ch, readInterestOp); &#125;&#125;public abstract class AbstractNioChannel extends AbstractChannel &#123; protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); // 初始化ChannelPipeline this.ch = ch; this.readInterestOp = readInterestOp; try &#123; // 将NIO的ServerSocketChannel设置为非阻塞模式 ch.configureBlocking(false); &#125; catch (IOException e) &#123; try &#123; ch.close(); &#125; catch (IOException e2) &#123; &#125; throw new ChannelException(\"Failed to enter non-blocking mode.\", e); &#125; &#125;&#125;public abstract class AbstractChannel extends DefaultAttributeMap implements Channel &#123; protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline(); // 初始化ChannelPipeline &#125; protected DefaultChannelPipeline newChannelPipeline() &#123; return new DefaultChannelPipeline(this); // 实例化ChannelPipeline &#125;&#125;public class DefaultChannelPipeline implements ChannelPipeline &#123; protected DefaultChannelPipeline(Channel channel) &#123; this.channel = ObjectUtil.checkNotNull(channel, \"channel\"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); // 创建ChannelPipeline的尾节点 head = new HeadContext(this); // 创建ChannelPipeline的头节点 head.next = tail; // 将head头节点的next指向tail尾节点 tail.prev = head; // 将tail尾节点的prev指向head头节点 &#125;&#125; 调用ServerBootstrap的bind方法最终调用超类AbstractBootstrap的bind，然后调用调用doBind方法，在initAndRegister方法首先调用ChannelFactory的newChannel方式，即调用ReflectiveChannelFactory的newChannel方法实例化NioServerSocketChannel对客户端accept连接操作感兴趣，且初始化ChannelPipeline。然后通过init方法给NioServerSocketChannel设置TCP参数，且将用户自定义的ChannelPipeline封装成ServerBootstrapAcceptor添加到ChannelPipeline。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable &#123; public ChannelFuture bind(int inetPort) &#123; return bind(new InetSocketAddress(inetPort)); &#125; public ChannelFuture bind(SocketAddress localAddress) &#123; validate(); if (localAddress == null) &#123; throw new NullPointerException(\"localAddress\"); &#125; return doBind(localAddress); &#125; public ChannelFuture bind(SocketAddress localAddress) &#123; validate(); if (localAddress == null) &#123; throw new NullPointerException(\"localAddress\"); &#125; return doBind(localAddress); &#125; private ChannelFuture doBind(final SocketAddress localAddress) &#123; final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; if (regFuture.isDone()) &#123; ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; &#125; else &#123; final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; promise.setFailure(cause); &#125; else &#123; promise.registered(); doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125; &#125; final ChannelFuture initAndRegister() &#123; Channel channel = null; // 实际类型为NioServerSocketChannel try &#123; // 实例化NioServerSocketChannel并初始化ChannelPipeline channel = channelFactory.newChannel(); // 这里就是调用前面ReflectiveChannelFactory的newChannel方法实例化NioServerSocketChannel init(channel); // 给NioServerSocketChannel设置options参数，将用户自定义的ChannelPipeline封装成ServerBootstrapAcceptor添加到ChannelPipeline &#125; catch (Throwable t) &#123; if (channel != null) &#123; channel.unsafe().closeForcibly(); return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &#125; return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); &#125; // 将ServerSocketChannel注册到BossGroup中的一个线程的Selector上 ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; return regFuture; &#125;&#125; AbstractBootstrap中的init方法会调用子类ServerBootstrap的init方法，首先设置NioServerSocketChannel的参数然后获取其中初始化好的ChannelPipeline，然后获取Worker Group和ServerBootstrap的childHandler方法设置的回调方法将其封装到ServerBootstrapAcceptor中，当有连接事件时调用channelRead方法将用户自定义的childHandler添加到ChannelPipeline中，且将连接过来的SocketChannel注册到WorkGroup中的一个线程的Selector上，和ServerSocketChannel注册到BossGroup走的同一个逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; &#123; void init(Channel channel) throws Exception &#123; final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) &#123; setChannelOptions(channel, options, logger); &#125; final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) &#123; for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) &#123; @SuppressWarnings(\"unchecked\") AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; ChannelPipeline p = channel.pipeline(); // 获取到在NioServerSocketChannel中初始化的ChannelPipeline final EventLoopGroup currentChildGroup = childGroup; // 即Worker Group final ChannelHandler currentChildHandler = childHandler; // ServerBootstrap的childHandler方法设置的回调方法 final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) &#123; currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); &#125; synchronized (childAttrs) &#123; currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); &#125; p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor(ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;); &#125;&#125;private static class ServerBootstrapAcceptor extends ChannelInboundHandlerAdapter &#123; private final EventLoopGroup childGroup; private final ChannelHandler childHandler; private final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] childOptions; private final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] childAttrs; private final Runnable enableAutoReadTask; ServerBootstrapAcceptor(final Channel channel, EventLoopGroup childGroup, ChannelHandler childHandler, Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] childOptions, Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] childAttrs) &#123; this.childGroup = childGroup; this.childHandler = childHandler; this.childOptions = childOptions; this.childAttrs = childAttrs; enableAutoReadTask = new Runnable() &#123; @Override public void run() &#123; channel.config().setAutoRead(true); &#125; &#125;; &#125; @Override @SuppressWarnings(\"unchecked\") public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; // 当有连接事件时调用channelRead方法将用户自定义的childHandler添加到ChannelPipeline中 final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) &#123; child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); &#125; try &#123; // 将连接过来的SocketChannel注册到WorkGroup中的一个线程的Selector上，和ServerSocketChannel注册到BossGroup走的同一个逻辑 // 这里调用的childGroup的register方法，实际是调用MultithreadEventLoopGroup的register方法 childGroup.register(child).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; forceClose(child, future.cause()); &#125; &#125; &#125;); &#125; catch (Throwable t) &#123; forceClose(child, t); &#125; &#125;&#125; 这里的next方法最终调用前面创建的PowerOfTwoEventExecutorChooser或GenericEventExecutorChooser的next方法从工作组中选择一个NioEventLoop来执行register方法。最终异步调用AbstractChannel的register0方法。首先调用AbstractNioChannel的doRegister方法将ServerSocketChannel注册到Selector上，相当于NIO中调用ServerSocketChannel的register方法。然后通过SingleThreadEventExecutor的execute方法将该任务添加到taskQueue异步执行AbstractChannel的register0方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public abstract class MultithreadEventLoopGroup extends MultithreadEventExecutorGroup implements EventLoopGroup &#123; public ChannelFuture register(Channel channel) &#123; // next方法最终调用前面创建的PowerOfTwoEventExecutorChooser或GenericEventExecutorChooser的next方法从工作组中选择一个NioEventLoop来执行register方法 return next().register(channel); &#125;&#125;public abstract class SingleThreadEventLoop extends SingleThreadEventExecutor implements EventLoop &#123; public ChannelFuture register(Channel channel) &#123; return register(new DefaultChannelPromise(channel, this)); &#125;&#125;public abstract class AbstractChannel extends DefaultAttributeMap implements Channel &#123; public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop == null) &#123; throw new NullPointerException(\"eventLoop\"); &#125; if (isRegistered()) &#123; promise.setFailure(new IllegalStateException(\"registered to an event loop already\")); return; &#125; if (!isCompatible(eventLoop)) &#123; promise.setFailure(new IllegalStateException(\"incompatible event loop type: \" + eventLoop.getClass().getName())); return; &#125; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; // 通过SingleThreadEventExecutor将该任务添加到taskQueue异步执行 eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; // 将ServerSocketChannel注册到Selector上，相当于NIO中调用ServerSocketChannel的register方法 register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; &#125; private void register0(ChannelPromise promise) &#123; try &#123; if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = neverRegistered; doRegister(); // 调用AbstractNioChannel把ServerSocketChannel注册到selector上 neverRegistered = false; registered = true; // 实际调用DefaultChannelPipeline的invokeHandlerAddedIfNeeded方法，最终调用ServerBootstrap的init方法中添加的ChannelInitializer，真正将ServerBootstrapAcceptor添加到ChannelPipeline pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // 调用pipeline中每个handler的channelRegistered方法 if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125;&#125;public abstract class AbstractNioChannel extends AbstractChannel &#123; protected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; // 相当于NIO中调用ServerSocketChannel的register方法，把ServerSocketChannel注册到selector上 selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; &#125; catch (CancelledKeyException e) &#123; if (!selected) &#123; eventLoop().selectNow(); selected = true; &#125; else &#123; throw e; &#125; &#125; &#125; &#125;&#125; 调用DefaultChannelPipeline的invokeHandlerAddedIfNeeded方法，最终调用ServerBootstrap的init方法中添加的ChannelInitializer，真正将ServerBootstrapAcceptor添加到ChannelPipeline。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class DefaultChannelPipeline implements ChannelPipeline &#123; final void invokeHandlerAddedIfNeeded() &#123; assert channel.eventLoop().inEventLoop(); if (firstRegistration) &#123; firstRegistration = false; callHandlerAddedForAllHandlers(); &#125; &#125; private void callHandlerAddedForAllHandlers() &#123; final PendingHandlerCallback pendingHandlerCallbackHead; synchronized (this) &#123; assert !registered; registered = true; pendingHandlerCallbackHead = this.pendingHandlerCallbackHead; this.pendingHandlerCallbackHead = null; &#125; PendingHandlerCallback task = pendingHandlerCallbackHead; while (task != null) &#123; task.execute(); task = task.next; &#125; &#125; private void callHandlerAdded0(final AbstractChannelHandlerContext ctx) &#123; try &#123; ctx.callHandlerAdded(); &#125; catch (Throwable t) &#123; boolean removed = false; try &#123; remove0(ctx); ctx.callHandlerRemoved(); removed = true; &#125; catch (Throwable t2) &#123; &#125; if (removed) &#123; fireExceptionCaught(new ChannelPipelineException(ctx.handler().getClass().getName() + \".handlerAdded() has thrown an exception; removed.\", t)); &#125; else &#123; fireExceptionCaught(new ChannelPipelineException(ctx.handler().getClass().getName() + \".handlerAdded() has thrown an exception; also failed to remove.\", t)); &#125; &#125; &#125;&#125;private final class PendingHandlerAddedTask extends PendingHandlerCallback &#123; PendingHandlerAddedTask(AbstractChannelHandlerContext ctx) &#123; super(ctx); &#125; @Override public void run() &#123; callHandlerAdded0(ctx); &#125; @Override void execute() &#123; EventExecutor executor = ctx.executor(); if (executor.inEventLoop()) &#123; callHandlerAdded0(ctx); &#125; else &#123; try &#123; executor.execute(this); &#125; catch (RejectedExecutionException e) &#123; remove0(ctx); ctx.setRemoved(); &#125; &#125; &#125;&#125;abstract class AbstractChannelHandlerContext implements ChannelHandlerContext, ResourceLeakHint &#123; final void callHandlerAdded() throws Exception &#123; if (setAddComplete()) &#123; handler().handlerAdded(this); &#125; &#125;&#125;public abstract class ChannelInitializer&lt;C extends Channel&gt; extends ChannelInboundHandlerAdapter &#123; public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; if (ctx.channel().isRegistered()) &#123; if (initChannel(ctx)) &#123; removeState(ctx); &#125; &#125; &#125; private boolean initChannel(ChannelHandlerContext ctx) throws Exception &#123; if (initMap.add(ctx)) &#123; try &#123; // 调用ServerBootstrap的init方法中添加的ChannelInitializer，真正将ServerBootstrapAcceptor添加到ChannelPipeline initChannel((C) ctx.channel()); &#125; catch (Throwable cause) &#123; exceptionCaught(ctx, cause); &#125; finally &#123; ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) &#123; pipeline.remove(this); &#125; &#125; return true; &#125; return false; &#125;&#125; 调用SingleThreadEventExecutor的execute方法首先将任务添加到队列taskQueue队列中，然后调用startThread方法最终调用SingleThreadEventExecutor的子类NioEventLoop的run方法。首先判断taskQueue队列中是否有任务需要处理，若没有则在NioEventLoop的select方法中调用Selector的select方法阻塞监听IO事件，且通过selectCnt变量来解决空轮训CPU100%的问题，若是空轮训selectCnt会一直++，当该数值大于等于默认512时，将重新创建Selector然后替换当前的Selector。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195public abstract class SingleThreadEventExecutor extends AbstractScheduledEventExecutor implements OrderedEventExecutor &#123; public void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(\"task\"); &#125; boolean inEventLoop = inEventLoop(); addTask(task); // 将任务添加到队列taskQueue队列中 if (!inEventLoop) &#123; startThread(); if (isShutdown()) &#123; boolean reject = false; try &#123; if (removeTask(task)) &#123; reject = true; &#125; &#125; catch (UnsupportedOperationException e) &#123; &#125; if (reject) &#123; reject(); &#125; &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125; &#125; private void startThread() &#123; if (state == ST_NOT_STARTED) &#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123; try &#123; doStartThread(); &#125; catch (Throwable cause) &#123; STATE_UPDATER.set(this, ST_NOT_STARTED); PlatformDependent.throwException(cause); &#125; &#125; &#125; &#125; private void doStartThread() &#123; assert thread == null; executor.execute(new Runnable() &#123; @Override public void run() &#123; thread = Thread.currentThread(); if (interrupted) &#123; thread.interrupt(); &#125; boolean success = false; updateLastExecutionTime(); try &#123; // 调用子类NioEventLoop的run方法 SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; &#125; &#125; &#125;); &#125;&#125;public final class NioEventLoop extends SingleThreadEventLoop &#123; protected void run() &#123; for (;;) &#123; try &#123; try &#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.BUSY_WAIT: case SelectStrategy.SELECT: // 若队列中没有任务 select(wakenUp.getAndSet(false)); // 监听IO事件 if (wakenUp.get()) &#123; selector.wakeup(); &#125; default: &#125; &#125; catch (IOException e) &#123; rebuildSelector0(); handleLoopException(e); continue; &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; try &#123; // Always handle shutdown even if the loop processing threw an exception. if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; return; &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; &#125; &#125; private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break; &#125; if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) &#123; selector.selectNow(); selectCnt = 1; break; &#125; int selectedKeys = selector.select(timeoutMillis); // 当timeoutMillis超时或有事件发生会break处理 selectCnt ++; // 用于解决空轮训CPU100%的问题 if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; break; &#125; if (Thread.interrupted()) &#123; selectCnt = 1; break; &#125; long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; selectCnt = 1; &#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; // 用于解决空轮训CPU100%的问题 selector = selectRebuildSelector(selectCnt); // 重新构建替换Selector selectCnt = 1; break; &#125; currentTimeNanos = time; &#125; &#125; catch (CancelledKeyException e) &#123; &#125; &#125;&#125;public abstract class SingleThreadEventExecutor extends AbstractScheduledEventExecutor implements OrderedEventExecutor &#123; protected boolean runAllTasks(long timeoutNanos) &#123; fetchFromScheduledTaskQueue(); Runnable task = pollTask(); if (task == null) &#123; afterRunningAllTasks(); return false; &#125; final long deadline = ScheduledFutureTask.nanoTime() + timeoutNanos; long runTasks = 0; long lastExecutionTime; for (;;) &#123; safeExecute(task); runTasks ++; if ((runTasks &amp; 0x3F) == 0) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); if (lastExecutionTime &gt;= deadline) &#123; break; &#125; &#125; task = pollTask(); if (task == null) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); break; &#125; &#125; afterRunningAllTasks(); this.lastExecutionTime = lastExecutionTime; return true; &#125;&#125;public abstract class AbstractEventExecutor extends AbstractExecutorService implements EventExecutor &#123; protected static void safeExecute(Runnable task) &#123; try &#123; task.run(); &#125; catch (Throwable t) &#123; &#125; &#125;&#125; 当有事件需要处理时调用NioEventLoop的processSelectedKeys方法，若是客户端的连接事件最终调用AbstractNioMessageChannel的NioMessageUnsafe的read方法处理客户端发送数据和连接请求事件。然后调用NioServerSocketChannel的doReadMessages方法获取SocketChannel，然后将SocketChannel包装为NioSocketChannel，且初始化ChannelPipeline将阻塞模式设置为非阻塞。然后调用ChannelPipeline的fireChannelRead方法，从而调用到前面封装用户自定义的childHandler的ServerBootstrapAcceptor的channelRead方法，将用户自定义的childHandler从BossGroup添加到WorkGroup，且将当前SocketChannel注册到WorkGroup中的一个Selector中。 值得注意的是将SocketChannel包装为NioSocketChannel时调用的超类AbstractNioByteChannel的构造方法中给SocketChannel绑定的感兴趣的时间为OP_READ事件，而前面NioServerSocketChannel构造方法中绑定的是OP_ACCEPT事件，从而将连接事件交给BossGroup处理，将发送数据的读写事件交给WorkGroup处理。且BossGroup和WorkGroup处理事件的逻辑是同一套逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156public final class NioEventLoop extends SingleThreadEventLoop &#123; private void processSelectedKeys() &#123; if (selectedKeys != null) &#123; processSelectedKeysOptimized(); &#125; else &#123; processSelectedKeysPlain(selector.selectedKeys()); &#125; &#125; private void processSelectedKeysOptimized() &#123; for (int i = 0; i &lt; selectedKeys.size; ++i) &#123; // 循环处理selectedKeys中所有的key final SelectionKey k = selectedKeys.keys[i]; selectedKeys.keys[i] = null; final Object a = k.attachment(); if (a instanceof AbstractNioChannel) &#123; processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); &#125; if (needsToSelectAgain) &#123; selectedKeys.reset(i + 1); selectAgain(); i = -1; &#125; &#125; &#125; private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) &#123; final EventLoop eventLoop; try &#123; eventLoop = ch.eventLoop(); &#125; catch (Throwable ignored) &#123; return; &#125; if (eventLoop != this || eventLoop == null) &#123; return; &#125; unsafe.close(unsafe.voidPromise()); return; &#125; try &#123; int readyOps = k.readyOps(); if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; // 移除OP_CONNECT事件 k.interestOps(ops); unsafe.finishConnect(); &#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; ch.unsafe().forceFlush(); // 处理写事件 &#125; if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); // 处理读事件，客户端发送数据或连接请求时会出发该方法 &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125; &#125;&#125;private final class NioMessageUnsafe extends AbstractNioUnsafe &#123; private final List&lt;Object&gt; readBuf = new ArrayList&lt;Object&gt;(); @Override public void read() &#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try &#123; try &#123; do &#123; int localRead = doReadMessages(readBuf); if (localRead == 0) &#123; break; &#125; if (localRead &lt; 0) &#123; closed = true; break; &#125; allocHandle.incMessagesRead(localRead); &#125; while (allocHandle.continueReading()); &#125; catch (Throwable t) &#123; exception = t; &#125; int size = readBuf.size(); // readBuf中存储的是OP_ACCEPT事件连接过来的所有NioSocketChannel for (int i = 0; i &lt; size; i ++) &#123; readPending = false; pipeline.fireChannelRead(readBuf.get(i)); // 调用ServerBootstrapAcceptor的channelRead方法 &#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (exception != null) &#123; closed = closeOnReadError(exception); pipeline.fireExceptionCaught(exception); &#125; if (closed) &#123; inputShutdown = true; if (isOpen()) &#123; close(voidPromise()); &#125; &#125; &#125; finally &#123; if (!readPending &amp;&amp; !config.isAutoRead()) &#123; removeReadOp(); &#125; &#125; &#125;&#125;public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel &#123; protected int doReadMessages(List&lt;Object&gt; buf) throws Exception &#123; SocketChannel ch = SocketUtils.accept(javaChannel()); // 获取SocketChannel try &#123; if (ch != null) &#123; // 将SocketChannel包装为NioSocketChannel，且初始化ChannelPipeline将阻塞模式设置为非阻塞 buf.add(new NioSocketChannel(this, ch)); return 1; &#125; &#125; catch (Throwable t) &#123; try &#123; ch.close(); &#125; catch (Throwable t2) &#123; &#125; &#125; return 0; &#125;&#125;public class NioSocketChannel extends AbstractNioByteChannel implements io.netty.channel.socket.SocketChannel &#123; public NioSocketChannel(Channel parent, SocketChannel socket) &#123; super(parent, socket); config = new NioSocketChannelConfig(this, socket.socket()); &#125;&#125;public abstract class AbstractNioByteChannel extends AbstractNioChannel &#123; protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &#123; super(parent, ch, SelectionKey.OP_READ); // 将channel感兴趣的事件设置为OP_READ &#125;&#125;public abstract class AbstractNioChannel extends AbstractChannel &#123; protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); // 调用超类AbstractChannel的构造方法初始化ChannelPipeline this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); // 设置为非阻塞模式 &#125; catch (IOException e) &#123; try &#123; ch.close(); &#125; catch (IOException e2) &#123; &#125; throw new ChannelException(\"Failed to enter non-blocking mode.\", e); &#125; &#125;&#125; 若是客户端的发送数据事件最终调用AbstractNioByteChannel的NioByteUnsafe的read方法，将接收到的数据调用SocketChannel中pipeline中所有hander的channelRead方法处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected class NioByteUnsafe extends AbstractNioUnsafe &#123; public final void read() &#123; final ChannelConfig config = config(); if (shouldBreakReadReady(config)) &#123; clearReadPending(); return; &#125; final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try &#123; do &#123; byteBuf = allocHandle.allocate(allocator); allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) &#123; byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; if (close) &#123; readPending = false; &#125; break; &#125; allocHandle.incMessagesRead(1); readPending = false; pipeline.fireChannelRead(byteBuf); // 调用SocketChannel中pipeline中所有hander的channelRead方法 byteBuf = null; &#125; while (allocHandle.continueReading()); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); // 调用SocketChannel中pipeline中所有hander的channelReadComplete方法 if (close) &#123; closeOnRead(pipeline); &#125; &#125; catch (Throwable t) &#123; handleReadException(pipeline, byteBuf, t, close, allocHandle); &#125; finally &#123; if (!readPending &amp;&amp; !config.isAutoRead()) &#123; removeReadOp(); &#125; &#125; &#125;&#125;","tags":[{"name":"Netty","slug":"Netty","permalink":"https://yaoyinglong.github.io/tags/Netty/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Netty","slug":"Cloud/Netty","permalink":"https://yaoyinglong.github.io/categories/Cloud/Netty/"}]},{"title":"Netty基础","date":"2021-12-08T16:00:00.000Z","path":"Blog/Cloud/Netty/Netty基础/","text":"NIO类库和API繁杂，使用麻烦需要熟练掌握Selector、ServerSocketChannel、SocketChannel、ByteBuffer等，且客户端断线重连、网络闪断、心跳处理、半包读写、 网络拥塞和异常流的处理等问题开发工作量和难度都非常大。 Netty对JDK自带的NIO的API进行了良好的封装，解决了上述问题。且Netty拥有高性能、吞吐量更高、延迟更低、减少资源消耗、最小化不必要的内存复制等优点。Netty现在都在用的是4.x，5.x版本已废弃，Netty4.x需要JDK6以上版本支持。 在分布式系统中，各个节点之间需要远程服务调用，高性能的RPC框架必不可少，Netty作为异步高性能通信框架，往往作为基础通信组件被这些RPC框架使用，RocketMQ、Dubbo、Zookeeper等底层就是用Netty作为基础通信组件，Hadoop高性能通信和序列化组件Avro的RPC框架，默认采用Netty进行跨界点通信，其Netty Service基于Netty框架二次封装实现。Netty作为高性能基础通信组件本身提供了TCP/UDP和HTTP协议栈。 Netty基本概念一个Netty应用通常由一个Bootstrap开始，主要作用是配置整个Netty程序串联各个组件，Netty中Bootstrap类是客户端程序的启动引导类，ServerBootstrap是服务端启动引导类。Netty中所有IO操作都是异步的不能立刻得知消息是否被正确处理，可过一会等它执行完成或直接注册一个监听，具体的实现就是通过Future和ChannelFutures，可注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件。 Channel是Netty网络通信组件，可用于执行网络I/O操作，Channel为用户提供当前网络连接通道状态，如是否打开、是否已连接，网络连接配置参数如接收缓冲区大小，提供异步的网络I/O操作如建立连接、读写、绑定端口等，异步调用意味着任何I/O调用都将立即返回，且不保证在调用结束时所请求的I/O操作已完成，调用立即返回一个ChannelFuture实例，通过注册监听器到ChannelFuture上可I/O操作成功、失败或取消时回调通知调用方，支持关联I/O操作与对应的处理程序。且不同协议、不同的阻塞类型的连接都有不同的Channel类型与之对应，涵盖了UDP和TCP网络IO以及文件IO： NioSocketChannel，异步的客户端TCP Socket连接 NioServerSocketChannel，异步的服务器端TCP Socket连接 NioDatagramChannel，异步的UDP连接 NioSctpChannel，异步的客户端Sctp连接 NioSctpServerChannel，异步的Sctp服务器端连接 Netty基于Selector对象实现I/O多路复用，通过Selector一个线程可以监听多个连接的Channel事件，当向一个Selector中注册Channel后，Selector内部机制就可自动不断地查询这些注册的Channel是否有已就绪的I/O事件，如可读、可写、网络连接完成等，这样程序就可以很简单地使用一个线程高效地管理多个Channel。 NioEventLoop中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用NioEventLoop的run方法，执行I/O任务和非I/O任务，I/O任务即SelectionKey中ready的事件如accept、connect、read、write等，由processSelectedKeys方法触发。非IO任务添加到taskQueue中的任务，如register0、bind0 等任务，由runAllTasks方法触发。 NioEventLoopGroup主要管理NioEventLoop的生命周期，可理解为一个线程池，内部维护了一组线程，每个NioEventLoop线程负责处理多个Channel上的事件，而一个Channel只对应于一个线程。 ChannelHandler是一个接口，处理I/O事件或拦截I/O操作并将其转发到其ChannelPipeline业务处理链中的下一个处理程序，ChannelHandler本身并没有提供很多方法，因为该接口有许多的方法需要实现，方便使用期间可继承用于处理入站I/O事件的子类ChannelInboundHandler和用于处理出站I/O事件的子类ChannelOutboundHandler。或使用ChannelInboundHandlerAdapter和ChannelOutboundHandlerAdapter适配器。 ChannelHandlerContext保存Channel相关的所有上下文信息，同时关联一个ChannelHandler对象。 ChannelPipline是保存ChannelHandler的List，用于处理或拦截Channel的入站事件和出站操作，ChannelPipeline实现了一种高级形式的拦截过滤器模式，使用户可完全控制事件处理方式，以及Channel中各个ChannelHandler如何相互交互，在Netty中每个Channel都有且仅有一个ChannelPipeline与之对应，而ChannelPipeline中又维护了一个由ChannelHandlerContext组成的双向链表，且每个ChannelHandlerContext中又关联着一个ChannelHandler。 read事件即入站事件和write事件即出站事件在一个双向链表中，入站事件会从链表head往后传递到最后一个入站的handler，出站事件会从链表tail往前传递到最前一个出站的handler，两种类型的handler互不干扰。 示例12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.35.Final&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 创建两个线程组bossGroup和workerGroup, 含有的子线程NioEventLoop的个数默认为cpu核数的两倍// bossGroup只是处理连接请求 ,真正的和客户端业务处理，会交给workerGroup完成EventLoopGroup bossGroup = new NioEventLoopGroup(3);EventLoopGroup workerGroup = new NioEventLoopGroup(8);try &#123; ServerBootstrap bootstrap = new ServerBootstrap(); // 创建服务器端的启动对象 // 使用链式编程来配置参数 bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) // 使用NioServerSocketChannel作为服务器的通道实现 // 初始化服务器连接队列大小，服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接。 // 多个客户端同时来的时候，服务端将不能处理客户端连接请求放在队列中等待处理 .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;//创建通道初始化对象，设置初始化参数，在SocketChannel建立起来之前执行 @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyServerHandler()); // 对workerGroup的SocketChannel设置处理器 &#125; &#125;); System.out.println(\"netty server start。。\"); // 绑定一个端口并且同步, 生成了一个ChannelFuture异步对象，通过isDone()等方法可以判断异步事件的执行情况 // 启动服务器并绑定端口，bind是异步操作，sync方法是等待异步操作执行完毕 ChannelFuture cf = bootstrap.bind(9000).sync(); // 给cf注册监听器，监听关心的事件 /*cf.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (cf.isSuccess()) &#123; System.out.println(\"监听端口9000成功\"); &#125; else &#123; System.out.println(\"监听端口9000失败\"); &#125; &#125; &#125;);*/ // 等待服务端监听端口关闭，closeFuture是异步操作 // 通过sync方法同步等待通道关闭处理完毕，这里会阻塞等待通道关闭完成，内部调用的是Object的wait()方法 cf.channel().closeFuture().sync();&#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully();&#125;/** * 自定义Handler需要继承netty规定好的某个HandlerAdapter(规范) */public class NettyServerHandler extends ChannelInboundHandlerAdapter &#123; /** * 当客户端连接服务器完成就会触发该方法 */ @Override public void channelActive(ChannelHandlerContext ctx) &#123; System.out.println(\"客户端连接通道建立完成\"); &#125; /** * 读取客户端发送的数据 * @param ctx 上下文对象, 含有通道channel，管道pipeline * @param msg 就是客户端发送的数据 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; //Channel channel = ctx.channel(); //ChannelPipeline pipeline = ctx.pipeline(); //本质是一个双向链接, 出站入站 // 将msg转成一个ByteBuf，类似NIO的ByteBuffer ByteBuf buf = (ByteBuf) msg; System.out.println(\"收到客户端的消息:\" + buf.toString(CharsetUtil.UTF_8)); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) &#123; // 数据读取完毕处理方法 ByteBuf buf = Unpooled.copiedBuffer(\"HelloClient\".getBytes(CharsetUtil.UTF_8)); ctx.writeAndFlush(buf); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; ctx.close(); // 处理异常, 一般是需要关闭通道 &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839EventLoopGroup group = new NioEventLoopGroup(); //客户端需要一个事件循环组try &#123; //创建客户端启动对象，注意客户端使用的不是ServerBootstrap而是Bootstrap Bootstrap bootstrap = new Bootstrap(); //设置相关参数 bootstrap.group(group) //设置线程组 .channel(NioSocketChannel.class) // 使用NioSocketChannel作为客户端的通道实现 .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyClientHandler()); //加入处理器 &#125; &#125;); System.out.println(\"netty client start。。\"); //启动客户端去连接服务器端 ChannelFuture cf = bootstrap.connect(\"127.0.0.1\", 9000).sync(); cf.channel().closeFuture().sync(); //对通道关闭进行监听&#125; finally &#123; group.shutdownGracefully();&#125;public class NettyClientHandler extends ChannelInboundHandlerAdapter &#123; // 当客户端连接服务器完成就会触发该方法 @Override public void channelActive(ChannelHandlerContext ctx) &#123; ByteBuf buf = Unpooled.copiedBuffer(\"HelloServer\".getBytes(CharsetUtil.UTF_8)); ctx.writeAndFlush(buf); &#125; // 当通道有读取事件时会触发，即服务端发送数据给客户端 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf buf = (ByteBuf) msg; System.out.println(\"收到服务端的消息:\" + buf.toString(CharsetUtil.UTF_8)); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; Handler生命周期回调接口调用顺序依次为： handlerAdded：新建立的连接会按照初始化策略，把handler添加到该channel的pipeline里面，即channel.pipeline.addLast(new LifeCycleInBoundHandler)执行完成后的回调 channelRegistered：当该连接分配到具体的Worker线程后，执行该回调 channelActive：channel准备工作完成，所有pipeline添加完成，并分配到具体的线上，说明该channel准备就绪可以使用了 channelRead：客户端向服务端发来数据，每次都会回调此方法，表示有数据可读 channelReadComplete：服务端每次读完一次完整的数据后，回调该方法表示数据读取完毕 channelInactive：当连接断开时该回调会被调用，底层TCP连接已被断开 channelUnRegistered：对应channelRegistered，当连接关闭后，释放绑定的Workder线程 channelUnRegistered：对应handlerAdded，将handler从该channel的pipeline移除后的回调方法 123456789101112131415161718192021222324252627282930313233343536373839404142public class LifeCycleInBoundHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"channelRegistered: channel注册到NioEventLoop\"); super.channelRegistered(ctx); &#125; @Override public void channelUnregistered(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"channelUnregistered: channel取消和NioEventLoop的绑定\"); super.channelUnregistered(ctx); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"channelActive: channel准备就绪\"); super.channelActive(ctx); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"channelInactive: channel被关闭\"); super.channelInactive(ctx); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(\"channelRead: channel中有可读的数据\" ); super.channelRead(ctx, msg); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"channelReadComplete: channel读数据完成\"); super.channelReadComplete(ctx); &#125; @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"handlerAdded: handler被添加到channel的pipeline\"); super.handlerAdded(ctx); &#125; @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"handlerRemoved: handler从channel的pipeline中移除\"); super.handlerRemoved(ctx); &#125;&#125; Netty线程模型 Netty抽象出BossGroup和WorkerGroup两组线程池，BossGroup专门负责接收客户端的连接，WorkerGroup专门负责网络的读写，BossGroup和WorkerGroup类型都是NioEventLoopGroup，NioEventLoopGroup相当于一个事件循环线程组，该组中含有多个事件循环线程，每个事件循环线程是NioEventLoop。 每个NioEventLoop都有一个Selector , 用于监听注册在其上的SocketChannel的网络通讯，每个Boss NioEventLoop线程内部循环执行如下步骤 处理Accept事件与Client建立连接，生成NioSocketChannel 将NioSocketChannel注册到某个Worker NIOEventLoop上的Selector 处理任务队列的任务， 即runAllTasks 每个Worker NIOEventLoop处理NioSocketChannel业务时会使用pipeline管道，管道中维护了很多Handler处理器用来处理Channel中的数据，线程循环执行如下步骤 轮询注册到当前Selector上的所有NioSocketChannel的read和write事件 处理I/O事件，即read , write事件，在对应NioSocketChannel处理业务 runAllTasks处理任务队列TaskQueue的任务，一些耗时业务处理一般可放入TaskQueue中慢慢处理，这样不影响数据在pipeline中的流动处理 ByteBufByteBuf由一串字节数组构成，ByteBuf提供了两个索引，分别用于读取数据和写入数据。这两个索引通过在字节数组中移动来定位需要读或者写信息的位置。当读ByteBuf时readerIndex读索引将会根据读取的字节数递增。当写ByteBuf时writerIndex会根据写入字节数进行递增。 通过readerindex和writerIndex和capacity，将buffer分成三个区域，已经读取区域[0, readerindex)，可读取区域[readerindex, writerIndex)，可写区域[writerIndex, capacity)。 若极限情况下readerIndex刚好读到writerIndex写入的地方，若readerIndex超过writerIndex时Netty会抛出 IndexOutOfBoundsException异常。 12345678910111213141516171819202122232425262728293031ByteBuf byteBuf = Unpooled.buffer(1);System.out.println(\"byteBuf=\" + byteBuf);for (int i = 0; i &lt; 8; i++) &#123; byteBuf.writeByte(i);&#125;System.out.println(\"byteBuf=\" + byteBuf);for (int i = 0; i &lt; 5; i++) &#123; System.out.println(byteBuf.getByte(i)); // readerIndex保持不变&#125;System.out.println(\"byteBuf=\" + byteBuf);for (int i = 0; i &lt; 5; i++) &#123; System.out.println(byteBuf.readByte()); // 移动readerIndex&#125;System.out.println(\"byteBuf=\" + byteBuf);//用Unpooled工具类创建ByteBufByteBuf byteBuf2 = Unpooled.copiedBuffer(\"hello,eleven!\", CharsetUtil.UTF_8);if (byteBuf2.hasArray()) &#123; //使用相关的方法 byte[] content = byteBuf2.array(); System.out.println(new String(content, CharsetUtil.UTF_8)); //将content转成字符串 System.out.println(\"byteBuf2=\" + byteBuf2); System.out.println(byteBuf2.getByte(0)); // 获取数组0这个位置的字符h的ascii码，h=104 int len = byteBuf2.readableBytes(); // 可读的字节数12 System.out.println(\"len=\" + len); for (int i = 0; i &lt; len; i++) &#123; //使用for取出各个字节 System.out.println((char) byteBuf2.getByte(i)); &#125; //范围读取 System.out.println(byteBuf2.getCharSequence(0, 6, CharsetUtil.UTF_8)); System.out.println(byteBuf2.getCharSequence(6, 6, CharsetUtil.UTF_8));&#125; 编码解码器通过Netty发送或接收消息时，会发生一次数据转换，入站消息被解码即从字节转换为另一种格式如Java对象，出站消息会被编码成字节。 Netty提供了一系列实用的编码解码器，都实现了ChannelInboundHadnler或ChannelOutboundHandler接口。编码解码器中channelRead方法已被重写，当调用解码器时将调用解码器所提供的decode()方法进行解码，并将已解码的字节转发给ChannelPipeline的下一个ChannelInboundHandler。 Netty提供了很多编解码器，如字符串编解码StringEncoder和StringDecoder，对象编解码ObjectEncoder和ObjectDecoder等。若要实现高效的编解码可用protobuf，但protobuf需要维护大量的proto文件比较麻烦。 protostuff是一个基于protobuf实现的序列化方法，它较于protobuf最明显的好处是，在几乎不损耗性能的情况下做到了不用写.proto文件来实现序列化。 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-api&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ProtostuffUtil &#123; private static Map&lt;Class&lt;?&gt;, Schema&lt;?&gt;&gt; cachedSchema = new ConcurrentHashMap&lt;Class&lt;?&gt;, Schema&lt;?&gt;&gt;(); private static &lt;T&gt; Schema&lt;T&gt; getSchema(Class&lt;T&gt; clazz) &#123; @SuppressWarnings(\"unchecked\") Schema&lt;T&gt; schema = (Schema&lt;T&gt;) cachedSchema.get(clazz); if (schema == null) &#123; schema = RuntimeSchema.getSchema(clazz); if (schema != null) &#123; cachedSchema.put(clazz, schema); &#125; &#125; return schema; &#125; /** * 序列化 */ public static &lt;T&gt; byte[] serializer(T obj) &#123; @SuppressWarnings(\"unchecked\") Class&lt;T&gt; clazz = (Class&lt;T&gt;) obj.getClass(); LinkedBuffer buffer = LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE); try &#123; Schema&lt;T&gt; schema = getSchema(clazz); return ProtostuffIOUtil.toByteArray(obj, schema, buffer); &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; finally &#123; buffer.clear(); &#125; &#125; /** * 反序列化 */ public static &lt;T&gt; T deserializer(byte[] data, Class&lt;T&gt; clazz) &#123; try &#123; T obj = clazz.newInstance(); Schema&lt;T&gt; schema = getSchema(clazz); ProtostuffIOUtil.mergeFrom(data, obj, schema); return obj; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; public static void main(String[] args) &#123; byte[] userBytes = ProtostuffUtil.serializer(new User(1, \"eleven\")); User user = ProtostuffUtil.deserializer(userBytes, User.class); System.out.println(user); &#125;&#125; 粘包拆包TCP是一个流协议即没有界限的一长串二进制数据，面向流的通信是无消息保护边界的。TCP作为传输层协议并不不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行数据包的划分，在业务上认为是一个完整的包，可能会被TCP拆分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。 解决粘包拆包比较常用的有消息定长度、在数据包尾部添加特殊分隔符、发送数据长度三种方式： 消息定长度：传输的数据大小固定长度，如每段长度固定为100字节，若不够空位补空格 在数据包尾部添加特殊分隔符：如下划线，中划线等，该方法简单易行，但选择分隔符时一定每条数据内部一定不能出现分隔符 发送长度：发送每条数据时，将数据的长度一并发送，如可选择每条数据的前4位是数据的长度，应用层处理时可根据长度来判断每条数据的开始和结束 Netty提供了多个解码器可进行分包的操作，也可通过继承ByteToMessageDecoder和MessageToByteEncoder自定义解码器： LineBasedFrameDecoder：回车换行分包 DelimiterBasedFrameDecoder：特殊分隔符分包 FixedLengthFrameDecoder：固定长度报文来分包 自动重连123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class NettyClient &#123; private String host; private int port; private Bootstrap bootstrap; private EventLoopGroup group; public static void main(String[] args) throws Exception &#123; NettyClient nettyClient = new NettyClient(\"localhost\", 9000); nettyClient.connect(); &#125; public NettyClient(String host, int port) &#123; this.host = host; this.port = port; init(); &#125; private void init() &#123; group = new NioEventLoopGroup(); //客户端需要一个事件循环组 bootstrap = new Bootstrap(); // bootstrap 可重用, 只需在NettyClient实例化的时候初始化即可. bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyClientHandler(NettyClient.this)); //加入处理器 &#125; &#125;); &#125; public void connect() throws Exception &#123; System.out.println(\"netty client start。。\"); ChannelFuture cf = bootstrap.connect(host, port); //启动客户端去连接服务器端 cf.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; //重连交给后端线程执行 future.channel().eventLoop().schedule(() -&gt; &#123; System.err.println(\"重连服务端...\"); try &#123; connect(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, 3000, TimeUnit.MILLISECONDS); &#125; else &#123; System.out.println(\"服务端连接成功...\"); &#125; &#125; &#125;); cf.channel().closeFuture().sync(); //对通道关闭进行监听 &#125;&#125;public class NettyClientHandler extends ChannelInboundHandlerAdapter &#123; private NettyClient nettyClient; public NettyClientHandler(NettyClient nettyClient) &#123; this.nettyClient = nettyClient; &#125; // channel 处于不活动状态时调用 @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; nettyClient.connect(); // channel处于不活动状态时调用重连 &#125;&#125;","tags":[{"name":"Netty","slug":"Netty","permalink":"https://yaoyinglong.github.io/tags/Netty/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Netty","slug":"Cloud/Netty","permalink":"https://yaoyinglong.github.io/categories/Cloud/Netty/"}]},{"title":"IO模型基础","date":"2021-12-08T16:00:00.000Z","path":"Blog/Cloud/Netty/IO模型基础/","text":"IO模型就是用怎样的通道进行数据的发送和接收，Java共支持BIO，NIO，AIO3种网络编程IO模型。 BIO BIO是同步阻塞模型，一个客户端连接对应一个处理线程，ServerSocket的accept方法是一个阻塞方法，若没有客户端链接将被阻塞，且服务端在接收客户端数据从输入流中读取数据时若没有数据可读也会被阻塞。同样客户端在通过输入流接收服务端回传的数据没有数据时也会被阻塞，若连接不做数据读写操作会导致线程阻塞浪费资源。 12345678910111213141516171819// 服务端ServerSocket serverSocket = new ServerSocket(9000);final Socket clientSocket = serverSocket.accept(); // 阻塞方法，没有连接时被阻塞byte[] bytes = new byte[1024];int read = socket.getInputStream().read(bytes); // 接收客户端的数据，没有数据可读时阻塞if (read != -1) &#123; System.out.println(\"接收到客户端数据：\" + new String(bytes, 0, read));&#125;socket.getOutputStream().write(\"HelloClient\".getBytes()); // 向客户端发送数据socket.getOutputStream().flush();socket.close(); // 关闭客户端// 客户端Socket socket = new Socket(\"localhost\", 9000);socket.getOutputStream().write(\"HelloServer\".getBytes()); //向服务端发送数据socket.getOutputStream().flush();byte[] bytes = new byte[1024];socket.getInputStream().read(bytes); // 接收服务端回传的数据，没有数据时阻塞System.out.println(\"接收到服务端的数据：\" + new String(bytes));socket.close(); 若想同一个连接可不断的收发数据，但该方式只能处理一个请求 1234567891011121314151617181920// 服务端ServerSocket serverSocket = new ServerSocket(9000);final Socket clientSocket = serverSocket.accept(); // 阻塞方法，没有连接时被阻塞while (true) &#123; byte[] bytes = new byte[1024]; int read = clientSocket.getInputStream().read(bytes); // 接收客户端的数据，没有数据可读时阻塞 if (read != -1) &#123; System.out.println(\"接收到客户端数据：\" + new String(bytes, 0, read)); &#125; else &#123; clientSocket.close(); &#125;&#125;// 客户端Socket socket = new Socket(\"localhost\", 9000);Scanner scanner = new Scanner(System.in);while (scanner.hasNextLine()) &#123; String msg = scanner.nextLine(); socket.getOutputStream().write(msg.getBytes()); // 向服务端发送数据 socket.getOutputStream().flush();&#125; 为了处理多个请求，可将数据的处理改为异步的，但若请求非常多会导致线程数非常多，会导致服务器线程太多，压力太大，如C10K问题。BIO方式适用于连接数目比较小且固定的架构， 该方式对服务器资源要求比较高， 但程序简单易理解。 12345678910111213141516171819202122// 服务端ServerSocket serverSocket = new ServerSocket(9000);while (true) &#123; final Socket clientSocket = serverSocket.accept(); new Thread(new Runnable() &#123; public void run() &#123; try &#123; while (true) &#123; byte[] bytes = new byte[1024]; int read = clientSocket.getInputStream().read(bytes); // 接收客户端的数据，没有数据可读时阻塞 if (read != -1) &#123; System.out.println(\"接收到客户端数据：\" + new String(bytes, 0, read)); &#125; else &#123; clientSocket.close(); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start();&#125; NIO同步非阻塞，服务器实现模式为一个线程可处理多个请求连接，客户端发送的连接请求都会注册到多路复用器Selector上，多路复用器轮询到连接有IO请求就进行处理。NIO适用于连接数目多且连接比较短的轻操作架构， 比聊天服务器、弹幕系统、服务器间通讯，但编程比较复杂。 1234567891011121314151617181920212223242526static List&lt;SocketChannel&gt; channelList = new ArrayList&lt;&gt;(); // 保存客户端连接public static void main(String[] args) throws IOException &#123; // 创建NIO ServerSocketChannel,与BIO的serverSocket类似 ServerSocketChannel serverSocket = ServerSocketChannel.open(); serverSocket.socket().bind(new InetSocketAddress(9000)); serverSocket.configureBlocking(false); // 设置ServerSocketChannel为非阻塞 while (true) &#123; // 非阻塞模式accept方法不会阻塞，NIO非阻塞是由操作系统内部实现的，底层调用了linux内核的accept函数 SocketChannel socketChannel = serverSocket.accept(); if (socketChannel != null) &#123; // 如果有客户端进行连接 socketChannel.configureBlocking(false); // 设置SocketChannel为非阻塞 channelList.add(socketChannel); // 保存客户端连接在List中 &#125; Iterator&lt;SocketChannel&gt; iterator = channelList.iterator(); while (iterator.hasNext()) &#123; // 遍历连接进行数据读取 SocketChannel sc = iterator.next(); ByteBuffer byteBuffer = ByteBuffer.allocate(128); int len = sc.read(byteBuffer); // 非阻塞模式read方法不会阻塞，否则会阻塞 if (len &gt; 0) &#123; // 若有数据，把数据打印出来 System.out.println(\"接收到消息：\" + new String(byteBuffer.array())); &#125; else if (len == -1) &#123; // 若客户端断开，把socket从集合中去掉 iterator.remove(); &#125; &#125; &#125;&#125; 若连接数太多会有大量无效遍历，且由于NIO非阻塞外层循环会一直执行，若有10000个连接，其中只有1000个连接有写数据，但由于其他9000个连接并没有断开，每次还是轮询遍历一万次，其中有十分之九的遍历都是无效的。引入多路复用器，当没有事件处理时程序将阻塞在Selector的select()方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// 服务端ServerSocketChannel serverSocket = ServerSocketChannel.open(); // 创建NIO ServerSocketChannelserverSocket.socket().bind(new InetSocketAddress(9000));serverSocket.configureBlocking(false); // 设置ServerSocketChannel为非阻塞Selector selector = Selector.open(); // 打开Selector处理Channel，即创建epoll// 把ServerSocketChannel注册到selector上，并且selector对客户端accept连接操作感兴趣SelectionKey selectionKey = serverSocket.register(selector, SelectionKey.OP_ACCEPT);while (true) &#123; selector.select(); // 阻塞等待需要处理的事件发生 // 获取selector中注册的全部事件的SelectionKey实例 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; // 遍历SelectionKey对事件进行处理 SelectionKey key = iterator.next(); iterator.remove(); //从事件集合里删除本次处理的key，防止下次select重复处理 if (key.isAcceptable()) &#123; // 如果是OP_ACCEPT事件，则进行连接获取和事件注册 ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); // 处理完连接请求不会继续等待客户端的数据发送 sc.configureBlocking(false); sc.register(key.selector(), SelectionKey.OP_READ); // 通过Selector监听Channel时对读事件感兴趣 &#125; else if (key.isReadable()) &#123; SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); // NIO非阻塞体现: 首先read方法不会阻塞，其次这种事件响应模型，当调用到read方法时肯定是发生了客户端发送数据的事件 int len = sc.read(buffer); if (len != -1) &#123; // 如果有数据，把数据打印出来 System.out.println(\"读取到客户端发送的数据：\" + new String(buffer.array(), 0, len)); &#125; else if (len == -1) &#123; // 如果客户端断开连接，关闭Socket socketChannel.close(); &#125; ByteBuffer bufferToWrite = ByteBuffer.wrap(\"helloClient\".getBytes()); sc.write(bufferToWrite); // 向客户端发送数据 key.interestOps(SelectionKey.OP_READ | SelectionKey.OP_WRITE); // 通过Selector监听Channel时对读写事件感兴趣 &#125; else if (key.isWritable())&#123; SocketChannel sc = (SocketChannel) key.channel(); System.out.println(\"write事件\"); // NIO事件触发是水平触发，使用Java的NIO编程时，在没有数据可以往外写的时候要取消写事件，在有数据往外写的时候再注册写事件 key.interestOps(SelectionKey.OP_READ); &#125; &#125;&#125;// 客户端SocketChannel clientChannel = SocketChannel.open(); // 获得一个Socket通道clientChannel.configureBlocking(false); // 设置通道为非阻塞Selector selector = Selector.open(); // 获得一个通道管理器// 客户端连接服务器，需要在listen方法中调用channel.finishConnect()才能完成连接clientChannel.connect(new InetSocketAddress(\"127.0.0.1\", 9000));//将通道管理器和该通道绑定，并为该通道注册SelectionKey.OP_CONNECT事件。clientChannel.register(selector, SelectionKey.OP_CONNECT);while (true) &#123; // 轮询访问selector selector.select(); Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator(); while (it.hasNext()) &#123; // 遍历SelectionKey对事件进行处理 SelectionKey key = (SelectionKey) it.next(); it.remove(); // 删除已选的key,以防重复处理 if (key.isConnectable()) &#123; // 连接事件发生 SocketChannel channel = (SocketChannel) key.channel(); if (channel.isConnectionPending()) &#123; channel.finishConnect(); // 如果正在连接，则完成连接 &#125; channel.configureBlocking(false); // 设置成非阻塞 ByteBuffer buffer = ByteBuffer.wrap(\"HelloServer\".getBytes()); channel.write(buffer); //给服务端发送信息 // 在和服务端连接成功之后，为了可以接收到服务端的信息，需要给通道设置读的权限。 channel.register(selector, SelectionKey.OP_READ); // 获得了可读的事件 &#125; else if (key.isReadable()) &#123; // 和服务端的read方法一样，服务器可读取消息，得到事件发生的Socket通道 SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); // 创建读取的缓冲区 int len = channel.read(buffer); if (len != -1) &#123; System.out.println(\"客户端收到信息：\" + new String(buffer.array(), 0, len)); &#125; &#125; &#125;&#125; NIO有Channel通道、Buffer缓冲区、Selector多路复用器三大核心组件： Channel类似于流，每个Channel对应一个Buffer缓冲区，Buffer底层是个数组 Channel会注册到Selector上，由Selector根据Channel读写事件的发生将其交由某个空闲的线程处理 NIO的Buffer和Channel都是既可读也可写 NIO底层在JDK1.4版本是用Linux内核函数select()或poll()来实现，Selector每次都会轮询所有SockChannel看哪个Channel有事件，有的话就处理，没有就继续遍历，JDK1.5开始引入了Linux内核函数基于事件响应机制的epoll来优化NIO。 在Linux环境中调用Selector的open()方法时调用EPollSelectorProvider.openSelector()方法创建EPollArrayWrapper对象，最终调用native方法epollCreate()方法从而调用Linux内核函数epoll_create创建epoll实例。然后调用SelectableChannel的register方法时，将SelectableChannel添加到EPollArrayWrapper内部集合中。 当调用Selector的select()方法时调用EPollSelectorImpl的doSelect方法，从EPollArrayWrapper内部集合中poll数据，然后调用epollCtl方法最终调用native方法epollCtl从而调用Linux内核函数epoll_ctl，然后调用native方法epollWait方法最终调用Linux内核方法epoll_wait等待epoll实例上的事件，当Socket收到数据后，中断程序调用回调函数给epoll实例的事件就绪列表rdlist中添加该Socket引用，这是由操作系统实现的，当程序执行到epoll_wait时，若rdlist已经引用了Socket则直接返回，若rdlist为空阻塞进程。 NIO整个调用流程就是Java调用操作系统的内核函数来创建Socket，获取到Socket文件描述符，再创建一个Selector对象，对应操作系统的Epoll描述符，将获取到的Socket连接的文件描述符的事件绑定到Selector对应的Epoll文件描述符上，进行事件的异步通知，就实现了使用一个线程且不需要太多的无效的遍历，将事件处理交给了操作系统内核中断程序实现，大大提高了效率。 AIOJDK7开始支持AIO异步非阻塞， 由操作系统完成后回调通知，服务端程序启动线程去处理通知， 一般适用于连接数较多且连接时间较长的应用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 服务端ExecutorService executorService = Executors.newCachedThreadPool(); // 也可不设置线程池//initialSize代表使用几个线程池处理AsynchronousChannelGroup threadGroup = AsynchronousChannelGroup.withCachedThreadPool(executorService, 1);final AsynchronousServerSocketChannel serverChannel = AsynchronousServerSocketChannel.open(threadGroup).bind(new InetSocketAddress(9000));serverChannel.accept(null, new CompletionHandler&lt;AsynchronousSocketChannel, Object&gt;() &#123; @Override public void completed(AsynchronousSocketChannel socketChannel, Object attachment) &#123; try &#123; System.out.println(\"2--\"+Thread.currentThread().getName()); // 再此接收客户端连接，如果不写这行代码后面的客户端连接连不上服务端 serverChannel.accept(attachment, this); System.out.println(socketChannel.getRemoteAddress()); ByteBuffer buffer = ByteBuffer.allocate(1024); socketChannel.read(buffer, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; System.out.println(\"3--\"+Thread.currentThread().getName()); buffer.flip(); System.out.println(new String(buffer.array(), 0, result)); socketChannel.write(ByteBuffer.wrap(\"HelloClient\".getBytes())); &#125; @Override public void failed(Throwable exc, ByteBuffer buffer) &#123; exc.printStackTrace(); &#125; &#125;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, Object attachment) &#123; exc.printStackTrace(); &#125;&#125;);System.out.println(\"1--\"+Thread.currentThread().getName());Thread.sleep(Integer.MAX_VALUE);// 客户端AsynchronousSocketChannel socketChannel = AsynchronousSocketChannel.open();socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 9000)).get();socketChannel.write(ByteBuffer.wrap(\"HelloServer\".getBytes()));ByteBuffer buffer = ByteBuffer.allocate(512);Integer len = socketChannel.read(buffer).get();if (len != -1) &#123; System.out.println(\"客户端收到信息：\" + new String(buffer.array(), 0, len));&#125;","tags":[{"name":"Netty","slug":"Netty","permalink":"https://yaoyinglong.github.io/tags/Netty/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Netty","slug":"Cloud/Netty","permalink":"https://yaoyinglong.github.io/categories/Cloud/Netty/"}]},{"title":"ShardingSphere基础","date":"2021-12-07T16:00:00.000Z","path":"Blog/DB/ShardingSphere基础/","text":"ShardingSphere包含ShardingJDBC、ShardingProxy和ShardingSidecar三个重要的产品。ShardingJDBC是用来做客户端分库分表的产品，而ShardingProxy是用来做服务端分库分表的产品，其中ShardingSidecar是针对Service Mesh定位的一个分库分表插件。 ShardingJDBC为轻量级Java框架，是客户端的一个工具包，在Java的JDBC层提供的额外服务。它使⽤客户端直连数据库，以Jar包形式提供服务无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。所有分库分表逻辑均由业务方自己控制，功能相对灵活，支持的数据库也非常多，但对业务侵入大，需要业务方自己定制所有的分库分表逻辑。 ShardingProxy为透明化的数据库代理端，是一个独立部署的服务，提供封装了数据库二进制协议的服务端版本，⽤于完成对异构语言的⽀持。对业务方无侵入，业务方可以像用一个普通的MySQL服务一样进行数据交互，基本上感觉不到后端分库分表逻辑的存在，但也意味着功能会比较固定，能够支持的数据库也比较少；目前提供MySQL和PostgreSQL版本，可使用任何兼容MySQL/PostgreSQL协议的访问客户端。 ShardingSphere核心功能是数据分片和读写分离，通过ShardingJDBC应用可透明的使用JDBC访问已经分库分表、读写分离的多个数据源，而不用关心数据源的数量以及数据如何分布。 逻辑表：水平拆分的数据库的相同逻辑和数据结构表的总称 真实表：在分片的数据库中真实存在的物理表 数据节点：数据分片的最小单元，由数据源名称和数据表组成 绑定表：分片规则一致的主表和子表 广播表：也叫公共表指所有分片数据源中都存在的表，表结构和表中的数据在每个数据库中都完全一致 分片键：用于分片的数据库字段，是将数据库或表进行水平拆分的关键字段，SQL中若没有分片字段，将会执行全路由，性能会很差。 分片算法：通过分片算法将数据进行分片，支持通过=、BETWEEN和IN分片，分片算法需要由应用开发者自行实现，灵活度非常高 分片策略：真正用于进行分片操作的是分片键+分片算法即分片策略，在ShardingJDBC中一般采用基于Groovy表达式的inline分片策略，通过一个包含分片键的算法表达式来制定分片策略，如t_user_$-&gt;{u_id%8}。 分片算法ShardingJDBC整个分库分表的核心在于配置的分片算法，使用inline分片算法提供一个分片键和一个分片表达式来制定分片算法，该方式配置简单，功能灵活，是分库分表最佳的配置方式，且可满足绝大多数分库分片场景。但若针对一些更为复杂的分片策略，如多分片键、按范围分片等场景，inline分片算法就不能满足了，ShardingSphere还提供的其他几种分片策略，目前提供了五种分片策略。 NoneShardingStrategy不分片，严格来说不算是一种分片策略了，只是ShardingSphere也提供了这么一个配置。 InlineShardingStrategy最常用的分片方式，通过inline.sharding-column配置分片键，通过algorithm-expression配置分片表达式，最终按照分片表达式来进行分片。通过table-strategy配置表的分片策略，通过database-strategy配置库的分片策略。 123456# inline分片策略spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cidspring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;&#123;cid%2+1&#125;spring.shardingsphere.sharding.tables.course.database-strategy.inline.sharding-column=cidspring.shardingsphere.sharding.tables.course.database-strategy.inline.algorithm-expression=m$-&gt;&#123;cid%2+1&#125; StandardShardingStrategy只支持单分片键的标准分片策略，通过standard.sharding-column配置分片键，通过standard.precise-algorithm-class-name配置按照=或IN逻辑的精确分片算法类名且该类必须实现io.shardingsphere.api.algorithm.sharding.standard.PreciseShardingAlgorithm接口，通过standard.range-algorithm-class-name配置按照Between条件进行的范围分片算法类名且该类必须实现io.shardingsphere.api.algorithm.sharding.standard.RangeShardingAlgorithm接口，分库和分表的精确分片算法和范围分片算法都是实现这两个接口。精确分片算法是必须提供的，范围分片算法是可选的。 1234567spring.shardingsphere.sharding.tables.course.table-strategy.standard.sharding-column=cidspring.shardingsphere.sharding.tables.course.table-strategy.standard.precise-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyPreciseTableShardingAlgorithmspring.shardingsphere.sharding.tables.course.table-strategy.standard.range-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyRangeTableShardingAlgorithmspring.shardingsphere.sharding.tables.course.database-strategy.standard.sharding-column=cidspring.shardingsphere.sharding.tables.course.database-strategy.standard.precise-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyPreciseDSShardingAlgorithmspring.shardingsphere.sharding.tables.course.database-strategy.standard.range-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyRangeDSShardingAlgorithm 12345678910111213141516public class MyPreciseTableShardingAlgorithm implements PreciseShardingAlgorithm&lt;Long&gt; &#123; @Override public String doSharding(Collection&lt;String&gt; availableTargetNames, PreciseShardingValue&lt;Long&gt; shardingValue) &#123; String logicTableName = shardingValue.getLogicTableName(); // 获取逻辑表 String cid = shardingValue.getColumnName(); // 获取分片键 Long cidValue = shardingValue.getValue(); // 实现 course_$-&gt;&#123;cid%2+1) BigInteger shardingValueB = BigInteger.valueOf(cidValue); BigInteger resB = shardingValueB.mod(new BigInteger(\"2\")).add(new BigInteger(\"1\")); String key = logicTableName + \"_\" + resB; if (availableTargetNames.contains(key)) &#123; // couse_1, course_2 return key; &#125; throw new UnsupportedOperationException(\"route \" + key + \" is not supported ,please check your config\"); &#125;&#125; 1234567891011public class MyRangeTableShardingAlgorithm implements RangeShardingAlgorithm&lt;Long&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, RangeShardingValue&lt;Long&gt; shardingValue) &#123; // select * from course where cid between 1 and 100; Long upperVal = shardingValue.getValueRange().upperEndpoint(); //100 Long lowerVal = shardingValue.getValueRange().lowerEndpoint(); //1 // TODO 完成具体的分表策略 String logicTableName = shardingValue.getLogicTableName(); return Arrays.asList(logicTableName + \"_1\", logicTableName + \"_2\"); &#125;&#125; ComplexShardingStrategy支持多分片键的复杂分片策略，通过complex.sharding-columns配置分片键，多个分片键用逗号分隔，通过complex.algorithm-class-name配置按多个分片列进行综合分片的分片算法实现类，且该实现类必须实现org.apache.shardingsphere.api.sharding.complex.ComplexKeysShardingAlgorithm接口。 12345spring.shardingsphere.sharding.tables.course.table-strategy.complex.sharding-columns= cid, user_idspring.shardingsphere.sharding.tables.course.table-strategy.complex.algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyComplexTableShardingAlgorithmspring.shardingsphere.sharding.tables.course.database-strategy.complex.sharding-columns=cid, user_idspring.shardingsphere.sharding.tables.course.database-strategy.complex.algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyComplexDSShardingAlgorithm 12345678910111213141516public class MyComplexTableShardingAlgorithm implements ComplexKeysShardingAlgorithm&lt;Long&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, ComplexKeysShardingValue&lt;Long&gt; shardingValue) &#123; Range&lt;Long&gt; cidRange = shardingValue.getColumnNameAndRangeValuesMap().get(\"cid\"); Collection&lt;Long&gt; userIdCol = shardingValue.getColumnNameAndShardingValuesMap().get(\"user_id\"); Long upperVal = cidRange.upperEndpoint(); Long lowerVal = cidRange.lowerEndpoint(); List&lt;String&gt; res = new ArrayList&lt;&gt;(); for (Long userId : userIdCol) &#123;// course_&#123;userID%2+1&#125; BigInteger userIdB = BigInteger.valueOf(userId); BigInteger target = userIdB.mod(new BigInteger(\"2\")).add(new BigInteger(\"1\")); res.add(shardingValue.getLogicTableName() + \"_\" + target); &#125; return res; &#125;&#125; HintShardingStrategy不需要分片键的强制分片策略，其分片键不跟SQL语句关联而是程序指定。对于一些复杂的情况如select count(*) from (select userid from t_user where userid in (1,3,5,7,9))这样的SQL语句，无法通过SQL语句指定一个分片键，这时就可通过程序给他指定一个分片键，如按userid奇偶分片的策略下，可指定1作为分片键，然后自行指定他的分片策略。 通过hint.algorithm-class-name配置分片算法实现类，且该类必须实现org.apache.shardingsphere.api.sharding.hint.HintShardingAlgorithm接口，该算法类同样需要分片键，通过HintManager.addDatabaseShardingValue方法指定分库分片键和通过HintManager.addTableShardingValue方法指定分表分片键。使用时该分片键是线程隔离的，只在当前线程有效，建议使用之后立即关闭，或者用try资源方式打开。 Hint分片策略并没有完全按照SQL解析树来构建分片策略，绕开了SQL解析，对某些比较复杂语句，Hint分片策略性能有可能会比较好。但Hint强制路由在使用时有非常多的限制： 1234567-- 不支持UNIONSELECT * FROM t_order1 UNION SELECT * FROM t_order2INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?-- 不支持多层子查询SELECT COUNT(*) FROM (SELECT * FROM t_order o WHERE o.id IN (SELECT id FROM t_order WHERE status = ?))-- 不支持函数计算，ShardingSphere只能通过SQL字面提取用于分片的值SELECT * FROM t_order WHERE to_date(create_time, 'yyyy-mm-dd') = '2019-01-01'; 1spring.shardingsphere.sharding.tables.course.table-strategy.hint.algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyHintTableShardingAlgorithm 12345678910public class MyHintTableShardingAlgorithm implements HintShardingAlgorithm&lt;Integer&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, HintShardingValue&lt;Integer&gt; shardingValue) &#123; String key = shardingValue.getLogicTableName() + \"_\" + shardingValue.getValues().toArray()[0]; if (availableTargetNames.contains(key)) &#123; return Arrays.asList(key); &#125; throw new UnsupportedOperationException(\"route \" + key + \" is not supported ,please check your config\"); &#125;&#125; 实例首先定义一个数据源m1，并对m1进行实际的JDBC参数配置，spring.shardingsphere.sharding.tables.course开头的一系列属性即定义了一个名为course的逻辑表，actual-data-nodes属性即定义course逻辑表的实际数据分布情况，他分布在m1.course_1和m1.course_2两个表。key-generator属性配置主键列以及主键生成策略，ShardingJDBC默认提供了UUID和SNOWFLAKE两种分布式主键生成策略。table-strategy属性配置分库分表策略，分片键为cid属性，分片算法为course_$-&gt;{cid%2+1}，表示按照cid模2+1的结果，然后加上前面的course__ 部分作为前缀就是其实际表结果，该表达式计算出来的结果需要能够与实际数据分布中的一种情况对应上否则就会报错。 1234567891011121314151617181920212223# 配置数据源，可配置多个，用逗号分隔spring.shardingsphere.datasource.names=m1# 数据源m1spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3307/coursedb?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=root# 通过groovy脚本配置真实表分布，指定course表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.course.actual-data-nodes=m1.course_$-&gt;&#123;1..2&#125;# 指定course表里中主键cid生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.course.key-generator.column=cidspring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE# 雪花算法的一个可选参数spring.shardingsphere.sharding.tables.course.key-generator.props.worker.id=1# 通过groovy脚本指定分表分片策略，约定cid值偶数添加到course_1表，奇数添加到course_2表spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid# 根据计算的字段算出对应的表名spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;&#123;cid%2+1&#125;# 打开sql输出日志spring.shardingsphere.props.sql.show=true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 通过上面的配置ShardingJDBC会帮我们完成具体的SQL转换以及数据的调用，不需要做其他特别的处理。最终这些配置被转换映射到ShardingRuleConfiguration中： 12345678910111213tables: course: actualDataNodes: m1.course_$-&gt;&#123;1..2&#125; # 数据节点 keyGenerator: # 主键生成策略配置 column: cid # 主键 props: worker.id: '1' type: SNOWFLAKE # 具体的主键生成策略 logicTable: course # 逻辑表 tableStrategy: # 分表策略 inline: # 分片策略 algorithmExpression: course_$-&gt;&#123;cid%2+1&#125; # 具体的分片算法 shardingColumn: cid # 分片键 多数据源多数据源的情况除了要配置分表分片策略，还需要配置分库分片策略，与前面的区别在于指定了多个数据源，actual-data-nodes数据节点配置所有变化，且增加了分库分片策略。 1234567891011121314151617181920212223242526272829303132# 配置数据源，可配置多个，用逗号分隔spring.shardingsphere.datasource.names=m1,m2# 数据源m1spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3307/coursedb?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=root# 数据源m2spring.shardingsphere.datasource.m2.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m2.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m2.url=jdbc:mysql://localhost:3307/coursedb2?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m2.username=rootspring.shardingsphere.datasource.m2.password=root# 通过groovy脚本配置真实表分布，指定course表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.course.actual-data-nodes=m$-&gt;&#123;1..2&#125;.course_$-&gt;&#123;1..2&#125;# 指定course表里中主键cid生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.course.key-generator.column=cidspring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE# 雪花算法的一个可选参数spring.shardingsphere.sharding.tables.course.key-generator.props.worker.id=1# 通过groovy脚本指定分表分片策略，约定cid值偶数添加到course_1表，奇数添加到course_2表spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid# 根据计算的字段算出对应的表名spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;&#123;cid%2+1&#125;# 分库策略spring.shardingsphere.sharding.tables.course.database-strategy.inline.sharding-column=cidspring.shardingsphere.sharding.tables.course.database-strategy.inline.algorithm-expression=m$-&gt;&#123;cid%2+1&#125;# 打开sql输出日志spring.shardingsphere.props.sql.show=true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 广播表配置1234# 广播表配置spring.shardingsphere.sharding.broadcast-tables=t_dictspring.shardingsphere.sharding.tables.t_dict.key-generator.column=dict_idspring.shardingsphere.sharding.tables.t_dict.key-generator.type=SNOWFLAKE 绑定表绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将⼤⼤提升。 1234567891011121314151617181920212223242526272829303132# 配置数据源，可配置多个，用逗号分隔spring.shardingsphere.datasource.names=m1# 数据源m1spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3306/coursedb?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=root# 通过groovy脚本配置真实表分布，指定t_dict表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.t_dict.actual-data-nodes=m1.t_dict_$-&gt;&#123;1..2&#125;spring.shardingsphere.sharding.tables.t_dict.key-generator.column=dict_idspring.shardingsphere.sharding.tables.t_dict.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_dict.key-generator.props.worker.id=1# t_dict表的分片键和分片算法spring.shardingsphere.sharding.tables.t_dict.table-strategy.inline.sharding-column=ustatusspring.shardingsphere.sharding.tables.t_dict.table-strategy.inline.algorithm-expression=t_dict_$-&gt;&#123;ustatus.toInteger()%2+1&#125;# 通过groovy脚本配置真实表分布，指定user表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.user.actual-data-nodes=m1.t_user_$-&gt;&#123;1..2&#125;# 指定user表里中主键user_id生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.user.key-generator.column=user_idspring.shardingsphere.sharding.tables.user.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.user.key-generator.props.worker.id=1# user表的分片键和分片算法spring.shardingsphere.sharding.tables.user.table-strategy.inline.sharding-column=ustatusspring.shardingsphere.sharding.tables.user.table-strategy.inline.algorithm-expression=t_user_$-&gt;&#123;ustatus.toInteger()%2+1&#125;# 绑定表示spring.shardingsphere.sharding.binding-tables[0]=user,t_dict# 打开sql输出日志spring.shardingsphere.props.sql.show = true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 读写分离123456789101112131415161718192021222324252627# 配置主从数据源，要基于MySQL主从架构。spring.shardingsphere.datasource.names=m0,s0# 数据源m0spring.shardingsphere.datasource.m0.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m0.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m0.url=jdbc:mysql://localhost:3307/masterdemo?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m0.username=rootspring.shardingsphere.datasource.m0.password=root# 数据源s0spring.shardingsphere.datasource.s0.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.s0.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.s0.url=jdbc:mysql://localhost:3308/masterdemo?serverTimezone=GMT%2B8spring.shardingsphere.datasource.s0.username=rootspring.shardingsphere.datasource.s0.password=root# 读写分离规则，m0主库，s0从库spring.shardingsphere.sharding.master-slave-rules.ds0.master-data-source-name=m0spring.shardingsphere.sharding.master-slave-rules.ds0.slave-data-source-names[0]=s0# 基于读写分离的表分片spring.shardingsphere.sharding.tables.t_dict.actual-data-nodes=ds0.t_dict# 指定t_dict表里中主键dict_id生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.t_dict.key-generator.column=dict_idspring.shardingsphere.sharding.tables.t_dict.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_dict.key-generator.props.worker.id=1# 打开sql输出日志spring.shardingsphere.props.sql.show = true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 核心原理 解析引擎解析过程分为词法解析和语法解析，词法解析器用于将SQL拆解为不可再分的原子符号称为Token，并根据不同数据库方言所提供的字典，将其归类为关键字、表达式、字面量和操作符，再使用语法解析器将SQL转换为Abstract Syntax Tree抽象语法树简称AST。 1SELECT id, name FROM t_user WHERE status = 'ACTIVE' AND age &gt; 18 SQL解析是整个分库分表的核心，其性能和兼容性是最重要的衡量指标，灰色表示需要进⼀步拆分，关键字的Token用绿色表示。 路由引擎根据解析上下文匹配数据库和表的分片策略，生成路由路径，ShardingSphere分片策略主要分为单片路由即分片键操作符是等号、多片路由即分片键的操作符是IN和范围路由即分片键的操作符是Between，不携带分片键的SQL则是广播路由。 分片策略通常可由数据库内置也可由用户方配置，内置分片策略大致可分为尾数取模、哈希、范围、标签、时间等，由用户方配置的分片策略则更加灵活，可根据使用方需求定制复合分片策略。实际使用时应尽量使用分片路由明确路由策略，因为广播路由影响过大不利于集群管理及扩展。 全库表路由：不带分片键的DQL、DML、DDL语句会遍历所有库表逐一执行。如select * from course或select * from course where ustatus=&#39;1&#39;不带分片键 全库路由：对数据库的操作都会遍历所有真实库，如set autocommit=0 全实例路由：DCL语句每个数据库实例只执行一次，如**CREATE USER customer@127.0.0.1 identified BY &#39;123&#39;**; 单播路由：从任意库中获取数据即可，如DESCRIBE course 阻断路由：屏蔽SQL对数据库的操作，如USE coursedb不会在真实库中执行，虚拟表操作不需要切换数据库 改写引擎只需要面向逻辑库和逻辑表来写SQL，最终由ShardigSphere的改写引擎将SQL改写为在真实数据库中可正确执行的语句，SQL改写分为正确性改写和优化改写。 执行引擎ShardingSphere并不是简单的将改写完的SQL提交到数据库执行，执行引擎的目标是自动化的平衡资源控制和执行效率。连接模式分为内存限制模式MEMORY_STRICTLY和连接限制模式CONNECTION_STRICTLY。 内存限制模式：只关注一个数据库连接的处理数量，通常一张真实表一个数据库连接 连接限制模式：只关注数据库连接的数量，较大的查询会进行串行操作 这两个模式通过spring.shardingsphere.props.max.connections.size.per.query=50参数配置，默认值为1，参见源码ConfigurationPropertyKey类。ShardingSphere会根据路由到某一个数据源的路由结果计算出所有需在数据库上执行的SQL数量，用该数量除以用户的配置项，得到每个数据库连接需执行的SQL数量。若数量&gt;1选择连接限制模式，数量&lt;=1就会选择内存限制模式。 内存限制模式不限制连接数，建立多个数据连接并发控制每个连接只去读取一个数据分片的数据，可最快把所有需要的数据读出来。且在归并阶段选择以每一条数据为单位进行归并即流式归并，归并完一批数据后释放内存，可很好的提高数据归并的效率，且防止出现内存溢出或垃圾回收频繁，吞吐量比较大，适合OLAP场景 连接限制模式限制连接数，至少有一个数据库连接会要去读取多个数据分片的数据，数据库连接采用串行方式依次读取多个数据分片的数据，将数据全部读到内存，进行统一数据归并即内存归并，归并效率会比较高适合OLTP场景 归并引擎将从各个数据节点获取的多数据结果集，组合成为一个结果集并正确的返回至请求客户端，有流式归并和内存归并两种归并方式： 流式归并：一条一条数据的方式进行归并 内存归并：将所有结果集都查询到内存中进行统一归并 分布式主键内置生成器支持UUID和SNOWFLAKE，并抽离出分布式主键生成器的接口，方便用户自行实现自定义的自增主键生成器。 UUID采用UUID.randomUUID()的方式产生唯一且不重复的分布式主键。最终生成一个字符串类型的主键。缺点是生成的主键无序。 SNOWFLAKE雪花算法能保证不同进程主键不重复相同进程主键有序，二进制形式包含4部分，从高位到低位分表为：1bit符号位、41bit时间戳位、10bit工作进程位，12bit序列号位。毫秒数在高位自增序列在低位，整个ID趋势递增；不依赖第三方组件稳定性高，生成ID性能也非常高；可根据自身业务特性分配bit位，非常灵活；但强依赖机器时钟，若机器上时钟回拨会导致发号重复。 1bit符号位：预留的符号位恒为零 41bit时间戳位：41位时间戳可容纳毫秒数为2的41次幂，一年所使用的毫秒数为365 * 24 * 60 * 60 * 1000 Math.pow(2, 41) / (365 * 24 * 60 * 60 * 1000L) = 69.73年不重复 10bit工作进程位：该标志Java进程内唯一，若分布式应用部署应保证每个工作进程的id不同，默认为0，可通过属性设置 12bit序列号位：该序列用来在同一个毫秒内生成不同的ID，若在该毫秒内生成数量超过4096即2的12次幂，则生成器会等待到下个毫秒继续生成。 SQL使用限制支持的SQL123456789101112131415161718192021222324SELECT * FROM tbl_name SELECT * FROM tbl_name WHERE (col1 = ? or col2 = ?) and col3 = ? SELECT * FROM tbl_name WHERE col1 = ? ORDER BY col2 DESC LIMIT ? SELECT COUNT(*), SUM(col1), MIN(col1), MAX(col1), AVG(col1) FROM tbl_name WHERE col1 = ? SELECT COUNT(col1) FROM tbl_name WHERE col2 = ? GROUP BY col1 ORDER BY col3 DESC LIMIT ?, ? INSERT INTO tbl_name (col1, col2,…) VALUES (?, ?, ….) INSERT INTO tbl_name VALUES (?, ?,….) INSERT INTO tbl_name (col1, col2, …) VALUES (?, ?, ….), (?, ?, ….) -- INSERT表和SELECT表必须为相同表或绑定表INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?-- REPLACE表和SELECT表必须为相同表或绑定表REPLACE INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?UPDATE tbl_name SET col1 = ? WHERE col2 = ? DELETE FROM tbl_name WHERE col1 = ? CREATE TABLE tbl_name (col1 int, …) ALTER TABLE tbl_name ADD col1 varchar(10) DROP TABLE tbl_name TRUNCATE TABLE tbl_name CREATE INDEX idx_name ON tbl_name DROP INDEX idx_name ON tbl_name DROP INDEX idx_name SELECT DISTINCT * FROM tbl_name WHERE col1 = ? SELECT COUNT(DISTINCT col1) FROM tbl_name SELECT subquery_alias.col1 FROM (select tbl_name.col1 from tbl_name where tbl_name.col2=?) subquery_alias 不支持的SQL123456789101112131415161718-- VALUES语句不支持运算表达式INSERT INTO tbl_name (col1, col2, …) VALUES(1+2, ?, …)-- SELECT子句暂不支持使用*号简写及内置的分布式主键生成器INSERT INTO tbl_name (col1, col2, …) SELECT * FROM tbl_name WHERE col3 = ?-- SELECT子句暂不支持使用*号简写及内置的分布式主键生成器REPLACE INTO tbl_name (col1, col2, …) SELECT * FROM tbl_name WHERE col3 = ?-- UNIONSELECT * FROM tbl_name1 UNION SELECT * FROM tbl_name2-- UNION ALLSELECT * FROM tbl_name1 UNION ALL SELECT * FROM tbl_name2-- 详见DISTINCT支持情况详细说明SELECT SUM(DISTINCT col1), SUM(col1) FROM tbl_name-- 会导致全路由SELECT * FROM tbl_name WHERE to_date(create_time, 'yyyy-mm-dd') = ?-- 暂不支持加括号的查询(SELECT * FROM tbl_name)-- 查询列是函数表达式时，查询列前不能使用表名，若查询表存在别名，则可使用表的别名SELECT MAX(tbl_name.col1) FROM tbl_name DISTINCT支持的SQL1234567891011121314SELECT DISTINCT * FROM tbl_name WHERE col1 = ?SELECT DISTINCT col1 FROM tbl_nameSELECT DISTINCT col1, col2, col3 FROM tbl_nameSELECT DISTINCT col1 FROM tbl_name ORDER BY col1SELECT DISTINCT col1 FROM tbl_name ORDER BY col2SELECT DISTINCT(col1) FROM tbl_nameSELECT AVG(DISTINCT col1) FROM tbl_nameSELECT SUM(DISTINCT col1) FROM tbl_nameSELECT COUNT(DISTINCT col1) FROM tbl_nameSELECT COUNT(DISTINCT col1) FROM tbl_name GROUP BY col1SELECT COUNT(DISTINCT col1 + col2) FROM tbl_nameSELECT COUNT(DISTINCT col1), SUM(DISTINCT col1) FROM tbl_nameSELECT COUNT(DISTINCT col1), col1 FROM tbl_name GROUP BY col1SELECT col1, COUNT(DISTINCT col1) FROM tbl_name GROUP BY col1 DISTINCT不支持的SQL12-- 查询列是函数表达式时，查询列前不能使用表名，若查询表存在别名，则可使用表的别名SELECT SUM(DISTINCT tbl_name.col1), SUM(tbl_name.col1) FROM tbl_name","tags":[{"name":"ShardingSphere","slug":"ShardingSphere","permalink":"https://yaoyinglong.github.io/tags/ShardingSphere/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"MySQL主从架构","date":"2021-12-06T16:00:00.000Z","path":"Blog/DB/MySQL主从架构/","text":"实际生产中，往往数据量会极为庞大，并且数据的安全性要求也更高，生产环境中MySQL必须是要搭建一套主从复制架构，同时可基于一些工具实现高可用架构。在此基础上则可基于一些中间件实现读写分离架构。若数据量非常大，还必须可实现分库分表的架构。 通过搭建MySQL主从集群可缓解MySQL数据存储及访问压力，搭建主从集群时，双方MySQL必须版本一致，至少主服务版本低于从服务，且两节点间时间需要同步。 数据安全：给主服务增加一个数据备份，可搭建主从架构或基于主从架构搭建互主架构 读写分离：读多写少的情况，主服务访问压力过大时，可将数据读请求转为由从服务来分担，主服务只负责数据写入请求 故障转移：当MySQL主服务宕机后可由一台从服务切换成为主服务，继续提供数据读写功能 MySQL主从架构一般都是通过binlog日志文件来进行的，即在主服务上打开binlog记录每一步数据库操作，从服务上会有一个IO线程，负责跟主服务建立一个TCP连接请求主服务将binlog传输过来。且主库上会有一个IO dump线程，负责通过该TCP连接把Binlog日志传输给从库IO线程。从服务IO线程会把读取到的binlog日志数据写入自己的relay日志文件中。然后从服务上另外一个SQL线程读取relay日志内容进行操作重演，达到还原数据的目的。通常对MySQL做的读写分离配置必须基于主从架构来搭建。 MySQL的Binlog不光可用于主从同步，还可用于缓存数据同步等场景。如Canal，可模拟一个Slave节点向MySQL发起Binlog同步，然后将数据落到Redis、Kafka等其他组件，实现数据实时流转。 主从搭建主节点配置对于主节点的配置文件my.cnf中，主要是添加打开binlog日志，以及指定server-id，配置好后service mysqld restart重启MySQL服务。 123456789101112131415161718192021222324252627282930313233[mysqld]# 服务节点的唯一标识，需要给集群中的每个服务分配一个单独的IDserver-id=47# 打开Binlog日志记录，并指定文件名log_bin=master-bin# Binlog日志文件log_bin-index=master-bin.indexskip-name-resolve# 设置连接端口port=3306# 设置mysql的安装目录basedir=/usr/local/mysql# 设置mysql数据库的数据的存放目录datadir=/usr/local/mysql/mysql-files# 允许最大连接数max_connections=200# 允许连接失败的次数。max_connect_errors=10# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用mysql_native_password插件认证default_authentication_plugin=mysql_native_password# 需要同步的二进制数据库名binlog-do-db=masterdemo# 只保留7天的二进制日志，以防磁盘被日志占满(可选)expire-logs-days=7# 不备份的数据库binlog-ignore-db=information_schemabinlog-ignore-db=performation_schemabinlog-ignore-db=sys 给root用户分配一个replication slave的权限，然后通过show master status命令查看主节点同步状态。 123456# 登录主数据库mysql -u root -pGRANT REPLICATION SLAVE ON *.* TO 'root'@'%';flush privileges;# 查看主节点同步状态：show master status; File和Position表示当前日志binlog文件和文件中的索引。Binlog_Do_DB表示需要记录binlog文件的库，Binlog_Ignore_DB不需要记录binlog文件的库，若没有进行配置，则表示针对全库记录日志。 开启binlog后数据库中所有操作都会被记录到datadir当中，以一组轮询文件的方式循环记录。上面指令查到的File和Position就是当前日志文件和位置，配置从服务时需要通过File和Position通知从服务从哪个地方开始记录binlog。 从节点配置从服务同样需要配置服务节点的唯一标识server-id，且需要打开bin-log日志记录，且需要打开relay-log日志。 12345678910111213141516171819202122232425262728293031323334[mysqld]# 主库和从库需要不一致server-id=48# 打开MySQL中继日志relay-log-index=slave-relay-bin.indexrelay-log=slave-relay-bin# 打开从服务二进制日志log-bin=mysql-bin# 使得更新的数据写进二进制日志中log-slave-updates=1# 设置3306端口port=3306# 设置mysql的安装目录basedir=/usr/local/mysql# 设置mysql数据库的数据的存放目录datadir=/usr/local/mysql/mysql-files# 允许最大连接数max_connections=200# 允许连接失败的次数。max_connect_errors=10# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用mysql_native_password插件认证default_authentication_plugin=mysql_native_password# 若salve库名称与master库名相同，使用本配置replicate-do-db = masterdemo # 若master库名[mastdemo]与salve库名[mastdemo01]不同，使用以下配置[需要做映射]replicate-rewrite-db = masterdemo -&gt; masterdemo01# 若不是要全部同步[默认全部同步]，则指定需要同步的表replicate-wild-do-table=masterdemo01.t_dictreplicate-wild-do-table=masterdemo01.t_num 启动从服务设置其主节点同步状态，CHANGE MASTER指令中需要指定的MASTER_LOG_FILE和MASTER_LOG_POS必须与主服务中查到的保持一致。且后续若要检查主从架构是否成功，也可通过检查主服务与从服务之间File和Position两个属性是否一致。 123456789101112131415#登录从服务mysql -u root -p;#设置同步主节点：CHANGE MASTER TOMASTER_HOST='192.168.232.128',MASTER_PORT=3306,MASTER_USER='root',MASTER_PASSWORD='root',MASTER_LOG_FILE='master-bin.000008',MASTER_LOG_POS=154GET_MASTER_PUBLIC_KEY=1;# 开启slavestart slave;# 查看主从同步状态，或者用show slave status \\G;这样查看比较简洁show slave status; 主从架构可能失败，若在slave从服务上查看slave状态，发现Slave_SQL_Running=no表示主从同步失败。这可能因为在从数据库进行了写操作，与同步过来的SQL操作冲突了，也可能slave从服务重启后有事务回滚了。 读写分离主从集群是单向的只能从主服务同步到从服务，而从服务的数据表更新无法同步到主服务。为了保证数据一致，通常需要保证数据只在主服务上写，而从服务只进行数据读取。但MySQL主从本身无法提供读写分离服务，需要由业务自己来实现。 需要限制用户写数据，可在从服务中将read_only参数的值设为1，set global read_only=1;可限制用户写入数据。但该属性有两个需要注意的地方： read_only=1设置只读模式，不影响slave同步复制功能 read_only=1设置的只读模式， 限定的是普通用户进行数据修改的操作，但不限定具有super权限的用户的数据修改操作。 若需限定super权限的用户写数据可设置super_read_only=0。若想连super权限用户的写操作也禁止使用flush tables with read lock;，但该设置会阻止主从同步复制。 其他集群方式若想进一步提高整个集群的读能力，可扩展出一主多从，为了减轻主节点进行数据同步的压力，可继续扩展出多级从的主从集群。为了提高整个集群的高可用能力，可扩展出多主集群。 也可扩展出互为主从的互主集群甚至是环形的主从集群，实现MySQL多活部署。搭建互主集群只需要按照主从方式，且在主服务上打开一个slave进程，且指向slave节点binlog当前文件地址和位置。 传统的Binlog方式搭建集群是基于日志记录点的方式来进行主从同步，还可通过GTID搭建方式搭建主从同步，GTID本质也是基于Binlog来实现的主从同步，GTID是基于一个全局事务ID来标识同步进度。该GTID全局事务ID是一个全局唯一且趋势递增的分布式ID策略。 GTID搭建方式是从MySQL5.6版本引入，即用到上面Executed_Grid_Set列，首先从服务器会告诉主服务器已经在从服务器执行完了哪些事务的GTID值，主库会把所有没有在从库上执行的事务，发送到从库上进行执行，且使用GTID复制可保证同一个事务只在指定从库上执行一次，可避免由于偏移量问题造成数据不一致。 1234567891011# 主节点my.cnf文件中添加如下配置gtid_mode=onenforce_gtid_consistency=onlog_bin=onserver_id=1binlog_format=row# 从节点my.cnf文件中添加如下配置gtid_mode=onenforce_gtid_consistency=onlog_slave_updates=1server_id=2 集群扩容若集群已运行一段时间，这时若要扩展新的从节点，之前的数据没办法从binlog来恢复。这时在扩展新的slave节点时，需要增加一个数据复制的操作。使用mysql的bin目录下的mysqldump工具生成数据备份文件。 12345# 在主库生成数据备份文件mysqldump -u root -p --all-databases &gt; backup.sql# 从库上将该文件导入即可mysql -u root -p &lt; backup.sql 延迟问题主从复制之间会有延迟，在做了读写分离后会更容易体现出来。即数据往主服务写，而读数据在从服务读。主从复制延迟可能造成刚插入了数据但查不到，大型集群中会很容易出现。 出现这个问题的根本在于，面向业务的主服务数据都是多线程并发写入的，而从服务是单个线程慢慢拉取binlog，这中间会有效率差。所以解决这个问题的关键是要让从服务也用多线程并行复制binlog数据。MySQL5.7开始支持并行复制。可在从服务上设置slave_parallel_workers为一个大于0的数，然后把slave_parallel_type设置为LOGICAL_CLOCK。 半同步赋值MySQL主从集群默认采用异步复制机制。主服务在执行用户提交的事务后写入binlog日志，然后给客户端返回成功响应，而binlog会由一个dump线程异步发送给Slave从服务。 由于发送binlog过程是异步的，主服务在向客户端反馈执行结果时，不知道binlog是否同步成功。若此时主服务宕机，而从服务还没有备份到新执行的binlog可能会丢数据。这就要靠MySQL的半同步复制机制来保证数据安全。 半同步复制机制是一种介于异步复制和全同步复制之前的机制，主库在执行完客户端提交的事务后，并不是立即返回客户端响应，而是等待至少一个从库接收并写到relay log中才返回给客户端，MySQL在等待确认时默认等待10s，若超过10s没有收到ack则会降级成为异步复制。 半同步复制相比异步复制，能够有效的提高数据的安全性，但这种安全性不是绝对的，其只保证事务提交后的binlog至少传输到了一个从库，不保证从库应用该事务binlog成功。 半同步复制机制会造成一定程度的延迟，该延迟时间至少是一个TCP/IP请求往返的时间。整个服务性能会有所下降。而当从服务出现问题时，主服务需要等待的时间就会更长，要等到从服务的服务恢复或者请求超时才能给用户响应。 半同步复制需要基于特定扩展模块来实现，而MySQL5.5版本开始默认自带了该模块。该模块包含在MySQL安装目录下lib/plugin目录下semisync_master.so和semisync_slave.so两个文件中。需在主服务上安装semisync_master模块，从服务上安装semisync_slave模块。 12345678910111213141516171819# 通过扩展库来安装半同步复制模块，需要指定扩展库的文件名mysql&gt; install plugin rpl_semi_sync_master soname &apos;semisync_master.so&apos;;Query OK, 0 rows affected (0.01 sec)# 打开半同步复制开关mysql&gt; set global rpl_semi_sync_master_enabled=ON;Query OK, 0 rows affected (0.00 sec)# 查看系统全局参数，rpl_semi_sync_master_timeout就是半同步复制等待应答最长等待时间，默认10秒mysql&gt; show global variables like &apos;rpl_semi%&apos;;+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| rpl_semi_sync_master_enabled | ON || rpl_semi_sync_master_timeout | 10000 | # 默认10秒| rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC | # 表示一种半同步复制的方式+-------------------------------------------+------------+6 rows in set, 1 warning (0.02 sec) 半同步复制有AFTER_SYNC和AFTER_COMMIT两种方式： AFTER_SYNC方式，主库把日志写入binlog且复制给从库，然后开始等待从库的响应。从库返回成功后主库再提交事务，接着给客户端返回一个成功响应。 AFTER_COMMIT方式，主库写入binlog后等待binlog复制到从库，主库就提交自己本地事务，再等待从库返回给自己一个成功响应，然后主库再给客户端返回响应。 123456789101112131415161718192021# 通过扩展库来安装半同步复制模块，需要指定扩展库的文件名mysql&gt; install plugin rpl_semi_sync_slave soname &apos;semisync_slave.so&apos;;Query OK, 0 rows affected (0.01 sec)# 打开半同步复制开关mysql&gt; set global rpl_semi_sync_slave_enabled = on;Query OK, 0 rows affected (0.00 sec)# 查看系统全局参数mysql&gt; show global variables like &apos;rpl_semi%&apos;;+---------------------------------+-------+| Variable_name | Value |+---------------------------------+-------+| rpl_semi_sync_slave_enabled | ON || rpl_semi_sync_slave_trace_level | 32 |+---------------------------------+-------+2 rows in set, 1 warning (0.00 sec)# 安装完slave端的半同步插件后，需要重启下slave服务mysql&gt; stop slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec) MySQL高可用方案使用MySQL自身功能来搭建的集群，不具备高可用功能，若MySQL主服务挂了，从服务没办法自动切换成主服务。常见的MySQL集群方案有三种: MMM、MHA、MGR。共同点： 对主从复制集群中的Master节点进行监控 自动的对Master进行迁移，通过VIP虚拟IP。 重新配置集群中其它slave对新的Master进行同步 MMMMaster-Master replication manager for MySQL即MySQL主主复制管理器是一套由Perl语言实现的脚本程序，可对MySQL集群进行监控和故障迁移，需要两个Master，但同一时间只有一个Master对外提供服务，可以说是主备模式。 通过一个VIP即虚拟IP机制来保证集群高可用，主节点上会通过一个虚拟IP地址来提供数据读写服务，当出现故障时，虚拟IP从原来主节点漂移到其他节点，由其他节点提供服务。 提供了读写VIP的配置，使读写请求都可以达到高可用；工具包相对比较完善，不需要额外的开发脚本；完成故障转移之后可对MySQL集群进行高可用监控；但故障简单粗暴，容易丢失事务，建议采用半同步复制方式，减少失败的概率；目前MMM社区已经缺少维护，不支持基于GTID的复制；适用于读写都需要高可用的场景以及基于日志点的复制方式。 MHAMaster High Availability Manager and Tools for MySQL由日本人开发基于Perl脚本。专门用于监控主库状态，当发现Master节点故障时，会提升其中拥有新数据的Slave节点成为新的Master节点，在此期间MHA会通过其他从节点获取额外信息来避免数据一致性方面的问题。MHA还提供了Mater节点的在线切换功能，MHA能够在30秒内实现故障切换，并能在故障切换过程中，最大程度的保证数据一致性。 MHA需要单独部署，分为Manager节点和Node节点。Manager节点一般是单独部署一台机器。而Node节点一般部署在每台MySQL机器上，Node节点得通过解析各个MySQL的日志来进行一些操作。 Manager节点会通过探测集群里Node节点去判断各个Node所在机器上的MySQL运行是否正常，若发现某个Master故障则直接把他的一个Slave提升为Master，然后让其他Slave都挂到新的Master上去，完全透明。 支持日志点复制方式和GTID方式；同MMM相比，MHA会尝试从旧Master中恢复旧二进制日志，但未必每次都能成功。若希望更少的数据丢失场景，建议使用MHA架构。但MHA需要自行开发VIP转移脚本；MHA只监控Master状态未监控Slave状态； MGRMGR：MySQL Group Replication是MySQL官方在5.7.17版本正式推出的一种组复制机制。主要是解决传统异步复制和半同步复制的数据一致性问题。由若干个节点共同组成一个复制组，一个事务提交后，必须经过超过半数节点的决议并通过后才可提交。MGR依靠分布式一致性协议Paxos协议的一个变体，实现了分布式下数据的最终一致性，提供了真正的数据高可用方案。 支持多主模式，但官方推荐单主模式，多主模式下，客户端可以随机向MySQL节点写入数据，单主模式下MGR集群会选出primary节点负责写请求，primary节点与其它节点都可以进行读请求处理。 基本无延迟，延迟比异步的小很多，支持多写模式，但是目前还不是很成熟，数据的强一致性，可以保证数据事务不丢失；仅支持innodb，且每个表必须提供主键，只能用在GTID模式下，且日志格式为row格式。适用于对主从延迟比较敏感，希望对写服务提供高可用，又不想安装第三方软件，数据强一致的场景。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"MongoDB基础","date":"2021-12-05T16:00:00.000Z","path":"Blog/DB/MongoDB基础/","text":"MongoDB的安装和启动，MongoDB启动默认使用/data/db路径作为数据存放路径，也可通过--dbpath参数指定其他路径，若未创建则启动报错，通过--auth参数以授权模式启动，通过--logpath参数设置日志文件存储路径。 MongoDB基于安全性考虑，默认安装后只会绑定本地回环IP即127.0.0.1，可通过启动服务时--bind_ip绑定IP。绑定后登陆时也需要通过该IP登陆。 12345678910111213wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.4.2.tgztar -xvzf mongodb-linux-x86_64-rhel70-4.4.2.tgzmkdir -p /data/db # 该路径是MongoDB默认的数据存放路径# --auth以授权模式启动，--logpath指定日志文件，--dbpath指定数据存放路径，若省略默认使用/data/db路径bin/mongod --auth --logpath /data/db/logpath/output --dbpath /data/db --bind_ip 192.168.109.200 --fork# 登陆 若是本机--host和--port可省略bin/mongo -host 192.168.109.200 -u eleven# 设置密码，登陆mongo后use admin # 切换数据库到admindb.createUser(&#123;user: \"eleven\", pwd: \"eleven\", roles: [\"root\"]&#125;) # 创建用户show users # 查看所有用户信息db.shutdownServer() # 停掉服务exit # 退出mongo MongoDB基本操作writeConcern定义了本次文档创建操作的安全写级别， 安全写级别用来判断一次数据库写入操作是否成功，安全写级别越高，丢失数据的风险就越低，但写入操作延迟也可能更高。writeConcern决定一个写操作落到多少个节点上才算成功。 发起写操作的程序将阻塞到写操作到达指定的节点数为止： 0：发起写操作，不关心是否成功 1- 集群中最大数据节点数：写操作需要被复制到指定节点数才算成功 majority：写操作需要被复制到大多数节点上才算成功，过半机制 插入文档时若没有显示指定主键，MongoDB将默认创建一个主键，字段固定为_id，ObjectId()可快速生成12字节id作为主键，ObjectId前四个字节代表主键生成时间，精确到秒。主键ID在客户端驱动生成，一定程度上代表了顺序性但不保证顺序性， 可通过ObjectId(&quot;id值&quot;).getTimestamp()获取创建时间。 1234# insertOne和insertMany命令不支持explain命令db.collection.insertMany([&#123;&lt;JSON对象1&gt;&#125;,&#123;&lt;JSON对象2&gt;&#125;],&#123;writeConcern: 安全级别,ordered: true/false&#125;) # 批量添加文档db.collection.insert(&lt;JSON对象&gt;, &#123;writeConcern: 安全级别&#125;) # 添加单个文档db.collection.insertOne(&lt;JSON对象&gt;, &#123;writeConcern: 安全级别&#125;) # 添加单个文档 ordered决定是否按顺序写入，顺序写入时，一旦遇到错误，便会退出，剩余的文档无论正确与否，都不会写入，乱序写入，则只要文档可正确写入，不管前面的文档是否是错误的文档。 123456789db.collection.find(&#123;&#125;) # 查询所有的文档 db.collection.find(&#123;&#125;).pretty() # 返回格式化后的文档db.collection.find(&#123;qty:0, status:\"D\"&#125;) # 精准等值查询db.collection.find(&#123;\"size.uom\": \"in\"&#125;) # 嵌套对象精准查询# 返回指定字段，默认会返回_id字段，同样可以通过指定_id:0，剩余字段不能混合指定db.collection.find(&#123;&#125;, &#123;item: 1, status: 1&#125;)# and和or条件查询，以及$in，$nin，$existsdb.collection.find(&#123;$and:[&#123;\"qty\":0&#125;,&#123;\"status\":\"A\"&#125;]&#125;).pretty()db.collection.find(&#123;$or:[&#123;\"qty\":0&#125;,&#123;\"status\":\"A\"&#125;]&#125;).pretty() 复合主键，若字段顺序变换即使内容完全一致，也会当做不同的对象被创建 1db.demeDoc.insert(&#123;_id: &#123;product_name: 1, product_type: 2&#125;, supplierId: \"001\", create_Time: new Date()&#125;) 逻辑操作符匹配 $not：匹配筛选条件不成立的文档 $and：匹配多个筛选条件同时满足的文档 $or：匹配至少一个筛选条件成立的文档 $nor：匹配多个筛选条件全部不满足的文档 12345db.members.find(&#123;points: &#123;$not: &#123; $lt: 100&#125;&#125;&#125;);db.members.find(&#123;$and: [&#123;nickName:&#123;$eq : \"曹操\"&#125;&#125;, &#123;points:&#123;$gt: 1000&#125;&#125;]&#125;);db.members.find(&#123;nickName:&#123;$eq: \"曹操\"&#125;, points:&#123;$gt: 1000&#125;&#125;); # 当作用在不同字段上可省略 $anddb.members.find(&#123;points:&#123;$gte:1000, $lte:2000&#125;&#125;); # 当作用在同一字段时可简化db.members.find(&#123;$or: [&#123;nickName:&#123;$eq : \"曹操\"&#125;&#125;, &#123;points:&#123;$gt: 1000&#125;&#125;]&#125;); 默认count()不考虑skip和limit效果，若希望考虑limit和skip，需要设置为true。 分布式环境下count不保证数据绝对正确。当同时应用sort，skip，limit时，应用顺序为sort，skip，limit。可使用$slice返回数组中部分元素，可使用$elementMatch进行数组元素匹配。 12345db.members.find().skip(1).limit(10).count();db.members.find().skip(1).limit(10).count(true);db.members.find().sort(&#123;field: 1/-1&#125;); # 排序，1：顺序，-1：逆序db.members.find(&#123;&#125;,&#123;_id:0, nickName:1, points:1, address: &#123;$slice:1&#125;&#125;); # 返回第一个元素db.members.find(&#123;&#125;,&#123;_id:0, nickName:1, points:1, tag: &#123;$elemMatch: &#123;$eq: \"00\"&#125;&#125;&#125;); 投影设置：{field: &lt;1：1表示需要返回，0：表示不需要返回，只能为0或1，非主键字段不能同时混选0或1&gt;} 1db.members.find(&#123;&#125;,&#123;_id:0, nickName:1, points:1&#125;) 更新操作，updateOne/updateMany方法要求更新条件部分必须具有以下之一，否则将报错 $set 给符合条件的文档新增一个字段，有该字段则修改其值 $unset 给符合条件的文档，删除一个字段 $push： 增加一个对象到数组底部 $pop：从数组底部删除一个对象 $pull：如果匹配指定的值，从数组中删除相应的对象 $pullAll：如果匹配任意的值，从数据中删除相应的对象 $addToSet：如果不存在则增加一个值到数组 $rename：重命名字段 $inc：加减字段值 $mul：相乘字段值 $min：采用最小值 $max：次用最大值 默认只会更新第一个匹配的值，可通过设置options {multi: true}设置匹配多个文档并更新 12345678# &lt;query&gt; 定义了更新时的筛选条件# &lt;update&gt; 文档提供了更新内容# &lt;options&gt; 声明了一些更新操作的参数db.collection.update(&lt;query&gt;,&lt;update&gt;,&lt;options&gt;)# 默认删除所有满足条件的文档，可设定参数&#123;justOne:true&#125;，只删除满足条件的第一条文档db.collection.remove(&lt;query&gt;,&lt;options&gt;)# 删除集合，不但删除集合内的所有文档，且删除集合的索引db.collection.drop(&#123;writeConcern:&lt;doc&gt;&#125;) 聚合操作聚合表达式 $&lt;field&gt;.&lt;sub_field&gt;：获取字段信息，sub_field字段可0个或多个 $literal: &lt;value&gt;：常量表达式 $$&lt;variable&gt;：系统变量表达式 $$CURRENT：指示管道中当前操作的文档 聚合管道阶段筛选管道操作和其他管道操作配合时候时，尽量放到开始阶段，可减少后续管道操作符要操作的文档数，提升效率 $project：对输入文档进行再次投影 $match：对输入文档进行筛选 $limit：筛选出管道内前 N 篇文档 $skip：跳过管道内前N篇文档 $unwind：展开输入文档中的数组字段 $sort：对输入文档进行排序 $lookup：对输入文档进行查询操作 $group：对输入文档进行分组 $out：对管道中的文档输出 1234567891011121314db.userInfo.aggregate(&#123;$project:&#123;name:\"$nickName\"&#125;&#125;) # 将原始字段投影成指定名称db.userInfo.aggregate(&#123;$project:&#123; name:\"$nickName\",_id:0,age:1&#125;&#125;); # 也可剔除不需要的字段db.userInfo.aggregate(&#123;$match:&#123;nickName:\"lisi\"&#125;&#125;); # 文档筛选db.userInfo.aggregate([&#123;$match:&#123;$and:[&#123;age:&#123;$gte:20&#125;&#125;,&#123;nickName:&#123;$eq:\"lisi\"&#125;&#125;]&#125;&#125;, &#123;$project: &#123;_id:0, name: \"$nickName\", age:1&#125;&#125;]);db.userInfo.aggregate(&#123;$limit:1&#125;);db.userInfo.aggregate(&#123;$skip:1&#125;);db.userInfo.aggregate(&#123;$unwind:&#123;path:\"$tags\"&#125;&#125;); # tags是一个数组db.userInfo.aggregate(&#123;$unwind:&#123;path:\"$tags\",includeArrayIndex:\"arrIndex\"&#125;&#125;); # 赋值给指定的字段# 展开时保留空数组，或者不存在数组字段的文档db.userInfo.aggregate(&#123;$unwind:&#123;path: \"$tags\",includeArrayIndex:\"arrIndex\",preserveNullAndEmptyArrays:true&#125;&#125;);# 对文档进行排序：1正序，-1倒序 db.userInfo.aggregate(&#123;$sort:&#123;age:-1&#125;&#125;);# 单一字段值进行关联查询db.accountDetail.aggregate(&#123;$lookup:&#123; from: \"需要关联的文档\",localField: \"本地字段\"，foreignField: \"外部文档关联字段\"，as \"作为新的字段，添加到文档中\"&#125;); 索引索引默认名称是索引键和索引中每个键的方向即1或-1的连接，使用下划线作为分隔符， 也可以通过指定name来自定义索引名称； 12345678db.collection.createIndex(&lt;keys&gt;, &lt;options&gt;) # 创建索引db.members.createIndex(&#123;name:1&#125;，&#123;name: \"index_name\"&#125;);db.members.getIndexes(); # 查询集合中已经存在的索引db.members.createIndex(&#123; name:1,age:-1&#125;); # 复合索引，按name升序排age降序db.members.createIndex(&#123;age:1&#125;,&#123;unique:true&#125;); # 唯一性索引db.sparsedemo.createIndex(&#123;name:1&#125;,&#123;unique:true ,sparse:true&#125;); # 稀疏索引# 日期字段或包含日期元素的数组字段，可使用设定生存时间的索引，来自动删除字段值超过生存时间的文档db.members.createIndex(&#123;create_time:1&#125;,&#123;expireAfterSeconds:30&#125;); 复制集MongoDB复制集主要意义在于实现服务高可用，类似于Redis哨兵模式，数据写入Primary主节点时将数据复制到另一个Secondary副本节点上，主节点发生故障时自动选举出一个新的替代节点。实现高可用的同时，复制集还有如下作用 数据分发：将数据从一个区域复制到另一个区域，减少另一个区域的读延迟 读写分离：不同类型的压力分别在不同的节点上执行 异地容灾：在数据中心故障时快速切换到异地 典型的复制集由三个或三个以上具有投票权的节点组成，其中一个Primary主节点接收写入操作，读操作和选举时投票，两个或多个Secondary从节点复制主节点上的新数据和选举时投票。 当一个修改操作到达主节点时，它对数据的操作将被记录下来，这些记录称为oplog，从节点通过从主节点上不断获取新进入主节点的oplog，并在自己的数据上回放，以此保持跟主节点的数据一致。 具有投票权的节点之间两两互相发送心跳，当5次心跳未收到时判断为节点失联，若主节点失联，从节点会发起选举，选出新的主节点，若从节点失联则不会产生新的选举，选举基于RAFT一致性算法实现，选举成功的必要条件是大多数投票节点存活，复制集中最多可有50个节点，但具有投票权的节点最多7个。 整个集群必须有大多数节点存活，被选举为主节点的节点必须能够与多数节点建立连接，具有较新的oplog，具有较高优先级。复制集节点有以下的选配项： v：是否具有投票权，有则参与投票 priority：优先级，优先级越高的节点越优先成为主节点。优先级为0的节点无法成为主节点,默认值为1。 hidden：隐藏，复制数据，但对应用不可见。隐藏节点可具有投票权，但优先级必须为0 slaveDelay：延迟，复制n秒之前的数据，保持与主节点的时间差 buildIndexes：从节点不建立索引 mongod -f /data/db/mongod.conf，默认情况下非主节点不允许读数据，可通过执行rs.secondaryOk()开启读权限 12345678910111213systemLog: destination: file path: /data/db/mongod.log logAppend: truestorage: dbPath: /data/db1net: bindIp: 0.0.0.0 port: 28017replication: replSetName: rs0processManagement: fork: true 分片集群 mongos路由节点： 提供集群单一入口，转发应用端请求，选择合适的数据节点进行读写，合并多个数据节点的返回。无状态，建议mongos节点集群部署以提供高可用性。客户请求应发给mongos而不是分片服务器，当查询包含分片键时，mongos将查询发送到指定分片，否则mongos将查询发送到所有分片，并汇总所有查询结果。 配置节点: 普通的mongod进程， 建议以复制集部署，提供高可用，提供集群元数据存储分片数据分布的数据。主节点故障时配置服务器进入只读模式，只读模式下数据段分裂和集群平衡都不可执行。整个复制集故障时，分片集群不可用。 数据节点：以复制集为单位，横向扩展最大1024分片，分片之间数据不重复，所有数据在一起才可以完整工作。 数据段的分裂，当数据段尺寸过大，或包含过多文档时，触发数据段分裂，只有新增、更新文档时才可能自动触发数据段分裂，数据段分裂通过更新元数据来实现 集群的平衡，后台运行的平衡器负责监视和调整集群的平衡，当最大和最小分片之间的数据段数量相差过大时触发 ，集群中添加或移除分片时也会触发 MongoDB分片集群特点：应用全透明，数据自动均衡，动态扩容，无需下线","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://yaoyinglong.github.io/tags/MongoDB/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"Kafka基础","date":"2021-12-03T16:00:00.000Z","path":"Blog/Cloud/MQ/Kafka基础/","text":"Kafka基础Kafka是scala语言编写的支持partition分区、replica多副本，基于Zookeeper协调的分布式消息系统，可实时处理大量数据以满足各种需求场景，如基于hadoop批处理系统、低延迟实时系统、Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等。 名称 解释 Broker 消息中间件处理节点，一个Kafka节点就是一个Broker，一个或者多个Broker组成Kafka集群 Topic Kafka根据Topic对消息进行归类，发布到Kafka集群的每条消息都需指定一个Topic Producer 消息生产者，向Broker发送消息的客户端，通过TCP协议来完成通信 Consumer 消息消费者，从Broker读取消息的客户端，通过TCP协议来完成通信 Consumer Group 每个Consumer属于一个特定Consumer Group，一条消息可被多个不同Consumer Group消费，但一个Consumer Group中只能有一个Consumer能消费该消息 Partition 物理上的概念，一个Topic可分为多个Partition，每个Partition内部消息是有序的 使用场景 日志收集：可用Kafka收集各种服务日志，通过kafka以统一接口服务方式开放给各种Consumer，如Hhadoop、Hbase、Solr等。 消息系统：解耦生产者和消费者、缓存消息等。 用户活动跟踪：Kafka经常被用来记录Web用户或App用户的各种活动，如浏览网页、搜索、点击等活动，被各个服务器发布到kafka的Topic中，然后订阅者通过订阅这些Topic来做实时监控分析，或装载到Hadoop、数据仓库中做离线分析和挖掘。 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用数据，生产各种操作的集中反馈，如报警和报告。 Kafka核心配置Kafka核心配置在config/server.properties配置文件中。 1234broker.id=0 # broker.id属性在kafka集群中必须要是唯一listeners=PLAINTEXT://localhost:9092 # kafka部署的机器ip和提供服务的端口号log.dir=/usr/local/data/kafka-logs # kafka的消息存储文件zookeeper.connect=192.168.65.60:2181 # kafka连接zookeeper的地址，若是集群则用逗号分割 Property Default Description broker.id 0 每个Broker都可用一个唯一非负整数id进行标识 log.dirs /tmp/kafka-logs 存放数据的路径，该路径并不唯一，可设置多个路径之间用逗号分隔，创建新partition时选择包含最少partitions路径下创建 listeners PLAINTEXT://192.168.65.60:9092 Server接受客户端连接的端口，ip配置kafka本机ip即可 zookeeper.connect localhost:2181 Kafka连接Zookeeper的地址，若是集群用逗号分隔 log.retention.hours 168 每个日志文件的保存时间。默认数据保存时间对所有topic都一样 num.partitions 1 创建Topic默认分区数 default.replication.factor 1 自动创建Topic默认副本数量，建议设置为大于等于2 min.insync.replicas 1 写数据到repica数量达到设定值才表示Producer发送消息成功，若Producer设置acks为-1，则每个repica写数据都必须成功 delete.topic.enable false 是否允许删除主题 12345678910111213141516171819202122232425262728bin/kafka-server-start.sh config/server.properties # 启动kafkabin/kafka-server-stop.sh # 停止kafka# 创建名字为test的Topic，该topic只有一个partition，且备份因子为1bin/kafka-topics.sh --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic test# 查看kafka中目前存在的topicbin/kafka-topics.sh --zookeeper localhost:2181 --list# 删除topicbin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test# 发送消息到kafka，若是集群--broker-list参数用逗号隔开bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test# 消费kafka集群最新消息，若是集群--bootstrap-server参数用逗号隔开bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test# 多主题消费kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --whitelist \"test|test-2\"# 通过--from-beginning从开始读取kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic test# 单播消费，一条消息只能被某一个消费者消费，让所有消费者在同一个消费组里即可bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup --topic test# 多播消费，同一条消息只能被同一个消费组下的某一个消费者消费的特性bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup-2 --topic test# 查看消费组名bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list# 查看消费组的消费偏移量，current-offset当前消费组的已消费偏移量，log-end-offset主题对应分区消息结束偏移量，lag当前消费组未消费消息数bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup# 查看下topic情况bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test# 增加topic的分区数量，目前kafka不支持减少分区bin/kafka-topics.sh --zookeeper localhost:2181 --alter --partitions 3 --topic test 同类消息发送到同一个Topic下面，每个Topic下面可有多个分区Partition日志文件，Partition是一个有序的message序列，这些message按顺序添加到commit log文件中。每个Partition中消息都有一个唯一编号offset，用来唯一标识某个分区中的message。 每个Partition都对应一个commit log文件，同一个Partition中的message的offset都是唯一的，但不同Partition中message的offset可能相同。 每个Partition分区中都有一个Leader副本节点和一个或多个Replicas副本以及一个Isr集合，Partition的Leader副本节点负责给定Partition的所有读写请求，Replicas表示某个Partition在哪几个Broker上存在备份，不管该节点是不是Leader，甚至该节点挂了也会列出。Isr集合是Replicas的一个子集，只列出存活的备份节点，且已同步备份了该Partition的节点。 Kafka一般不会删除消息，不管是否被消费。只会根据配置的日志保留时间log.retention.hours确认消息多久被删除，默认保留最近一周的消息。Kafka性能与保留消息数据量大小没有关系。 每个Consumer是基于commit log中消费进度即offset来进行工作的，消费offset由Consumer来维护，一般按照顺序逐条消费commit log中的消息，可通过指定offset来重复消费某些消息或跳过某些消息。意味Consumer对集群影响非常小，添加或减少Consumer对于集群或其他Consumer没有影响，因为每个Consumer维护各自的消费offset。 一个Topic代表逻辑上的一个业务数据集，对于大型网站来说，后端数据都是海量的，消息可能非常巨量，若把这么多数据都放在一台机器上可能会有容量限制问题，可在Topic内部划分多个Partition来分片存储数据，不同Partition可位于不同机器上，每台机器上都运行一个Kafka的Broker进程。 分片存储的好处，提高并行度，且commit log文件会受到所在机器的文件系统大小的限制，分区后可将不同分区放在不同机器上，相当于对数据做分布式存储，理论上一个Topic可处理任意数量数据。 Kafka集群Kafka将很多集群关键信息记录在Zookeeper中，保证自己的无状态，从而在水平扩容时非常方便。commit log的Partitions分布在Kafka集群中不同Broker上，每个Broker上该Partition分区的副本可请求备份其他Broker上Partition上副本的数据，Kafka集群支持配置一个Partition备份数量。每个Partition都有一个Broker上的副本起到Leader的作用，0个或多个其他的Broker副本作为Follwers作用。作为Leader的副本处理所有针对该Partition的读写请求，作为Followers的副本被动复制作为Leader的副本的结果，不提供读写，主要是为了保证多副本数据与消费的一致性。若一个Partition分区中Leader副本失效其中一个Follower副本将自动变成新的Leader副本。 生产者将消息发送到Topic中去，同时负责选择将message发送到Topic的哪个Partition中。通过round-robin做简单的负载均衡。也可根据消息中某个关键字来进行区分，通常第二种方式使用更多。 对于消费者，传统的消息传递模式有队列模式和发布订阅模式，且基于这2种模式提供了一种Consumer的抽象概念Consumer Group。 Queue模式：多个Consumer从服务器中读取数据，消息只会到达一个Consumer，所有Consumer都位于同一Consumer Group下 Publish-Subscribe模式：消息会被广播给所有Consumer，所有Consumer都有唯一的Consumer Group。 通常一个Topic会有几个Consumer Group，每个Consumer Group都是一个逻辑上的订阅者，每个Consumer Group由多个Consumer 实例组成，从而达到可扩展和容灾的功能。 一个Partition同一时刻在一个Consumer Group中只能有一个Consumer在消费，Partition分区类似于RocketMQ中的队列，从而保证消费顺序。Consumer Group中的Consumer数不能比一个Topic中Partition的数量多，否则多出来的Consumer消费不到消息。Kafka只在Partition范围内保证消息消费的局部顺序性，不能在同一个Topic中多个Partition中保证总的消费顺序性。 若有在总体上保证消费顺序的需求，则可通过将Topic的Partition数量设置为1，将Consumer Group中的Consumer数量也设置为1，但会影响性能，故Kafka顺序消费很少用。 客户端调用12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt;&lt;/dependency&gt; 生产者包含一些关键的参数，包括发送消息持久化机制参数ProducerConfig.ACKS_CONFIG，发送失败会重试次数ProducerConfig.RETRIES_CONFIG，重试时间间隔ProducerConfig.RETRY_BACKOFF_MS_CONFIG，以及发送时可指定Partition分区，同步发送异步发送等。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Properties props = new Properties();props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");/* 发出消息持久化机制参数（1）acks=0：表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息。（2）acks=1：至少等待leader成功将数据写入本地log，但不用等待所有followe都成功写入。就可继续发送下一条消息。该情况下若follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。（3）acks=-1或all：需等待min.insync.replicas，默认为1，推荐配置大于等于2，该参数配置的副本个数都成功写入日志，这种策略会保证 只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置。 */props.put(ProducerConfig.ACKS_CONFIG, \"1\");// 发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但也可能造成消息重复发送，如网络抖动，故需在接收者处做好消息接收的幂等性处理props.put(ProducerConfig.RETRIES_CONFIG, 3);// 重试时间间隔设置props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MBprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);// 默认值是0，消息必须立即被发送，但这样会影响性能，一般设置10毫秒左右，该消息发送完后会进入本地的一个batch，// 若10毫秒内该batch满了16kb就随batch一起被发送出去，若10毫秒内batch没满，则也必须把消息发送出去，不能让消息的发送延迟时间太长props.put(ProducerConfig.LINGER_MS_CONFIG, 10);// 把发送的key从字符串序列化为字节数组props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());// 把发送消息value从字符串序列化为字节数组props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);int msgNum = 5;final CountDownLatch countDownLatch = new CountDownLatch(msgNum);for (int i = 1; i &lt;= msgNum; i++) &#123; // 指定发送分区 // ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME , 0, order.getOrderId().toString(), JSON.toJSONString(order)); // 未指定发送分区，具体发送的分区计算公式：hash(key)%partitionNum ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME, String.valueOf(i), \"order \" + i); // 等待消息发送成功的同步阻塞方法 // RecordMetadata metadata = producer.send(producerRecord).get(); // System.out.println(\"同步方式发送消息结果：\" + \"topic-\" + metadata.topic() + \"|partition-\" + metadata.partition() + \"|offset-\" + metadata.offset()); //异步回调方式发送消息 producer.send(producerRecord, new Callback() &#123; @Override public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if (exception != null) &#123; System.err.println(\"发送消息失败：\" + exception.getStackTrace()); &#125; if (metadata != null) &#123; System.out.println(\"异步方式发送消息结果：\" + \"topic-\" + metadata.topic() + \"|partition-\" + metadata.partition() + \"|offset-\" + metadata.offset()); &#125; countDownLatch.countDown(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.close(); 消费者同样可指定消费的分区，指定消费者组名称，是否自动提交，自动提交时间间隔，心跳时间间隔等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980String TOPIC_NAME = \"my-replicated-topic\";String CONSUMER_GROUP_NAME = \"testGroup\";Properties props = new Properties();props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");// 消费分组名props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);// 是否自动提交offset，默认就是trueprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");// 自动提交offset的间隔时间props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"false\");/*当消费主题的是一个新的消费组，或指定offset的消费方式，offset不存在，则可通过以下两种方式消费消息- latest(默认) ：只消费自己启动之后发送到主题的消息- earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于consumer.seekToBeginning(每次都从头开始消费)*///props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");// consumer给broker发送心跳的间隔时间，broker接收到心跳若此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，该时间可以稍微短一点props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);// 一次poll最大拉取消息的条数，若消费者处理速度很快，可以设置大点，若处理速度一般，可以设置小点props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);// 若两次poll操作间隔超过该时间，则broker认为该consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);consumer.subscribe(Arrays.asList(TOPIC_NAME));// 消费指定分区//consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 消息回溯消费//consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 指定offset消费//consumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);// 从指定时间点开始消费/*List&lt;PartitionInfo&gt; topicPartitions = consumer.partitionsFor(TOPIC_NAME);//从1小时前开始消费long fetchDataTime = new Date().getTime() - 1000 * 60 * 60;Map&lt;TopicPartition, Long&gt; map = new HashMap&lt;&gt;();for (PartitionInfo par : topicPartitions) &#123; map.put(new TopicPartition(topicName, par.partition()), fetchDataTime);&#125;Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap = consumer.offsetsForTimes(map);for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) &#123; TopicPartition key = entry.getKey(); OffsetAndTimestamp value = entry.getValue(); if (key == null || value == null) continue; Long offset = value.offset(); System.out.println(\"partition-\" + key.partition() + \"|offset-\" + offset); System.out.println(); //根据消费里的timestamp确定offset if (value != null) &#123; consumer.assign(Arrays.asList(key)); consumer.seek(key, offset); &#125;&#125;*/while (true) &#123; // poll() API 是拉取消息的长轮询 ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; System.out.printf(\"收到消息：partition = %d,offset = %d, key = %s, value = %s%n\", record.partition(), record.offset(), record.key(), record.value()); &#125; /*if (records.count() &gt; 0) &#123; // 手动同步提交offset，当前线程会阻塞直到offset提交成功一般使用同步提交，因为提交之后一般也没有什么逻辑代码了 consumer.commitSync(); // 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑 consumer.commitAsync(new OffsetCommitCallback() &#123; @Override public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) &#123; if (exception != null) &#123; System.err.println(\"Commit failed for \" + offsets); System.err.println(\"Commit failed exception: \" + exception.getStackTrace()); &#125; &#125; &#125;); &#125;*/&#125; Spring整合1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233spring: kafka: bootstrap-servers: localhost:9092,localhost:9093,localhost:9094 producer: # 生产者 retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送 batch-size: 16384 buffer-memory: 33554432 acks: 1 # 指定消息key和消息体的编解码方式 key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer consumer: group-id: default-group enable-auto-commit: false auto-offset-reset: earliest key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer listener: # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交 # RECORD # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交 # BATCH # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交 # TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交 # COUNT # TIME | COUNT 有一个条件满足时提交 # COUNT_TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交 # MANUAL # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种 # MANUAL_IMMEDIATE ack_mode: manual_immediate 123456private final static String TOPIC_NAME = \"my-replicated-topic\";@Autowiredprivate KafkaTemplate&lt;String, String&gt; kafkaTemplate;public void send() &#123; kafkaTemplate.send(TOPIC_NAME, 0, \"key\", \"this is a msg\");&#125; 123456789101112131415161718192021222324/** * @KafkaListener(groupId = \"testGroup\", topicPartitions = &#123; * @TopicPartition(topic = \"topic1\", partitions = &#123;\"0\", \"1\"&#125;), * @TopicPartition(topic = \"topic2\", partitions = \"0\", * partitionOffsets = @PartitionOffset(partition = \"1\", initialOffset = \"100\")) * &#125;, concurrency = \"6\") * concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数 */@KafkaListener(topics = \"my-replicated-topic\", groupId = \"testGroup\")public void listenTestGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); //手动提交offset //ack.acknowledge();&#125;// 配置多个消费组@KafkaListener(topics = \"my-replicated-topic\", groupId = \"elevenGroup\")public void listenElevenGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); ack.acknowledge();&#125; 设计原理 总控制器ControllerKafka集群中会有一个或多个Broker，其中有一个Broker会被选举为Kafka Controller控制器，其负责管理整个集群中所有分区和副本的状态。 当某个分区的Leader副本出现故障时，由控制器负责为该分区选举新的Leader副本。 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有Broker更新其元数据信息。 当使用kafka-topics.sh脚本为某个Topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。 Kafka集群启动时自动选举一台Broker作为Controller来管理整个集群，选举过程是集群中每个Broker都会尝试在Zookeeper上创建一个 /controller临时节点，Zookeeper会保证有且仅有一个Broker能创建成功，创建成功的Broker则成为集群的总控器Controller。 Controller选举机制当Controller角色的Broker宕机时Zookeeper临时节点会消失，集群里其他Broker会一直监听/controller临时节点，发现临时节点消失则竞争再次创建/controller临时节点，这就是Controller的选举机制。具备控制器身份的Broker需要比其他普通Broker多一份职责： 监听Broker相关的变化，为Zookeeper中的/brokers/ids节点添加BrokerChangeListener，用来处理Broker增减变化。 监听Topic相关的变化，为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理Topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除Topic动作。 从Zookeeper中读取当前所有与Topic、Partition以及Broker有关信息并进行相应的管理。对所有Topic所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听Topic中分区分配变化。 更新集群元数据信息，同步到其他普通Broker节点中。 Partition副本选举Leader机制Controller会监听/brokers/ids节点可感知Broker是否存活，当Controller感知到分区Leader所在Broker挂了，参数unclean.leader.election.enable=false的前提下，Controller会从ISR列表里挑第一个Broker作为Leader，因为第一个Broker最先放进ISR列表可能是同步数据最多的副本，若参数unclean.leader.election.enable=true代表在ISR列表里所有副本都挂了时可在ISR列表以外的副本中选Leader，该设置可提高可用性，但选出的新Leader可能数据少很多。 副本进入ISR列表有两个条件：副本节点不能产生分区，必须能与Zookeeper保持会话以及跟Leader副本网络连通；副本能复制Leader上的所有写操作，且不能落后太多，超过replica.lag.time.max.ms时间都没跟Leader同步过一次的副本会被移出ISR列表； offset记录机制每个Consumer会定期将自己消费分区的offset提交给Kafka内部名称为__consumer_offsets的Topic，提交过去时key为consumerGroupId+topic+分区号，value就是当前offset的值，Kafka会定期清理该Topic里的消息保留最新的那条数据，因为__consumer_offsets可能会接收高并发的请求，Kafka默认给其分配50个分区，可通过offsets.topic.num.partitions设置，这样可通过加机器的方式抗大并发。 通过公式hash(consumerGroupId) % __consumer_offsets主题的分区数可选出Consumer消费的offset要提交到__consumer_offsets的哪个分区。 消费者Rebalance机制Rebalance机制：若消费组中消费者数量变化或消费分区数变化，Kafka会重新分配消费者消费分区的关系。如Consumer Group中某个消费者挂了，此时会自动把分配给它的分区交给其它消费者，若其恢复则又会把一些分区重新交还给它。 Rebalance只针对Subscribe这种不指定分区消费的情况，若通过assign消费方式指定了分区Kafka不会进行Rebanlance。当消费组中Consumer增加或减少、动态给Topic增加分区、消费组订阅了更多的Topic等情况可能触发消费者Rebalance。 Rebalance过程中消费者无法从Kafka消费消息，对Kafka的TPS会有影响，若Kafka集群内节点较多，Rebalance重平衡可能会耗时极多，应尽量避免在系统高峰期Rebalance重平衡。 消费者Rebalance分区分配策略消费者Rebalance分区分配策略主要有range、round-robin、sticky三种Rebalance策略，默认为range分配策略。Kafka提供消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略。 range策略：按分区序号排序，假设n＝分区数／消费者数量，m＝分区数%消费者数量，则前m个消费者每个分配n+1个分区，消费者数量 - m个消费者每个分配n个分区。 round-robin策略：轮询分配 sticky策略：初始时分配策略与round-robin类似，但在Rebalance时需要保证分区分配尽可能均匀、分区分配尽可能与上次分配保持相同两个原则。当两者发生冲突时，第一个目标优先于第二个目标 。这样可以最大程度维持原来的分区分配的策略。 Rebalance过程 当有消费者加入消费组时，消费者、消费组及组协调器之间会依次经历选择组协调器、加入消费组、SYNC GROUP三个阶段； 选择组协调器：每个Consumer Group都会选择一个Broker作为自己的组协调器GroupCoordinator，负责监控该消费组中所有消费者心跳，以及判断是否宕机，然后开启消费者Rebalance。Consumer Group中每个Consumer启动时会向Kafka集群中某个节点发送 FindCoordinatorRequest请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接。Consumer消费的offset要提交到__consumer_offsets的哪个分区，该分区Leader对应的Broker就是该Consumer Group的GroupCoordinator。 加入消费组：消费者会向GroupCoordinator发送JoinGroupRequest请求并处理响应。然后GroupCoordinator从一个Consumer Group中选择第一个加入Group的Consumer作为Leader消费组协调器，把Consumer Group情况发送给该Leader，接着该Consumer Leader会负责制定分区方案。 SYNC GROUP：Consumer Leader通过给GroupCoordinator发送SyncGroupRequest，接着GroupCoordinator把分区方案下发给各个Consumer，具体的Consumer根据指定分区的Leader Broker进行网络连接以及消息消费。 Producer发布消息机制Producer采用push模式将消息发布到Broker，每条消息都被append到顺序写磁盘到Patition中，Producer发送消息到Broker时，会根据分区算法选择将其存储到哪一个Partition，路由机制为： 指定了Patition，则直接使用； 未指定Patition但指定了key，通过对key的value进行hash选出一个Patition Patition和key都未指定，使用轮询选出一个Patition。 Producer先从Zookeeper的/brokers/.../state节点找到该Partition的Leader，然后将消息发送给该Leader，Leader将消息写入本地commit log，Followers从Leader Pull消息，写入本地commit log后向Leader发送ACK，Leader收到所有ISR中的Replica的ACK后，增加最后 commit 的offset即high watermark高水位简称HW并向Producer发送ACK。 HW和LEOHigh Watermark俗称高水位，取一个Partition对应的ISR中最小的log-end-offset即LEO作为HW，Consumer最多只能消费到HW所在的位置。每个Replica都有HW，Leader和Follower各自负责更新自己的HW状态。对于Leader新写入的消息Consumer不能立刻消费，Leader会等待该消息被所有ISR中的Replicas同步后更新HW，此时消息才能被Consumer消费。这样保证了若Leader所在Broker失效，该消息仍然可从新选举的Leader中获取。对于来自内部Broker的读取请求没有HW的限制。ISR以及HW和LEO的流转过程： Kafka复制机制既不是完全的同步复制，也不是单纯的异步复制。同步复制要求所有能工作的Follower都复制完，这条消息才会被commit极大影响了吞吐率。异步复制方式下Follower异步从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下若Follower还未复制完落后于Leader时，若Leader宕机则会丢失数据。Kafka使用ISR方式则很好均衡了确保数据不丢失以及吞吐率。acks=1的情况: 日志分段存储Kafka一个分区的消息数据对应存储在一个文件夹下，以Topic名称+分区号命名，消息在分区内是分段存储，每个段的消息都存储在不一样的log文件里，这种特性方便过期分段文件快速被删除，Kafka规定一个段位的log文件最大为1G。 Kafka每次往分区发4K消息就会记录一条当前消息的offset到index文件以及记录一条当前消息的发送时间戳与对应的offset到timeindex文件，若要定位消息的offset会先在index文件里快速定位，若需要按照时间来定位消息的offset，会先在timeindex文件里查找，再去log文件里找具体消息，相当于一个稀疏索引； 123456# 部分消息的offset索引文件，Kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件，若要定位消息的offset会先在该文件里快速定位，再去log文件里找具体消息，相当于一个稀疏索引00000000000000000000.index# 消息存储文件，主要存offset和消息体00000000000000000000.log# 消息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件，若需要按照时间来定位消息的offset，会先在这个文件里查找00000000000000000000.timeindex 一个日志段文件满了，会自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，该过程叫做log rolling，正在被写入的日志段文件叫做active log segment。 实际问题消息丢失消息发送端 acks=0： 表示Producer不需要等待任何Broker确认收到消息的回复，就可继续发送下一条消息。性能最高，但是最容易丢消息。大数据统计报表场景，对性能要求很高，对数据丢失不敏感的情况可用这种。 acks=1： 至少要等待Leader已经成功将数据写入本地log，但不需要等待所有Follower是否成功写入。就可继续发送下一条消息。该情况下若Follower没有成功备份数据，而此时Leader挂掉则消息会丢失。 acks=-1或all： Leader需等待所有备份即min.insync.replicas配置的备份个数都成功写入日志，该策略会保证只要有一个备份存活就不会丢失数据。 消息消费端若消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但此时Consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了。 消息重复消费消息发送端：发送消息若配置了重试机制，如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息 消息消费端：若消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理，一般消费端都是要做消费幂等处理。 消息乱序若发送端配置了重试机制，Kafka不会等之前那条消息完全发送成功才去发送下一条消息，可能会出现发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了，是否一定要配置重试要根据业务情况而定。也可用同步发送的模式去发消息，当然acks不能设置为0，这样也能保证消息发送的有序。 kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但性能比较低，可在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列，一个内存队列开启一个线程顺序处理消息。 消息积压线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致Broker积压大量未消费消息。若积压了上百万未消费消息需要紧急处理，可修改消费端程序，让其将收到的消息快速转发到其他Topic，可设置很多分区，然后再启动多个消费者同时消费新主题的不同分区。 由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息。此种情况可将这些消费不成功的消息转发到其它队列里去，类似死信队列，后面再慢慢分析死信队列里的消息处理问题。 延时队列延时队列存储的对象是延时消息。指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取该消息进行消费，但Kafka不支持延时队列。 实现思路：发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中如topic_1s，topic_5s，topic_10s，…topic_2h，一般不能支持任意时间段的延时，然后通过定时器进行轮训消费这些Topic，查看消息是否到期，若到期则把该消息发送到具体业务处理的Topic中，队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，若到了就转发，如果还没到这一次定时任务就可以提前结束了。 消息回溯若某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费，可以指定从多久之前的消息回溯消费，这种可以用Consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费。 消息传递保障kafka生产者的幂等性，因发送端重试导致的消息重复发送问题，Kafka幂等性可保证重复发送的消息只接收一次，只需在生产者加上参数props.put(&quot;enable.idempotence&quot;, true)即可，默认是false不开启，Kafka每次发送消息会生成PID和Sequence Number并将这两个属性一起发送给Broker，Broker将PID和Sequence Number跟消息绑定一起存起来，若生产者重发相同消息，Broker会检查PID和Sequence Number，若相同不会再接收。 每个新的Producer在初始化时会被分配一个唯一的PID，PID对用户完全是透明的，生产者若重启则会生成新的PID，每个PID该Producer发送到每个Partition的数据都有对应的序列号即Sequence Number，这些序列号是从0开始单调递增的。 Kafka的事务Kafka事务不同于Rocketmq，Rocketmq是保障本地事务与MQ消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性，一般在Kafka流式计算场景用得多一点，如kafka需要对一个Topic中的消息做不同的流式计算处理，处理完分别发到不同的Topic里，这些Topic分别被不同的下游系统消费如hbase，redis，es等，这种肯定希望系统发送到多个topic的数据保持事务一致性。 12345678910111213141516171819202122Properties props = new Properties();props.put(\"bootstrap.servers\", \"localhost:9092\");props.put(\"transactional.id\", \"my-transactional-id\");Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());producer.initTransactions(); //初始化事务try &#123; producer.beginTransaction(); //开启事务 for (int i = 0; i &lt; 100; i++) &#123;//发到不同的主题的不同分区 producer.send(new ProducerRecord&lt;&gt;(\"hdfs-topic\", Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(\"es-topic\", Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(\"redis-topic\", Integer.toString(i), Integer.toString(i))); &#125; producer.commitTransaction(); //提交事务&#125; catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) &#123; producer.close();&#125; catch (KafkaException e) &#123; producer.abortTransaction(); //回滚事务&#125;producer.close();","tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://yaoyinglong.github.io/tags/Kafka/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"RocketMQ消费者源码","date":"2021-12-02T16:00:00.000Z","path":"Blog/Cloud/MQ/RocketMQ消费者源码/","text":"消费者以消费者组的模式开展。消费者组之间有集群模式和广播模式两种消费模式。消费模式有推模式和拉模式。推模式是由拉模式封装组成。 集群模式下，一个消费队列同一时间只能被一个消费者消费，而一个消费者可以同时消费多个队列。RocketMQ只支持一个队列上的局部消息顺序，不保证全局消息顺序。 在DefaultMQPushConsumer中的start方法中，通过调用MQClientManager的getOrCreateMQClientInstance方法实例化关键类MQClientInstance，在MQClientInstance中实例化了PullMessageService和RebalanceService两个线程类。MQClientInstance的start方法中会启动PullMessageService和RebalanceService线程。 RebalanceService线程默认每20s执行一次，调用MQClientInstance的doRebalance方法遍历当前客户端所有消费者组的所有消费者，再通过RebalanceImpl的doRebalance方法遍历消费者对应的所有Topic，然后通过rebalanceByTopic对集群模式和广播模式进行处理，然后通过updateProcessQueueTableInRebalance方法遍历Topic下所有的队列将未消费的消息封装成PullRequest列表最终通过PullMessageService的executePullRequestImmediately方法将PullRequest任务添加阻塞队列中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149public class RebalanceService extends ServiceThread &#123; public void run() &#123; log.info(this.getServiceName() + \" service started\"); while (!this.isStopped()) &#123; this.waitForRunning(waitInterval); this.mqClientFactory.doRebalance(); &#125; log.info(this.getServiceName() + \" service end\"); &#125;&#125;public class MQClientInstance &#123; public void doRebalance() &#123; // 客户端负载均衡 针对当前消费者所属的每一个消费者组 for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123; MQConsumerInner impl = entry.getValue(); if (impl != null) &#123; try &#123; impl.doRebalance(); &#125; &#125; &#125; &#125;&#125;public abstract class RebalanceImpl &#123; public void doRebalance(final boolean isOrder) &#123; Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner(); if (subTable != null) &#123; for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123; final String topic = entry.getKey(); try &#123; // 客户端负载：真正进行负载都是根据主题来进行的。 this.rebalanceByTopic(topic, isOrder); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; this.truncateMessageQueueNotMyTopic(); &#125; private void rebalanceByTopic(final String topic, final boolean isOrder) &#123; switch (messageModel) &#123; case BROADCASTING: &#123; //广播模式，不需要进行负载。每个消费者都要消费。只需要更新负载信息。 Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) &#123; boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, mqSet); &#125; &#125; break; &#125; case CLUSTERING: &#123; // 客户端负载：集群模式负载方法 Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); //订阅的主题 List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup); //客户端ID if (mqSet != null &amp;&amp; cidAll != null) &#123; List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;(); mqAll.addAll(mqSet); Collections.sort(mqAll); //排序后才能保证消费者负载策略相对稳定。 Collections.sort(cidAll); AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy; //MessageQueue的负载策略，有五种实现类 List&lt;MessageQueue&gt; allocateResult = null; try &#123;//按负载策略进行分配，返回当前消费者实际订阅的MessageQueue集合。 allocateResult = strategy.allocate(this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); &#125; catch (Throwable e) &#123; return; &#125; Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;(); if (allocateResult != null) &#123; allocateResultSet.addAll(allocateResult); &#125; boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, allocateResultSet); &#125; &#125; break; &#125; default: break; &#125; &#125; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125;&#125;public class RebalancePushImpl extends RebalanceImpl &#123; public void dispatchPullRequest(List&lt;PullRequest&gt; pullRequestList) &#123; for (PullRequest pullRequest : pullRequestList) &#123; this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest); &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void executePullRequestImmediately(final PullRequest pullRequest) &#123; this.mQClientFactory.getPullMessageService().executePullRequestImmediately(pullRequest); &#125;&#125; PullMessageService线程的run方法中消费PullRequest请求，最终调用DefaultMQPushConsumerImpl的pullMessage方法，首先会对消息进行流量和消息大小限流，若不满足限流条线丢到线程池中延迟处理，定义了一个拉取消息的回调函数PullCallback，若拉取消息失败则调用onException将其丢到线程池中延迟处理下次继续重试处理，若成功则调用onSuccess方法，在该方法中若拉取到数据后会调用executePullRequestLater或executePullRequestImmediately方法再次将拉取请求放入任务队列中，若有数据则会一直拉取直到数据被消费完则PullStatus会变为非FOUND状态。不论获取消息成功还是失败都会将请求再次放回队列，便于长轮训的方式拉取消息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157public class PullMessageService extends ServiceThread &#123; public void run() &#123; while (!this.isStopped()) &#123; try &#123; //拉取消息的请求队列 PullRequest pullRequest = this.pullRequestQueue.take(); this.pullMessage(pullRequest); //处理请求 &#125; &#125; &#125; private void pullMessage(final PullRequest pullRequest) &#123; final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup()); if (consumer != null) &#123; DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer; impl.pullMessage(pullRequest); // 推模式的消费者最终还是会使用拉消息的方式 &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void pullMessage(final PullRequest pullRequest) &#123; // 拉取消息的核心流程 final ProcessQueue processQueue = pullRequest.getProcessQueue(); //获取要处理的消息：ProcessQueue if (processQueue.isDropped()) &#123; //如果队列被抛弃，直接返回 return; &#125; pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis()); //先更新时间戳 try &#123; this.makeSureStateOK(); &#125; catch (MQClientException e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; if (this.isPause()) &#123; //如果处理队列被挂起，延迟1S后再执行。 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND); return; &#125; long cachedMessageCount = processQueue.getMsgCount().get(); //获得最大待处理消息数量 long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); //获得最大待处理消息大小 if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123; //从数量进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123; //从消息大小进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (!this.consumeOrderly) &#123; // 若是有序消息 if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; &#125; else &#123; if (processQueue.isLocked()) &#123; if (!pullRequest.isLockedFirst()) &#123; final long offset = this.rebalanceImpl.computePullFromWhere(pullRequest.getMessageQueue()); boolean brokerBusy = offset &lt; pullRequest.getNextOffset(); pullRequest.setLockedFirst(true); pullRequest.setNextOffset(offset); &#125; &#125; else &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; &#125; // 获取订阅信息 final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (null == subscriptionData) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; final long beginTimestamp = System.currentTimeMillis(); PullCallback pullCallback = new PullCallback() &#123; // 客户端默认的拉取的回调函数，在拉取到消息后会进入这个方法处理。 @Override public void onSuccess(PullResult pullResult) &#123; if (pullResult != null) &#123; pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult, subscriptionData); switch (pullResult.getPullStatus()) &#123; case FOUND: long prevRequestOffset = pullRequest.getNextOffset(); pullRequest.setNextOffset(pullResult.getNextBeginOffset()); long pullRT = System.currentTimeMillis() - beginTimestamp; DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullRT(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullRT); long firstMsgOffset = Long.MAX_VALUE; if (pullResult.getMsgFoundList() == null || pullResult.getMsgFoundList().isEmpty()) &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; else &#123; firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset(); DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullTPS(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullResult.getMsgFoundList().size()); boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList()); // 消费者消息服务处理消费到的消息 DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispatchToConsume); if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123; // 退模式下任务间隔时间 DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval()); &#125; else &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; &#125; break; case NO_NEW_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case NO_MATCHED_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case OFFSET_ILLEGAL: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); pullRequest.getProcessQueue().setDropped(true); DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() &#123; @Override public void run() &#123; try &#123; DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(), pullRequest.getNextOffset(), false); DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue()); DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue()); &#125; &#125; &#125;, 10000); break; default: break; &#125; &#125; &#125; @Override public void onException(Throwable e) &#123; DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;; boolean commitOffsetEnable = false; long commitOffsetValue = 0L; if (MessageModel.CLUSTERING == this.defaultMQPushConsumer.getMessageModel()) &#123; commitOffsetValue = this.offsetStore.readOffset(pullRequest.getMessageQueue(), ReadOffsetType.READ_FROM_MEMORY); if (commitOffsetValue &gt; 0) &#123; commitOffsetEnable = true; &#125; &#125; String subExpression = null; boolean classFilter = false; SubscriptionData sd = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (sd != null) &#123; if (this.defaultMQPushConsumer.isPostSubscriptionWhenPull() &amp;&amp; !sd.isClassFilterMode()) &#123; subExpression = sd.getSubString(); &#125; classFilter = sd.isClassFilterMode(); &#125; int sysFlag = PullSysFlag.buildSysFlag(commitOffsetEnable, true, subExpression != null, classFilter); try &#123;// 客户端实际与服务器交互，拉取消息的地方，拉取成功后回调PullCallback this.pullAPIWrapper.pullKernelImpl(pullRequest.getMessageQueue(), subExpression, subscriptionData.getExpressionType(), subscriptionData.getSubVersion(), pullRequest.getNextOffset(), this.defaultMQPushConsumer.getPullBatchSize(), sysFlag, commitOffsetValue, BROKER_SUSPEND_MAX_TIME_MILLIS, CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND, CommunicationMode.ASYNC, pullCallback); &#125; catch (Exception e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;&#125; 在拉取消息成功PullCallback回调方法中，普通消息和顺序消息分别调用ConsumeMessageConcurrentlyService和ConsumeMessageOrderlyService的submitConsumeRequest方法。最终通过ConsumeRequest线程来处理，在该线程中具体消费者的consumeMessage方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public class ConsumeMessageConcurrentlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispatchToConsume) &#123; final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); if (msgs.size() &lt;= consumeBatchSize) &#123; //一次只拉取32条数据，不足32直接处理 ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue); try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; else &#123;//超过32条，就进行分页处理。 for (int total = 0; total &lt; msgs.size(); ) &#123; List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize); for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123; if (total &lt; msgs.size()) &#123; msgThis.add(msgs.get(total)); &#125; else &#123; break; &#125; &#125; ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue); //消费请求处理线程 try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; for (; total &lt; msgs.size(); total++) &#123; msgThis.add(msgs.get(total)); &#125; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; &#125; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispathToConsume) &#123; if (dispathToConsume) &#123; ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue); this.consumeExecutor.submit(consumeRequest); &#125; &#125;&#125;class ConsumeRequest implements Runnable &#123; public void run() &#123; if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123;//通过加锁，将并发的消息顺序进行消费。消息处理的方式没什么特别。 if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125;&#125; 消息的拉取最终调用的是PullAPIWrapper的pullKernelImpl方法，拉取模式固定为ASYNC，最终调用MQClientAPIImpl的pullMessageAsync方法想Broker发送RequestCode.PULL_MESSAGE命令拉取消息，在operationComplete方法中完成PullCallback回调。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class PullAPIWrapper &#123; public PullResult pullKernelImpl(final MessageQueue mq, final String subExpression, final String expressionType, final long subVersion, final long offset, final int maxNums, final int sysFlag, final long commitOffset, final long brokerSuspendMaxTimeMillis, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; //找到Broker FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); if (null == findBrokerResult) &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(mq.getTopic()); findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); &#125; if (findBrokerResult != null) &#123; &#123;// check version 版本检查 if (!ExpressionType.isTagType(expressionType) &amp;&amp; findBrokerResult.getBrokerVersion() &lt; MQVersion.Version.V4_1_0_SNAPSHOT.ordinal()) &#123; throw new MQClientException(\"The broker[\" + mq.getBrokerName() + \", \" + findBrokerResult.getBrokerVersion() + \"] does not upgrade to support for filter message by \" + expressionType, null); &#125; &#125; int sysFlagInner = sysFlag; if (findBrokerResult.isSlave()) &#123; sysFlagInner = PullSysFlag.clearCommitOffsetFlag(sysFlagInner); &#125; //构建请求 PullMessageRequestHeader requestHeader = new PullMessageRequestHeader(); requestHeader.setConsumerGroup(this.consumerGroup); requestHeader.setTopic(mq.getTopic()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setQueueOffset(offset); requestHeader.setMaxMsgNums(maxNums); requestHeader.setSysFlag(sysFlagInner); requestHeader.setCommitOffset(commitOffset); requestHeader.setSuspendTimeoutMillis(brokerSuspendMaxTimeMillis); requestHeader.setSubscription(subExpression); requestHeader.setSubVersion(subVersion); requestHeader.setExpressionType(expressionType); String brokerAddr = findBrokerResult.getBrokerAddr(); if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) &#123; brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); &#125; //拉取消息 PullResult pullResult = this.mQClientFactory.getMQClientAPIImpl().pullMessage(brokerAddr, requestHeader, timeoutMillis, communicationMode, pullCallback); return pullResult; &#125; throw new MQClientException(\"The broker[\" + mq.getBrokerName() + \"] not exist\", null); &#125;&#125;public class MQClientAPIImpl &#123; public PullResult pullMessage(final String addr, final PullMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.PULL_MESSAGE, requestHeader); //几种拉取方式 switch (communicationMode) &#123; case ONEWAY: assert false; return null; case ASYNC: this.pullMessageAsync(addr, request, timeoutMillis, pullCallback); return null; case SYNC: return this.pullMessageSync(addr, request, timeoutMillis); default: assert false; break; &#125; return null; &#125; private void pullMessageAsync(final String addr, final RemotingCommand request, final long timeoutMillis, final PullCallback pullCallback) throws RemotingException, InterruptedException &#123; this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; //异步拉取 @Override public void operationComplete(ResponseFuture responseFuture) &#123; RemotingCommand response = responseFuture.getResponseCommand(); //处理拉取消息的结果 if (response != null) &#123; //有响应 try &#123; PullResult pullResult = MQClientAPIImpl.this.processPullResponse(response); assert pullResult != null; pullCallback.onSuccess(pullResult); &#125; catch (Exception e) &#123; pullCallback.onException(e); &#125; &#125; else &#123;//没响应 if (!responseFuture.isSendRequestOK()) &#123; pullCallback.onException(new MQClientException(\"send request failed to \" + addr + \". Request: \" + request, responseFuture.getCause())); &#125; else if (responseFuture.isTimeout()) &#123; pullCallback.onException(new MQClientException(\"wait response from \" + addr + \" timeout :\" + responseFuture.getTimeoutMillis() + \"ms\" + \". Request: \" + request, responseFuture.getCause())); &#125; else &#123; pullCallback.onException(new MQClientException(\"unknown reason. addr: \" + addr + \", timeoutMillis: \" + timeoutMillis + \". Request: \" + request, responseFuture.getCause())); &#125; &#125; &#125; &#125;); &#125;&#125; 在Broker通过PullMessageProcessor方法的processRequest方法处理RequestCode.PULL_MESSAGE请求。首先端构建消息过滤器，然后在DefaultMessageStore的getMessage查询消息中调用MessageFilter的isMatchedByConsumeQueue方法。若ResponseCode.PULL_NOT_FOUND未拉取到数据，则再创建一个拉取请求且通过PullRequestHoldService的suspendPullRequest将该请求放入ManyPullRequest请求拉取队列，从而实现长连接。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109private RemotingCommand processRequest(final Channel channel, RemotingCommand request, boolean brokerAllowSuspend) throws RemotingCommandException &#123; RemotingCommand response = RemotingCommand.createResponseCommand(PullMessageResponseHeader.class); final PullMessageResponseHeader responseHeader = (PullMessageResponseHeader) response.readCustomHeader(); final PullMessageRequestHeader requestHeader = (PullMessageRequestHeader) request.decodeCommandCustomHeader(PullMessageRequestHeader.class); response.setOpaque(request.getOpaque()); SubscriptionGroupConfig subscriptionGroupConfig = this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(requestHeader.getConsumerGroup()); final boolean hasSuspendFlag = PullSysFlag.hasSuspendFlag(requestHeader.getSysFlag()); final boolean hasCommitOffsetFlag = PullSysFlag.hasCommitOffsetFlag(requestHeader.getSysFlag()); final boolean hasSubscriptionFlag = PullSysFlag.hasSubscriptionFlag(requestHeader.getSysFlag()); final long suspendTimeoutMillisLong = hasSuspendFlag ? requestHeader.getSuspendTimeoutMillis() : 0; TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); SubscriptionData subscriptionData = null; ConsumerFilterData consumerFilterData = null; if (hasSubscriptionFlag) &#123; try &#123; subscriptionData = FilterAPI.build(requestHeader.getTopic(), requestHeader.getSubscription(), requestHeader.getExpressionType()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = ConsumerFilterManager.build(requestHeader.getTopic(), requestHeader.getConsumerGroup(), requestHeader.getSubscription(), requestHeader.getExpressionType(), requestHeader.getSubVersion()); assert consumerFilterData != null; &#125; &#125; &#125; else &#123; ConsumerGroupInfo consumerGroupInfo = this.brokerController.getConsumerManager().getConsumerGroupInfo(requestHeader.getConsumerGroup()); subscriptionData = consumerGroupInfo.findSubscriptionData(requestHeader.getTopic()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = this.brokerController.getConsumerFilterManager().get(requestHeader.getTopic(), requestHeader.getConsumerGroup()); &#125; &#125; //在Broker端构建消息过滤器 MessageFilter messageFilter; if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123; messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; else &#123; messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; // 获取消息 final GetMessageResult getMessageResult = this.brokerController.getMessageStore().getMessage(requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getQueueOffset(), requestHeader.getMaxMsgNums(), messageFilter); if (getMessageResult != null) &#123; response.setRemark(getMessageResult.getStatus().name()); responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset()); responseHeader.setMinOffset(getMessageResult.getMinOffset()); responseHeader.setMaxOffset(getMessageResult.getMaxOffset()); if (getMessageResult.isSuggestPullingFromSlave()) &#123; responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly()); &#125; else &#123; responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID); &#125; //消息拉取结果 switch (getMessageResult.getStatus()) &#123; case FOUND: response.setCode(ResponseCode.SUCCESS); break; case MESSAGE_WAS_REMOVING: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case NO_MATCHED_LOGIC_QUEUE: case NO_MESSAGE_IN_QUEUE: break; case NO_MATCHED_MESSAGE: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case OFFSET_FOUND_NULL: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_OVERFLOW_BADLY: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; case OFFSET_OVERFLOW_ONE: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_TOO_SMALL: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; default: assert false; break; &#125; switch (response.getCode()) &#123; case ResponseCode.SUCCESS: this.brokerController.getBrokerStatsManager().incGroupGetNums(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getMessageCount()); this.brokerController.getBrokerStatsManager().incGroupGetSize(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getBufferTotalSize()); this.brokerController.getBrokerStatsManager().incBrokerGetNums(getMessageResult.getMessageCount()); break; case ResponseCode.PULL_NOT_FOUND: if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123; long pollingTimeMills = suspendTimeoutMillisLong; if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;// 消息长轮询 pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills(); &#125; String topic = requestHeader.getTopic(); long offset = requestHeader.getQueueOffset(); int queueId = requestHeader.getQueueId(); //没有拉取到消息，就再创建一个拉取请求 PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills, this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter); //将请求放入ManyRequestPull请求队列，为了配合长连接处理 this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest); response = null; break; &#125; &#125; &#125; boolean storeOffsetEnable = brokerAllowSuspend; storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag; storeOffsetEnable = storeOffsetEnable &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE; if (storeOffsetEnable) &#123; this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel), requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset()); &#125; return response;&#125; 长轮询对于消息的发送基本能达到实时的效果，是通过PullRequestHoldService类中长轮训来实现的，该类是一个线程类，在Broker中的BrokerController中被实例化和启动。客户端拉取数时未拉取到数据就会将请求通过suspendPullRequest方法放入pullRequestTable中。在run方法中一直循环若没有消息就waitForRunning方法等待5s，若有数据则会被提前唤醒。然后通过checkHoldRequest方法检查请求对象，若有数据则将数据返回给客户端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class PullRequestHoldService extends ServiceThread &#123; private ConcurrentMap&lt;String, ManyPullRequest&gt; pullRequestTable = new ConcurrentHashMap&lt;String, ManyPullRequest&gt;(1024); public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123; String key = this.buildKey(topic, queueId); ManyPullRequest mpr = this.pullRequestTable.get(key); if (null == mpr) &#123; mpr = new ManyPullRequest(); ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr); if (prev != null) &#123; mpr = prev; &#125; &#125; mpr.addPullRequest(pullRequest); &#125; public void run() &#123; // 处理ManyPullRequest线程 while (!this.isStopped()) &#123; try &#123;// 如果开启了长轮询，等待5秒后再去查 if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123; this.waitForRunning(5 * 1000); &#125; else &#123;//没有开启长轮询，等待1秒后再去查。 this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills()); &#125; long beginLockTimestamp = this.systemClock.now(); this.checkHoldRequest(); //检查请求对象 long costTime = this.systemClock.now() - beginLockTimestamp; &#125; catch (Throwable e) &#123; &#125; &#125; &#125; private void checkHoldRequest() &#123; for (String key : this.pullRequestTable.keySet()) &#123; String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR); if (2 == kArray.length) &#123; String topic = kArray[0]; int queueId = Integer.parseInt(kArray[1]); //从CommitLog中检查是否有新的消息。 final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); try &#123;//通知消息到达 this.notifyMessageArriving(topic, queueId, offset); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset) &#123; notifyMessageArriving(topic, queueId, maxOffset, null, 0, null, null); &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset, final Long tagsCode, long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123; String key = this.buildKey(topic, queueId); //CommitLog消息到达通知 ManyPullRequest mpr = this.pullRequestTable.get(key); if (mpr != null) &#123; List&lt;PullRequest&gt; requestList = mpr.cloneListAndClear(); if (requestList != null) &#123; List&lt;PullRequest&gt; replayList = new ArrayList&lt;PullRequest&gt;(); for (PullRequest request : requestList) &#123; long newestOffset = maxOffset; if (newestOffset &lt;= request.getPullFromThisOffset()) &#123; newestOffset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); &#125; if (newestOffset &gt; request.getPullFromThisOffset()) &#123; //判断是否有新的消息 //检查新的消息是否是ConsumeQueue感兴趣的消息 boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode, new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap)); if (match &amp;&amp; properties != null) &#123; match = request.getMessageFilter().isMatchedByCommitLog(null, properties); &#125; if (match) &#123; //如果是感兴趣的消息，就等待线程唤醒后执行消息推送。 try &#123; this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; &#125; if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123; try &#123; //请求超时后也给客户端响应。 this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; replayList.add(request); &#125; if (!replayList.isEmpty()) &#123; mpr.addPullRequest(replayList); &#125; &#125; &#125; &#125;&#125;public class PullMessageProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public void executeRequestWhenWakeup(final Channel channel, final RemotingCommand request) throws RemotingCommandException &#123; Runnable run = new Runnable() &#123; @Override public void run() &#123; try &#123; final RemotingCommand response = PullMessageProcessor.this.processRequest(channel, request, false); if (response != null) &#123; response.setOpaque(request.getOpaque()); response.markResponseType(); try &#123; channel.writeAndFlush(response).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; &#125; &#125; &#125;); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; catch (RemotingCommandException e1) &#123; &#125; &#125; &#125;; this.brokerController.getPullMessageExecutor().submit(new RequestTask(run, channel, request)); &#125;&#125; 还有一种方式在DefaultMessageStore的ReputMessageService线程类的run方法中执行分发请求时，执行完分发请求后通过调用NotifyMessageArrivingListener的arriving方法从而调用PullRequestHoldService的notifyMessageArriving方法进行一起请求线程的检查从而通知到客户端。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667class ReputMessageService extends ServiceThread &#123; @Override public void run() &#123; while (!this.isStopped()) &#123; try &#123; // 每隔1毫秒，往ConsumeQueue和IndexFile中转发一次CommitLog写入的消息 Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; private void doReput() &#123; if (this.reputFromOffset &lt; DefaultMessageStore.this.commitLog.getMinOffset()) &#123; log.warn(\"The reputFromOffset=&#123;&#125; is smaller than minPyOffset=&#123;&#125;, this usually indicate that the dispatch behind too much and the commitlog has expired.\", this.reputFromOffset, DefaultMessageStore.this.commitLog.getMinOffset()); this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset(); &#125; for (boolean doNext = true; this.isCommitLogAvailable() &amp;&amp; doNext; ) &#123; if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &amp;&amp; this.reputFromOffset &gt;= DefaultMessageStore.this.getConfirmOffset()) &#123; break; &#125; SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); // 获取CommitLog中的消息 if (result != null) &#123; try &#123; this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; //从CommitLog中获取一个DispatchRequest,拿到一份需要进行转发的消息，也就是从commitlog中读取的。 DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); //分发CommitLog写入消息 // 长轮询： 如果有消息到了主节点，并且开启了长轮询。 if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; //唤醒NotifyMessageArrivingListener的arriving方法，进行一次请求线程的检查 DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap()); &#125; this.reputFromOffset += size; readSize += size; if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) &#123; // 从节点 DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet(); DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic()).addAndGet(dispatchRequest.getMsgSize()); &#125; &#125; else if (size == 0) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset); readSize = result.getSize(); &#125; &#125; else if (!dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; this.reputFromOffset += size; &#125; else &#123; doNext = false; if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() || DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) &#123; this.reputFromOffset += result.getSize() - readSize; &#125; &#125; &#125; &#125; &#125; finally &#123; result.release(); &#125; &#125; else &#123; doNext = false; &#125; &#125; &#125;&#125; 集群模式下消费者策略Consumer也是以MessageQueue为单位来进行负载均衡，分为集群模式和广播模式。广播模式下每条消息都会投递给订阅了Topic的所有消费者实例，在Consumer分配Queue时，所有Consumer都分到所有的Queue。集群消费模式每条消息只需要投递到订阅该Topic的Consumer Group下的一个实例，RocketMQ采用主动拉取方式拉取并消费消息，在拉取时需明确指定拉取哪一条MessageQueue。 每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时会按照Queue的数量和实例的数量平均分配Queue给每个实例。每次分配时都会将MessageQueue和消费者ID进行排序，再用不同的分配算法进行分配。内置的分配的算法共有六种，分别对应AllocateMessageQueueStrategy下的六种实现类，可在Consumer中直接指定。默认情况下使用的是最简单的平均分配策略。 AllocateMachineRoomNearby：将同机房的Consumer和Broker优先分配在一起。该策略可通过一个machineRoomResolver对象来定制Consumer和Broker的机房解析规则。还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配。一般用平均分配策略或轮询分配策略。 AllocateMessageQueueAveragely：平均分配，将所有MessageQueue平均分给每一个消费者 AllocateMessageQueueAveragelyByCircle： 轮询分配，轮流的给一个消费者分配一个MessageQueue。 AllocateMessageQueueByConfig： 直接指定一个messageQueue列表，类似于广播模式，直接指定所有队列。 AllocateMessageQueueByMachineRoom：按逻辑机房的概念进行分配。对BrokerName和ConsumerIdc有定制化的配置。 AllocateMessageQueueConsistentHash：一致性哈希策略只需要指定一个虚拟节点数，用一个哈希环算法，虚拟节点是为了让Hash数据在环上分布更为均匀。 对于消费者策略可以通过DefaultMQPushConsumer构造方法设置，默认是使用AllocateMessageQueueAveragely平均分配策略。且该负载均衡策略在RebalanceImpl的rebalanceByTopic方法中被调用。 123456789101112131415161718192021222324252627public class AllocateMessageQueueAveragely implements AllocateMessageQueueStrategy &#123; public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll, List&lt;String&gt; cidAll) &#123; if (currentCID == null || currentCID.length() &lt; 1) &#123; throw new IllegalArgumentException(\"currentCID is empty\"); &#125; if (mqAll == null || mqAll.isEmpty()) &#123; throw new IllegalArgumentException(\"mqAll is null or mqAll empty\"); &#125; if (cidAll == null || cidAll.isEmpty()) &#123; throw new IllegalArgumentException(\"cidAll is null or cidAll empty\"); &#125; List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;(); if (!cidAll.contains(currentCID)) &#123; log.info(\"[BUG] ConsumerGroup: &#123;&#125; The consumerId: &#123;&#125; not in cidAll: &#123;&#125;\", consumerGroup, currentCID, cidAll); return result; &#125; int index = cidAll.indexOf(currentCID); int mod = mqAll.size() % cidAll.size(); int averageSize = mqAll.size() &lt;= cidAll.size() ? 1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size() + 1 : mqAll.size() / cidAll.size()); int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod; int range = Math.min(averageSize, mqAll.size() - startIndex); for (int i = 0; i &lt; range; i++) &#123; result.add(mqAll.get((startIndex + i) % mqAll.size())); &#125; return result; &#125;&#125; 顺序消息12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.setNamesrvAddr(\"localhost:9876\");producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(\"OrderTopicTest\", \"order_\" + orderId, \"KEY\" + orderId, (\"order_\" + orderId + \" step \" + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; // 实际就是传入的orderId int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(\"%s%n\", sendResult); &#125;&#125;producer.shutdown(); 顺序消息，对于生产者发送消息需要将消息发送到同一个MessageQueue中，可通过MessageQueueSelector，对于需要保持顺序的消息传入同一个业务参数orderId，通过orderId对消息队列的取模得到一个固定的MessageQueue，在发送消息时就能将数据发送到同一个消息队列中了。但不能100%保证消息的顺序，若发生宕机可能导致发送到不同的MessageQueue中。 12345678910111213141516171819202122232425262728293031323334353637public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg, MessageQueueSelector selector, Object arg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg, selector, arg); &#125; private SendResult sendSelectImpl(Message msg, MessageQueueSelector selector, Object arg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; MessageQueue mq = null; try &#123; List&lt;MessageQueue&gt; messageQueueList = mQClientFactory.getMQAdminImpl().parsePublishMessageQueues(topicPublishInfo.getMessageQueueList()); Message userMessage = MessageAccessor.cloneMessage(msg); String userTopic = NamespaceUtil.withoutNamespace(userMessage.getTopic(), mQClientFactory.getClientConfig().getNamespace()); userMessage.setTopic(userTopic); // 这里回调上面示例中MessageQueueSelector的select方法，这里的arg就是传入的orderId mq = mQClientFactory.getClientConfig().queueWithNamespace(selector.select(messageQueueList, userMessage, arg)); &#125; catch (Throwable e) &#123; throw new MQClientException(\"select message queue throwed exception.\", e); &#125; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTime) &#123; throw new RemotingTooMuchRequestException(\"sendSelectImpl call timeout\"); &#125; if (mq != null) &#123; return this.sendKernelImpl(msg, mq, communicationMode, sendCallback, null, timeout - costTime); &#125; else &#123; throw new MQClientException(\"select message queue return null.\", null); &#125; &#125; validateNameServerSetting(); throw new MQClientException(\"No route info for this topic, \" + msg.getTopic(), null); &#125;&#125; 对于每个消费端在创建DefaultMQPushConsumer时指定consumerGroup，在DefaultMQPushConsumer的start方法中调用DefaultMQPushConsumerImpl的start方法从而将consumerGroup设置到RebalancePushImpl中。且通过registerMessageListener方法设置的MessageListenerOrderly会被赋值给DefaultMQPushConsumerImpl的messageListenerInner，在DefaultMQPushConsumerImpl的start方法中判断messageListenerInner类型最终调用ConsumeMessageOrderlyService的start方法启动异步线程。 1234567891011121314DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\");consumer.setNamesrvAddr(\"localhost:9876\");consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(\"OrderTopicTest\", \"*\");consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(\"收到消息内容 \" + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class DefaultMQPushConsumer extends ClientConfig implements MQPushConsumer &#123; private String consumerGroup; public DefaultMQPushConsumer(final String consumerGroup) &#123; this(null, consumerGroup, null, new AllocateMessageQueueAveragely()); &#125; public DefaultMQPushConsumer(final String namespace, final String consumerGroup, RPCHook rpcHook, AllocateMessageQueueStrategy allocateMessageQueueStrategy) &#123; this.consumerGroup = consumerGroup; this.namespace = namespace; this.allocateMessageQueueStrategy = allocateMessageQueueStrategy; defaultMQPushConsumerImpl = new DefaultMQPushConsumerImpl(this, rpcHook); &#125; public void registerMessageListener(MessageListenerOrderly messageListener) &#123; this.messageListener = messageListener; this.defaultMQPushConsumerImpl.registerMessageListener(messageListener); &#125; public void start() throws MQClientException &#123; setConsumerGroup(NamespaceUtil.wrapNamespace(this.getNamespace(), this.consumerGroup)); this.defaultMQPushConsumerImpl.start(); if (null != traceDispatcher) &#123; try &#123; traceDispatcher.start(this.getNamesrvAddr(), this.getAccessChannel()); &#125; catch (MQClientException e) &#123; &#125; &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void registerMessageListener(MessageListener messageListener) &#123; this.messageListenerInner = messageListener; &#125; public MessageListener getMessageListenerInner() &#123; return messageListenerInner; &#125; public synchronized void start() throws MQClientException &#123; switch (this.serviceState) &#123; case CREATE_JUST: this.serviceState = ServiceState.START_FAILED; this.checkConfig(); // 检查配置 this.copySubscription(); if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123; this.defaultMQPushConsumer.changeInstanceNameToPID(); &#125; //K2 客户端创建工厂，这个是核心对象 this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook); this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup()); this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel()); // 集群模式下消费者策略 this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy()); this.rebalanceImpl.setmQClientFactory(this.mQClientFactory); this.pullAPIWrapper = new PullAPIWrapper(mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode()); this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookList); if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123; this.offsetStore = this.defaultMQPushConsumer.getOffsetStore(); &#125; else &#123; switch (this.defaultMQPushConsumer.getMessageModel()) &#123; case BROADCASTING: this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; case CLUSTERING: this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; default: break; &#125; this.defaultMQPushConsumer.setOffsetStore(this.offsetStore); &#125; this.offsetStore.load(); //根据客户端配置实例化不同的consumeMessageService if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123; // 顺序消息 this.consumeOrderly = true; this.consumeMessageService = new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner()); &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123; // 非顺序消息 this.consumeOrderly = false; this.consumeMessageService = new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner()); &#125; this.consumeMessageService.start(); //注册本地的消费者组缓存。 boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this); if (!registerOK) &#123; this.serviceState = ServiceState.CREATE_JUST; this.consumeMessageService.shutdown(defaultMQPushConsumer.getAwaitTerminationMillisWhenShutdown()); throw new MQClientException(\"The consumer group[\" + this.defaultMQPushConsumer.getConsumerGroup() + \"] has been created before, specify another name please.\" + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL), null); &#125; mQClientFactory.start(); this.serviceState = ServiceState.RUNNING; break; case RUNNING: case START_FAILED: case SHUTDOWN_ALREADY: throw new MQClientException(\"The PushConsumer service state not OK, maybe started once, \" + this.serviceState + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK), null); default: break; &#125; this.updateTopicSubscribeInfoWhenSubscriptionChanged(); this.mQClientFactory.checkClientInBroker(); this.mQClientFactory.sendHeartbeatToAllBrokerWithLock(); this.mQClientFactory.rebalanceImmediately(); &#125;&#125; ConsumeMessageOrderlyService线程会每隔20s执行一次，最终调用RebalancePushImpl超类RebalanceImpl的lock方法，通过LockBatchRequestBody设置前面设置到RebalancePushImpl中的consumerGroup，向Broker获取队列锁，且将锁定的队列缓存到processQueueTable中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void start() &#123; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123; this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; // 每20s执行一次 ConsumeMessageOrderlyService.this.lockMQPeriodically(); &#125; &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); &#125; &#125; public synchronized void lockMQPeriodically() &#123; if (!this.stopped) &#123; this.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll(); &#125; &#125;&#125;public abstract class RebalanceImpl &#123; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125; public boolean lock(final MessageQueue mq) &#123; FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), MixAll.MASTER_ID, true); if (findBrokerResult != null) &#123; LockBatchRequestBody requestBody = new LockBatchRequestBody(); requestBody.setConsumerGroup(this.consumerGroup); requestBody.setClientId(this.mQClientFactory.getClientId()); requestBody.getMqSet().add(mq); try &#123; Set&lt;MessageQueue&gt; lockedMq = this.mQClientFactory.getMQClientAPIImpl().lockBatchMQ(findBrokerResult.getBrokerAddr(), requestBody, 1000); for (MessageQueue mmqq : lockedMq) &#123; ProcessQueue processQueue = this.processQueueTable.get(mmqq); if (processQueue != null) &#123; processQueue.setLocked(true); processQueue.setLastLockTimestamp(System.currentTimeMillis()); &#125; &#125; boolean lockOK = lockedMq.contains(mq); return lockOK; &#125; catch (Exception e) &#123; &#125; &#125; return false; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; class ConsumeRequest implements Runnable &#123; private final ProcessQueue processQueue; private final MessageQueue messageQueue; @Override public void run() &#123; // 每一个ConsumeRequest消费任务不是以消费消息条数来计算，而是根据消费时间，默认当消费时长大于MAX_TIME_CONSUME_CONTINUOUSLY，默认60s后，本次消费任务结束，由消费组内其他线程继续消费 if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123; // 通过加锁，将并发的消息顺序进行消费。消息处理的方式没什么特别。 // 广播模式直接进入消费，无需锁定处理对列因为相互直接无竞争，集群模式proceessQueue被锁定并且锁未超时 if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); if (this.processQueue.isDropped()) &#123; break; &#125; status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://yaoyinglong.github.io/tags/RocketMQ/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"RocketMQ消息存储源码","date":"2021-12-01T16:00:00.000Z","path":"Blog/Cloud/MQ/RocketMQ消息存储源码/","text":"RocketMQ的存储文件包括消息文件Commitlog、消息消费队列文件ConsumerQueue、Hash索引文件IndexFile、监测点文件checkPoint、abort关闭异常文件。单个消息存储文件、消息消费队列文件、Hash索引文件长度固定以便使用内存映射机制进行文件的读写操作。 RocketMQ组织文件以文件起始偏移量来命令文件，根据偏移量能快速定位到真实物理文件。基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制，异步刷盘是指在消息存储时先追加到内存映射文件，然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘。 为了保证消息发送的高吞吐量，采用单一文件存储所有主题消息，保证消息存储是完全的顺序写，但这样给文件读取带来了不便，为了方便消息消费构建了消息消费队列文件，基于主题与队列进行组织，同时为消息实现了Hash索引，可以为消息设置索引键，故能快速从CommitLog文件中检索消息。 当消息达到CommitLog后，会通过ReputMessageService线程接近实时地将消息转发给消息消费队列文件与索引文件。为了安全起见引入abort文件，记录Broker停机是否是正常关闭，在重启Broker时为了保证CommitLog文件、消息消费队列文件与Hash索引文件的正确性，分别采用不同策略来恢复文件。 RocketMQ不会永久存储消息文件、消息消费队列文件，而是启动文件过期机制并在磁盘空间不足或默认4点删除过期文件，文件保存72小时并且在删除文件时并不会判断该消息文件上的消息是否被消费。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DefaultMessageStore implements MessageStore &#123; public void start() throws Exception &#123; lock = lockFile.getChannel().tryLock(0, 1, false); if (lock == null || lock.isShared() || !lock.isValid()) &#123; throw new RuntimeException(\"Lock failed,MQ already started\"); &#125; lockFile.getChannel().write(ByteBuffer.wrap(\"lock\".getBytes())); lockFile.getChannel().force(true); &#123; long maxPhysicalPosInLogicQueue = commitLog.getMinOffset(); for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) &#123; for (ConsumeQueue logic : maps.values()) &#123; if (logic.getMaxPhysicOffset() &gt; maxPhysicalPosInLogicQueue) &#123; maxPhysicalPosInLogicQueue = logic.getMaxPhysicOffset(); &#125; &#125; &#125; if (maxPhysicalPosInLogicQueue &lt; 0) &#123; maxPhysicalPosInLogicQueue = 0; &#125; if (maxPhysicalPosInLogicQueue &lt; this.commitLog.getMinOffset()) &#123; maxPhysicalPosInLogicQueue = this.commitLog.getMinOffset(); &#125; // Broker启动时会启动一个线程来更新ConsumerQueue索引文件。 this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue); this.reputMessageService.start(); while (true) &#123; if (dispatchBehindBytes() &lt;= 0) &#123; break; &#125; Thread.sleep(1000); &#125; this.recoverTopicQueueTable(); &#125; if (!messageStoreConfig.isEnableDLegerCommitLog()) &#123; this.haService.start(); this.handleScheduleMessageService(messageStoreConfig.getBrokerRole()); &#125; this.flushConsumeQueueService.start(); this.commitLog.start(); this.storeStatsService.start(); this.createTempFile(); this.addScheduleTask(); // Broker启动删除过期文件的定时任务 this.shutdown = false; &#125;&#125; 消息存储对于消息的存储是通过DefaultMessageStore的putMessage方法最终调用CommitLog的putMessage方法从而使用mmap零拷贝来完成数据的存储。对于延迟消息会将实际的Topic替换为SCHEDULE_TOPIC_XXXX，通过异步任务当到达时间点时再从该队列中取出再放入原来实际的Topic中。 对于CommitLog文件的写同一时间只能有一个线程，首先会获取当前要写的MappedFile，若该文件已满或不存在则创建一个MappedFile，通过MappedFile的appendMessage方法将数据写入缓存中。然后执行handleDiskFlush方法将缓存中的数据刷到磁盘中，以及通过handleHA方法进行主从同步。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public interface MessageStore &#123; default CompletableFuture&lt;PutMessageResult&gt; asyncPutMessage(final MessageExtBrokerInner msg) &#123; return CompletableFuture.completedFuture(putMessage(msg)); &#125;&#125;public class DefaultMessageStore implements MessageStore &#123; public PutMessageResult putMessage(MessageExtBrokerInner msg) &#123; PutMessageStatus checkStoreStatus = this.checkStoreStatus(); if (checkStoreStatus != PutMessageStatus.PUT_OK) &#123; return new PutMessageResult(checkStoreStatus, null); &#125; PutMessageStatus msgCheckStatus = this.checkMessage(msg); if (msgCheckStatus == PutMessageStatus.MESSAGE_ILLEGAL) &#123; return new PutMessageResult(msgCheckStatus, null); &#125; long beginTime = this.getSystemClock().now(); //我们跟踪下这个最典型的消息写入commitlog的方法 PutMessageResult result = this.commitLog.putMessage(msg); long elapsedTime = this.getSystemClock().now() - beginTime; this.storeStatsService.setPutMessageEntireTimeMax(elapsedTime); if (null == result || !result.isOk()) &#123; this.storeStatsService.getPutMessageFailedTimes().incrementAndGet(); &#125; return result; &#125;&#125;public class CommitLog &#123; public PutMessageResult putMessage(final MessageExtBrokerInner msg) &#123; msg.setStoreTimestamp(System.currentTimeMillis()); // Set the storage time msg.setBodyCRC(UtilAll.crc32(msg.getBody())); AppendMessageResult result = null; StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService(); String topic = msg.getTopic(); int queueId = msg.getQueueId(); final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag()); if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) &#123; if (msg.getDelayTimeLevel() &gt; 0) &#123; // Delay Delivery if (msg.getDelayTimeLevel() &gt; this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) &#123; msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()); &#125; topic = TopicValidator.RMQ_SYS_SCHEDULE_TOPIC; // 将消息的Topic替换为SCHEDULE_TOPIC_XXXX queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); msg.setTopic(topic); msg.setQueueId(queueId); &#125; &#125; InetSocketAddress bornSocketAddress = (InetSocketAddress) msg.getBornHost(); if (bornSocketAddress.getAddress() instanceof Inet6Address) &#123; msg.setBornHostV6Flag(); &#125; InetSocketAddress storeSocketAddress = (InetSocketAddress) msg.getStoreHost(); if (storeSocketAddress.getAddress() instanceof Inet6Address) &#123; msg.setStoreHostAddressV6Flag(); &#125; long elapsedTimeInLock = 0; MappedFile unlockMappedFile = null; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(); //mappedFile 零拷贝实现 putMessageLock.lock(); // 线程锁 注意使用锁的这种方式 try &#123; long beginLockTimestamp = this.defaultMessageStore.getSystemClock().now(); this.beginTimeInLock = beginLockTimestamp; msg.setStoreTimestamp(beginLockTimestamp); if (null == mappedFile || mappedFile.isFull()) &#123; mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise &#125; if (null == mappedFile) &#123; beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null); &#125; // 直接以Append的方式写入文件 result = mappedFile.appendMessage(msg, this.appendMessageCallback); switch (result.getStatus()) &#123; // 文件写入的结果 case PUT_OK: break; case END_OF_FILE: //文件写满了，就创建一个新文件，重写消息 unlockMappedFile = mappedFile; mappedFile = this.mappedFileQueue.getLastMappedFile(0); if (null == mappedFile) &#123; beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result); &#125; result = mappedFile.appendMessage(msg, this.appendMessageCallback); break; case MESSAGE_SIZE_EXCEEDED: case PROPERTIES_SIZE_EXCEEDED: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result); case UNKNOWN_ERROR: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result); default: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result); &#125; elapsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginLockTimestamp; beginTimeInLock = 0; &#125; finally &#123; putMessageLock.unlock(); &#125; if (null != unlockMappedFile &amp;&amp; this.defaultMessageStore.getMessageStoreConfig().isWarmMapedFileEnable()) &#123; this.defaultMessageStore.unlockMappedFile(unlockMappedFile); &#125; PutMessageResult putMessageResult = new PutMessageResult(PutMessageStatus.PUT_OK, result); storeStatsService.getSinglePutMessageTopicTimesTotal(msg.getTopic()).incrementAndGet(); storeStatsService.getSinglePutMessageTopicSizeTotal(topic).addAndGet(result.getWroteBytes()); handleDiskFlush(result, putMessageResult, msg); //文件刷盘 handleHA(result, putMessageResult, msg); //主从同步 return putMessageResult; &#125;&#125; MappedFileQueue对应CommitLog目录下的文件，文件名称为第一个数据的偏移量加个上文件的固定大小，最终会通过AllocateMappedFileService的putRequestAndReturnMappedFile方法创建一个MappedFile对象。 123456789101112131415161718192021222324252627282930313233343536public class MappedFileQueue &#123; // MappedFileQueue对应CommitLog目录下的文件 public MappedFile getLastMappedFile(final long startOffset) &#123; return getLastMappedFile(startOffset, true); &#125; public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) &#123; long createOffset = -1; MappedFile mappedFileLast = getLastMappedFile(); if (mappedFileLast == null) &#123; createOffset = startOffset - (startOffset % this.mappedFileSize); &#125; if (mappedFileLast != null &amp;&amp; mappedFileLast.isFull()) &#123; createOffset = mappedFileLast.getFileFromOffset() + this.mappedFileSize; &#125; if (createOffset != -1 &amp;&amp; needCreate) &#123; String nextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset); String nextNextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset + this.mappedFileSize); MappedFile mappedFile = null; if (this.allocateMappedFileService != null) &#123; mappedFile = this.allocateMappedFileService.putRequestAndReturnMappedFile(nextFilePath, nextNextFilePath, this.mappedFileSize); &#125; else &#123; try &#123; mappedFile = new MappedFile(nextFilePath, this.mappedFileSize); &#125; catch (IOException e) &#123; &#125; &#125; if (mappedFile != null) &#123; if (this.mappedFiles.isEmpty()) &#123; mappedFile.setFirstCreateInQueue(true); &#125; this.mappedFiles.add(mappedFile); &#125; return mappedFile; &#125; return mappedFileLast; &#125;&#125; AllocateMappedFileService是一个线程类，putRequestAndReturnMappedFile中会把任务放入队列中，然后在run方法中取处理任务，该线程是在DefaultMessageStore的构造方法中创建启动。这里会将写满的文件刷到磁盘中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131public class AllocateMappedFileService extends ServiceThread &#123; private ConcurrentMap&lt;String, AllocateRequest&gt; requestTable = new ConcurrentHashMap&lt;String, AllocateRequest&gt;(); private PriorityBlockingQueue&lt;AllocateRequest&gt; requestQueue = new PriorityBlockingQueue&lt;AllocateRequest&gt;(); public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) &#123; int canSubmitRequests = 2; if (this.messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; if (this.messageStore.getMessageStoreConfig().isFastFailIfNoBufferInStorePool() &amp;&amp; BrokerRole.SLAVE != this.messageStore.getMessageStoreConfig().getBrokerRole()) &#123; //if broker is slave, don't fast fail even no buffer in pool canSubmitRequests = this.messageStore.getTransientStorePool().availableBufferNums() - this.requestQueue.size(); &#125; &#125; AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize); boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null; if (nextPutOK) &#123; if (canSubmitRequests &lt;= 0) &#123; this.requestTable.remove(nextFilePath); return null; &#125; boolean offerOK = this.requestQueue.offer(nextReq); canSubmitRequests--; &#125; AllocateRequest nextNextReq = new AllocateRequest(nextNextFilePath, fileSize); boolean nextNextPutOK = this.requestTable.putIfAbsent(nextNextFilePath, nextNextReq) == null; if (nextNextPutOK) &#123; if (canSubmitRequests &lt;= 0) &#123; this.requestTable.remove(nextNextFilePath); &#125; else &#123; boolean offerOK = this.requestQueue.offer(nextNextReq); &#125; &#125; if (hasException) &#123; return null; &#125; AllocateRequest result = this.requestTable.get(nextFilePath); try &#123; if (result != null) &#123; boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS); if (!waitOK) &#123; return null; &#125; else &#123; this.requestTable.remove(nextFilePath); return result.getMappedFile(); &#125; &#125; &#125; return null; &#125; public void run() &#123; while (!this.isStopped() &amp;&amp; this.mmapOperation()) &#123; &#125; &#125; private boolean mmapOperation() &#123; boolean isSuccess = false; AllocateRequest req = null; try &#123; req = this.requestQueue.take(); AllocateRequest expectedRequest = this.requestTable.get(req.getFilePath()); if (null == expectedRequest) &#123; return true; &#125; if (expectedRequest != req) &#123; return true; &#125; if (req.getMappedFile() == null) &#123; long beginTime = System.currentTimeMillis(); MappedFile mappedFile; if (messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; try &#123; mappedFile = ServiceLoader.load(MappedFile.class).iterator().next(); mappedFile.init(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool()); &#125; catch (RuntimeException e) &#123; mappedFile = new MappedFile(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool()); &#125; &#125; else &#123; mappedFile = new MappedFile(req.getFilePath(), req.getFileSize()); &#125; long elapsedTime = UtilAll.computeElapsedTimeMilliseconds(beginTime); if (elapsedTime &gt; 10) &#123; int queueSize = this.requestQueue.size(); &#125; if (mappedFile.getFileSize() &gt;= this.messageStore.getMessageStoreConfig().getMappedFileSizeCommitLog() &amp;&amp; this.messageStore.getMessageStoreConfig().isWarmMapedFileEnable()) &#123; mappedFile.warmMappedFile(this.messageStore.getMessageStoreConfig().getFlushDiskType(), this.messageStore.getMessageStoreConfig().getFlushLeastPagesWhenWarmMapedFile()); &#125; req.setMappedFile(mappedFile); this.hasException = false; isSuccess = true; &#125; &#125; catch (InterruptedException e) &#123; this.hasException = true; return false; &#125; catch (IOException e) &#123; this.hasException = true; if (null != req) &#123; requestQueue.offer(req); try &#123; Thread.sleep(1); &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125; finally &#123; if (req != null &amp;&amp; isSuccess) req.getCountDownLatch().countDown(); &#125; return true; &#125;&#125;public class MappedFile extends ReferenceResource &#123; public void warmMappedFile(FlushDiskType type, int pages) &#123; long beginTime = System.currentTimeMillis(); ByteBuffer byteBuffer = this.mappedByteBuffer.slice(); int flush = 0; long time = System.currentTimeMillis(); for (int i = 0, j = 0; i &lt; this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) &#123; byteBuffer.put(i, (byte) 0); if (type == FlushDiskType.SYNC_FLUSH) &#123; if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) &gt;= pages) &#123; flush = i; mappedByteBuffer.force(); // force flush when flush disk type is sync &#125; &#125; if (j % 1000 == 0) &#123; // prevent gc try &#123; Thread.sleep(0); &#125; &#125; &#125; if (type == FlushDiskType.SYNC_FLUSH) &#123; mappedByteBuffer.force(); // force flush when prepare load finished &#125; this.mlock(); &#125;&#125; 消息是通过MappedFile的appendMessage方法以Append的方式写入文件缓存中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class MappedFile extends ReferenceResource &#123; public AppendMessageResult appendMessage(final MessageExtBrokerInner msg, final AppendMessageCallback cb) &#123; return appendMessagesInner(msg, cb); &#125; public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) &#123; assert messageExt != null; assert cb != null; int currentPos = this.wrotePosition.get(); if (currentPos &lt; this.fileSize) &#123; ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); byteBuffer.position(currentPos); AppendMessageResult result; if (messageExt instanceof MessageExtBrokerInner) &#123; result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt); &#125; else if (messageExt instanceof MessageExtBatch) &#123; result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt); &#125; else &#123; return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR); &#125; this.wrotePosition.addAndGet(result.getWroteBytes()); this.storeTimestamp = result.getStoreTimestamp(); return result; &#125; return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR); &#125;&#125;public class CommitLog &#123; public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank, final MessageExtBatch messageExtBatch) &#123; byteBuffer.mark(); long wroteOffset = fileFromOffset + byteBuffer.position(); //physical offset keyBuilder.setLength(0); // Record ConsumeQueue information keyBuilder.append(messageExtBatch.getTopic()); keyBuilder.append('-'); keyBuilder.append(messageExtBatch.getQueueId()); String key = keyBuilder.toString(); Long queueOffset = CommitLog.this.topicQueueTable.get(key); if (null == queueOffset) &#123; queueOffset = 0L; CommitLog.this.topicQueueTable.put(key, queueOffset); &#125; long beginQueueOffset = queueOffset; int totalMsgLen = 0; int msgNum = 0; msgIdBuilder.setLength(0); final long beginTimeMills = CommitLog.this.defaultMessageStore.now(); ByteBuffer messagesByteBuff = messageExtBatch.getEncodedBuff(); int sysFlag = messageExtBatch.getSysFlag(); int storeHostLength = (sysFlag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0 ? 4 + 4 : 16 + 4; ByteBuffer storeHostHolder = ByteBuffer.allocate(storeHostLength); this.resetByteBuffer(storeHostHolder, storeHostLength); ByteBuffer storeHostBytes = messageExtBatch.getStoreHostBytes(storeHostHolder); messagesByteBuff.mark(); while (messagesByteBuff.hasRemaining()) &#123; final int msgPos = messagesByteBuff.position(); // 1 TOTALSIZE final int msgLen = messagesByteBuff.getInt(); final int bodyLen = msgLen - 40; //only for log, just estimate it if (msgLen &gt; this.maxMessageSize) &#123; // Exceeds the maximum message CommitLog.log.warn(\"message size exceeded, msg total size: \" + msgLen + \", msg body size: \" + bodyLen + \", maxMessageSize: \" + this.maxMessageSize); return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED); &#125; totalMsgLen += msgLen; if ((totalMsgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) &#123; // Determines whether there is sufficient free space this.resetByteBuffer(this.msgStoreItemMemory, 8); this.msgStoreItemMemory.putInt(maxBlank); // 1 TOTALSIZE this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 2 MAGICCODE messagesByteBuff.reset(); // 3 The remaining space may be any value ignore previous read byteBuffer.reset(); //Here the length of the specially set maxBlank ignore the previous appended messages byteBuffer.put(this.msgStoreItemMemory.array(), 0, 8); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgIdBuilder.toString(), messageExtBatch.getStoreTimestamp(), beginQueueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills); &#125; messagesByteBuff.position(msgPos + 20); //move to add queue offset and commitlog offset messagesByteBuff.putLong(queueOffset); messagesByteBuff.putLong(wroteOffset + totalMsgLen - msgLen); storeHostBytes.rewind(); String msgId; if ((sysFlag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0) &#123; msgId = MessageDecoder.createMessageId(this.msgIdMemory, storeHostBytes, wroteOffset + totalMsgLen - msgLen); &#125; else &#123; msgId = MessageDecoder.createMessageId(this.msgIdV6Memory, storeHostBytes, wroteOffset + totalMsgLen - msgLen); &#125; if (msgIdBuilder.length() &gt; 0) &#123; msgIdBuilder.append(',').append(msgId); &#125; else &#123; msgIdBuilder.append(msgId); &#125; queueOffset++; msgNum++; messagesByteBuff.position(msgPos + msgLen); &#125; messagesByteBuff.position(0); messagesByteBuff.limit(totalMsgLen); byteBuffer.put(messagesByteBuff); messageExtBatch.setEncodedBuff(null); AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, totalMsgLen, msgIdBuilder.toString(), messageExtBatch.getStoreTimestamp(), beginQueueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills); result.setMsgNum(msgNum); CommitLog.this.topicQueueTable.put(key, queueOffset); return result; &#125;&#125; 同步数据刷盘是通过CommitLog的handleDiskFlush方法来完成的，最终将耍盘任务通过putRequest方法提交到GroupCommitService中，异步消息刷盘任务也是调用的putRequest方法，GroupCommitService是一个线程在CommitLog的start方法中被启动，从run方法中可知该刷盘任务每10ms执行一次。最终调用MappedFileQueue的flush方法强迫把写入内存的数据刷入到磁盘文件中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public class CommitLog &#123; public CompletableFuture&lt;PutMessageStatus&gt; submitFlushRequest(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) &#123; if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123; final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; if (messageExt.isWaitStoreMsgOK()) &#123; GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes(), this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); service.putRequest(request); return request.future(); // 直接返回future不会同步等待 &#125; else &#123; service.wakeup(); return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK); &#125; &#125; else &#123; // 若打开了对外内存，就需要先将对外内存写入到文件映射中，再存盘 if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; flushCommitLogService.wakeup(); &#125; else &#123; commitLogService.wakeup(); &#125; return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK); &#125; &#125; public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) &#123; if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123; // Synchronization flush 同步刷盘 final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; if (messageExt.isWaitStoreMsgOK()) &#123;//构建一个GroupCommitRequest，交给GroupCommitService处理。 GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); CompletableFuture&lt;PutMessageStatus&gt; flushOkFuture = request.future(); PutMessageStatus flushStatus = null; try &#123; //同步等待文件刷新 flushStatus = flushOkFuture.get(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout(), TimeUnit.MILLISECONDS); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; &#125; if (flushStatus != PutMessageStatus.PUT_OK) &#123; putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125; &#125; else &#123; service.wakeup(); &#125; &#125; else &#123; // Asynchronous flush 异步刷盘，异步刷盘是把消息映射到MappedFile后，单独唤醒一个服务来进行刷盘 if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; flushCommitLogService.wakeup(); &#125; else &#123; commitLogService.wakeup(); &#125; &#125; &#125;&#125;class GroupCommitService extends FlushCommitLogService &#123; private volatile List&lt;GroupCommitRequest&gt; requestsWrite = new ArrayList&lt;GroupCommitRequest&gt;(); private volatile List&lt;GroupCommitRequest&gt; requestsRead = new ArrayList&lt;GroupCommitRequest&gt;(); public synchronized void putRequest(final GroupCommitRequest request) &#123; synchronized (this.requestsWrite) &#123; this.requestsWrite.add(request); &#125; this.wakeup(); &#125; public void run() &#123; while (!this.isStopped()) &#123; try &#123; this.waitForRunning(10); this.doCommit(); &#125; &#125; try &#123;// Under normal circumstances shutdown, wait for the arrival of the request, and then flush Thread.sleep(10); &#125; synchronized (this) &#123; this.swapRequests(); &#125; this.doCommit(); &#125; private void doCommit() &#123; synchronized (this.requestsRead) &#123; if (!this.requestsRead.isEmpty()) &#123; for (GroupCommitRequest req : this.requestsRead) &#123; // 消息刷盘 // There may be a message in the next file, so a maximum of two times the flush boolean flushOK = false; for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) &#123; flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset(); if (!flushOK) &#123; // 当前索引位置小于请求数据的位置执行刷盘 CommitLog.this.mappedFileQueue.flush(0); &#125; &#125; req.wakeupCustomer(flushOK ? PutMessageStatus.PUT_OK : PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125; long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp(); if (storeTimestamp &gt; 0) &#123; CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp); &#125; this.requestsRead.clear(); &#125; else &#123; // Because of individual messages is set to not sync flush, it will come to this process CommitLog.this.mappedFileQueue.flush(0); &#125; &#125; &#125;&#125;public class MappedFileQueue &#123; public boolean flush(final int flushLeastPages) &#123; boolean result = true; MappedFile mappedFile = this.findMappedFileByOffset(this.flushedWhere, this.flushedWhere == 0); if (mappedFile != null) &#123; long tmpTimeStamp = mappedFile.getStoreTimestamp(); int offset = mappedFile.flush(flushLeastPages); long where = mappedFile.getFileFromOffset() + offset; result = where == this.flushedWhere; this.flushedWhere = where; if (0 == flushLeastPages) &#123; this.storeTimestamp = tmpTimeStamp; &#125; &#125; return result; &#125;&#125;public int flush(final int flushLeastPages) &#123; if (this.isAbleToFlush(flushLeastPages)) &#123; if (this.hold()) &#123; int value = getReadPosition(); try &#123; // force方法就是强迫把写入内存的数据刷入到磁盘文件里去 if (writeBuffer != null || this.fileChannel.position() != 0) &#123; this.fileChannel.force(false); &#125; else &#123; this.mappedByteBuffer.force(); &#125; &#125; this.flushedPosition.set(value); this.release(); &#125; else &#123; this.flushedPosition.set(getReadPosition()); &#125; &#125; return this.getFlushedPosition();&#125; 消息分发当CommitLog写入一条消息后，会有一个后台线程ReputMessageService每隔1ms就会去拉取CommitLog中最新更新的一批消息，然后分别转发到ComsumeQueue和IndexFile中。若服务异常宕机，会造成CommitLog和ConsumeQueue、IndexFile文件不一致，有消息写入CommitLog后，没有分发到索引文件，这样消息就丢失了。DefaultMappedStore的load方法提供了恢复索引文件的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class ReputMessageService extends ServiceThread &#123; public void run() &#123; while (!this.isStopped()) &#123; try &#123; // 每隔1毫秒，往ConsumeQueue和IndexFile中转发一次CommitLog写入的消息 Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; private void doReput() &#123; if (this.reputFromOffset &lt; DefaultMessageStore.this.commitLog.getMinOffset()) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset(); &#125; for (boolean doNext = true; this.isCommitLogAvailable() &amp;&amp; doNext; ) &#123; if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &amp;&amp; this.reputFromOffset &gt;= DefaultMessageStore.this.getConfirmOffset()) &#123; break; &#125; SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); // 获取CommitLog中的消息 if (result != null) &#123; try &#123; this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; //从CommitLog中获取一个DispatchRequest,拿到一份需要进行转发的消息，也就是从commitlog中读取的。 DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); //分发CommitLog写入消息 // 长轮询： 如果有消息到了主节点，并且开启了长轮询。 if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; //唤醒NotifyMessageArrivingListener的arriving方法，进行一次请求线程的检查 DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap()); &#125; this.reputFromOffset += size; readSize += size; if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) &#123; DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet(); DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic()).addAndGet(dispatchRequest.getMsgSize()); &#125; &#125; else if (size == 0) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset); readSize = result.getSize(); &#125; &#125; else if (!dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; this.reputFromOffset += size; &#125; else &#123; doNext = false; if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() || DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) &#123; this.reputFromOffset += result.getSize() - readSize; &#125; &#125; &#125; &#125; &#125; finally &#123; result.release(); &#125; &#125; else &#123; doNext = false; &#125; &#125; &#125; public void doDispatch(DispatchRequest req) &#123; for (CommitLogDispatcher dispatcher : this.dispatcherList) &#123; dispatcher.dispatch(req); // 将commitLog写入的事件转发到ComsumeQueue和IndexFile &#125; &#125;&#125; 对于ConsumeQueue文件的写入是通过调用CommitLogDispatcherBuildConsumeQueue的dispatch方法，在分发时首先通过DefaultMessageStore的findConsumeQueue方法按消息Topic和queueId找到对应的消息队列，然后调用ConsumeQueue的putMessagePositionInfoWrapper正则去完成写入到对应的缓存以及刷盘工作。最终调用的MappedFile的appendMessage来完成数据的持久化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; // Consumequeue文件分发的构建器 final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: DefaultMessageStore.this.putMessagePositionInfo(request); break; case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: break; &#125; &#125;&#125;public class DefaultMessageStore implements MessageStore &#123; private final ConcurrentMap&lt;String, ConcurrentMap&lt;Integer, ConsumeQueue&gt;&gt; consumeQueueTable; public void putMessagePositionInfo(DispatchRequest dispatchRequest) &#123; ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); cq.putMessagePositionInfoWrapper(dispatchRequest); &#125; public ConsumeQueue findConsumeQueue(String topic, int queueId) &#123; // 获取具体的队列 ConcurrentMap&lt;Integer, ConsumeQueue&gt; map = consumeQueueTable.get(topic); if (null == map) &#123; ConcurrentMap&lt;Integer, ConsumeQueue&gt; newMap = new ConcurrentHashMap&lt;Integer, ConsumeQueue&gt;(128); ConcurrentMap&lt;Integer, ConsumeQueue&gt; oldMap = consumeQueueTable.putIfAbsent(topic, newMap); if (oldMap != null) &#123; map = oldMap; &#125; else &#123; map = newMap; &#125; &#125; ConsumeQueue logic = map.get(queueId); if (null == logic) &#123; ConsumeQueue newLogic = new ConsumeQueue(topic, queueId, StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), this.getMessageStoreConfig().getMappedFileSizeConsumeQueue(), this); ConsumeQueue oldLogic = map.putIfAbsent(queueId, newLogic); if (oldLogic != null) &#123; logic = oldLogic; &#125; else &#123; logic = newLogic; &#125; &#125; return logic; &#125;&#125;public class ConsumeQueue &#123; public void putMessagePositionInfoWrapper(DispatchRequest request) &#123; final int maxRetries = 30; boolean canWrite = this.defaultMessageStore.getRunningFlags().isCQWriteable(); for (int i = 0; i &lt; maxRetries &amp;&amp; canWrite; i++) &#123; long tagsCode = request.getTagsCode(); if (isExtWriteEnable()) &#123; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); cqExtUnit.setFilterBitMap(request.getBitMap()); cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); cqExtUnit.setTagsCode(request.getTagsCode()); long extAddr = this.consumeQueueExt.put(cqExtUnit); if (isExtAddr(extAddr)) &#123; tagsCode = extAddr; &#125; &#125; // ConsumeQueue数据分发 boolean result = this.putMessagePositionInfo(request.getCommitLogOffset(), request.getMsgSize(), tagsCode, request.getConsumeQueueOffset()); if (result) &#123; if (this.defaultMessageStore.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE || this.defaultMessageStore.getMessageStoreConfig().isEnableDLegerCommitLog()) &#123; this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(request.getStoreTimestamp()); &#125; this.defaultMessageStore.getStoreCheckpoint().setLogicsMsgTimestamp(request.getStoreTimestamp()); return; &#125; else &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; this.defaultMessageStore.getRunningFlags().makeLogicsQueueError(); &#125; private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode, final long cqOffset) &#123; if (offset + size &lt;= this.maxPhysicOffset) &#123; return true; &#125; this.byteBufferIndex.flip(); this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE); this.byteBufferIndex.putLong(offset); this.byteBufferIndex.putInt(size); this.byteBufferIndex.putLong(tagsCode); final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset); if (mappedFile != null) &#123; if (mappedFile.isFirstCreateInQueue() &amp;&amp; cqOffset != 0 &amp;&amp; mappedFile.getWrotePosition() == 0) &#123; this.minLogicOffset = expectLogicOffset; this.mappedFileQueue.setFlushedWhere(expectLogicOffset); this.mappedFileQueue.setCommittedWhere(expectLogicOffset); this.fillPreBlank(mappedFile, expectLogicOffset); &#125; if (cqOffset != 0) &#123; long currentLogicOffset = mappedFile.getWrotePosition() + mappedFile.getFileFromOffset(); if (expectLogicOffset &lt; currentLogicOffset) &#123; return true; &#125; &#125; this.maxPhysicOffset = offset + size; return mappedFile.appendMessage(this.byteBufferIndex.array()); &#125; return false; &#125;&#125; 对于Index文件的分发是通过CommitLogDispatcherBuildIndex中最终调用IndexService的buildIndex方法完成的，首先先通过retryGetAndCreateIndexFile获取IndexFile，若不存在则创建，让后通过IndexFile的putKey方法将数据写入磁盘。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169class CommitLogDispatcherBuildIndex implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) &#123; DefaultMessageStore.this.indexService.buildIndex(request); &#125; &#125;&#125;public class IndexService &#123; public void buildIndex(DispatchRequest req) &#123; IndexFile indexFile = retryGetAndCreateIndexFile(); if (indexFile != null) &#123; long endPhyOffset = indexFile.getEndPhyOffset(); DispatchRequest msg = req; String topic = msg.getTopic(); String keys = msg.getKeys(); if (msg.getCommitLogOffset() &lt; endPhyOffset) &#123; //重复消息直接返回 return; &#125; final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: break; case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: return; // 回退消息直接返回 &#125; // indexFile索引文件构建的核心步骤 if (req.getUniqKey() != null) &#123; // 若存在唯一键 indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); if (indexFile == null) &#123; return; &#125; &#125; if (keys != null &amp;&amp; keys.length() &gt; 0) &#123; // 若存在过滤的keys String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i &lt; keyset.length; i++) &#123; String key = keyset[i]; if (key.length() &gt; 0) &#123; indexFile = putKey(indexFile, msg, buildKey(topic, key)); if (indexFile == null) &#123; return; &#125; &#125; &#125; &#125; &#125; &#125; public IndexFile retryGetAndCreateIndexFile() &#123; IndexFile indexFile = null; for (int times = 0; null == indexFile &amp;&amp; times &lt; MAX_TRY_IDX_CREATE; times++) &#123; indexFile = this.getAndCreateLastIndexFile(); if (null != indexFile) break; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; if (null == indexFile) &#123; this.defaultMessageStore.getAccessRights().makeIndexFileError(); &#125; return indexFile; &#125; public IndexFile getAndCreateLastIndexFile() &#123; IndexFile indexFile = null; IndexFile prevIndexFile = null; long lastUpdateEndPhyOffset = 0; long lastUpdateIndexTimestamp = 0; &#123; this.readWriteLock.readLock().lock(); if (!this.indexFileList.isEmpty()) &#123; IndexFile tmp = this.indexFileList.get(this.indexFileList.size() - 1); if (!tmp.isWriteFull()) &#123; indexFile = tmp; &#125; else &#123; lastUpdateEndPhyOffset = tmp.getEndPhyOffset(); lastUpdateIndexTimestamp = tmp.getEndTimestamp(); prevIndexFile = tmp; &#125; &#125; this.readWriteLock.readLock().unlock(); &#125; if (indexFile == null) &#123; try &#123; // 按照时间生成Index文件名称 String fileName = this.storePath + File.separator + UtilAll.timeMillisToHumanString(System.currentTimeMillis()); indexFile = new IndexFile(fileName, this.hashSlotNum, this.indexNum, lastUpdateEndPhyOffset, lastUpdateIndexTimestamp); this.readWriteLock.writeLock().lock(); this.indexFileList.add(indexFile); &#125; catch (Exception e) &#123; &#125; finally &#123; this.readWriteLock.writeLock().unlock(); &#125; if (indexFile != null) &#123; // 开启线程将之前的IndexFile缓存中的数据刷到磁盘中 final IndexFile flushThisFile = prevIndexFile; Thread flushThread = new Thread(new Runnable() &#123; @Override public void run() &#123; IndexService.this.flush(flushThisFile); &#125; &#125;, \"FlushIndexFileThread\"); flushThread.setDaemon(true); flushThread.start(); &#125; &#125; return indexFile; &#125; private IndexFile putKey(IndexFile indexFile, DispatchRequest msg, String idxKey) &#123; for (boolean ok = indexFile.putKey(idxKey, msg.getCommitLogOffset(), msg.getStoreTimestamp()); !ok; ) &#123; indexFile = retryGetAndCreateIndexFile(); if (null == indexFile) &#123; return null; &#125; ok = indexFile.putKey(idxKey, msg.getCommitLogOffset(), msg.getStoreTimestamp()); &#125; return indexFile; &#125;&#125;public class IndexFile &#123; public boolean putKey(final String key, final long phyOffset, final long storeTimestamp) &#123; if (this.indexHeader.getIndexCount() &lt; this.indexNum) &#123; int keyHash = indexKeyHashMethod(key); int slotPos = keyHash % this.hashSlotNum; int absSlotPos = IndexHeader.INDEX_HEADER_SIZE + slotPos * hashSlotSize; FileLock fileLock = null; try &#123;// fileLock = this.fileChannel.lock(absSlotPos, hashSlotSize, false); int slotValue = this.mappedByteBuffer.getInt(absSlotPos); if (slotValue &lt;= invalidIndex || slotValue &gt; this.indexHeader.getIndexCount()) &#123; slotValue = invalidIndex; &#125; long timeDiff = storeTimestamp - this.indexHeader.getBeginTimestamp(); timeDiff = timeDiff / 1000; if (this.indexHeader.getBeginTimestamp() &lt;= 0) &#123; timeDiff = 0; &#125; else if (timeDiff &gt; Integer.MAX_VALUE) &#123; timeDiff = Integer.MAX_VALUE; &#125; else if (timeDiff &lt; 0) &#123; timeDiff = 0; &#125; int absIndexPos = IndexHeader.INDEX_HEADER_SIZE + this.hashSlotNum * hashSlotSize + this.indexHeader.getIndexCount() * indexSize; this.mappedByteBuffer.putInt(absIndexPos, keyHash); this.mappedByteBuffer.putLong(absIndexPos + 4, phyOffset); this.mappedByteBuffer.putInt(absIndexPos + 4 + 8, (int) timeDiff); this.mappedByteBuffer.putInt(absIndexPos + 4 + 8 + 4, slotValue); this.mappedByteBuffer.putInt(absSlotPos, this.indexHeader.getIndexCount()); if (this.indexHeader.getIndexCount() &lt;= 1) &#123; this.indexHeader.setBeginPhyOffset(phyOffset); this.indexHeader.setBeginTimestamp(storeTimestamp); &#125; if (invalidIndex == slotValue) &#123; this.indexHeader.incHashSlotCount(); &#125; this.indexHeader.incIndexCount(); this.indexHeader.setEndPhyOffset(phyOffset); this.indexHeader.setEndTimestamp(storeTimestamp); return true; &#125; catch (Exception e) &#123; &#125; finally &#123; if (fileLock != null) &#123; try &#123; fileLock.release(); &#125; &#125; &#125; &#125; return false; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://yaoyinglong.github.io/tags/RocketMQ/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"RocketMQ生产者源码","date":"2021-12-01T16:00:00.000Z","path":"Blog/Cloud/MQ/RocketMQ生产者源码/","text":"普通消息不论同步请求还是异步请求最终都是调用DefaultMQProducerImpl的sendDefaultImpl方法，首先通过tryToFindTopicPublishInfo方法获取Topic信息，先从本地缓存找，若本地缓存没有则调用MQClientAPIImpl的getTopicRouteInfoFromNameServer方法通过RequestCode.GET_ROUTEINFO_BY_TOPIC关联调用NameServer的DefaultRequestProcessor的getRouteInfoByTopic方法获取Topic信息；Topic信息在Producter启动时就注册到NameServer了，且每30s发送心跳也会发送Topic相关的信息。 然后通过MQFaultStrategy的selectOneMessageQueue获取具体的具体要将消息发送到哪一个队列中，Producer选择MessageQueue方法是消息数自增对队列数取模，可通过sendLatencyFaultEnable参数开启Broker故障延迟机制，发送消息失败后一定时间内不在往同一个Queue重复发送的机制，在LatencyFaultToleranceImpl中维护了曾经发送失败的Broker列表到faultItemTable中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; Validators.checkMessage(msg, this); msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg); &#125; public void send(Message msg, SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); this.defaultMQProducerImpl.send(msg, sendCallback); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void send(final Message msg, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, InterruptedException &#123; final long beginStartTime = System.currentTimeMillis(); ExecutorService executor = this.getAsyncSenderExecutor(); try &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &gt; costTime) &#123; try &#123; sendDefaultImpl(msg, CommunicationMode.ASYNC, sendCallback, timeout - costTime); &#125; catch (Exception e) &#123; sendCallback.onException(e); // 调用回调方法 &#125; &#125; else &#123; // 调用回调方法 sendCallback.onException(new RemotingTooMuchRequestException(\"DEFAULT ASYNC send call timeout\")); &#125; &#125; &#125;); &#125; catch (RejectedExecutionException e) &#123; throw new MQClientException(\"executor rejected \", e); &#125; &#125; private SendResult sendDefaultImpl(Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); final long invokeID = random.nextLong(); long beginTimestampFirst = System.currentTimeMillis(); long beginTimestampPrev = beginTimestampFirst; long endTimestamp = beginTimestampFirst; // 生产者获取Topic的公开信息 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; boolean callTimeout = false; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; String[] brokersSent = new String[timesTotal]; for (; times &lt; timesTotal; times++) &#123; // 重试次数，异步默认重试2次共3次，同步不重试共1次 String lastBrokerName = null == mq ? null : mq.getBrokerName(); // Producer计算把消息发到哪个MessageQueue中，自增然后取模 MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) &#123; mq = mqSelected; brokersSent[times] = mq.getBrokerName(); // 根据MessageQueue去获取目标节点的信息。 try &#123; beginTimestampPrev = System.currentTimeMillis(); if (times &gt; 0) &#123; // 重新发送期间使用命名空间重置主题 msg.setTopic(this.defaultMQProducer.withNamespace(msg.getTopic())); &#125; long costTime = beginTimestampPrev - beginTimestampFirst; if (timeout &lt; costTime) &#123; // 判断是否超时，默认3s callTimeout = true; break; // 若超时 &#125; // 实际发送消息的方法 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime); endTimestamp = System.currentTimeMillis(); this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); switch (communicationMode) &#123; case ASYNC: return null; // 异步发送返回null case ONEWAY: return null; // 单向发送返回null case SYNC: if (sendResult.getSendStatus() != SendStatus.SEND_OK) &#123; if (this.defaultMQProducer.isRetryAnotherBrokerWhenNotStoreOK()) &#123; continue; // 若重试则继续，否则直接返回结果 &#125; &#125; return sendResult; default: break; &#125; &#125; &#125; else &#123; break; &#125; &#125; if (sendResult != null) &#123; return sendResult; &#125; info += FAQUrl.suggestTodo(FAQUrl.SEND_MSG_FAILED); MQClientException mqClientException = new MQClientException(info, exception); if (callTimeout) &#123; throw new RemotingTooMuchRequestException(\"sendDefaultImpl call timeout\"); &#125; throw mqClientException; &#125; validateNameServerSetting(); throw new MQClientException(\"No route info of this topic: \" + msg.getTopic() + FAQUrl.suggestTodo(FAQUrl.NO_TOPIC_ROUTE_INFO), null).setResponseCode(ClientErrorCode.NOT_FOUND_TOPIC_EXCEPTION); &#125; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; return this.mqFaultStrategy.selectOneMessageQueue(tpInfo, lastBrokerName); &#125; // 找路由表的过程都是先从本地缓存找，本地缓存没有，就去NameServer上申请。 private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123; TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123; this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); // Producer向NameServer获取更新Topic的路由信息。 this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); // 还是从本地缓存中寻找Topic路由信息。 topicPublishInfo = this.topicPublishInfoTable.get(topic); &#125; if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123; return topicPublishInfo; &#125; else &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer); topicPublishInfo = this.topicPublishInfoTable.get(topic); return topicPublishInfo; &#125; &#125;&#125;public class MQFaultStrategy &#123; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; // sendLatencyFaultEnable默认关闭，Broker故障延迟机制，表示一种发送消息失败后一定时间内不在往同一个Queue重复发送的机制 if (this.sendLatencyFaultEnable) &#123; try &#123; // Producer选择MessageQueue的方法是自增然后取模。 int index = tpInfo.getSendWhichQueue().getAndIncrement(); for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size(); if (pos &lt; 0) pos = 0; MessageQueue mq = tpInfo.getMessageQueueList().get(pos); // Broker轮询，尽量将请求平均分配给不同的Broker if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123; if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName)) return mq; &#125; &#125; final String notBestBroker = latencyFaultTolerance.pickOneAtLeast(); int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker); if (writeQueueNums &gt; 0) &#123; final MessageQueue mq = tpInfo.selectOneMessageQueue();// 自增取模计算 if (notBestBroker != null) &#123; mq.setBrokerName(notBestBroker); mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums); &#125; return mq; &#125; else &#123; latencyFaultTolerance.remove(notBestBroker); &#125; &#125; return tpInfo.selectOneMessageQueue(); // 自增取模计算 &#125; return tpInfo.selectOneMessageQueue(lastBrokerName); // 自增取模计算 &#125;&#125;public class TopicPublishInfo &#123; //选择MessageQueue的方式：递增取模 public MessageQueue selectOneMessageQueue() &#123; int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; return this.messageQueueList.get(pos); &#125; public MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123; if (lastBrokerName == null) &#123; return selectOneMessageQueue(); &#125; else &#123; int index = this.sendWhichQueue.getAndIncrement(); for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123; int pos = Math.abs(index++) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; MessageQueue mq = this.messageQueueList.get(pos); if (!mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; return selectOneMessageQueue(); &#125; &#125;&#125; 不论是同步还是异步或是单向消息最终都会调用MQClientAPIImpl的sendMessage方法，不同的是同步方法没有SendCallback回调。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152public class DefaultMQProducerImpl implements MQProducerInner &#123; private SendResult sendKernelImpl(final Message msg, final MessageQueue mq, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); // 找到Master节点地址 if (null == brokerAddr) &#123;// 通过Broker名称获取Broker地址，若获取不到则去NameServer上获取。 tryToFindTopicPublishInfo(mq.getTopic()); brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); &#125; SendMessageContext context = null; if (brokerAddr != null) &#123; brokerAddr = MixAll.brokerVIPChannel(this.defaultMQProducer.isSendMessageWithVIPChannel(), brokerAddr); byte[] prevBody = msg.getBody(); try &#123; if (!(msg instanceof MessageBatch)) &#123; //for MessageBatch,ID has been set in the generating process MessageClientIDSetter.setUniqID(msg); // 批量消息 &#125; boolean topicWithNamespace = false; if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123; msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace()); topicWithNamespace = true; &#125; int sysFlag = 0; boolean msgBodyCompressed = false; if (this.tryToCompressMessage(msg)) &#123; // 消息体大于4K将默认压缩 sysFlag |= MessageSysFlag.COMPRESSED_FLAG; msgBodyCompressed = true; &#125; final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123; sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE; &#125; SendMessageRequestHeader requestHeader = new SendMessageRequestHeader(); requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTopic(msg.getTopic()); requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey()); requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setSysFlag(sysFlag); requestHeader.setBornTimestamp(System.currentTimeMillis()); requestHeader.setFlag(msg.getFlag()); requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties())); requestHeader.setReconsumeTimes(0); requestHeader.setUnitMode(this.isUnitMode()); requestHeader.setBatch(msg instanceof MessageBatch); if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; // 重试消息 String reconsumeTimes = MessageAccessor.getReconsumeTime(msg); if (reconsumeTimes != null) &#123; requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME); &#125; String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg); if (maxReconsumeTimes != null) &#123; requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES); &#125; &#125; SendResult sendResult = null; switch (communicationMode) &#123; case ASYNC: Message tmpMessage = msg; boolean messageCloned = false; if (msgBodyCompressed) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; msg.setBody(prevBody); &#125; if (topicWithNamespace) &#123; if (!messageCloned) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; &#125; msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQProducer.getNamespace())); &#125; long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(\"sendKernelImpl call timeout\"); &#125; // 真正向Broker发送消息，异步要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), tmpMessage, requestHeader, timeout - costTimeAsync, communicationMode, sendCallback, topicPublishInfo, this.mQClientFactory, this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(), context, this); break; case ONEWAY: case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(\"sendKernelImpl call timeout\"); &#125; // 真正向Broker发送消息，同步不需要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), msg, requestHeader, timeout - costTimeSync, communicationMode, context, this); break; default: assert false; break; &#125; if (this.hasSendMessageHook()) &#123;//消息发送完成后执行钩子程序。 context.setSendResult(sendResult); this.executeSendMessageHookAfter(context); &#125; return sendResult; &#125; &#125; throw new MQClientException(\"The broker[\" + mq.getBrokerName() + \"] not exist\", null); &#125;&#125;public class MQClientAPIImpl &#123; // 不论同步还是异步最终都会调用该方法 public SendResult sendMessage(final String addr, final String brokerName, final Message msg, final SendMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final SendMessageContext context, final DefaultMQProducerImpl producer) throws RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); RemotingCommand request = null; String msgType = msg.getProperty(MessageConst.PROPERTY_MESSAGE_TYPE); boolean isReply = msgType != null &amp;&amp; msgType.equals(MixAll.REPLY_MESSAGE_FLAG); if (isReply) &#123; if (sendSmartMsg) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE, requestHeader); &#125; &#125; else &#123; if (sendSmartMsg || msg instanceof MessageBatch) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(msg instanceof MessageBatch ? RequestCode.SEND_BATCH_MESSAGE : RequestCode.SEND_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_MESSAGE, requestHeader); &#125; &#125; request.setBody(msg.getBody()); switch (communicationMode) &#123; case ONEWAY: this.remotingClient.invokeOneway(addr, request, timeoutMillis); return null; case ASYNC: final AtomicInteger times = new AtomicInteger(); long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(\"sendMessage call timeout\"); &#125; this.sendMessageAsync(addr, brokerName, msg, timeoutMillis - costTimeAsync, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, context, producer); return null; case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(\"sendMessage call timeout\"); &#125; return this.sendMessageSync(addr, brokerName, msg, timeoutMillis - costTimeSync, request); default: assert false; break; &#125; return null; &#125; &#125; 对于同步消息最终用通过RequestCode.SEND_MESSAGE编号最终在Broker中执行SendMessageProcessor的processRequest方法，异步消息最终调用的是SendMessageProcessor的asyncProcessRequest方法，最终都是调用的asyncProcessRequest方法，不同点在于同步消息的processRequest中获取到异步CompletableFuture直接调用get方法等待结果，不论是同步还是异步方法最终都是在handlePutMessageResultFuture方法中调用CompletableFuture的thenApply方法，在响应后最终在handlePutMessageResult中调用doResponse方法将结果写回给客户端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class MQClientAPIImpl &#123; private SendResult sendMessageSync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand response = this.remotingClient.invokeSync(addr, request, timeoutMillis); assert response != null; return this.processSendResponse(brokerName, msg, response); &#125;&#125;public class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient &#123; public RemotingCommand invokeSync(String addr, final RemotingCommand request, long timeoutMillis) throws InterruptedException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException &#123; long beginStartTime = System.currentTimeMillis(); // channel是和Nameserver之间建立的一个连接。 final Channel channel = this.getAndCreateChannel(addr); if (channel != null &amp;&amp; channel.isActive()) &#123; // 网络连接ok则发送请求 try &#123; doBeforeRpcHooks(addr, request); //计算时间 long costTime = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTime) &#123; throw new RemotingTimeoutException(\"invokeSync call timeout\"); &#125; RemotingCommand response = this.invokeSyncImpl(channel, request, timeoutMillis - costTime); // 真正发网络请求的地方 doAfterRpcHooks(RemotingHelper.parseChannelRemoteAddr(channel), request, response); return response; &#125; catch (RemotingSendRequestException e) &#123; this.closeChannel(addr, channel); throw e; &#125; catch (RemotingTimeoutException e) &#123; if (nettyClientConfig.isClientCloseSocketIfTimeout()) &#123; this.closeChannel(addr, channel); &#125; throw e; &#125; &#125; else &#123; this.closeChannel(addr, channel); throw new RemotingConnectException(addr); &#125; &#125;&#125;public class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; RemotingCommand response = null; try &#123; response = asyncProcessRequest(ctx, request).get(); &#125; return response; &#125; public CompletableFuture&lt;RemotingCommand&gt; asyncProcessRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final SendMessageContext mqtraceContext; switch (request.getCode()) &#123; case RequestCode.CONSUMER_SEND_MSG_BACK: return this.asyncConsumerSendMsgBack(ctx, request); default: SendMessageRequestHeader requestHeader = parseRequestHeader(request); if (requestHeader == null) &#123; return CompletableFuture.completedFuture(null); &#125; mqtraceContext = buildMsgContext(ctx, requestHeader); this.executeSendMessageHookBefore(ctx, request, mqtraceContext); if (requestHeader.isBatch()) &#123; return this.asyncSendBatchMessage(ctx, request, mqtraceContext, requestHeader); &#125; else &#123; return this.asyncSendMessage(ctx, request, mqtraceContext, requestHeader); &#125; &#125; &#125; private CompletableFuture&lt;RemotingCommand&gt; asyncSendMessage(ChannelHandlerContext ctx, RemotingCommand request, SendMessageContext mqtraceContext, SendMessageRequestHeader requestHeader) &#123; final RemotingCommand response = preSend(ctx, request, requestHeader); final SendMessageResponseHeader responseHeader = (SendMessageResponseHeader)response.readCustomHeader(); if (response.getCode() != -1) &#123; return CompletableFuture.completedFuture(response); &#125; final byte[] body = request.getBody(); int queueIdInt = requestHeader.getQueueId(); TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); if (queueIdInt &lt; 0) &#123; queueIdInt = randomQueueId(topicConfig.getWriteQueueNums()); &#125; MessageExtBrokerInner msgInner = new MessageExtBrokerInner(); msgInner.setTopic(requestHeader.getTopic()); msgInner.setQueueId(queueIdInt); if (!handleRetryAndDLQ(requestHeader, response, request, msgInner, topicConfig)) &#123; return CompletableFuture.completedFuture(response); &#125; msgInner.setBody(body); msgInner.setFlag(requestHeader.getFlag()); MessageAccessor.setProperties(msgInner, MessageDecoder.string2messageProperties(requestHeader.getProperties())); msgInner.setPropertiesString(requestHeader.getProperties()); msgInner.setBornTimestamp(requestHeader.getBornTimestamp()); msgInner.setBornHost(ctx.channel().remoteAddress()); msgInner.setStoreHost(this.getStoreHost()); msgInner.setReconsumeTimes(requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes()); String clusterName = this.brokerController.getBrokerConfig().getBrokerClusterName(); MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_CLUSTER, clusterName); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); CompletableFuture&lt;PutMessageResult&gt; putMessageResult = null; Map&lt;String, String&gt; origProps = MessageDecoder.string2messageProperties(requestHeader.getProperties()); String transFlag = origProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (transFlag != null &amp;&amp; Boolean.parseBoolean(transFlag)) &#123; if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) &#123; response.setCode(ResponseCode.NO_PERMISSION); response.setRemark(\"the broker[\" + this.brokerController.getBrokerConfig().getBrokerIP1() + \"] sending transaction message is forbidden\"); return CompletableFuture.completedFuture(response); &#125; putMessageResult = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner); // 事务消息持久化 &#125; else &#123; putMessageResult = this.brokerController.getMessageStore().asyncPutMessage(msgInner); // 普通消息持久化 &#125; return handlePutMessageResultFuture(putMessageResult, response, request, msgInner, responseHeader, mqtraceContext, ctx, queueIdInt); &#125;&#125; 对于异步方法当获取到响应后会回调InvokeCallback中的operationComplete方法，在该方法中若成功则回调用SendCallback的onSuccess方法。若失败则走重试逻辑若中还是失败则回调用SendCallback的onException方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MQClientAPIImpl &#123; private void sendMessageAsync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final AtomicInteger times, final SendMessageContext context, final DefaultMQProducerImpl producer) throws InterruptedException, RemotingException &#123; final long beginStartTime = System.currentTimeMillis(); this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; @Override public void operationComplete(ResponseFuture responseFuture) &#123; long cost = System.currentTimeMillis() - beginStartTime; RemotingCommand response = responseFuture.getResponseCommand(); if (null == sendCallback &amp;&amp; response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); if (context != null &amp;&amp; sendResult != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); return; &#125; if (response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); assert sendResult != null; if (context != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; try &#123; sendCallback.onSuccess(sendResult); // 回调用SendCallback的onSuccess方法 &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); &#125; catch (Exception e) &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, e, context, false, producer); &#125; &#125; else &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); if (!responseFuture.isSendRequestOK()) &#123; MQClientException ex = new MQClientException(\"send request failed\", responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else if (responseFuture.isTimeout()) &#123; MQClientException ex = new MQClientException(\"wait response timeout \" + responseFuture.getTimeoutMillis() + \"ms\", responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else &#123; MQClientException ex = new MQClientException(\"unknow reseaon\", responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; &#125; &#125; &#125;); &#125;&#125; 事务消息对于事务消息的发送是通过TransactionMQProducer类的sendMessageInTransaction方法来完成的，若事务消息设置了延迟参数则将会被清除，会设置TRAN_MSG属性为true，然后调用send方法发送消费到Broker，send方法中和普通的发送消息调用的一个方法，但普通消息是走的DefaultMessageStore的asyncPutMessage方法，事务消息是走的TransactionalMessageServiceImpl的asyncPrepareMessage方法。若发送成功则调用设置的TransactionListener的executeLocalTransaction方法，然后调用MQClientAPIImpl的endTransactionOneway方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class TransactionMQProducer extends DefaultMQProducer &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final Object arg) throws MQClientException &#123; if (null == this.transactionListener) &#123; throw new MQClientException(\"TransactionListener is null\", null); &#125; msg.setTopic(NamespaceUtil.wrapNamespace(this.getNamespace(), msg.getTopic())); return this.defaultMQProducerImpl.sendMessageInTransaction(msg, null, arg); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final LocalTransactionExecuter localTransactionExecuter, final Object arg) throws MQClientException &#123; TransactionListener transactionListener = getCheckListener(); if (null == localTransactionExecuter &amp;&amp; null == transactionListener) &#123; throw new MQClientException(\"tranExecutor is null\", null); &#125; if (msg.getDelayTimeLevel() != 0) &#123; // 不支持延迟消息 MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_DELAY_TIME_LEVEL); &#125; Validators.checkMessage(msg, this.defaultMQProducer); SendResult sendResult = null; MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, \"true\"); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup()); try &#123; sendResult = this.send(msg); &#125; catch (Exception e) &#123; throw new MQClientException(\"send message Exception\", e); &#125; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; // 默认本地事务状态为UNKNOW Throwable localException = null; switch (sendResult.getSendStatus()) &#123; case SEND_OK: &#123; try &#123; if (sendResult.getTransactionId() != null) &#123; msg.putUserProperty(\"__transactionId__\", sendResult.getTransactionId()); &#125; String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !\"\".equals(transactionId)) &#123; msg.setTransactionId(transactionId); &#125; if (null != localTransactionExecuter) &#123; // 默认localTransactionExecuter为null localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg); &#125; else if (transactionListener != null) &#123; // transactionListener是调用时设置的 localTransactionState = transactionListener.executeLocalTransaction(msg, arg); &#125; if (null == localTransactionState) &#123; localTransactionState = LocalTransactionState.UNKNOW; &#125; &#125; catch (Throwable e) &#123; localException = e; &#125; &#125; break; case FLUSH_DISK_TIMEOUT: case FLUSH_SLAVE_TIMEOUT: case SLAVE_NOT_AVAILABLE: localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE; break; default: break; &#125; try &#123; this.endTransaction(sendResult, localTransactionState, localException); &#125; TransactionSendResult transactionSendResult = new TransactionSendResult(); transactionSendResult.setSendStatus(sendResult.getSendStatus()); transactionSendResult.setMessageQueue(sendResult.getMessageQueue()); transactionSendResult.setMsgId(sendResult.getMsgId()); transactionSendResult.setQueueOffset(sendResult.getQueueOffset()); transactionSendResult.setTransactionId(sendResult.getTransactionId()); transactionSendResult.setLocalTransactionState(localTransactionState); return transactionSendResult; &#125; public void endTransaction(final SendResult sendResult, final LocalTransactionState localTransactionState, final Throwable localException) throws RemotingException, MQBrokerException, InterruptedException, UnknownHostException &#123; final MessageId id; if (sendResult.getOffsetMsgId() != null) &#123; id = MessageDecoder.decodeMessageId(sendResult.getOffsetMsgId()); &#125; else &#123; id = MessageDecoder.decodeMessageId(sendResult.getMsgId()); &#125; String transactionId = sendResult.getTransactionId(); final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(sendResult.getMessageQueue().getBrokerName()); EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader(); requestHeader.setTransactionId(transactionId); requestHeader.setCommitLogOffset(id.getOffset()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTranStateTableOffset(sendResult.getQueueOffset()); requestHeader.setMsgId(sendResult.getMsgId()); String remark = localException != null ? (\"executeLocalTransactionBranch exception: \" + localException.toString()) : null; this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, requestHeader, remark, this.defaultMQProducer.getSendMsgTimeout()); &#125;&#125;public class MQClientAPIImpl &#123; public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis); &#125;&#125; 首先会将将真正的事务Topic存储到REAL_TOPIC属性中，然后将Topic换成RMQ_SYS_TRANS_HALF_TOPIC，然后将替换了Topic的事务消息通过DefaultMessageStore的asyncPutMessage方法最终存储到CommitLog中。 1234567891011121314151617public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public CompletableFuture&lt;PutMessageResult&gt; asyncPrepareMessage(MessageExtBrokerInner messageInner) &#123; return transactionalMessageBridge.asyncPutHalfMessage(messageInner); &#125; public CompletableFuture&lt;PutMessageResult&gt; asyncPutHalfMessage(MessageExtBrokerInner messageInner) &#123; return store.asyncPutMessage(parseHalfMessageInner(messageInner)); &#125; private MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) &#123; MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic()); // 将真正的事务Topic存储到REAL_TOPIC属性中 MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msgInner.getQueueId())); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE)); msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic()); // Topic换成RMQ_SYS_TRANS_HALF_TOPIC msgInner.setQueueId(0); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); return msgInner; &#125;&#125; 最终通过RequestCode.END_TRANSACTION编码关联调用EndTransactionProcessor的processRequest方法，不论是是COMMIT还是ROLLBACK都将消息从RMQ_SYS_TRANS_HALF_TOPIC队列中查询出，若是COMMIT则将从RMQ_SYS_TRANS_HALF_TOPIC队列中查询的消息真正存储到其真实的Topic队列中，然后成功则再在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加一条对应的消息标识该Half消息被删除。若为ROLLBACK则直接在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加一条对应的消标识事务结束。开源版本进行了阉割，不会走回查逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class EndTransactionProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final RemotingCommand response = RemotingCommand.createResponseCommand(null); final EndTransactionRequestHeader requestHeader = (EndTransactionRequestHeader)request.decodeCommandCustomHeader(EndTransactionRequestHeader.class); if (BrokerRole.SLAVE == brokerController.getMessageStoreConfig().getBrokerRole()) &#123; response.setCode(ResponseCode.SLAVE_NOT_AVAILABLE); return response; // 若当前节点是从节点 &#125; OperationResult result = new OperationResult(); if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123; MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage()); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback())); msgInner.setQueueOffset(requestHeader.getTranStateTableOffset()); msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset()); msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp()); MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_TRANSACTION_PREPARED); // 将事务消息TRAN_MSG标记移除 RemotingCommand sendResult = sendFinalMessage(msgInner);// 将从RMQ_SYS_TRANS_HALF_TOPIC队列中查询的消息真正存储到其真实的Topic队列中 if (sendResult.getCode() == ResponseCode.SUCCESS) &#123;// 存储成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return sendResult; &#125; return res; &#125; &#125; else if (MessageSysFlag.TRANSACTION_ROLLBACK_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().rollbackMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123;// 成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return res; &#125; &#125; response.setCode(result.getResponseCode()); response.setRemark(result.getResponseRemark()); return response; &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public OperationResult commitMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; public OperationResult rollbackMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; private OperationResult getHalfMessageByOffset(long commitLogOffset) &#123; OperationResult response = new OperationResult(); MessageExt messageExt = this.transactionalMessageBridge.lookMessageByOffset(commitLogOffset); if (messageExt != null) &#123; response.setPrepareMessage(messageExt); response.setResponseCode(ResponseCode.SUCCESS); &#125; else &#123; response.setResponseCode(ResponseCode.SYSTEM_ERROR); response.setResponseRemark(\"Find prepared transaction message failed\"); &#125; return response; &#125;&#125; 在BrokerController的initialTransaction()方法中会初始化事务消息检查类TransactionalMessageCheckService，该类是一个线程类，在BrokerController的start方法中通过startProcessorByHa方法开启事务消息检查线程。若已经超过最大回查次数，则将消息添加到TRANS_CHECK_MAXTIME_TOPIC队列中，若需要检查则将消息写回RMQ_SYS_TRANS_HALF_TOPIC队列中防止再次失败，然后调用AbstractTransactionalMessageCheckListener的resolveHalfMsg方法检查消息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public class TransactionalMessageCheckService extends ServiceThread &#123; public void run() &#123; // 默认60s long checkInterval = brokerController.getBrokerConfig().getTransactionCheckInterval(); while (!this.isStopped()) &#123; this.waitForRunning(checkInterval); &#125; &#125; protected void waitForRunning(long interval) &#123; if (hasNotified.compareAndSet(true, false)) &#123; this.onWaitEnd(); return; &#125; waitPoint.reset(); try &#123; waitPoint.await(interval, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; hasNotified.set(false); this.onWaitEnd(); &#125; &#125; protected void onWaitEnd() &#123; long timeout = brokerController.getBrokerConfig().getTransactionTimeOut(); // 获取超时时间6s int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax(); // 获取最大回查次数15 long begin = System.currentTimeMillis(); this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener()); &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public void check(long transactionTimeout, int transactionCheckMax, AbstractTransactionalMessageCheckListener listener) &#123; try &#123; String topic = TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC; // RMQ_SYS_TRANS_HALF_TOPIC Set&lt;MessageQueue&gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(topic); if (msgQueues == null || msgQueues.size() == 0) &#123; return; &#125; for (MessageQueue messageQueue : msgQueues) &#123; long startTime = System.currentTimeMillis(); MessageQueue opQueue = getOpQueue(messageQueue); long halfOffset = transactionalMessageBridge.fetchConsumeOffset(messageQueue); long opOffset = transactionalMessageBridge.fetchConsumeOffset(opQueue); if (halfOffset &lt; 0 || opOffset &lt; 0) &#123; continue; &#125; List&lt;Long&gt; doneOpOffset = new ArrayList&lt;&gt;(); HashMap&lt;Long, Long&gt; removeMap = new HashMap&lt;&gt;(); PullResult pullResult = fillOpRemoveMap(removeMap, opQueue, opOffset, halfOffset, doneOpOffset); if (null == pullResult) &#123; continue; &#125; int getMessageNullCount = 1; long newOffset = halfOffset; long i = halfOffset; while (true) &#123; if (System.currentTimeMillis() - startTime &gt; MAX_PROCESS_TIME_LIMIT) &#123; break; &#125; if (removeMap.containsKey(i)) &#123; Long removedOpOffset = removeMap.remove(i); doneOpOffset.add(removedOpOffset); &#125; else &#123; GetResult getResult = getHalfMsg(messageQueue, i); // 消费RMQ_SYS_TRANS_HALF_TOPIC队列中的事务消息 MessageExt msgExt = getResult.getMsg(); if (msgExt == null) &#123; if (getMessageNullCount++ &gt; MAX_RETRY_COUNT_WHEN_HALF_NULL) &#123; break; &#125; if (getResult.getPullResult().getPullStatus() == PullStatus.NO_NEW_MSG) &#123; break; &#125; else &#123; i = getResult.getPullResult().getNextBeginOffset(); newOffset = i; continue; &#125; &#125; if (needDiscard(msgExt, transactionCheckMax) || needSkip(msgExt)) &#123;// 若已经超过最大回查次数了 listener.resolveDiscardMsg(msgExt); // 将消息添加到TRANS_CHECK_MAXTIME_TOPIC队列中 newOffset = i + 1; i++; continue; &#125; if (msgExt.getStoreTimestamp() &gt;= startTime) &#123; break; &#125; long valueOfCurrentMinusBorn = System.currentTimeMillis() - msgExt.getBornTimestamp(); long checkImmunityTime = transactionTimeout; String checkImmunityTimeStr = msgExt.getUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS); if (null != checkImmunityTimeStr) &#123; checkImmunityTime = getImmunityTime(checkImmunityTimeStr, transactionTimeout); if (valueOfCurrentMinusBorn &lt; checkImmunityTime) &#123; if (checkPrepareQueueOffset(removeMap, doneOpOffset, msgExt)) &#123; newOffset = i + 1; i++; continue; &#125; &#125; &#125; else &#123; if ((0 &lt;= valueOfCurrentMinusBorn) &amp;&amp; (valueOfCurrentMinusBorn &lt; checkImmunityTime)) &#123; break; &#125; &#125; List&lt;MessageExt&gt; opMsg = pullResult.getMsgFoundList(); boolean isNeedCheck = (opMsg == null &amp;&amp; valueOfCurrentMinusBorn &gt; checkImmunityTime) || (opMsg != null &amp;&amp; (opMsg.get(opMsg.size() - 1).getBornTimestamp() - startTime &gt; transactionTimeout)) || (valueOfCurrentMinusBorn &lt;= -1); if (isNeedCheck) &#123; if (!putBackHalfMsgQueue(msgExt, i)) &#123; // 写回RMQ_SYS_TRANS_HALF_TOPIC队列中 continue; &#125; listener.resolveHalfMsg(msgExt); // 真正检查消息的地方，回调客户端checkLocalTransaction方法 &#125; else &#123; pullResult = fillOpRemoveMap(removeMap, opQueue, pullResult.getNextBeginOffset(), halfOffset, doneOpOffset); continue; &#125; &#125; newOffset = i + 1; i++; &#125; if (newOffset != halfOffset) &#123; transactionalMessageBridge.updateConsumeOffset(messageQueue, newOffset); &#125; long newOpOffset = calculateOpOffset(doneOpOffset, opOffset); if (newOpOffset != opOffset) &#123; transactionalMessageBridge.updateConsumeOffset(opQueue, newOpOffset); &#125; &#125; &#125; &#125;&#125; 检查消息是异步执行的，首先还原当前消息真正的Topic，然后通过Broker2Client的checkProducerTransactionState方法中通过RequestCode.CHECK_TRANSACTION_STATE关联调用ClientRemotingProcessor的ClientRemotingProcessor方法。 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractTransactionalMessageCheckListener &#123; public void resolveHalfMsg(final MessageExt msgExt) &#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; sendCheckMessage(msgExt); &#125; catch (Exception e) &#123; &#125; &#125; &#125;); &#125; public void sendCheckMessage(MessageExt msgExt) throws Exception &#123; CheckTransactionStateRequestHeader checkTransactionStateRequestHeader = new CheckTransactionStateRequestHeader(); checkTransactionStateRequestHeader.setCommitLogOffset(msgExt.getCommitLogOffset()); checkTransactionStateRequestHeader.setOffsetMsgId(msgExt.getMsgId()); checkTransactionStateRequestHeader.setMsgId(msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX)); checkTransactionStateRequestHeader.setTransactionId(checkTransactionStateRequestHeader.getMsgId()); checkTransactionStateRequestHeader.setTranStateTableOffset(msgExt.getQueueOffset()); msgExt.setTopic(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC)); // 真正的Topic msgExt.setQueueId(Integer.parseInt(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_QUEUE_ID))); msgExt.setStoreSize(0); String groupId = msgExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); Channel channel = brokerController.getProducerManager().getAvaliableChannel(groupId); if (channel != null) &#123; brokerController.getBroker2Client().checkProducerTransactionState(groupId, channel, checkTransactionStateRequestHeader, msgExt); &#125; &#125;&#125;public class Broker2Client &#123; public void checkProducerTransactionState(final String group, final Channel channel, final CheckTransactionStateRequestHeader requestHeader, final MessageExt messageExt) throws Exception &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.CHECK_TRANSACTION_STATE, requestHeader); request.setBody(MessageDecoder.encode(messageExt, false)); try &#123; this.brokerController.getRemotingServer().invokeOneway(channel, request, 10); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 首先调用自定义TransactionListener的checkLocalTransaction方法，然后调用MQClientAPIImpl的endTransactionOneway方法。最终又调用EndTransactionProcessor的processRequest方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand checkTransactionState(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final CheckTransactionStateRequestHeader requestHeader = (CheckTransactionStateRequestHeader) request.decodeCommandCustomHeader(CheckTransactionStateRequestHeader.class); final ByteBuffer byteBuffer = ByteBuffer.wrap(request.getBody()); final MessageExt messageExt = MessageDecoder.decode(byteBuffer); if (messageExt != null) &#123; if (StringUtils.isNotEmpty(this.mqClientFactory.getClientConfig().getNamespace())) &#123; messageExt.setTopic(NamespaceUtil.withoutNamespace(messageExt.getTopic(), this.mqClientFactory.getClientConfig().getNamespace())); &#125; String transactionId = messageExt.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !\"\".equals(transactionId)) &#123; messageExt.setTransactionId(transactionId); &#125; final String group = messageExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); if (group != null) &#123; MQProducerInner producer = this.mqClientFactory.selectProducer(group); if (producer != null) &#123; final String addr = RemotingHelper.parseChannelRemoteAddr(ctx.channel()); producer.checkTransactionState(addr, messageExt, requestHeader); &#125; &#125; &#125; return null; &#125; &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void checkTransactionState(final String addr, final MessageExt msg, final CheckTransactionStateRequestHeader header) &#123; Runnable request = new Runnable() &#123; private final String brokerAddr = addr; private final MessageExt message = msg; private final CheckTransactionStateRequestHeader checkRequestHeader = header; private final String group = DefaultMQProducerImpl.this.defaultMQProducer.getProducerGroup(); @Override public void run() &#123; TransactionCheckListener transactionCheckListener = DefaultMQProducerImpl.this.checkListener(); TransactionListener transactionListener = getCheckListener(); if (transactionCheckListener != null || transactionListener != null) &#123; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; Throwable exception = null; try &#123; if (transactionCheckListener != null) &#123; localTransactionState = transactionCheckListener.checkLocalTransactionState(message); &#125; else if (transactionListener != null) &#123; localTransactionState = transactionListener.checkLocalTransaction(message); &#125; &#125; catch (Throwable e) &#123; exception = e; &#125; this.processTransactionState(localTransactionState, group, exception); &#125; &#125; private void processTransactionState(final LocalTransactionState localTransactionState, final String producerGroup, final Throwable exception) &#123; final EndTransactionRequestHeader thisHeader = new EndTransactionRequestHeader(); thisHeader.setCommitLogOffset(checkRequestHeader.getCommitLogOffset()); thisHeader.setProducerGroup(producerGroup); thisHeader.setTranStateTableOffset(checkRequestHeader.getTranStateTableOffset()); thisHeader.setFromTransactionCheck(true); String uniqueKey = message.getProperties().get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (uniqueKey == null) &#123; uniqueKey = message.getMsgId(); &#125; thisHeader.setMsgId(uniqueKey); thisHeader.setTransactionId(checkRequestHeader.getTransactionId()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; String remark = null; if (exception != null) &#123; remark = \"checkLocalTransactionState Exception: \" + RemotingHelper.exceptionSimpleDesc(exception); &#125; try &#123; DefaultMQProducerImpl.this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, thisHeader, remark, 3000); &#125; catch (Exception e) &#123; &#125; &#125; &#125;; this.checkExecutor.submit(request); &#125;&#125;public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis);&#125; 延迟消息 延迟消息写入时会将延迟消息转为写入到SCHEDULE_TOPIC_XXXX的Topic中，系统内置的该Topic有18个队列，对应18个延迟级别。ScheduleMessageService会每隔1s执行一次DeliverDelayedMessageTimerTask.executeOnTimeup任务，将消息从延迟队列中写入正常Topic中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class ScheduleMessageService extends ConfigManager &#123; private static final long FIRST_DELAY_TIME = 1000L; private static final long DELAY_FOR_A_WHILE = 100L; private static final long DELAY_FOR_A_PERIOD = 10000L; public void start() &#123; // 延迟消息服务的启动方法 if (started.compareAndSet(false, true)) &#123; this.timer = new Timer(\"ScheduleMessageTimerThread\", true); for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123; Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (null == offset) &#123; offset = 0L; &#125; if (timeDelay != null) &#123;//定时执行延迟消息处理任务 this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); &#125; &#125; this.timer.scheduleAtFixedRate(new TimerTask() &#123; //每隔10秒，将延迟消息持久化到硬盘中。 @Override public void run() &#123; try &#123; if (started.get()) ScheduleMessageService.this.persist(); &#125; catch (Throwable e) &#123; &#125; &#125; &#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); &#125; &#125;&#125;class DeliverDelayedMessageTimerTask extends TimerTask &#123; public void run() &#123; try &#123; if (isStarted()) &#123; this.executeOnTimeup(); &#125; &#125; catch (Exception e) &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, this.offset), DELAY_FOR_A_PERIOD); &#125; &#125; public void executeOnTimeup() &#123; // 拿到延迟级别对应的队列 ConsumeQueue cq = ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC, delayLevel2QueueId(delayLevel)); long failScheduleOffset = offset; if (cq != null) &#123; SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset); if (bufferCQ != null) &#123; try &#123; long nextOffset = offset; int i = 0; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); // 遍历每个延迟队列的消息 for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123; long offsetPy = bufferCQ.getByteBuffer().getLong(); int sizePy = bufferCQ.getByteBuffer().getInt(); long tagsCode = bufferCQ.getByteBuffer().getLong(); if (cq.isExtAddr(tagsCode)) &#123; if (cq.getExt(tagsCode, cqExtUnit)) &#123; tagsCode = cqExtUnit.getTagsCode(); &#125; &#125; long now = System.currentTimeMillis(); long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode); nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); long countdown = deliverTimestamp - now; if (countdown &lt;= 0) &#123; //把每个延迟消息封装成一个MessageExt MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); if (msgExt != null) &#123; try &#123; MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); if (TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC.equals(msgInner.getTopic())) &#123; continue; &#125; //将延迟消息写入正常消息队列，这样就能被消费者正常消费了。 PutMessageResult putMessageResult = ScheduleMessageService.this.writeMessageStore.putMessage(msgInner); if (putMessageResult != null &amp;&amp; putMessageResult.getPutMessageStatus() == PutMessageStatus.PUT_OK) &#123; continue; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_PERIOD); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; // end of for nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_WHILE); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; finally &#123; bufferCQ.release(); &#125; &#125; else &#123; // end of if (bufferCQ != null) long cqMinOffset = cq.getMinOffsetInQueue(); if (offset &lt; cqMinOffset) &#123; failScheduleOffset = cqMinOffset; &#125; &#125; &#125; // end of if (cq != null) ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, failScheduleOffset), DELAY_FOR_A_WHILE); &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://yaoyinglong.github.io/tags/RocketMQ/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"RocketMQ高级特性","date":"2021-11-29T16:00:00.000Z","path":"Blog/Cloud/MQ/RocketMQ高级特性/","text":"消息模型RocketMQ主要由Producer、Broker、Consumer三部分组成，Producer负责生产消息，Consumer负责消费消息，Broker负责存储消息。 Broker在实际部署过程中对应一台服务器，每个Broker可存储多个Topic消息，每个Topic消息也可分片存储于不同的Broker。MessageQueue用于存储消息的物理地址，每个Topic中的消息地址存储于多个MessageQueue中。ConsumerGroup由多个Consumer 实例构成。 每个Broker下都会生成对应的Topic的文件夹，每个Topic文件夹下会为每个队列生成一个以队列id作为文件名的文件夹，在文件夹内才是对应的MessageQueue文件。 消息生产者RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要； 生产者中会把同一类Producer组成一个集合，叫做生产者组，这类Producer发送同一类消息且发送逻辑一致。若发送的是事务消息且原始生产者在发送之后崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费。 消息消费者一个消息消费者会从Broker服务器拉取消息，从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费。 拉取式消费的应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程。 推动式消费模式下Broker收到数据后会主动推送给消费端，该消费模式一般实时性较高，底层也是通过拉取模式来实现的，与Broker建立长连接达到消息实时接收的效果。 消费者同样会把同一类Consumer组成一个集合，叫做消费者组，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易。消费者组的消费者实例必须订阅完全相同的Topic。RocketMQ支持两种消息模式：集群消费Clustering和广播消费Broadcasting。 集群消费模式：相同Consumer Group的每个Consumer实例平均分摊消息。不同的Consumer Group全量接收消息。 广播消费模式：相同Consumer Group的每个Consumer实例都接收全量的消息。 TopicTopic表示一类消息的集合，每个Topic包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。 同一个Topic下的数据，会分片保存到不同的Broker上，而每一个分片单位为MessageQueue。MessageQueue是生产者发送消息与消费者消费消息的最小单位。 Broker Server消息中转角色，负责存储消息、转发消息。代理服务器在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备。代理服务器也存储消息相关元数据，包括消费者组、消费进度偏移和主题和队列消息等。Broker Server要保证高可用需要搭建主从集群架构。RocketMQ中有普通集群和Dledger高可用集群两种Broker架构模式。 普通集群该集群模式下会给每个节点分配一个固定角色，Master负责响应客户端的请求并存储消息。Slave则只负责对Master的消息进行同步保存，并响应部分客户端的读请求，消息同步方式分为同步同步和异步同步。该集群模式下各节点角色无法进行切换，即Master节点挂了，则这一组Broker就不可用了，Slave不会顶上去成为Master。 Dledger高可用集群Dledger是RocketMQ 4.5引入的实现高可用集群的一项技术。该模式下集群会随机选出一个节点作为Master，当Master节点挂了后，会从Slave中自动选出一个节点升级成为Master。 Dledger会从集群中选举出Master节点，完成Master节点往Slave节点的消息同步，且接管Broker的CommitLog消息存储。Dledger是使用Raft算法来进行节点选举的。 每个节点有Leader、Follower、Candidate三个状态，正常运行情况下，集群中会有一个leader，其他都是Follower且只响应Leader和Candidate的请求，而客户端的请求全部由Leader处理，即使有客户端请求到了一个Follower也会将请求转发到Leader。 集群刚启动时每个节点都是Follower状态，之后集群内部会发送一个timeout信号，所有Follower转成Candidate去拉取选票，获得大多数选票的节点选为Leader，其他候选人转为Follower。若一个timeout信号发出时，没有选出Leader，将会重新开始一次新的选举。Leader节点会往其他节点发送心跳信号，确认其Leader状态。 然后启动定时器，若指定时间内未收到Leader心跳，则转为Candidate状态，然后向其他成员发起投票请求，若收到半数以上成员的投票，则Candidate会晋升为Leader，然后Leader也有可能会退化成Follower。 在Raft协议中会将时间分为一些任意时间长度的时间片段叫做term。term会使用一个全局唯一，连续递增的编号作为标识，起到一个逻辑时钟的作用。 在每个term时间片里都会进行新的选举，每个Candidate都会努力争取成为Leader。Leader节点在一个term时间片里会保持Leader状态，同一时间段内，集群中只会有一个Leader。某些情况下形成不了多数派，那该term可能直到结束都没有leader，直到下一个term再重新发起选举，也就没有了Zookeeper中的脑裂问题。而在每次重新选举的过程中， Leader也有可能会退化成为Follower。在该集群中Leader节点会不断变化。 每次选举的过程中，每个节点都会存储当前term编号，并在节点之间进行交流时带上自己的term编号。若一个节点发现他的编号比另外一个小，则会将自己的编号更新为较大的那一个。若Leader或Candidate发现自己的编号不是最新的，则会自动转成Follower。若接收到的请求term编号小于自己的编号term将会拒绝执行。 在选举过程中，Raft协议会通过心跳机制发起Leader选举。节点都是从Follower状态开始，若收到了来自Leader或Candidate的心跳RPC请求，则会保持Follower状态，避免争抢成为Candidate。而Leader会往其他节点发送心跳信号，来确认自己的地位。若Follower两个timeout信号内没有收到Leader的心跳信号，则会认为Leader挂了，发起新一轮选举。 选举开始后，每个Follower会增加自己当前的term，并将自己转为Candidate。然后向其他节点发起投票请求，请求时默认投自己一票。之后Candidate状态可能会发生以下三种变化： 赢得选举成为Leader：若在一个term内收到了大多数的选票，将会在接下的剩余term时间内称为Leader，然后就可通过发送心跳确立自己的地位。每一个Server在一个term内只能投一张选票，并且按先到先得的原则投出 其他节点成为Leader：在等待投票时，可能会收到其他Server发出心跳信号，说明Leader已产生。这时通过比较自己的term编号和RPC过来的term编号，若比对方大说明Leader的term过期，则拒绝该RPC并继续保持候选人身份，若对方编号不比自己小则承认对方的地位,转为follower。 选票被瓜分选举失败：若无Candidate获取大多数选票，则无Leader产生，Candidate们等待超时后发起另一轮选举，为防止下一次选票还被瓜分，Raft采用随机Election Timeout即随机休眠时间机制防止选票被持续瓜分。通过将timeout随机设为一段区间上的某个值，因此很大概率会有某个Candidate率先超时然后赢得大部分选票。 以三个节点的集群为例，集群启动时三个节点都是Follower，发起投票后三个节点都会给自己投票，一轮投票下来三个节点的term都是1，选举不出Leader；三个节点会进入随机休眠，然后开始新一轮投票； Dledger还会采用Raft协议进行多副本消息同步，数据同步会通过uncommitted阶段和commited阶段两个阶段来完成。 Leader Broker上的Dledger收到一条数据后，会标记为uncommitted状态，然后他通过自己的DledgerServer组件把该uncommitted数据发给Follower Broker的DledgerServer组件。 Follower Broker的DledgerServer收到uncommitted消息后，必须返回一个Ack给Leader Broker的Dledger。若Leader Broker收到超过半数的Follower Broker返回的Ack之后，就会把消息标记为committed状态。 Leader Broker上的DledgerServer就会发送committed消息给Follower Broker上的DledgerServer，让他们把消息也标记为committed状态。 消息存储分布式队列因为有高可靠性的要求，所以数据要进行持久化存储。RocketMQ采用的是类似于Kafka的文件存储机制，即直接用磁盘文件来保存消息，而不需要借助MySQL这一类索引工具。 MQ收到一条消息后，需要向生产者返回一个ACK响应，并将消息存储起来。 MQ Push一条消息给消费者后，等待消费者的ACK响应，需要将消息标记为已消费。若没有标记为消费，MQ会不断尝试往消费者推送这条消息。 MQ需要定期删除一些过期的消息，这样才能保证服务一直可用。 目前的高性能磁盘，顺序写速度可以达到600MB/s， 超过一般网卡传输速度。但是磁盘随机写速度只有大概100KB/s，RocketMQ的消息用顺序写保证了消息存储的速度。 Linux操作系统分为用户态和内核态，文件操作、网络操作需要涉及这两种形态的切换，免不了进行数据复制。一台服务器把本机磁盘文件的内容发送到客户端，一般分为读取本地文件内容、将读取的内容通过网络发送出去两个步骤。看似简单的操作，实际进行了4 次数据复制： 从磁盘复制数据到内核态内存 从内核态内存复制到用户态内存 然后从用户态内存复制到网络驱动的内核态内存 最后从网络驱动的内核态内存复制到网卡中进行传输 通过使用mmap方式，可省去向用户态内存复制，提高速度。这种机制在Java中是通过NIO包中的MappedByteBuffer实现的。RocketMQ充分利用该特性，也就是所谓的零拷贝技术，提高消息存盘和网络发送速度。 采用MappedByteBuffer这种内存映射的方式有几个限制：一次只能映射1.5~2G的文件至用户态的虚拟内存，这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因。 零拷贝在Java NIO中提供了mmap和sendfile两种实现方式，mmap适合比较小的文件，sendfile适合传递比较大的文件。 消息存储结构RocketMQ消息的存储分为三个部分： CommitLog：存储消息的元数据，所有消息都会顺序存入到CommitLog文件当中。CommitLog由多个文件组成，每个文件固定大小1G，以第一条消息的偏移量为文件名。 ConsumerQueue：存储消息在CommitLog的索引，一个MessageQueue一个文件，记录当前MessageQueue被哪些消费者组消费到了哪一条CommitLog。每个Broker下都会生成对应的Topic的文件夹，每个Topic文件夹下会为每个队列生成一个以队列id作为文件名的文件夹，在文件夹内才是对应的MessageQueue文件。 IndexFile：为了消息查询提供了一种通过key或时间区间来查询消息的方法，这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程 abort：该文件是RocketMQ用来判断程序是否正常关闭的一个标识文件。正常情况下在启动时创建关闭服务时删除。若遇到服务器宕机或kill -9等一些非正常关闭服务的情况，该abort文件不会删除，RocketMQ就可判断上一次服务是非正常关闭，做一些数据恢复的操作。 checkpoint：数据存盘检查点。 config/*.json：将Topic配置、消费者组配置、消费者组消息偏移量Offset等关键配置信息进行存盘保存。 刷盘机制RocketMQ需要将消息存储到磁盘上才能保证断电后消息不丢失，才可以让存储的消息量超出内存的限制。为了提高性能，会尽量保证磁盘的顺序写。消息在写入磁盘时有SYNC_FLUSH同步刷盘和ASYNC_FLUSH异步刷盘两种写磁盘的方式。通过Broker配置文件中flushDiskType参数设置。 同步刷盘：返回写成功状态时，消息已经被写入磁盘。消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。 异步刷盘：返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作快速写入。 主从复制若Broker以集群方式部署，会有一个Master节点和多个Slave节点，消息需要从Master复制到Slave上。而消息复制的方式分为同步复制和异步复制。通过Broker配置文件里的brokerRole参数进行设置，该参数可以被设置成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。 同步复制：等Master和Slave都写入消息成功后才反馈给客户端写入成功的状态。若Master故障Slave上有全部数据备份，很容易恢复数据。同步复制会增大数据写入延迟降低系统的吞吐量。 异步复制：Master写入消息成功就反馈给客户端写入成功的状态，再异步将消息复制给Slave节点。系统拥有较低延迟和较高吞吐量。但若Master故障而有些数据没有完成复制就会造成数据丢失。 负载均衡Producer负载均衡Producer发送消息时，默认会轮询目标Topic下的所有MessageQueue，并采用递增取模方式往不同的MessageQueue上发送消息，让消息平均落在不同的Queue上。由于MessageQueue是分布在不同的Broker上，故消息也会发送到不同的Broker上。生产者在发送消息时，可指定一个MessageQueueSelector，通过该对象来将消息发送到指定的MessageQueue上，可通过该方式保证消息局部有序。 Consumer负载均衡Consumer也是以MessageQueue为单位来进行负载均衡，分为集群模式和广播模式。广播模式下每条消息都会投递给订阅了Topic的所有消费者实例，在Consumer分配Queue时，所有Consumer都分到所有的Queue。 集群消费模式每条消息只需要投递到订阅该Topic的Consumer Group下的一个实例，RocketMQ采用主动拉取方式拉取并消费消息，在拉取时需明确指定拉取哪一条MessageQueue。 每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时会按照Queue的数量和实例的数量平均分配Queue给每个实例。 每次分配时都会将MessageQueue和消费者ID进行排序，再用不同的分配算法进行分配。内置的分配的算法共有六种，分别对应AllocateMessageQueueStrategy下的六种实现类，可在Consumer中直接指定。默认情况下使用的是最简单的平均分配策略。 AllocateMachineRoomNearby：将同机房的Consumer和Broker优先分配在一起。该策略可通过一个machineRoomResolver对象来定制Consumer和Broker的机房解析规则。还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配。一般用平均分配策略或轮询分配策略。 AllocateMessageQueueAveragely：平均分配，将所有MessageQueue平均分给每一个消费者 AllocateMessageQueueAveragelyByCircle： 轮询分配，轮流的给一个消费者分配一个MessageQueue。 AllocateMessageQueueByConfig： 直接指定一个messageQueue列表，类似于广播模式，直接指定所有队列。 AllocateMessageQueueByMachineRoom：按逻辑机房的概念进行分配。对BrokerName和ConsumerIdc有定制化的配置。 AllocateMessageQueueConsistentHash：一致性哈希策略只需要指定一个虚拟节点数，用一个哈希环算法，虚拟节点是为了让Hash数据在环上分布更为均匀。 消息重试广播模式的消息是不存在消息重试机制，消息消费失败后不会再重新进行发送，继续消费新的消息。对于普通消息，当消费者消费消息失败后，可通过设置返回状态达到消息重试的结果。 集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置，有返回Action.ReconsumeLater、返回NULL、抛出异常三种配置方式。 重试消息会进入一个%RETRY%+ConsumeGroup队列中，默认允许每条消息最多重试16次，重试时间跟延迟消息的延迟级别是对应的，不过取的是延迟级别的后16级别。 重试次数 与上次重试的间隔时间 重试次数 与上次重试的间隔时间 1 10秒 9 7分钟 2 30秒 10 8分钟 3 1分钟 11 9分钟 4 2分钟 12 10分钟 5 3分钟 13 20分钟 6 4分钟 14 30分钟 7 5分钟 15 1小时 8 6分钟 16 2小时 若消息重试16次后仍然失败，消息将不再投递转为进入死信队列，可通过consumer.setMaxReconsumeTimes(20)自定义重试次数，当定制的重试次数超过16次后，消息重试时间间隔均为2小时。 消息最大重试次数的设置对相同GroupID下的所有Consumer实例有效。且最后启动的Consumer会覆盖之前启动的Consumer的配置。 死信队列当一条消息消费失败会自动进行消息重试，若消息超过最大重试次数，RocketMQ认为该消息有问题，但不会立刻将该消息丢弃，而是将其发送到这个消费者组对应的一种特殊队列死信队列。死信队列名称%DLQ%+ConsumGroup。 一个死信队列对应一个ConsumGroup，而不是对应某个消费者实例。 若一个ConsumeGroup没有产生死信队列，RocketMQ就不会为其创建相应的死信队列。 一个死信队列包含了该ConsumeGroup里的所有死信消息，而不区分该消息Topic。 死信队列中的消息不会再被消费者正常消费。 死信队列的有效期跟正常消息相同，默认3天，对应broker.conf中的fileReservedTime属性。超过该最长时间的消息都会被删除，而不管消息是否消费过。 通常一条消息进入了死信队列，意味着消息在消费处理的过程中出现了比较严重的错误，且无法自行恢复。此时，一般需要人工去查看死信队列中的消息，对错误原因进行排查。然后对死信消息进行处理，比如转发到正常的Topic重新进行消费或者丢弃。 消息幂等 发送时消息重复：当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 若此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同且MessageID也相同的消息。 投递时消息重复：消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。 为了保证消息至少被消费一次，RocketMQ服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且MessageID也相同的消息。 负载均衡时消息重复：包括但不限于网络抖动、Broker重启以及订阅方应用重启，当RocketMQ的Broker或客户端重启、扩容或缩容时，会触发Rebalance，此时消费者可能会收到重复消息。 在RocketMQ中，无法保证每个消息只被投递一次，所以要在业务上自行来保证消息消费的幂等性。RocketMQ的每条消息都有一个唯一的MessageId，该参数在多次投递的过程中是不会改变，业务上可用MessageId来作为判断幂等的关键依据。 MessageId无法保证全局唯一，也会有冲突的情况。所以在一些对幂等性要求严格的场景，最好是使用业务上唯一的一个标识如订单ID。而该业务标识可使用Message的Key来进行传递。 消息零丢失 生产者使用事务消息机制。 Broker配置同步刷盘+Dledger主从架构 消费者不要使用异步消费。 整个MQ挂了之后准备降级方案 消息积压处理若Topic下的MessageQueue配置得是足够多的，每个Consumer实际上会分配多个MessageQueue来进行消费。可通过增加Consumer服务节点数量来加快消息的消费，等积压消息消费完了，再恢复成正常情况。最极限的情况是把Consumer的节点个数设置成跟MessageQueue的个数相同。此时再继续增加Consumer的服务节点就没有用了。 若Topic下的MessageQueue配置不够多，就不能用上面这种增加Consumer节点个数的方法。若要快速处理积压的消息，可创建一个新的Topic，配置足够多的MessageQueue，把所有消费者节点的目标Topic转向新的Topic，并紧急上线一组新的消费者，只负责消费旧Topic中的消息，并转储到新的Topic中，在新的Topic上就可以通过增加消费者个数来提高消费速度了。 若RocketMQ原本是采用的普通方式搭建主从架构，而现在想要中途改为使用Dledger高可用集群，这时若不想历史消息丢失，就需要先将消息进行对齐，也就是要消费者把所有的消息都消费完，再来切换主从架构。因为Dledger集群会接管RocketMQ原有的CommitLog日志，切换主从架构时，若有消息没有消费完，这些消息是存在旧的CommitLog中的，就无法再进行消费了。该场景下也是需要尽快的处理掉积压的消息。","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://yaoyinglong.github.io/tags/RocketMQ/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"RocketMQ基础","date":"2021-11-28T16:00:00.000Z","path":"Blog/Cloud/MQ/RocketMQ基础/","text":"RocketMQ架构 Producer消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。 Producer启动后会随机选择NameServer集群中其中一个节点建立长连接，定期从NameServer获取Topic路由信息，并判断当前订阅Topic存在哪些Broker上，轮询从队列列表中选择一个队列，并向提供Topic服务的队列所在的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer消息消费的角色，支持分布式集群方式部署。支持以Push推，Pull拉两种模式对消息进行消费。同时支持集群方式和广播方式消费，提供实时消息订阅机制。 Consumer启动后会随机选择NameServer集群中其中一个节点建立长连接，定期从NameServer获取Topic路由信息，并判断当前订阅Topic存在哪些Broker上，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可从Master订阅消息，也可从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离，判断是否读老消息产生读I/O，以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。 NameServerNameServer一个非常简单的Topic路由注册中心，支持Broker动态注册与发现。通常也是集群方式部署，各实例间不信息通讯。Broker向每台NameServer注册自己的路由信息，故每个NameServer实例上都保存一份完整的路由信息。若当某个NameServer因某种原因下线，Broker仍可向其它NameServer同步其路由信息，Producer和Consumer仍可动态感知Broker路由信息。NameServer主要包括Broker管理和路由信息管理两个功能： Broker管理：NameServer接受Broker集群的注册信息且保存作为路由信息基本数据。提供心跳检测机制，检查Broker是否存活； 路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer可知道整个Broker集群的路由信息，从而进行消息的投递和消费。 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。NameServer启动后监听端口，等待Broker、Producer、Consumer连接，相当于一个路由控制中心。 BrokerServerBroker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了以下几个重要子模块。 Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 Client Manager：负责管理Producer和Consumer客户端和维护Consumer的Topic订阅信息 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker和Slave Broker之间的数据同步功能。 Index Service：根据特定Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。 Broker分为Master与Slave，一个Master可对应多个Slave，一个Slave只能对应一个Master，Master与Slave对应关系通过指定相同的BrokerName不同BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master可部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 虽然支持一Master多Slave，但只有BrokerId=1的从服务器才会参与消息读负载。Broker启动后跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker如IP、端口等信息，以及存储所有Topic信息。注册成功后NameServer集群中就有Topic与Broker映射关系。 RocketMQ使用基本样例生产者发送消息有同步发送、异步发送和单向发送三种方式，单向发送使用sendOneway方法来发送消息，该方法无返回值无回调。 12345678DefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\");producer.setNamesrvAddr(\"localhost:9876\");producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.sendOneway(msg);&#125;producer.shutdown(); 同步发送使用send方法同步传递消息，消息会发给集群中的一个Broker节点 123456789DefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\");producer.setNamesrvAddr(\"localhost:9876\");producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(\"%s%n\", sendResult);&#125;producer.shutdown(); 由于是异步发送，这里引入了CountDownLatch，保证所有Producer发送消息的回调方法都执行完了再停止Producer服务。 12345678910111213141516171819202122232425DefaultMQProducer producer = new DefaultMQProducer(\"Jodie_Daily_test\");producer.setNamesrvAddr(\"localhost:9876\");producer.start();producer.setRetryTimesWhenSendAsyncFailed(0);int messageCount = 100;final CountDownLatch countDownLatch = new CountDownLatch(messageCount);for (int i = 0; i &lt; messageCount; i++) &#123; final int index = i; Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; countDownLatch.countDown(); System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; countDownLatch.countDown(); System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.shutdown(); 消费者消费消息有两种模式：消费者主动去Broker上拉取消息的拉模式；消费者等待Broker把消息推送过来的推模式。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class PullConsumer &#123; private static final Map&lt;MessageQueue, Long&gt; OFFSE_TABLE = new HashMap&lt;MessageQueue, Long&gt;(); public static void main(String[] args) throws MQClientException &#123; DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(\"please_rename_unique_group_name_5\"); consumer.setNamesrvAddr(\"localhost:9876\"); consumer.start(); Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(\"TopicTest\"); for (MessageQueue mq : mqs) &#123; System.out.printf(\"Consume from the queue: %s%n\", mq); SINGLE_MQ: while (true) &#123; try &#123; PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32); System.out.printf(\"%s%n\", pullResult); putMessageQueueOffset(mq, pullResult.getNextBeginOffset()); if (pullResult.getMsgFoundList() != null) &#123; for (MessageExt messageExt : pullResult.getMsgFoundList()) &#123; System.out.println(\"messageExt：\" + messageExt); &#125; &#125; switch (pullResult.getPullStatus()) &#123; case FOUND: break; case NO_MATCHED_MSG: break; case NO_NEW_MSG: break SINGLE_MQ; case OFFSET_ILLEGAL: break; default: break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; consumer.shutdown(); &#125; private static long getMessageQueueOffset(MessageQueue mq) &#123; Long offset = OFFSE_TABLE.get(mq); if (offset != null) &#123; return offset; &#125; return 0; &#125; private static void putMessageQueueOffset(MessageQueue mq, long offset) &#123; OFFSE_TABLE.put(mq, offset); &#125;&#125;public class LitePullConsumerAssign &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(\"please_rename_unique_group_name\"); litePullConsumer.setNamesrvAddr(\"localhost:9876\"); litePullConsumer.setAutoCommit(false); litePullConsumer.start(); Collection&lt;MessageQueue&gt; mqSet = litePullConsumer.fetchMessageQueues(\"TopicTest\"); List&lt;MessageQueue&gt; list = new ArrayList&lt;&gt;(mqSet); List&lt;MessageQueue&gt; assignList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; assignList.add(list.get(i)); &#125; litePullConsumer.assign(assignList); litePullConsumer.seek(assignList.get(0), 10); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(\"%s %n\", messageExts); litePullConsumer.commitSync(); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125;public class LitePullConsumerSubscribe &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(\"lite_pull_consumer_test\"); litePullConsumer.setNamesrvAddr(\"localhost:9876\"); litePullConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); litePullConsumer.subscribe(\"TopicTest\", \"*\"); litePullConsumer.start(); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(\"%s%n\", messageExts); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125; 消费者推模式 123456789101112DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_JODIE_1\");consumer.setNamesrvAddr(\"localhost:9876\");consumer.subscribe(\"TopicTest\", \"*\");consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 顺序消息发送者端默认情况下，消息发送者会采取Round Robin轮询方式把消息发送到不同MessageQueue分区队列，消费者消费时也从多个MessageQueue上拉取消息，该情况下消息是不能保证顺序的。仅当一组有序的消息发送到同一个MessageQueue时，才能利用MessageQueue先进先出的特性保证这一组消息有序。而Broker中一个队列内的消息是可以保证有序的。 消费者端消费者会从多个消息队列取消息。虽然每个消息队列消息是有序的，但多个队列之间消息仍是乱序的。消费者端要保证消息有序，就需要按队列一个一个来取消息，即取完一个队列的消息后，再去取下一个队列的消息。而给Consumer注入的MessageListenerOrderly对象，在RocketMQ内部就会通过锁队列的方式保证消息是一个一个队列来取的。MessageListenerConcurrently消息监听器则不会锁队列，每次都是从多个Message中取一批数据，默认不超过32条，因此也无法保证消息有序。 12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.setNamesrvAddr(\"localhost:9876\");producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(\"OrderTopicTest\", \"order_\" + orderId, \"KEY\" + orderId, (\"order_\" + orderId + \" step \" + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(\"%s%n\", sendResult); &#125;&#125;producer.shutdown(); 123456789101112131415DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\");consumer.setNamesrvAddr(\"localhost:9876\");consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(\"OrderTopicTest\", \"*\");consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(\"收到消息内容 \" + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;);consumer.start(); 广播消息在集群状态MessageModel.CLUSTERING下，每条消息只会被同一个消费者组中的一个实例消费到。而广播模式则是把消息模式设置为MessageModel.BROADCASTING，将给所有订阅对应主题的消费者发送消息，而不管消费者是不是同一个消费者组。 12345678910111213DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_1\");consumer.setNamesrvAddr(\"localhost:9876\");consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.setMessageModel(MessageModel.BROADCASTING); // 将消息模式设置为BROADCASTINGconsumer.subscribe(\"TopicTest\", \"*\");consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 延迟消息延迟时间的设置是在Message消息对象上设置一个延迟级别setDelayTimeLevel(3)，开源版RocketMQ中，对延迟消息并不支持任意时间的延迟设定，而是只支持18个固定的延迟级别，1到18分别对应messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h。这18个延迟级别也支持自行定义，不过一般情况下最好不要自定义修改。 12345678910DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 分组名称producer.setNamesrvAddr(\"localhost:9876\");producer.start();for (int i = 0; i &lt; 2; i++) &#123; Message msg = new Message(\"TopicTest\", \"TagA\", (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); // messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h msg.setDelayTimeLevel(3); // 延时队列 SendResult sendResult = producer.send(msg);&#125;producer.shutdown(); 批量消息将多条消息合并成一个批量消息，一次发送出去，可减少网络IO，提升吞吐量。批量消息的使用有一定限制，这些消息Topic和waitStoreMsgOK必须相同，且不能是延迟消息、事务消息等。 12345678910DefaultMQProducer producer = new DefaultMQProducer(\"BatchProducerGroupName\");producer.setNamesrvAddr(\"localhost:9876\");producer.start();String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, \"Tag\", \"OrderID001\", \"Hello world 0\".getBytes()));messages.add(new Message(topic, \"Tag\", \"OrderID002\", \"Hello world 1\".getBytes()));messages.add(new Message(topic, \"Tag\", \"OrderID003\", \"Hello world 2\".getBytes()));producer.send(messages);producer.shutdown(); 若批量消息大于1MB就不要用一个批次发送，而要拆分成多个批次消息发送。实际最大的限制是4194304字节约4MB； 123456789101112131415DefaultMQProducer producer = new DefaultMQProducer(\"BatchProducerGroupName\");producer.setNamesrvAddr(\"localhost:9876\");producer.start();String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;(100 * 1000);for (int i = 0; i &lt; 100 * 1000; i++) &#123; messages.add(new Message(topic, \"Tag\", \"OrderID\" + i, (\"Hello world \" + i).getBytes()));&#125;producer.send(messages);ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem);&#125;producer.shutdown(); 12345678910111213141516171819202122232425262728293031323334353637383940class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final List&lt;Message&gt; messages; private int sizeLimit = 1000 * 1000; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; //for log overhead if (tmpSize &gt; sizeLimit) &#123; if (nextIndex - currIndex == 0) &#123; nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; sizeLimit) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125; 过滤消息可使用Message的Tag属性来简单快速的过滤信息，TAG是RocketMQ中特有的一个消息属性，一个应用可以就用一个Topic，而应用中的不同业务就用TAG来区分。 1234567891011DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name\");consumer.setNamesrvAddr(\"localhost:9876\");consumer.subscribe(\"TagFilterTest\", \"TagA || TagC\");consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 一个消息只能有一个TAG，不能满足一些比较复杂的场景。 可使用SQL表达式来对消息进行过滤，但只有推模式的消费者可使用SQL过滤。拉模式是用不了的。RocketMQ只定义了一些基本语法来支持这个特性。也可很容易地扩展它。 数值比较：&gt;、&gt;=、&lt;、&lt;=、BETWEEN、= 字符比较：=、&lt;&gt;、IN、IS NULL、IS NOT NULL 逻辑符号：AND、OR、NOT 数值：123，3.1415；字符：&#39;abc&#39;；必须用单引号包裹起来 特殊常量：NULL，布尔值TRUE或FALSE 12345678910111213141516171819202122DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.start();String[] tags = new String[]&#123;\"TagA\", \"TagB\", \"TagC\"&#125;;for (int i = 0; i &lt; 15; i++) &#123; Message msg = new Message(\"SqlFilterTest\", tags[i % tags.length], (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(\"a\", String.valueOf(i)); // 自定义字段 SendResult sendResult = producer.send(msg); System.out.printf(\"%s%n\", sendResult);&#125;producer.shutdown();// 消费者示例DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name\");consumer.setNamesrvAddr(\"localhost:9876\");consumer.subscribe(\"SqlFilterTest\", MessageSelector.bySql(\"(TAGS is not null and TAGS in ('TagA', 'TagB'))and (a is not null and a between 0 and 3)\"));consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 事务消息事务消息是在分布式系统中保证最终一致性的两阶段提交的消息实现，可保证本地事务执行与消息发送两个操作的原子性，事务消息只涉及到消息发送者，对消息消费者来说没有什么特别，即只保证了分布式事务的一半。事务消息的关键是在TransactionMQProducer中指定了一个TransactionListener事务监听器，该事务监听器就是事务消息的关键控制器； 123456789101112131415161718192021222324TransactionListener transactionListener = new TransactionListenerImpl();TransactionMQProducer producer = new TransactionMQProducer(\"please_rename_unique_group_name\");producer.setNamesrvAddr(\"127.0.0.1:9876\");ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName(\"client-transaction-msg-check-thread\"); return thread; &#125;&#125;);producer.setExecutorService(executorService);producer.setTransactionListener(transactionListener);producer.start();String[] tags = new String[]&#123;\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"&#125;;for (int i = 0; i &lt; 10; i++) &#123; Message msg = new Message(\"TopicTest\", tags[i % tags.length], \"KEY\" + i, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES, \"15\"); // 回查次数 msg.putUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS, \"10000\"); // 回查时间 SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(\"%s%n\", sendResult); Thread.sleep(10);&#125;producer.shutdown(); 123456789101112131415161718192021222324public class TransactionListenerImpl implements TransactionListener &#123; @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, \"TagA\")) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, \"TagB\")) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, \"TagC\")) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, \"TagD\")) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125;&#125; 事务消息不支持延迟消息和批量消息，为了避免单个消息被检查太多次而导致队列消息累积，回查次数由BrokerConfig.transactionCheckMax参数来配置，默认15次，可在broker.conf中覆盖，实际检查次数会在message中保存一个用户属性MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES。该属性值大于transactionCheckMax则丢弃，默认情况下同时打印错误日志，可通过重写AbstractTransactionCheckListener类来修改该行为。 该用户属性值按回查次数递增，也可在Producer中自行覆盖该属性。 回查时间间隔由BrokerConfig.transactionTimeOut参数来配置，默认6秒，可在broker.conf中修改，也可给消息配置一个MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS属性来给消息指定一个特定的消息回查时间。 事务性消息可能不止一次被检查或消费；提交给用户的目标主题消息可能会失败，目前以日志的记录而定。其高可用性通过RocketMQ本身的高可用性机制来保证，若希望确保事务消息不丢失、且事务完整性得到保证，建议使用同步双重写入机制。 事务消息的生产者ID不能与其他类型消息的生产者ID共享。与其他类型的消息不同，事务消息允许反向查询，MQ服务器能通过事务消息的生产者ID查询到消费者。 事务消息机制在发送消息时，会将消息转为一个half半消息，并存入RocketMQ内部的一个RMQ_SYS_TRANS_HALF_TOPIC，该Topic对消费者不可见，然后执行本地事务执行commit提交，则Broker会将投递到RMQ_SYS_TRANS_HALF_TOPIC中的消息投递到用户指定真正Topic中，然后再投递一个表示删除的消息到RMQ_SYS_TRANS_OP_HALF_TOPIC中，表示当前事务已完成，若本地事务rollback 回滚，则没有投递到真实Topic的过程，只需要投递表示删除的消息到RMQ_SYS_TRANS_OP_HALF_TOPIC，若Commit提交或Rollback回滚失败，Broker默认每6s中回查调用checkLocalTransaction一次，在该回查方法中再次回滚会提交事务，默认最多15次。 ACL权限控制ACL权限控制主要为RocketMQ提供Topic资源级别的用户访问控制，可在Client客户端通过RPCHook注入AccessKey和SecretKey签名；将对应的权限控制属性，包括Topic访问权限、IP白名单和AccessKey和SecretKey签名等，设置在$ROCKETMQ_HOME/conf/plain_acl.yml配置文件中。Broker端对AccessKey所拥有的权限进行校验，校验不过抛出异常。 1234567891011121314151617181920212223242526272829303132333435private static final String ACL_ACCESS_KEY = \"RocketMQ\";private static final String ACL_SECRET_KEY = \"1234567\";public static void producer() throws MQClientException &#123; DefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\", getAclRPCHook()); producer.setNamesrvAddr(\"127.0.0.1:9876\"); producer.start(); for (int i = 0; i &lt; 128; i++) &#123; try &#123; Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(\"%s%n\", sendResult); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; producer.shutdown();&#125;public static void pushConsumer() throws MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_5\", getAclRPCHook(), new AllocateMessageQueueAveragely()); consumer.setNamesrvAddr(\"127.0.0.1:9876\"); consumer.subscribe(\"TopicTest\", \"*\"); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start();&#125;static RPCHook getAclRPCHook() &#123; return new AclClientRPCHook(new SessionCredentials(ACL_ACCESS_KEY, ACL_SECRET_KEY));&#125; Broker端具体配置信息可参见源码包下docs/cn/acl/user_guide.md，在broker.conf中通过aclEnable=true打开acl的标志。然后就可以用plain_acl.yml来进行权限配置了。且该配置文件是热加载的，修改后不用重启Broker服务。 1234567891011121314151617181920212223242526globalWhiteRemoteAddresses: # 全局白名单，不受ACL控制，通常需要将主从架构中所有节点加进来- 10.10.103.*- 192.168.0.*accounts:- accessKey: RocketMQ secretKey: 12345678 whiteRemoteAddress: admin: false defaultTopicPerm: DENY # 默认Topic访问策略是拒绝 defaultGroupPerm: SUB # 默认Group访问策略是只允许订阅 topicPerms: - topicA=DENY # topicA拒绝 - topicB=PUB|SUB # topicB允许发布和订阅消息 - topicC=SUB # topicC只允许订阅 groupPerms: # the group should convert to retry topic - groupA=DENY - groupB=PUB|SUB - groupC=SUB# 第二个账户，只要是来自192.168.1.*的IP，就可以访问所有资源- accessKey: rocketmq2 secretKey: 12345678 whiteRemoteAddress: 192.168.1.* # if it is admin, it could access all resources admin: true SpringBoot集成SpringBoot集成RocketMQ的starter依赖是由Spring社区提供的，目前正在快速迭代的过程当中，不同版本之间的差距非常大，故需特别注意版本。通过内置的RocketMQTemplate来与RocketMQ交互。 123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 1234# NameServer地址rocketmq.name-server=localhost:9876# 默认的消息生产者组rocketmq.producer.group=springBootGroup SpringBoot集成RocketMQ，消费者部分核心功能都集成到@RocketMQMessageListener注解。消息过滤可以由里面的selectorType属性和selectorExpression来定制，由consumeMode来有序消费还是并发消费等；1234567891011121314151617181920@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate rocketMQTemplate; public void sendMessage(String topic, String msg) &#123; String[] tags = new String[]&#123;\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"&#125;; for (String tag : tags) &#123; String destination = topic + \":\" + tag; this.rocketMQTemplate.convertAndSend(destination, msg); &#125; &#125;&#125;@Component@RocketMQMessageListener(consumerGroup = \"MyConsumerGroup\", messageModel = MessageModel.CLUSTERING, topic = \"TestTopic\", consumeMode = ConsumeMode.CONCURRENTLY, selectorExpression = \"TagA\")public class SpringConsumer implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; System.out.println(\"Received message1 : \" + message); &#125;&#125; 对于事务消息需要添加一个事务消息监听器，对于消息TAG的使用，需要通过将TAG拼接到Topic后面。SpringBoot依赖中的Message对象和RocketMQ中的Message对象是两个不同的对象，SpringBoot中的Message中就没有TAG属性，Tag属性被移到了发送目标中，以Topic:Tag的方式指定。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@ExtRocketMQTemplateConfigurationpublic class ExtRocketMQTemplate extends RocketMQTemplate &#123;&#125;@RocketMQTransactionListener(rocketMQTemplateBeanName = \"extRocketMQTemplate\")public class MyTransactionImpl implements RocketMQLocalTransactionListener &#123; private ConcurrentHashMap&lt;Object, Message&gt; localTrans = new ConcurrentHashMap&lt;&gt;(); @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; Object transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID); String destination = arg.toString(); localTrans.put(transId, msg); //这个msg的实现类是GenericMessage，里面实现了toString方法 //在Header中自定义的RocketMQHeaders.TAGS属性，到这里就没了。但是RocketMQHeaders.TRANSACTION_ID这个属性就还在。 //而message的Header里面会默认保存RocketMQHeaders里的属性，但是都会加上一个RocketMQHeaders.PREFIX前缀 System.out.println(\"executeLocalTransaction msg = \" + msg); //转成RocketMQ的Message对象 org.apache.rocketmq.common.message.Message message = RocketMQUtil.convertToRocketMessage(new StringMessageConverter(), \"UTF-8\", destination, msg); String tags = message.getTags(); if (StringUtils.contains(tags, \"TagA\")) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, \"TagB\")) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125; @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) &#123; String transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID).toString(); Message originalMessage = localTrans.get(transId); // 这里能够获取到自定义的transaction_id属性 System.out.println(\"checkLocalTransaction msg = \" + originalMessage); // 获取标签时，自定义的RocketMQHeaders.TAGS拿不到，但是框架会封装成一个带RocketMQHeaders.PREFIX的属性 String tags = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TAGS).toString(); if (StringUtils.contains(tags, \"TagC\")) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, \"TagD\")) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125;&#125;@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate extRocketMQTemplate; public void sendMessageInTransaction(String topic, String msg) throws InterruptedException &#123; String[] tags = new String[]&#123;\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"&#125;; for (int i = 0; i &lt; 10; i++) &#123; //尝试在Header中加入一些自定义的属性。 Message&lt;String&gt; message = MessageBuilder.withPayload(msg) .setHeader(RocketMQHeaders.TRANSACTION_ID, \"TransID_\" + i) //发到事务监听器里后，这个自己设定的TAGS属性会丢失。但是上面那个属性不会丢失。 .setHeader(RocketMQHeaders.TAGS, tags[i % tags.length]) //MyProp在事务监听器里也能拿到，为什么就单单这个RocketMQHeaders.TAGS拿不到？这只能去调源码了。 .setHeader(\"MyProp\", \"MyProp_\" + i) .build(); String destination = topic + \":\" + tags[i % tags.length]; //这里发送事务消息时，还是会转换成RocketMQ的Message对象，再调用RocketMQ的API完成事务消息机制。 SendResult sendResult = extRocketMQTemplate.sendMessageInTransaction(destination, message, destination); System.out.printf(\"%s%n\", sendResult); Thread.sleep(10); &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://yaoyinglong.github.io/tags/RocketMQ/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"RabbitMQ高级特性及Spring集成","date":"2021-11-25T16:00:00.000Z","path":"Blog/Cloud/MQ/RabbitMQ高级特性及Spring集成/","text":"消息可靠性投递持久化：Exchange持久化、Queue持久化、Message持久化；生产方确认Confirm；消费方确认Ack；Broker高可用； 生成端确认使用RabbitMQ时，作为消息发送方希望杜绝任何消息丢失或投递失败场景。RabbitMQ提供了Confirm确认模式和Return退回模式两种方式用来控制消息的投递可靠性。 RabbitMQ整个消息投递的路径为：Producer到Rabbitmq Broker到Exchange到Queue到Consumer；消息从Producer到Exchange则会返回一个ConfirmCallback。消息从Exchange到Queue投递失败则会返回一个ReturnCallback。可利用这两个Callback控制消息的可靠性投递； 设置ConnectionFactory的publisher-confirms=&quot;true&quot;开启确认模式。使用RabbitTemplate的setConfirmCallback设置回调函数。当消息发送到Exchange后回调confirm方法。在方法中判断ack，若为true则发送成功，若为false则发送失败需要处理。 设置ConnectionFactory的publisher-returns=&quot;true&quot;开启退回模式。使用RabbitTemplate的setReturnCallback设置退回函数，当消息从Exchange路由到Queue失败后，若设置了rabbitTemplate.setMandatory(true)参数，则会将消息退回给Producer并执行回调函数returnedMessage。 消费端确认ack指Acknowledge确认，表示消费端收到消息后的确认方式，有三种确认方式： 自动确认：acknowledge=&quot;none&quot; 手动确认：acknowledge=&quot;manual&quot; 根据异常情况确认：acknowledge=&quot;auto&quot; 自动确认是指当消息一旦被Consumer接收到，则自动确认收到，并将相应message从RabbitMQ消息缓存中移除。但在实际业务处理中，很可能消息接收到，业务处理出现异常，则该消息会丢失。若设置了手动确认方式，则需要在业务处理成功后，调用channel.basicAck()手动签收，若出现异常则调用channel.basicNack()方法，让其自动重新发送消息。 123456789101112131415&lt;!--加载配置文件--&gt;&lt;context:property-placeholder location=\"classpath:rabbitmq.properties\"/&gt;&lt;!-- 定义rabbitmq connectionFactory --&gt;&lt;rabbit:connection-factory id=\"connectionFactory\" host=\"$&#123;rabbitmq.host&#125;\" port=\"$&#123;rabbitmq.port&#125;\" username=\"$&#123;rabbitmq.username&#125;\" password=\"$&#123;rabbitmq.password&#125;\" virtual-host=\"$&#123;rabbitmq.virtual-host&#125;\" publisher-confirms=\"true\" publisher-returns=\"true\"/&gt;&lt;!--定义管理交换机、队列--&gt;&lt;rabbit:admin connection-factory=\"connectionFactory\"/&gt;&lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt;&lt;rabbit:template id=\"rabbitTemplate\" connection-factory=\"connectionFactory\"/&gt;&lt;!--消息可靠性投递（生产端）--&gt;&lt;rabbit:queue id=\"test_queue_confirm\" name=\"test_queue_confirm\"/&gt;&lt;rabbit:direct-exchange name=\"test_exchange_confirm\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=\"test_queue_confirm\" key=\"confirm\"/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:direct-exchange&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath:spring-rabbitmq-producer.xml\")public class ProducerTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testConfirm() &#123; //测试Confirm模式 //定义回调 rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; /** * @param correlationData 相关配置信息 * @param ack exchange交换机 是否成功收到了消息。true 成功，false代表失败 * @param cause 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; System.out.println(\"confirm方法被执行了....\" + correlationData.getId()); // ack为true表示消息已经到达交换机 if (ack) &#123; // 接收成功 System.out.println(\"接收成功消息\" + cause); &#125; else &#123; // 接收失败 System.out.println(\"接收失败消息\" + cause); // 做一些处理，让消息再次发送。 &#125; &#125; &#125;); // 进行消息发送 for (int i = 0; i &lt; 5; i++) &#123; rabbitTemplate.convertAndSend(\"test_exchange_confirm\", \"confirm\", \"message Confirm...\"); &#125; &#125; @Test public void testReturn() &#123; // 测试return模式 // 设置交换机处理失败消息的模式，为true时消息到达不了队列时，会将消息重新返回给生产者 rabbitTemplate.setMandatory(true); // 定义回调 rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &#123; /** * @param message 消息对象 * @param replyCode 错误码 * @param replyText 错误信息 * @param exchange 交换机 * @param routingKey 路由键 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(\"return 执行了....\"); System.out.println(\"message:\" + message); System.out.println(\"replyCode:\" + replyCode); System.out.println(\"replyText:\" + replyText); System.out.println(\"exchange:\" + exchange); System.out.println(\"routingKey:\" + routingKey); &#125; &#125;); // 进行消息发送 rabbitTemplate.convertAndSend(\"test_exchange_confirm\", \"confirm\", \"message return...\"); &#125;&#125; 12345&lt;!--定义监听器容器 acknowledge=\"manual\":手动签收 prefetch=\"1\":每次抓取多少条消息 --&gt;&lt;!--定义监听器容器 acknowledge=\"manual\" prefetch=\"1\" --&gt;&lt;rabbit:listener-container connection-factory=\"connectionFactory\" acknowledge=\"manual\" prefetch=\"1\"&gt; &lt;rabbit:listener ref=\"ackListener\" queue-names=\"test_queue_confirm\"&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 12345678910111213141516171819202122@Componentpublic class AckListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; //1、获取消息的id long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //2、获取消息 System.out.println(\"message:\" + new String(message.getBody())); //3、进行业务处理 System.out.println(\"=====进行业务处理====\"); //模拟出现异常 int i = 5/0; //4、进行消息签收 channel.basicAck(deliveryTag, false); System.out.println(\"收到了消息:\" + deliveryTag); &#125; catch (Exception e) &#123; //拒绝签收，第三个参数：requeue：重回队列。如果设置为true，则消息重新回到queue，broker会重新发送该消息给消费端 channel.basicNack(deliveryTag, false, true); &#125; &#125;&#125; 消费端限流在&lt;rabbit:listener-container&gt;中配置prefetch属性设置消费端一次拉取多少消息，消费端的确认模式一定为手动确认acknowledge=&quot;manual&quot;。 TTL当消息达到存活时间后，还未被消费会被自动清除，RabbitMQ可对消息设置过期时间，也可对整个队列设置过期时间。 设置队列过期时间使用参数x-message-ttl单位ms毫秒，会对整个队列消息统一过期。设置消息过期时间使用参数expiration单位ms毫秒，当该消息在队列头部时，会单独判断这一消息是否过期。若两者都进行了设置以时间短的为准。 123456789101112&lt;rabbit:queue name=\"test_queue_ttl\" id=\"test_queue_ttl\"&gt; &lt;!--设置queue的参数--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--x-message-ttl指队列的过期时间--&gt; &lt;entry key=\"x-message-ttl\" value=\"10000\" value-type=\"java.lang.Integer\"/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=\"test_exchange_ttl\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=\"ttl.#\" queue=\"test_queue_ttl\"/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 死信队列死信队列DXL。Dead Letter Exchange死信交换机，当消息成为Dead Message后，可被重新发送到另一个交换机，这个交换机就是DLX。消息成为死信的三种情况： 队列消息长度到达限制； 消费者拒接消费消息，basicNack/basicReject且不把消息重新放入原目标队列，requeue=false； 原队列存在消息过期设置，消息到达超时时间未被消费； 死信交换机和死信队列和普通的没有区别，当消息成为死信后，若该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列。可通过给队列设置x-dead-letter-exchange和x-dead-letter-routing-key参数来绑定死信交换机； 12345678910111213141516171819202122232425262728293031323334&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) 3. 正常队列绑定死信交换机 设置两个参数： * x-dead-letter-exchange：死信交换机名称 * x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt;&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) --&gt;&lt;rabbit:queue name=\"test_queue_dlx\" id=\"test_queue_dlx\"&gt; &lt;!--3. 正常队列绑定死信交换机--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--3.1 x-dead-letter-exchange：死信交换机名称--&gt; &lt;entry key=\"x-dead-letter-exchange\" value=\"exchange_dlx\"/&gt; &lt;!--3.2 x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt; &lt;entry key=\"x-dead-letter-routing-key\" value=\"dlx.hehe\"/&gt; &lt;!--4.1 设置队列的过期时间 ttl--&gt; &lt;entry key=\"x-message-ttl\" value=\"10000\" value-type=\"java.lang.Integer\"/&gt; &lt;!--4.2 设置队列的长度限制 max-length--&gt; &lt;entry key=\"x-max-length\" value=\"10\" value-type=\"java.lang.Integer\"/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=\"test_exchange_dlx\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=\"test.dlx.#\" queue=\"test_queue_dlx\"/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!-- 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) --&gt;&lt;rabbit:queue name=\"queue_dlx\" id=\"queue_dlx\"/&gt;&lt;rabbit:topic-exchange name=\"exchange_dlx\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=\"dlx.#\" queue=\"queue_dlx\"/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=\"connectionFactory\" acknowledge=\"manual\" prefetch=\"1\"&gt; &lt;!--定义监听器，监听正常队列--&gt; &lt;rabbit:listener ref=\"dlxListener\" queue-names=\"test_queue_dlx\"&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 123456789101112131415161718192021@Componentpublic class DlxListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //1.接收转换消息 System.out.println(new String(message.getBody())); //2. 处理业务逻辑 System.out.println(\"处理业务逻辑...\"); //int i = 3/0;//出现错误 //3. 手动签收 channel.basicAck(deliveryTag, true); &#125; catch (Exception e) &#123; //e.printStackTrace(); System.out.println(\"出现异常，拒绝接受\"); //4.拒绝签收，不重回队列 requeue=false channel.basicNack(deliveryTag, true, false); &#125; &#125;&#125; 延迟队列延迟队列即消息进入队列后不会立即被消费，只有到达指定时间后才会被消费，在RabbitMQ中并未提供延迟队列功能。但是可使用TTL+死信队列组合实现延迟队列的效果； 123456789101112131415161718192021222324252627&lt;!-- 延迟队列： 1. 定义正常交换机（order_exchange）和队列(order_queue) 2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx) 3. 绑定，设置正常队列过期时间为30分钟--&gt;&lt;!-- 1. 定义正常交换机（order_exchange）和队列(order_queue)--&gt;&lt;rabbit:queue id=\"order_queue\" name=\"order_queue\"&gt; &lt;!--3. 绑定，设置正常队列过期时间为30分钟--&gt; &lt;rabbit:queue-arguments&gt; &lt;entry key=\"x-dead-letter-exchange\" value=\"order_exchange_dlx\"/&gt; &lt;entry key=\"x-dead-letter-routing-key\" value=\"dlx.order.cancel\"/&gt; &lt;entry key=\"x-message-ttl\" value=\"10000\" value-type=\"java.lang.Integer\"/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=\"order_exchange\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=\"order.#\" queue=\"order_queue\"/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!--2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx)--&gt;&lt;rabbit:queue id=\"order_queue_dlx\" name=\"order_queue_dlx\"/&gt;&lt;rabbit:topic-exchange name=\"order_exchange_dlx\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=\"dlx.order.#\" queue=\"order_queue_dlx\"/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=\"connectionFactory\" acknowledge=\"manual\" prefetch=\"1\"&gt; &lt;!--延迟队列效果实现：一定要监听的是死信队列！！！--&gt; &lt;rabbit:listener ref=\"orderListener\" queue-names=\"order_queue_dlx\"&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 消息幂等性保障可通过版本号实现乐观锁的方式优化； 消息积压消费者宕机积压、消费者消费能力不足积压、生产者者流量太大等都可能导致消息积压； 可通过上线更多的消费者，进行正常消费上线专门的队列消费服务，将消息先批量取出来记录数据库再慢慢处理； Spring集成12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:rabbit=\"http://www.springframework.org/schema/rabbit\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd\"&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=\"classpath:rabbitmq.properties\"/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=\"connectionFactory\" host=\"$&#123;rabbitmq.host&#125;\" port=\"$&#123;rabbitmq.port&#125;\" username=\"$&#123;rabbitmq.username&#125;\" password=\"$&#123;rabbitmq.password&#125;\" virtual-host=\"$&#123;rabbitmq.virtual-host&#125;\"/&gt; &lt;!-- 定义管理交换机、队列 --&gt; &lt;rabbit:admin connection-factory=\"connectionFactory\"/&gt; &lt;!-- 定义持久化队列，不存在则自动创建；不绑定到交换机则绑定到默认交换机，默认交换机类型为direct，名字为：\"\"，路由键为队列的名称 --&gt; &lt;!-- id：bean的名称，name：queue的名称，auto-declare：自动创建，durable：是否持久化，auto-delete：自动删除。最后一个消费者和该队列断开连接后，自动删除队列 --&gt; &lt;rabbit:queue id=\"spring_queue\" name=\"spring_queue\" auto-declare=\"true\" durable=\"false\"/&gt; &lt;!-- 广播；所有队列都能收到消息 --&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=\"spring_fanout_queue_1\" name=\"spring_fanout_queue_1\" auto-declare=\"true\"/&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=\"spring_fanout_queue_2\" name=\"spring_fanout_queue_2\" auto-declare=\"true\"/&gt; &lt;!--定义广播类型交换机；并绑定上述两个队列--&gt; &lt;rabbit:fanout-exchange id=\"spring_fanout_exchange\" name=\"spring_fanout_exchange\" auto-declare=\"true\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=\"spring_fanout_queue_1\"/&gt; &lt;rabbit:binding queue=\"spring_fanout_queue_2\"/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:fanout-exchange&gt; &lt;!-- 路由；所有队列都能收到消息 --&gt; &lt;rabbit:queue id=\"spring_direct_queue\" name=\"spring_direct_queue\" auto-declare=\"true\"/&gt; &lt;rabbit:direct-exchange id=\"spring_direct_exchange\" name=\"spring_direct_exchange\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=\"spring_direct_queue\"/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; &lt;!-- 通配符；*匹配一个单词，#匹配多个单词 --&gt; &lt;rabbit:queue id=\"spring_topic_queue_star\" name=\"spring_topic_queue_star\" auto-declare=\"true\"/&gt; &lt;rabbit:queue id=\"spring_topic_queue_well\" name=\"spring_topic_queue_well\" auto-declare=\"true\"/&gt; &lt;rabbit:queue id=\"spring_topic_queue_well2\" name=\"spring_topic_queue_well2\" auto-declare=\"true\"/&gt; &lt;!-- 声明 topic 类型的交换机 --&gt; &lt;rabbit:topic-exchange name=\"spring_topic_exchange\" id=\"spring_topic_exchange\" auto-declare=\"true\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=\"eleven.*\" queue=\"spring_topic_queue_star\"/&gt; &lt;rabbit:binding pattern=\"eleven.#\" queue=\"spring_topic_queue_well\"/&gt; &lt;rabbit:binding pattern=\"itcast.*\" queue=\"spring_topic_queue_well2\"/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:topic-exchange&gt; &lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt; &lt;rabbit:template id=\"rabbitTemplate\" connection-factory=\"connectionFactory\"/&gt;&lt;/beans&gt; 12345678910111213141516171819202122@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath:spring-rabbitmq-producer-basic.xml\")public class ProducerBasicTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testHelloWorld() &#123; rabbitTemplate.convertAndSend(\"spring_queue\", \"hello world spring...\"); &#125; @Test public void testFanout() &#123; rabbitTemplate.convertAndSend(\"spring_fanout_exchange\", \"\", \"spring fanout...\"); &#125; @Test public void testDirect() &#123; rabbitTemplate.convertAndSend(\"spring_direct_exchange\", \"info\", \"spring_direct...\"); &#125; @Test public void testTopic() &#123; rabbitTemplate.convertAndSend(\"spring_topic_exchange\", \"eleven.hehe.haha\", \"spring topic...\"); &#125;&#125; 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:rabbit=\"http://www.springframework.org/schema/rabbit\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd\"&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=\"classpath:rabbitmq.properties\"/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=\"connectionFactory\" host=\"$&#123;rabbitmq.host&#125;\" port=\"$&#123;rabbitmq.port&#125;\" username=\"$&#123;rabbitmq.username&#125;\" password=\"$&#123;rabbitmq.password&#125;\" virtual-host=\"$&#123;rabbitmq.virtual-host&#125;\"/&gt; &lt;bean id=\"springQueueListener\" class=\"com.eleven.icode.rabbitmq.SpringQueueListener\"/&gt; &lt;bean id=\"fanoutListener\" class=\"com.eleven.icode.rabbitmq.SpringQueueListener\"/&gt; &lt;bean id=\"fanoutListener2\" class=\"com.eleven.icode.rabbitmq.SpringQueueListener\"/&gt; &lt;bean id=\"topicListenerStar\" class=\"com.eleven.icode.rabbitmq.SpringQueueListener\"/&gt; &lt;bean id=\"topicListenerWell\" class=\"com.eleven.icode.rabbitmq.SpringQueueListener\"/&gt; &lt;bean id=\"topicListenerWell2\" class=\"com.eleven.icode.rabbitmq.SpringQueueListener\"/&gt; &lt;rabbit:listener-container connection-factory=\"connectionFactory\" auto-declare=\"true\"&gt; &lt;rabbit:listener ref=\"springQueueListener\" queue-names=\"spring_queue\"/&gt; &lt;rabbit:listener ref=\"fanoutListener\" queue-names=\"spring_fanout_queue_1\"/&gt; &lt;rabbit:listener ref=\"fanoutListener2\" queue-names=\"spring_fanout_queue_2\"/&gt; &lt;rabbit:listener ref=\"topicListenerStar\" queue-names=\"spring_topic_queue_star\"/&gt; &lt;rabbit:listener ref=\"topicListenerWell\" queue-names=\"spring_topic_queue_well\"/&gt; &lt;rabbit:listener ref=\"topicListenerWell2\" queue-names=\"spring_topic_queue_well2\"/&gt; &lt;/rabbit:listener-container&gt;&lt;/beans&gt; 123456public class SpringQueueListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; System.out.println(new String(message.getBody())); &#125;&#125; SpringBoot集成1234567spring: rabbitmq: host: localhost #主机ip port: 5672 #端口 username: eleven password: eleven virtual-host: eleven 12345678910111213141516171819202122232425262728@Configurationpublic class TopicConfig &#123; @Bean public Queue topicQ1() &#123; // 声明队列 return new Queue(\"topic_sb_mq_q1\"); &#125; @Bean public Queue topicQ2() &#123; // 声明队列 return new Queue(\"topic_sb_mq_q2\"); &#125; @Bean public TopicExchange setTopicExchange() &#123; // 声明exchange return new TopicExchange(\"topicExchange\"); &#125; @Bean public Binding bindTopicHebei1() &#123; // 声明binding，需要声明一个roytingKey return BindingBuilder.bind(topicQ1()).to(setTopicExchange()).with(\"changsha.*\"); &#125; @Bean public Binding bindTopicHebei2() &#123; return BindingBuilder.bind(topicQ2()).to(setTopicExchange()).with(\"#.beijing\"); &#125;&#125;@RabbitListener(queues = \"topic_sb_mq_q2\")public void topicReceiveq2(String message) &#123; System.out.println(\"Topic模式 topic_sb_mq_q2 received message : \" + message);&#125;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://yaoyinglong.github.io/tags/RabbitMQ/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"RabbitMQ基础","date":"2021-11-24T16:00:00.000Z","path":"Blog/Cloud/MQ/RabbitMQ基础/","text":"MQ的优势系统的耦合性越高，容错性就越低，可维护性就越低，可使用MQ对应用解耦，提升容错性和可维护性； 异步提速，提速用户体验和系统吞吐量 削峰填谷，可以提高系统稳定性 MQ劣势系统引入的外部依赖越多，系统的稳定性就越差，一旦MQ宕机，就会对业务造成影响，如何保证MQ高可用至关重要；系统复杂度提高。 基本概念 RabbitMQ是基于AMQP网络协议即Advanced Message Queuing Protocol高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息。 采用Erlang语言开发，其基础架构图如下： Broker：接收和分发消息的应用，RabbitMQ Server就是Message Broker Virtual host：出于多租户和安全因素设计，把AMQP基本组件划分到一个虚拟的分组中，当多个不同用户使用同一个RabbitMQ server提供的服务时，可划分出多个vhost，每个用户在自己的vhost创建exchange、queue等 Connection：publisher、consumer和broker之间的TCP连接 Channel：在Connection内部建立的逻辑连接，若应用程序支持多线程，通常每个Thread创建单独的Channel进行通讯，AMQP Method包含了Channel Id帮助客户端和Message Broker识别Channel，故Channel之间是完全隔离的。若每一次访问RabbitMQ都建立一个Connection，在消息量大时建立TCP Connection开销将巨大，效率也较低。Channel作为轻量级的 Connection极大减少了操作系统建立TCP Connection开销。 Exchange：Message到达Broker的第一站，接收消息然后根据分发规则，匹配查询表中的Routing Key，分发消息到具体的Queue中，只具备消息转发，不具备消息存储能力，若没有任何队列与Exchange绑定或没有符合路由规则的队列消息将丢失。Exchange有常见以下3种类型： Fanout广播：将消息交给所有绑定到交换机的队列 Direct定向：把消息交给符合指定Routing Key的队列 Topic通配符：把消息交给符合Routing Pattern路由模式的队列 Queue：消息最终被送到这里等待Consumer消费 Binding：Exchange和Queue之间的虚拟连接，Binding中可包含Routing Key。Binding信息被保存到Exchange中的查询表中，作为Message分发依据。 RabbitMQ工作模式RabbitMQ提供了简单模式、Work Queues工作队列、Publish/Subscribe发布订阅模式、Routing路由模式、Topics主题模式、RPC远程调用模式6种工作模式。 123456789101112131415161718public class RabbitUtils &#123; private static ConnectionFactory connectionFactory = new ConnectionFactory(); static &#123; connectionFactory.setHost(\"localhost\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"eleven\"); connectionFactory.setPassword(\"eleven\"); connectionFactory.setVirtualHost(\"eleven\"); &#125; public static Connection getConnection() &#123; try &#123; return connectionFactory.newConnection(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 简单模式一个生产者、一个消费者，不需要设置交换机，使用默认的交换机 1234567891011121314151617181920212223242526272829303132333435363738public class Producer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = RabbitUtils.getConnection(); // 获取TCP长连接 Channel channel = connection.createChannel();// 创建通信“通道”，相当于TCP中的虚拟连接 // 声明并创建一个队列，如果队列已存在，则使用这个队列 // 五个参数分别为：队列名称ID、是否持久化false对应不持久化数据，MQ停掉数据就会丢失、是否队列私有化，false则代表所有消费者都可以访问，true代表只有第一次拥有它的消费者才能一直使用，其他消费者不让访问 // 是否自动删除false代表连接停掉后不自动删除掉这个队列、其他额外的参数这里设置为null channel.queueDeclare(RabbitConstant.QUEUE_HELLOWORLD, false, false, false, null); String message = \"test message\"; // 四个参数：exchange交换机，暂时用不到这里设置为空字符串、队列名称、额外的设置属性、最后一个参数是要传递的消息字节数组 channel.basicPublish(\"\", RabbitConstant.QUEUE_HELLOWORLD, null, message.getBytes()); channel.close(); &#125;&#125;public class Consumer &#123; public static void main(String[] args) throws IOException &#123; Connection conn = RabbitUtils.getConnection(); // 获取TCP长连接 Channel channel = conn.createChannel();// 创建通信“通道”，相当于TCP中的虚拟连接 channel.queueDeclare(RabbitConstant.QUEUE_HELLOWORLD, false, false, false, null); // 从MQ服务器中获取数据，创建一个消息消费者 //三个参数：队列名、是否自动确认收到消息，false代表手动编程来确认消息MQ的推荐做法、 传入DefaultConsumer的实现类 channel.basicConsume(RabbitConstant.QUEUE_HELLOWORLD, false, new Reciver(channel)); &#125;&#125;public class Reciver extends DefaultConsumer &#123; private Channel channel; public Reciver(Channel channel) &#123; super(channel); this.channel = channel; &#125; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body); System.out.println(\"消费者接收到的消息：\" + message + \"，消息的TagId：\" + envelope.getDeliveryTag()); // false只确认签收当前的消息，设置为true的时候则代表签收该消费者所有未签收的消息 channel.basicAck(envelope.getDeliveryTag(), false); &#125;&#125; Work Queues工作队列模式相对于简单模式，可多个消费端共同消费同一个队列消息，且对于同一个消息消费者之间是竞争关系，对于任务过重或任务较多情况使用工作队列可提高任务处理速度，比如短信通知服务、邮件通知服务等。不用定义交换机，生产者是面向队列发送消息，底层使用默认交换机； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class OrderSystem &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SMS, false, false, false, null); for (int i = 1; i &lt;= 100; i++) &#123; SMS sms = new SMS(\"乘客\" + i, \"13900000\" + i, \"您的车票已预订成功\"); String jsonSMS = new Gson().toJson(sms); channel.basicPublish(\"\", RabbitConstant.QUEUE_SMS, null, jsonSMS.getBytes()); &#125; System.out.println(\"发送数据成功\"); channel.close(); connection.close(); &#125;&#125;public class SMSSender1 &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SMS, false, false, false, null); // 若不写basicQos(1)，则自动MQ会将所有请求平均发送给所有消费者 // basicQos,MQ不再对消费者一次发送多个请求，而是消费者处理完一个消息后（确认后），再从队列中获取一个新的 channel.basicQos(1); // 处理完一个取一个，处理速度快的机器将多处理消息，若不设置则会平均分配 channel.basicConsume(RabbitConstant.QUEUE_SMS, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String jsonSMS = new String(body); System.out.println(\"SMSSender1-短信发送成功:\" + jsonSMS); channel.basicAck(envelope.getDeliveryTag(), false); // false只确认签收当前的消息 &#125; &#125;); &#125;&#125;public class SMSSender2 &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SMS, false, false, false, null); // 若不写basicQos(1)，则自动MQ会将所有请求平均发送给所有消费者 // basicQos,MQ不再对消费者一次发送多个请求，而是消费者处理完一个消息后（确认后），再从队列中获取一个新的 channel.basicQos(1); // 处理完一个取一个，处理速度快的机器将多处理消息，若不设置则会平均分配 channel.basicConsume(RabbitConstant.QUEUE_SMS, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String jsonSMS = new String(body); System.out.println(\"SMSSender2-短信发送成功:\" + jsonSMS); channel.basicAck(envelope.getDeliveryTag(), false); // false只确认签收当前的消息 &#125; &#125;); &#125;&#125; 发布订阅模式相对于前两个模式增加了交换机，且须将交换机设置为fanout类型，且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列，一个消息可被多个消费者都收到。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class WeatherBureau &#123; // 这里使用到了交换机，需要手动创建交换机否则会报错，且指定交换机类型为fanout public static void main(String[] args) throws Exception &#123; Connection connection = RabbitUtils.getConnection(); String input = new Scanner(System.in).next(); Channel channel = connection.createChannel(); //第一个参数交换机名字 其他参数和之前的一样 channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER,\"\" , null , input.getBytes()); channel.close(); connection.close(); &#125;&#125;public class BiaDu &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); // 获取TCP长连接 final Channel channel = connection.createChannel(); //获取虚拟连接 channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); // 声明队列信息 // queueBind用于将队列与交换机绑定，参数1：队列名 参数2：交互机名 参数三：路由key（暂时用不到) channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER, \"\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"百度天气收到气象信息：\" + new String(body)); channel.basicAck(envelope.getDeliveryTag() , false); &#125; &#125;); &#125;&#125;public class Sina &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); //获取TCP长连接 final Channel channel = connection.createChannel(); //获取虚拟连接 channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); //声明队列信息 // queueBind用于将队列与交换机绑定，参数1：队列名 参数2：交互机名 参数三：路由key（暂时用不到) channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER, \"\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"新浪天气收到气象信息：\" + new String(body)); channel.basicAck(envelope.getDeliveryTag() , false); &#125; &#125;); &#125;&#125; 路由模式须将交换机设置为direct类型，队列与交换机的绑定不能是任意绑定，需要指定一个Routing Key即路由key，消息发送方在向Exchange发消息时，也必须指定消息Routing Key；Exchange不再把消息交给每一个绑定的队列，而是根据消息Routing Key进行判断，只有队列Routing key与消息Routing Key完全一致，才会接收到消息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class WeatherBureau &#123; // 要手动创建交换机否则会报错，且指定交换机类型为direct，否则路由将失效 public static void main(String[] args) throws Exception &#123; Map&lt;String, String&gt; area = new LinkedHashMap&lt;String, String&gt;(); area.put(\"china.hunan.changsha.20201127\", \"中国湖南长沙20201127天气数据\"); area.put(\"china.hubei.wuhan.20201127\", \"中国湖北武汉20201127天气数据\"); area.put(\"china.hunan.zhuzhou.20201127\", \"中国湖南株洲20201127天气数据\"); area.put(\"us.cal.lsj.20201127\", \"美国加州洛杉矶20201127天气数据\"); area.put(\"china.hebei.shijiazhuang.20201128\", \"中国河北石家庄20201128天气数据\"); area.put(\"china.hubei.wuhan.20201128\", \"中国湖北武汉20201128天气数据\"); area.put(\"china.henan.zhengzhou.20201128\", \"中国河南郑州20201128天气数据\"); area.put(\"us.cal.lsj.20201128\", \"美国加州洛杉矶20201128天气数据\"); Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); Iterator&lt;Map.Entry&lt;String, String&gt;&gt; itr = area.entrySet().iterator(); while (itr.hasNext()) &#123; Map.Entry&lt;String, String&gt; me = itr.next(); //第一个参数交换机名字，第二个参数作为 消息的routing key channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_ROUTING, me.getKey(), null, me.getValue().getBytes()); &#125; channel.close(); connection.close(); &#125;&#125;public class BiaDu &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); // queueBind用于将队列与交换机绑定，参数1：队列名 参数2：交互机名 参数三：路由key channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_ROUTING, \"china.hunan.changsha.20201127\"); channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_ROUTING, \"china.hebei.shijiazhuang.20201128\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"百度天气收到气象信息：\" + new String(body)); channel.basicAck(envelope.getDeliveryTag() , false); &#125; &#125;); &#125;&#125;public class Sina &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); // 指定队列与交换机以及routing key之间的关系 channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_ROUTING, \"us.cal.lsj.20201127\"); channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_ROUTING, \"china.hubei.wuhan.20201127\"); channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_ROUTING, \"us.cal.lsj.20201128\"); channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_ROUTING, \"china.henan.zhengzhou.20201012\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"新浪天气收到气象信息：\" + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 主题模式须将交换机设置为topic类型，Topic类型与Direct相比，都可根据Routing Key把消息路由到不同队列。Topic类型Exchange可让队列在绑定Routing key时使用通配符；Routing Key一般都是一个或多个单词组成，多个单词之间以.分割，如：item.insert；主题模式可实现发布订阅模式路由模式的功能，只是主题模式在配置Routing Key时刻使用通配符，显得更加灵活； 通配符规则：#匹配一个或多个词，*匹配一个任意词，如：item.#能够匹配item.insert.abc或者item.insert，item.*只能匹配item.insert或item.update 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class WeatherBureau &#123; // 要手动创建交换机否则会报错，且指定交换机类型为topic，否则路由将失效 public static void main(String[] args) throws Exception &#123; Map&lt;String, String&gt; area = new LinkedHashMap&lt;String, String&gt;(); area.put(\"china.hunan.changsha.20201127\", \"中国湖南长沙20201127天气数据\"); area.put(\"china.hubei.wuhan.20201127\", \"中国湖北武汉20201127天气数据\"); area.put(\"china.hunan.zhuzhou.20201127\", \"中国湖南株洲20201127天气数据\"); area.put(\"us.cal.lsj.20201127\", \"美国加州洛杉矶20201127天气数据\"); area.put(\"china.hebei.shijiazhuang.20201128\", \"中国河北石家庄20201128天气数据\"); area.put(\"china.hubei.wuhan.20201128\", \"中国湖北武汉20201128天气数据\"); area.put(\"china.henan.zhengzhou.20201128\", \"中国河南郑州20201128天气数据\"); area.put(\"us.cal.lsj.20201128\", \"美国加州洛杉矶20201128天气数据\"); Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); for (Map.Entry&lt;String, String&gt; entry : area.entrySet()) &#123; //第一个参数交换机名字，第二个参数作为 消息的routing key channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_ROUTING, entry.getKey(), null, entry.getValue().getBytes()); &#125; channel.close(); connection.close(); &#125;&#125;public class BiaDu &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); // queueBind用于将队列与交换机绑定，参数1：队列名 参数2：交互机名 参数三：路由key channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_TOPIC, \"*.*.*.20201127\"); channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_TOPIC, \"china.hebei.shijiazhuang.20201128\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"百度天气收到气象信息：\" + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125;public class Sina &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); // 获取TCP长连接 final Channel channel = connection.createChannel(); //获取虚拟连接 channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); //声明队列信息 // 指定队列与交换机以及routing key之间的关系 channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_TOPIC, \"us.#\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"新浪天气收到气象信息：\" + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 消息确认机制RabbitMQ提供了监听器来接收消息投递状态，消息确认涉及Confirm和Return两种状态，RabbitMQ在传递消息的过程中充当代理人的角色，生产者可以通过监听器来知道消息是否被正确投递到Broker。Confirm代表生产者将消息送到Broker时产生的状态，后续会出现ack和nack两种情况： ack：代表Broker已经将数据接收 nack：代表Broker拒收消息，可能是队列已满、限流、IO异常等 Return代表消息被Broker正常接收ack后，但Broker没有对应的队列进行投递时产生的状态，消息被退回给生产者；Confirm和Return两种状态只代表生成者与Broker之间消息投递情况，与消费者是否接收、确认消息无关； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class WeatherBureau &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Map&lt;String, String&gt; area = new LinkedHashMap&lt;String, String&gt;(); area.put(\"china.hunan.changsha.20201127\", \"中国湖南长沙20201127天气数据\"); area.put(\"china.hubei.wuhan.20201127\", \"中国湖北武汉20201127天气数据\"); area.put(\"china.hunan.zhuzhou.20201127\", \"中国湖南株洲20201127天气数据\"); area.put(\"us.cal.lsj.20201127\", \"美国加州洛杉矶20201127天气数据\"); area.put(\"china.hebei.shijiazhuang.20201128\", \"中国河北石家庄20201128天气数据\"); area.put(\"china.hubei.wuhan.20201128\", \"中国湖北武汉20201128天气数据\"); area.put(\"china.henan.zhengzhou.20201128\", \"中国河南郑州20201128天气数据\"); area.put(\"us.cal.lsj.20201128\", \"美国加州洛杉矶20201128天气数据\"); Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); //开启confirm监听模式 channel.confirmSelect(); channel.addConfirmListener(new ConfirmListener() &#123; @Override public void handleAck(long l, boolean b) throws IOException &#123; //第二个参数代表接收的数据是否为批量接收，一般用不到。 System.out.println(\"消息已被Broker接收,Tag:\" + l); &#125; @Override public void handleNack(long l, boolean b) throws IOException &#123; System.out.println(\"消息已被Broker拒收,Tag:\" + l); &#125; &#125;); channel.addReturnListener(new ReturnCallback() &#123; @Override public void handle(Return r) &#123; System.err.println(\"===========================\"); System.err.println(\"Return编码：\" + r.getReplyCode() + \"-Return描述:\" + r.getReplyText()); System.err.println(\"交换机:\" + r.getExchange() + \"-路由key:\" + r.getRoutingKey()); System.err.println(\"Return主题：\" + new String(r.getBody())); System.err.println(\"===========================\"); &#125; &#125;); for (Map.Entry&lt;String, String&gt; entry : area.entrySet()) &#123; // 第三个参数为：mandatory true代表如果消息无法正常投递则return回生产者，如果false，则直接将消息放弃。 channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, entry.getKey(), true, null, entry.getValue().getBytes()); &#125; //如果关闭则无法进行监听，因此此处不需要关闭 // channel.close(); // connection.close(); &#125;&#125;public class Baidu &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); //queueBind用于将队列与交换机绑定，参数1：队列名 参数2：交互机名 参数三：路由key channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_TOPIC, \"*.*.*.20201127\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"百度天气收到气象信息：\" + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125;public class Sina &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_TOPIC, \"us.#\"); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"腾讯天气收到气象信息：\" + new String(body));// channel.basicAck(envelope.getDeliveryTag() , false); // 第二个参数是否应用于多消息，第三个参数是否重新放回队列 channel.basicNack(envelope.getDeliveryTag(), false, false); &#125; &#125;); &#125;&#125;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://yaoyinglong.github.io/tags/RabbitMQ/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"MQ","slug":"Cloud/MQ","permalink":"https://yaoyinglong.github.io/categories/Cloud/MQ/"}]},{"title":"Zookeeper集群Leader选举","date":"2021-11-22T16:00:00.000Z","path":"Blog/Cloud/Zookeeper/Zookeeper集群Leader选举/","text":"Zookeeper集群的启动是通过QuorumPeerMain的main方法中调用initializeAndRun方法，单机模式的启动是调用ZooKeeperServerMain的main方法，集群的启动是调用本类的runFromConfig方法，最终调用QuorumPeer的start方法来完成集群的启动。对于ServerCnxnFactory默认是使用NIO即创建NIOServerCnxnFactory，官方推荐Netty可通过指定VM参数-Dzookeeper.serverCnxnFactory=org.apache.zookeeper.server.NettyServerCnxnFactory使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class QuorumPeerMain &#123; public static void main(String[] args) &#123; QuorumPeerMain main = new QuorumPeerMain(); main.initializeAndRun(args); System.exit(0); &#125; protected void initializeAndRun(String[] args) throws ConfigException, IOException, AdminServerException &#123; QuorumPeerConfig config = new QuorumPeerConfig(); if (args.length == 1) &#123; config.parse(args[0]); // 解析配置文件加载到内存，包括myid文件内容校验 &#125; DatadirCleanupManager purgeMgr = new DatadirCleanupManager(config.getDataDir(), config.getDataLogDir(), config.getSnapRetainCount(), config.getPurgeInterval()); purgeMgr.start(); // 清理快照文件任务 if (args.length == 1 &amp;&amp; config.isDistributed()) &#123; runFromConfig(config); // 集群启动核心流程 &#125; else &#123; ZooKeeperServerMain.main(args); // 单机模式启动 &#125; &#125; public void runFromConfig(QuorumPeerConfig config) throws IOException, AdminServerException &#123; try &#123; ServerCnxnFactory cnxnFactory = null; ServerCnxnFactory secureCnxnFactory = null; if (config.getClientPortAddress() != null) &#123; cnxnFactory = ServerCnxnFactory.createFactory(); // 初始化服务端链接对象zk默认用NIO，官方推荐Netty cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns(), false); &#125; quorumPeer = getQuorumPeer(); // 获取本节点对象 quorumPeer.setTxnFactory(new FileTxnSnapLog(config.getDataLogDir(), config.getDataDir())); quorumPeer.enableLocalSessions(config.areLocalSessionsEnabled()); quorumPeer.enableLocalSessionsUpgrading(config.isLocalSessionsUpgradingEnabled()); quorumPeer.setElectionType(config.getElectionAlg()); // 设置选举类型，默认为3 quorumPeer.setMyid(config.getServerId()); quorumPeer.setTickTime(config.getTickTime()); quorumPeer.setMinSessionTimeout(config.getMinSessionTimeout()); quorumPeer.setMaxSessionTimeout(config.getMaxSessionTimeout()); quorumPeer.setInitLimit(config.getInitLimit()); quorumPeer.setSyncLimit(config.getSyncLimit()); quorumPeer.setConfigFileName(config.getConfigFilename()); quorumPeer.setZKDatabase(new ZKDatabase(quorumPeer.getTxnFactory())); // 初始化内存数据库对象 quorumPeer.setQuorumVerifier(config.getQuorumVerifier(), false); quorumPeer.initConfigInZKDatabase(); quorumPeer.setCnxnFactory(cnxnFactory); // 将上面创建的初始服务连接对象放入本服务节点对象 quorumPeer.setSecureCnxnFactory(secureCnxnFactory); quorumPeer.setSslQuorum(config.isSslQuorum()); quorumPeer.setUsePortUnification(config.shouldUsePortUnification()); quorumPeer.setLearnerType(config.getPeerType()); quorumPeer.setSyncEnabled(config.getSyncEnabled()); quorumPeer.setQuorumListenOnAllIPs(config.getQuorumListenOnAllIPs()); quorumPeer.setQuorumSaslEnabled(config.quorumEnableSasl); quorumPeer.setQuorumCnxnThreadsSize(config.quorumCnxnThreadsSize); quorumPeer.initialize(); quorumPeer.start(); // 启动服务节点 quorumPeer.join(); &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125; 首先判断当前myid是否在配置文件中配置的集群列表中，然后通过loadDataBase调用ZKDatabase的loadDataBase方法读取快照和事务日志后恢复服务器数据库。然后通过前面创建的NettyServerCnxnFactory的start方法启动Netty服务绑定2181端口。然后通过startLeaderElection方法初始化集群选举leader相关对象数据，最后执行QuorumPeer的run方法启动集群选举leader线程。 12345678910111213141516public class QuorumPeer extends ZooKeeperThread implements QuorumStats.Provider &#123; public synchronized void start() &#123; if (!getView().containsKey(myid)) &#123; // 判断当前myid是否在配置文件中配置的集群列表中 throw new RuntimeException(\"My id \" + myid + \" not in the peer list\"); &#125; loadDataBase(); // 加载文件数据到内存，读取快照和事务日志后恢复服务器数据库 startServerCnxnFactory(); // 启动Netty服务 try &#123; adminServer.start(); // 启动内嵌jetty服务，默认8080端口，用来查看服务端状态信息 &#125; catch (AdminServerException e) &#123; System.out.println(e); &#125; startLeaderElection(); // 初始化集群选举leader相关对象数据 super.start(); // 执行当前类的run方法，启动集群选举leader线程 &#125;&#125; 集群选举初始化初始化集群选举leader相关对象数据，首先将当前选票currentVote设置为本节点，然后启动QuorumCnxManager.Listener线程类开启BIO监听选举端口，然后通过FastLeaderElection启动快速选举算法相关的线程。 123456789101112131415161718192021222324252627282930313233343536public class QuorumPeer extends ZooKeeperThread implements QuorumStats.Provider &#123; synchronized public void startLeaderElection() &#123; try &#123; if (getPeerState() == ServerState.LOOKING) &#123; // 初始时默认为ServerState.LOOKING currentVote = new Vote(myid, getLastLoggedZxid(), getCurrentEpoch()); // 默认将当前选票置为当前节点 &#125; &#125; catch (IOException e) &#123; RuntimeException re = new RuntimeException(e.getMessage()); re.setStackTrace(e.getStackTrace()); throw re; &#125; this.electionAlg = createElectionAlgorithm(electionType); // 初始化选举数据管理器，启动选举监听，启动快速选举算法相关的线程 &#125; protected Election createElectionAlgorithm(int electionAlgorithm) &#123; Election le = null; switch (electionAlgorithm) &#123; case 3: // electionAlgorithm默认为3 QuorumCnxManager qcm = createCnxnManager(); // 初始化选举数据管理器 QuorumCnxManager oldQcm = qcmRef.getAndSet(qcm); // 将新建的选举数据管理器设置到qcmRef，并返回旧的 if (oldQcm != null) &#123; oldQcm.halt(); // 若旧的选举数据管理器不为null则关闭旧的 &#125; QuorumCnxManager.Listener listener = qcm.listener; if (listener != null) &#123; listener.start(); // 启动选举监听，调用QuorumCnxManager.Listener的run方法 FastLeaderElection fle = new FastLeaderElection(this, qcm); fle.start(); // 启动快速选举算法相关的线程 le = fle; &#125; break; default: assert false; &#125; return le; &#125;&#125; 开启BIO监听选举端口，当接收到数据后通过receiveConnection处理接收到的数据，首先读取发送选票的机器sid即该机器myid文件中配置的值，由于Socket链接是全双工的为了防止重复链接的创建，Zookeeper只允许sid大的机器连接sid小的机器，若当前机器的sid大于发送选票机器的sid则关闭Socket连接，然后当前机器主动发起socket连接到发送选票的id较小的机器。若小于则为其创建一个独属的选票发送器线程和选票接收线程用于将来发送或接收选票使用，且将选票发送器与sid对应放入senderWorkerMap中缓存起来，且给发送选票sid机器初始化一个发送选票队列放入queueSendMap中。然后启动选票发送线程和选票接收线程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class Listener extends ZooKeeperThread &#123; public void run() &#123; // 使用普通的socket通信即BIO int numRetries = 0; InetSocketAddress addr; Socket client = null; Exception exitException = null; while ((!shutdown) &amp;&amp; (portBindMaxRetry == 0 || numRetries &lt; portBindMaxRetry)) &#123; try &#123; ss = new ServerSocket(); // 初始化Socket ss.setReuseAddress(true); self.recreateSocketAddresses(self.getId()); addr = self.getElectionAddress(); // 获取进行选举的ip和端口，即配置文件中配置的当前服务的server.1=127.0.0.1:3001 setName(addr.toString()); ss.bind(addr); // 绑定监听地址：127.0.0.1:3001 while (!shutdown) &#123; try &#123; client = ss.accept(); // 在选举端口监听连接 setSockOpts(client); if (quorumSaslAuthEnabled) &#123; receiveConnectionAsync(client); &#125; else &#123; receiveConnection(client); // 接收连接数据 &#125; numRetries = 0; &#125; &#125; &#125; &#125; &#125;&#125;public class QuorumCnxManager &#123; public void receiveConnection(final Socket sock) &#123; DataInputStream din = null; try &#123; din = new DataInputStream(new BufferedInputStream(sock.getInputStream())); handleConnection(sock, din); // 处理连接信息 &#125; catch (IOException e) &#123; closeSocket(sock); &#125; &#125; private void handleConnection(Socket sock, DataInputStream din) throws IOException &#123; Long sid = null, protocolVersion = null; InetSocketAddress electionAddr = null; try &#123; protocolVersion = din.readLong(); // 读取发送选票的机器id，即myid文件中配置的值 if (protocolVersion &gt;= 0) &#123; // this is a server id and not a protocol version sid = protocolVersion; &#125; else &#123; try &#123; InitialMessage init = InitialMessage.parse(protocolVersion, din); sid = init.sid; electionAddr = init.electionAddr; &#125; catch (InitialMessage.InitialMessageException ex) &#123; closeSocket(sock); return; &#125; &#125; if (sid == QuorumPeer.OBSERVER_ID) &#123; sid = observerCounter.getAndDecrement(); &#125; &#125; catch (IOException e) &#123; closeSocket(sock); return; &#125; authServer.authenticate(sock, din); // 认证权限相关的处理 if (sid &lt; self.getId()) &#123; // 若发送选票的机器id小于当前机器则关闭连接，为了防止机器之间相互重复的建立socket连接，不允许id小的机器连接id大的机器 SendWorker sw = senderWorkerMap.get(sid); if (sw != null) &#123; sw.finish(); &#125; closeSocket(sock); // 关闭Socket连接 if (electionAddr != null) &#123; connectOne(sid, electionAddr); &#125; else &#123; connectOne(sid); // 当前机器主动发起socket连接到发送选票的id较小的机器 &#125; &#125; else if (sid == self.getId()) &#123; // 一般不可能发送，若发生可能是bug &#125; else &#123; // Otherwise start worker threads to receive data. // 在接收到选票时，就给发选票的机器建立一个选票发送器线程供将来发送选票使用，并启动发送线程 SendWorker sw = new SendWorker(sock, sid); // 给发送选票sid这台机器创建一个选票发送器 RecvWorker rw = new RecvWorker(sock, din, sid, sw); // 开启接收选票线程 sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if (vsw != null) &#123; vsw.finish(); &#125; senderWorkerMap.put(sid, sw); // 将选票发送器与sid对应放入map queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY)); // 给发送选票sid机器初始化一个发送选票队列放入map sw.start(); // 启动选票发送线程 rw.start(); // 启动选票接收线程 &#125; &#125;&#125; 在快速选举类FastLeaderElection的start方法中通过Messenger类启动了发送选票线程WorkerSender和接收选票线程WorkerReceiver。这里的两个线程与QuorumCnxManager.Listener中开启的SendWorker和RecvWorker组成了Leader选举的多层队列架构。 这里可以将选举底层分为由WorkerSender和WorkerReceiver组成的选举应用层，以及由SendWorker和RecvWorker组成的选举传输层。应用层有自己的队列统一接收和发送选票，传输层也有自己的队列，且是按照发送机器分配的队列，避免给没太机器发送消息时相互影响。 12345678910111213141516171819202122232425262728293031323334public class FastLeaderElection implements Election &#123; LinkedBlockingQueue&lt;ToSend&gt; sendqueue; LinkedBlockingQueue&lt;Notification&gt; recvqueue; public FastLeaderElection(QuorumPeer self, QuorumCnxManager manager) &#123; this.stop = false; this.manager = manager; starter(self, manager); &#125; private void starter(QuorumPeer self, QuorumCnxManager manager) &#123; this.self = self; proposedLeader = -1; proposedZxid = -1; sendqueue = new LinkedBlockingQueue&lt;ToSend&gt;(); recvqueue = new LinkedBlockingQueue&lt;Notification&gt;(); this.messenger = new Messenger(manager); &#125; void start() &#123; this.wsThread.start(); // 运行发送选票线程 this.wrThread.start(); // 运行接收选票线程 &#125;&#125;protected class Messenger &#123; WorkerSender ws; WorkerReceiver wr; Messenger(QuorumCnxManager manager) &#123; this.ws = new WorkerSender(manager); // 用于发送选票的异步线程 this.wsThread = new Thread(this.ws, \"WorkerSender[myid=\" + self.getId() + \"]\"); this.wsThread.setDaemon(true); this.wr = new WorkerReceiver(manager); // 用于接收选票的异步线程 this.wrThread = new Thread(this.wr, \"WorkerReceiver[myid=\" + self.getId() + \"]\"); this.wrThread.setDaemon(true); &#125;&#125; 应用层发送选票线程WorkerSender，首先从从应用层发送阻塞队列里获取选票信息，然后判断发送方是否为本节点，若为本节点则将选票信息放入传输层接收选票的阻塞队列recvQueue中由WorkerReceiver异步处理。若不为本节点则将选票信息放入传输层待发送队列由SendWorker异步处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class WorkerSender extends ZooKeeperThread &#123; public void run() &#123; while (!stop) &#123; try &#123; ToSend m = sendqueue.poll(3000, TimeUnit.MILLISECONDS); // 从应用层发送阻塞队列里获取选票 if (m == null) continue; process(m); // 处理取出的选票 &#125; catch (InterruptedException e) &#123; break; &#125; &#125; &#125; void process(ToSend m) &#123; ByteBuffer requestBuffer = buildMsg(m.state.ordinal(), m.leader, m.zxid, m.electionEpoch, m.peerEpoch, m.configData); manager.toSend(m.sid, requestBuffer); &#125;&#125;public class QuorumCnxManager &#123; public void toSend(Long sid, ByteBuffer b) &#123; if (this.mySid == sid) &#123; // 若选票接收机器是自己，则放入本节点传输层接收队列中 b.position(0); addToRecvQueue(new Message(b.duplicate(), sid)); &#125; else &#123; ArrayBlockingQueue&lt;ByteBuffer&gt; bq = new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY); ArrayBlockingQueue&lt;ByteBuffer&gt; oldq = queueSendMap.putIfAbsent(sid, bq); if (oldq != null) &#123; addToSendQueue(oldq, b); // 放入传输层待发送队列 &#125; else &#123; addToSendQueue(bq, b); // 放入传输层待发送队列 &#125; connectOne(sid); // 与对方sid机器建立连接 &#125; &#125; public void addToRecvQueue(Message msg) &#123; synchronized (recvQLock) &#123; if (recvQueue.remainingCapacity() == 0) &#123; try &#123; recvQueue.remove(); &#125; catch (NoSuchElementException ne) &#123; &#125; &#125; try &#123; recvQueue.add(msg); // 将接收到的选票丢入传输层接收选票的阻塞队列recvQueue中异步处理 &#125; catch (IllegalStateException ie) &#123; &#125; &#125; &#125;&#125; 应用层接收选票线程WorkerReceiver首先从应用层阻塞队列recvQueue中取出选票，首先判断接收到的选票是否是由无投票权的节点，若是则将当前节点的投出的选票信息返回应用层发送队列中发送给发起方。否则判断单签节点状态，若为LOOKING状态则将选票信息放入应用层接收队列由传输层RecvWorker线程去处理。且若发送选票方是选举状态且其选举周期小于本节点，则把本节点投出的选票回发给发送选票方，该情况可能是发送选票方节点后启动。若本节点状态不是LOOKING但发送选票的节点状态为LOOKING，则说明Leader已经明确，则currentVote中存储的是Leader节点的票据信息，则只需要将Leader的票据信息回发即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576class WorkerReceiver extends ZooKeeperThread &#123; public void run() &#123; Message response; while (!stop) &#123; try &#123; response = manager.pollRecvQueue(3000, TimeUnit.MILLISECONDS); // 从传输层接收队列recvQueue中取出选票 if (response == null) continue; // 若未渠道则继续等待下一次获取选票 final int capacity = response.buffer.capacity(); if (capacity &lt; 28) &#123; continue; // 当前协议和前两代协议至少发送28bytes &#125; response.buffer.clear(); Notification n = new Notification(); int rstate = response.buffer.getInt(); long rleader = response.buffer.getLong(); long rzxid = response.buffer.getLong(); long relectionEpoch = response.buffer.getLong(); long rpeerepoch; int version = 0x0; QuorumVerifier rqv = null; if (!validVoter(response.sid)) &#123; // 若来自无投票权的节点则将当前节点投出的选票信息返回应用层发送队列中发送给发起方 Vote current = self.getCurrentVote(); QuorumVerifier qv = self.getQuorumVerifier(); ToSend notmsg = new ToSend(ToSend.mType.notification, current.getId(), current.getZxid(), logicalclock.get(), self.getPeerState(), response.sid, current.getPeerEpoch(), qv.toString().getBytes()); sendqueue.offer(notmsg); // 将当前的选票信息放回应用层发送队列中 &#125; else &#123; QuorumPeer.ServerState ackstate = QuorumPeer.ServerState.LOOKING; switch (rstate) &#123; case 0: ackstate = QuorumPeer.ServerState.LOOKING; break; case 1: ackstate = QuorumPeer.ServerState.FOLLOWING; break; case 2: ackstate = QuorumPeer.ServerState.LEADING; break; case 3: ackstate = QuorumPeer.ServerState.OBSERVING; break; default: continue; &#125; n.leader = rleader; n.zxid = rzxid; n.electionEpoch = relectionEpoch; n.state = ackstate; n.sid = response.sid; n.peerEpoch = rpeerepoch; n.version = version; n.qv = rqv; if (self.getPeerState() == QuorumPeer.ServerState.LOOKING) &#123; recvqueue.offer(n); // 是本机且还处于选举状态，放入应用层接收队列，由RecvWorker线程去处理 // 若发送选票方是选举状态，且发送选票方选举周期小于自己，则把自己PK出来的选票回发给发送选票方 if ((ackstate == QuorumPeer.ServerState.LOOKING) &amp;&amp; (n.electionEpoch &lt; logicalclock.get())) &#123; Vote v = getVote(); QuorumVerifier qv = self.getQuorumVerifier(); ToSend notmsg = new ToSend(ToSend.mType.notification, v.getId(), v.getZxid(), logicalclock.get(), self.getPeerState(), response.sid, v.getPeerEpoch(), qv.toString().getBytes()); sendqueue.offer(notmsg); // 把自己PK出来的选票回发给发送选票方，其实就是当前节点的投票发送回去 &#125; &#125; else &#123; // 若本节点状态不是LOOKING但发送选票的节点状态为LOOKING，则说明Leader已经明确，则只需要将Leader的票据信息返回即可 Vote current = self.getCurrentVote(); // 获取本节点当前的投票 if (ackstate == QuorumPeer.ServerState.LOOKING) &#123; QuorumVerifier qv = self.getQuorumVerifier(); ToSend notmsg = new ToSend(ToSend.mType.notification, current.getId(), current.getZxid(), current.getElectionEpoch(), self.getPeerState(), response.sid, current.getPeerEpoch(), qv.toString().getBytes()); sendqueue.offer(notmsg); // 把本节点的投票回发给发送选票方 &#125; &#125; &#125; &#125; catch (InterruptedException e) &#125; &#125;&#125;public Message pollRecvQueue(long timeout, TimeUnit unit) throws InterruptedException &#123; return recvQueue.poll(timeout, unit); // 从传输层接收队列中取出选票&#125; 传输层接收选票线程RecvWorker，将接收到的选票信息放入传输层接收选票队列recvQueue中由应用层WorkerReceiver线程异步处理。这里接收到的选票信息是由其他节点的SendWorker线程发来的。RecvWorker线程是每个连接的节点都创建了一个。 1234567891011121314151617181920212223242526272829303132333435class RecvWorker extends ZooKeeperThread &#123; public void run() &#123; threadCnt.incrementAndGet(); try &#123; while (running &amp;&amp; !shutdown &amp;&amp; sock != null) &#123; int length = din.readInt(); if (length &lt;= 0 || length &gt; PACKETMAXSIZE) &#123; throw new IOException(\"Received packet with invalid packet: \" + length); &#125; byte[] msgArray = new byte[length]; din.readFully(msgArray, 0, length); ByteBuffer message = ByteBuffer.wrap(msgArray); addToRecvQueue(new Message(message.duplicate(), sid)); // 将接收到的选票丢入recvQueue中异步处理 &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; sw.finish(); closeSocket(sock); &#125; &#125;&#125;public void addToRecvQueue(Message msg) &#123; synchronized (recvQLock) &#123; if (recvQueue.remainingCapacity() == 0) &#123; try &#123; recvQueue.remove(); &#125; catch (NoSuchElementException ne) &#123; &#125; &#125; try &#123; recvQueue.add(msg); // 将接收到的选票丢入传输层接收选票队列recvQueue中由应用层WorkerReceiver线程异步处理 &#125; catch (IllegalStateException ie) &#123; &#125; &#125;&#125; 传输层发送选票线程SendWorker，这里队列中的数据是应用层发送选票线程WorkerSender放入队列中的，将选票数据从队列中取出发送给对应的节点，这里的SendWorker线程是每个连接的节点都创建了一个。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class SendWorker extends ZooKeeperThread &#123; public void run() &#123; threadCnt.incrementAndGet(); try &#123; ArrayBlockingQueue&lt;ByteBuffer&gt; bq = queueSendMap.get(sid); // 取出发送选票队列 if (bq == null || isSendQueueEmpty(bq)) &#123; ByteBuffer b = lastMessageSent.get(sid); if (b != null) &#123; send(b); // 发送选票 &#125; &#125; &#125; catch (IOException e) &#123; this.finish(); &#125; try &#123; while (running &amp;&amp; !shutdown &amp;&amp; sock != null) &#123; ByteBuffer b = null; try &#123; ArrayBlockingQueue&lt;ByteBuffer&gt; bq = queueSendMap.get(sid); // 取出发送选票的阻塞队列 if (bq != null) &#123; b = pollSendQueue(bq, 1000, TimeUnit.MILLISECONDS); // 从阻塞队列中取出选票 &#125; else &#123; break; &#125; if (b != null) &#123; lastMessageSent.put(sid, b); send(b); // 发送选票 &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; catch (Exception e) &#123; &#125; this.finish(); &#125; synchronized void send(ByteBuffer b) throws IOException &#123; byte[] msgBytes = new byte[b.capacity()]; try &#123; b.position(0); b.get(msgBytes); &#125; catch (BufferUnderflowException be) &#123; return; &#125; dout.writeInt(b.capacity()); dout.write(b.array()); dout.flush(); &#125;&#125; 集群选举启动QuorumPeer就是一个Thread线程类，启动集群选举就是掉用该类的run方法来完成的。若本节点为LOOKING状态，不论是不是只读模式最终会通过makeLEStrategy().lookForLeader()调用FastLeaderElection的lookForLeader方法来完成选举功能。若本节点为LEADING状态，在Leader的lead()方法中会同步数据给从节点且会每隔一段时间给从节点发送ping消息保持长连接；若本节点为OBSERVING状态或FOLLOWING状态，在其Observer的observeLeader()方法和Follower的followLeader()方法中会与leader建立连接并接收leader数据同步且一直保持连接。不论是这三种哪种状态，若连接断开则将通过updateServerState()方法将本节点更新为LOOKING状态，然后重新进行选举。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class QuorumPeer extends ZooKeeperThread implements QuorumStats.Provider &#123; public void run() &#123; try &#123; while (running) &#123; // 死循环根据当前节点状态做对应业务处理 switch (getPeerState()) &#123; // 获取本节点状态 case LOOKING: if (Boolean.getBoolean(\"readonlymode.enabled\")) &#123; // 只读模式 final ReadOnlyZooKeeperServer roZk = new ReadOnlyZooKeeperServer(logFactory, this, this.zkDb); Thread roZkMgr = new Thread() &#123; public void run() &#123; try &#123; sleep(Math.max(2000, tickTime)); if (ServerState.LOOKING.equals(getPeerState())) &#123; roZk.startup(); &#125; &#125; catch (InterruptedException e) &#123; &#125; catch (Exception e) &#123; &#125; &#125; &#125;; try &#123; roZkMgr.start(); reconfigFlagClear(); if (shuttingDownLE) &#123; shuttingDownLE = false; startLeaderElection(); &#125; setCurrentVote(makeLEStrategy().lookForLeader()); &#125; catch (Exception e) &#123; LOG.warn(\"Unexpected exception\", e); setPeerState(ServerState.LOOKING); &#125; finally &#123; roZkMgr.interrupt(); roZk.shutdown(); &#125; &#125; else &#123; try &#123; // 这里的Leader选举策略默认是FastLeaderElection reconfigFlagClear(); // 将reconfigFlag置为false，在updateServerState()方法中会用到 if (shuttingDownLE) &#123; shuttingDownLE = false; startLeaderElection(); &#125; setCurrentVote(makeLEStrategy().lookForLeader()); // 调用FastLeaderElection的lookForLeader方法 &#125; catch (Exception e) &#123; setPeerState(ServerState.LOOKING); &#125; &#125; break; case OBSERVING: try &#123; setObserver(makeObserver(logFactory)); observer.observeLeader(); &#125; catch (Exception e) &#123; &#125; finally &#123; observer.shutdown(); setObserver(null); updateServerState(); &#125; break; case FOLLOWING: try &#123; setFollower(makeFollower(logFactory)); follower.followLeader(); // 与leader建立连接并接收leader数据同步 &#125; catch (Exception e) &#123; &#125; finally &#123; follower.shutdown(); setFollower(null); updateServerState(); // 将自己的状态改为LOOKING，进入下一轮选举 &#125; break; case LEADING: try &#123; setLeader(makeLeader(logFactory)); leader.lead(); setLeader(null); &#125; catch (Exception e) &#123; &#125; finally &#123; if (leader != null) &#123; leader.shutdown(\"Forcing shutdown\"); setLeader(null); &#125; updateServerState(); &#125; break; &#125; start_fle = Time.currentElapsedTime(); &#125; &#125; &#125;&#125;private synchronized void updateServerState() &#123; if (!reconfigFlag) &#123; // 进行选举流程时会通过reconfigFlagClear()方法先将reconfigFlag置为false setPeerState(ServerState.LOOKING); return; &#125; if (getId() == getCurrentVote().getId()) &#123; setPeerState(ServerState.LEADING); &#125; else if (getLearnerType() == LearnerType.PARTICIPANT) &#123; setPeerState(ServerState.FOLLOWING); &#125; else if (getLearnerType() == LearnerType.OBSERVER) &#123; setPeerState(ServerState.OBSERVING); &#125; else &#123; // currently shouldn't happen since there are only 2 learner types setPeerState(ServerState.LOOKING); &#125; reconfigFlag = false;&#125; Leader选举首先会将本节点选举周期加一，其初始化选票为本节点，然后将给自己的投票通过sendNotifications将选票放入应用层发送队列由WorkerSender线程异步处理。然后通过while循环对接收到的选票进行处理，首先从应用层接收队列中取出接收到的选票，第一次启动时没有选票会跟需要发送选票的机器建立连接，若获取到选票先判断发送选票方选票是否有效即判断发送选票方sid与选票是否在votingMembers中，然后根据发送方的状态走不同的逻辑。 若发送选票方为LOOKING状态即选举主线，首先判断发送选票方选举周期大于本节点选举周期，该情况可能是本节点后启动加入集群选举或网络中断恢复后加入集群选举，其他机器都选举好几轮了，故需要更新本节点选举周期到最新，然后清空之前的选票箱，然后通过totalOrderPredicate进行选票PK，并将最终通过updateProposal方法将PK获胜的选票更新，最后将获胜的选票发送给所有其他参与投票的节点。若发送选票方选举周期小于本节点选举周期，一般是发送选票的机器刚加入到集群选举，发起投它自己的选票，这种选票一般废弃掉；若选举周期相等，则将发送方节点投递的选票和本节点投递的选票进行选票PK，若发送方节点投递的选票获胜则将选票更新并发送给所有参与选票的节点； 将收到的选票放入选票箱中，然后通过过半数选举leader逻辑，判断是否已经产生了leader，若已产生会查看是否有新选票加入，若有再做一次PK，若新选票获胜则重新选举，若没有新选票加入则返回最终的Leader设置到currentVote属性中。 若发送方节点为OBSERVING状态则直接退出不参与选举，若发送选票方节点为FOLLOWING或LEADING状态，一般是本节点去加入已经选出leader的集群，本节点处于LOKING状态会先将选票投给自己，其他机器接收到后回发已选出的集群leader选票给本节点。直接将收到的集群选票做过半数选举leader逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class FastLeaderElection implements Election &#123; public Vote lookForLeader() throws InterruptedException &#123; if (self.start_fle == 0) &#123; self.start_fle = Time.currentElapsedTime(); &#125; try &#123; HashMap&lt;Long, Vote&gt; recvset = new HashMap&lt;Long, Vote&gt;(); HashMap&lt;Long, Vote&gt; outofelection = new HashMap&lt;Long, Vote&gt;(); int notTimeout = finalizeWait; synchronized (this) &#123; logicalclock.incrementAndGet(); // 选举周期加一 updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); // 初始化选票为自己 &#125; sendNotifications(); // 发送选票选自己 // 当前节点是选举状态会不断从应用层接收队列中获取选票做选举 while ((self.getPeerState() == ServerState.LOOKING) &amp;&amp; (!stop)) &#123; // 从应用层接收队列中取出接收到的选票 Notification n = recvqueue.poll(notTimeout, TimeUnit.MILLISECONDS); if (n == null) &#123; // 第一次启动时肯定没有选票，这时会跟需要发送选票的机器建立连接 if (manager.haveDelivered()) &#123; sendNotifications(); &#125; else &#123; manager.connectAll(); &#125; int tmpTimeOut = notTimeout * 2; notTimeout = (tmpTimeOut &lt; maxNotificationInterval ? tmpTimeOut : maxNotificationInterval); &#125; else if (validVoter(n.sid) &amp;&amp; validVoter(n.leader)) &#123;// 判断发送选票方选票是否有效，其实就是判断sid与选票是否在votingMembers中 switch (n.state) &#123; // 根据发送方的状态走不同的逻辑 case LOOKING: // 选举主线 // 接收的选票选举周期大于自己的选举周期，1.可能是自己后启动加入集群选举；2.网络中断恢复后加入集群选举；其他机器都选举好几轮了，所以需要更新自己的选举周期到最新 if (n.electionEpoch &gt; logicalclock.get()) &#123; logicalclock.set(n.electionEpoch); // 更新自己的选举周期到最新 recvset.clear(); // 清空之前的选票箱 // 选票PK，因为自己选举周期落后，可能是刚加入集群选举，所以是拿收到的选票跟给自己的选票做PK if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, getInitId(), getInitLastLoggedZxid(), getPeerEpoch())) &#123; updateProposal(n.leader, n.zxid, n.peerEpoch); // 接收到的选票获胜，更新选票 &#125; else &#123; updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); // 本节点获胜，更新选票 &#125; sendNotifications(); // 发送选票给其他参与选举的所有节点 &#125; else if (n.electionEpoch &lt; logicalclock.get()) &#123; break;// 接收的选票选举周期小于自己的选举周期，一般发送选票的机器刚加入到集群选举，发起投它自己的选票，这种选票一般废弃掉 &#125; else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) &#123; // 接收的选票的选举周期等于自己，说明大家一直都在参与选举，则在选举PK时需要拿收到的选票跟之前本机投的选票做PK updateProposal(n.leader, n.zxid, n.peerEpoch); // 接收到的选票获胜，更新选票 sendNotifications(); // 发送选票给其他参与选举的所有节点 &#125; recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); // 将接收到的选票放入选票箱 if (termPredicate(recvset, new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch))) &#123; // 过半数选举leader逻辑 // 虽然termPredicate已经选出leader，但需要查看是否有新选票加入，若有再做一次PK，若新选票获胜则重新选举 while ((n = recvqueue.poll(finalizeWait, TimeUnit.MILLISECONDS)) != null) &#123; if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) &#123; recvqueue.put(n); break; // 若新选票获胜则重新选举，则退出重新选举 &#125; &#125; if (n == null) &#123; // 若选出的Leader节点是当前节点，则设置为LEADING，否则设置为FOLLOWING或OBSERVING self.setPeerState((proposedLeader == self.getId()) ? ServerState.LEADING : learningState()); Vote endVote = new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch); leaveInstance(endVote); return endVote; // 返回选出的Leader并设置到本节点的currentVote属性中 &#125; &#125; break; case OBSERVING: // 若是OBSERVING状态的节点则不参与选举 break; case FOLLOWING: case LEADING: // FOLLOWING和LEADING状态的都会走该逻辑，这种状态一般是已经选出leader的集群有新机器加入，新机器处于LOKING状态，会先将选票投给自己 // 其他机器接收到后会发已选出的集群leader选票给该机器，该选票的发送方状态就是LEADING或FOLLOWING if (n.electionEpoch == logicalclock.get()) &#123; // 若选举周期相等 recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); // 判断n的选票是否超过半数 if (termPredicate(recvset, new Vote(n.version, n.leader, n.zxid, n.electionEpoch, n.peerEpoch, n.state)) &amp;&amp; checkLeader(outofelection, n.leader, n.electionEpoch)) &#123; self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING : learningState()); Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote; &#125; &#125; outofelection.put(n.sid, new Vote(n.version, n.leader, n.zxid, n.electionEpoch, n.peerEpoch, n.state)); if (termPredicate(outofelection, new Vote(n.version, n.leader, n.zxid, n.electionEpoch, n.peerEpoch, n.state)) &amp;&amp; checkLeader(outofelection, n.leader, n.electionEpoch)) &#123; synchronized (this) &#123; logicalclock.set(n.electionEpoch); self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING : learningState()); &#125; Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote; &#125; break; default: break; &#125; &#125; &#125; return null; &#125; &#125;&#125;synchronized void updateProposal(long leader, long zxid, long epoch) &#123; proposedLeader = leader; proposedZxid = zxid; proposedEpoch = epoch;&#125;private void sendNotifications() &#123; for (long sid : self.getCurrentAndNextConfigVoters()) &#123; QuorumVerifier qv = self.getQuorumVerifier(); // 选票中最大zxid是从内存树中取得 ToSend notmsg = new ToSend(ToSend.mType.notification, proposedLeader, proposedZxid, logicalclock.get(), QuorumPeer.ServerState.LOOKING, sid, proposedEpoch, qv.toString().getBytes()); sendqueue.offer(notmsg); // 给所有其他参与投票的节点发送选票到应用层发送队列 &#125;&#125; 对于选票的PK逻辑，首先比较选票的选举周期，若前者的选票的选举周期大于后者的则返回true，若选举周期相等则比较最大事务zxid，若前者大返回true，若最大事务zxid也相等，则比较sid或者叫myid，若前者大返回true，否则返回false； 1234567protected boolean totalOrderPredicate(long newId, long newZxid, long newEpoch, long curId, long curZxid, long curEpoch) &#123; if (self.getQuorumVerifier().getWeight(newId) == 0) &#123; return false; &#125; // 首先比较收到的选票的选举周期，若收到的选票的选举周期大于当前的则返回true，若选举周期相同，比较zxid，若选举周期相同，zxid也相同，则比较myid return ((newEpoch &gt; curEpoch) || ((newEpoch == curEpoch) &amp;&amp; ((newZxid &gt; curZxid) || ((newZxid == curZxid) &amp;&amp; (newId &gt; curId)))));&#125; 过半数选举leader逻辑，是判断选票箱中vote的选票是否超过参与选举机器的半数，没有超过半数则返回false； 12345678910111213141516171819202122232425262728protected boolean termPredicate(Map&lt;Long, Vote&gt; votes, Vote vote) &#123; // 过半数选举leader逻辑，判断vote的选票是否超过半数 SyncedLearnerTracker voteSet = new SyncedLearnerTracker(); voteSet.addQuorumVerifier(self.getQuorumVerifier()); if (self.getLastSeenQuorumVerifier() != null &amp;&amp; self.getLastSeenQuorumVerifier().getVersion() &gt; self.getQuorumVerifier().getVersion()) &#123; voteSet.addQuorumVerifier(self.getLastSeenQuorumVerifier()); &#125; // 遍历选票箱中收到的选票与本机投的leader选票对比，若相等，则将投票机器sid加入到选票箱 for (Map.Entry&lt;Long, Vote&gt; entry : votes.entrySet()) &#123; if (vote.equals(entry.getValue())) &#123; voteSet.addAck(entry.getKey()); &#125; &#125; return voteSet.hasAllQuorums(); // 判断投票机器是否超过半数，超过半数返回true&#125;public class SyncedLearnerTracker &#123; public boolean hasAllQuorums() &#123; for (QuorumVerifierAcksetPair qvAckset : qvAcksetPairs) &#123; if (!qvAckset.getQuorumVerifier().containsQuorum(qvAckset.getAckset())) return false; // containsQuorum判断投票机器是否超过半数 &#125; return true; &#125;&#125;public class QuorumMaj implements QuorumVerifier &#123; public boolean containsQuorum(Set&lt;Long&gt; ackSet) &#123; return (ackSet.size() &gt; half); &#125;&#125; 若本节点为OBSERVING状态，则通过makeObserver新建一个Observer类然后调用其observeLeader()方法，与leader建立连接并接收leader数据同步且一直保持连接，若连接断开会将observer关闭后置空且将当前节点状态置为LOOKING。 123456789101112131415161718192021222324252627public class Observer extends Learner&#123; void observeLeader() throws Exception &#123; zk.registerJMX(new ObserverBean(this, zk), self.jmxLocalPeerBean); try &#123; QuorumServer leaderServer = findLeader(); try &#123; // 连接到leader节点交换信息的端口，如配置的2001 connectToLeader(leaderServer.addr, leaderServer.hostname);// 主动向leader发起socket连接 long newLeaderZxid = registerWithLeader(Leader.OBSERVERINFO);// 注册自己到Leader if (self.isReconfigStateChange()) throw new Exception(\"learned about role change\"); syncWithLeader(newLeaderZxid);// 同步leader数据 QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) &#123; // 死循环获取数据且保持连接 readPacket(qp);// 若leader挂了，这里从leader取数据时会抛出异常退出循环 processPacket(qp); &#125; &#125; catch (Exception e) &#123; try &#123; sock.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; pendingRevalidations.clear(); &#125; &#125; &#125;&#125; 若本节点为FOLLOWING状态，其逻辑和OBSERVING状态的节点类似。若连接断开会将observer关闭后置空且将当前节点状态置为LOOKING。 1234567891011121314151617181920212223242526272829303132333435363738public class Follower extends Learner&#123; void followLeader() throws InterruptedException &#123; self.end_fle = Time.currentElapsedTime(); long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); self.start_fle = 0; self.end_fle = 0; fzk.registerJMX(new FollowerBean(this, zk), self.jmxLocalPeerBean); try &#123; QuorumServer leaderServer = findLeader(); // 获取leader server try &#123; connectToLeader(leaderServer.addr, leaderServer.hostname); // 主动向leader发起socket连接 long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); // 注册自己到Leader if (self.isReconfigStateChange()) throw new Exception(\"learned about role change\"); long newEpoch = ZxidUtils.getEpochFromZxid(newEpochZxid); if (newEpoch &lt; self.getAcceptedEpoch()) &#123; throw new IOException(\"Error: Epoch of leader is lower\"); &#125; syncWithLeader(newEpochZxid); // 同步leader数据 QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) &#123; // while死循环接收leader同步的数据 readPacket(qp); // 若leader挂了，这里从leader取数据时会抛出异常退出循环 processPacket(qp); &#125; &#125; catch (Exception e) &#123; try &#123; sock.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; pendingRevalidations.clear(); &#125; &#125; finally &#123; zk.unregisterJMX((Learner)this); &#125; &#125;&#125; 若本节点为LEADING状态，其逻辑与OBSERVING和FOLLOWING状态的节点有一点区别，这里是调用Leader的lead()方法，首先会通过LearnerCnxAcceptor同步数据给从节点，然后每隔一段时间给从节点发送ping消息保持长连接。若连接断开会将observer关闭后置空且将当前节点状态置为LOOKING。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class Leader &#123; void lead() throws IOException, InterruptedException &#123; self.end_fle = Time.currentElapsedTime(); long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); self.start_fle = 0; self.end_fle = 0; zk.registerJMX(new LeaderBean(this, zk), self.jmxLocalPeerBean); try &#123; self.tick.set(0); zk.loadData(); // 初始化LeaderZookeeperServer数据 leaderStateSummary = new StateSummary(self.getCurrentEpoch(), zk.getLastProcessedZxid()); cnxAcceptor = new LearnerCnxAcceptor(); cnxAcceptor.start(); // 同步数据给从节点 long epoch = getEpochToPropose(self.getId(), self.getAcceptedEpoch()); zk.setZxid(ZxidUtils.makeZxid(epoch, 0)); synchronized(this)&#123; lastProposed = zk.getZxid(); &#125; newLeaderProposal.packet = new QuorumPacket(NEWLEADER, zk.getZxid(), null, null); QuorumVerifier lastSeenQV = self.getLastSeenQuorumVerifier(); QuorumVerifier curQV = self.getQuorumVerifier(); if (curQV.getVersion() == 0 &amp;&amp; curQV.getVersion() == lastSeenQV.getVersion()) &#123; try &#123; QuorumVerifier newQV = self.configFromString(curQV.toString()); newQV.setVersion(zk.getZxid()); self.setLastSeenQuorumVerifier(newQV, true); &#125; catch (Exception e) &#123; throw new IOException(e); &#125; &#125; newLeaderProposal.addQuorumVerifier(self.getQuorumVerifier()); if (self.getLastSeenQuorumVerifier().getVersion() &gt; self.getQuorumVerifier().getVersion())&#123; newLeaderProposal.addQuorumVerifier(self.getLastSeenQuorumVerifier()); &#125; waitForEpochAck(self.getId(), leaderStateSummary); self.setCurrentEpoch(epoch); try &#123; waitForNewLeaderAck(self.getId(), zk.getZxid()); &#125; catch (InterruptedException e) &#123; shutdown(\"Waiting for a quorum of followers, only synced with sids: [ \" + newLeaderProposal.ackSetsToString() + \" ]\"); HashSet&lt;Long&gt; followerSet = new HashSet&lt;Long&gt;(); for(LearnerHandler f : getLearners()) &#123; if (self.getQuorumVerifier().getVotingMembers().containsKey(f.getSid()))&#123; followerSet.add(f.getSid()); &#125; &#125; boolean initTicksShouldBeIncreased = true; for (Proposal.QuorumVerifierAcksetPair qvAckset:newLeaderProposal.qvAcksetPairs) &#123; if (!qvAckset.getQuorumVerifier().containsQuorum(followerSet)) &#123; initTicksShouldBeIncreased = false; break; &#125; &#125; return; &#125; startZkServer(); String initialZxid = System.getProperty(\"zookeeper.testingonly.initialZxid\"); if (initialZxid != null) &#123; long zxid = Long.parseLong(initialZxid); zk.setZxid((zk.getZxid() &amp; 0xffffffff00000000L) | zxid); &#125; if (!System.getProperty(\"zookeeper.leaderServes\", \"yes\").equals(\"no\")) &#123; self.setZooKeeperServer(zk); &#125; self.adminServer.setZooKeeperServer(zk); boolean tickSkip = true; String shutdownMessage = null; while (true) &#123; synchronized (this) &#123; long start = Time.currentElapsedTime(); long cur = start; long end = start + self.tickTime / 2; while (cur &lt; end) &#123; wait(end - cur); cur = Time.currentElapsedTime(); &#125; if (!tickSkip) &#123; self.tick.incrementAndGet(); &#125; SyncedLearnerTracker syncedAckSet = new SyncedLearnerTracker(); syncedAckSet.addQuorumVerifier(self.getQuorumVerifier()); if (self.getLastSeenQuorumVerifier() != null &amp;&amp; self.getLastSeenQuorumVerifier().getVersion() &gt; self.getQuorumVerifier().getVersion()) &#123; syncedAckSet.addQuorumVerifier(self.getLastSeenQuorumVerifier()); &#125; syncedAckSet.addAck(self.getId()); for (LearnerHandler f : getLearners()) &#123; if (f.synced()) &#123; syncedAckSet.addAck(f.getSid()); &#125; &#125; if (!this.isRunning()) &#123; shutdownMessage = \"Unexpected internal error\"; break; &#125; if (!tickSkip &amp;&amp; !syncedAckSet.hasAllQuorums()) &#123; shutdownMessage = \"Not sufficient followers synced, only synced with sids: [ \" + syncedAckSet.ackSetsToString() + \" ]\"; break; &#125; tickSkip = !tickSkip; &#125; for (LearnerHandler f : getLearners()) &#123; f.ping(); // leader跟所有follower定时发送ping请求保持长连接 &#125; &#125; if (shutdownMessage != null) &#123; shutdown(shutdownMessage); &#125; &#125; &#125;&#125;","tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://yaoyinglong.github.io/tags/Zookeeper/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Zookeeper","slug":"Cloud/Zookeeper","permalink":"https://yaoyinglong.github.io/categories/Cloud/Zookeeper/"}]},{"title":"","date":"2021-11-21T16:00:00.000Z","path":"Blog/index/","text":"基本信息姓名：姚应龙（可以叫我小姚或姚工） 性别&amp;年龄：男/1993（身份证1991与实际有出入） 工龄：Java开发，正式工作4年半，大学期间公司实习近一年（中移在线一年，冰鉴三年半仍在职） 技术栈具有扎实的Java基础，研究过Map、AQS、线程池、Condition、BlockingQueue、Lock等源码，熟练掌握反射、泛型、注解等基础开发技术 深入理解JVM、JMM、垃圾收集机制、GC算法原理、类加载机制、锁机制等底层原理，熟悉JVM常用参数、JVM参数调优、GC参数、JVM故障分析、JVisualVM、Arthas、以及jmap和jstack等JDK提供的工具命令，有一定的JVM线上调优经验 深入理解MySQL底层数据结构与算法、索引原理、索引使用以及索引优化、事务隔离级别与锁机制、MVCC机制，对MySQL的集群架构和高可用方案有一定的了解，如读写分离、集群扩容、半同步复制机制，了解ShardingSphere底层原理 深入理解Spring设计原理以及底层架构，研究过IoC容器的启动过程、Bean加载过程，AOP切面解析与代理创建、事务调用、事件监听等核心源码，循环依赖Bean加载原理 深入理解SpringBoot设计原理以及底层架构，研究过SpringBoot JAR包启动、自动装配、启动过程、资源加载等源码 深入理解Redis线程模型，熟练掌握Redis核心数据结构及使用场景、集群架构、性能优化，熟悉多级缓存架构、过期策略，熟悉各种缓存高并发使用场景，如缓存失效、缓存穿透、缓存雪崩、热KEY重建优化、链接池预热、缓存与数据库双写不一致。 熟悉常见消息中间件Kafka、RabbitMQ、RocketMQ使用，深入研究过RocketMQ消息存储、生产者、消费者、事务消息、延迟消息、死信队列等源码，掌握各种消息通信场景疑难问题解决方案，如消息丢失、重复消费、消息顺序性、大规模消息积压问题 深入理解BIO、NIO、AIO等IO通信模型，深入研究过Netty底层基于NIO多路复用封装源码，熟悉Netty线程模型、直接内存、零拷贝机制、ByteBuf扩容机制，对Netty高并发新能架构设计有一定的理解 深入理解Mybatis设计原理以及底层架构，研究过Mybatis配置文件解析、SQL执行、缓存机制以及如何集成到Spring等源码 深入理解Nacos设计原理以及底层架构，研究过Nacos服务注册中心AP模式和CP模式、配置中心、集群成员信息同步等源码 深入理解Zookeeper设计原理以及底层架构，研究过Zookeeper集群Leader选举、ZAB原子广播协议、事件监听机制源码 深入理解Dubbo设计原理以及底层架构，研究过Dubbo服务导入、导出、SPI机制、服务调用、与Spring集成等源码 深入理解Seata设计原理以及底层架构，研究过Seata AT模式分布式事务、与Spring事务集成等源码 深入理解Sentinel设计原理以及底层架构，研究过Sentinel限流熔断降级、规则发布、配置持久化等源码 深入理解Tomcat设计原理以及底层整体架构，研究过Tomcat启动、请求处理、响应处理等源码 深入理解Maven生命周期，熟练掌握Maven的使用、常用插件、个性化打包、依赖冲突解决、聚合与继承等 熟悉ElasticSearch架构原理、文档写入原理、检索原理、DSL高级查询、分值计算原理、聚合搜索等 熟悉基础的数据结构与算法，熟悉基本的排序算法及原理，熟悉树、图和常见查找算法原理 熟悉JMeter、LoadRunner等压测工具，熟悉XML，在实际的项目中使用过自定义XSD，来完成特定功能 熟悉IT 和UT测试及Mockito测试框架，有写测试用例的习惯，熟练HTML、JSP、JQuery、JavaScript、CSS等前端技术 熟悉Python能够独立完成简单爬虫以及一些常用的工具，毕业设计《舆情分析》使用Python做的爬虫爬取网易新闻，熟悉py4j框架 熟悉MongoDB、HDFS、Livy、Spark 熟悉JIRA的使用，熟悉SonarQube，为公司搭建SonarQube并应用到实际的项目中。 能熟练使用Intellij开发工具，熟悉掌握其使用技巧和绝大部分快捷键，常用快捷键和插件都有总结成博客。 熟悉基本的Linux操作命令，现在工作中使用Linux也比较频繁，比较多的用于查日志和监控。 熟悉微信公众平台的开发、熟悉了解Docker。 熟悉Go语言的基本语法，使用Go在LeetCode上刷过一些题。 教育背景学历：本科/西华大学/信息工程 时间：2013.09—2017.06 主修：计算机应用基础A、信息论与编码、通信原理、无线通信原理与移动网络、数字通信等。 由于读了一年高四，从二专到二本，艰辛的一年使我成长了很多学到了很多感悟了很多。大学第一年自然而然的当起了学霸，大一上学期后半段，有个很厉害的老师叫卿朝进，上了我们专业的一门叫信息工程概论的课，一节课下来大家新潮澎湃，并且想在我们这批人中找一些人组建实验室。一下在我找到了我的方向，我第一个去找了他，但是由于内向腼腆，说话声音发抖脸红冒汗，最终他没有看上我。最后我连续给他发了几次邮件，最终他收留了我。 大学四年基本是在实验室度过，第一个寒假开始在实验室学习数模电，大一下学期开始做一个小玩意简单的红外感应设备，花了整整一个学期整电路画PCB调试等，暑假老师接了一个四川省农业厅畜禽遗传资源动态监测平台的项目，什么都不懂开始硬上，整整一个暑假的煎熬一点一点的百度，才把整个项目的运行起来，最终把项目完成了，记忆尤新，从此打开了新世界的大门。 大二由于老师的资源，有幸参与了解联通报表的开发，开始接触Oracle，暑假到成都东叶舟科技有限公司实习。 大三由于同学的资源，自己接了两个小的系统开发，中途也参与了老师的一些项目。大三的暑假由于Nokia的公开日，有幸参观且进行模拟面试，最终有幸到Nokia实习了半年，这半年收获巨大，由衷感谢。 大四上半学期在Nokia实习，下半学期基本在找工作，中途有两家比较满意的公司HR给了口头offer，但最终都由于业务变动未能入职，对于一心想留在成都的我最终却没能留下来有点小失落，我知道不如意才使人成长，就当是一次锻炼，便坚定信念出发了。 实习经历大学期间总共参加过两次实习。分别是在Nokia成都六个月和东叶舟科技有限公司两个月。 第一次是大二的暑假2015.07—2015.09为期两个月在成都东叶舟科技有限公司，主要参与了渝富金融微信平台、笑山羊商店系统、新华网微信小游戏三个系统的开发，第一个项目是做后端开发，后两个是做前端开发，也是这次终于前端后端打通了。通过这次实习最大的收获是思维方式从一个学校学生到公司员工的转变，极大的增强了适应能力，当然技术上的收获也很大，后端技术加强了，新学会了前端开发。 第二次实习是大三的暑假2016.07到大四上学期结束2017.01为期六个月在Nokia成都，由于当时Nokia并不招收正式员工，以及找工作的原因并没有续实习。在Nokia就参与了一个内部项目Communication Matrix，刚开始花了一两天学了下Thymeleaf，然后做了大概一个月前端，然后开始做后端开发。这个项目简单的说是一个通用的Excel数据管理系统，当时主要是针对Nokia各个地区用到的网元配置的Excel文件。用的Spring全家桶（Spring Boot、Spring Security、Thymeleaf），这次实习可以说使我得到了一此质的提升，对框架的使用和理解有了巨大提升，最重要一点是Leader的技术很强，从他那学到了很多编程思想上的东西，即使是现在很多时候很多东西我还是在参照学习这个项目。这次实习让我不再畏惧英文文档，掌握了单元测试的思想能够灵活运用IT和UT，在RedHat上做MySQL的增量备份脚本，对Linux和MySQL有了更深入的认识。 工作经历到目前为止呆过两家公司，中移动在线服务有限公司和上海冰鉴信息科技有限公司。 中移动在线服务有限公司是国企中国移动旗下的一个专职子公司工作地点河南郑州，对于一个只想留在成都热衷技术的我，并不是我理想的地方，虽然项目经验相对于应届毕业生来说丰富，技术等各方面能力自认为不差，由于实习错过了很多好机会，以及两次本命年的玩笑，最终去了中移的实名制团队，该部门主要是做实名认证相关的业务，以及一些对外拓展业务。 一开始是进入的智能门禁组，为了熟悉和了解整个公司的技术、业务和环境，安排去维护实名认证企业平台，主要技术是SSM和Dubbo，主要的工作内容是BUG修复和一些功能的优化升级，技术含量不高。之后就是智能门禁项目的开发，主要技术还是SSM和Dubbo，刚开始熟悉项目Leader叫我对人脸识别接口进行压测，学会了JMeter的使用，之后就是一些常规开发。 由于人员调整，被调到集中交付中心小组（中途又有一次人员调整门禁组长想把我要回去，虽然没成功虽然我也想回门禁组)，主要是帮助省公司做线上售卡业务，以及认证激活，第一个功能就是挖异营销模块，相当于集中交付的主业务的一个缩影，就我一个人独立来完成设计和开发，由于需要用到身份证正反验证和视频认证激活，已有的流程中耦合了很多各式各样的业务逻辑，所以不能直接用而且没有注释全是一团乱麻，又将原来的身份证验证和视频认证的代码全部梳理出来了一套可读性较高逻辑简单重复代码少的新流程出来，因此我变成了整个小组最熟悉视频认证流程的两个人之一，像之后的集团购卡认证和新疆视频认证改造的这类比较大型复杂的需求都分到了我这。 在中移动体会到了大厂的系统环境的复杂性，以及各种权限把控的严格性，以及各种上线流程的复杂性。对git的使用以及分支的管理有比较深刻的理解，对Oracle的使用和体会更加深入，以及学会了JIRA的基础使用，学会了工作总结，我的工作技术总结，听说当时走的时候留给他们的总结组长还时长说起，还是比较自豪的。 之所以离开去冰鉴，并不是因为待遇问题，说实话冰鉴给的待遇和中移差不多，甚至严格的讲要差那么一丢丢，离开主要是因为中移是国企对于一个想走技术流的人来说并不理想，大家应该都懂；其二用的技术比较老，仅仅业务的复杂性很高，成长速度达不到我的预期；其三冰鉴是创业公司会很锻炼人，能够使我快熟成长；其四是我的一个师兄在冰鉴。 上海冰鉴信息科技有限公司我是18年4月中旬入职的成都分公司，周五离职中移从郑州回成都用了一天时间租房周一入职冰鉴虽略显匆忙，不管怎么说是我理想的工作地点。进公司做的是企业征信，用的Spring Cloud微服务架构，项目是使用SpringBoot、Mybatis、Redis、Kafka以及Docker等比较新的技术，是我比较理想的技术架构。中途由于系统出了些小故障，排查问题以及解决问题的过程中，通过JMeter对SpringMvc异步实现进行压测通过VisualVm工具对Tomcat参数调整监测，对Tomcat的工作原理有了一些理解和认识，以及对SpringMvc异步处理原理和实现以及异步线程池有了比较深入的理解，对压测工具JMeter使用更加熟练。之后又对分布式锁、Hystrix限流熔断降级做了一段时间的LoadRunner压测通过VisualVm工具观察，对VisualVm工具使用更加熟练，并学会了LoadRunner的使用。对JIRA的使用和理解更加深刻，对微服务架构的理解更加深入，对IT和UT的理解更加深入。而且对于这些内容我都一一做了总结并添加到了我的博客中。 中途人员调整，我被调到了数据平台，由于我个人比较严谨做事细致负责，之前合作时我的IT和UT写的比较好，工作效率比较高bug率比较低，以及个人之前系统之前出了几次故障，个人征信的组长把我要到了个人小组。到个人组主要做个人系统的重构开发，主要用到的还是Spring Cloud那一套，引入了Apollo、Spring Cloud Sleuth等一些技术，一开始主要负责模型服务的开发，借鉴PMML的思想来实现一套通过XML配置来描述模型的算法，模型服务通过解析XML来实现相关的算法。搭建SonarQube并应用到项目中。 模型服务成熟后到个人业务服务的开发，由于业务的发展开发了个人决策服务，用于个人业务需求的配置，就不用像个人服务那样用代买来实现，通过配置直接实现业务，还支持groovy脚本配置。以及外部部署的产品服务，通过Maven的assembly插件将固定的产品类和配置文件等打包成一个项目部署到外部。 目前主要做的是数据测试平台，一个批量服务，用于跑批量任务，以及做一些数据分析的配置以及出一些分析报告，支持配置Python脚本执行，数据清洗，链接，统计描述等功能，还新增了定制化的Zeppelin服务分析功能，理解Zeppelin源码并搭建我们自己的分析工具。 个人简介本科信息工程，自学Java，在校期间参与过比较多的实际项目，自己单独接过外包项目，积极主动，大一暑假开始做实际的项目，大二暑假就在成都东页舟科技有限公司实习参加实习，大三结束到诺基亚西门子通信技术有限公司实习了半年，处理和解决实际问题的能力比较强，善于挑战，毕业设计自拟了一个大数据相关的题目，使用Python做新闻爬虫，MongoDB做数据库，Spark做新闻舆情情感分析，Redis做消息队列，这些技术在做之前都没有接触过。 自学能力强，目前用到的技术都是通过自学的；善于学习；自律性比较强，会给自己指定一些学习计划；适应环境的能力强，能够很快的融入一个新环境，善于自我调节；善于总结工作效率高，工作中的一些问题及技术都进行总结，以便提高工作效率，有自己的博客 https://yaoyinglong.github.io 工作积极主动认真负责，考虑问题比较全面；做事严谨；有良好的编程风格，良好的团队协作能力；目前偶尔也会去LeetCode上刷一刷算法题。","tags":[],"categories":[]},{"title":"Zookeeper基础","date":"2021-11-18T16:00:00.000Z","path":"Blog/Cloud/Zookeeper/Zookeeper基础/","text":"Zookeeper是一个分布式协调框架，是Apache Hadoop的一个子项目，主要用来解决分布式应用中经常遇到的一些数据管理问题，如统一命名服务、状态同步服务、集群管理、分布式应用配置项管理等。可理解为是一个用于存储少量数据的基于内存的数据库，其核心为文件系统数据结构+监听通知机制。 Zookeeper经典应用场景有：分布式注册中心，分布式配置中心，分布式锁，分布式队列，集群选举，分布式屏障，发布订阅； 文件系统数据结构 每个子目录都被称为znode目录节点，和文件系统类似，可自由增加、删除znode，以及在一个znode下增加、删除子znode。 PERSISTENT持久化目录节点：客户端与zookeeper断开连接后，该节点依旧存在，只要不手动删除该节点，他将永远存在； PERSISTENT_SEQUENTIAL持久化顺序编号目录节点：客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号，即在持久化节点的基础上带顺序； EPHEMERAL临时目录节点：客户端与zookeeper断开连接后，该节点被删除； EPHEMERAL_SEQUENTIAL临时顺序编号目录节点：客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号；即在临时节点的基础上带顺序； Container容器节点：3.5.3版本新增，若Container节点下面没有子节点，则Container节点在未来会被Zookeeper自动清除，定时任务默认60s检查一次； TTL节点：默认禁用，只能通过系统配置zookeeper.extendedTypesEnabled=true开启，不稳定；超过了TTL指定时间后会被自动清除； 监听机制客户端注册监听它关心的任意节点，或者目录节点及递归子目录节点，若注册的是对某个节点的监听，则当该节点被删除，或者被修改时，对应的客户端将被通知；若注册的是对某个目录的监听，则当该目录有子节点被创建，或者有子节点被删除，对应的客户端将被通知；若注册的是对某个目录的递归子节点进行监听，则当该目录下面的任意子节点有目录结构的变化即有子节点被创建或被删除或者根节点有数据变化时，对应的客户端将被通知。 所有的通知都是一次性的，及无论是对节点还是对目录进行的监听，一旦触发对应监听即被移除。递归子节点，监听是对所有子节点的，每个子节点下面的事件同样只会被触发一次。 Zookeeper安装123456789wget https://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.5.8/apache-zookeeper-3.5.8-bin.tar.gztar -zxvf apache-zookeeper-3.5.8-bin.tar.gzcd apache-zookeeper-3.5.8-bin# 重命名配置文件zoo_sample.cfgcp zoo_sample.cfg zoo.cfg# 启动Zookeeper，可通过bin/zkServer.sh来查看都支持哪些参数 bin/zkServer.sh start conf/zoo.cfg# Zookeeper客户端连接服务端bin/zkCli.sh -server ip:port Zookeeper命令可通过help查看Zookeeper所支持的所有命令 12345678910111213141516171819202122232425addauth scheme authclose config [-c] [-w] [-s]connect host:portcreate [-s] [-e] [-c] [-t ttl] path [data] [acl]delete [-v version] pathdeleteall pathdelquota [-n|-b] pathget [-s] [-w] pathgetAcl [-s] pathhistory listquota pathls [-s] [-w] [-R] pathls2 path [watch]printwatches on|offquit reconfig [-s] [-v version] [[-file path] | [-members serverID=host:port1:port2;port3[,...]*]] | [-add serverId=host:port1:port2;port3[,...]]* [-remove serverId[,...]*]redo cmdnoremovewatches path [-c|-d|-a] [-l]rmr pathset [-s] [-v version] path datasetAcl [-s] [-v version] [-R] path aclsetquota -n|-b val pathstat [-w] pathsync path 创建Zookeeper节点 1create [-s] [-e] [-c] [-t ttl] path [data] [acl] 中括号为可选项，没有则默认创建持久化节点，-s顺序节点，-e临时节点，-c容器节点，-t可给节点添加过期时间，默认禁用，需要通过系统参数启用-Dzookeeper.extendedTypesEnabled=true； 1234567891011121314# 创建持久化节点并设置数据为some-datacreate /test-node some-data# 获取节点数据get /test-node# 更新节点数据set /test-node some-data-change# 创建临时节点并设置数据为data，临时节点不能创建子节点create -e /ephemeral data# 创建临时顺序节点，顺序节点将再seq-parent目录下顺序递增：/seq-parent/0000000000create -s -e /seq-parent/ data# 给顺序节点添加前缀：/seq-parent/profix-0000000001create -s -e /seq-parent/profix-# 创建容器节点，若未给其创建子节点，容器节点表现和持久化节点一样，若给容器节点创建了子节点，后续又把子节点清空，容器节点也会被zookeeper删除create -c /container 查看节点状态信息 123456789101112131415# 查看节点状态信息stat /test-nodecZxid = 0xfctime = Mon Nov 22 10:32:02 CST 2021mZxid = 0x10mtime = Mon Nov 22 10:32:36 CST 2021pZxid = 0xfcversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 16numChildren = 0# 获取数据的同时查看节点状态信息get -s /test-node cZxid：创建znode的事务ID，即Zxid值 mZxid：最后修改znode的事务ID pZxid：最后添加或删除子节点的事务ID，子节点列表发生变化才会发生改变 ctime：znode创建时间 mtime：znode最近修改时间 dataVersion：znode的当前数据版本，可根据该版本号对有并发修改数据实现乐观锁的功能 cversion：znode子节点结果集版本，一个节点的子节点增加、删除都会影响这个版本 aclVersion：表示对此znode的acl版本。 ephemeralOwner：znode是临时znode时，表示znode所有者的sessionID。 若znode不是临时znode，则该字段设置为零。 dataLength：znode数据字段的长度。 numChildren：znode的子znode的数量。 12345# 乐观锁的实现，用set命令修改数据的时候可以把版本号带上set -v 1 /test-node change# 数据修改版本号会递增，再用以前的版本号去修改，将会导致修改失败set -v 1 /test-node changeversion No is not valid : /test-node 创建子节点，zookeeper是以节点组织数据的，没有相对路径这么一说 1234# 创建子节点，create /test-node/test-sub-node# 递归查看递归子节点列表ls -R / 事件监听机制，一旦事件触发，对应的注册立刻被移除，所以事件监听是一次性的 12345678# 注册监听的同时获取数据get -w /test-node# 对节点进行监听，且获取元数据信息stat -w /test-node# 目录的变化，会触发事件，且一旦触发，对应的监听也会被移除，后续对节点的创建没有触发监听事件ls -w /test-node# 递归监听子目录ls -R -w /test-node Zookeeper事件类型：None连接建立事件，NodeCreated节点创建，NodeDeleted节点删除，NodeDataChanged节点数据变化，NodeChildrenChanged子节点列表变化，DataWatchRemoved节点监听被移除，ChildWatchRemoved子节点监听被移除； ACL权限控制Zookeeper的ACL权限控制，可控制节点读写操作，保证数据安全性，Zookeeper ACL权限设置分为Scheme权限模式、ID授权对象、Permission权限信息3部分组成。最终组成一条如scheme:id:permission格式的ACL请求信息。 Scheme权限模式：用来设置ZooKeeper服务器进行权限验证的方式。ZooKeeper 的权限验证方式大体分为两种类型： 范围验证，ZooKeeper可针对一个IP或者一段IP地址授予某种权限。如可让一个IP地址为ip：192.168.0.110的机器对服务器上的某个数据节点具有写入的权限。或者也可以通过ip:192.168.0.1/24给一段IP地址的机器赋权。 口令验证，也可理解为用户名密码的方式。在ZooKeeper中这种验证方式是Digest认证，而Digest认证方式首先在客户端传送username:password这种形式的权限表示符后，ZooKeeper服务端会对密码部分使用SHA-1和BASE64算法进行加密以保证安全性。 Super权限模式, Super可认为是一种特殊的Digest认证。具有Super权限的客户端可对ZooKeeper上的任意数据节点进行任意操作。 ID授权对象：授权对象就是要把权限赋予谁，对应于4种不同的权限模式来说，若选择IP方式，使用的授权对象可以是一个IP地址或IP地址段；若使用Digest或Super方式，则对应于一个用户名。若是World模式，则是授权系统中所有用户。 Permission权限信息：指可在数据节点上执行的操作种类，ZooKeeper中已经定义好的权限有5种： 数据节点c:create创建权限，授予权限的对象可在数据节点下创建子节点； 数据节点w:wirte更新权限，授予权限的对象可更新该数据节点； 数据节点r:read读取权限，授予权限的对象可读取该节点内容以及子节点列表信息； 数据节点d:delete删除权限，授予权限的对象可删除该数据节点的子节点； 数据节点a:admin管理者权限，授予权限的对象可对该数据节点体进行ACL权限设置。 可通过系统参数zookeeper.skipACL=yes进行配置，默认是no，可配置为true,，则配置过的ACL将不再进行权限检测，可通过如下命令对权限信息进行操作： getAcl：获取某个节点的acl权限信息 setAcl：设置某个节点的acl权限信息 addauth：输入认证授权信息，相当于注册用户信息，注册时输入明文密码，zk将以密文的形式存储 123456789101112131415161718# 获取某个节点的具体权限信息getAcl /test-node# 获取某个节点的具体权限信息同时获取节点状态信息getAcl -s /test-node# 创建时设置ACL权限create /zk-node datatest digest:gj:X/NSthOB0fD/OT6iilJ55WJVado=:cdrwa# setAcl设置ACL权限setAcl /zk-node digest:gj:X/NSthOB0fD/OT6iilJ55WJVado=:cdrwa# 访问前需要添加授权信息addauth digest gj:test# auth明文授权，使用之前需要先通过addauth注册用户信息，后续可以直接用明文授权addauth digest u100:p100create /node-1 node1data auth:u100:p100:cdwra# IP授权模式，多个指定IP可以通过逗号分隔，如setAcl /node-ip ip:IP1:rw,ip:IP2:asetAcl /node-ip ip:192.168.109.128:cdwracreate /node-ip data ip:192.168.109.128:cdwra# Super超级管理员模式，启动时通过JVM系统参数开启-Dzookeeper.DigestAuthenticationProvider.superDigest=super:&lt;base64encoded(SHA1(password))&gt; 可通过如下方式生成授权ID 123456// echo -n &lt;user&gt;:&lt;password&gt; | openssl dgst -binary -sha1 | openssl base64@Testpublic void generateSuperDigest() throws NoSuchAlgorithmException &#123; String sId = DigestAuthenticationProvider.generateDigest(\"gj:test\"); System.out.println(sId);// gj:X/NSthOB0fD/OT6iilJ55WJVado=&#125; 持久化Zookeeper数据的组织形式为一个类似文件系统的数据结构，而这些数据都是存储在内存中的，针对每一次客户端的事务操作，Zookeeper都会将其记录到事务日志中。可在zookeeper的主配置文件zoo.cfg中配置内存中的数据持久化目录，也就是事务日志存储路径dataLogDir，若未配置dataLogDir，事务日志将存储到dataDir目录， zookeeper提供了格式化工具可以进行数据查看事务日志数据org.apache.zookeeper.server.LogFormatter 1java -classpath .:slf4j-api-1.7.25.jar:zookeeper-3.5.8.jar:zookeeper-jute-3.5.8.jar org.apache.zookeeper.server.LogFormatter /usr/local/zookeeper/apache-zookeeper-3.5.8-bin/data/version-2/log.1 Zookeeper进行事务日志文件操作时会频繁进行磁盘IO操作，事务日志不断追加写操作会触发底层磁盘IO为文件开辟新的磁盘块，为了提升磁盘IO的效率，Zookeeper在创建事务日志文件时进行了文件空间预分配，即在创建文件时，就向操作系统申请一块大一点的磁盘块。该预分配的磁盘大小可以通过系统参数zookeeper.preAllocSize配置。 事务日志文件名为log.&lt;当时最大事务ID&gt;，日志文件是顺序写入的，故该最大事务ID也将是整个事务日志文件中最小的事务ID，日志满了即进行下一次事务日志文件的创建。 数据快照用于记录Zookeeper服务器上某一时刻的全量数据，并将其写入到指定的磁盘文件中。可通过配置snapCount配置间隔事务请求个数，数据存储在dataDir指定的目录中，可通过如下方式进行查看快照数据，为避免集群中所有机器在同一时间进行快照，实际快照生成时机为事务数达到snapCount/2 + 随机数时开始快照，随机数范围为1 ~ snapCount/2。 1java -classpath .:slf4j-api-1.7.25.jar:zookeeper-3.5.8.jar:zookeeper-jute-3.5.8.jar org.apache.zookeeper.server.SnapshotFormatter /usr/local/zookeeper/apache-zookeeper-3.5.8-bin/data-dir/version-2/snapshot.0 快照事务日志文件名为snapshot.&lt;当时最大事务ID&gt;，日志满了即进行下一次事务日志文件的创建，快照数据主要是为了快速恢复，事务日志文件是每次事务请求都会进行追加的操作，快照是达到某种设定条件下的内存全量数据。通常快照数据是反应当时内存数据的状态。事务日志是更全面的数据，所以恢复数据时，可先恢复快照数据，再通过增量恢复事务日志中的数据即可。 Zookeeper集群Zookeeper集群模式有Leader、Follower、Observer三种类型的角色： Leader: 处理所有的事务写请求，可处理读请求，集群中只能有一个Leader Follower：只能处理读请求，同时作为Leader候选节点，即若Leader宕机，Follower节点要参与到新的Leader选举中，有可能成为新的Leader节点 Observer：只能处理读请求。不能参与选举 1234567891011121314151617181920212223242526272829303132333435363738# 重命名zoo_sample.cfg文件cp conf/zoo_sample.cfg conf/zoo-1.cfg# 修改配置文件zoo-1.cfg，原配置文件里有的，修改成下面的值，没有的则加上dataDir=/usr/local/data/zookeeper-1clientPort=2181server.1=127.0.0.1:2001:3001:participant # participant可不用写，默认就是participantserver.2=127.0.0.1:2002:3002:participantserver.3=127.0.0.1:2003:3003:participantserver.4=127.0.0.1:2004:3004:observer# 拷贝zoo1.cfg文件，修改dataDir和clientPortcp conf/zoo1.cfg conf/zoo2.cfgcp conf/zoo1.cfg conf/zoo3.cfgcp conf/zoo1.cfg conf/zoo4.cfgvim conf/zoo2.cfgdataDir=/usr/local/data/zookeeper-2clientPort=2182vim conf/zoo3.cfgdataDir=/usr/local/data/zookeeper-3clientPort=2183vim conf/zoo4.cfgdataDir=/usr/local/data/zookeeper-4clientPort=2184# 创建四个文件夹在每个目录中创建文件myid文件，写入当前实例的server id，即1，2，3，4 cd /usr/local/data/zookeeper-1vim myid1 cd /usr/local/data/zookeeper-2vim myid2 cd /usr/local/data/zookeeper-3vim myid3 cd /usr/local/data/zookeeper-4vim myid4# 客户端连接集群bin/zkCli.sh -server ip1:port1,ip2:port2,ip3:port3 tickTime：用于配置Zookeeper中最小时间单位的长度，很多运行时的时间间隔都是使用tickTime的倍数来表示的。 initLimit：该参数用于配置Leader服务器等待Follower启动，并完成数据同步的时间。Follower服务器在启动过程中，会与Leader建立连接并完成数据的同步，从而确定自己对外提供服务的起始状态。Leader服务器允许Follower在initLimit时间内完成该工作。 syncLimit：Leader与Follower心跳检测的最大延时间 dataDir：Zookeeper保存数据目录，默认Zookeeper将写数据的日志文件也保存在这个目录里。 clientPort：该端口是客户端连接Zookeeper服务器的端口，Zookeeper会监听该端口，接受客户端的访问请求。 server.A=B:C:D:E：其中A是一个数字，表示第几号服务器；B是这个服务器的ip地址；C表示该服务器与集群中的Leader服务器交换信息的端口；D表示集群中的Leader服务器挂了重新进行选举的端口就是用来执行选举时服务器相互通信的端口。若是伪集群的配置方式，由于B都是一样，故不同的Zookeeper实例通信端口号不能一样，所以要给它们分配不同的端口号。若需要通过添加不参与集群选举以及事务请求的过半机制的 Observer节点，可在E的位置，添加observer标识。 分布式锁实现 Zookeeper非公平锁实现在并发比较高的情况下，性能会下降的比较厉害，因为所有连接都在对同一个节点进行监听，当服务器检测到删除事件时，要通知所有的连接，所有的连接同时收到事件，再次并发竞争，这就是羊群效应。 公平锁可以有效的解决羊群效应，借助于临时顺序节点，可以避免同时多个节点的并发竞争锁，缓解了服务端压力，这种实现方式所有加锁请求都进行排队加锁，请求进来直接在/lock节点下创建一个临时顺序节点，然后判断自己是否是lock节点下最小的节点，若是则获得锁，若不是则监听前一个节点。","tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://yaoyinglong.github.io/tags/Zookeeper/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Zookeeper","slug":"Cloud/Zookeeper","permalink":"https://yaoyinglong.github.io/categories/Cloud/Zookeeper/"}]},{"title":"Redis分布式锁实现","date":"2021-11-16T16:00:00.000Z","path":"Blog/Cloud/Redis/Redis分布式锁实现/","text":"分布式锁的各种问题及优化并发情况下以下代码可能导致超买 12345678int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"stock\")); // jedis.get(\"stock\")if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(\"stock\", realStock + \"\"); // jedis.set(key,value) System.out.println(\"扣减成功，剩余库存:\" + realStock);&#125; else &#123; System.out.println(\"扣减失败，库存不足\");&#125; 为了解决该问题可以通过redis加上分布式锁，该方式是解决了并发问题，但是引入了新的问题，若业务代码异常可能导致锁永远得不到释放。 1234567891011121314String lockKey = \"product_101\";Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, \"product_id\");if (!result) &#123; return \"error_code\";&#125;int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"stock\"));if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(\"stock\", realStock + \"\"); System.out.println(\"扣减成功，剩余库存:\" + realStock);&#125; else &#123; System.out.println(\"扣减失败，库存不足\");&#125;stringRedisTemplate.delete(lockKey); 可以通过finally中来释放锁来解决业务代码异常的情况，但若当锁获取成功后机器宕机了，同样锁还是不能得到释放。 1234567891011121314151617String lockKey = \"product_101\";try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, \"product_id\"); if (!result) &#123; return \"error_code\"; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"stock\")); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(\"stock\", realStock + \"\"); System.out.println(\"扣减成功，剩余库存:\" + realStock); &#125; else &#123; System.out.println(\"扣减失败，库存不足\"); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可以通过给锁加上一个过期时间的方式来解决获取锁成功后机器宕机，导致锁不能被释放的情况，但是这种写法还是没有完全解决，因为加锁和设置缓存时间不是原子操作。 123456789101112131415161718String lockKey = \"product_101\";try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, \"product_id\"); stringRedisTemplate.expire(lockKey, 10, TimeUnit.SECONDS); if (!result) &#123; return \"error_code\"; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"stock\")); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(\"stock\", realStock + \"\"); System.out.println(\"扣减成功，剩余库存:\" + realStock); &#125; else &#123; System.out.println(\"扣减失败，库存不足\"); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过在加锁的同时设置超时原子操作来解决该问题，但设置了超时时间若当前业务代码没有被执行完其本身没有释放锁，但由于过期锁被清理掉了，新的线程加锁进来后，之前执行业务代码的线程又去把新的线程的锁释放了，将导致锁完全失效。 1234567891011121314151617String lockKey = \"product_101\";try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, \"product_id\", 30, TimeUnit.SECONDS); if (!result) &#123; return \"error_code\"; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"stock\")); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(\"stock\", realStock + \"\"); System.out.println(\"扣减成功，剩余库存:\" + realStock); &#125; else &#123; System.out.println(\"扣减失败，库存不足\"); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过给锁设置唯一标识的方式来解决其他线程释放非自身设置的锁，所有线程只能释放本线程设置的锁。 1234567891011121314151617181920String lockKey = \"product_101\";String clientId = UUID.randomUUID().toString();try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, \"product_id\", 30, TimeUnit.SECONDS); if (!result) &#123; return \"error_code\"; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"stock\")); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(\"stock\", realStock + \"\"); System.out.println(\"扣减成功，剩余库存:\" + realStock); &#125; else &#123; System.out.println(\"扣减失败，库存不足\"); &#125;&#125; finally &#123; if (clientId.equals(stringRedisTemplate.opsForValue().get(lockKey))) &#123; stringRedisTemplate.delete(lockKey); &#125;&#125; 索然上面的锁已经很完善了，但还是有锁因为超时时间导致的极小概率的并发问题，该问题可以通过给锁续命即判断业务代码是否执行完成，若未完成则重置超时时间的方式来解决该问题。Redisson就是这样做的。 1234567891011121314151617String lockKey = \"product_101\";String clientId = UUID.randomUUID().toString();RLock redissonLock = redisson.getLock(lockKey);try &#123; //加锁 redissonLock.lock(); //setIfAbsent(lockKey, clientId, 30, TimeUnit.SECONDS); int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"stock\")); // jedis.get(\"stock\") if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(\"stock\", realStock + \"\"); // jedis.set(key,value) System.out.println(\"扣减成功，剩余库存:\" + realStock); &#125; else &#123; System.out.println(\"扣减失败，库存不足\"); &#125;&#125; finally &#123; redissonLock.unlock();&#125; 红锁RedLock是一种利用多Master对共享资源做互斥访问，基于N个完全独立的Redis节点，运行Redlock算法通过在客户端依次执行下面的步骤来完成获取锁的操作： 获取当前时间，毫秒数 按顺序依次向N个Redis节点执行获取锁操作，该获取操作跟前面基于单Redis节点获取锁过程相同，为了保证在某个Redis节点不可用的时候算法能够继续运行，该获取锁操作还有一个超时时间，几十毫秒量级，它要远小于锁的有效时间。客户端在向某个Redis节点获取锁失败后，应该立即尝试下一个Redis节点，这里的失败应该包含任何类型的失败，如该Redis节点不可用、该Redis节点上的锁已经被其它客户端持有 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。若客户端从大多数Redis节点即&gt;= N/2+1成功获取到了锁，且获取锁总耗时没有超过锁的有效时间，则此时客户端才认为最终获取锁成功；否则认为最终获取锁失败 若最终获取锁成功，则该锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间 若最终获取锁失败了，可能由于获取到锁的Redis节点个数少于N/2+1，或整个获取锁的过程耗时超过了锁的最初有效时间，则客户端应该立即向所有Redis节点发起释放锁操作 释放锁的过程比较简单：客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁时成功与否。在最后释放锁时，客户端应该向所有Redis节点发起释放锁的操作，即使当时向某个节点获取锁没有成功，在释放锁时也不应该漏掉该节点。因为若客户端发给某个Redis节点获取锁的请求成功到达了该Redis节点，该节点也成功执行了SET操作，但返回给客户端的响应包却丢失。在客户端看来，获取锁的请求由于超时而失败了，但在Redis这边看来，加锁已经成功了。因此释放锁时，客户端也应该对当时获取锁失败的那些Redis节点同样发起请求。 但由于N个Redis节点中的大多数能正常工作就能保证Redlock正常工作，因此理论上它的可用性更高。单Redis节点的分布式锁在failover的时锁失效的问题，在Redlock中不存在了，但若有节点发生崩溃重启，还是会对锁的安全性有影响，具体的影响程度跟Redis对数据的持久化程度有关。 假设一共有5个Redis节点A、B、C、D、E，若客户端1成功锁住了A、B、C，获取锁成功， 但D和E没有锁住，节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了，节点C重启后，客户端2锁住了C、D、E， 获取锁成功，针对同一资源客户端1和客户端2同时获得了锁。 Redis的AOF持久化方式默认是每秒写一次磁盘，最坏情况下可能丢失1秒的数据，为了尽可能不丢数据，Redis允许设置成每次修改数据都进行fsync，但这会降低性能。当然，即使执行了fsync也仍然有可能丢失数据，这取决于系统而不是Redis的实现。故上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。为了应对这一问题，可通过延迟重启，即一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，该时间应该大于锁的有效时间，该节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。 Redisson锁原理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class Redisson implements RedissonClient &#123; public RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name); &#125;&#125;public class RedissonLock extends RedissonExpirable implements RLock &#123; public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); this.commandExecutor = commandExecutor; this.id = commandExecutor.getConnectionManager().getId(); this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(); &#125; public void lock(long leaseTime, TimeUnit unit) &#123; try &#123; lockInterruptibly(leaseTime, unit); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123; long threadId = Thread.currentThread().getId(); // 获取当前线程的ID Long ttl = tryAcquire(leaseTime, unit, threadId); // 尝试获取锁，并返回锁剩余持有时间 if (ttl == null) &#123; // 若锁剩余持有时间为null，表示获取锁成功 return; // 获取锁成功 &#125; RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; ttl = tryAcquire(leaseTime, unit, threadId); if (ttl == null) &#123; break; &#125; if (ttl &gt;= 0) &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; else &#123; getEntry(threadId).getLatch().acquire(); &#125; &#125; &#125; finally &#123; unsubscribe(future, threadId); &#125; &#125; private Long tryAcquire(long leaseTime, TimeUnit unit, long threadId) &#123; return get(tryAcquireAsync(leaseTime, unit, threadId)); &#125; private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123; if (leaseTime != -1) &#123; // 设置了超时时间的逻辑 return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; // 未设置超时时间默认设置超时时间为30s RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123; @Override public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; return; &#125; Long ttlRemaining = future.getNow(); if (ttlRemaining == null) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); return ttlRemainingFuture; &#125; &lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); // 异步执行lua命令获取锁，若获取锁成功返回null，否则返回剩余持有时间 return commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, command, \"if (redis.call('exists', KEYS[1]) == 0) then \" + // 判断锁是否存在 \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + // 将锁的的状态设置为1 \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + // 给锁加上失效时间 \"return nil; \" + \"end; \" + \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + // 重入锁的处理，锁存在，且加锁对象是当前线程 \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + // 将锁加一 \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + // 重置失效时间 \"return nil; \" + \"end; \" + \"return redis.call('pttl', KEYS[1]);\", // 返回锁剩余的失效时间 Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &#125; private void scheduleExpirationRenewal(final long threadId) &#123; if (expirationRenewalMap.containsKey(getEntryName())) &#123; return; &#125; // 每10s执行一次 Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; RFuture&lt;Boolean&gt; future = commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + // 若KEY存在则返回true，否则返回false \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + // 重置超时时间 \"return 1; \" + \"end; \" + \"return 0;\", Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); future.addListener(new FutureListener&lt;Boolean&gt;() &#123; @Override public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123; expirationRenewalMap.remove(getEntryName()); if (!future.isSuccess()) &#123; return; &#125; if (future.getNow()) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); &#125; &#125;, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); if (expirationRenewalMap.putIfAbsent(getEntryName(), task) != null) &#123; task.cancel(); &#125; &#125;&#125; LUA脚本Redis在2.6推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行： 减少网络开销：本来5次网络请求的操作，可用一个请求完成，原先5次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延。这点跟管道类似。 原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。管道不是原子的，不过redis的批量操作命令是原子。 替代redis的事务功能：redis自带的事务功能很鸡肋，而redis的lua脚本几乎实现了常规的事务功能，官方推荐如果要使用redis的事务功能可以用redis lua替代。 可以使用EVAL命令对Lua脚本进行求值。EVAL命令的格式如下： 1EVAL script numkeys key [key ...] arg [arg ...] script参数是一段Lua脚本程序，它会被运行在Redis服务器上下文中，numkeys参数用于指定键名参数的个数。键名参数key [key ...]从EVAL的第三个参数开始算起，表示在脚本中所用到的那些Redis键(key)，这些键名参数可在Lua中通过全局变量KEYS数组，用1为基址的形式访问KEYS[1]，KEYS[2] 以此类推。 在命令的最后不是键名参数的附加参数arg [arg ...]，可在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似(ARGV[1]、ARGV[2]，在Lua脚本中，可使用redis.call()函数来执行Redis命令： 1234567891011jedis.set(\"product_stock_10016\", \"15\"); //初始化商品10016的库存String script = \" local count = redis.call('get', KEYS[1]) \" + \" local a = tonumber(count) \" + \" local b = tonumber(ARGV[1]) \" + \" if a &gt;= b then \" + \" redis.call('set', KEYS[1], a-b) \" + \" return 1 \" + \" end \" + \" return 0 \";Object obj = jedis.eval(script, Arrays.asList(\"product_stock_10016\"), Arrays.asList(\"10\"));System.out.println(obj); 不要在Lua脚本中出现死循环和耗时的运算，否则redis会阻塞，将不接受其他的命令，所以使用时要注意不能出现死循环、耗时的运算。redis是单进程、单线程执行脚本。管道不会阻塞redis。","tags":[{"name":"分布式锁","slug":"分布式锁","permalink":"https://yaoyinglong.github.io/tags/分布式锁/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"https://yaoyinglong.github.io/categories/Cloud/Redis/"}]},{"title":"Redis缓存及性能优化","date":"2021-11-15T16:00:00.000Z","path":"Blog/Cloud/Redis/Redis缓存及性能优化/","text":"配置文件调优123456789101112131415161718192021222324252627282930313233343536373839# 列表对象listlist-max-ziplist-size -2 # 单个ziplist节点最大能存储8kb，超过则进行分裂将数据存储在新的ziplistlist-compress-depth 1 # 0表示所有节点都不压缩，1表示头结点和尾节点不压缩其他节点压缩# 哈希对象hashhash-max-ziplist-entries 512 # 元素个数超过512，将改为HashTable编码hash-max-ziplist-value 64 # 单个元素大小超过64byte，将改为HashTable编码# 集合对象setset-max-intset-entries 512 # 存储元素超过512时，使用HashTable编码# 有序集合对象zsetzset-max-ziplist-entries 128 # 元素个数超过128，将用skiplist编码zset-max-ziplist-value 64 # 单个元素大小超过64byte，将用skiplist编码# 持久化相关的save 60 1000 # 关闭RDB只需要将所有的save保存策略注释掉即可appendonly yes # 打开AOF功能appendfsync always # 每次有新命令追加到AOF文件时就执行一次fsync，非常慢也非常安全appendfsync everysec # 每秒fsync一次，足够快且在故障时只会丢失1秒钟的数据appendfsync no # 从不fsync，将数据交给操作系统来处理。更快，也更不安全的选择auto-aof-rewrite-min-size 64mb # aof文件至少达到64M才会自动重写，文件太小恢复速度本来就很快，重写意义不大auto-aof-rewrite-percentage 100 # aof文件自上一次重写后文件大小增长了100%则再次触发重写aof-use-rdb-preamble yes # 开启混合持久化，注意必须先开启aof# 集群相关的min-replicas-to-write 1 # 写数据成功最少同步的slave数量maxclients 10000 # redis支持的最大连接数maxmemory 0 # 最大可使用内存值byte，默认0不限制# volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰# volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除# volatile-random：从已设置过期时间的key中，随机选择key淘汰# allkeys-lru：从所有key中选择最近最少使用的进行淘汰# allkeys-random：从所有key中随机选择key进行淘汰# noeviction：当内存达到阈值的时候，新写入操作报错# volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据# allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据maxmemory_policy noeviction # 当达到maxmemory时的淘汰策略 缓存穿透缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 若从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。 缓存空对象空对象缓存过期时间设置的短一点，最长不超过5分钟 1234567891011121314151617String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 若存储数据为空，需要设置一个过期时间(300秒) if (storageValue == null) &#123; cache.expire(key, 60 * 5); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 布隆过滤器对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，可用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。布隆过滤器判定某个值存在时，该值可能不存在；当判定不存在时，则肯定不存在。 布隆过滤器就是一个大型位数组和几个不一样的无偏hash函数。所谓无偏就是能把元素hash值算得比较均匀。向布隆过滤器中添加key时，会使用多个hash函数对key进行hash算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个hash函数都会算得一个不同的位置。再把位数组的这几个位置都置为1就完成了add操作。 向布隆过滤器询问key是否存在时，跟add一样也会把hash的几个位置都算出来，判断位数组中这几个位置是否都为1，只要有一个位为0，则说明布隆过滤器中该key不存在。若都是1并不能说明该key就一定存在，只是极有可能存在，因为这些位被置为1可能是因为其它的key存在所致。若该位数组比较稀疏则存在概率就越大，若该位数组比较拥挤则存在概率就越低。 布隆过滤器适用于数据命中不高、 数据相对固定、 实时性低通常是数据集较大的应用场景，代码维护较为复杂，但是缓存空间占用很少。使用布隆过滤器需要把所有数据提前放入布隆过滤器，且在增加数据时也要往布隆过滤器里放。布隆过滤器不能删除数据，若要删除得重新初始化布隆过滤器。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617public class RedissonBloomFilter &#123; public static void main(String[] args) &#123; Config config = new Config(); config.useSingleServer().setAddress(\"redis://localhost:6379\"); // 构造Redisson RedissonClient redisson = Redisson.create(config); RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(\"nameList\"); // 初始化布隆过滤器：预计元素为100000000L，误差率为3%，根据这两个参数会计算出底层的bit数组大小 bloomFilter.tryInit(100000000L,0.03); // 将eleven插入到布隆过滤器中 bloomFilter.add(\"eleven\"); // 判断下面号码是否在布隆过滤器中 System.out.println(bloomFilter.contains(\"eleven\")); //false System.out.println(bloomFilter.contains(\"张三\")); //false System.out.println(bloomFilter.contains(\"李四\")); //true &#125;&#125; 缓存失效大批量缓存在同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。 123456789101112131415161718String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 设置一个过期时间(300到600之间的一个随机数) int expireTime = new Random().nextInt(300) + 300; if (storageValue == null) &#123; cache.expire(key, expireTime); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 缓存雪崩缓存雪崩是指缓存层支撑不住或宕掉后，大量请求打向后端存储层。由于缓存层承载着大量请求，有效地保护了存储层，但若缓存层由于某些原因不能提供服务，如超大并发缓存层支撑不住，或者由于缓存设计不好，类似大量请求访问bigkey，导致缓存能支撑的并发急剧下降，于是大量请求打到存储层，存储层调用量暴增，造成存储层也会级联宕机的情况。 预防和解决缓存雪崩问题， 可从以下三个方面进行着手。 事前：保证缓存层服务高可用性，比如使用Redis Sentinel哨兵模式或Redis Cluster集群模式。 事中：依赖隔离组件为后端限流熔断并降级。如使用Sentinel或Hystrix限流降级组件。可针对不同数据采取不同的处理方式。当业务应用访问的是非核心数据时，暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。 事后：开启Redis持久化机制，能尽快恢复缓存集群 提前演练。在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定。 热KEY重建优化使用缓存+过期时间策略既可以加速数据读写，又保证数据定期更新，这种模式基本能够满足绝大部分需求。但若当前key是一个热点key并发量非常大，或重建缓存不能在短时间完成，可能是一个复杂计算如复杂的SQL、多次IO、多个依赖等， 可能会对应用造成致命的危害。 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃，要解决该问题主要就是要避免大量线程同时重建缓存。可利用互斥锁来解决，只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。 123456789101112131415161718192021String get(String key) &#123; // 从Redis中获取数据 String value = redis.get(key); // 如果value为空， 则开始重构缓存 if (value == null) &#123; // 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex String mutexKey = \"mutext:key:\" + key; if (redis.set(mutexKey, \"1\", \"ex 180\", \"nx\")) &#123; // 分布式锁 // 从数据源获取数据 value = db.get(key); // 回写Redis， 并设置过期时间 redis.setex(key, timeout, value); // 删除key_mutex redis.delete(mutexKey); &#125; else &#123; // 其他线程休息50毫秒后重试 Thread.sleep(50); get(key); &#125; &#125; return value;&#125; 缓存与数据库双写不一致在大并发下，同时操作数据库与缓存会存在数据不一致性问题 对于并发几率很小的数据，这种几乎不用考虑该问题，很少会发生缓存不一致，可给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。就算并发很高，若业务上能容忍短时间的缓存数据不一致，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。 若不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。也可用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。 以上针对的都是读多写少的情况加入缓存提高性能，若写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可直接操作数据库。放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性。 性能优化KEY设计KEY的设计以业务名为前缀，用逗号分割，在保证语义的前提下，控制KEY的长度，不要包含空格、换行、单双引号等特殊字符。 bigkey对于value值要拒绝bigkey防止网卡流量限制以及慢查询，对于字符串类型value超过10kb就是bigkey；非字符串类型元素个数不要超过5000；非字符串的bigkey不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题。 bigkey会导致redis阻塞、网络拥堵等问题，每次获取要产生的网络流量较大，一般服务器会采用单机多实例的方式来部署，bigkey可能会对其他实例也造成影响。过期删除若未使用Redis 4.0的过期异步删除lazyfree-lazy-expire yes，则可能阻塞Redis。可通过bigkey拆分成几个段储存从而解决bigkey问题。 命令使用O(N)命令关注N的数量，如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值，有遍历的需求可使用hscan、sscan、zscan代替，禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理会有干扰，要合适使用数字进行分区。 过期策略惰性删除 | 被动删除当读或写key时，才对key进行检测，若已经达到过期时间，则删除。若这些过期的key没有被访问，那么他就一直无法被删除，而且一直占用内存。 定期删除 | 主动删除每隔一段时间对数据库做一次检查，删除里面的过期key。由于不可能对所有key去做轮询来删除，所以redis会每次随机取一些key去做检查和删除。 当前已用内存超过maxmemory限定时，触发主动清理策略。 定期+惰性都没有删除过期的key每次定期随机查询key的时候没有删掉，这些key也没有做查询的话，就会导致这些key一直保存无法被删除，这时候就会走到redis的内存淘汰机制。 volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰 volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除 volatile-random：从已设置过期时间的key中，随机选择key淘汰 allkeys-lru：从所有key中选择最近最少使用的进行淘汰 allkeys-random：从所有key中随机选择key进行淘汰 noeviction：当内存达到阈值的时候，新写入操作报错 volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据 allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据 LRU &amp; LFULRU算法是以最近一次访问时间作为参考淘汰很久没被访问过的数据，LFU算法以次数作为参考淘汰最近一段时间被访问次数最少的数据。 当存在热点数据时LRU的效率很好，但偶发性、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用LFU可能更好点。 根据自身业务类型，配置好maxmemory-policy，默认是noeviction，推荐使用volatile-lru。若不设置最大内存，当Redis内存超出物理内存限制时，内存数据会开始和磁盘产生频繁的交换swap，会让Redis性能急剧下降。当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作del key同步到从结点删除数据。 连接池预热使用带有连接池的数据库，可以有效控制连接，同时提高效率 1234567891011121314151617181920212223242526List&lt;Jedis&gt; minIdleJedisList = new ArrayList&lt;Jedis&gt;(jedisPoolConfig.getMinIdle());for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = pool.getResource(); minIdleJedisList.add(jedis); jedis.ping(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; //注意，这里不能马上close将连接还回连接池，否则最后连接池里只会建立1个连接。。 //jedis.close(); &#125;&#125;//统一将预热的连接还回连接池for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = minIdleJedisList.get(i); //将连接归还回连接池 jedis.close(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"https://yaoyinglong.github.io/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"https://yaoyinglong.github.io/categories/Cloud/Redis/"}]},{"title":"Redis集群架构","date":"2021-11-14T16:00:00.000Z","path":"Blog/Cloud/Redis/Redis集群架构/","text":"主从架构12345678910111213141516171819# 复制一份redis.conf文件port 6380pidfile /var/run/redis_6380.pid # 把pid进程号写入pidfile配置的文件logfile \"6380.log\"dir /usr/local/redis-5.0.3/data/6380 # 指定数据存放目录# 需要注释掉bind# bind 127.0.0.1 绑定机器网卡ip，多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可不配置bind# 配置主从复制replicaof 192.168.0.60 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveofreplica-read-only yes # 配置从节点只读# 启动从节点redis-server redis.conf# 连接从节点redis-cli -p 6380# 测试在6379实例上写数据，6380实例是否能及时同步新修改数据# 可以自己再配置一个6381的从节点 若为master主节点配置了一个slave从节点，不管该slave从节点是否是第一次连接上Master主节点，都会发送一个PSYNC命令给master请求复制数据。 master主节点收到PSYNC命令后，会在后台进行数据持久化通过bgsave生成最新的rdb快照文件，持久化期间master会继续接收客户端请求，且把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕以后，master主节点会把这份rdb文件数据集发送给slave从节点，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。master主节点再将之前缓存在内存中的命令发送给slave从节点。 当master主节点与slave从节点之间的连接由于某些原因而断开时，slave从节点能够自动重连Master主节点，若master收到了多个slave从节点并发连接请求，它只会进行一次持久化，然后把这一份持久化的数据发送给多个并发连接的slave从节点。 当master主节点和slave从节点断开重连后，一般都会对整份数据进行复制。但从Redis 2.8开始，PSYNC命令支持部分数据复制去master同步数据，slave从节点与master主节点能够在网络连接断开重连后只进行部分数据复制即断点续传。 master会在其内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据，master主节点和它所有slave从节点都维护了复制数据下标offset和master进程id，当网络连接断开后，slave从节点会请求master主节点从所记录的数据下标开始继续进行未完成的复制。若master主节点进程id变化，或slave从节点数据下标offset太旧超出master主节点缓存队列，则将进行一次全量数据复制。 若有很多从节点，多个从节点同时复制主节点导致主节点压力过大，为了缓解主从复制风暴，可让部分从节点与从节点同步数据。 哨兵模式 sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点，哨兵架构下client端第一次从哨兵找出redis的主节点，后续直接访问redis主节点，不会每次都通过sentinel哨兵代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端，redis的client端一般都实现了订阅功能，订阅sentinel哨兵发布的节点变动消息。 12345678910111213141516171819# 复制一份sentinel.conf文件cp sentinel.conf sentinel-26379.confport 26379daemonize yespidfile \"/var/run/redis-sentinel-26379.pid\"logfile \"26379.log\"dir \"/usr/local/redis-5.0.3/data\"# sentinel monitor &lt;master-redis-name&gt; &lt;master-redis-ip&gt; &lt;master-redis-port&gt; &lt;quorum&gt;# quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效sentinel monitor mmaster 192.168.0.60 6379 2 # mmaster名字随便取，客户端访问时会用到# 启动sentinel哨兵实例src/redis-sentinel sentinel-26379.conf# 查看sentinel的info信息src/redis-cli -p 26379127.0.0.1:26379&gt;info # 可以看到Sentinel的info里已经识别出了redis的主从# 可再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改 sentinel集群都启动完毕后，会将哨兵集群的元数据信息写入所有sentinel配置文件中，追加在文件的最下面： 1234sentinel known-replica mmaster 192.168.0.60 6380 #代表redis主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 #代表redis主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 # 感知到的其它哨兵节点 当redis主节点如果挂了，哨兵集群会重新选举出新的redis主节点，同时修改所有sentinel节点配置文件的集群元数据信息，如6379的redis挂了，假设选举出的新主节点是6380： 1234sentinel known-replica mmaster 192.168.0.60 6379 # 主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 # 主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 # 感知到的其它哨兵节点 同时修改sentinel文件里之前配置的mmaster对应的6379端口，改为6380，当6379的redis实例再次启动时，哨兵集群根据集群元数据信息就可以将6379端口的redis节点作为从节点加入集群 1sentinel monitor mmaster 192.168.0.60 6380 2 1234567891011121314151617181920212223242526272829public class JedisSentinelTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); String masterName = \"mmaster\"; Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); sentinels.add(new HostAndPort(\"172.16.20.53\", 26379).toString()); sentinels.add(new HostAndPort(\"172.16.20.53\", 26380).toString()); sentinels.add(new HostAndPort(\"172.16.20.53\", 26381).toString()); // JedisSentinelPool其实本质跟JedisPool类似，都是与redis主节点建立的连接池 // JedisSentinelPool并不是说与sentinel建立的连接池，而是通过sentinel发现redis主节点并与其建立连接 JedisSentinelPool jedisSentinelPool = new JedisSentinelPool(masterName, sentinels, config, 3000, null); Jedis jedis = null; try &#123; jedis = jedisSentinelPool.getResource(); System.out.println(jedis.set(\"sentinel\", \"eleven\")); System.out.println(jedis.get(\"sentinel\")); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125;&#125; Spring Boot整合Redis哨兵模式，只需要引入如下依赖，并将哨兵的节点信息配置到配置文件中，即可通过自动注入的方式引入StringRedisTemplate或RedisTemplate进行使用， 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 sentinel: # 哨兵模式 master: mmaster # 主服务器所在集群名称 nodes: 192.168.0.60:26379,192.168.0.60:26380,192.168.0.60:26381 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 12345678910111213141516171819202122232425@RestControllerpublic class IndexController &#123; private static final Logger logger = LoggerFactory.getLogger(IndexController.class); @Autowired private StringRedisTemplate stringRedisTemplate; /** * 测试节点挂了哨兵重新选举新的master节点，客户端是否能动态感知到 * 新的master选举出来后，哨兵会把消息发布出去，客户端实际上是实现了一个消息监听机制， * 当哨兵把新master的消息发布出去，客户端会立马感知到新master的信息，从而动态切换访问的masterip */ @RequestMapping(\"/test_sentinel\") public void testSentinel() throws InterruptedException &#123; int i = 1; while (true)&#123; try &#123; stringRedisTemplate.opsForValue().set(\"zhuge\"+i, i+\"\"); System.out.println(\"设置key：\"+ \"zhuge\" + i); i++; Thread.sleep(1000); &#125;catch (Exception e)&#123; logger.error(\"错误：\", e); &#125; &#125; &#125;&#125; Redis 3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，若master节点异常则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，且性能和高可用性等各方面表现一般，且在主从切换瞬间存在访问瞬断情况，且哨兵模式只有一个主节点对外提供服务，无法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。 集群模式 Redis集群是一个由多个主从节点群组成的分布式服务器群，具有复制、高可用和分片特性，Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。只需要将每个节点设置成集群模式，这种集群模式没有中心节点可水平扩展，据官方文档称可以线性扩展到上万个节点，官方推荐不超过1000个节点。Redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单，Redis集群需要至少三个master主节点。 1234567891011121314151617181920212223242526272829303132333435363738# 第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下mkdir -p /usr/local/redis-clustermkdir 8001 8004# 把之前的redis.conf配置文件copy到8001下，修改如下内容：daemonize yesport 8001 # 分别对每个机器的端口号进行设置pidfile /var/run/redis_8001.pid # 把pid进程号写入pidfile配置的文件dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）cluster-enabled yes（启动集群模式）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）cluster-node-timeout 10000# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问protected-mode no # 关闭保护模式appendonly yes# 如果要设置密码需要增加如下配置：requirepass eleven # 设置redis访问密码masterauth eleven # 设置集群节点间访问密码，跟上面一致# 分别启动redis实例，然后检查是否启动成功src/redis-server redis.confps -ef | grep redis # 查看是否启动成功# 首先需要确认集群机器之间redis实例能相互访问，可先把所有机器防火墙关掉，若不关闭防火墙则需打开redis服务端口和集群节点gossip通信端口16379，默认是在redis端口号上加1W# systemctl stop firewalld # 临时关闭防火墙# systemctl disable firewalld # 禁止开机启动# 用redis-cli创建整个redis集群，redis5以前版本集群依靠ruby脚本redis-trib.rb实现# 命令中的1代表为每个创建的主服务器节点创建一个从服务器节点src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006# 验证集群， -a访问服务端密码，-c表示集群模式，指定ip地址和端口号src/redis-cli -a eleven -c -h 192.168.0.61 -p 8001cluster info # 查看集群信息cluster nodes # 查看节点列表# 关闭集群则需要逐个进行关闭，使用命令：src/redis-cli -a eleven -c -h 192.168.0.60 -p 8001 shutdown Redis集群Cluster将所有数据划分为16384个slots槽位，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。当Redis Cluster的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。当客户端要查找某个key时，可直接定位到目标节点。Cluster默认会对key值使用crc16算法进行hash得到一个整数值，然后用这个整数值对16384进行取模来得到具体槽位。 槽位的信息可能存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整，即跳转重定向。当客户端向节点发出指令，若发现指令的key所在槽位不在本节点，则向客户端发送一个携带目标操作的节点地址的特殊跳转指令，告诉客户端连该节点获取数据。客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地槽位映射表缓存。 增加集群实例首先启动实例，然后使用add-node命令新增一个主节点8007(master)，前面的ip:port为新增节点，后面的ip:port为已知存在节点。当添加节点成功后，新增的节点不会有任何数据，因为它还没有分配任何的slot即hash槽，需要为新节点手工分配hash槽。找到集群中的任意一个主节点，对其进行重新分片工作。 12src/redis-cli -a eleven --cluster add-node 192.168.0.61:8007 192.168.0.61:8001 # 新增实例src/redis-cli -a eleven --cluster reshard 192.168.0.61:8001 # 重新分片 添加从节点，同样先启动实例，然后通过add-node命令将实例添加到集群中，然后执行replicate命令来指定当前节点的主节点id，首先需要连接新加的当前节点8008的客户端，然后使用集群命令进行操作，把当前的8008节点指定到一个主节点下 1cluster replicate 2728a594a0498e98e4b83a537e19f9a0a3790f38 # 后面这串id为8007的节点id 删除集群实例对于从节点的删除直接使用del-node命令删除即可 1src/redis-cli -a eleven --cluster del-node 192.168.0.61:8008 a1cfe35722d151cf70585cee21275565393c0956 若删除主节点，由于主节点中有分配的hash槽，必须先把hash槽放入其他可用主节点中，然后再进行移除操作，不然会丢失数据 12src/redis-cli -a eleven --cluster reshard 192.168.0.61:8007 # 释放hash槽src/redis-cli -a eleven --cluster del-node 192.168.0.61:8007 2728a594a0498e98e4b83a537e19f9a0a3790f38 集群节点通信机制redis cluster节点间采取gossip协议进行通信；维护集群的元数据有集中式和gossip；元数据包括集群节点信息，主从角色，节点数量，各节点共享的数据等 集中式优点在于元数据更新和读取时效性非常好，一旦元数据出现变更立即就会更新到集中式的存储中，其他节点读取时立即就可感知到；但压力全部集中在一个地方，可能导致元数据的存储压力。很多中间件都会借助zookeeper集中式存储元数据。 gossip协议包含多种消息，优点在于元数据不集中在一个地方更新比较分散，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时降低了压力；缺点在于元数据更新有延时可能导致集群的一些操作会有一些滞后。 meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信； ping：每个节点都会频繁给其他节点发送ping，其中包含本节点状态以及本节点维护的集群元数据，互相通过ping交换元数据 pong：对ping和meet消息的返回，包含本节点的状态和其他信息，也可用于信息广播和更新 fail：某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。 每个节点都有一个专门用于节点间gossip通信的端口，为本节点提供服务的端口号+10000，每个节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几点收到ping消息之后返回pong消息。 网络并非是一直稳定的，网络抖动就是非常常见的一种现象，突然之间部分连接变得不可访问，然后很快又恢复正常。为解决这种问题，Redis Cluster提供了一种选项cluster-node-timeout，表示当某个节点持续timeout的时间失联时，才认定该节点出现故障，需要进行主从切换。若没有该选项网络抖动会导致主从频繁切换以及数据的重新复制。 集群选举当slave从节点发现master主节点变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程。 首选slave发现自己的master变为FAIL，将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息，其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack，尝试failover的slave收集master返回的FAILOVER_AUTH_ACK，slave收到超过半数master的ack后变成新Master，最后slave广播Pong消息通知其他集群节点。 从节点并不是在主节点一进入FAIL状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保等待FAIL状态在集群中传播，若slave立即尝试选举，其它masters或许尚未意识到FAIL状态可能会拒绝投票。 延迟计算公式：DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms，SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。故持有最新数据的slave将会首先发起选举。 脑裂数据丢失问题Redis集群没有过半机制会有脑裂问题，网络分区导致脑裂后多个主节点对外提供写服务，一旦网络分区恢复会将其中一个主节点变为从节点，从而导致大量数据丢失。规避方法可以在redis配置里加上min-replicas-to-write配置写数据成功最少同步的slave数量，该数量可模仿大于半数机制配置。但该配置在一定程度上会影响集群的可用性，如slave要是少于1个，该集群就算leader正常也不能提供服务，需要具体场景权衡选择。 1min-replicas-to-write 1 # 写数据成功最少同步的slave数量 当redis.conf的配置cluster-require-full-coverage为no时，表示当负责一个插槽的主库下线且没有相应的从库进行故障恢复时集群仍然可用，若为yes则集群不可用。 新master的选举需要大于半数的集群master节点同意才能选举成功，若只有两个master节点，当其中一个挂了，是达不到选举新master的条件的。奇数个master节点可以在满足选举该条件的基础上节省一个节点，如三个master节点和四个master节点的集群相比，若都挂一个master节点都能选举新master节点，若都挂两个master节点都没法选举新master节点，故奇数的master节点更多的是从节省机器资源角度出发说的。 集群批量操作问题对于类似mset、mget这样的多个key的原生批量操作命令，redis集群只支持所有key落在同一slot的情况，若有多个key一定要用mset命令在redis集群上操作，则可在key的前面加上{XX}，则数据分片hash计算只会是大括号里的值，这样能确保不同的key能落到同一slot中。 1mset &#123;user1&#125;:1:name zhuge &#123;user1&#125;:1:age 18 集群使用借助redis的java客户端jedis可以操作以上集群，引用jedis版本的maven坐标如下 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031public class JedisClusterTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); Set&lt;HostAndPort&gt; jedisClusterNode = new HashSet&lt;HostAndPort&gt;(); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8001)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8002)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8003)); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8004)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8005)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8006)); JedisCluster jedisCluster = null; try &#123; // connectionTimeout：指的是连接一个url的连接等待时间 // soTimeout：指的是连接上一个url，获取response的返回等待时间 jedisCluster = new JedisCluster(jedisClusterNode, 6000, 5000, 10, \"eleven\", config); System.out.println(jedisCluster.set(\"cluster\", \"eleven\")); System.out.println(jedisCluster.get(\"cluster\")); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (jedisCluster != null) &#123; jedisCluster.close(); &#125; &#125; &#125;&#125; 集群的Spring Boot整合Redis连接 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 password: eleven cluster: nodes: 192.168.0.61:8001,192.168.0.62:8002,192.168.0.63:8003,192.168.0.61:8004,192.168.0.62:8005,192.168.0.63:8006 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 1234567891011@RestControllerpublic class IndexController &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @RequestMapping(\"/test_cluster\") public void testCluster() throws InterruptedException &#123; stringRedisTemplate.opsForValue().set(\"eleven\", \"666\"); System.out.println(stringRedisTemplate.opsForValue().get(\"eleven\")); &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"https://yaoyinglong.github.io/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"https://yaoyinglong.github.io/categories/Cloud/Redis/"}]},{"title":"Redis基础","date":"2021-11-13T16:00:00.000Z","path":"Blog/Cloud/Redis/Redis基础/","text":"Redis是非关系型的键值对数据库，可根据键以O(1)时间复杂度取出或插入关联值，Redis数据是存在内存中，键值对中键可以是字符串、整型、浮点型等且键唯一。值的类型可以是string、hash、list、set、sorted set等。内置了复制、磁盘持久化、LUA脚本、事务、SSL、ACLs、客户端缓存、客户端代理等功能，通过哨兵模式和Cluster模式提供高可用。 Redis的速度非常的快，单机的Redis就可以支撑每秒10几万的并发，相对于MySQL来说，性能是MySQL的几十倍。 完全基于内存操作 C语言实现，优化过的数据结构，基于几种基础的数据结构，Redis做了大量的优化，性能极高 使用单线程，无上下文的切换成本 基于非阻塞的IO多路复用机制 Redis的单线程主要是指Redis的网络IO和键值对读写是由一个线程来完成的，但Redis的其他功能如持久化、异步删除、集群数据同步等由额外线程执行。 Redis单线程之所以这么快，是由于Redis所有数据都在内存中，所有运算都是内存级别的运算，且单线程避免了多线程的切换性能损耗问题。正因为Redis是单线程，故需小心使用Redis指令，对于耗时的指令如keys，一定要谨慎使用，否则可能会导致Redis卡顿。 Redis单线程之所以能处理很高的并发的客户端链接，其是利用epoll来实现的IO多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器将事件分发给事件处理器。 虽然6.0后改用多线程，但并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能，执行命令还是使用单线程。 应用场景计数器：可对String进行自增自减运算从而实现计数器功能，这种内存型数据库读写性能非常高，很适合存储频繁读写的计数量 分布式ID生成：利用自增特性，一次请求一个大一点的步长如incr 2000，缓存在本地使用，用完再请求 海量数据统计：通过位图bitmap存储是否参过某次活动，是否已读谋篇文章，用户是否为会员，日活统计 Session共享：可统一存储多台应用服务器会话信息，一个用户可请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性 分布式队列、阻塞队列：List双向链表可通过lpush/rpush和rpop/lpop写入和读取消息，可通过使用brpop/blpop来实现阻塞队列 分布式锁实现：使用Redis自带的SETNX命令实现分布式锁 热点数据存储：最新评论，最新文章列表，使用list存储，ltrim取出热点数据，删除老数据 社交类需求：可通过Set交集实现共同好友等功能，可通过Set求差集进行好友推荐、文章推荐 排行榜：sorted_set可实现有序性操作，从而实现排行榜等功能 延迟队列：通过sorted_set使用当前时间戳 + 需要延迟的时长做score，消息内容作为元素，调用zadd来生产消息，消费者使用zrangbyscore获取当前时间之前的数据做轮询处理。消费完再删除任务rem key member Redis安装1234567891011121314151617181920212223242526272829303132333435# 安装gccyum install gcc# 把下载好的redis-5.0.3.tar.gz放在/usr/local文件夹下，并解压wget http://download.redis.io/releases/redis-5.0.3.tar.gztar xzf redis-5.0.3.tar.gzcd redis-5.0.3# 进入到解压好的redis-5.0.3目录下，进行编译与安装make# 修改配置daemonize yes # 后台启动protected-mode no # 关闭保护模式，若开启只有本机才可访问redis# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器哪些网卡ip去访问，内网一般可不配置bind，注释掉即可# 启动服务src/redis-server redis.conf# 验证启动是否成功 ps -ef | grep redis # 进入redis客户端 src/redis-cli # 退出客户端quit# 退出redis服务pkill redis-server kill 进程号 src/redis-cli shutdown # 查看redis支持的最大连接数，在redis.conf文件中可修改，默认maxclients 10000CONFIG GET maxclients Redis基本数据类型Redis是基于数组和链表来存储海量数据的，通过对key进行hash取模定位到数组下标，产生hash冲突则通过链表来存储冲突的数据，Redis有16个DB。 1234567891011typedef struct redisDb &#123; dict *dict; /* The keyspace for this DB 存储K-V数据*/ dict *expires; /* Timeout of keys with a timeout set 过期时间字典 */ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP) 阻塞队列的处理*/ dict *ready_keys; /* Blocked keys that received a PUSH key跟客户端链接之间的关系*/ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* Average TTL, just for stats */ unsigned long expires_cursor; /* Cursor of the active expire cycle. */ list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */&#125; redisDb; Redis是非关系型的键值对数据库，可根据键以O(1)的时间复杂度取出或插入关联值，数据是基于内存的，键值对中键的类型可以是字符串、整型、浮点型等且键唯一，值的类型可以是string、hash、list、set、sorted set等。 用于保存键值对的抽象数据结构，redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的而是渐进式的。 每个dict字典有两个dictht，是为了通过渐进式rehash提升扩容时的性能，若发生扩容会创建新的dictht且将旧的dictht数据向新的dictht拷贝，最终释放掉就的dictht，但数据量非常大的情况会非常耗时，而redis执行命令是单线程的，会导致整个性能降低，故redis使用了渐进式的rehash，即扩容是会创建新的dictht，但不会一次全部将旧dictht的数据搬运到新dictht上，而是访问到某个key时才选择一部分搬运，当没有访问时也会通过事件轮询来搬数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344typedef struct dict &#123; // redis中的hashtable dictType *type; // 类型 void *privdata; dictht ht[2];// ht[0] , ht[1] =null long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict;/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123; // hashtable数据结构，每个字典都有两个dictht，用于在旧表到新表时通过渐进式的rehash dictEntry **table; unsigned long size; // hashtable 容量 unsigned long sizemask; // size -1 unsigned long used; // hashtable 元素个数 used / size =1&#125; dictht;typedef struct dictType &#123; uint64_t (*hashFunction)(const void *key); // 使用的hash函数封装在hashFunction void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); // keyCompare类似equals方法 void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType;typedef struct dictEntry &#123; void *key; // string对象其实就是sds union &#123; // 用于存储值 void *val; // 可能是string、list、hash等 uint64_t u64; // 占8 byte int64_t s64; // 占8 byte double d; // 占8 byte &#125; v; struct dictEntry *next; // 链表，用于解决hash冲突&#125; dictEntry;// redisObject对象: string, list, set, hash, zsettypedef struct redisObject &#123;// 总共占用16个byte，缓存行为64byte, unsigned type:4; // 4 bit: 表示数据类型：string, list, set, hash, zset unsigned encoding:4; // 4 bit, 内存底层类型：int、row、embstr、quicklist、hashtable、ziplist、intset、skiplist unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). 24 bit */ int refcount; // 4 byte 用于引用计数法来管理内存 void *ptr; // 8 byte 总空间: 4 bit + 4 bit + 24 bit + 4 byte + 8 byte = 16 byte &#125; robj; 对外提供的数据结构基于基础的数据结构，Redis封装了自己的对象系统，包含字符串对象string、列表对象list、哈希对象hash、集合对象set、有序集合对象zset，每种对象都用到了至少一种基础的数据结构。Redis通过encoding属性设置对象的编码形式来提升灵活性和效率，基于不同的场景Redis会自动做出优化。不同对象的编码如下： 字符串对象string：int整数、embstr编码的简单动态字符串、raw简单动态字符串 列表对象list：ziplist、quicklist 哈希对象hash：ziplist、hashtable 集合对象set：intset、hashtable 有序集合对象zset：ziplist、skiplist 字符串对象string可用于单值缓存、对象缓存、分布式锁的实现、计数器、Web集群Session共享、分布式系统全局序列号生成，可批量生成提升性能。若大量数据储存成string可能导致频繁rehash。 Redis没有直接使用C语言传统的字符串表示，而是自己实现的叫做简单动态字符串SDS的抽象类型。C语言的字符串不记录自身的长度信息，而SDS则保存了长度信息，这样将获取字符串长度的时间由O(N)降低到了O(1)，同时可避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。 Redis并没有直接使用C语言char数组作为字符串的实现，而是自定义了一个simple dynamic string即SDS，且C语言作为字符串结束是通过\\0作为字符串结束，在redis中可能会导致数据问题。 二进制安全的数据结构即自定义SDS防止\\0导致数据丢失，提供了内存预分配机制避免频繁内存分配，在字符串末尾加上\\0兼容C语言的函数库 123456789# 并不是每次都成倍扩容，当达到1M时不会再成倍扩容，而是每次加1Msds: free: 0 # 剩余容量 len: 4 # 最大长度 char buf[]=&quot;test&quot; # 当需要append为test123时，使用(4 + 3) * 2 = 14sds: # 适用于append、setbit命令 free: 7 # 剩余容量，认为修改可能还会再次被修改，且只扩大不缩小 len: 14 # 最大长度 char buf[]=&quot;test123&quot; -&gt; test123 这里Key长度为8即其本身占用8byte+\\0占1byte，这里key明显使用的是sdshdr5，其数据结构本身额外占1byte，值是使用的sdshdr8，数据结构本身占3byte，数据长度为4即占5byte，redisObject数据结构本身占16byte，dictEntry 数据结构本身占24byte，故总共占8 + 1 + 1 + 3 + 5 + 16 + 24 = 58。12345set sds_test aaaamemory usage sds_test # 58，实际数据长度为4 + \\0即5个bytedebug object sds_testappend sds_test b # (1 + 5) * 2 = 12 增长了8memory usage sds_test # 66 = 58 + 8 String在Redis中使用得非常多，redis 3.2以前由于int是4个字节可表示0到2^32 -1即42亿多数据，通常可能不用到这么大，在redis 3.2之后对len和free进行了优化，增加了很多数据类。对于不同的范围使用不同的数据结构进行描述。 1234567891011121314151617181920212223242526272829303132333435363738394041// redis 3.2以前，由于int是4个字节可表示0到2^32 -1即42亿多数据，通常可能不用到这么大struct sdshdr &#123; int len; int free; char buf[];&#125;;// redis 3.2之后，增加了很多数据类，len表示长度，alloc分配的空间，typedef char *sds;struct __attribute__ ((__packed__)) sdshdr5 &#123; // 0 - 2 ^ 5 - 1 unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];// buf[0]: z: 0101001&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; // 1个字节长度 uint8_t len; /* used 1byte*/ uint8_t alloc; /* excluding the header and null terminator 1byte*/ unsigned char flags; /* 3 lsb of type, 5 unused bits 1byte*/ char buf[]; // 由于会兼容c语言会加上\\0占用一个byte&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; // 2个字节长度 uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; // 4个字节长度 uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; // 8个字节长度 uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;#define SDS_TYPE_5 0 // flags前三位表示的值，sdshdr5#define SDS_TYPE_8 1 // flags前三位表示的值，sdshdr8#define SDS_TYPE_16 2 // flags前三位表示的值，sdshdr16#define SDS_TYPE_32 3 // flags前三位表示的值，sdshdr32#define SDS_TYPE_64 4 // flags前三位表示的值，sdshdr64 String类型在Redis中是非常紧凑的，flags用于表示数据类型，占一个字节即8位，sdshdr5中前三位用于表示类型，后五位用于表示长度，这也是sdshdr5的由来。对于剩余的sdshdr8、sdshdr16、sdshdr32、sdshdr64等类型，flags前三位依然表示数据类型，后5位闲置未使用。 若是encoding编码为int，则*ptr直接用于存储数据，对于embstr编码类型，由于操作系统缓存行为64byte，而redisObject对象占16byte，要利用缓存行的优化，还剩余48byte，对于sdshdr8类型的数据，结构占用3字节为了兼容\\0故总共占4字节，还剩余44个字节可用，故若字符长度小于等于44byte的数据，可利用操作系统缓存行特性，一次IO就获取到数据。长度超过44则编码类型为row。 12345678set intstr 55type intstrobject encoding intstrset emb_str aaaaset emb_str aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaset emb_str aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabobject encoding emb_str 列表对象listlist是一个按加入的时间顺序排序的有序数据结构，Redis采用双端链表quicklist和ziplist作为list的底层实现。可以通过设置每个ziplist的最大容量和quicklist的数据压缩范围提升数据存取效率。 12list-max-ziplist-size -2 # 单个ziplist节点最大能存储8kb，超过则进行分裂将数据存储在新的ziplistlist-compress-depth 1 # 0表示所有节点都不压缩，1表示头结点和尾节点不压缩其他节点压缩 压缩列表ziplist压缩列表是为节约内存而开发的顺序性数据结构，可包含多个节点，每个节点可保存一个字节数组或整数值。zlbytes能存储元素个数，zltail尾节点索引位置即在ziplist中的便宜字节数，可以很方便找到最后一项数据，从而在ziplist尾端快速地执行push或pop操作，zllen当前ziplist有多少个元素，zlend标识ziplist最优一个字节即数据的结尾恒等于255。prerawlen前一个元素的数据长度，len表示entry中数据的长度，data即真实数据存储。 quicklist是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，表头节点的前置和后置节点都指向NULL。 可通过LPUSH + LPOP实现Stack栈，LPUSH + RPOP实现Queue队列，LPUSH + BRPOP实现阻塞队列，可应用于类似微博、微信公众号消息流。 哈希对象hashhash数据结构底层实现为一个字典，数据量较小时底层使用ziplist存储，数据量较大时将改为HashTable编码存储。同类数据归类整合储存方便数据管理，相比string操作消耗内存与CPU更小，更节省空间，但过期功能不能使用在field上只能用在key上，集群架构下不适合大规模使用。可应用于如电商购物车，用户id为key，商品id为field，商品数量为value。 12hash-max-ziplist-entries 512 # 元素个数超过512，将改为HashTable编码hash-max-ziplist-value 64 # 单个元素大小超过64byte，将改为HashTable编码 可将同类型数据整合存储，方便数据管理，相比string操作消耗内存和CPU更小，但过期功能不能使用在field上，只能用在key上，集群架构下不适合大规模使用。 1234hset hash_test field1 value1hset hash_test field2 aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahset hash_test field2 aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabobject encoding hash_test 集合对象setset是无序的自动去重的集合数据结构，底层实现为一个value为null的字典，当数据可用整型表示时，set集合将被编码为intset数据结构，当数据无法用整型表示时或元素个数大于set-max-intset-entries配置值时将使用HashTable存储数据。 1set-max-intset-entries 512 # 存储元素超过512时，使用HashTable编码 整数集合intset用于保存整数值的集合抽象数据结构，整数集合是一个有序的整型数据结构，整型集合在Redis中可保存int16_t，int32_t，int64_t类型的整型数据，底层实现为数组，且可保证集合中不会出现重复数据。 123456789typedef struct intset &#123; uint32_t encoding; // 编码类型 uint32_t length; // 元素个数 int8_t contents[]; // 元素存储&#125; intset; #define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t)) 12345sadd set_test 11 12 13type set_testsadd set_test aasmembers set_testobject encoding set_test SINTER set1 set2 set3 得到集合{c}，SUNION set1 set2 set3得到集合{a,b,c,d,e}，SDIFF set1 set2 set3得到集合{a} 可应用于类似抽奖小程序，SADD key {uid}加入抽奖集合，SMEMBERS key查看参与抽奖所有用户，SRANDMEMBER key [count]或SPOP key [count]抽取count名中奖者。 微信微博点赞、收藏、标签等功能，SADD like:{msgID} {userID}点赞，SREM like:{msgID} {userID}取消点赞，SISMEMBER like:{msgID} {userID}检查用户是否点过赞，SMEMBERS like:{msgID}获取点赞的用户列表，SCARD like:{msgID}获取点赞用户数 有序集合对象zsetzset是有序的自动去重的集合数据结构，底层实现为字典 + 跳表skiplist，当数据比较少时，用ziplist编码结构存储。 12zset-max-ziplist-entries 128 # 元素个数超过128，将用skiplist编码zset-max-ziplist-value 64 # 单个元素大小超过64byte，将用skiplist编码 跳跃表skiplist有序集合的底层实现之一，redis中实现有序集合键和集群节点的内部结构中都是使用跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。 可应用于排行榜，如展示当日排行前十、七日搜索榜单计算、七日排行前十等 1234zadd zset_test 1 member1 2 member2object encoding zset_testzadd zset_test 1 aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaazadd zset_test 1 aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaab GeoHashgeohash是一种地理位置编码方法，它将地理位置编码为一串简短的字母和数字，是一种分层的空间数据结构，将空间细分为网格形状的桶，是Z顺序曲线的众多应用之一，通常是空间填充曲线。 通过GeoHash算法，可将经纬度的二维坐标变成一个可排序、可比较的字符串编码，在编码中每个字符代表一个区域，且前面的字符是后面字符的父区域。 GeoHash利用Z阶曲线进行编码，可将二维所有点转换成一阶曲线，地理位置坐标点通过编码转换成一维值，利用有序数据结构如B树、SkipList等均可进行范围搜索，因此利用GeoHash算法查找邻近点比较快。Z阶曲线虽然有局部保序性，但它也有突变性，在每个Z字母的拐角都可能出现顺序的突变。 BitMap基本思想是用一个bit位来标记某个元素对应的Value，可大大节省存储空间，可用于快速排序、快速去重、快速查找、亿级日活统计等，在数据比较密集时才有优势。布隆过滤器就是使用的BitMap。可通过与操作做连续多少天活跃统计。 12345setbit key offset value # 设置bigmap下标位置offset的value，value只能为0或1getbit key offset # 获取bigmap下标位置offset的valuebitop or after_key key1 key2 # 将key1 和 key2做按位或操作且将结果保存到 after_key中bitop and after_key key1 key2 # 将key1 和 key2做按位与操作且将结果保存到after_key中bitcount key # 统计key中位为1的个数 Redis持久化RDB快照默认情况下Redis将内存数据库快照保存在名字为dump.rdb的二进制文件中，可对Redis进行设置，让它在N秒内数据集至少有M个改动这一条件被满足时， 自动保存一次数据集快照。如以下设置会让Redis在满足60秒内有至少有1000个键被改动时， 自动保存一次数据集，还可手动执行命令生成RDB快照，执行命令save或bgsave可生成dump.rdb文件，每次命令执行都会将所有Redis内存快照到一个新的rdb文件里，并覆盖原有rdb快照文件。 1# save 60 1000 // 关闭RDB只需要将所有的save保存策略注释掉即可 Redis借助操作系统提供的写时复制技术Copy-On-Write, COW，在生成快照同时依然可正常处理写命令。bgsave子进程由主线程fork生成，可共享主线程所有内存数据。bgsave子进程运行后，开始读取主线程内存数据，并把它们写入RDB文件。此时若主线程对这些数据也都是读操作，则主线程和bgsave子进程相互不影响。若主线程要修改一块数据，则这块数据就会被复制一份，生成该数据的副本。然后bgsave子进程会把这个副本数据写入RDB文件，这个过程中主线程仍可直接修改原来的数据。 save和bgsave命令的IO类型一个是同步一个是异步，save会阻塞redis其他命令，bgsave不会阻塞，只是在生成子进程执行调用fork函数时会有短暂阻塞；它们时间复杂度都是O(n)，save命令不会消耗额外内存，bgsave命令需要fork子进程需要消耗额外内存。 AOF快照功能并不是非常耐久durable，若Redis因某些原因故障停机，服务器将丢失最近写入且仍未保存到快照中的数据。从1.1版本开始，Redis增加了一种完全耐久的持久化方式AOF持久化，将修改的每一条指令记录进appendonly.aof文件中，先写入os cache，每隔一段时间fsync到磁盘，每执行增删改命令时就会被aof文件记录。 可通过修改配置文件来打开AOF功能以及设置fsync策略，默认并推荐的措施为每秒fsync一次， 这种fsync策略可兼顾速度和安全性，AOF文件中可能有很多无用指令，故AOF会定期根据内存的最新数据生成aof文件。也可以通过redis客户端执行命令bgrewriteaof手动重写AOF。AOF重写redis会fork出一个子进程去做与bgsave命令类似，不会对redis正常命令处理有太多影响。 123456appendonly yes # 打开AOF功能appendfsync always # 每次有新命令追加到AOF文件时就执行一次fsync，非常慢也非常安全appendfsync everysec # 每秒fsync一次，足够快且在故障时只会丢失1秒钟的数据appendfsync no # 从不fsync，将数据交给操作系统来处理。更快，也更不安全的选择auto-aof-rewrite-min-size 64mb # aof文件至少达到64M才会自动重写，文件太小恢复速度本来就很快，重写意义不大auto-aof-rewrite-percentage 100 # aof文件自上一次重写后文件大小增长了100%则再次触发重写 RDB快照和AOF两种持久化策略生产环境可以都启用，redis启动时若既有RDB文件又有AOF文件则优先选择aof文件恢复数据，因为AOF一般来说数据更全一点。 命令 RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 容易丢数据 根据策略决定 混合持久化重启Redis时，很少使用RDB来恢复内存状态，因为RDB会丢失大量数据，通常使用AOF日志重放，但重放AOF日志性能相对RDB来说要慢很多，这样在Redis实例很大的情况下，启动需要花费很长的时间。 Redis 4.0为了解决该问题引入了混合持久化。 1aof-use-rdb-preamble yes # 开启混合持久化，注意必须先开启aof 若开启了混合持久化，AOF在重写时不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。 混合模式下Redis重启时，可先加载RDB内容，然后再重放增量AOF日志就可以完全替代之前的AOF全量文件重放，因此重启效率大幅得到提升。 Redis存储数据序列化StringRedisTemplate继承自RedisTemplate一般用来存储字符串，默认序列化机制为StringRedisSerializer。若需存储对象一般用RedisTemplate，其底层用序列化机制是JdkSerializationRedisSerializer，这种存储对象要求对象实现Serializable接口，底层存的是二进制的序列化数组，不便在redis中查看，故一般用Jackson2JsonRedisSerializer序列化机制，其能将对象转成JSON存储，且不需要对象实现Serializable接口，且方便在redis中查看。若无需在redis中查看数据且对性能要求较高，可以采用protobuf序列化。 12345678RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();Jackson2JsonRedisSerializer&lt;Object&gt; jsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;Object&gt;(Object.class);// value的序列化采用jsonRedisSerializertemplate.setValueSerializer(jsonRedisSerializer);template.setHashValueSerializer(jsonRedisSerializer);// key的序列化采用StringRedisSerializertemplate.setKeySerializer(new StringRedisSerializer());template.setHashKeySerializer(new StringRedisSerializer()); Redis备份策略写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份，每次copy备份的时候，都把太旧的备份删除 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏 RedisTemplate方法与命令对应关系String类型 Redis命令 RedisTemplate方法 备注 set key value rt.opsForValue().set(“key”, “value”) 存入字符串键值对 get key rt.opsForValue().get(“key”) 获取一个字符串键值 del key rt.delete(“key”) 删除一个键 strlen key rt.opsForValue().size(“key”) getset key value rt.opsForValue().getAndSet(“key”, “value”) getrange key start end rt.opsForValue().get(“key”, start, end) append key value rt.opsForValue().append(“key”, “value”) Hash类型 Redis命令 RedisTemplate方法 备注 hmset key field1 value1 field2 value2… rt.opsForHash().putAll(“key”, map) 在一个哈希表key中存储多个键值对 hset key field value rt.opsForHash().put(“key”,”field”,”value”) hexists key field rt.opsForHash().hasKey(“key”,”field”) hgetall key rt.opsForHash().entries(“key”) 返回Map对象 hvals key rt.opsForHash().values(“key”) 返回List对象 hkeys key rt.opsForHash().keys(“key”) 返回List对象 hmget key field1 field2… rt.opsForHash().multiGet(“key”, keyList) hsetnx key field value rt.opsForHash().putIfAbsent(“key”, “field”, “value” hdel key field1 field2 rt.opsForHash().delete(“key”, “field1”, “field2”) hget key field rt.opsForHash().get(“key”, “field”) List类型 Redis命令 RedisTemplate方法 备注 lpush list node1 node2 node3… rt.opsForList().leftPush(“list”,”node”)rt.opsForList().leftPushAll(“list”, list) rpush list node1 node2 node3… rt.opsForList().rightPush(“list”,”node”)rt.opsForList().rightPushAll(“list”,list) lindex key index rt.opsForList().index(“list”, index) llen key rt.opsForList().size(“key”) lpop key rt.opsForList().leftPop(“key”) rpop key rt.opsForList().rightPop(“key”) lpushx list node rt.opsForList().leftPushIfPresent(“list”,”node”) rpushx list node rt.opsForList().rightPushIfPresent(“list”,”node”) lrange list start end rt.opsForList().range(“list”,start,end) lrem list count value rt.opsForList().remove(“list”,count,”value”) lset key index value rt.opsForList().set(“list”,index,”value”) Set类型 Redis命令 RedisTemplate方法 备注 sadd key member1 member2… rt.boundSetOps(“key”).add(“member1”,”member2”,…)rt.opsForSet().add(“key”, set) scard key rt.opsForSet().size(“key”) sidff key1 key2 rt.opsForSet().difference(“key1”, “key2”) sinter key1 key2 rt.opsForSet().intersect(“key1”, “key2”) sunion key1 key2 rt.opsForSet().union(“key1”, “key2”) sdiffstore des key1 key2 rt.opsForSet().differenceAndStore(“key1”, “key2”, “des”) sinter des key1 key2 rt.opsForSet().intersectAndStore(“key1”, “key2”, “des”) sunionstore des key1 key2 rt.opsForSet().unionAndStore(“key1”, “key2”, “des”) sismember key member rt.opsForSet().isMember(“key”, “member”) smembers key rt.opsForSet().members(“key”) spop key rt.opsForSet().pop(“key”) srandmember key count rt.opsForSet().randomMember(“key”, count) srem key member1 member2… rt.opsForSet().remove(“key”, “member1”, “member2”, …)","tags":[{"name":"Redis","slug":"Redis","permalink":"https://yaoyinglong.github.io/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"https://yaoyinglong.github.io/categories/Cloud/Redis/"}]},{"title":"Feign集成原理","date":"2021-11-11T16:00:00.000Z","path":"Blog/Cloud/Feign集成原理/","text":"Feign是Netflix开发的声明式、模板化的HTTP客户端，可帮助我们更加便捷、优雅地调用HTTP API，Feign可以做到使用HTTP请求远程服务时就像调用本地方法一样的体验。 Spring Cloud整合Feign只需要引入以下依赖，且需要通过@EnableFeignClients注解开启Feign： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 日志配置若需要需要对Feign的接口进行问题排查，或者想看看调用性能，就需要配置Feign的日志，可通过配置类的方式指定日志级别。 1234567891011121314// 注意： 此处配置@Configuration注解就会全局生效，如果想指定对应微服务生效，就不能配置public class FeignConfig &#123; /** * 日志级别: * NONE【性能最佳，适用于生产】：不记录任何日志（默认值）。 * BASIC【适用于生产环境追踪问题】：仅记录请求方法、URL、响应状态代码以及执行时间。 * HEADERS：记录BASIC级别的基础上，记录请求和响应的header。 * FULL【比较适用于开发及测试环境定位问题】：记录请求和响应的header、body和元数据。 */ @Bean public Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 局部配置，让调用的微服务生效，在@FeignClient注解中指定使用的配置类： 12345@FeignClient(value = \"mall-order\", path = \"/order\", configuration = FeignConfig.class, fallback = FallbackOrderFeignService.class)public interface OrderFeignService &#123; @RequestMapping(value = \"/findOrderByUserId/&#123;userId&#125;\") Object findOrderByUserId(@PathVariable(value = \"userId\") Integer userId);&#125; 局部配置还可以通过yml配置类完成，对应属性配置类为FeignClientProperties.FeignClientConfiguration，如拦截器、契约、超时时间等，Feign的底层用的是Ribbon，但超时时间以Feign配置为准。 12345678910111213141516171819202122232425262728feign: client: config: mall-order: #对应微服务 loggerLevel: FULL contract: feign.Contract.Default #指定Feign原生注解契约配置 #配置拦截器 requestInterceptors[0]: com.eleven.***.interceptor.FeignAuthRequestInterceptor # 连接超时时间，默认2s connectTimeout: 5000 # 请求处理超时时间，默认5s readTimeout: 10000 # 配置编解码器 encoder: feign.jackson.JacksonEncoder decoder: feign.jackson.JacksonDecoder httpclient: enabled: true #feign 使用 Apache HttpClient 可以忽略，默认开启 okhttp: enabled: true #feign 使用 okhttp compression: # 配置 GZIP 来压缩数据 request: enabled: true # 配置压缩的类型 mime-types: text/xml,application/xml,application/json # 最小压缩值 min-request-size: 2048 response: enabled: true Feign对SpringMvc的支持是通过配置契约来完成的，Spring Cloud中默认的是SpringMvcContract契约。若调用的接口有权限控制，可通过配置拦截器的方式实现，每次Feign发起HTTP调用之前，会去执行拦截器中的逻辑。 12345678@Beanpublic Contract feignContract() &#123; return new Contract.Default();&#125;@Beanpublic BasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new BasicAuthRequestInterceptor(\"eleven\", \"123456\");&#125; 集成原理Feign的集成是通过@EnableFeignClients注解中导入了FeignClientsRegistrar类，该类实现了ImportBeanDefinitionRegistrar接口，故在Spring容器启动时会调用其registerBeanDefinitions完成将所有被@FeignClient注解标注的接口通过FeignClientFactoryBean注册到Spring容器中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899class FeignClientsRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, EnvironmentAware &#123; public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; registerDefaultConfiguration(metadata, registry); registerFeignClients(metadata, registry); &#125; public void registerFeignClients(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; ClassPathScanningCandidateComponentProvider scanner = getScanner(); scanner.setResourceLoader(this.resourceLoader); Set&lt;String&gt; basePackages; Map&lt;String, Object&gt; attrs = metadata.getAnnotationAttributes(EnableFeignClients.class.getName()); AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class); final Class&lt;?&gt;[] clients = attrs == null ? null : (Class&lt;?&gt;[]) attrs.get(\"clients\"); if (clients == null || clients.length == 0) &#123; scanner.addIncludeFilter(annotationTypeFilter); // 添加过滤器，过滤出所有被@FeignClient注解标注的类 basePackages = getBasePackages(metadata); // 获取扫描的包路径，若未配置则默认为当前类所在的包 &#125; else &#123; final Set&lt;String&gt; clientClasses = new HashSet&lt;&gt;(); basePackages = new HashSet&lt;&gt;(); for (Class&lt;?&gt; clazz : clients) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); clientClasses.add(clazz.getCanonicalName()); &#125; AbstractClassTestingTypeFilter filter = new AbstractClassTestingTypeFilter() &#123; @Override protected boolean match(ClassMetadata metadata) &#123; String cleaned = metadata.getClassName().replaceAll(\"\\\\$\", \".\"); return clientClasses.contains(cleaned); &#125; &#125;; scanner.addIncludeFilter(new AllTypeFilter(Arrays.asList(filter, annotationTypeFilter))); &#125; for (String basePackage : basePackages) &#123; // 遍历所有的包 Set&lt;BeanDefinition&gt; candidateComponents = scanner.findCandidateComponents(basePackage); // 扫描出所有被@FeignClient注解标注的接口 for (BeanDefinition candidateComponent : candidateComponents) &#123; // @FeignClient直接标注在接口上 if (candidateComponent instanceof AnnotatedBeanDefinition) &#123; AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent; AnnotationMetadata annotationMetadata = beanDefinition.getMetadata(); Assert.isTrue(annotationMetadata.isInterface(), \"@FeignClient can only be specified on an interface\"); Map&lt;String, Object&gt; attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getCanonicalName()); String name = getClientName(attributes); // 获取配置的客户端名称 registerClientConfiguration(registry, name, attributes.get(\"configuration\")); registerFeignClient(registry, annotationMetadata, attributes); &#125; &#125; &#125; &#125; private String getClientName(Map&lt;String, Object&gt; client) &#123; if (client == null) &#123; return null; &#125; String value = (String) client.get(\"contextId\"); if (!StringUtils.hasText(value)) &#123; // 获取@FeignClient注解的value属性值 value = (String) client.get(\"value\"); &#125; if (!StringUtils.hasText(value)) &#123; // 获取@FeignClient注解的name属性值 value = (String) client.get(\"name\"); &#125; if (!StringUtils.hasText(value)) &#123; // 获取@FeignClient注解的serviceId属性值 value = (String) client.get(\"serviceId\"); &#125; if (StringUtils.hasText(value)) &#123; return value; &#125; throw new IllegalStateException(\"Either 'name' or 'value' must be provided in @\" + FeignClient.class.getSimpleName()); &#125; private void registerFeignClient(BeanDefinitionRegistry registry, AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) &#123; String className = annotationMetadata.getClassName(); // 获取@FeignClient注解标注的接口的全限定名 // 将BeanDefinition的beanClass设置为FeignClientFactoryBean.class BeanDefinitionBuilder definition = BeanDefinitionBuilder.genericBeanDefinition(FeignClientFactoryBean.class); validate(attributes); // 校验@FeignClient注解fallback和fallbackFactory属性 definition.addPropertyValue(\"url\", getUrl(attributes)); // 若@FeignClient注解中配置的是url对其进行处理 definition.addPropertyValue(\"path\", getPath(attributes)); // 对@FeignClient注解中配置的是path属性进行处理 String name = getName(attributes); // 获取配置的客户端名称，即value或name或serviceId属性中配置的值，优先级从低到高 definition.addPropertyValue(\"name\", name); String contextId = getContextId(attributes); // 若默认未配置contextId注解，则默认为上面获取到的客户端名称name definition.addPropertyValue(\"contextId\", contextId); definition.addPropertyValue(\"type\", className); // 这里将原接口的Type设置到了FeignClientFactoryBean中，便于通过类型注入 definition.addPropertyValue(\"decode404\", attributes.get(\"decode404\")); definition.addPropertyValue(\"fallback\", attributes.get(\"fallback\")); definition.addPropertyValue(\"fallbackFactory\", attributes.get(\"fallbackFactory\")); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); String alias = contextId + \"FeignClient\"; AbstractBeanDefinition beanDefinition = definition.getBeanDefinition(); beanDefinition.setAttribute(FactoryBean.OBJECT_TYPE_ATTRIBUTE, className); boolean primary = (Boolean) attributes.get(\"primary\"); beanDefinition.setPrimary(primary); String qualifier = getQualifier(attributes); if (StringUtils.hasText(qualifier)) &#123; alias = qualifier; &#125; BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className, new String[] &#123; alias &#125;); BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry); &#125; public static BeanDefinitionBuilder genericBeanDefinition(Class&lt;?&gt; beanClass) &#123; BeanDefinitionBuilder builder = new BeanDefinitionBuilder(new GenericBeanDefinition()); builder.beanDefinition.setBeanClass(beanClass); // 将BeanDefinition的beanClass设置为FeignClientFactoryBean.class return builder; &#125;&#125; 由于@FeignClient注解只能标注在接口上，而Spring容器中的Bean不能是接口，故这里通过FactoryBean的子类FeignClientFactoryBean来完成将被@FeignClient注解标注接口注册到Spring容器中。 1234567891011121314151617181920212223242526272829303132333435class FeignClientFactoryBean implements FactoryBean&lt;Object&gt;, InitializingBean, ApplicationContextAware &#123; public Object getObject() throws Exception &#123; return getTarget(); &#125; &lt;T&gt; T getTarget() &#123; FeignContext context = applicationContext.getBean(FeignContext.class); Feign.Builder builder = feign(context); // 对具体的Client接口进行配置，如encoder、decoder、retryer等 if (!StringUtils.hasText(url)) &#123; if (!name.startsWith(\"http\")) &#123; url = \"http://\" + name; &#125; else &#123; url = name; &#125; url += cleanPath(); // 对url进行拼接，例：http://mall-order/order // 若FeignClient没有地址属性，用JDK动态代理生成FeignBlockingLoadBalancerClient代理 return (T) loadBalance(builder, context, new HardCodedTarget&lt;&gt;(type, name, url)); &#125; if (StringUtils.hasText(url) &amp;&amp; !url.startsWith(\"http\")) &#123; url = \"http://\" + url; &#125; String url = this.url + cleanPath(); Client client = getOptional(context, Client.class); if (client != null) &#123; if (client instanceof LoadBalancerFeignClient) &#123; client = ((LoadBalancerFeignClient) client).getDelegate(); &#125; if (client instanceof FeignBlockingLoadBalancerClient) &#123; client = ((FeignBlockingLoadBalancerClient) client).getDelegate(); &#125; builder.client(client); &#125; Targeter targeter = get(context, Targeter.class); return (T) targeter.target(this, builder, context, new HardCodedTarget&lt;&gt;(type, name, url)); &#125;&#125; 用JDK动态代理生成FeignBlockingLoadBalancerClient代理，通过Feign接口时通过代理类最终会调用FeignBlockingLoadBalancerClient代理类的execute方法，最终会通过LoadBalancerClient去获取ServiceInstance让后调用具体的服务。 123456789101112131415161718192021222324public class FeignBlockingLoadBalancerClient implements Client &#123; private final Client delegate; private final BlockingLoadBalancerClient loadBalancerClient; public FeignBlockingLoadBalancerClient(Client delegate, BlockingLoadBalancerClient loadBalancerClient) &#123; this.delegate = delegate; this.loadBalancerClient = loadBalancerClient; &#125; public Response execute(Request request, Request.Options options) throws IOException &#123; final URI originalUri = URI.create(request.url()); String serviceId = originalUri.getHost(); Assert.state(serviceId != null, \"Request URI does not contain a valid hostname: \" + originalUri); ServiceInstance instance = loadBalancerClient.choose(serviceId); if (instance == null) &#123; return Response.builder().request(request) .status(HttpStatus.SERVICE_UNAVAILABLE.value()) .body(message, StandardCharsets.UTF_8).build(); &#125; String reconstructedUrl = loadBalancerClient.reconstructURI(instance, originalUri).toString(); Request newRequest = Request.create(request.httpMethod(), reconstructedUrl, request.headers(), request.body(), request.charset(), request.requestTemplate()); return delegate.execute(newRequest, options); &#125;&#125; Feign中默认使用JDK原生的URLConnection发送HTTP请求，可集成别的组件来替换掉URLConnection，如Apache HttpClient，OkHttp等。Feign发起调用真正执行逻辑： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public interface Client &#123; class Default implements Client &#123; public Response execute(Request request, Options options) throws IOException &#123; HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection, request); &#125; &#125;&#125;@ConditionalOnClass(Feign.class)@ConditionalOnBean(BlockingLoadBalancerClient.class)@AutoConfigureBefore(FeignAutoConfiguration.class)@AutoConfigureAfter(FeignRibbonClientAutoConfiguration.class)@EnableConfigurationProperties(FeignHttpClientProperties.class)@Configuration(proxyBeanMethods = false)@Import(&#123; HttpClientFeignLoadBalancerConfiguration.class, OkHttpFeignLoadBalancerConfiguration.class, DefaultFeignLoadBalancerConfiguration.class &#125;)public class FeignLoadBalancerAutoConfiguration &#123;&#125;@Configuration(proxyBeanMethods = false)@ConditionalOnClass(ApacheHttpClient.class)@ConditionalOnBean(BlockingLoadBalancerClient.class)@ConditionalOnProperty(value = \"feign.httpclient.enabled\", matchIfMissing = true)@Import(HttpClientFeignConfiguration.class)class HttpClientFeignLoadBalancerConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(BlockingLoadBalancerClient loadBalancerClient, HttpClient httpClient) &#123; ApacheHttpClient delegate = new ApacheHttpClient(httpClient); return new FeignBlockingLoadBalancerClient(delegate, loadBalancerClient); &#125;&#125;@Configuration(proxyBeanMethods = false)@ConditionalOnClass(OkHttpClient.class)@ConditionalOnProperty(\"feign.okhttp.enabled\")@ConditionalOnBean(BlockingLoadBalancerClient.class)@Import(OkHttpFeignConfiguration.class)class OkHttpFeignLoadBalancerConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(okhttp3.OkHttpClient okHttpClient, BlockingLoadBalancerClient loadBalancerClient) &#123; OkHttpClient delegate = new OkHttpClient(okHttpClient); return new FeignBlockingLoadBalancerClient(delegate, loadBalancerClient); &#125;&#125;@Configuration(proxyBeanMethods = false)class DefaultFeignLoadBalancerConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(BlockingLoadBalancerClient loadBalancerClient) &#123; return new FeignBlockingLoadBalancerClient(new Client.Default(null, null), loadBalancerClient); &#125;&#125;","tags":[{"name":"Feign","slug":"Feign","permalink":"https://yaoyinglong.github.io/tags/Feign/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"}]},{"title":"Gateway源码","date":"2021-11-09T16:00:00.000Z","path":"Blog/Cloud/网关/Gateway源码/","text":"网关作为流量的入口，常用的功能包括路由转发，权限校验，限流等，Spring Cloud Gateway是Spring Cloud官方推出的由WebFlux + Netty + Reactor实现的响应式的第二代API网关框架，定位于取代Netflix Zuul。 Spring Cloud Gateway的核心概念：路由Route、断言、过滤器。路由是网关中最基础的部分，路由信息包括一个ID、一个目的URI、一组断言工厂、一组Filter组成，若断言为真则说明请求的URL和配置的路由匹配；Spring Cloud Gateway中的断言函数类型是Spring5.0框架中的ServerWebExchange，允许开发者去定义匹配Http Request中的任何信息，如请求头和参数等；Spring Cloud Gateway的过滤器分为GatewayFilIer和GlobalFilter，可对请求和响应进行处理。 Spring Cloud Gateway工作原理跟Zuul的差不多，最大的区别就是Gateway的Filter只有pre和post两种，客户端向Spring Cloud Gateway发出请求，若请求与网关定义的路由匹配，则该请求会被发送到网关Web处理程序，此时处理程序运行特定的请求过滤器链。过滤器之间用虚线分开的原因是过滤器可能会在发送代理请求的前后执行逻辑。所有pre过滤器逻辑先执行，然后执行代理请求；代理请求完成后执行post过滤器逻辑。 Gateway对请求处理的核心逻辑是在DispatcherHandler中，在DispatcherHandler中依次调用HandlerMapping、HandlerAdapter、HandlerResultHandler三个核心接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DispatcherHandler implements WebHandler, ApplicationContextAware &#123; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; if (this.handlerMappings == null) &#123; return createNotFoundError(); &#125; return Flux.fromIterable(this.handlerMappings) .concatMap(mapping -&gt; mapping.getHandler(exchange)) // 获取具体的HandlerMapping，这里返回FilteringWebHandler .next() .switchIfEmpty(createNotFoundError()) // 若路由断言匹配未匹配到，则返回Empty，这里对Empty进行处理 .flatMap(handler -&gt; invokeHandler(exchange, handler)) // 调用具体的HandlerAdapter的handle .flatMap(result -&gt; handleResult(exchange, result)); &#125; private Mono&lt;HandlerResult&gt; invokeHandler(ServerWebExchange exchange, Object handler) &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter handlerAdapter : this.handlerAdapters) &#123; if (handlerAdapter.supports(handler)) &#123; return handlerAdapter.handle(exchange, handler); &#125; &#125; &#125; return Mono.error(new IllegalStateException(\"No HandlerAdapter: \" + handler)); &#125; private Mono&lt;Void&gt; handleResult(ServerWebExchange exchange, HandlerResult result) &#123; return getResultHandler(result).handleResult(exchange, result) .checkpoint(\"Handler \" + result.getHandler() + \" [DispatcherHandler]\") .onErrorResume(ex -&gt; result.applyExceptionHandler(ex).flatMap(exResult -&gt; &#123; String text = \"Exception handler \" + exResult.getHandler() + \", error=\\\"\" + ex.getMessage() + \"\\\" [DispatcherHandler]\"; return getResultHandler(exResult).handleResult(exchange, exResult).checkpoint(text); &#125;)); &#125; private HandlerResultHandler getResultHandler(HandlerResult handlerResult) &#123; if (this.resultHandlers != null) &#123; for (HandlerResultHandler resultHandler : this.resultHandlers) &#123; if (resultHandler.supports(handlerResult)) &#123; return resultHandler; &#125; &#125; &#125; throw new IllegalStateException(\"No HandlerResultHandler for \" + handlerResult.getReturnValue()); &#125; private &lt;R&gt; Mono&lt;R&gt; createNotFoundError() &#123; return Mono.defer(() -&gt; &#123; Exception ex = new ResponseStatusException(HttpStatus.NOT_FOUND, \"No matching handler\"); return Mono.error(ex); &#125;); &#125;&#125; HandlerMappingHandlerMapping负责路径到Handler的映射，Gateway中RoutePredicateHandlerMapping实现了AbstractHandlerMapping，其作用是执行所有的Route的断言工厂PredicateFactory匹配路由信息，通过断言判断路由是否可用，且将路由信息绑定到请求上下文中，最终返回FilteringWebHandler。 也可自定义断言工厂需继承AbstractRoutePredicateFactory类重写apply方法的逻辑。在apply方法中可以通过exchange.getRequest()拿到ServerHttpRequest对象，从而可获取到请求的参数、请求方式、请求头等信息。 12345678910111213141516public abstract class AbstractHandlerMapping extends ApplicationObjectSupport implements HandlerMapping, Ordered, BeanNameAware &#123; public Mono&lt;Object&gt; getHandler(ServerWebExchange exchange) &#123; return getHandlerInternal(exchange).map(handler -&gt; &#123; ServerHttpRequest request = exchange.getRequest(); if (hasCorsConfigurationSource(handler) || CorsUtils.isPreFlightRequest(request)) &#123; // 处理跨域问题 CorsConfiguration config = (this.corsConfigurationSource != null ? this.corsConfigurationSource.getCorsConfiguration(exchange) : null); CorsConfiguration handlerConfig = getCorsConfiguration(handler, exchange); config = (config != null ? config.combine(handlerConfig) : handlerConfig); if (!this.corsProcessor.process(config, exchange) || CorsUtils.isPreFlightRequest(request)) &#123; return REQUEST_HANDLED_HANDLER; &#125; &#125; return handler; &#125;); &#125;&#125; 首先通过lookupRoute方法找出所有与当前请求匹配的Route，在匹配之前从RouteLocator的实现类CachingRouteLocator中已经转换好的Route，在应用启动时会通过RouteLocator的实现类RouteDefinitionRouteLocator通过PropertiesRouteDefinitionLocator从GatewayProperties中读取路由配置RouteDefinition且将其转换为Route并缓存到CachingRouteLocator中。除此之外若在DiscoveryClientRouteDefinitionLocator会获取集群中所有的实例并将其构建成RouteDefinition，最终转换并合并到CachingRouteLocator中。 在lookupRoute中通过遍历所有的Route，并遍历调用其具体的PredicateFactory的test方法，过滤出其test方法放回true的route。然后将匹配的路由绑定到请求上下文中。最终返回FilteringWebHandler。 1234567891011121314151617181920212223242526public class RoutePredicateHandlerMapping extends AbstractHandlerMapping &#123; protected Mono&lt;?&gt; getHandlerInternal(ServerWebExchange exchange) &#123; if (this.managementPortType == DIFFERENT &amp;&amp; this.managementPort != null &amp;&amp; exchange.getRequest().getURI().getPort() == this.managementPort) &#123; return Mono.empty(); &#125; exchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName()); return lookupRoute(exchange).flatMap((Function&lt;Route, Mono&lt;?&gt;&gt;) r -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); exchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r); // 将匹配的路由绑定到请求上下文中，以便FilteringWebHandler的handle方法中使用 return Mono.just(webHandler); // 最终返回FilteringWebHandler &#125;).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -&gt; &#123; // 未找到匹配的路由 exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); &#125;))); &#125; protected Mono&lt;Route&gt; lookupRoute(ServerWebExchange exchange) &#123; return this.routeLocator.getRoutes().concatMap(route -&gt; Mono.just(route).filterWhen(r -&gt; &#123; exchange.getAttributes().put(GATEWAY_PREDICATE_ROUTE_ATTR, r.getId()); return r.getPredicate().apply(exchange); // 调用具体的PredicateFactory的test方法，过滤出test方法放回true的route &#125;).doOnError(e -&gt; logger.error(\"Error applying predicate for route: \" + route.getId(), e)).onErrorResume(e -&gt; Mono.empty())) .next() .map(route -&gt; &#123; validateRoute(route, exchange); return route; &#125;); &#125;&#125; HandlerAdapter调用具体的HandlerAdapter的调用，在DelegatingWebFluxConfiguration配置类的超类WebFluxConfigurationSupport中注入了SimpleHandlerAdapter。而FilteringWebHandler是WebHandler的子类。在SimpleHandlerAdapter的handle方法中调用FilteringWebHandler的handle方法。由于SimpleHandlerAdapter返回的是Mono.empty()故不会触发handleResult方法。 123456789101112public class SimpleHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return WebHandler.class.isAssignableFrom(handler.getClass()); &#125; @Override public Mono&lt;HandlerResult&gt; handle(ServerWebExchange exchange, Object handler) &#123; WebHandler webHandler = (WebHandler) handler; Mono&lt;Void&gt; mono = webHandler.handle(exchange); return mono.then(Mono.empty()); &#125;&#125; 在GatewayAutoConfiguration配置类中注入了FilteringWebHandler，由于全局的过滤器GlobalFilter与GatewayFilter故在其构造方法中通过适配器模式将GlobalFilter转换成了GatewayFilter。然后通过责任链模式挨个调用GatewayFilter的filter方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(name = \"spring.cloud.gateway.enabled\", matchIfMissing = true)@EnableConfigurationProperties@AutoConfigureBefore(&#123; HttpHandlerAutoConfiguration.class, WebFluxAutoConfiguration.class &#125;)@AutoConfigureAfter(&#123; GatewayLoadBalancerClientAutoConfiguration.class, GatewayClassPathWarningAutoConfiguration.class &#125;)@ConditionalOnClass(DispatcherHandler.class)public class GatewayAutoConfiguration &#123; public FilteringWebHandler filteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; return new FilteringWebHandler(globalFilters); &#125;&#125;public class FilteringWebHandler implements WebHandler &#123; private final List&lt;GatewayFilter&gt; globalFilters; public FilteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; this.globalFilters = loadFilters(globalFilters);// 通过适配器模式将GlobalFilter转换为GatewayFilter &#125; private static List&lt;GatewayFilter&gt; loadFilters(List&lt;GlobalFilter&gt; filters) &#123; return filters.stream().map(filter -&gt; &#123; GatewayFilterAdapter gatewayFilter = new GatewayFilterAdapter(filter); if (filter instanceof Ordered) &#123; int order = ((Ordered) filter).getOrder(); return new OrderedGatewayFilter(gatewayFilter, order); &#125; return gatewayFilter; &#125;).collect(Collectors.toList()); &#125; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; Route route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR); // 从请求上下文中取出前面绑定的Route List&lt;GatewayFilter&gt; gatewayFilters = route.getFilters(); // 获取Route中配置的filters List&lt;GatewayFilter&gt; combined = new ArrayList&lt;&gt;(this.globalFilters); combined.addAll(gatewayFilters); // 合并配置的filters和自动注入的全局的filters AnnotationAwareOrderComparator.sort(combined); // 对GatewayFilter列表排序 return new DefaultGatewayFilterChain(combined).filter(exchange); &#125;&#125;private static class DefaultGatewayFilterChain implements GatewayFilterChain &#123; private final int index; private final List&lt;GatewayFilter&gt; filters; DefaultGatewayFilterChain(List&lt;GatewayFilter&gt; filters) &#123; this.filters = filters; this.index = 0; &#125; private DefaultGatewayFilterChain(DefaultGatewayFilterChain parent, int index) &#123; this.filters = parent.getFilters(); this.index = index; &#125; public Mono&lt;Void&gt; filter(ServerWebExchange exchange) &#123; return Mono.defer(() -&gt; &#123; if (this.index &lt; filters.size()) &#123; GatewayFilter filter = filters.get(this.index); DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1); return filter.filter(exchange, chain); &#125; else &#123; return Mono.empty(); // complete &#125; &#125;); &#125;&#125; 也可自定义GatewayFilter，自定义GatewayFilter是通过自定义过滤器工厂来完成的，自定义工厂可集成一些列的AbstractGatewayFilterFactory来完成响应的功能，还可通过实现GlobalFilter来自定义全局的过滤器。对于uri支持lb://的方式类配置目标微服务的请求地址，就是通过LoadBalancerClientFilter过滤器来完成的。 123456789101112131415161718192021222324252627282930313233343536373839public class LoadBalancerClientFilter implements GlobalFilter, Ordered &#123; public static final int LOAD_BALANCER_CLIENT_FILTER_ORDER = 10100; protected final LoadBalancerClient loadBalancer; private LoadBalancerProperties properties; public LoadBalancerClientFilter(LoadBalancerClient loadBalancer, LoadBalancerProperties properties) &#123; this.loadBalancer = loadBalancer; this.properties = properties; &#125; public int getOrder() &#123; return LOAD_BALANCER_CLIENT_FILTER_ORDER; &#125; @Override @SuppressWarnings(\"Duplicates\") public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; URI url = exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR); String schemePrefix = exchange.getAttribute(GATEWAY_SCHEME_PREFIX_ATTR); if (url == null || (!\"lb\".equals(url.getScheme()) &amp;&amp; !\"lb\".equals(schemePrefix))) &#123; return chain.filter(exchange); &#125; addOriginalRequestUrl(exchange, url); final ServiceInstance instance = choose(exchange); if (instance == null) &#123; throw NotFoundException.create(properties.isUse404(), \"Unable to find instance for \" + url.getHost()); &#125; URI uri = exchange.getRequest().getURI(); String overrideScheme = instance.isSecure() ? \"https\" : \"http\"; if (schemePrefix != null) &#123; overrideScheme = url.getScheme(); &#125; URI requestUrl = loadBalancer.reconstructURI(new DelegatingServiceInstance(instance, overrideScheme), uri); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, requestUrl); return chain.filter(exchange); &#125; protected ServiceInstance choose(ServerWebExchange exchange) &#123; // 通过负载均衡算法获取具体的实例对象 return loadBalancer.choose(((URI) exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR)).getHost()); &#125;&#125;","tags":[{"name":"网关","slug":"网关","permalink":"https://yaoyinglong.github.io/tags/网关/"},{"name":"Gateway","slug":"Gateway","permalink":"https://yaoyinglong.github.io/tags/Gateway/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"网关","slug":"Cloud/网关","permalink":"https://yaoyinglong.github.io/categories/Cloud/网关/"}]},{"title":"Seata分布式事务原理","date":"2021-11-08T16:00:00.000Z","path":"Blog/Cloud/Seata/Seata分布式事务原理/","text":"以下是分布式事务的核心逻辑，确切的说是Seata中TM事务管理器的核心逻辑，跟本地事务的核心逻辑很类似，Seata的AT模式也是基于本地事务的，对本地事务的处理都是通过代理对象DataSourceProxy来完成的，DataSourceProxy是RM资源管理器的具体实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class TransactionalTemplate &#123; public Object execute(TransactionalExecutor business) throws Throwable &#123; // 1. Get transactionInfo TransactionInfo txInfo = business.getTransactionInfo(); if (txInfo == null) &#123; throw new ShouldNeverHappenException(\"transactionInfo does not exist\"); &#125; // 获取当前全局事务，若不为空，则交易角色为GlobalTransactionRole.Participant GlobalTransaction tx = GlobalTransactionContext.getCurrent(); Propagation propagation = txInfo.getPropagation(); // 获取当前全局事务的传播属性 SuspendedResourcesHolder suspendedResourcesHolder = null; try &#123; switch (propagation) &#123; // 根据事务的传播属性做相应的处理 case NOT_SUPPORTED: // 若事务存在，则将其暂停 if (existingTransaction(tx)) &#123; suspendedResourcesHolder = tx.suspend(); &#125; return business.execute(); // 若不存在事务则直接执行业务方法 case REQUIRES_NEW: // 若事务存在，则暂停它，然后开始新的事务 if (existingTransaction(tx)) &#123; suspendedResourcesHolder = tx.suspend(); tx = GlobalTransactionContext.createNew(); &#125; break; // 继续执行新的事务 case SUPPORTS: // 若事务不存在，则在没有事务的情况下执行 if (notExistingTransaction(tx)) &#123; return business.execute(); &#125; break; // 若事务存在，继续执行事务 case REQUIRED: // 若当前事务存在，则使用当前事务执行，否则继续并使用新事务执行 break; case NEVER: // 若事务存在，则抛出异常 if (existingTransaction(tx)) &#123; throw new TransactionException(String.format(\"Existing transaction found for transaction marked with propagation 'never', xid = %s\", tx.getXid())); &#125; else &#123; // 直接执行业务方法 return business.execute(); &#125; case MANDATORY: // 事务不存在，则抛出异常。 if (notExistingTransaction(tx)) &#123; throw new TransactionException(\"No existing transaction found for transaction marked with propagation 'mandatory'\"); &#125; break; // 继续并执行当前事务。 default: throw new TransactionException(\"Not Supported Propagation:\" + propagation); &#125; if (tx == null) &#123; // 若当前全局事务为null，则创建角色为GlobalTransactionRole.Launcher的新事务 tx = GlobalTransactionContext.createNew(); &#125; // set current tx config to holder GlobalLockConfig previousConfig = replaceGlobalLockConfig(txInfo); try &#123;// 若tx角色是GlobalTransactionRole.Launcher，则发送beginTransaction的请求给TC，否则什么都不做 beginTransaction(txInfo, tx); // 开启全局事务 Object rs; try &#123;// Do Your Business rs = business.execute(); // 执行业务逻辑 &#125; catch (Throwable ex) &#123; // 回滚所需的业务异常 completeTransactionAfterThrowing(txInfo, tx, ex); throw ex; &#125; commitTransaction(tx); // 提交全局事务 return rs; &#125; finally &#123; //5. clear resumeGlobalLockConfig(previousConfig); triggerAfterCompletion(); cleanUp(); &#125; &#125; finally &#123; // If the transaction is suspended, resume it. if (suspendedResourcesHolder != null) &#123; tx.resume(suspendedResourcesHolder); &#125; &#125; &#125;&#125; 首先是获取当前全局事务，首先通过RootContext获取全局事务的Xid，若Xid不为空则说明是嵌套事务，则通过Xid创建一个角色为Participant的GlobalTransaction。这个角色是非常重要的。然后根据事务的传播属性作相应的处理。 123456789101112131415public class GlobalTransactionContext &#123; public static GlobalTransaction getCurrent() &#123; String xid = RootContext.getXID(); if (xid == null) &#123; return null; &#125; return new DefaultGlobalTransaction(xid, GlobalStatus.Begin, GlobalTransactionRole.Participant); &#125; public static GlobalTransaction createNew() &#123; return new DefaultGlobalTransaction(); &#125;&#125;DefaultGlobalTransaction() &#123; this(null, GlobalStatus.UnKnown, GlobalTransactionRole.Launcher);&#125; 开启全局事务若全局事务GlobalTransaction角色是GlobalTransactionRole.Launcher，则向TC事务协调者发送开启全局事务请求且获取全局事务Xid，若角色为Participant则说明是嵌套事务或分支事务，不需要开启新的全局事务故直接返回。若需要开启全局事务，则通过RPC向TC发送开启全局事务请求，并获取全局事务Xid并通过RootContext绑定到线程上下文中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class TransactionalTemplate &#123; private void beginTransaction(TransactionInfo txInfo, GlobalTransaction tx) throws TransactionalExecutor.ExecutionException &#123; try &#123; triggerBeforeBegin(); tx.begin(txInfo.getTimeOut(), txInfo.getName()); // 开启全局事务 triggerAfterBegin(); &#125; catch (TransactionException txe) &#123; throw new TransactionalExecutor.ExecutionException(tx, txe, TransactionalExecutor.Code.BeginFailure); &#125; &#125;&#125;public class DefaultGlobalTransaction implements GlobalTransaction &#123; public void begin(int timeout, String name) throws TransactionException &#123; if (role != GlobalTransactionRole.Launcher) &#123; assertXIDNotNull(); return; // 调用者业务方法可能多重嵌套创建多个GlobalTransaction对象开启事务方法，故GlobalTransaction有GlobalTransactionRole角色属性，只有Launcher角色的才有开启、提交、回滚事务的权利 &#125; assertXIDNull(); String currentXid = RootContext.getXID(); if (currentXid != null) &#123; throw new IllegalStateException(\"Global transaction already exists, can't begin a new global transaction, currentXid = \" + currentXid); &#125; xid = transactionManager.begin(null, null, name, timeout); // 获取全局事务id status = GlobalStatus.Begin; // 设置全局事务未begin状态 RootContext.bind(xid); // 将xid保存到线程上下文中 &#125;&#125;public class DefaultTransactionManager implements TransactionManager &#123; public String begin(String applicationId, String transactionServiceGroup, String name, int timeout) throws TransactionException &#123; GlobalBeginRequest request = new GlobalBeginRequest(); request.setTransactionName(name); request.setTimeout(timeout); GlobalBeginResponse response = (GlobalBeginResponse) syncCall(request); // 同步RPC调用Seata-Server服务获取全局事务id if (response.getResultCode() == ResultCode.Failed) &#123; throw new TmTransactionException(TransactionExceptionCode.BeginFailed, response.getMsg()); &#125; return response.getXid(); // 获取RPC调用返回的全局事务Id，xid结构：idAddress + \":\" + port + \":\" + tranId &#125; private AbstractTransactionResponse syncCall(AbstractTransactionRequest request) throws TransactionException &#123; try &#123; return (AbstractTransactionResponse) TmNettyRemotingClient.getInstance().sendSyncRequest(request); &#125; catch (TimeoutException toe) &#123; throw new TmTransactionException(TransactionExceptionCode.IO, \"RPC timeout\", toe); &#125; &#125;&#125; 最终RPC掉到事务协调者TC的DefaultCoordinator的doGlobalBegin方法，默认超时时间是60s。通过ipAddress、port、transactionId生成全局唯一的事务Xid，并最终将全局事务信息插入global_table表中。且将全局事务Xid返回给事务管理器TM。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class DefaultCoordinator extends AbstractTCInboundHandler implements TransactionMessageHandler, Disposable &#123; protected void doGlobalBegin(GlobalBeginRequest request, GlobalBeginResponse response, RpcContext rpcContext) throws TransactionException &#123; response.setXid(core.begin(rpcContext.getApplicationId(), rpcContext.getTransactionServiceGroup(), request.getTransactionName(), request.getTimeout())); &#125;&#125;public class DefaultCore implements Core &#123; public String begin(String applicationId, String transactionServiceGroup, String name, int timeout) throws TransactionException &#123; GlobalSession session = GlobalSession.createGlobalSession(applicationId, transactionServiceGroup, name, timeout); // 生成全局session // SessionHolder中根据配置的mode类型，通过解析SessionManager实现类上的@LoadLevel注解加载具体的SessionManager session.addSessionLifecycleListener(SessionHolder.getRootSessionManager()); session.begin(); // seata支持三种存储方式：file、db、redis，在seata-server的file.conf中指定store.mode eventBus.post(new GlobalTransactionEvent(session.getTransactionId(), GlobalTransactionEvent.ROLE_TC, session.getTransactionName(), session.getBeginTime(), null, session.getStatus())); return session.getXid(); &#125;&#125;public class GlobalSession implements SessionLifecycle, SessionStorable &#123; public void begin() throws TransactionException &#123; this.status = GlobalStatus.Begin; this.beginTime = System.currentTimeMillis(); this.active = true; for (SessionLifecycleListener lifecycleListener : lifecycleListeners) &#123; lifecycleListener.onBegin(this); // 调用AbstractSessionManager的onBegin存储生成的GlobalSession &#125; &#125;&#125;public class GlobalSession implements SessionLifecycle, SessionStorable &#123; public static GlobalSession createGlobalSession(String applicationId, String txServiceGroup, String txName, int timeout) &#123; GlobalSession session = new GlobalSession(applicationId, txServiceGroup, txName, timeout); return session; &#125; public GlobalSession(String applicationId, String transactionServiceGroup, String transactionName, int timeout) &#123; this.transactionId = UUIDGenerator.generateUUID(); this.status = GlobalStatus.Begin; this.applicationId = applicationId; this.transactionServiceGroup = transactionServiceGroup; this.transactionName = transactionName; this.timeout = timeout; this.xid = XID.generateXID(transactionId); &#125;&#125;public class XID &#123; public static String generateXID(long tranId) &#123; return ipAddress + \":\" + port + \":\" + tranId; &#125;&#125;public abstract class AbstractSessionManager implements SessionManager, SessionLifecycleListener &#123; public void onBegin(GlobalSession globalSession) throws TransactionException &#123; addGlobalSession(globalSession); // 调用具体的SessionManager的addGlobalSession方法存储生成的GlobalSession &#125;&#125;@LoadLevel(name = \"db\", scope = Scope.PROTOTYPE)public class DataBaseSessionManager extends AbstractSessionManager implements Initialize &#123; public void addGlobalSession(GlobalSession session) throws TransactionException &#123; if (StringUtils.isBlank(taskName)) &#123;// 调用实现类DataBaseTransactionStoreManager的writeSession，将全局事务信息插入global_table表中 boolean ret = transactionStoreManager.writeSession(LogOperation.GLOBAL_ADD, session); if (!ret) &#123; throw new StoreException(\"addGlobalSession failed.\"); &#125; &#125; else &#123; boolean ret = transactionStoreManager.writeSession(LogOperation.GLOBAL_UPDATE, session); if (!ret) &#123; throw new StoreException(\"addGlobalSession failed.\"); &#125; &#125; &#125;&#125; 分支事务执行分支事务的执行是依赖于本地事务，通过DataSourceProxy代理类创建的ConnectionProxy来完成分支事务的提交回滚等操作，通过ConnectionProxy代理类中创建的PreparedStatementProxy来完成具体SQL的执行。若获取不到全局锁或不是AT模式则直接执行本地事务。根据具体SQL类型获取到具体的事务执行器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class PreparedStatementProxy extends AbstractPreparedStatementProxy implements PreparedStatement, ParametersHolder &#123; public boolean execute() throws SQLException &#123; return ExecuteTemplate.execute(this, (statement, args) -&gt; statement.execute()); &#125;&#125;public class ExecuteTemplate &#123; public static &lt;T, S extends Statement&gt; T execute(StatementProxy&lt;S&gt; statementProxy, StatementCallback&lt;T, S&gt; statementCallback, Object... args) throws SQLException &#123; return execute(null, statementProxy, statementCallback, args); &#125; public static &lt;T, S extends Statement&gt; T execute(List&lt;SQLRecognizer&gt; sqlRecognizers, StatementProxy&lt;S&gt; statementProxy, StatementCallback&lt;T, S&gt; statementCallback, Object... args) throws SQLException &#123; if (!RootContext.requireGlobalLock() &amp;&amp; BranchType.AT != RootContext.getBranchType()) &#123; // 若不能获取到全局锁 或不是AT模式 则直接执行本地事务 return statementCallback.execute(statementProxy.getTargetStatement(), args); &#125; String dbType = statementProxy.getConnectionProxy().getDbType(); if (CollectionUtils.isEmpty(sqlRecognizers)) &#123; sqlRecognizers = SQLVisitorFactory.get(statementProxy.getTargetSQL(), dbType); &#125; Executor&lt;T&gt; executor; if (CollectionUtils.isEmpty(sqlRecognizers)) &#123; executor = new PlainExecutor&lt;&gt;(statementProxy, statementCallback); &#125; else &#123; if (sqlRecognizers.size() == 1) &#123; SQLRecognizer sqlRecognizer = sqlRecognizers.get(0); switch (sqlRecognizer.getSQLType()) &#123; case INSERT: // 根据具体的dbType以及@LoadLevel加载具体的InsertExecutor，这里以MySQLInsertExecutor为例 executor = EnhancedServiceLoader.load(InsertExecutor.class, dbType, new Class[]&#123;StatementProxy.class, StatementCallback.class, SQLRecognizer.class&#125;, new Object[]&#123;statementProxy, statementCallback, sqlRecognizer&#125;); break; case UPDATE: executor = new UpdateExecutor&lt;&gt;(statementProxy, statementCallback, sqlRecognizer); break; case DELETE: executor = new DeleteExecutor&lt;&gt;(statementProxy, statementCallback, sqlRecognizer); break; case SELECT_FOR_UPDATE: executor = new SelectForUpdateExecutor&lt;&gt;(statementProxy, statementCallback, sqlRecognizer); break; default: executor = new PlainExecutor&lt;&gt;(statementProxy, statementCallback); break; &#125; &#125; else &#123; executor = new MultiExecutor&lt;&gt;(statementProxy, statementCallback, sqlRecognizers); &#125; &#125; T rs; try &#123; // 调用MySQLInsertExecutor的超类BaseTransactionalExecutor的execute方法 rs = executor.execute(args); &#125; catch (Throwable ex) &#123; if (!(ex instanceof SQLException)) &#123; ex = new SQLException(ex); &#125; throw (SQLException) ex; &#125; return rs; &#125;&#125; 执行分支事务时首先绑定全局事务Xid，将事务的自动提交设置为false，若发生锁冲突会失败重试默认重试次数为30次，且LockRetryPolicy清理undo日志、锁的key且本地事务回滚。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public abstract class BaseTransactionalExecutor&lt;T, S extends Statement&gt; implements Executor&lt;T&gt; &#123; public T execute(Object... args) throws Throwable &#123; String xid = RootContext.getXID(); if (xid != null) &#123; statementProxy.getConnectionProxy().bind(xid); // 绑定全局事务Id &#125; statementProxy.getConnectionProxy().setGlobalLockRequire(RootContext.requireGlobalLock()); return doExecute(args); // 调用超类AbstractDMLBaseExecutor的doExecute &#125;&#125;public abstract class AbstractDMLBaseExecutor&lt;T, S extends Statement&gt; extends BaseTransactionalExecutor&lt;T, S&gt; &#123; public T doExecute(Object... args) throws Throwable &#123; // 这里将事务的自动提交设置为手动提交 AbstractConnectionProxy connectionProxy = statementProxy.getConnectionProxy(); // 获取到代理的Connection if (connectionProxy.getAutoCommit()) &#123; return executeAutoCommitTrue(args); // 本地事务提交逻辑，这里会将事务设置为手动提交 &#125; else &#123; return executeAutoCommitFalse(args); // 设置本地事务提交逻辑为手动提交 &#125; &#125; protected T executeAutoCommitTrue(Object[] args) throws Throwable &#123; ConnectionProxy connectionProxy = statementProxy.getConnectionProxy(); try &#123; connectionProxy.setAutoCommit(false); // 设置本地事务为手动提交 return new LockRetryPolicy(connectionProxy).execute(() -&gt; &#123; T result = executeAutoCommitFalse(args); connectionProxy.commit(); return result; &#125;); &#125; catch (Exception e) &#123; if (!LockRetryPolicy.isLockRetryPolicyBranchRollbackOnConflict()) &#123; connectionProxy.getTargetConnection().rollback(); // 回滚本地事务 &#125; throw e; &#125; finally &#123; connectionProxy.getContext().reset(); connectionProxy.setAutoCommit(true); &#125; &#125; public &lt;T&gt; T execute(Callable&lt;T&gt; callable) throws Exception &#123; if (LOCK_RETRY_POLICY_BRANCH_ROLLBACK_ON_CONFLICT) &#123; // 默认为true return doRetryOnLockConflict(callable); &#125; else &#123; return callable.call(); &#125; &#125; protected &lt;T&gt; T doRetryOnLockConflict(Callable&lt;T&gt; callable) throws Exception &#123; LockRetryController lockRetryController = new LockRetryController(); while (true) &#123; try &#123; return callable.call(); // 调用doCommit()方法分支事务注册 &#125; catch (LockConflictException lockConflict) &#123; onException(lockConflict); // LockRetryPolicy清理undo日志，锁的key，且本地事务回滚 lockRetryController.sleep(lockConflict); &#125; catch (Exception e) &#123; onException(e); throw e; &#125; &#125; &#125; protected void onException(Exception e) throws Exception &#123; ConnectionContext context = connection.getContext(); context.getUndoItems().clear(); context.getLockKeysBuffer().clear(); connection.getTargetConnection().rollback(); &#125;&#125;public class LockRetryController &#123; public void sleep(Exception e) throws LockWaitTimeoutException &#123; if (--lockRetryTimes &lt; 0) &#123; // lockRetryTimes默认30次 throw new LockWaitTimeoutException(\"Global lock wait timeout\", e); &#125; try &#123; Thread.sleep(lockRetryInternal); // 默认休眠10ms &#125; catch (InterruptedException ignore) &#123; &#125; &#125; &#125; 最终会调用executeAutoCommitFalse方法来生成前置镜像，执行本地事务SQL，以及生成后置镜像，且通过前置镜像和后置镜像生成undo_log且将其保存到缓存中。 12345678910111213141516171819202122232425public abstract class AbstractDMLBaseExecutor&lt;T, S extends Statement&gt; extends BaseTransactionalExecutor&lt;T, S&gt; &#123; protected T executeAutoCommitFalse(Object[] args) throws Exception &#123; if (!JdbcConstants.MYSQL.equalsIgnoreCase(getDbType()) &amp;&amp; isMultiPk()) &#123; throw new NotSupportYetException(\"multi pk only support mysql!\"); &#125; TableRecords beforeImage = beforeImage(); // 生成前置镜像 T result = statementCallback.execute(statementProxy.getTargetStatement(), args); // 执行业务SQL TableRecords afterImage = afterImage(beforeImage); // BaseInsertExecutor生成后置镜像，为了查后置镜像事务隔离级别为读未提交 prepareUndoLog(beforeImage, afterImage); // 通过前置镜像和后置镜像生成undo log回滚日志 return result; &#125;&#125;public abstract class BaseTransactionalExecutor&lt;T, S extends Statement&gt; implements Executor&lt;T&gt; &#123; protected void prepareUndoLog(TableRecords beforeImage, TableRecords afterImage) throws SQLException &#123; if (beforeImage.getRows().isEmpty() &amp;&amp; afterImage.getRows().isEmpty()) &#123; return; &#125; ConnectionProxy connectionProxy = statementProxy.getConnectionProxy(); TableRecords lockKeyRecords = sqlRecognizer.getSQLType() == SQLType.DELETE ? beforeImage : afterImage; String lockKeys = buildLockKey(lockKeyRecords); connectionProxy.appendLockKey(lockKeys); SQLUndoLog sqlUndoLog = buildUndoItem(beforeImage, afterImage); // 将前置镜像和后置镜像封装为SQLUndoLog connectionProxy.appendUndoLog(sqlUndoLog); // 缓存sqlUndoLog对象，并未插入到数据库 &#125;&#125; 然后调用ConnectionProxy的commit方法完成分支事务注册，然后将undo日志保存到undo_log表中，以及本地事务提交。内层的事务提交不会再走锁冲突重试机制了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ConnectionProxy extends AbstractConnectionProxy &#123; public void commit() throws SQLException &#123; try &#123; LOCK_RETRY_POLICY.execute(() -&gt; &#123; doCommit(); return null; &#125;); &#125; catch (SQLException e) &#123; if (targetConnection != null &amp;&amp; !getAutoCommit()) &#123; rollback(); &#125; throw e; &#125; catch (Exception e) &#123; throw new SQLException(e); &#125; &#125; private void doCommit() throws SQLException &#123; if (context.inGlobalTransaction()) &#123; processGlobalTransactionCommit(); // 分支事务注册，发起BranchRegisterRequest请求，返回分支branchId，保存undolog，数据库本地事务提交 &#125; else if (context.isGlobalLockRequire()) &#123; processLocalCommitWithGlobalLocks(); // 数据库本地事务提交 &#125; else &#123; targetConnection.commit(); // 数据库本地事务提交 &#125; &#125; private void processGlobalTransactionCommit() throws SQLException &#123; try &#123; register(); // 注册分支事务 &#125; catch (TransactionException e) &#123; recognizeLockKeyConflictException(e, context.buildLockKeys()); &#125; try &#123; // 根据具体的dbType获取具体的UndoLogManager，这里以MySQLUndoLogManager为例 UndoLogManagerFactory.getUndoLogManager(this.getDbType()).flushUndoLogs(this); // 保存undolog到undo_log表中 targetConnection.commit(); // 数据库本地事务提交 &#125; catch (Throwable ex) &#123; report(false); throw new SQLException(ex); &#125; if (IS_REPORT_SUCCESS_ENABLE) &#123; report(true); &#125; context.reset(); &#125;&#125;public static class LockRetryPolicy &#123; public &lt;T&gt; T execute(Callable&lt;T&gt; callable) throws Exception &#123; if (LOCK_RETRY_POLICY_BRANCH_ROLLBACK_ON_CONFLICT) &#123; // 默认为true return callable.call(); &#125; else &#123; // 若为false，会有锁的重试机制 return doRetryOnLockConflict(callable); &#125; &#125;&#125; 分支事务注册，通过资源管理器RM向TC发起分支事务注册请求请求，返回分支branchId且将其绑定到ConnectionContext中。 12345678910public class ConnectionProxy extends AbstractConnectionProxy &#123; private void register() throws TransactionException &#123; if (!context.hasUndoLog() || context.getLockKeysBuffer().isEmpty()) &#123; return; &#125; // 分支事务注册，发起BranchRegisterRequest请求，返回分支branchId Long branchId = DefaultResourceManager.get().branchRegister(BranchType.AT, getDataSourceProxy().getResourceId(), null, context.getXid(), null, context.buildLockKeys()); context.setBranchId(branchId); &#125;&#125; 通过RPC注册分支事务最终执行DefaultCoordinator的doBranchRegister方法，首先通过全局事务Xid从global_table表中查询全局事务检查其是否存在。然后获取全局锁且收集行锁，将其保存到lock_table表中，最后将分支事务信息保存到branch_table表中，然后返回分支事务branchId。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class DefaultCoordinator extends AbstractTCInboundHandler implements TransactionMessageHandler, Disposable &#123; protected void doBranchRegister(BranchRegisterRequest request, BranchRegisterResponse response, RpcContext rpcContext) throws TransactionException &#123; // 注册分支事务，返回branchId response.setBranchId(core.branchRegister(request.getBranchType(), request.getResourceId(), rpcContext.getClientId(), request.getXid(), request.getApplicationData(), request.getLockKey())); &#125;&#125;public class DefaultCore implements Core &#123; public Long branchRegister(BranchType branchType, String resourceId, String clientId, String xid, String applicationData, String lockKeys) throws TransactionException &#123; return getCore(branchType).branchRegister(branchType, resourceId, clientId, xid, applicationData, lockKeys); &#125;&#125;public abstract class AbstractCore implements Core &#123; public Long branchRegister(BranchType branchType, String resourceId, String clientId, String xid, String applicationData, String lockKeys) throws TransactionException &#123; GlobalSession globalSession = assertGlobalSessionNotNull(xid, false); return SessionHolder.lockAndExecute(globalSession, () -&gt; &#123; globalSessionStatusCheck(globalSession); globalSession.addSessionLifecycleListener(SessionHolder.getRootSessionManager()); BranchSession branchSession = SessionHelper.newBranchByGlobal(globalSession, branchType, resourceId, applicationData, lockKeys, clientId); branchSessionLock(globalSession, branchSession); // 获取全局锁，且收集行锁，将其保存到lock_table表 try &#123; globalSession.addBranch(branchSession); // 向全局Session中添加分支session &#125; catch (RuntimeException ex) &#123; branchSessionUnlock(branchSession); // 释放全局锁，DB模式将删除lock_table表对应记录 throw new BranchTransactionException(FailedToAddBranch, String.format(\"Failed to store branch xid = %s branchId = %s\", globalSession.getXid(), branchSession.getBranchId()), ex); &#125; return branchSession.getBranchId(); &#125;); &#125; private GlobalSession assertGlobalSessionNotNull(String xid, boolean withBranchSessions) throws TransactionException &#123; // DB模式，从数据库获取GlobalSession，若withBranchSessions为true则包括分支事务信息 GlobalSession globalSession = SessionHolder.findGlobalSession(xid, withBranchSessions); if (globalSession == null) &#123; // 若查询不到可能是事务超时了，则抛出异常 throw new GlobalTransactionException(TransactionExceptionCode.GlobalTransactionNotExist, String.format(\"Could not found global transaction xid = %s, may be has finished.\", xid)); &#125; return globalSession; &#125;&#125;public class GlobalSession implements SessionLifecycle, SessionStorable &#123; public void addBranch(BranchSession branchSession) throws TransactionException &#123; for (SessionLifecycleListener lifecycleListener : lifecycleListeners) &#123; lifecycleListener.onAddBranch(this, branchSession); // 将分支事务信息保存到branch_table表中 &#125; branchSession.setStatus(BranchStatus.Registered); // 设置分支session状态是已注册 add(branchSession); &#125; &#125;@LoadLevel(name = \"db\", scope = Scope.PROTOTYPE)public class DataBaseSessionManager extends AbstractSessionManager implements Initialize &#123; public void addBranchSession(GlobalSession globalSession, BranchSession session) throws TransactionException &#123; if (StringUtils.isNotBlank(taskName)) &#123; return; &#125; // 将分支事务信息插入branch_table表中 boolean ret = transactionStoreManager.writeSession(LogOperation.BRANCH_ADD, session); if (!ret) &#123; throw new StoreException(\"addBranchSession failed.\"); &#125; &#125;&#125; 若分支事务执行一次会调用rollback方法，然后RPC调用TC报告该分支事务执行失败，在TM向TC发送事务回滚请求时，TC遍历所有注册的分支事务时，会判断分支事务状态，若失败则不会在做多余的回调操作。 1234567891011121314151617181920212223242526public class ConnectionProxy extends AbstractConnectionProxy &#123; public void rollback() throws SQLException &#123; targetConnection.rollback(); // 回滚本地事务 if (context.inGlobalTransaction() &amp;&amp; context.isBranchRegistered()) &#123; report(false); // 报告TC分支事务执行失败 &#125; context.reset(); &#125; private void report(boolean commitDone) throws SQLException &#123; if (context.getBranchId() == null) &#123; return; &#125; int retry = REPORT_RETRY_COUNT; while (retry &gt; 0) &#123; try &#123; DefaultResourceManager.get().branchReport(BranchType.AT, context.getXid(), context.getBranchId(), commitDone ? BranchStatus.PhaseOne_Done : BranchStatus.PhaseOne_Failed, null); return; &#125; catch (Throwable ex) &#123; retry--; if (retry == 0) &#123; throw new SQLException(\"Failed to report branch status \" + commitDone, ex); &#125; &#125; &#125; &#125;&#125; 事务提交通过分布式事务的提交只能由TM的Launcher角色来完成，向TC发起全局事务提交请求，RPC调用DefaultCoordinator#doGlobalCommit，若事务提交失败会重试，默认5次。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class TransactionalTemplate &#123; private void commitTransaction(GlobalTransaction tx) throws TransactionalExecutor.ExecutionException &#123; try &#123; triggerBeforeCommit(); tx.commit(); // 提交全局事务 triggerAfterCommit(); &#125; catch (TransactionException txe) &#123;// 4.1 Failed to commit throw new TransactionalExecutor.ExecutionException(tx, txe, TransactionalExecutor.Code.CommitFailure); &#125; &#125;&#125;public class DefaultGlobalTransaction implements GlobalTransaction &#123; public void commit() throws TransactionException &#123; // 调用者业务方法可能多重嵌套创建多个GlobalTransaction对象开启事务方法，故GlobalTransaction有GlobalTransactionRole角色属性，只有Launcher角色的才有开启、提交、回滚事务的权利 if (role == GlobalTransactionRole.Participant) &#123; return; &#125; assertXIDNotNull(); int retry = COMMIT_RETRY_COUNT &lt;= 0 ? DEFAULT_TM_COMMIT_RETRY_COUNT : COMMIT_RETRY_COUNT; try &#123; while (retry &gt; 0) &#123; try &#123; // 发起全局事务提交，发起GlobalCommitRequest请求，RPC调用DefaultCoordinator#doGlobalCommit status = transactionManager.commit(xid); // 提交全局事务，若异常则重试，默认5次 break; &#125; catch (Throwable ex) &#123; retry--; if (retry == 0) &#123; throw new TransactionException(\"Failed to report global commit\", ex); &#125; &#125; &#125; &#125; finally &#123; if (xid.equals(RootContext.getXID())) &#123; suspend(); &#125; &#125; &#125; &#125;public class DefaultTransactionManager implements TransactionManager &#123; public GlobalStatus commit(String xid) throws TransactionException &#123; GlobalCommitRequest globalCommit = new GlobalCommitRequest(); globalCommit.setXid(xid); // 发起全局事务提交，发起GlobalCommitRequest请求，RPC调用DefaultCoordinator#doGlobalCommit GlobalCommitResponse response = (GlobalCommitResponse) syncCall(globalCommit); return response.getGlobalStatus(); &#125;&#125; TC收到提交事务请求后，首先检查当前全局事务是否存在，若不存在直接返回失败，若支持异步提交，则将全局事务的状态改为AsyncCommitting异步提交，然后通过异步任务提交分支事务。若不支持则同步调用doGlobalCommit方法遍历分支事务提交分支事务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class DefaultCoordinator extends AbstractTCInboundHandler implements TransactionMessageHandler, Disposable &#123; protected void doGlobalCommit(GlobalCommitRequest request, GlobalCommitResponse response, RpcContext rpcContext) throws TransactionException &#123; response.setGlobalStatus(core.commit(request.getXid())); &#125;&#125;public class DefaultCore implements Core &#123; public GlobalStatus commit(String xid) throws TransactionException &#123; GlobalSession globalSession = SessionHolder.findGlobalSession(xid); // DB模式查询global_table表 if (globalSession == null) &#123; // 若查询不到全局事务则返回失败 return GlobalStatus.Finished; &#125; globalSession.addSessionLifecycleListener(SessionHolder.getRootSessionManager()); // just lock changeStatus boolean shouldCommit = SessionHolder.lockAndExecute(globalSession, () -&gt; &#123; // Highlight: Firstly, close the session, then no more branch can be registered. globalSession.closeAndClean(); if (globalSession.getStatus() == GlobalStatus.Begin) &#123; if (globalSession.canBeCommittedAsync()) &#123; globalSession.asyncCommit(); // AT模式默认异步提交，正常情况下最终返回GlobalStatus.Committed return false; &#125; else &#123; globalSession.changeStatus(GlobalStatus.Committing); return true; // 同步提交分支事务 &#125; &#125; return false; &#125;); if (shouldCommit) &#123; // 若不支持异步提交，则同步提交分支事务 boolean success = doGlobalCommit(globalSession, false); if (success &amp;&amp; !globalSession.getBranchSessions().isEmpty()) &#123; globalSession.asyncCommit(); return GlobalStatus.Committed; &#125; else &#123; return globalSession.getStatus(); &#125; &#125; else &#123; return globalSession.getStatus() == GlobalStatus.AsyncCommitting ? GlobalStatus.Committed : globalSession.getStatus(); &#125; &#125;&#125;public class GlobalSession implements SessionLifecycle, SessionStorable &#123; public void asyncCommit() throws TransactionException &#123; // 被DefaultCoordinator#handleAsyncCommitting异步轮训处理AsyncCommitting任务 this.addSessionLifecycleListener(SessionHolder.getAsyncCommittingSessionManager()); // 更新global_table表记录中对应数据状态status为1即Begin SessionHolder.getAsyncCommittingSessionManager().addGlobalSession(this); this.changeStatus(GlobalStatus.AsyncCommitting); // 更新状态为GlobalStatus.AsyncCommitting &#125; &#125; 在事务协调者TC服务启动类Server的main方法中会调用DefaultCoordinator的init方法，从而初始化异步延时线程池用于异步提交分支事务。不论同步提交还是异步提交分支事务最终都是通过调用doGlobalCommit方法完成的。AT模式默认是支持异步提交分支事务。分支事务的提交是通过给每个分支资源管理器RM发送提交请求。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class DefaultCoordinator extends AbstractTCInboundHandler implements TransactionMessageHandler, Disposable &#123; private ScheduledThreadPoolExecutor asyncCommitting = new ScheduledThreadPoolExecutor(1, new NamedThreadFactory(\"AsyncCommitting\", 1)); protected void handleAsyncCommitting() &#123; Collection&lt;GlobalSession&gt; asyncCommittingSessions = SessionHolder.getAsyncCommittingSessionManager().allSessions(); if (CollectionUtils.isEmpty(asyncCommittingSessions)) &#123; return; &#125; for (GlobalSession asyncCommittingSession : asyncCommittingSessions) &#123; // 遍历全局事务 try &#123; if (GlobalStatus.AsyncCommitting != asyncCommittingSession.getStatus()) &#123; continue; &#125; asyncCommittingSession.addSessionLifecycleListener(SessionHolder.getRootSessionManager()); core.doGlobalCommit(asyncCommittingSession, true); // 遍历分支事务提交 &#125; catch (TransactionException ex) &#123; &#125; &#125; &#125; public void init() &#123; retryRollbacking.scheduleAtFixedRate(() -&gt; &#123; try &#123; handleRetryRollbacking(); // 初始化retryRollbacking定时任务线程池，默认间隔1s &#125; catch (Exception e) &#123; &#125; &#125;, 0, ROLLBACKING_RETRY_PERIOD, TimeUnit.MILLISECONDS); retryCommitting.scheduleAtFixedRate(() -&gt; &#123; try &#123; handleRetryCommitting(); // 初始化handleRetryCommitting定时任务线程池，默认间隔1s &#125; catch (Exception e) &#123; &#125; &#125;, 0, COMMITTING_RETRY_PERIOD, TimeUnit.MILLISECONDS); asyncCommitting.scheduleAtFixedRate(() -&gt; &#123; try &#123; handleAsyncCommitting(); // 初始化handleAsyncCommitting定时任务线程池，默认间隔1s &#125; catch (Exception e) &#123; &#125; &#125;, 0, ASYNC_COMMITTING_RETRY_PERIOD, TimeUnit.MILLISECONDS); timeoutCheck.scheduleAtFixedRate(() -&gt; &#123; try &#123; timeoutCheck(); &#125; catch (Exception e) &#123; &#125; &#125;, 0, TIMEOUT_RETRY_PERIOD, TimeUnit.MILLISECONDS); undoLogDelete.scheduleAtFixedRate(() -&gt; &#123; try &#123; undoLogDelete(); &#125; catch (Exception e) &#123; &#125; &#125;, UNDO_LOG_DELAY_DELETE_PERIOD, UNDO_LOG_DELETE_PERIOD, TimeUnit.MILLISECONDS); &#125;&#125;public class DefaultCore implements Core &#123; public boolean doGlobalCommit(GlobalSession globalSession, boolean retrying) throws TransactionException &#123; boolean success = true; eventBus.post(new GlobalTransactionEvent(globalSession.getTransactionId(), GlobalTransactionEvent.ROLE_TC, globalSession.getTransactionName(), globalSession.getBeginTime(), null, globalSession.getStatus())); if (globalSession.isSaga()) &#123; success = getCore(BranchType.SAGA).doGlobalCommit(globalSession, retrying); &#125; else &#123; for (BranchSession branchSession : globalSession.getSortedBranches()) &#123; if (!retrying &amp;&amp; branchSession.canBeCommittedAsync()) &#123; continue; // 如果不重试，请跳过canBeCommittedAsync分支 &#125; BranchStatus currentStatus = branchSession.getStatus(); if (currentStatus == BranchStatus.PhaseOne_Failed) &#123; // 当前分支事务状态为PhaseOne_Failed globalSession.removeBranch(branchSession); // 释放全局锁，删除branch_table信息，删除分支事务信息，移除缓存 continue; &#125; try &#123; // 提交分支事务，RPC调用AsyncWorker#doBranchCommits向RM发起BranchCommitRequest请求 BranchStatus branchStatus = getCore(branchSession.getBranchType()).branchCommit(globalSession, branchSession); switch (branchStatus) &#123; case PhaseTwo_Committed: // 提交成功 globalSession.removeBranch(branchSession); // 释放全局锁，删除branch_table信息，删除分支事务信息，移除缓存 continue; case PhaseTwo_CommitFailed_Unretryable: // 支持异步提交，则交给定时线程池处理 if (globalSession.canBeCommittedAsync()) &#123; continue; &#125; else &#123; SessionHelper.endCommitFailed(globalSession); return false; &#125; default: if (!retrying) &#123; globalSession.queueToRetryCommit(); return false; &#125; if (globalSession.canBeCommittedAsync()) &#123; continue; &#125; else &#123; return false; &#125; &#125; &#125; catch (Exception ex) &#123; if (!retrying) &#123; globalSession.queueToRetryCommit(); throw new TransactionException(ex); &#125; &#125; &#125; if (globalSession.hasBranch()) &#123; return false; &#125; &#125; if (success &amp;&amp; globalSession.getBranchSessions().isEmpty()) &#123; SessionHelper.endCommitted(globalSession); eventBus.post(new GlobalTransactionEvent(globalSession.getTransactionId(), GlobalTransactionEvent.ROLE_TC, globalSession.getTransactionName(), globalSession.getBeginTime(), System.currentTimeMillis(), globalSession.getStatus())); &#125; return success; &#125;&#125; TC发送的分支事务提交的请求最终会调用RM的AsyncWorker的branchCommit方法，将请求放入队列中，在init方法中创建了异步处理任务，隔1s执行一次，这里做的仅仅是删除undo_log表中对应的记录，AT模式本地事务在执行完成后就已提交，这里无需做特别的处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class AsyncWorker implements ResourceManagerInbound &#123; private static final BlockingQueue&lt;Phase2Context&gt; ASYNC_COMMIT_BUFFER = new LinkedBlockingQueue&lt;&gt;(ASYNC_COMMIT_BUFFER_LIMIT); public BranchStatus branchCommit(BranchType branchType, String xid, long branchId, String resourceId, String applicationData) throws TransactionException &#123; if (!ASYNC_COMMIT_BUFFER.offer(new Phase2Context(branchType, xid, branchId, resourceId, applicationData))) &#123; &#125; return BranchStatus.PhaseTwo_Committed; &#125; public synchronized void init() &#123; ScheduledExecutorService timerExecutor = new ScheduledThreadPoolExecutor(1, new NamedThreadFactory(\"AsyncWorker\", 1, true)); timerExecutor.scheduleAtFixedRate(() -&gt; &#123; try &#123; doBranchCommits(); &#125; catch (Throwable e) &#123; &#125; &#125;, 10, 1000 * 1, TimeUnit.MILLISECONDS); // 每1s执行一次 &#125; private void doBranchCommits() &#123; // 因为都成功了，无需回滚成功的数据，只需要删除生成的操作日志就行，采用异步方式，提高效率 if (ASYNC_COMMIT_BUFFER.isEmpty()) &#123; return; &#125; Map&lt;String, List&lt;Phase2Context&gt;&gt; mappedContexts = new HashMap&lt;&gt;(DEFAULT_RESOURCE_SIZE); List&lt;Phase2Context&gt; contextsGroupedByResourceId; while (!ASYNC_COMMIT_BUFFER.isEmpty()) &#123; Phase2Context commitContext = ASYNC_COMMIT_BUFFER.poll(); contextsGroupedByResourceId = CollectionUtils.computeIfAbsent(mappedContexts, commitContext.resourceId, key -&gt; new ArrayList&lt;&gt;()); contextsGroupedByResourceId.add(commitContext); &#125; for (Map.Entry&lt;String, List&lt;Phase2Context&gt;&gt; entry : mappedContexts.entrySet()) &#123; Connection conn = null; DataSourceProxy dataSourceProxy; try &#123; try &#123; DataSourceManager resourceManager = (DataSourceManager) DefaultResourceManager.get().getResourceManager(BranchType.AT); dataSourceProxy = resourceManager.get(entry.getKey()); if (dataSourceProxy == null) &#123; throw new ShouldNeverHappenException(\"Failed to find resource on \" + entry.getKey()); &#125; conn = dataSourceProxy.getPlainConnection(); &#125; catch (SQLException sqle) &#123; continue; &#125; contextsGroupedByResourceId = entry.getValue(); Set&lt;String&gt; xids = new LinkedHashSet&lt;&gt;(UNDOLOG_DELETE_LIMIT_SIZE); Set&lt;Long&gt; branchIds = new LinkedHashSet&lt;&gt;(UNDOLOG_DELETE_LIMIT_SIZE); for (Phase2Context commitContext : contextsGroupedByResourceId) &#123; xids.add(commitContext.xid); branchIds.add(commitContext.branchId); int maxSize = Math.max(xids.size(), branchIds.size()); if (maxSize == UNDOLOG_DELETE_LIMIT_SIZE) &#123; try &#123; // 删除undo_log记录 UndoLogManagerFactory.getUndoLogManager(dataSourceProxy.getDbType()).batchDeleteUndoLog(xids, branchIds, conn); &#125; catch (Exception ex) &#123; &#125; xids.clear(); branchIds.clear(); &#125; &#125; if (CollectionUtils.isEmpty(xids) || CollectionUtils.isEmpty(branchIds)) &#123; return; &#125; try &#123; // 删除undo_log记录 UndoLogManagerFactory.getUndoLogManager(dataSourceProxy.getDbType()).batchDeleteUndoLog(xids, branchIds, conn); &#125; catch (Exception ex) &#123; &#125; if (!conn.getAutoCommit()) &#123; conn.commit(); &#125; &#125; catch (Throwable e) &#123; LOGGER.error(e.getMessage(), e); try &#123; if (conn != null) &#123; conn.rollback(); &#125; &#125; catch (SQLException rollbackEx) &#123; &#125; &#125; finally &#123; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException closeEx) &#123; &#125; &#125; &#125; &#125; &#125;&#125; 事务回滚同事务的提交一样事务的回滚，也只能通过TM的Launcher角色才能发起，若回滚异常同样会重试5次，最终也是通过RPC调用TC执行回滚操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class TransactionalTemplate &#123; private void completeTransactionAfterThrowing(TransactionInfo txInfo, GlobalTransaction tx, Throwable originalException) throws TransactionalExecutor.ExecutionException &#123; //roll back if (txInfo != null &amp;&amp; txInfo.rollbackOn(originalException)) &#123; try &#123; rollbackTransaction(tx, originalException); // 异常回滚 &#125; catch (TransactionException txe) &#123; // Failed to rollback throw new TransactionalExecutor.ExecutionException(tx, txe, TransactionalExecutor.Code.RollbackFailure, originalException); &#125; &#125; else &#123; // not roll back on this exception, so commit commitTransaction(tx); &#125; &#125; private void rollbackTransaction(GlobalTransaction tx, Throwable originalException) throws TransactionException, TransactionalExecutor.ExecutionException &#123; triggerBeforeRollback(); tx.rollback(); triggerAfterRollback(); throw new TransactionalExecutor.ExecutionException(tx, GlobalStatus.RollbackRetrying.equals(tx.getLocalStatus()) ? TransactionalExecutor.Code.RollbackRetrying : TransactionalExecutor.Code.RollbackDone, originalException); &#125;&#125;public class DefaultGlobalTransaction implements GlobalTransaction &#123; public void rollback() throws TransactionException &#123; // 调用者业务方法可能多重嵌套创建多个GlobalTransaction对象开启事务方法，故GlobalTransaction有GlobalTransactionRole角色属性，只有Launcher角色的才有开启、提交、回滚事务的权利 if (role == GlobalTransactionRole.Participant) &#123; return; &#125; assertXIDNotNull(); int retry = ROLLBACK_RETRY_COUNT &lt;= 0 ? DEFAULT_TM_ROLLBACK_RETRY_COUNT : ROLLBACK_RETRY_COUNT; try &#123; while (retry &gt; 0) &#123; try &#123; // 调用DefaultTransactionManager获取回滚状态，出现异常会进行重试，默认5次 status = transactionManager.rollback(xid); break; &#125; catch (Throwable ex) &#123; retry--; if (retry == 0) &#123; throw new TransactionException(\"Failed to report global rollback\", ex); &#125; &#125; &#125; &#125; finally &#123; if (xid.equals(RootContext.getXID())) &#123; suspend(); &#125; &#125; &#125;&#125;public class DefaultTransactionManager implements TransactionManager &#123; public GlobalStatus rollback(String xid) throws TransactionException &#123; // 调用seata-server发起GlobalRollbackRequest GlobalRollbackRequest globalRollback = new GlobalRollbackRequest(); globalRollback.setXid(xid); GlobalRollbackResponse response = (GlobalRollbackResponse) syncCall(globalRollback); // RPC调用DefaultCoordinator#doGlobalRollback return response.getGlobalStatus(); // 获取RPC调用返回的全局事务状态 &#125;&#125; 最终通过TC的DefaultCoordinator的doGlobalRollback方法，遍历所有的分支事务给所有分支发送事务回滚通知，若回滚成功释放全局锁，删除branch_table信息，移除缓存。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class DefaultCoordinator extends AbstractTCInboundHandler implements TransactionMessageHandler, Disposable &#123; protected void doGlobalRollback(GlobalRollbackRequest request, GlobalRollbackResponse response, RpcContext rpcContext) throws TransactionException &#123; response.setGlobalStatus(core.rollback(request.getXid())); // 全局事务回滚 &#125;&#125;public class DefaultCore implements Core &#123; public GlobalStatus rollback(String xid) throws TransactionException &#123; GlobalSession globalSession = SessionHolder.findGlobalSession(xid); // DB模式从数据库获取GlobalSession信息 if (globalSession == null) &#123; return GlobalStatus.Finished; &#125; globalSession.addSessionLifecycleListener(SessionHolder.getRootSessionManager()); boolean shouldRollBack = SessionHolder.lockAndExecute(globalSession, () -&gt; &#123; globalSession.close(); if (globalSession.getStatus() == GlobalStatus.Begin) &#123; globalSession.changeStatus(GlobalStatus.Rollbacking); return true; &#125; return false; &#125;); if (!shouldRollBack) &#123; return globalSession.getStatus(); &#125; doGlobalRollback(globalSession, false); return globalSession.getStatus(); &#125; public boolean doGlobalRollback(GlobalSession globalSession, boolean retrying) throws TransactionException &#123; boolean success = true; // start rollback event eventBus.post(new GlobalTransactionEvent(globalSession.getTransactionId(), GlobalTransactionEvent.ROLE_TC, globalSession.getTransactionName(), globalSession.getBeginTime(), null, globalSession.getStatus())); if (globalSession.isSaga()) &#123; // 执行Saga模式的回滚逻辑 success = getCore(BranchType.SAGA).doGlobalRollback(globalSession, retrying); &#125; else &#123; for (BranchSession branchSession : globalSession.getReverseSortedBranches()) &#123; BranchStatus currentBranchStatus = branchSession.getStatus(); if (currentBranchStatus == BranchStatus.PhaseOne_Failed) &#123; // 若是第一阶段失败 globalSession.removeBranch(branchSession); // 删除分支事务信息，释放全局锁 continue; &#125; try &#123; BranchStatus branchStatus = branchRollback(globalSession, branchSession); // 分支事务回滚，返回分支事务状态 switch (branchStatus) &#123; case PhaseTwo_Rollbacked: globalSession.removeBranch(branchSession); // 删除分支事务信息，释放全局锁 continue; case PhaseTwo_RollbackFailed_Unretryable: // 返回TimeoutRollbackFailed或RollbackFailed SessionHelper.endRollbackFailed(globalSession); return false; default: if (!retrying) &#123; globalSession.queueToRetryRollback(); &#125; return false; &#125; &#125; catch (Exception ex) &#123; if (!retrying) &#123; globalSession.queueToRetryRollback(); &#125; throw new TransactionException(ex); &#125; &#125; GlobalSession globalSessionTwice = SessionHolder.findGlobalSession(globalSession.getXid()); if (globalSessionTwice != null &amp;&amp; globalSessionTwice.hasBranch()) &#123; return false; &#125; &#125; if (success) &#123; SessionHelper.endRollbacked(globalSession); // 删除全局事务 eventBus.post(new GlobalTransactionEvent(globalSession.getTransactionId(), GlobalTransactionEvent.ROLE_TC, globalSession.getTransactionName(), globalSession.getBeginTime(), System.currentTimeMillis(), globalSession.getStatus())); &#125; return success; &#125;&#125; 当RM收到TC的回滚通知后通过DataSourceManager的branchRollback进行响应的处理，主要逻辑是通过事务xid和分支事务branchId从undo_log表中查询出undo_log，然就将其解析遍历执行rollback补偿，最后将其从undo_log表中删除。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class DataSourceManager extends AbstractResourceManager implements Initialize &#123; public BranchStatus branchRollback(BranchType branchType, String xid, long branchId, String resourceId, String applicationData) throws TransactionException &#123; DataSourceProxy dataSourceProxy = get(resourceId); if (dataSourceProxy == null) &#123; throw new ShouldNeverHappenException(); &#125; try &#123; UndoLogManagerFactory.getUndoLogManager(dataSourceProxy.getDbType()).undo(dataSourceProxy, xid, branchId); &#125; catch (TransactionException te) &#123; if (te.getCode() == TransactionExceptionCode.BranchRollbackFailed_Unretriable) &#123; return BranchStatus.PhaseTwo_RollbackFailed_Unretryable; &#125; else &#123; return BranchStatus.PhaseTwo_RollbackFailed_Retryable; &#125; &#125; return BranchStatus.PhaseTwo_Rollbacked; // 返回BranchStatus &#125;&#125;public abstract class AbstractUndoLogManager implements UndoLogManager &#123; public void undo(DataSourceProxy dataSourceProxy, String xid, long branchId) throws TransactionException &#123; Connection conn = null; ResultSet rs = null; PreparedStatement selectPST = null; boolean originalAutoCommit = true; for (; ; ) &#123; try &#123; conn = dataSourceProxy.getPlainConnection(); if (originalAutoCommit = conn.getAutoCommit()) &#123; conn.setAutoCommit(false); &#125; selectPST = conn.prepareStatement(SELECT_UNDO_LOG_SQL); // Find UNDO LOG 找到undolog selectPST.setLong(1, branchId); selectPST.setString(2, xid); rs = selectPST.executeQuery(); boolean exists = false; while (rs.next()) &#123; exists = true; int state = rs.getInt(ClientTableColumnsName.UNDO_LOG_LOG_STATUS); if (!canUndo(state)) &#123; return; &#125; String contextString = rs.getString(ClientTableColumnsName.UNDO_LOG_CONTEXT); Map&lt;String, String&gt; context = parseContext(contextString); byte[] rollbackInfo = getRollbackInfo(rs); String serializer = context == null ? null : context.get(UndoLogConstants.SERIALIZER_KEY); UndoLogParser parser = serializer == null ? UndoLogParserFactory.getInstance() : UndoLogParserFactory.getInstance(serializer); BranchUndoLog branchUndoLog = parser.decode(rollbackInfo); try &#123; // put serializer name to local setCurrentSerializer(parser.getName()); List&lt;SQLUndoLog&gt; sqlUndoLogs = branchUndoLog.getSqlUndoLogs(); if (sqlUndoLogs.size() &gt; 1) &#123; Collections.reverse(sqlUndoLogs); &#125; for (SQLUndoLog sqlUndoLog : sqlUndoLogs) &#123; TableMeta tableMeta = TableMetaCacheFactory.getTableMetaCache(dataSourceProxy.getDbType()).getTableMeta(conn, sqlUndoLog.getTableName(), dataSourceProxy.getResourceId()); sqlUndoLog.setTableMeta(tableMeta); AbstractUndoExecutor undoExecutor = UndoExecutorFactory.getUndoExecutor(dataSourceProxy.getDbType(), sqlUndoLog); undoExecutor.executeOn(conn); // 执行rollback补偿 &#125; &#125; finally &#123; // remove serializer name removeCurrentSerializer(); &#125; &#125; if (exists) &#123; deleteUndoLog(xid, branchId, conn); // 删除undo_log conn.commit(); &#125; else &#123; insertUndoLogWithGlobalFinished(xid, branchId, UndoLogParserFactory.getInstance(), conn); conn.commit(); &#125; return; &#125; catch (SQLIntegrityConstraintViolationException e) &#123; &#125; catch (Throwable e) &#123; if (conn != null) &#123; try &#123; conn.rollback(); &#125; catch (SQLException rollbackEx) &#123; &#125; &#125; throw new BranchTransactionException(BranchRollbackFailed_Retriable, String.format(\"Branch session rollback failed and try again later xid = %s branchId = %s %s\", xid, branchId, e.getMessage()), e); &#125; finally &#123; try &#123; if (rs != null) &#123; rs.close(); &#125; if (selectPST != null) &#123; selectPST.close(); &#125; if (conn != null) &#123; if (originalAutoCommit) &#123; conn.setAutoCommit(true); &#125; conn.close(); &#125; &#125; catch (SQLException closeEx) &#123; &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"分布式事务","slug":"分布式事务","permalink":"https://yaoyinglong.github.io/tags/分布式事务/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Seata","slug":"Cloud/Seata","permalink":"https://yaoyinglong.github.io/categories/Cloud/Seata/"}]},{"title":"Seata集成原理","date":"2021-11-07T16:00:00.000Z","path":"Blog/Cloud/Seata/Seata集成原理/","text":"Seata的集成包括两部分，一部分是对@GlobalTransactional、@GlobalLock等分布式事务注解的支持，一方面是对分支事务用到的一些RPC组件的处理，如RestTemplate、Feign以及添加SeataHandlerInterceptor等。 对于@GlobalTransactional、@GlobalLock等分布式事务注解支持是通过SeataAutoConfiguration配置类中注入的GlobalTransactionScanner来完成。该类实现了InitializingBean接口在其初始化时，会通过afterPropertiesSet方法初始化资源管理器RMClient和事务管理器TMClient。且该类还实现了AbstractAutoProxyCreator接口，在Bean初始化时通过后置处理器给Bean上或Bean的方法上带有@GlobalTransactional、@GlobalLock注解的Bean创建代理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798@ComponentScan(basePackages = \"io.seata.spring.boot.autoconfigure.properties\")@ConditionalOnProperty(prefix = StarterConstants.SEATA_PREFIX, name = \"enabled\", havingValue = \"true\", matchIfMissing = true)@Configuration@EnableConfigurationProperties(&#123;SeataProperties.class&#125;)public class SeataAutoConfiguration &#123; @Bean @DependsOn(&#123;BEAN_NAME_SPRING_APPLICATION_CONTEXT_PROVIDER, BEAN_NAME_FAILURE_HANDLER&#125;) @ConditionalOnMissingBean(GlobalTransactionScanner.class) public GlobalTransactionScanner globalTransactionScanner(SeataProperties seataProperties, FailureHandler failureHandler) &#123; return new GlobalTransactionScanner(seataProperties.getApplicationId(), seataProperties.getTxServiceGroup(), failureHandler); &#125;&#125;public class GlobalTransactionScanner extends AbstractAutoProxyCreator implements ConfigurationChangeListener, InitializingBean, ApplicationContextAware, DisposableBean &#123; public void afterPropertiesSet() &#123; // 初始化TMClient以及RMClient ConfigurationCache.addConfigListener(ConfigurationKeys.DISABLE_GLOBAL_TRANSACTION, (ConfigurationChangeListener)this); if (disableGlobalTransaction) &#123; return; &#125; if (initialized.compareAndSet(false, true)) &#123; initClient(); &#125; &#125; private void initClient() &#123; if (StringUtils.isNullOrEmpty(applicationId) || StringUtils.isNullOrEmpty(txServiceGroup)) &#123; throw new IllegalArgumentException(String.format(\"applicationId: %s, txServiceGroup: %s\", applicationId, txServiceGroup)); &#125; TMClient.init(applicationId, txServiceGroup, accessKey, secretKey); // 初始化TMClient RMClient.init(applicationId, txServiceGroup); // 初始化RMClient registerSpringShutdownHook(); &#125; protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; try &#123; // AOP逻辑，初始化Bean的后置处理器中调用此方法，添加全局事务拦截器 synchronized (PROXYED_SET) &#123; if (PROXYED_SET.contains(beanName)) &#123; return bean; &#125; interceptor = null; if (TCCBeanParserUtils.isTccAutoProxy(bean, beanName, applicationContext)) &#123; // TCC模式 interceptor = new TccActionInterceptor(TCCBeanParserUtils.getRemotingDesc(beanName)); ConfigurationCache.addConfigListener(ConfigurationKeys.DISABLE_GLOBAL_TRANSACTION, (ConfigurationChangeListener)interceptor); &#125; else &#123; // 使用@GlobalTransactional或者@GlobalLock注解 Class&lt;?&gt; serviceInterface = SpringProxyUtils.findTargetClass(bean); Class&lt;?&gt;[] interfacesIfJdk = SpringProxyUtils.findInterfaces(bean); if (!existsAnnotation(new Class[]&#123;serviceInterface&#125;) &amp;&amp; !existsAnnotation(interfacesIfJdk)) &#123; return bean; // 若不存在@GlobalTransactional注解直接跳过生成AOP代理 &#125; if (interceptor == null) &#123; if (globalTransactionalInterceptor == null) &#123; globalTransactionalInterceptor = new GlobalTransactionalInterceptor(failureHandlerHook); ConfigurationCache.addConfigListener(ConfigurationKeys.DISABLE_GLOBAL_TRANSACTION, (ConfigurationChangeListener)globalTransactionalInterceptor); &#125; interceptor = globalTransactionalInterceptor; &#125; &#125; if (!AopUtils.isAopProxy(bean)) &#123; bean = super.wrapIfNecessary(bean, beanName, cacheKey); &#125; else &#123; AdvisedSupport advised = SpringProxyUtils.getAdvisedSupport(bean); // getAdvicesAndAdvisorsForBean方法是 Advisor[] advisor = buildAdvisors(beanName, getAdvicesAndAdvisorsForBean(null, null, null)); for (Advisor avr : advisor) &#123; advised.addAdvisor(0, avr); &#125; &#125; PROXYED_SET.add(beanName); return bean; &#125; &#125; catch (Exception exx) &#123; throw new RuntimeException(exx); &#125; &#125; private boolean existsAnnotation(Class&lt;?&gt;[] classes) &#123; if (CollectionUtils.isNotEmpty(classes)) &#123; for (Class&lt;?&gt; clazz : classes) &#123; if (clazz == null) &#123; continue; &#125; GlobalTransactional trxAnno = clazz.getAnnotation(GlobalTransactional.class); if (trxAnno != null) &#123; // 类上是否被标注@GlobalTransactional注解 return true; &#125; Method[] methods = clazz.getMethods(); for (Method method : methods) &#123; trxAnno = method.getAnnotation(GlobalTransactional.class); if (trxAnno != null) &#123; // 方法上是否被标注@GlobalTransactional注解 return true; &#125; GlobalLock lockAnno = method.getAnnotation(GlobalLock.class); if (lockAnno != null) &#123; // 方法上是否被标注@GlobalLock注解 return true; &#125; &#125; &#125; &#125; return false; &#125;&#125; 执行带有@GlobalTransactional注解的方法执行时会被GlobalTransactionalInterceptor拦截调用其invoke方法。最终通过TransactionalTemplate的execute来执行全局事务方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class GlobalTransactionalInterceptor implements ConfigurationChangeListener, MethodInterceptor &#123; private final TransactionalTemplate transactionalTemplate = new TransactionalTemplate(); private final GlobalLockTemplate globalLockTemplate = new GlobalLockTemplate(); public Object invoke(final MethodInvocation methodInvocation) throws Throwable &#123; Class&lt;?&gt; targetClass = methodInvocation.getThis() != null ? AopUtils.getTargetClass(methodInvocation.getThis()) : null; Method specificMethod = ClassUtils.getMostSpecificMethod(methodInvocation.getMethod(), targetClass); if (specificMethod != null &amp;&amp; !specificMethod.getDeclaringClass().equals(Object.class)) &#123; final Method method = BridgeMethodResolver.findBridgedMethod(specificMethod); final GlobalTransactional globalTransactionalAnnotation = getAnnotation(method, targetClass, GlobalTransactional.class); final GlobalLock globalLockAnnotation = getAnnotation(method, targetClass, GlobalLock.class); boolean localDisable = disable || (degradeCheck &amp;&amp; degradeNum &gt;= degradeCheckAllowTimes); if (!localDisable) &#123; if (globalTransactionalAnnotation != null) &#123; // 处理被标注了@GlobalTransactional注解的方法 return handleGlobalTransaction(methodInvocation, globalTransactionalAnnotation); &#125; else if (globalLockAnnotation != null) &#123; // 处理被标注了@GlobalLock注解的方法 return handleGlobalLock(methodInvocation, globalLockAnnotation); &#125; &#125; &#125; return methodInvocation.proceed(); &#125; Object handleGlobalTransaction(final MethodInvocation methodInvocation, final GlobalTransactional globalTrxAnno) throws Throwable &#123; boolean succeed = true; try &#123; return transactionalTemplate.execute(new TransactionalExecutor() &#123; @Override public Object execute() throws Throwable &#123; return methodInvocation.proceed(); &#125; public String name() &#123; String name = globalTrxAnno.name(); if (!StringUtils.isNullOrEmpty(name)) &#123; return name; // 在@GlobalTransactional注解中声明了事务名称 &#125; return formatMethod(methodInvocation.getMethod()); // 被@GlobalTransactional注解标注的方法的签名 &#125; @Override public TransactionInfo getTransactionInfo() &#123; // reset the value of timeout int timeout = globalTrxAnno.timeoutMills(); // 全局事务超时时间 if (timeout &lt;= 0 || timeout == DEFAULT_GLOBAL_TRANSACTION_TIMEOUT) &#123; timeout = defaultGlobalTransactionTimeout; &#125; TransactionInfo transactionInfo = new TransactionInfo(); transactionInfo.setTimeOut(timeout); transactionInfo.setName(name()); transactionInfo.setPropagation(globalTrxAnno.propagation()); transactionInfo.setLockRetryInternal(globalTrxAnno.lockRetryInternal()); transactionInfo.setLockRetryTimes(globalTrxAnno.lockRetryTimes()); Set&lt;RollbackRule&gt; rollbackRules = new LinkedHashSet&lt;&gt;(); for (Class&lt;?&gt; rbRule : globalTrxAnno.rollbackFor()) &#123; rollbackRules.add(new RollbackRule(rbRule)); &#125; for (String rbRule : globalTrxAnno.rollbackForClassName()) &#123; rollbackRules.add(new RollbackRule(rbRule)); &#125; for (Class&lt;?&gt; rbRule : globalTrxAnno.noRollbackFor()) &#123; rollbackRules.add(new NoRollbackRule(rbRule)); &#125; for (String rbRule : globalTrxAnno.noRollbackForClassName()) &#123; rollbackRules.add(new NoRollbackRule(rbRule)); &#125; transactionInfo.setRollbackRules(rollbackRules); return transactionInfo; &#125; &#125;); &#125; catch (TransactionalExecutor.ExecutionException e) &#123; TransactionalExecutor.Code code = e.getCode(); switch (code) &#123; case RollbackDone: throw e.getOriginalException(); case BeginFailure: succeed = false; failureHandler.onBeginFailure(e.getTransaction(), e.getCause()); throw e.getCause(); case CommitFailure: succeed = false; failureHandler.onCommitFailure(e.getTransaction(), e.getCause()); throw e.getCause(); case RollbackFailure: failureHandler.onRollbackFailure(e.getTransaction(), e.getOriginalException()); throw e.getOriginalException(); case RollbackRetrying: failureHandler.onRollbackRetrying(e.getTransaction(), e.getOriginalException()); throw e.getOriginalException(); default: throw new ShouldNeverHappenException(String.format(\"Unknown TransactionalExecutor.Code: %s\", code)); &#125; &#125; finally &#123; if (degradeCheck) &#123; EVENT_BUS.post(new DegradeCheckEvent(succeed)); &#125; &#125; &#125;&#125; TransactionalTemplate中是全局事务的核心逻辑，首先获取当前全局事务，若不为空则说明是分支事务，则将交易角色设置为GlobalTransactionRole.Participant，然后根据事务的传播属性做相应的处理，若为新事务则创建角色为GlobalTransactionRole.Launcher的新事务，且发送beginTransaction的请求给事务协调者TC获取全局事务的Xid。然后执行业务逻辑，在业务逻辑中有分支事务的对分支事务处理，若发生异常则有Launcher角色向事务协调者TC发送回滚请求，从而通过undo_log回滚所有分支事务，若事务成功也是由Launcher角色向事务协调者TC发送提交请求。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class TransactionalTemplate &#123; public Object execute(TransactionalExecutor business) throws Throwable &#123; // 1. Get transactionInfo TransactionInfo txInfo = business.getTransactionInfo(); if (txInfo == null) &#123; throw new ShouldNeverHappenException(\"transactionInfo does not exist\"); &#125; // 获取当前全局事务，若不为空，则交易角色为GlobalTransactionRole.Participant GlobalTransaction tx = GlobalTransactionContext.getCurrent(); Propagation propagation = txInfo.getPropagation(); // 获取当前全局事务的传播属性 SuspendedResourcesHolder suspendedResourcesHolder = null; try &#123; switch (propagation) &#123; // 根据事务的传播属性做相应的处理 case NOT_SUPPORTED: // 若事务存在，则将其暂停 if (existingTransaction(tx)) &#123; // 判断tx是否为null suspendedResourcesHolder = tx.suspend(); &#125; return business.execute(); // 若不存在事务则直接执行业务方法 case REQUIRES_NEW: // 若事务存在，则暂停它，然后开始新的事务 if (existingTransaction(tx)) &#123; // 判断tx是否为null suspendedResourcesHolder = tx.suspend(); tx = GlobalTransactionContext.createNew(); &#125; break; // 继续执行新的事务 case SUPPORTS: // 若事务不存在，则在没有事务的情况下执行 if (notExistingTransaction(tx)) &#123; // 判断tx是否为null return business.execute(); &#125; break; // 若事务存在，继续执行事务 case REQUIRED: // 若当前事务存在，则使用当前事务执行，否则继续并使用新事务执行 break; case NEVER: // 若事务存在，则抛出异常 if (existingTransaction(tx)) &#123; // 判断tx是否为null throw new TransactionException(String.format(\"Existing transaction found for transaction marked with propagation 'never', xid = %s\", tx.getXid())); &#125; else &#123; // 直接执行业务方法 return business.execute(); &#125; case MANDATORY: // 事务不存在，则抛出异常。 if (notExistingTransaction(tx)) &#123; throw new TransactionException(\"No existing transaction found for transaction marked with propagation 'mandatory'\"); &#125; break; // 继续并执行当前事务。 default: throw new TransactionException(\"Not Supported Propagation:\" + propagation); &#125; if (tx == null) &#123; // 若当前全局事务为null，则创建角色为GlobalTransactionRole.Launcher的新事务 tx = GlobalTransactionContext.createNew(); &#125; // set current tx config to holder GlobalLockConfig previousConfig = replaceGlobalLockConfig(txInfo); try &#123;// 若tx角色是GlobalTransactionRole.Launcher，则发送beginTransaction的请求给TC，否则什么都不做 beginTransaction(txInfo, tx); // 开启全局事务 Object rs; try &#123;// Do Your Business rs = business.execute(); // 执行业务逻辑 &#125; catch (Throwable ex) &#123; // 回滚所需的业务异常 completeTransactionAfterThrowing(txInfo, tx, ex); throw ex; &#125; commitTransaction(tx); // 提交全局事务 return rs; &#125; finally &#123; //5. clear resumeGlobalLockConfig(previousConfig); triggerAfterCompletion(); cleanUp(); &#125; &#125; finally &#123; // If the transaction is suspended, resume it. if (suspendedResourcesHolder != null) &#123; tx.resume(suspendedResourcesHolder); &#125; &#125; &#125;&#125;public static GlobalTransaction getCurrent() &#123; String xid = RootContext.getXID(); // 从上下文中获取全局事务Xid if (xid == null) &#123; // 获取不到则说明是新事务 return null; &#125; return new DefaultGlobalTransaction(xid, GlobalStatus.Begin, GlobalTransactionRole.Participant);&#125; 数据源代理通过@EnableAutoDataSourceProxy中导入的AutoDataSourceProxyRegistrar类完成SeataDataSourceBeanPostProcessor和SeataAutoDataSourceProxyCreator类的注入。 123456789101112131415161718192021222324252627282930313233343536373839404142@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(AutoDataSourceProxyRegistrar.class)@Documentedpublic @interface EnableAutoDataSourceProxy &#123; boolean useJdkProxy() default false; String[] excludes() default &#123;&#125;; String dataSourceProxyMode() default \"AT\"; // 默认AT模式&#125;public class AutoDataSourceProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; private static final String ATTRIBUTE_KEY_USE_JDK_PROXY = \"useJdkProxy\"; private static final String ATTRIBUTE_KEY_EXCLUDES = \"excludes\"; private static final String ATTRIBUTE_KEY_DATA_SOURCE_PROXY_MODE = \"dataSourceProxyMode\"; public static final String BEAN_NAME_SEATA_DATA_SOURCE_BEAN_POST_PROCESSOR = \"seataDataSourceBeanPostProcessor\"; public static final String BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR = \"seataAutoDataSourceProxyCreator\"; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; Map&lt;String, Object&gt; annotationAttributes = importingClassMetadata.getAnnotationAttributes(EnableAutoDataSourceProxy.class.getName()); boolean useJdkProxy = Boolean.parseBoolean(annotationAttributes.get(ATTRIBUTE_KEY_USE_JDK_PROXY).toString()); String[] excludes = (String[]) annotationAttributes.get(ATTRIBUTE_KEY_EXCLUDES); String dataSourceProxyMode = (String) annotationAttributes.get(ATTRIBUTE_KEY_DATA_SOURCE_PROXY_MODE); //register seataDataSourceBeanPostProcessor bean def if (!registry.containsBeanDefinition(BEAN_NAME_SEATA_DATA_SOURCE_BEAN_POST_PROCESSOR)) &#123; AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder .genericBeanDefinition(SeataDataSourceBeanPostProcessor.class) .addConstructorArgValue(excludes) .addConstructorArgValue(dataSourceProxyMode) .getBeanDefinition(); registry.registerBeanDefinition(BEAN_NAME_SEATA_DATA_SOURCE_BEAN_POST_PROCESSOR, beanDefinition); &#125; //register seataAutoDataSourceProxyCreator bean def if (!registry.containsBeanDefinition(BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR)) &#123; AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder .genericBeanDefinition(SeataAutoDataSourceProxyCreator.class) .addConstructorArgValue(useJdkProxy) .addConstructorArgValue(excludes) .addConstructorArgValue(dataSourceProxyMode) .getBeanDefinition(); registry.registerBeanDefinition(BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR, beanDefinition); &#125; &#125;&#125; 不仅仅需要对@GlobalTransactional注解的支持，还需要对数据源DataSource对象创建DataSourceProxy代理。该逻辑是在SeataAutoConfiguration配置类中的SeataDataSourceConfiguration来完成。 1234567891011121314@Configuration@ConditionalOnProperty(prefix = StarterConstants.SEATA_PREFIX, name = &#123;\"enableAutoDataSourceProxy\", \"enable-auto-data-source-proxy\"&#125;, havingValue = \"true\", matchIfMissing = true)static class SeataDataSourceConfiguration &#123; @Bean(BEAN_NAME_SEATA_DATA_SOURCE_BEAN_POST_PROCESSOR) @ConditionalOnMissingBean(SeataDataSourceBeanPostProcessor.class) public SeataDataSourceBeanPostProcessor seataDataSourceBeanPostProcessor(SeataProperties seataProperties) &#123; return new SeataDataSourceBeanPostProcessor(seataProperties.getExcludesForAutoProxying(), seataProperties.getDataSourceProxyMode()); &#125; @Bean(BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR) @ConditionalOnMissingBean(SeataAutoDataSourceProxyCreator.class) public SeataAutoDataSourceProxyCreator seataAutoDataSourceProxyCreator(SeataProperties seataProperties) &#123; return new SeataAutoDataSourceProxyCreator(seataProperties.isUseJdkProxy(), seataProperties.getExcludesForAutoProxying(), seataProperties.getDataSourceProxyMode()); &#125;&#125; 首先通过SeataDataSourceBeanPostProcessor后置处理器，在DataSource初始化完成后创建一个DataSourceProxy代理将其缓存到dataSourceProxyMap中。然后通过AbstractAutoProxyCreator的子类SeataAutoDataSourceProxyCreator给所有的DataSource真正的创建代理，在执行所有的DataSource的方法时会调用SeataAutoDataSourceProxyAdvice的Invoke方法，从dataSourceProxyMap中获取对应的缓存的代理对象，从而调用代理对象中的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class SeataDataSourceBeanPostProcessor implements BeanPostProcessor &#123; private final List&lt;String&gt; excludes; private final BranchType dataSourceProxyMode; public SeataDataSourceBeanPostProcessor(String[] excludes, String dataSourceProxyMode) &#123; this.excludes = Arrays.asList(excludes); this.dataSourceProxyMode = BranchType.XA.name().equalsIgnoreCase(dataSourceProxyMode) ? BranchType.XA : BranchType.AT; &#125; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof DataSource) &#123; // 给数据源创建代理对象 //When not in the excludes, put and init proxy. if (!excludes.contains(bean.getClass().getName())) &#123; // 对代理对象初始化 DataSourceProxyHolder.get().putDataSource((DataSource) bean, dataSourceProxyMode); &#125; if (bean instanceof SeataDataSourceProxy) &#123; return ((SeataDataSourceProxy) bean).getTargetDataSource(); &#125; &#125; return bean; &#125;&#125;public class DataSourceProxyHolder &#123; private static final int MAP_INITIAL_CAPACITY = 8; private ConcurrentHashMap&lt;DataSource, SeataDataSourceProxy&gt; dataSourceProxyMap; public SeataDataSourceProxy putDataSource(DataSource dataSource, BranchType dataSourceProxyMode) &#123; DataSource originalDataSource; if (dataSource instanceof SeataDataSourceProxy) &#123; SeataDataSourceProxy dataSourceProxy = (SeataDataSourceProxy) dataSource; if (dataSourceProxyMode == dataSourceProxy.getBranchType()) &#123; return (SeataDataSourceProxy)dataSource; &#125; originalDataSource = dataSourceProxy.getTargetDataSource(); &#125; else &#123; originalDataSource = dataSource; &#125; return CollectionUtils.computeIfAbsent(this.dataSourceProxyMap, originalDataSource, BranchType.XA == dataSourceProxyMode ? DataSourceProxyXA::new : DataSourceProxy::new); &#125;&#125;public class SeataAutoDataSourceProxyCreator extends AbstractAutoProxyCreator &#123; // 给DataSource自动创建代理 public SeataAutoDataSourceProxyCreator(boolean useJdkProxy, String[] excludes, String dataSourceProxyMode) &#123; this.excludes = Arrays.asList(excludes); this.advisor = new DefaultIntroductionAdvisor(new SeataAutoDataSourceProxyAdvice(dataSourceProxyMode)); setProxyTargetClass(!useJdkProxy); &#125; protected Object[] getAdvicesAndAdvisorsForBean(Class&lt;?&gt; beanClass, String beanName, TargetSource customTargetSource) throws BeansException &#123; return new Object[]&#123;advisor&#125;; &#125; // beanClass是DataSource的子类 &amp;&amp; beanClass不是beanClass的子类 &amp;&amp; beanClass没有被排除，则创建通过SeataAutoDataSourceProxyAdvice创建代理 protected boolean shouldSkip(Class&lt;?&gt; beanClass, String beanName) &#123; return !DataSource.class.isAssignableFrom(beanClass) || SeataProxy.class.isAssignableFrom(beanClass) || excludes.contains(beanClass.getName()); &#125;&#125;public class SeataAutoDataSourceProxyAdvice implements MethodInterceptor, IntroductionInfo &#123; private final BranchType dataSourceProxyMode; private final Class&lt;? extends SeataDataSourceProxy&gt; dataSourceProxyClazz; public SeataAutoDataSourceProxyAdvice(String dataSourceProxyMode) &#123; if (BranchType.AT.name().equalsIgnoreCase(dataSourceProxyMode)) &#123; this.dataSourceProxyMode = BranchType.AT; this.dataSourceProxyClazz = DataSourceProxy.class; &#125; else if (BranchType.XA.name().equalsIgnoreCase(dataSourceProxyMode)) &#123; this.dataSourceProxyMode = BranchType.XA; this.dataSourceProxyClazz = DataSourceProxyXA.class; &#125; else &#123; throw new IllegalArgumentException(\"Unknown dataSourceProxyMode: \" + dataSourceProxyMode); &#125; RootContext.setDefaultBranchType(this.dataSourceProxyMode); &#125; public Object invoke(MethodInvocation invocation) throws Throwable &#123; if (!RootContext.requireGlobalLock() &amp;&amp; dataSourceProxyMode != RootContext.getBranchType()) &#123; return invocation.proceed(); &#125; Method method = invocation.getMethod(); Object[] args = invocation.getArguments(); Method m = BeanUtils.findDeclaredMethod(dataSourceProxyClazz, method.getName(), method.getParameterTypes()); if (m != null) &#123; SeataDataSourceProxy dataSourceProxy = DataSourceProxyHolder.get().putDataSource((DataSource) invocation.getThis(), dataSourceProxyMode); return m.invoke(dataSourceProxy, args); // 调用DataSourceProxy的代理方法 &#125; else &#123; return invocation.proceed(); &#125; &#125; public Class&lt;?&gt;[] getInterfaces() &#123; return new Class[]&#123;SeataProxy.class&#125;; &#125;&#125; 在DataSourceProxy中创建了Connection的代理对象ConnectionProxy， 在ConnectionProxy重写了事务的提交回滚等方法，且在其超类AbstractConnectionProxy中为Statement和PreparedStatement也生成了代理对象StatementProxy和PreparedStatementProxy。在这些类中相应的扩展从而实现了分布式事务的相关逻辑。从此也可以知道Seata的AT模式是依赖于数据库本地事务的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class DataSourceProxy extends AbstractDataSourceProxy implements Resource &#123; public ConnectionProxy getConnection() throws SQLException &#123; Connection targetConnection = targetDataSource.getConnection(); return new ConnectionProxy(this, targetConnection); &#125;&#125;public class ConnectionProxy extends AbstractConnectionProxy &#123; public void commit() throws SQLException &#123; try &#123; LOCK_RETRY_POLICY.execute(() -&gt; &#123; doCommit(); return null; &#125;); &#125; catch (SQLException e) &#123; if (targetConnection != null &amp;&amp; !getAutoCommit()) &#123; rollback(); &#125; throw e; &#125; catch (Exception e) &#123; throw new SQLException(e); &#125; &#125; public void rollback() throws SQLException &#123; targetConnection.rollback(); if (context.inGlobalTransaction() &amp;&amp; context.isBranchRegistered()) &#123; report(false); &#125; context.reset(); &#125; public void setAutoCommit(boolean autoCommit) throws SQLException &#123; if ((context.inGlobalTransaction() || context.isGlobalLockRequire()) &amp;&amp; autoCommit &amp;&amp; !getAutoCommit()) &#123; doCommit(); &#125; targetConnection.setAutoCommit(autoCommit); &#125;&#125;public abstract class AbstractConnectionProxy implements Connection &#123; public Statement createStatement() throws SQLException &#123; Statement targetStatement = getTargetConnection().createStatement(); return new StatementProxy(this, targetStatement); &#125; public PreparedStatement prepareStatement(String sql) throws SQLException &#123; String dbType = getDbType(); PreparedStatement targetPreparedStatement = null; if (BranchType.AT == RootContext.getBranchType()) &#123; List&lt;SQLRecognizer&gt; sqlRecognizers = SQLVisitorFactory.get(sql, dbType); if (sqlRecognizers != null &amp;&amp; sqlRecognizers.size() == 1) &#123; SQLRecognizer sqlRecognizer = sqlRecognizers.get(0); if (sqlRecognizer != null &amp;&amp; sqlRecognizer.getSQLType() == SQLType.INSERT) &#123; TableMeta tableMeta = TableMetaCacheFactory.getTableMetaCache(dbType).getTableMeta(getTargetConnection(), sqlRecognizer.getTableName(), getDataSourceProxy().getResourceId()); String[] pkNameArray = new String[tableMeta.getPrimaryKeyOnlyName().size()]; tableMeta.getPrimaryKeyOnlyName().toArray(pkNameArray); targetPreparedStatement = getTargetConnection().prepareStatement(sql,pkNameArray); &#125; &#125; &#125; if (targetPreparedStatement == null) &#123; targetPreparedStatement = getTargetConnection().prepareStatement(sql); &#125; return new PreparedStatementProxy(this, targetPreparedStatement, sql); &#125;&#125; RPC集成对于RestTemplate的集成是通过SeataRestTemplateAutoConfiguration配置类来完成的，通过@PostConstruct注解标注的初始化方法中给RestTemplate添加SeataRestTemplateInterceptor拦截器。该拦截器的作用就是若当前全局事务的Xid存在，则将其设置到请求的header中。 12345678910111213141516171819202122232425262728293031@Configuration(proxyBeanMethods = false)public class SeataRestTemplateAutoConfiguration &#123; @Bean public SeataRestTemplateInterceptor seataRestTemplateInterceptor() &#123; return new SeataRestTemplateInterceptor(); &#125; @Autowired(required = false) private Collection&lt;RestTemplate&gt; restTemplates; @Autowired private SeataRestTemplateInterceptor seataRestTemplateInterceptor; @PostConstruct public void init() &#123; if (this.restTemplates != null) &#123; for (RestTemplate restTemplate : restTemplates) &#123; List&lt;ClientHttpRequestInterceptor&gt; interceptors = new ArrayList&lt;ClientHttpRequestInterceptor&gt;(restTemplate.getInterceptors()); interceptors.add(this.seataRestTemplateInterceptor); restTemplate.setInterceptors(interceptors); &#125; &#125; &#125;&#125;public class SeataRestTemplateInterceptor implements ClientHttpRequestInterceptor &#123; public ClientHttpResponse intercept(HttpRequest httpRequest, byte[] bytes, ClientHttpRequestExecution clientHttpRequestExecution) throws IOException &#123; HttpRequestWrapper requestWrapper = new HttpRequestWrapper(httpRequest); String xid = RootContext.getXID(); if (!StringUtils.isEmpty(xid)) &#123; requestWrapper.getHeaders().add(RootContext.KEY_XID, xid); &#125; return clientHttpRequestExecution.execute(requestWrapper, bytes); &#125;&#125; 对于Feign的集成是通过SeataFeignClientAutoConfiguration中的内部配置类FeignBeanPostProcessorConfiguration中导入的后置处理器来完成，主要是通过SeataFeignObjectWrapper给Client对象创建了一个SeataFeignClient代理，在该代理中会将全局事务的Xid设置到Header中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Configuration(proxyBeanMethods = false)@ConditionalOnClass(Client.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class SeataFeignClientAutoConfiguration &#123; @Configuration(proxyBeanMethods = false) protected static class FeignBeanPostProcessorConfiguration &#123; @Bean SeataBeanPostProcessor seataBeanPostProcessor(SeataFeignObjectWrapper seataFeignObjectWrapper) &#123; return new SeataBeanPostProcessor(seataFeignObjectWrapper); &#125; @Bean SeataContextBeanPostProcessor seataContextBeanPostProcessor(BeanFactory beanFactory) &#123; return new SeataContextBeanPostProcessor(beanFactory); &#125; @Bean SeataFeignObjectWrapper seataFeignObjectWrapper(BeanFactory beanFactory) &#123; return new SeataFeignObjectWrapper(beanFactory); &#125; &#125;&#125;public class SeataBeanPostProcessor implements BeanPostProcessor &#123; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return this.seataFeignObjectWrapper.wrap(bean); &#125;&#125;public class SeataFeignObjectWrapper &#123; Object wrap(Object bean) &#123; if (bean instanceof Client &amp;&amp; !(bean instanceof SeataFeignClient)) &#123; if (bean instanceof LoadBalancerFeignClient) &#123; LoadBalancerFeignClient client = ((LoadBalancerFeignClient) bean); return new SeataLoadBalancerFeignClient(client.getDelegate(), factory(), clientFactory(), this); &#125; if (bean instanceof FeignBlockingLoadBalancerClient) &#123; FeignBlockingLoadBalancerClient client = (FeignBlockingLoadBalancerClient) bean; return new SeataFeignBlockingLoadBalancerClient(client.getDelegate(), beanFactory.getBean(BlockingLoadBalancerClient.class), this); &#125; return new SeataFeignClient(this.beanFactory, (Client) bean); &#125; return bean; &#125;&#125;public class SeataFeignClient implements Client &#123; public Response execute(Request request, Request.Options options) throws IOException &#123; Request modifiedRequest = getModifyRequest(request); return this.delegate.execute(modifiedRequest, options); &#125; private Request getModifyRequest(Request request) &#123; String xid = RootContext.getXID(); if (StringUtils.isEmpty(xid)) &#123; return request; &#125; Map&lt;String, Collection&lt;String&gt;&gt; headers = new HashMap&lt;&gt;(MAP_SIZE); headers.putAll(request.headers()); List&lt;String&gt; seataXid = new ArrayList&lt;&gt;(); seataXid.add(xid); headers.put(RootContext.KEY_XID, seataXid); return Request.create(request.method(), request.url(), headers, request.body(), request.charset()); &#125;&#125; 这是针对请求发送的处理，对于分支事务接收到请求时也需要获取到全局事务的Xid设置到RootContext中，该功能是通过SeataHandlerInterceptorConfiguration配置类中添加SeataHandlerInterceptor拦截器来完成的。 12345678910111213141516171819202122232425262728293031323334353637@ConditionalOnWebApplicationpublic class SeataHandlerInterceptorConfiguration implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new SeataHandlerInterceptor()).addPathPatterns(\"/**\"); &#125;&#125;public class SeataHandlerInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; String xid = RootContext.getXID(); String rpcXid = request.getHeader(RootContext.KEY_XID); if (StringUtils.isBlank(xid) &amp;&amp; rpcXid != null) &#123; RootContext.bind(rpcXid); if (log.isDebugEnabled()) &#123; &#125; &#125; return true; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception e) &#123; if (StringUtils.isNotBlank(RootContext.getXID())) &#123; String rpcXid = request.getHeader(RootContext.KEY_XID); if (StringUtils.isEmpty(rpcXid)) &#123; return; &#125; String unbindXid = RootContext.unbind(); if (log.isDebugEnabled()) &#123; &#125; if (!rpcXid.equalsIgnoreCase(unbindXid)) &#123; if (unbindXid != null) &#123; RootContext.bind(unbindXid); &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"分布式事务","slug":"分布式事务","permalink":"https://yaoyinglong.github.io/tags/分布式事务/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Seata","slug":"Cloud/Seata","permalink":"https://yaoyinglong.github.io/categories/Cloud/Seata/"}]},{"title":"常见限流算法","date":"2021-11-04T16:00:00.000Z","path":"Blog/Cloud/Sentinel/常见限流算法/","text":"计数器法定义一个时间窗口，以及时间窗口内最大请求数，当每个请求来时判断请求时间是否小于窗口起始时间加时间窗口时长，即是否在时间窗口内，若在则将计数器加一，且判断当前时间窗口内是否超过最大请求控制数，否则将窗口起始时间重置为当前时间，且重置请求数。缺点精度太低。 123456789101112131415161718192021public class Counter &#123; public long timeStamp = System.currentTimeMillis(); // 当前时间 public int reqCount = 0; // 初始化计数器 public final int limit = 100; // 时间窗口内最大请求数 public final long interval = 1000 * 60; // 时间窗口ms public boolean limit() &#123; long now = System.currentTimeMillis(); if (now &lt; timeStamp + interval) &#123; // 在时间窗口内 reqCount++; // 判断当前时间窗口内是否超过最大请求控制数 return reqCount &lt;= limit; &#125; else &#123; timeStamp = now; // 超时后重置 reqCount = 1; return true; &#125; &#125;&#125; 滑动时间窗口为了解决计数器法统计精度太低的问题，引入了滑动窗口算法，红色的矩形框表示一个时间窗口，一个时间窗口就是一分钟，将滑动窗口划成了6格，所以每格代表的是10秒钟，每过10秒钟，时间窗口就会往右滑动一格，每一个格子都有自己独立的计数器counter。 计数器算法其实就是滑动窗口算法。只是它没有对时间窗口做进一步地划分，所以只有1格。当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 滑动时间窗口限流实现，假设某个服务最多只能每秒钟处理100个请求，我们可以设置一个1秒钟的滑动时间窗口， * 窗口中有10个格子，每个格子100毫秒，每100毫秒移动一次，每次移动都需要记录当前服务请求的次数 */public class SlidingTimeWindow &#123; //服务访问次数，可以放在Redis中，实现分布式系统的访问计数 Long counter = 0L; //使用LinkedList来记录滑动窗口的10个格子。 LinkedList&lt;Long&gt; slots = new LinkedList&lt;Long&gt;(); public static void main(String[] args) throws InterruptedException &#123; SlidingTimeWindow timeWindow = new SlidingTimeWindow(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; timeWindow.doCheck(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); while (true) &#123; //TODO 判断限流标记 timeWindow.counter++; Thread.sleep(new Random().nextInt(15)); &#125; &#125; private void doCheck() throws InterruptedException &#123; while (true) &#123; slots.addLast(counter); if (slots.size() &gt; 10) &#123; slots.removeFirst(); &#125; //比较最后一个和第一个，两者相差100以上就限流 if ((slots.peekLast() - slots.peekFirst()) &gt; 100) &#123; System.out.println(\"限流了。。\"); //TODO 修改限流标记为true &#125; else &#123; //TODO 修改限流标记为false &#125; Thread.sleep(100); &#125; &#125;&#125; 漏桶算法有一个固定容量的桶，有水流进来也有水流出去，对于流进来的水来说，无法预计一共有多少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，该桶可以固定水流出的速率。且当桶满后多余的水将溢出。漏桶算法天生就限制了请求的速度，当使用了漏桶算法，保证接口会以一个常速速率来处理请求。故漏桶算法天生不会出现临界问题。 12345678910111213141516171819public class LeakyBucket &#123; public long timeStamp = System.currentTimeMillis(); // 当前时间 public long capacity; // 桶的容量 public long rate; // 水漏出的速度(每秒系统能处理的请求数) public long water; // 当前水量(当前累积请求数) public boolean limit() &#123; long now = System.currentTimeMillis(); water = Math.max(0, water - ((now - timeStamp) / 1000) * rate); // 先执行漏水，计算剩余水量 timeStamp = now; if ((water + 1) &lt; capacity) &#123; // 尝试加水,并且水还未满 water += 1; return true; &#125; else &#123; // 水满，拒绝加水 return false; &#125; &#125;&#125; 令牌桶算法令牌桶算法比漏桶算法稍显复杂，有一个固定容量的桶，桶里存放着令牌，桶一开始是空的，token以 一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃，每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通过。 123456789101112131415161718192021public class TokenBucket &#123; public long timeStamp = System.currentTimeMillis(); // 当前时间 public long capacity; // 桶的容量 public long rate; // 令牌放入速度 public long tokens; // 当前令牌数量 public boolean grant() &#123; long now = System.currentTimeMillis(); // 先添加令牌 tokens = Math.min(capacity, tokens + (now - timeStamp) * rate); timeStamp = now; if (tokens &lt; 1) &#123; // 若不到1个令牌,则拒绝 return false; &#125; else &#123; // 还有令牌，领取令牌 tokens -= 1; return true; &#125; &#125;&#125; 计数器算法是最简单的算法，可以看成是滑动窗口的低精度实现。滑动窗口由于需要存储多份的计数器，所以滑动窗口在实现上需要更多的存储空间。若滑动窗口的精度越高，需要的存储空间就越大。 漏桶算法和令牌桶算法最明显的区别是令牌桶算法允许流量一定程度的突发，默认的令牌桶算法，取走token是不需要耗费时间的，若桶内有100个token时，则可瞬间允许100个请求通过。","tags":[{"name":"限流","slug":"限流","permalink":"https://yaoyinglong.github.io/tags/限流/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Sentinel","slug":"Cloud/Sentinel","permalink":"https://yaoyinglong.github.io/categories/Cloud/Sentinel/"}]},{"title":"Sentinel配置持久化","date":"2021-11-04T16:00:00.000Z","path":"Blog/Cloud/Sentinel/Sentinel配置持久化/","text":"sentinel规则的推送模式原始模式、Pull模式、Push模式三种，原始模式是通过API将规则数据推送至客户端，并直接更新到内存中，简单无任何依赖，但规则保存在内存中，重启失效； Pull模式Pull模式是通过扩展写数据源WritableDataSource，客户端主动向某个规则管理中心定期轮训拉取规则，可以是文件或数据库，不能保证很强的实时性，过于频繁拉取可能造成性能问题。 在第一次调用接口时，会执行Env的静态代码块，该静态代码块中会通过SPI机制加载sentinel相关依赖包下META/services/下所有的InitFunc实例类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Env &#123; public static final Sph sph = new CtSph(); static &#123; // If init fails, the process will exit. InitExecutor.doInit(); // 通过SPI机制加载sentinel相关依赖包下META/services/下所有的InitFunc实例类 &#125;&#125;public final class InitExecutor &#123; public static void doInit() &#123; // Sentinel扩展点，通过SPI的方式加载实现了InitFunc接口的类 if (!initialized.compareAndSet(false, true)) &#123; return; &#125; try &#123; ServiceLoader&lt;InitFunc&gt; loader = ServiceLoaderUtil.getServiceLoader(InitFunc.class); List&lt;OrderWrapper&gt; initList = new ArrayList&lt;OrderWrapper&gt;(); for (InitFunc initFunc : loader) &#123; RecordLog.info(\"[InitExecutor] Found init func: \" + initFunc.getClass().getCanonicalName()); insertSorted(initList, initFunc); &#125; for (OrderWrapper w : initList) &#123; w.func.init(); RecordLog.info(String.format(\"[InitExecutor] Executing %s with order %d\", w.func.getClass().getCanonicalName(), w.order)); &#125; &#125; catch (Exception ex) &#123; RecordLog.warn(\"[InitExecutor] WARN: Initialization failed\", ex); ex.printStackTrace(); &#125; catch (Error error) &#123; RecordLog.warn(\"[InitExecutor] ERROR: Initialization failed with fatal error\", error); error.printStackTrace(); &#125; &#125; private static void insertSorted(List&lt;OrderWrapper&gt; list, InitFunc func) &#123; int order = resolveOrder(func); // 获取排序，若该类上没有@InitOrder注解则默认是最低优先级即Integer.MAX_VALUE int idx = 0; for (; idx &lt; list.size(); idx++) &#123; if (list.get(idx).getOrder() &gt; order) &#123; break; &#125; &#125; list.add(idx, new OrderWrapper(order, func)); // 将其按照order从大到小即优先级越低越排在前面的顺序放入List中 &#125; private static int resolveOrder(InitFunc func) &#123; if (!func.getClass().isAnnotationPresent(InitOrder.class)) &#123; return InitOrder.LOWEST_PRECEDENCE; &#125; else &#123; return func.getClass().getAnnotation(InitOrder.class).value(); &#125; &#125;&#125; 可通过SPI机制自定义一个FileDataSourceInit类实现InitFunc接口用文件的方式持久化规则配置，当然也可以通过数据库的方式来实现持久化规则配置原理都一样。 123456789101112public class FileDataSourceInit implements InitFunc &#123; @Override public void init() throws Exception &#123; RuleFileUtils.mkdirIfNotExits(PersistenceRuleConstant.STORE_PATH); // 创建文件存储目录 RuleFileUtils.createFileIfNotExits(PersistenceRuleConstant.RULES_MAP); // 创建规则文件 dealFlowRules(); // 处理流控规则逻辑 配置读写数据源 dealDegradeRules(); // 处理降级规则 dealSystemRules(); // 处理系统规则 dealParamFlowRules(); // 处理热点参数规则 dealAuthRules(); // 处理授权规则 &#125;&#125; 首先通过文件路径初始化FileRefreshableDataSource，在其初始化是首先会先初始化其超类AbstractDataSource，在该超类中会对Converter进行赋值以及SentinelProperty初始化为DynamicSentinelProperty。 123456789101112131415161718192021222324252627282930private void dealFlowRules() throws FileNotFoundException &#123; String ruleFilePath = PersistenceRuleConstant.RULES_MAP.get(PersistenceRuleConstant.FLOW_RULE_PATH).toString(); ReadableDataSource&lt;String, List&lt;FlowRule&gt;&gt; flowRuleDataSource = new FileRefreshableDataSource(ruleFilePath, RuleListConverterUtils.flowRuleListParser); FlowRuleManager.register2Property(flowRuleDataSource.getProperty()); WritableDataSource&lt;List&lt;FlowRule&gt;&gt; flowRuleWDS = new FileWritableDataSource&lt;List&lt;FlowRule&gt;&gt;( ruleFilePath, RuleListConverterUtils.flowFuleEnCoding ); // 将可写数据源注册至transport模块的WritableDataSourceRegistry中. // 这样收到控制台推送的规则时，Sentinel 会先更新到内存，然后将规则写入到文件中. WritableDataSourceRegistry.registerFlowDataSource(flowRuleWDS);&#125;public abstract class AbstractDataSource&lt;S, T&gt; implements ReadableDataSource&lt;S, T&gt; &#123; protected final Converter&lt;S, T&gt; parser; protected final SentinelProperty&lt;T&gt; property; public AbstractDataSource(Converter&lt;S, T&gt; parser) &#123; if (parser == null) &#123; throw new IllegalArgumentException(\"parser can't be null\"); &#125; this.parser = parser; this.property = new DynamicSentinelProperty&lt;T&gt;(); &#125; public T loadConfig() throws Exception &#123; return loadConfig(readSource()); &#125; public T loadConfig(S conf) throws Exception &#123; T value = parser.convert(conf); return value; &#125;&#125; 然后再初始化AutoRefreshDataSource超类，在该超类中会添加一个定时刷新文件的规则数据的定时任务，在更新内存中规则时是通过DynamicSentinelProperty中注册的监听器来完成的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public abstract class AutoRefreshDataSource&lt;S, T&gt; extends AbstractDataSource&lt;S, T&gt; &#123; private ScheduledExecutorService service; protected long recommendRefreshMs = 3000; public AutoRefreshDataSource(Converter&lt;S, T&gt; configParser, final long recommendRefreshMs) &#123; super(configParser); if (recommendRefreshMs &lt;= 0) &#123; throw new IllegalArgumentException(\"recommendRefreshMs must &gt; 0, but \" + recommendRefreshMs + \" get\"); &#125; this.recommendRefreshMs = recommendRefreshMs; startTimerService(); // 扩展自动更新功能 &#125; private void startTimerService() &#123; // 自动更新定时任务，开启线程监控本地文件最后修改时间，周期3s service = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"sentinel-datasource-auto-refresh-task\", true)); service.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; if (!isModified()) &#123; // 若没有修改则直接跳过 return; &#125; T newValue = loadConfig(); // 若修改过，获取文件最后的修改时间，并加载文件 getProperty().updateValue(newValue); // 更新到内存中 &#125; catch (Throwable e) &#123; &#125; &#125; &#125;, recommendRefreshMs, recommendRefreshMs, TimeUnit.MILLISECONDS); // 默认每3s执行一次 &#125;&#125;public class DynamicSentinelProperty&lt;T&gt; implements SentinelProperty&lt;T&gt; &#123; protected Set&lt;PropertyListener&lt;T&gt;&gt; listeners = Collections.synchronizedSet(new HashSet&lt;PropertyListener&lt;T&gt;&gt;()); private T value = null; public void addListener(PropertyListener&lt;T&gt; listener) &#123; listeners.add(listener); listener.configLoad(value); &#125; public boolean updateValue(T newValue) &#123; if (isEqual(value, newValue)) &#123; return false; &#125; value = newValue; for (PropertyListener&lt;T&gt; listener : listeners) &#123; listener.configUpdate(newValue); // 用新规则替换旧规则，并通知所有所有属性监听器回调configUpdate &#125; return true; &#125;&#125;private static final class FlowPropertyListener implements PropertyListener&lt;List&lt;FlowRule&gt;&gt; &#123; @Override public void configUpdate(List&lt;FlowRule&gt; value) &#123; Map&lt;String, List&lt;FlowRule&gt;&gt; rules = FlowRuleUtil.buildFlowRuleMap(value); if (rules != null) &#123; flowRules.clear(); flowRules.putAll(rules); &#125; &#125; @Override public void configLoad(List&lt;FlowRule&gt; conf) &#123; Map&lt;String, List&lt;FlowRule&gt;&gt; rules = FlowRuleUtil.buildFlowRuleMap(conf); if (rules != null) &#123; flowRules.clear(); flowRules.putAll(rules); &#125; &#125;&#125; 在初始化FileRefreshableDataSource时会将规则数据加载到内存中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class FileRefreshableDataSource&lt;T&gt; extends AutoRefreshDataSource&lt;String, T&gt; &#123; public FileRefreshableDataSource(String fileName, Converter&lt;String, T&gt; configParser) throws FileNotFoundException &#123; this(new File(fileName), configParser, DEFAULT_REFRESH_MS, DEFAULT_BUF_SIZE, DEFAULT_CHAR_SET); &#125; public FileRefreshableDataSource(File file, Converter&lt;String, T&gt; configParser, long recommendRefreshMs, int bufSize, Charset charset) throws FileNotFoundException &#123; super(configParser, recommendRefreshMs); if (bufSize &lt;= 0 || bufSize &gt; MAX_SIZE) &#123; throw new IllegalArgumentException(\"bufSize must between (0, \" + MAX_SIZE + \"], but \" + bufSize + \" get\"); &#125; if (file == null || file.isDirectory()) &#123; throw new IllegalArgumentException(\"File can't be null or a directory\"); &#125; if (charset == null) &#123; throw new IllegalArgumentException(\"charset can't be null\"); &#125; this.buf = new byte[bufSize]; this.file = file; this.charset = charset; // If the file does not exist, the last modified will be 0. this.lastModified = file.lastModified(); firstLoad(); &#125; private void firstLoad() &#123; try &#123; T newValue = loadConfig(); getProperty().updateValue(newValue); &#125; catch (Throwable e) &#123; RecordLog.info(\"loadConfig exception\", e); &#125; &#125; public String readSource() throws Exception &#123; // AbstractDataSource中的loadConfig方法调用该方法加载数据 if (!file.exists()) &#123;// Will throw FileNotFoundException later. RecordLog.warn(String.format(\"[FileRefreshableDataSource] File does not exist: %s\", file.getAbsolutePath())); &#125; FileInputStream inputStream = null; try &#123; inputStream = new FileInputStream(file); FileChannel channel = inputStream.getChannel(); if (channel.size() &gt; buf.length) &#123; throw new IllegalStateException(file.getAbsolutePath() + \" file size=\" + channel.size() + \", is bigger than bufSize=\" + buf.length + \". Can't read\"); &#125; int len = inputStream.read(buf); return new String(buf, 0, len, charset); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125; &#125; protected boolean isModified() &#123; // 在定时更新规则配置的任务中调用该方法判断文件是否被改变 long curLastModified = file.lastModified(); if (curLastModified != this.lastModified) &#123; this.lastModified = curLastModified; return true; &#125; return false; &#125;&#125; 然后通过FlowRuleManager给SentinelProperty注册监听器，用于规则数据的刷新，这里是以流控规则为例，其他的规则通过相应的规则管理器的对应方法。 1234567891011121314151617181920212223242526272829303132333435363738public class FlowRuleManager &#123; private static final Map&lt;String, List&lt;FlowRule&gt;&gt; flowRules = new ConcurrentHashMap&lt;String, List&lt;FlowRule&gt;&gt;(); private static final FlowPropertyListener LISTENER = new FlowPropertyListener(); private static SentinelProperty&lt;List&lt;FlowRule&gt;&gt; currentProperty = new DynamicSentinelProperty&lt;List&lt;FlowRule&gt;&gt;(); private static final ScheduledExecutorService SCHEDULER = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"sentinel-metrics-record-task\", true)); static &#123; currentProperty.addListener(LISTENER); SCHEDULER.scheduleAtFixedRate(new MetricTimerListener(), 0, 1, TimeUnit.SECONDS); // 监控指标的定时统计 &#125; public static void register2Property(SentinelProperty&lt;List&lt;FlowRule&gt;&gt; property) &#123; AssertUtil.notNull(property, \"property cannot be null\"); synchronized (LISTENER) &#123; currentProperty.removeListener(LISTENER); property.addListener(LISTENER); currentProperty = property; &#125; &#125;&#125;private static final class FlowPropertyListener implements PropertyListener&lt;List&lt;FlowRule&gt;&gt; &#123; @Override public void configUpdate(List&lt;FlowRule&gt; value) &#123; Map&lt;String, List&lt;FlowRule&gt;&gt; rules = FlowRuleUtil.buildFlowRuleMap(value); if (rules != null) &#123; flowRules.clear(); flowRules.putAll(rules); &#125; RecordLog.info(\"[FlowRuleManager] Flow rules received: \" + flowRules); &#125; @Override public void configLoad(List&lt;FlowRule&gt; conf) &#123; Map&lt;String, List&lt;FlowRule&gt;&gt; rules = FlowRuleUtil.buildFlowRuleMap(conf); if (rules != null) &#123; flowRules.clear(); flowRules.putAll(rules); &#125; RecordLog.info(\"[FlowRuleManager] Flow rules loaded: \" + flowRules); &#125;&#125; 对于写规则的实现其实相对简单，最终会调用WritableDataSource的write方法完成数据的持久化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class FileWritableDataSource&lt;T&gt; implements WritableDataSource&lt;T&gt; &#123; public FileWritableDataSource(String filePath, Converter&lt;T, String&gt; configEncoder) &#123; this(new File(filePath), configEncoder); &#125; public FileWritableDataSource(File file, Converter&lt;T, String&gt; configEncoder) &#123; this(file, configEncoder, DEFAULT_CHARSET); &#125; public FileWritableDataSource(File file, Converter&lt;T, String&gt; configEncoder, Charset charset) &#123; if (file == null || file.isDirectory()) &#123; throw new IllegalArgumentException(\"Bad file\"); &#125; if (configEncoder == null) &#123; throw new IllegalArgumentException(\"Config encoder cannot be null\"); &#125; if (charset == null) &#123; throw new IllegalArgumentException(\"Charset cannot be null\"); &#125; this.configEncoder = configEncoder; this.file = file; this.charset = charset; &#125; public void write(T value) throws Exception &#123; lock.lock(); try &#123; String convertResult = configEncoder.convert(value); FileOutputStream outputStream = null; try &#123; outputStream = new FileOutputStream(file); byte[] bytesArray = convertResult.getBytes(charset); RecordLog.info(String.format(\"[FileWritableDataSource] Writing to file %s: %s\", file.toString(), convertResult)); outputStream.write(bytesArray); outputStream.flush(); &#125; finally &#123; if (outputStream != null) &#123; try &#123; outputStream.close(); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 最后通过WritableDataSourceRegistry将对应的WritableDataSource进行注册，在CommandHandler中对其更新是会调用具体的方法获取具体的WritableDataSource进行write操作。 123456789101112131415161718public final class WritableDataSourceRegistry &#123; private static WritableDataSource&lt;List&lt;FlowRule&gt;&gt; flowDataSource = null; private static WritableDataSource&lt;List&lt;AuthorityRule&gt;&gt; authorityDataSource = null; private static WritableDataSource&lt;List&lt;DegradeRule&gt;&gt; degradeDataSource = null; private static WritableDataSource&lt;List&lt;SystemRule&gt;&gt; systemSource = null; public static synchronized void registerFlowDataSource(WritableDataSource&lt;List&lt;FlowRule&gt;&gt; datasource) &#123; flowDataSource = datasource; &#125; public static synchronized void registerAuthorityDataSource(WritableDataSource&lt;List&lt;AuthorityRule&gt;&gt; dataSource) &#123; authorityDataSource = dataSource; &#125; public static synchronized void registerDegradeDataSource(WritableDataSource&lt;List&lt;DegradeRule&gt;&gt; dataSource) &#123; degradeDataSource = dataSource; &#125; public static synchronized void registerSystemDataSource(WritableDataSource&lt;List&lt;SystemRule&gt;&gt; dataSource) &#123; systemSource = dataSource; &#125;&#125; Sentinel控制台通过API将规则推送至客户端并更新到内存中，接着注册的写数据源会将新的规则保存到本地的文件中。使用pull模式的数据源时一般不需要对Sentinel控制台进行改造。使用时首先需要引入sentinel-datasource-extension依赖，让后将自定义的持久化包引入即可。 1234567891011&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-extension&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- sentinel规则pull模式依赖 改造拉模式实现--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-extension-file-pull&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt;&lt;/dependency&gt; Push模式Push是通过通过Sentinel控制台直接推送到Nacos配置中心，然后配置中心再更新到本地，基于Nacos配置中心的推送需要额外引入sentinel-datasource-nacos依赖。且配置相应规则的数据源： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152cloud: nacos: discovery: server-addr: 127.0.0.1:8848 ephemeral: false sentinel: transport: # 添加sentinel的控制台地址 dashboard: 127.0.0.1:8080 # 指定应用与Sentinel控制台交互的端口，应用本地会起一个该端口占用的HttpServer port: 8719 datasource: ds-flow: nacos: server-addr: 127.0.0.1:8848 dataId: $&#123;spring.application.name&#125;-flow groupId: DEFAULT_GROUP namespace: sentinel data-type: json rule-type: flow ds-degrade: nacos: server-addr: 127.0.0.1:8848 dataId: $&#123;spring.application.name&#125;-degrade groupId: DEFAULT_GROUP namespace: sentinel data-type: json rule-type: degrade ds-param-flow: nacos: server-addr: 127.0.0.1:8848 dataId: $&#123;spring.application.name&#125;-param-flow groupId: DEFAULT_GROUP namespace: sentinel data-type: json rule-type: param-flow ds-system: nacos: server-addr: 127.0.0.1:8848 dataId: $&#123;spring.application.name&#125;-system groupId: DEFAULT_GROUP namespace: sentinel data-type: json rule-type: system ds-authority: nacos: server-addr: 127.0.0.1:8848 dataId: $&#123;spring.application.name&#125;-authority groupId: DEFAULT_GROUP namespace: sentinel data-type: json rule-type: authority 对于Nacos的集成是通过SentinelDataSourceHandler中遍历SentinelProperties的datasource属性，该属性是一个存放DataSourcePropertiesConfiguration的Map，而DataSourcePropertiesConfiguration是持有具体的类型的配置类。最后通过AbstractDataSourceProperties根据具体的配置的RuleType调用具体规则管理器给具体的SentinelProperty注册监听器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class SentinelProperties &#123; private Map&lt;String, DataSourcePropertiesConfiguration&gt; datasource = new TreeMap&lt;&gt;(String.CASE_INSENSITIVE_ORDER); public Map&lt;String, DataSourcePropertiesConfiguration&gt; getDatasource() &#123; return datasource; &#125;&#125;public class DataSourcePropertiesConfiguration &#123; private FileDataSourceProperties file; private NacosDataSourceProperties nacos; private ZookeeperDataSourceProperties zk; private ApolloDataSourceProperties apollo; private RedisDataSourceProperties redis; private ConsulDataSourceProperties consul;&#125;public class SentinelDataSourceHandler implements SmartInitializingSingleton &#123; public void afterSingletonsInstantiated() &#123; sentinelProperties.getDatasource().forEach((dataSourceName, dataSourceProperties) -&gt; &#123; try &#123; List&lt;String&gt; validFields = dataSourceProperties.getValidField(); if (validFields.size() != 1) &#123; log.error(\"[Sentinel Starter] DataSource \" + dataSourceName + \" multi datasource active and won't loaded: \" + dataSourceProperties.getValidField()); return; &#125; AbstractDataSourceProperties abstractDataSourceProperties = dataSourceProperties.getValidDataSourceProperties(); abstractDataSourceProperties.setEnv(env); abstractDataSourceProperties.preCheck(dataSourceName); registerBean(abstractDataSourceProperties, dataSourceName + \"-sentinel-\" + validFields.get(0) + \"-datasource\"); &#125; catch (Exception e) &#123; &#125; &#125;); &#125; private void registerBean(final AbstractDataSourceProperties dataSourceProperties, String dataSourceName) &#123; Map&lt;String, Object&gt; propertyMap = Arrays.stream(dataSourceProperties.getClass().getDeclaredFields()).collect(HashMap::new, (m, v) -&gt; &#123; try &#123; v.setAccessible(true); m.put(v.getName(), v.get(dataSourceProperties)); &#125; catch (IllegalAccessException e) &#123; throw new RuntimeException(\"[Sentinel Starter] DataSource \" + dataSourceName + \" field: \" + v.getName() + \" invoke error\", e); &#125; &#125;, HashMap::putAll); propertyMap.put(CONVERTER_CLASS_FIELD, dataSourceProperties.getConverterClass()); propertyMap.put(DATA_TYPE_FIELD, dataSourceProperties.getDataType()); BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(dataSourceProperties.getFactoryBeanName()); propertyMap.forEach((propertyName, propertyValue) -&gt; &#123; Field field = ReflectionUtils.findField(dataSourceProperties.getClass(), propertyName); if (null == field) &#123; return; &#125; if (DATA_TYPE_FIELD.equals(propertyName)) &#123; String dataType = StringUtils.trimAllWhitespace(propertyValue.toString()); if (CUSTOM_DATA_TYPE.equals(dataType)) &#123; try &#123; if (StringUtils.isEmpty(dataSourceProperties.getConverterClass())) &#123; throw new RuntimeException(\"[Sentinel Starter] DataSource \" + dataSourceName + \"dataType is custom, please set converter-class property\"); &#125; String customConvertBeanName = \"sentinel-\" + dataSourceProperties.getConverterClass(); if (!this.beanFactory.containsBean(customConvertBeanName)) &#123; this.beanFactory.registerBeanDefinition(customConvertBeanName, BeanDefinitionBuilder.genericBeanDefinition(Class.forName(dataSourceProperties.getConverterClass())).getBeanDefinition()); &#125; builder.addPropertyReference(\"converter\", customConvertBeanName); &#125; catch (ClassNotFoundException e) &#123; throw new RuntimeException(\"[Sentinel Starter] DataSource \" + dataSourceName + \" handle \" + dataSourceProperties.getClass().getSimpleName() + \" error, class name: \" + dataSourceProperties.getConverterClass(), e); &#125; &#125; else &#123; if (!dataTypeList.contains(StringUtils.trimAllWhitespace(propertyValue.toString()))) &#123; throw new RuntimeException(\"[Sentinel Starter] DataSource \" + dataSourceName + \" dataType: \" + propertyValue + \" is not support now. please using these types: \" + dataTypeList.toString()); &#125; builder.addPropertyReference(\"converter\", \"sentinel-\" + propertyValue.toString() + \"-\" + dataSourceProperties.getRuleType().getName() + \"-converter\"); &#125; &#125; else if (CONVERTER_CLASS_FIELD.equals(propertyName)) &#123; return; &#125; else &#123; // wired properties Optional.ofNullable(propertyValue).ifPresent(v -&gt; builder.addPropertyValue(propertyName, v)); &#125; &#125;); this.beanFactory.registerBeanDefinition(dataSourceName, builder.getBeanDefinition()); AbstractDataSource newDataSource = (AbstractDataSource) this.beanFactory.getBean(dataSourceName); dataSourceProperties.postRegister(newDataSource); // 注意配置的数据源类型，给具体的类型注册监听器 &#125;&#125;public class AbstractDataSourceProperties &#123; public void postRegister(AbstractDataSource dataSource) &#123; switch (this.getRuleType()) &#123; case FLOW: FlowRuleManager.register2Property(dataSource.getProperty()); break; case DEGRADE: DegradeRuleManager.register2Property(dataSource.getProperty()); break; case PARAM_FLOW: ParamFlowRuleManager.register2Property(dataSource.getProperty()); break; case SYSTEM: SystemRuleManager.register2Property(dataSource.getProperty()); break; case AUTHORITY: AuthorityRuleManager.register2Property(dataSource.getProperty()); break; case GW_FLOW: GatewayRuleManager.register2Property(dataSource.getProperty()); break; case GW_API_GROUP: GatewayApiDefinitionManager.register2Property(dataSource.getProperty()); break; default: break; &#125; &#125;&#125; NacosDataSourceProperties构造方法中调用超类设置factoryBeanName为NacosDataSourceFactoryBean，故在SentinelDataSourceHandler中的registerBean方法中getBean其实是调用NacosDataSourceFactoryBean的getObject方法创建了一个NacosDataSource。 123456789101112131415161718192021222324252627282930313233public class NacosDataSourceProperties extends AbstractDataSourceProperties &#123; public NacosDataSourceProperties() &#123; super(NacosDataSourceFactoryBean.class.getName()); &#125;&#125;public class AbstractDataSourceProperties &#123; public AbstractDataSourceProperties(String factoryBeanName) &#123; this.factoryBeanName = factoryBeanName; &#125;&#125;public class NacosDataSourceFactoryBean implements FactoryBean&lt;NacosDataSource&gt; &#123; public NacosDataSource getObject() throws Exception &#123; Properties properties = new Properties(); if (!StringUtils.isEmpty(this.serverAddr)) &#123; properties.setProperty(PropertyKeyConst.SERVER_ADDR, this.serverAddr); &#125; else &#123; properties.setProperty(PropertyKeyConst.ACCESS_KEY, this.accessKey); properties.setProperty(PropertyKeyConst.SECRET_KEY, this.secretKey); properties.setProperty(PropertyKeyConst.ENDPOINT, this.endpoint); &#125; if (!StringUtils.isEmpty(this.namespace)) &#123; properties.setProperty(PropertyKeyConst.NAMESPACE, this.namespace); &#125; if (!StringUtils.isEmpty(this.username)) &#123; properties.setProperty(PropertyKeyConst.USERNAME, this.username); &#125; if (!StringUtils.isEmpty(this.password)) &#123; properties.setProperty(PropertyKeyConst.PASSWORD, this.password); &#125; return new NacosDataSource(properties, groupId, dataId, converter); // 创建NacosNacosDataSource &#125;&#125; 在NacosDataSource中给具体的dataId注册了监听器，更变时会回调更新。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class NacosDataSource&lt;T&gt; extends AbstractDataSource&lt;String, T&gt; &#123; public NacosDataSource(final Properties properties, final String groupId, final String dataId, Converter&lt;String, T&gt; parser) &#123; super(parser); if (StringUtil.isBlank(groupId) || StringUtil.isBlank(dataId)) &#123; throw new IllegalArgumentException(String.format(\"Bad argument: groupId=[%s], dataId=[%s]\", groupId, dataId)); &#125; AssertUtil.notNull(properties, \"Nacos properties must not be null, you could put some keys from PropertyKeyConst\"); this.groupId = groupId; this.dataId = dataId; this.properties = properties; this.configListener = new Listener() &#123; // 创建监听器 @Override public Executor getExecutor() &#123; return pool; &#125; @Override public void receiveConfigInfo(final String configInfo) &#123; // 当配置发生变更回调该方法 T newValue = NacosDataSource.this.parser.convert(configInfo); // 解析配置 getProperty().updateValue(newValue); // 通过监听器更新到内存 &#125; &#125;; initNacosListener(); // 初始化Nacos监听器 loadInitialConfig(); &#125; private void initNacosListener() &#123; try &#123; this.configService = NacosFactory.createConfigService(this.properties); configService.addListener(dataId, groupId, configListener); // 给具体的dataId注册监听器，配置发生变化时回调 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public String readSource() throws Exception &#123; if (configService == null) &#123; throw new IllegalStateException(\"Nacos config service has not been initialized or error occurred\"); &#125; return configService.getConfig(dataId, groupId, DEFAULT_TIMEOUT); &#125; private void loadInitialConfig() &#123; try &#123; T newValue = loadConfig(); getProperty().updateValue(newValue); &#125; catch (Exception ex) &#123; &#125; &#125;&#125; 目前这种方式集成可在Nacos中修改被Sentinel控制台感应到，但在Sentinel控制台修改不能被Nacos感应到。从Sentinel 1.4.0开始，Sentinel控制台提供用于实现应用维度的规则推送DynamicRulePublisher和拉取DynamicRuleProvider接口，可以通过对源码进行改造通过直接让Sentinel控制台与Nacos配置中心通信，可参照Sentinel Dashboard test包下的流控规则拉取和推送的实现逻辑。 以流控规则为例，通过实现DynamicRuleProvider和DynamicRulePublisher，从而实现规则向Nacos配置中心的推送和拉取。在具体的规则修改接口中将原来的推送和拉取规则的地方修改为上面实现的内容。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Component(value = \"flowRuleNacosProvider\")public class FlowRuleNacosProvider implements DynamicRuleProvider&lt;List&lt;FlowRuleEntity&gt;&gt; &#123; @Autowired private ConfigService configService; @Value(value = \"$&#123;sentinel.nacos.config.refreshTimeoutMs:3000&#125;\") private Integer refreshTimeoutMs; @Override public List&lt;FlowRuleEntity&gt; getRules(String appName, String ip, Integer port) throws Exception &#123; // 从Nacos配置中心拉取配置 String rules = configService.getConfig( appName + NacosConfigUtil.FLOW_DATA_ID_POSTFIX, NacosConfigUtil.GROUP_ID, 3000); if (StringUtil.isEmpty(rules)) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;FlowRule&gt; flowRuleList = JSON.parseArray(rules, FlowRule.class); return flowRuleList.stream() .map(rule -&gt; FlowRuleEntity.fromFlowRule(appName, ip, port, rule)) .collect(Collectors.toList()); &#125;&#125;@Component(\"flowRuleNacosPublisher\")public class FlowRuleNacosPublisher implements DynamicRulePublisher&lt;List&lt;FlowRuleEntity&gt;&gt; &#123; @Autowired private ConfigService configService; @Override public void publish(String app, List&lt;FlowRuleEntity&gt; rules) throws Exception &#123; AssertUtil.notEmpty(app, \"app name cannot be empty\"); if (rules == null) &#123; return; &#125; configService.publishConfig( app + NacosConfigUtil.FLOW_DATA_ID_POSTFIX, NacosConfigUtil.GROUP_ID, NacosConfigUtil.convertToRule(rules)); &#125;&#125;@Configurationpublic class NacosConfig &#123; @Value(value = \"$&#123;sentinel.nacos.config.serverAddr:localhost:8848&#125;\") private String serverAddr; @Bean public ConfigService nacosConfigService() throws Exception &#123; return ConfigFactory.createConfigService(serverAddr); &#125;&#125;","tags":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://yaoyinglong.github.io/tags/Sentinel/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Sentinel","slug":"Cloud/Sentinel","permalink":"https://yaoyinglong.github.io/categories/Cloud/Sentinel/"}]},{"title":"Sentinel限流熔断降级源码","date":"2021-11-03T16:00:00.000Z","path":"Blog/Cloud/Sentinel/Sentinel限流熔断降级源码/","text":"客户端使用Sentinel可通过@SentinelResource注解以AOP增强的方式，也可通过SentinelWebInterceptor拦截器的方式。对于AOP增强的方式是通过在spring-cloud-starter-alibaba-sentinel中的spring.factories中配置的SentinelAutoConfiguration配置类导入的SentinelResourceAspect来配置的AOP增强。 12345678910111213141516171819202122232425@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(name = \"spring.cloud.sentinel.enabled\", matchIfMissing = true)@EnableConfigurationProperties(SentinelProperties.class)public class SentinelAutoConfiguration &#123; @Autowired private SentinelProperties properties; @PostConstruct private void init() &#123; if (properties.isEager()) &#123; // earlier initialize InitExecutor.doInit(); // 调用SPI扩展进行初始化 &#125; &#125; @Bean @ConditionalOnMissingBean public SentinelResourceAspect sentinelResourceAspect() &#123; return new SentinelResourceAspect(); // 对标注@SentinelResource注解的方法进行增强 &#125; @Bean @ConditionalOnMissingBean @ConditionalOnClass(name = \"org.springframework.web.client.RestTemplate\") @ConditionalOnProperty(name = \"resttemplate.sentinel.enabled\", havingValue = \"true\", matchIfMissing = true) public SentinelBeanPostProcessor sentinelBeanPostProcessor(ApplicationContext applicationContext) &#123; return new SentinelBeanPostProcessor(applicationContext); // 通过@SentinelRestTemplate注解对RestTemplate进行增强处理 &#125;&#125; SentinelResourceAspect中其实就是对切点配置，以及Advice方法的配置，对所有标注@SentinelResource注解的方法进行拦截。 123456789101112131415161718192021222324252627282930313233343536373839public class SentinelResourceAspect extends AbstractSentinelAspectSupport &#123; @Pointcut(\"@annotation(com.alibaba.csp.sentinel.annotation.SentinelResource)\") public void sentinelResourceAnnotationPointcut() &#123; // 切点，对所有带有@SentinelResource注解的方法进行拦截 &#125; @Around(\"sentinelResourceAnnotationPointcut()\") public Object invokeResourceWithSentinel(ProceedingJoinPoint pjp) throws Throwable &#123; Method originMethod = resolveMethod(pjp); SentinelResource annotation = originMethod.getAnnotation(SentinelResource.class); // 获取方法上的@SentinelResource注解 if (annotation == null) &#123;// Should not go through here. throw new IllegalStateException(\"Wrong state for SentinelResource annotation\"); &#125; String resourceName = getResourceName(annotation.value(), originMethod); // 获取注解上配置的资源名称 EntryType entryType = annotation.entryType(); // 默认值为OUT int resourceType = annotation.resourceType(); // 默认值为0 Entry entry = null; try &#123;// 申请一个entry，若申请成功，则说明没有被限流，否则抛出BlockException表示已被限流 entry = SphU.entry(resourceName, resourceType, entryType, pjp.getArgs()); Object result = pjp.proceed(); return result; &#125; catch (BlockException ex) &#123; // 规则校验异常，处理注解属性blockHandler中配置的方法 return handleBlockException(pjp, annotation, ex); &#125; catch (Throwable ex) &#123; Class&lt;? extends Throwable&gt;[] exceptionsToIgnore = annotation.exceptionsToIgnore(); // The ignore list will be checked first. if (exceptionsToIgnore.length &gt; 0 &amp;&amp; exceptionBelongsTo(ex, exceptionsToIgnore)) &#123; throw ex; &#125; if (exceptionBelongsTo(ex, annotation.exceptionsToTrace())) &#123; traceException(ex); return handleFallback(pjp, annotation, ex); // 处理抛出的业务异常，处理fallback方法 &#125; throw ex; // No fallback function can handle the exception, so throw it out. &#125; finally &#123; if (entry != null) &#123; entry.exit(1, pjp.getArgs()); &#125; &#125; &#125;&#125; 通过SentinelWebInterceptor拦截器的方式是在spring-cloud-starter-alibaba-sentinel中的spring.factories中配置的SentinelWebAutoConfiguration配置类来完成的，该配置类实现了WebMvcConfigurer，容器启动时向Web拦截器链中添加了SentinelWebInterceptor拦截器来实现Sentinel的集成。 123456789101112131415161718192021@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnProperty(name = \"spring.cloud.sentinel.enabled\", matchIfMissing = true)@ConditionalOnClass(SentinelWebInterceptor.class)@EnableConfigurationProperties(SentinelProperties.class)public class SentinelWebAutoConfiguration implements WebMvcConfigurer &#123; @Autowired private Optional&lt;SentinelWebInterceptor&gt; sentinelWebInterceptorOptional; @Bean @ConditionalOnProperty(name = \"spring.cloud.sentinel.filter.enabled\", matchIfMissing = true) public SentinelWebInterceptor sentinelWebInterceptor(SentinelWebMvcConfig sentinelWebMvcConfig) &#123; return new SentinelWebInterceptor(sentinelWebMvcConfig); &#125; public void addInterceptors(InterceptorRegistry registry) &#123; // 容器启动时调用该方法 if (!sentinelWebInterceptorOptional.isPresent()) &#123; return; // 获取SentinelWebInterceptor，若为空则直接返回 &#125; SentinelProperties.Filter filterConfig = properties.getFilter(); // filterConfig.getUrlPatterns()获取的结果默认置为/**通配符，即所有路径 registry.addInterceptor(sentinelWebInterceptorOptional.get()).order(filterConfig.getOrder()).addPathPatterns(filterConfig.getUrlPatterns()); &#125;&#125; SentinelWebInterceptor拦截器默认为/**即拦截所有路径，最终会调用超类AbstractSentinelInterceptor的preHandle以及afterCompletion方法来完成Sentinel相关的功能。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class SentinelWebInterceptor extends AbstractSentinelInterceptor &#123; private final SentinelWebMvcConfig config; public SentinelWebInterceptor(SentinelWebMvcConfig config) &#123; super(config); if (config == null) &#123; // Use the default config by default. this.config = new SentinelWebMvcConfig(); &#125; else &#123; this.config = config; &#125; &#125; protected String getResourceName(HttpServletRequest request) &#123; // Resolve the Spring Web URL pattern from the request attribute. Object resourceNameObject = request.getAttribute(HandlerMapping.BEST_MATCHING_PATTERN_ATTRIBUTE); if (resourceNameObject == null || !(resourceNameObject instanceof String)) &#123; return null; &#125; String resourceName = (String) resourceNameObject; UrlCleaner urlCleaner = config.getUrlCleaner(); if (urlCleaner != null) &#123; resourceName = urlCleaner.clean(resourceName); &#125; if (StringUtil.isNotEmpty(resourceName) &amp;&amp; config.isHttpMethodSpecify()) &#123; // Add method specification if necessary resourceName = request.getMethod().toUpperCase() + \":\" + resourceName; &#125; return resourceName; &#125; protected String getContextName(HttpServletRequest request) &#123; if (config.isWebContextUnify()) &#123; return super.getContextName(request); &#125; return getResourceName(request); &#125;&#125;public abstract class AbstractSentinelInterceptor implements HandlerInterceptor &#123; public static final String SENTINEL_SPRING_WEB_CONTEXT_NAME = \"sentinel_spring_web_context\"; private static final String EMPTY_ORIGIN = \"\"; private final BaseWebMvcConfig baseWebMvcConfig; public AbstractSentinelInterceptor(BaseWebMvcConfig config) &#123; this.baseWebMvcConfig = config; &#125; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; try &#123; String resourceName = getResourceName(request); if (StringUtil.isEmpty(resourceName)) &#123; return true; &#125; if (increaseReferece(request, this.baseWebMvcConfig.getRequestRefName(), 1) != 1) &#123; return true; &#125; String origin = parseOrigin(request); // Parse the request origin using registered origin parser. String contextName = getContextName(request); ContextUtil.enter(contextName, origin); Entry entry = SphU.entry(resourceName, ResourceTypeConstants.COMMON_WEB, EntryType.IN); request.setAttribute(baseWebMvcConfig.getRequestAttributeName(), entry); return true; &#125; catch (BlockException e) &#123; try &#123; // 处理注解属性blockHandler方法，当抛出BlockException规则校验异常时会被调用 handleBlockException(request, response, e); &#125; finally &#123; ContextUtil.exit(); &#125; return false; &#125; &#125; public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; if (increaseReferece(request, this.baseWebMvcConfig.getRequestRefName(), -1) != 0) &#123; return; &#125; Entry entry = getEntryInRequest(request, baseWebMvcConfig.getRequestAttributeName()); if (entry == null) &#123; // should not happen return; &#125; traceExceptionAndExit(entry, ex); // 在该方法中执行entry.exit() removeEntryInRequest(request); ContextUtil.exit(); &#125; protected String parseOrigin(HttpServletRequest request) &#123; String origin = EMPTY_ORIGIN; if (baseWebMvcConfig.getOriginParser() != null) &#123; origin = baseWebMvcConfig.getOriginParser().parseOrigin(request); if (StringUtil.isEmpty(origin)) &#123; return EMPTY_ORIGIN; &#125; &#125; return origin; &#125; protected String getContextName(HttpServletRequest request) &#123; return SENTINEL_SPRING_WEB_CONTEXT_NAME; &#125;&#125; 具体调用逻辑首先获取规则校验链，规则链是根据其上的@SpiOrder注解中定义的值进行排序的，然后逐个调用Slot校验链中的每个校验规则的entry逻辑，若调用过程抛出BlockException异常，则逐个调用Slot校验链中的每一个校验规则的退出exit逻辑。 12345678910111213141516171819202122232425262728293031323334353637383940public class SphU &#123; public static Entry entry(String name, int resourceType, EntryType trafficType) throws BlockException &#123; return Env.sph.entryWithType(name, resourceType, trafficType, 1, OBJECTS0); &#125;&#125;public class CtSph implements Sph &#123; public Entry entryWithType(String name, int resourceType, EntryType entryType, int count, Object[] args) throws BlockException &#123; return entryWithType(name, resourceType, entryType, count, false, args); &#125; public Entry entryWithType(String name, int resourceType, EntryType entryType, int count, boolean prioritized, Object[] args) throws BlockException &#123; StringResourceWrapper resource = new StringResourceWrapper(name, entryType, resourceType); return entryWithPriority(resource, count, prioritized, args); // prioritized固定传入的false，count固定传入1 &#125; private Entry entryWithPriority(ResourceWrapper resourceWrapper, int count, boolean prioritized, Object... args) throws BlockException &#123; Context context = ContextUtil.getContext(); if (context instanceof NullContext) &#123; return new CtEntry(resourceWrapper, null, context); &#125; if (context == null) &#123; // Using default context. context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME); &#125; if (!Constants.ON) &#123; // 若全局规则开关是关闭的，则不做规则校验 return new CtEntry(resourceWrapper, null, context); &#125; ProcessorSlot&lt;Object&gt; chain = lookProcessChain(resourceWrapper); // 获取规则校验链，规则链是根据其上的@SpiOrder进行排序的 if (chain == null) &#123; // 若规则校验链为null，则不做规则校验 return new CtEntry(resourceWrapper, null, context); &#125; Entry e = new CtEntry(resourceWrapper, chain, context); try &#123; // 逐个调用Slot校验链条中的每个校验规则的entry逻辑 chain.entry(context, resourceWrapper, null, count, prioritized, args); &#125; catch (BlockException e1) &#123; e.exit(count, args); // 逐个调用slot校验链条中的每一个校验规则的退出exit逻辑 throw e1; &#125; catch (Throwable e1) &#123;// This should not happen, unless there are errors existing in Sentinel internal. RecordLog.info(\"Sentinel unexpected exception\", e1); &#125; return e; &#125;&#125; 校验规则链的加载是通过SPI的方式加载SlotChainBuilder接口的实现类，这里默认加载DefaultSlotChainBuilder，在该类的build方法中又通过SPI的方式加载了一系列的ProcessorSlot接口的实现类，且这些校验规则的实现类是根据类上@SpiOrder注解中定义的值来进行排队，且值越小越排在前面执行，若无该注解则默认其排序值为Integer.MAX_VALUE，即排在最后面。校验规则的优先级从高到低为NodeSelectorSlot、ClusterBuilderSlot、LogSlot、StatisticSlot、AuthoritySlot、SystemSlot、FlowSlot、DegradeSlot。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586ProcessorSlot&lt;Object&gt; lookProcessChain(ResourceWrapper resourceWrapper) &#123; ProcessorSlotChain chain = chainMap.get(resourceWrapper); if (chain == null) &#123; synchronized (LOCK) &#123; chain = chainMap.get(resourceWrapper); if (chain == null) &#123; if (chainMap.size() &gt;= Constants.MAX_SLOT_CHAIN_SIZE) &#123; // Entry size limit. return null; // 若chainMap中的规则链数量超过了6000 &#125; chain = SlotChainProvider.newSlotChain(); Map&lt;ResourceWrapper, ProcessorSlotChain&gt; newMap = new HashMap&lt;ResourceWrapper, ProcessorSlotChain&gt;(chainMap.size() + 1); newMap.putAll(chainMap); newMap.put(resourceWrapper, chain); chainMap = newMap; &#125; &#125; &#125; return chain;&#125;public final class SlotChainProvider &#123; private static volatile SlotChainBuilder slotChainBuilder = null; public static ProcessorSlotChain newSlotChain() &#123; if (slotChainBuilder != null) &#123; return slotChainBuilder.build(); &#125; // 通过SPI机制加载Slot Chain加载sentinel-core包下的META-INF/services中对应的文件里的类 slotChainBuilder = SpiLoader.loadFirstInstanceOrDefault(SlotChainBuilder.class, DefaultSlotChainBuilder.class); if (slotChainBuilder == null) &#123;// Should not go through here. RecordLog.warn(\"[SlotChainProvider] Wrong state when resolving slot chain builder, using default\"); slotChainBuilder = new DefaultSlotChainBuilder(); &#125; return slotChainBuilder.build(); // 调用DefaultSlotChainBuilder的build方法 &#125;&#125;public class DefaultSlotChainBuilder implements SlotChainBuilder &#123; public ProcessorSlotChain build() &#123; // 构建资源的slot校验链条，每个资源都有自己独立的校验链条，类似Netty的pipeline ProcessorSlotChain chain = new DefaultProcessorSlotChain(); List&lt;ProcessorSlot&gt; sortedSlotList = SpiLoader.loadPrototypeInstanceListSorted(ProcessorSlot.class); for (ProcessorSlot slot : sortedSlotList) &#123; if (!(slot instanceof AbstractLinkedProcessorSlot)) &#123; continue; // 若ProcessorSlot不是AbstractLinkedProcessorSlot的子类则跳过 &#125; chain.addLast((AbstractLinkedProcessorSlot&lt;?&gt;) slot); // 按照顺序加入到ProcessorSlotChain中 &#125; return chain; &#125;&#125;public final class SpiLoader &#123; public static &lt;T&gt; List&lt;T&gt; loadPrototypeInstanceListSorted(Class&lt;T&gt; clazz) &#123; try &#123; ServiceLoader&lt;T&gt; serviceLoader = ServiceLoaderUtil.getServiceLoader(clazz); List&lt;SpiOrderWrapper&lt;T&gt;&gt; orderWrappers = new ArrayList&lt;&gt;(); for (T spi : serviceLoader) &#123; int order = SpiOrderResolver.resolveOrder(spi); SpiOrderResolver.insertSorted(orderWrappers, spi, order); // 对加载的Slot进行排序，越小越排在前面 &#125; List&lt;T&gt; list = new ArrayList&lt;&gt;(orderWrappers.size()); for (int i = 0; i &lt; orderWrappers.size(); i++) &#123; list.add(orderWrappers.get(i).spi); &#125; return list; &#125; catch (Throwable t) &#123; t.printStackTrace(); return new ArrayList&lt;&gt;(); &#125; &#125; private static class SpiOrderResolver &#123; private static &lt;T&gt; void insertSorted(List&lt;SpiOrderWrapper&lt;T&gt;&gt; list, T spi, int order) &#123; int idx = 0; for (; idx &lt; list.size(); idx++) &#123; if (list.get(idx).getOrder() &gt; order) &#123; break; // 根据@SpiOrder注解中配置的值来进行比较排序，越小越排在前面 &#125; &#125; list.add(idx, new SpiOrderWrapper&lt;&gt;(order, spi)); &#125; private static &lt;T&gt; int resolveOrder(T spi) &#123; if (!spi.getClass().isAnnotationPresent(SpiOrder.class)) &#123; return SpiOrder.LOWEST_PRECEDENCE; &#125; else &#123; return spi.getClass().getAnnotation(SpiOrder.class).value(); &#125; &#125; &#125;&#125; 对于校验链条的调用首先通过DefaultProcessorSlotChain的entry方法调用AbstractLinkedProcessorSlot的transformEntry方法在调用具体实现。 1234567891011public class DefaultProcessorSlotChain extends ProcessorSlotChain &#123; public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args) throws Throwable &#123; first.transformEntry(context, resourceWrapper, t, count, prioritized, args); &#125;&#125;public abstract class AbstractLinkedProcessorSlot&lt;T&gt; implements ProcessorSlot&lt;T&gt; &#123; void transformEntry(Context context, ResourceWrapper resourceWrapper, Object o, int count, boolean prioritized, Object... args) throws Throwable &#123; T t = (T)o; entry(context, resourceWrapper, t, count, prioritized, args); &#125;&#125; 首先调用NodeSelectorSlot校验规则，该规则负责收集资源路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级。通过fireEntry触发下一规则调用。然后调用ClusterBuilderSlot集群校验规则，LogSlot规则很简单其实就是打印日志。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@SpiOrder(-10000)public class NodeSelectorSlot extends AbstractLinkedProcessorSlot&lt;Object&gt; &#123; private volatile Map&lt;String, DefaultNode&gt; map = new HashMap&lt;String, DefaultNode&gt;(10); public void entry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable &#123; // 负责收集资源路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级 DefaultNode node = map.get(context.getName()); if (node == null) &#123; synchronized (this) &#123; node = map.get(context.getName()); if (node == null) &#123; node = new DefaultNode(resourceWrapper, null); HashMap&lt;String, DefaultNode&gt; cacheMap = new HashMap&lt;String, DefaultNode&gt;(map.size()); cacheMap.putAll(map); cacheMap.put(context.getName(), node); map = cacheMap; ((DefaultNode) context.getLastNode()).addChild(node); // Build invocation tree &#125; &#125; &#125; context.setCurNode(node); fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125;&#125;@SpiOrder(-9000)public class ClusterBuilderSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; private static volatile Map&lt;ResourceWrapper, ClusterNode&gt; clusterNodeMap = new HashMap&lt;&gt;(); private volatile ClusterNode clusterNode = null; public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; if (clusterNode == null) &#123; synchronized (lock) &#123; if (clusterNode == null) &#123; // Create the cluster node. clusterNode = new ClusterNode(resourceWrapper.getName(), resourceWrapper.getResourceType()); HashMap&lt;ResourceWrapper, ClusterNode&gt; newMap = new HashMap&lt;&gt;(Math.max(clusterNodeMap.size(), 16)); newMap.putAll(clusterNodeMap); newMap.put(node.getId(), clusterNode); clusterNodeMap = newMap; &#125; &#125; &#125; node.setClusterNode(clusterNode); if (!\"\".equals(context.getOrigin())) &#123; Node originNode = node.getClusterNode().getOrCreateOriginNode(context.getOrigin()); context.getCurEntry().setOriginNode(originNode); &#125; fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125;&#125;@SpiOrder(-8000)public class LogSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode obj, int count, boolean prioritized, Object... args) throws Throwable &#123; try &#123; fireEntry(context, resourceWrapper, obj, count, prioritized, args); &#125; catch (BlockException e) &#123; EagleEyeLogUtil.log(resourceWrapper.getName(), e.getClass().getSimpleName(), e.getRuleLimitApp(), context.getOrigin(), count); throw e; &#125; catch (Throwable e) &#123; RecordLog.warn(\"Unexpected entry exception\", e); &#125; &#125;&#125; 接下来是稍微复杂一点的StatisticSlot，用于存储资源统计信息以及调用者信息，例如该资源的RT、QPS、threadCount等等，这些信息将作为多维度限流降级的依据。其主要是在StatisticNode类中实现了滑动窗口算法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@SpiOrder(-7000)public class StatisticSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; try &#123; // 用于存储资源的统计信息以及调用者信息，例如该资源的RT、QPS、threadCount等等，这些信息将作为多维度限流降级的依据 // Do some checking. fireEntry(context, resourceWrapper, node, count, prioritized, args); // 触发下移规则调用 // Request passed, add thread count and pass count. node.increaseThreadNum(); // 当前调用线程数加一 node.addPassRequest(count); // 增加规则校验通过调用数，调用滑动时间窗口计数算法请求 if (context.getCurEntry().getOriginNode() != null) &#123; // Add count for origin node. context.getCurEntry().getOriginNode().increaseThreadNum(); context.getCurEntry().getOriginNode().addPassRequest(count); &#125; if (resourceWrapper.getEntryType() == EntryType.IN) &#123; Constants.ENTRY_NODE.increaseThreadNum(); Constants.ENTRY_NODE.addPassRequest(count); &#125; for (ProcessorSlotEntryCallback&lt;DefaultNode&gt; handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) &#123; handler.onPass(context, resourceWrapper, node, count, args); &#125; &#125; catch (PriorityWaitException ex) &#123; node.increaseThreadNum(); if (context.getCurEntry().getOriginNode() != null) &#123; context.getCurEntry().getOriginNode().increaseThreadNum(); &#125; if (resourceWrapper.getEntryType() == EntryType.IN) &#123; Constants.ENTRY_NODE.increaseThreadNum(); &#125; for (ProcessorSlotEntryCallback&lt;DefaultNode&gt; handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) &#123; handler.onPass(context, resourceWrapper, node, count, args); &#125; &#125; catch (BlockException e) &#123; // Blocked, set block exception to current entry. context.getCurEntry().setBlockError(e); node.increaseBlockQps(count); // 增加被规则限流的调用数 if (context.getCurEntry().getOriginNode() != null) &#123; context.getCurEntry().getOriginNode().increaseBlockQps(count); &#125; if (resourceWrapper.getEntryType() == EntryType.IN) &#123; Constants.ENTRY_NODE.increaseBlockQps(count); &#125; for (ProcessorSlotEntryCallback&lt;DefaultNode&gt; handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) &#123; handler.onBlocked(e, context, resourceWrapper, node, count, args); &#125; throw e; &#125; catch (Throwable e) &#123; // Unexpected internal error, set error to current entry. context.getCurEntry().setError(e); throw e; &#125; &#125;&#125; StatisticNode中定义了两个滑动时间窗口，一个是秒级别的滑动时间窗口rollingCounterInSecond，有两个窗格每个窗格500ms。分钟级别的滑动时间窗口rollingCounterInMinute，有60个窗格，每个窗格1s。两个时间窗口底层都是通过ArrayMetric来实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class StatisticNode implements Node &#123; // 初始化一个跨度为1000ms包含两个500ms时间窗口对象rollingCounterInSecond，初始化时两个小窗口为空 private transient volatile Metric rollingCounterInSecond = new ArrayMetric(SampleCountProperty.SAMPLE_COUNT, IntervalProperty.INTERVAL); // 初始化一个跨度为一分钟包含60个1s时间窗口对象rollingCounterInMinute，初始化时每个小窗口为空 private transient Metric rollingCounterInMinute = new ArrayMetric(60, 60 * 1000, false); private LongAdder curThreadNum = new LongAdder(); private long lastFetchTime = -1; public void addPassRequest(int count) &#123; rollingCounterInSecond.addPass(count); // 将通过的请求添加到秒级时间窗口中 rollingCounterInMinute.addPass(count); // 将通过的请求添加到分钟级时间窗口中 &#125;&#125;public class ArrayMetric implements Metric &#123; private final LeapArray&lt;MetricBucket&gt; data; public ArrayMetric(int sampleCount, int intervalInMs) &#123; // sampleCount为2，intervalInMs为1000ms this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs); &#125; public ArrayMetric(int sampleCount, int intervalInMs, boolean enableOccupy) &#123; if (enableOccupy) &#123; this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs); &#125; else &#123; // 默认走下面这个分支，sampleCount默认为60，intervalInMs默认为60 * 1000 this.data = new BucketLeapArray(sampleCount, intervalInMs); &#125; &#125;&#125;public class OccupiableBucketLeapArray extends LeapArray&lt;MetricBucket&gt; &#123; public OccupiableBucketLeapArray(int sampleCount, int intervalInMs) &#123; super(sampleCount, intervalInMs); this.borrowArray = new FutureBucketLeapArray(sampleCount, intervalInMs); &#125;&#125;public abstract class LeapArray&lt;T&gt; &#123; protected int windowLengthInMs; protected int sampleCount; protected int intervalInMs; protected final AtomicReferenceArray&lt;WindowWrap&lt;T&gt;&gt; array; public LeapArray(int sampleCount, int intervalInMs) &#123; // 初始化一个跨度为1000ms包含两个500ms时间窗口对象，初始化时两个小窗口为空 this.windowLengthInMs = intervalInMs / sampleCount; // 时间窗口长度为500ms this.intervalInMs = intervalInMs; this.sampleCount = sampleCount; this.array = new AtomicReferenceArray&lt;&gt;(sampleCount); // 数组长度为2，放时间窗口的数组 &#125;&#125; 通过LeapArray的currentWindow方法根据当前时间获取当前对应的窗格，首先根据当前时间计算出当前请求应该处于的窗格下标，再根据当前时间计算出当前窗格的起始时间。从时间窗口数组中获取根据当前时间计算的下标对应的old时间窗口，若old时间窗口为空，则新建一个时间窗口，并放入时间窗口数组中并返回创建的时间窗格；若old时间窗口起始时间跟依据当前时间计算出的时间窗口起始时间相同，则当前时间应该落在old时间窗口内，直接返回old时间窗；若依据当前时间算出的时间窗口起始时间大于old时间窗口的起始时间，则将old时间窗口重置，变为当前时间应该落入的时间窗口。相当于实现了一个循环数组。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class StatisticNode implements Node &#123; private final LeapArray&lt;MetricBucket&gt; data; public void addPassRequest(int count) &#123; // 初始化一个跨度为1000ms包含两个500ms时间窗口对象rollingCounterInSecond，初始化时两个小窗口为空 rollingCounterInSecond.addPass(count); // 初始化一个跨度为一分钟包含60个1s时间窗口对象rollingCounterInMinute，初始化时每个小窗口为空 rollingCounterInMinute.addPass(count); &#125;&#125;public class ArrayMetric implements Metric &#123; public void addPass(int count) &#123; WindowWrap&lt;MetricBucket&gt; wrap = data.currentWindow(); // 根据当前时间定位到具体的窗格 wrap.value().addPass(count); // 将具体的窗格的具体指标加一 &#125;&#125;public abstract class LeapArray&lt;T&gt; &#123; public WindowWrap&lt;T&gt; currentWindow() &#123; // 根据当前时间定位到具体的窗格 return currentWindow(TimeUtil.currentTimeMillis()); &#125; public WindowWrap&lt;T&gt; currentWindow(long timeMillis) &#123; if (timeMillis &lt; 0) &#123; return null; &#125; int idx = calculateTimeIdx(timeMillis); // 根据当前时间计算当前计数应该落在哪个小窗格中 long windowStart = calculateWindowStart(timeMillis); // 计算当前时间窗口的起始时间位置 while (true) &#123; WindowWrap&lt;T&gt; old = array.get(idx); // 从时间窗口数组中获取一句当前时间计算的下标对应的old时间窗口 if (old == null) &#123; // 若old时间窗口为空，则新建一个时间窗口，并放入时间窗口数组中 WindowWrap&lt;T&gt; window = new WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); if (array.compareAndSet(idx, null, window)) &#123; return window; &#125; else &#123; Thread.yield(); &#125; &#125; else if (windowStart == old.windowStart()) &#123; return old; // 若old时间窗口起始时间跟依据当前时间计算出的时间窗口起始时间相同，则当前时间应该落在old时间窗口内，直接返回old时间窗 &#125; else if (windowStart &gt; old.windowStart()) &#123; if (updateLock.tryLock()) &#123; try &#123; // 若依据当前时间算出的时间窗口起始时间大于old时间窗口的起始时间，则将old时间窗口重置，变为当前时间应该落入的时间窗口 return resetWindowTo(old, windowStart); &#125; finally &#123; updateLock.unlock(); &#125; &#125; else &#123; Thread.yield(); &#125; &#125; else if (windowStart &lt; old.windowStart()) &#123; // 不会出现，除非出现时钟回拨 return new WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); &#125; &#125; &#125; private int calculateTimeIdx(/*@Valid*/ long timeMillis) &#123; long timeId = timeMillis / windowLengthInMs; // 秒级windowLengthInMs为500ms，分钟级windowLengthInMs为1000ms return (int)(timeId % array.length()); &#125; protected long calculateWindowStart(/*@Valid*/ long timeMillis) &#123; return timeMillis - timeMillis % windowLengthInMs; // 秒级windowLengthInMs为500ms，分钟级windowLengthInMs为1000ms &#125;&#125; 在统计计数时根据请求调用结果事件类型创建一个数组，不同的类型将计数加到其对应的数组下标的LongAdder中。 123456789101112131415161718192021222324252627public class MetricBucket &#123; private final LongAdder[] counters; private volatile long minRt; // 默认值为5000 public MetricBucket() &#123; MetricEvent[] events = MetricEvent.values(); // 根据所有的状态类型创建一个数组 this.counters = new LongAdder[events.length]; for (MetricEvent event : events) &#123; counters[event.ordinal()] = new LongAdder(); &#125; initMinRt(); &#125; public void addPass(int n) &#123; add(MetricEvent.PASS, n); // 增加时间窗口中的请求通过数 &#125; public MetricBucket add(MetricEvent event, long n) &#123; counters[event.ordinal()].add(n); // 时间窗口中请求数据统计实际放在一个counter数组中，不停的下标代表不同的数据统计指标 return this; &#125;&#125;public enum MetricEvent &#123; PASS, // 通过所有校验规则 BLOCK, // 未通过校验规则，抛出BlockException的调用 EXCEPTION, // 发生业务异常的调用 SUCCESS, // 调用完成的情况，不管是否抛出异常 RT, // 所有的SUCCESS调用耗时的总时间 OCCUPIED_PASS&#125; 授权规则也相对简单其实就是对配置的黑白名单进行校验，判断若授权规则为黑名单且请求者包含在黑名单中，或若授权规则为白名单且请求者不包含在白名单中则抛出授权规则异常。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@SpiOrder(-6000)public class AuthoritySlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; checkBlackWhiteAuthority(resourceWrapper, context); // 校验资源授权规则，黑名单白名单规则校验 fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; void checkBlackWhiteAuthority(ResourceWrapper resource, Context context) throws AuthorityException &#123; Map&lt;String, Set&lt;AuthorityRule&gt;&gt; authorityRules = AuthorityRuleManager.getAuthorityRules(); if (authorityRules == null) &#123; return; &#125; Set&lt;AuthorityRule&gt; rules = authorityRules.get(resource.getName()); if (rules == null) &#123; return; &#125; for (AuthorityRule rule : rules) &#123; // 授权规则遍历 if (!AuthorityRuleChecker.passCheck(rule, context)) &#123; // 若授权规则为黑名单且请求者包含在黑名单中，或若授权规则为白名单且请求者不包含在白名单中 throw new AuthorityException(context.getOrigin(), rule); &#125; &#125; &#125;&#125;final class AuthorityRuleChecker &#123; static boolean passCheck(AuthorityRule rule, Context context) &#123; String requester = context.getOrigin(); if (StringUtil.isEmpty(requester) || StringUtil.isEmpty(rule.getLimitApp())) &#123; return true; // Empty origin or empty limitApp will pass. &#125; int pos = rule.getLimitApp().indexOf(requester); // Do exact match with origin name. boolean contain = pos &gt; -1; if (contain) &#123; boolean exactlyMatch = false; String[] appArray = rule.getLimitApp().split(\",\"); for (String app : appArray) &#123; if (requester.equals(app)) &#123; exactlyMatch = true; break; &#125; &#125; contain = exactlyMatch; &#125; int strategy = rule.getStrategy(); if (strategy == RuleConstant.AUTHORITY_BLACK &amp;&amp; contain) &#123; return false; // 若授权规则为黑名单且请求者包含在黑名单中 &#125; if (strategy == RuleConstant.AUTHORITY_WHITE &amp;&amp; !contain) &#123; return false; // 若授权规则为白名单且请求者不包含在白名单中 &#125; return true; &#125;&#125; SystemSlot系统规则中QPS、RT、线程数都是使用统计规则StatisticSlot中统计的数据，然后进行了相关的计算判断。 12345678910111213141516171819202122232425262728293031323334353637383940@SpiOrder(-5000)public class SystemSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; SystemRuleManager.checkSystem(resourceWrapper); fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125;&#125;public final class SystemRuleManager &#123; public static void checkSystem(ResourceWrapper resourceWrapper) throws BlockException &#123; if (resourceWrapper == null) &#123; return; &#125; if (!checkSystemStatus.get()) &#123; // Ensure the checking switch is on. return; // 若系统校验资源规则开关是关闭的 &#125; if (resourceWrapper.getEntryType() != EntryType.IN) &#123; // for inbound traffic only return; // 系统资源校验规则只对EntryType.IN入模式生效 &#125; double currentQps = Constants.ENTRY_NODE == null ? 0.0 : Constants.ENTRY_NODE.successQps(); if (currentQps &gt; qps) &#123; // total qps throw new SystemBlockException(resourceWrapper.getName(), \"qps\"); &#125; int currentThread = Constants.ENTRY_NODE == null ? 0 : Constants.ENTRY_NODE.curThreadNum(); if (currentThread &gt; maxThread) &#123; // total thread throw new SystemBlockException(resourceWrapper.getName(), \"thread\"); &#125; double rt = Constants.ENTRY_NODE == null ? 0 : Constants.ENTRY_NODE.avgRt(); if (rt &gt; maxRt) &#123; throw new SystemBlockException(resourceWrapper.getName(), \"rt\"); &#125; if (highestSystemLoadIsSet &amp;&amp; getCurrentSystemAvgLoad() &gt; highestSystemLoad) &#123; // load. BBR algorithm. if (!checkBbr(currentThread)) &#123; throw new SystemBlockException(resourceWrapper.getName(), \"load\"); &#125; &#125; if (highestCpuUsageIsSet &amp;&amp; getCurrentCpuUsage() &gt; highestCpuUsage) &#123; // cpu usage throw new SystemBlockException(resourceWrapper.getName(), \"cpu\"); &#125; &#125;&#125; FlowSlot流控规则首先获取所有该资源配置的流控规则，若未配置直接返回，否则根据流控模式获取具体的目标资源，然后通过canPass方法调用具体的流控效果类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@SpiOrder(-2000)public class FlowSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; checkFlow(resourceWrapper, context, node, count, prioritized); fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; void checkFlow(ResourceWrapper resource, Context context, DefaultNode node, int count, boolean prioritized) throws BlockException &#123; checker.checkFlow(ruleProvider, resource, context, node, count, prioritized); &#125; private final Function&lt;String, Collection&lt;FlowRule&gt;&gt; ruleProvider = new Function&lt;String, Collection&lt;FlowRule&gt;&gt;() &#123; @Override public Collection&lt;FlowRule&gt; apply(String resource) &#123; // Flow rule map should not be null. Map&lt;String, List&lt;FlowRule&gt;&gt; flowRules = FlowRuleManager.getFlowRuleMap();// 获取所有配置的流控规则列表 return flowRules.get(resource);// 获取该资源相关的流控规则 &#125; &#125;;&#125;public class FlowRuleChecker &#123; public void checkFlow(Function&lt;String, Collection&lt;FlowRule&gt;&gt; ruleProvider, ResourceWrapper resource, Context context, DefaultNode node, int count, boolean prioritized) throws BlockException &#123; if (ruleProvider == null || resource == null) &#123; return; &#125; Collection&lt;FlowRule&gt; rules = ruleProvider.apply(resource.getName()); // 获取资源相关的校验规则 if (rules != null) &#123; for (FlowRule rule : rules) &#123; // 对资源逐条校验每个规则 if (!canPassCheck(rule, context, node, count, prioritized)) &#123; throw new FlowException(rule.getLimitApp(), rule); &#125; &#125; &#125; &#125; public boolean canPassCheck(/*@NonNull*/ FlowRule rule, Context context, DefaultNode node, int acquireCount, boolean prioritized) &#123; String limitApp = rule.getLimitApp(); if (limitApp == null) &#123; return true; &#125; if (rule.isClusterMode()) &#123; // 集群限流规则 return passClusterCheck(rule, context, node, acquireCount, prioritized); &#125; return passLocalCheck(rule, context, node, acquireCount, prioritized); // 单机限流规则 &#125; private static boolean passLocalCheck(FlowRule rule, Context context, DefaultNode node, int acquireCount, boolean prioritized) &#123; Node selectedNode = selectNodeByRequesterAndStrategy(rule, context, node); if (selectedNode == null) &#123; return true; &#125; return rule.getRater().canPass(selectedNode, acquireCount, prioritized); &#125; static Node selectNodeByRequesterAndStrategy(/*@NonNull*/ FlowRule rule, Context context, DefaultNode node) &#123; String limitApp = rule.getLimitApp(); // The limit app should not be empty. int strategy = rule.getStrategy(); String origin = context.getOrigin(); if (limitApp.equals(origin) &amp;&amp; filterOrigin(origin)) &#123; if (strategy == RuleConstant.STRATEGY_DIRECT) &#123; // 流控模式：直接 // Matches limit origin, return origin statistic node. return context.getOriginNode(); &#125; return selectReferenceNode(rule, context, node); &#125; else if (RuleConstant.LIMIT_APP_DEFAULT.equals(limitApp)) &#123; if (strategy == RuleConstant.STRATEGY_DIRECT) &#123; // 流控模式：关联 // Return the cluster node. return node.getClusterNode(); &#125; return selectReferenceNode(rule, context, node); &#125; else if (RuleConstant.LIMIT_APP_OTHER.equals(limitApp) &amp;&amp; FlowRuleManager.isOtherOrigin(origin, rule.getResource())) &#123; if (strategy == RuleConstant.STRATEGY_DIRECT) &#123; // 流控模式：链路 return context.getOriginNode(); &#125; return selectReferenceNode(rule, context, node); &#125; return null; &#125; static Node selectReferenceNode(FlowRule rule, Context context, DefaultNode node) &#123; String refResource = rule.getRefResource(); int strategy = rule.getStrategy(); if (StringUtil.isEmpty(refResource)) &#123; return null; &#125; if (strategy == RuleConstant.STRATEGY_RELATE) &#123; // 流控模式：关联 return ClusterBuilderSlot.getClusterNode(refResource); &#125; if (strategy == RuleConstant.STRATEGY_CHAIN) &#123; // 流控模式：链路 if (!refResource.equals(context.getName())) &#123; return null; &#125; return node; &#125; return null; // No node. &#125;&#125; 直接失败流控效果相对简单，其实现类是DefaultController，直接从当前秒级的时间窗口中遍历所有小窗格，获取通过所有校验规则请求数，即QPS数，若当前QPS加请求数大于配置的值，则返回false直接抛出异常。 1234567891011121314151617181920212223242526272829public class DefaultController implements TrafficShapingController &#123; public boolean canPass(Node node, int acquireCount, boolean prioritized) &#123; // 快速失败 int curCount = avgUsedTokens(node); // 从当前时间窗口中取统计指标数据 if (curCount + acquireCount &gt; count) &#123; // 若当前qps大于count阈值返回false，校验不通过 if (prioritized &amp;&amp; grade == RuleConstant.FLOW_GRADE_QPS) &#123; // prioritized一般传入的false long currentTime; long waitInMs; currentTime = TimeUtil.currentTimeMillis(); waitInMs = node.tryOccupyNext(currentTime, acquireCount, count); if (waitInMs &lt; OccupyTimeoutProperty.getOccupyTimeout()) &#123; node.addWaitingRequest(currentTime + waitInMs, acquireCount); node.addOccupiedPass(acquireCount); sleep(waitInMs); // PriorityWaitException indicates that the request will pass after waiting for &#123;@link @waitInMs&#125;. throw new PriorityWaitException(waitInMs); &#125; &#125; return false; &#125; return true; &#125; private int avgUsedTokens(Node node) &#123; if (node == null) &#123; return DEFAULT_AVG_USED_TOKENS; &#125; // 若阈值类型是QPS则返回QPS若是线程数则返回当前线程数 return grade == RuleConstant.FLOW_GRADE_THREAD ? node.curThreadNum() : (int)(node.passQps()); &#125;&#125; 预热流控效果使用的是令牌桶算法实现的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class WarmUpController implements TrafficShapingController &#123; protected double count; private int coldFactor; protected int warningToken = 0; private int maxToken; protected double slope; protected AtomicLong storedTokens = new AtomicLong(0); protected AtomicLong lastFilledTime = new AtomicLong(0); public WarmUpController(double count, int warmUpPeriodInSec, int coldFactor) &#123; construct(count, warmUpPeriodInSec, coldFactor); &#125; private void construct(double count, int warmUpPeriodInSec, int coldFactor) &#123; if (coldFactor &lt;= 1) &#123; throw new IllegalArgumentException(\"Cold factor should be larger than 1\"); &#125; this.count = count; this.coldFactor = coldFactor; // thresholdPermits = 0.5 * warmupPeriod / stableInterval. warningToken = 100; warningToken = (int)(warmUpPeriodInSec * count) / (coldFactor - 1); // / maxPermits = thresholdPermits + 2 * warmupPeriod / (stableInterval + coldInterval) maxToken = 200 maxToken = warningToken + (int)(2 * warmUpPeriodInSec * count / (1.0 + coldFactor)); // slope = (coldIntervalMicros - stableIntervalMicros) / (maxPermits - thresholdPermits); slope = (coldFactor - 1.0) / count / (maxToken - warningToken); &#125; public boolean canPass(Node node, int acquireCount) &#123; return canPass(node, acquireCount, false); &#125; public boolean canPass(Node node, int acquireCount, boolean prioritized) &#123; // 通过令牌桶算法来完成预热 long passQps = (long) node.passQps(); long previousQps = (long) node.previousPassQps(); syncToken(previousQps); // 开始计算它的斜率，如果进入了警戒线，开始调整他的qps long restToken = storedTokens.get(); if (restToken &gt;= warningToken) &#123; long aboveToken = restToken - warningToken; // 消耗的速度要比warning快，但是要比慢，current interval = restToken*slope+1/count double warningQps = Math.nextUp(1.0 / (aboveToken * slope + 1.0 / count)); if (passQps + acquireCount &lt;= warningQps) &#123; return true; &#125; &#125; else &#123; if (passQps + acquireCount &lt;= count) &#123; return true; &#125; &#125; return false; &#125; protected void syncToken(long passQps) &#123; long currentTime = TimeUtil.currentTimeMillis(); currentTime = currentTime - currentTime % 1000; long oldLastFillTime = lastFilledTime.get(); if (currentTime &lt;= oldLastFillTime) &#123; return; &#125; long oldValue = storedTokens.get(); long newValue = coolDownTokens(currentTime, passQps); if (storedTokens.compareAndSet(oldValue, newValue)) &#123; long currentValue = storedTokens.addAndGet(0 - passQps); if (currentValue &lt; 0) &#123; storedTokens.set(0L); &#125; lastFilledTime.set(currentTime); &#125; &#125; private long coolDownTokens(long currentTime, long passQps) &#123; long oldValue = storedTokens.get(); long newValue = oldValue; // 添加令牌的判断前提条件: 当令牌的消耗程度远远低于警戒线的时候 if (oldValue &lt; warningToken) &#123; newValue = (long)(oldValue + (currentTime - lastFilledTime.get()) * count / 1000); &#125; else if (oldValue &gt; warningToken) &#123; if (passQps &lt; (int)count / coldFactor) &#123; newValue = (long)(oldValue + (currentTime - lastFilledTime.get()) * count / 1000); &#125; &#125; return Math.min(newValue, maxToken); &#125;&#125; 排队等待流控效果是使用漏桶算法实现，Sentinel是根据配置的QPS计算出请求的间隔时间，然后根据间隔时间来计算请求是被直接拒绝还是休眠等待。 1234567891011121314151617181920212223242526272829303132333435363738394041public class RateLimiterController implements TrafficShapingController &#123; private final int maxQueueingTimeMs; private final double count; private final AtomicLong latestPassedTime = new AtomicLong(-1); public boolean canPass(Node node, int acquireCount, boolean prioritized) &#123; // 使用漏桶算法 if (acquireCount &lt;= 0) &#123; // Pass when acquire count is less or equal than 0. return true; &#125; if (count &lt;= 0) &#123; // Reject when count is less or equal than 0. return false; // Otherwise,the costTime will be max of long and waitTime will overflow in some cases. &#125; long currentTime = TimeUtil.currentTimeMillis(); long costTime = Math.round(1.0 * (acquireCount) / count * 1000); // 根据配置的QPS计算每两个请求之间的间隔 long expectedTime = costTime + latestPassedTime.get(); // 此请求的预期通过时间 if (expectedTime &lt;= currentTime) &#123; // Contention may exist here, but it's okay. latestPassedTime.set(currentTime); return true; &#125; else &#123;// Calculate the time to wait. long waitTime = costTime + latestPassedTime.get() - TimeUtil.currentTimeMillis(); // 计算等待时间 if (waitTime &gt; maxQueueingTimeMs) &#123; // 若等待时间超过超时时间，则直接拒绝 return false; &#125; else &#123; long oldTime = latestPassedTime.addAndGet(costTime); try &#123; waitTime = oldTime - TimeUtil.currentTimeMillis(); if (waitTime &gt; maxQueueingTimeMs) &#123; latestPassedTime.addAndGet(-costTime); return false; &#125; if (waitTime &gt; 0) &#123; // in race condition waitTime may &lt;= 0 Thread.sleep(waitTime); // 休眠等待时长的时间 &#125; return true; &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; return false; &#125;&#125; 资源降级规则若熔断器开关是关闭状态直接通过，若是打开状态首先判断时间是否达到了熔断结束时间，若达到了则将开关置为半开状态，放一个请求去执行，若请求执行失败则继续将断路器开关置为打开状态，在exit操作时会计算失败比例，然后判断更新断路器状态。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@SpiOrder(-1000)public class DegradeSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; performChecking(context, resourceWrapper); fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; void performChecking(Context context, ResourceWrapper r) throws BlockException &#123; List&lt;CircuitBreaker&gt; circuitBreakers = DegradeRuleManager.getCircuitBreakers(r.getName()); if (circuitBreakers == null || circuitBreakers.isEmpty()) &#123; return; &#125; for (CircuitBreaker cb : circuitBreakers) &#123; if (!cb.tryPass(context)) &#123; throw new DegradeException(cb.getRule().getLimitApp(), cb.getRule()); &#125; &#125; &#125;&#125;public abstract class AbstractCircuitBreaker implements CircuitBreaker &#123; public boolean tryPass(Context context) &#123; if (currentState.get() == State.CLOSED) &#123; // Template implementation. return true; // 若熔断器开关是关闭状态 &#125; if (currentState.get() == State.OPEN) &#123; // 若熔断器开关是打开状态 return retryTimeoutArrived() &amp;&amp; fromOpenToHalfOpen(context); // 对于半开状态，允许请求探测 &#125; return false; &#125; protected boolean fromOpenToHalfOpen(Context context) &#123; if (currentState.compareAndSet(State.OPEN, State.HALF_OPEN)) &#123; notifyObservers(State.OPEN, State.HALF_OPEN, null); Entry entry = context.getCurEntry(); entry.whenTerminate(new BiConsumer&lt;Context, Entry&gt;() &#123; @Override public void accept(Context context, Entry entry) &#123; if (entry.getBlockError() != null) &#123; // 若依然请求失败，将断路器继续打开 currentState.compareAndSet(State.HALF_OPEN, State.OPEN); notifyObservers(State.HALF_OPEN, State.OPEN, 1.0d); &#125; &#125; &#125;); return true; &#125; return false; &#125; protected boolean fromHalfOpenToOpen(double snapshotValue) &#123; if (currentState.compareAndSet(State.HALF_OPEN, State.OPEN)) &#123; updateNextRetryTimestamp(); // 只要断路器再次被打开，就会按配置的熔断时长更新断路器的熔断周期 notifyObservers(State.HALF_OPEN, State.OPEN, snapshotValue); return true; &#125; return false; &#125; protected boolean fromHalfOpenToClose() &#123; if (currentState.compareAndSet(State.HALF_OPEN, State.CLOSED)) &#123; resetStat(); // 重置慢调用和中调用统计次数为0 notifyObservers(State.HALF_OPEN, State.CLOSED, null); return true; &#125; return false; &#125; protected void transformToOpen(double triggerValue) &#123; State cs = currentState.get(); switch (cs) &#123; case CLOSED: fromCloseToOpen(triggerValue); break; case HALF_OPEN: fromHalfOpenToOpen(triggerValue); break; default: break; &#125; &#125;&#125; Sentinel中断路器有根据异常数及比例降级ExceptionCircuitBreaker，和慢调用比例降级ResponseTimeCircuitBreaker两种实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class ExceptionCircuitBreaker extends AbstractCircuitBreaker &#123; // 调用异常数及比例判断逻辑 public void onRequestComplete(Context context) &#123; // 调用异常数及比例判断逻辑 Entry entry = context.getCurEntry(); if (entry == null) &#123; return; &#125; Throwable error = entry.getError(); SimpleErrorCounter counter = stat.currentWindow().value(); if (error != null) &#123; counter.getErrorCount().add(1); &#125; counter.getTotalCount().add(1); handleStateChangeWhenThresholdExceeded(error); &#125; private void handleStateChangeWhenThresholdExceeded(Throwable error) &#123; if (currentState.get() == State.OPEN) &#123; return; &#125; if (currentState.get() == State.HALF_OPEN) &#123; if (error == null) &#123; // In detecting request fromHalfOpenToClose(); &#125; else &#123; fromHalfOpenToOpen(1.0d); &#125; return; &#125; List&lt;SimpleErrorCounter&gt; counters = stat.values(); long errCount = 0; long totalCount = 0; for (SimpleErrorCounter counter : counters) &#123; errCount += counter.errorCount.sum(); totalCount += counter.totalCount.sum(); &#125; if (totalCount &lt; minRequestAmount) &#123; return; &#125; double curCount = errCount; if (strategy == DEGRADE_GRADE_EXCEPTION_RATIO) &#123; curCount = errCount * 1.0d / totalCount; // Use errorRatio &#125; if (curCount &gt; threshold) &#123; transformToOpen(curCount); &#125; &#125;&#125;public class ResponseTimeCircuitBreaker extends AbstractCircuitBreaker &#123; public void onRequestComplete(Context context) &#123; // 慢调用比例降级判断逻辑 SlowRequestCounter counter = slidingCounter.currentWindow().value(); Entry entry = context.getCurEntry(); if (entry == null) &#123; return; &#125; long completeTime = entry.getCompleteTimestamp(); if (completeTime &lt;= 0) &#123; completeTime = TimeUtil.currentTimeMillis(); &#125; long rt = completeTime - entry.getCreateTimestamp(); if (rt &gt; maxAllowedRt) &#123; counter.slowCount.add(1); // 若请求响应时间超过最大RT时间，把慢调用次数加一 &#125; counter.totalCount.add(1); // 总调用次数加一 handleStateChangeWhenThresholdExceeded(rt); // 调用完处理断路器状态 &#125; private void handleStateChangeWhenThresholdExceeded(long rt) &#123; if (currentState.get() == State.OPEN) &#123; return; // 若断路器是打开状态直接返回 &#125; if (currentState.get() == State.HALF_OPEN) &#123; // 若断路器是搬开状态 if (rt &gt; maxAllowedRt) &#123; // 断路器半开状态一般都是尝试调用一次请求，若这次调用响应时间依然超过最大RT阈值则将断路器打开 fromHalfOpenToOpen(1.0d); &#125; else &#123; // 若这次调用响应时间没有超过最大RT阈值则将断路器关闭 fromHalfOpenToClose(); &#125; return; &#125; // 走到这里说明断路器是关闭状态的 List&lt;SlowRequestCounter&gt; counters = slidingCounter.values(); long slowCount = 0; long totalCount = 0; for (SlowRequestCounter counter : counters) &#123; slowCount += counter.slowCount.sum(); // 时间窗口内慢调用次数中总和 totalCount += counter.totalCount.sum(); // 时间窗口内总调用次数中总和 &#125; if (totalCount &lt; minRequestAmount) &#123; return; // 若总调用次数小于配置最小请求数，则不修改断路器状态，直接返回 &#125; double currentRatio = slowCount * 1.0d / totalCount; // 计算慢调用比例 if (currentRatio &gt; maxSlowRequestRatio) &#123; transformToOpen(currentRatio); // 若慢调用比例超过配置阈值则将断路器打开 &#125; &#125;&#125;","tags":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://yaoyinglong.github.io/tags/Sentinel/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Sentinel","slug":"Cloud/Sentinel","permalink":"https://yaoyinglong.github.io/categories/Cloud/Sentinel/"}]},{"title":"Sentinel规则发布源码","date":"2021-11-02T16:00:00.000Z","path":"Blog/Cloud/Sentinel/Sentinel规则发布源码/","text":"Sentinel规则发布是通过Dashboard模块的FlowControllerV1的apiAddFlowRule方法，首先将数据保存到服务端缓存中，若扩展了持久化可进行先关的持久化，然后和sentinel客户端通信，异步设置流控规则将数据推送给客户端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115@RestController@RequestMapping(value = \"/v1/flow\")public class FlowControllerV1 &#123; @Autowired private InMemoryRuleRepositoryAdapter&lt;FlowRuleEntity&gt; repository; @Autowired private SentinelApiClient sentinelApiClient; @PostMapping(\"/rule\") @AuthAction(PrivilegeType.WRITE_RULE) public Result&lt;FlowRuleEntity&gt; apiAddFlowRule(@RequestBody FlowRuleEntity entity) &#123; Result&lt;FlowRuleEntity&gt; checkResult = checkEntityInternal(entity); if (checkResult != null) &#123; return checkResult; &#125; entity.setId(null); Date date = new Date(); entity.setGmtCreate(date); entity.setGmtModified(date); entity.setLimitApp(entity.getLimitApp().trim()); entity.setResource(entity.getResource().trim()); try &#123; entity = repository.save(entity); // 控制台保存规则，持久化扩展点RuleRepository publishRules(entity.getApp(), entity.getIp(), entity.getPort()).get(5000, TimeUnit.MILLISECONDS); return Result.ofSuccess(entity); &#125; catch (Throwable t) &#123; Throwable e = t instanceof ExecutionException ? t.getCause() : t; return Result.ofFail(-1, e.getMessage()); &#125; &#125;&#125;public abstract class InMemoryRuleRepositoryAdapter&lt;T extends RuleEntity&gt; implements RuleRepository&lt;T, Long&gt; &#123; // 通过客户端服务名称、IP、端口以及服务端生成的ID来嵌套映射存储发布的规则 private Map&lt;MachineInfo, Map&lt;Long, T&gt;&gt; machineRules = new ConcurrentHashMap&lt;&gt;(16); // 通过服务端生成的ID映射存储发布的规则 private Map&lt;Long, T&gt; allRules = new ConcurrentHashMap&lt;&gt;(16); // 通过客户端服务名称映射存储发布的规则 private Map&lt;String, Map&lt;Long, T&gt;&gt; appRules = new ConcurrentHashMap&lt;&gt;(16); public T save(T entity) &#123; if (entity.getId() == null) &#123; entity.setId(nextId()); &#125; T processedEntity = preProcess(entity); if (processedEntity != null) &#123; allRules.put(processedEntity.getId(), processedEntity); machineRules.computeIfAbsent(MachineInfo.of(processedEntity.getApp(), processedEntity.getIp(), processedEntity.getPort()), e -&gt; new ConcurrentHashMap&lt;&gt;(32)).put(processedEntity.getId(), processedEntity); appRules.computeIfAbsent(processedEntity.getApp(), v -&gt; new ConcurrentHashMap&lt;&gt;(32)).put(processedEntity.getId(), processedEntity); &#125; return processedEntity; &#125; public List&lt;T&gt; findAllByMachine(MachineInfo machineInfo) &#123; Map&lt;Long, T&gt; entities = machineRules.get(machineInfo); if (entities == null) &#123; return new ArrayList&lt;&gt;(); &#125; return new ArrayList&lt;&gt;(entities.values()); &#125;&#125;public class SentinelApiClient &#123; private static final String SET_RULES_PATH = \"setRules\"; private CompletableFuture&lt;Void&gt; publishRules(String app, String ip, Integer port) &#123; List&lt;FlowRuleEntity&gt; rules = repository.findAllByMachine(MachineInfo.of(app, ip, port)); return sentinelApiClient.setFlowRuleOfMachineAsync(app, ip, port, rules); // 和sentinel客户端通信，异步设置流控规则 &#125; public CompletableFuture&lt;Void&gt; setFlowRuleOfMachineAsync(String app, String ip, int port, List&lt;FlowRuleEntity&gt; rules) &#123; return setRulesAsync(app, ip, port, FLOW_RULE_TYPE, rules); &#125; private CompletableFuture&lt;Void&gt; setRulesAsync(String app, String ip, int port, String type, List&lt;? extends RuleEntity&gt; entities) &#123; try &#123; AssertUtil.notNull(entities, \"rules cannot be null\"); AssertUtil.notEmpty(app, \"Bad app name\"); AssertUtil.notEmpty(ip, \"Bad machine IP\"); AssertUtil.isTrue(port &gt; 0, \"Bad machine port\"); String data = JSON.toJSONString(entities.stream().map(r -&gt; r.toRule()).collect(Collectors.toList())); Map&lt;String, String&gt; params = new HashMap&lt;&gt;(2); params.put(\"type\", type); params.put(\"data\", data); return executeCommand(app, ip, port, SET_RULES_PATH, params, true).thenCompose(r -&gt; &#123; if (\"success\".equalsIgnoreCase(r.trim())) &#123; return CompletableFuture.completedFuture(null); &#125; return AsyncUtils.newFailedFuture(new CommandFailedException(r)); &#125;); &#125; catch (Exception e) &#123; return AsyncUtils.newFailedFuture(e); &#125; &#125; private CompletableFuture&lt;String&gt; executeCommand(String app, String ip, int port, String api, Map&lt;String, String&gt; params, boolean useHttpPost) &#123; CompletableFuture&lt;String&gt; future = new CompletableFuture&lt;&gt;(); if (StringUtil.isBlank(ip) || StringUtil.isBlank(api)) &#123; future.completeExceptionally(new IllegalArgumentException(\"Bad URL or command name\")); return future; &#125; StringBuilder urlBuilder = new StringBuilder(); // 拼接客户端推送规则配置的URL urlBuilder.append(\"http://\"); urlBuilder.append(ip).append(':').append(port).append('/').append(api); if (params == null) &#123; params = Collections.emptyMap(); &#125; if (!useHttpPost || !isSupportPost(app, ip, port)) &#123;// Using GET in older versions, append parameters after url if (!params.isEmpty()) &#123; if (urlBuilder.indexOf(\"?\") == -1) &#123; urlBuilder.append('?'); &#125; else &#123; urlBuilder.append('&amp;'); &#125; urlBuilder.append(queryString(params)); &#125; return executeCommand(new HttpGet(urlBuilder.toString())); &#125; else &#123;// Using POST return executeCommand(postRequest(urlBuilder.toString(), params, isSupportEnhancedContentType(app, ip, port))); &#125; &#125;&#125; 客户端接收数据是Sentinel通过SPI的方式在启动时加载实现了InitFunc接口的类，从而加载SPI接口CommandCenter从而加载SimpleHttpCommandCenter来完成的。 12345678910111213141516171819202122232425262728293031323334353637383940public final class InitExecutor &#123; private static AtomicBoolean initialized = new AtomicBoolean(false); private static AtomicBoolean initialized = new AtomicBoolean(false); public static void doInit() &#123; // Sentinel扩展点，通过SPI的方式加载实现了InitFunc接口的类 if (!initialized.compareAndSet(false, true)) &#123; return; &#125; try &#123; ServiceLoader&lt;InitFunc&gt; loader = ServiceLoaderUtil.getServiceLoader(InitFunc.class); List&lt;OrderWrapper&gt; initList = new ArrayList&lt;OrderWrapper&gt;(); for (InitFunc initFunc : loader) &#123; insertSorted(initList, initFunc); &#125; for (OrderWrapper w : initList) &#123; w.func.init(); &#125; &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; catch (Error error) &#123; error.printStackTrace(); &#125; &#125; private static void insertSorted(List&lt;OrderWrapper&gt; list, InitFunc func) &#123; int order = resolveOrder(func); // 获取排序，若该类上没有@InitOrder注解则默认是最低优先级即Integer.MAX_VALUE int idx = 0; for (; idx &lt; list.size(); idx++) &#123; if (list.get(idx).getOrder() &gt; order) &#123; break; &#125; &#125; list.add(idx, new OrderWrapper(order, func)); // 将其按照order从大到小即优先级越低越排在前面的顺序放入List中 &#125; private static int resolveOrder(InitFunc func) &#123; if (!func.getClass().isAnnotationPresent(InitOrder.class)) &#123; return InitOrder.LOWEST_PRECEDENCE; &#125; else &#123; return func.getClass().getAnnotation(InitOrder.class).value(); &#125; &#125;&#125; CommandCenter接口也是通过SPI方式加载目前有两个实现SimpleHttpCommandCenter和NettyHttpCommandCenter。且默认是使用SimpleHttpCommandCenter，首先会调用其beforeStart方法加载遍历实现了SPI接口CommandHandler的所有类，并解析这些实现类上@CommandMapping注解的name属性作为路由使用。 123456789101112131415161718192021222324252627282930313233343536373839@InitOrder(-1)public class CommandCenterInitFunc implements InitFunc &#123; @Override public void init() throws Exception &#123; CommandCenter commandCenter = CommandCenterProvider.getCommandCenter(); if (commandCenter == null) &#123; return; &#125; commandCenter.beforeStart(); commandCenter.start(); &#125;&#125;public class SimpleHttpCommandCenter implements CommandCenter &#123; public void beforeStart() throws Exception &#123; // Register handlers Map&lt;String, CommandHandler&gt; handlers = CommandHandlerProvider.getInstance().namedHandlers(); registerCommands(handlers); // 注册所有实现了CommandHandler的SPI接口 &#125;&#125;public class CommandHandlerProvider implements Iterable&lt;CommandHandler&gt; &#123; private final ServiceLoader&lt;CommandHandler&gt; serviceLoader = ServiceLoaderUtil.getServiceLoader(CommandHandler.class); public Map&lt;String, CommandHandler&gt; namedHandlers() &#123; Map&lt;String, CommandHandler&gt; map = new HashMap&lt;String, CommandHandler&gt;(); for (CommandHandler handler : serviceLoader) &#123; String name = parseCommandName(handler); // 解析@CommandMapping注解中配置的接口名称 if (!StringUtil.isEmpty(name)) &#123; map.put(name, handler); &#125; &#125; return map; &#125; private String parseCommandName(CommandHandler handler) &#123; CommandMapping commandMapping = handler.getClass().getAnnotation(CommandMapping.class); if (commandMapping != null) &#123; return commandMapping.name(); &#125; else &#123; return null; &#125; &#125;&#125; 然后调用SimpleHttpCommandCenter的start方法中异步启动ServerThread线程开启Socket服务端监听，当监听接收到数据后通过HttpEventTask异步任务解析请求。且监听端口是从8719开始，若被占用则依次向上加一。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class SimpleHttpCommandCenter implements CommandCenter &#123; private static final int PORT_UNINITIALIZED = -1; private static final int DEFAULT_SERVER_SO_TIMEOUT = 3000; private static final int DEFAULT_PORT = 8719; private ExecutorService executor = Executors.newSingleThreadExecutor(new NamedThreadFactory(\"sentinel-command-center-executor\")); private ExecutorService bizExecutor; private ServerSocket socketReference; public void beforeStart() throws Exception &#123; // Register handlers Map&lt;String, CommandHandler&gt; handlers = CommandHandlerProvider.getInstance().namedHandlers(); registerCommands(handlers); // 注册所有实现了CommandHandler的SPI接口 &#125; public void start() throws Exception &#123; int nThreads = Runtime.getRuntime().availableProcessors(); this.bizExecutor = new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10), new NamedThreadFactory(\"sentinel-command-center-service-executor\"), new RejectedExecutionHandler() &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; CommandCenterLog.info(\"EventTask rejected\"); throw new RejectedExecutionException(); &#125; &#125;); Runnable serverInitTask = new Runnable() &#123; int port; &#123; try &#123; port = Integer.parseInt(TransportConfig.getPort()); &#125; catch (Exception e) &#123; port = DEFAULT_PORT; &#125; &#125; @Override public void run() &#123; boolean success = false; ServerSocket serverSocket = getServerSocketFromBasePort(port); if (serverSocket != null) &#123; socketReference = serverSocket; executor.submit(new ServerThread(serverSocket)); success = true; port = serverSocket.getLocalPort(); &#125; if (!success) &#123; port = PORT_UNINITIALIZED; &#125; TransportConfig.setRuntimePort(port); executor.shutdown(); &#125; &#125;; new Thread(serverInitTask).start(); &#125;&#125;class ServerThread extends Thread &#123; private ServerSocket serverSocket; ServerThread(ServerSocket s) &#123; this.serverSocket = s; setName(\"sentinel-courier-server-accept-thread\"); &#125; @Override public void run() &#123; while (true) &#123; Socket socket = null; try &#123; socket = this.serverSocket.accept(); setSocketSoTimeout(socket); HttpEventTask eventTask = new HttpEventTask(socket); bizExecutor.submit(eventTask); &#125; catch (Exception e) &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (Exception e1) &#123; &#125; &#125; try &#123;// In case of infinite log. Thread.sleep(10); &#125; catch (InterruptedException e1) &#123;// Indicates the task should stop. break; &#125; &#125; &#125; &#125;&#125; HttpEventTask中首先解析参数，然后通过从在SimpleHttpCommandCenter的beforeStart方法中解析的路由中匹配到具体的CommandHandler接口实现类，并调用其handle方法完成客户端规则推送。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class HttpEventTask implements Runnable &#123; public void run() &#123; if (socket == null) &#123; return; &#125; PrintWriter printWriter = null; InputStream inputStream = null; try &#123; long start = System.currentTimeMillis(); inputStream = new BufferedInputStream(socket.getInputStream()); OutputStream outputStream = socket.getOutputStream(); printWriter = new PrintWriter(new OutputStreamWriter(outputStream, Charset.forName(SentinelConfig.charset()))); String firstLine = readLine(inputStream); CommandRequest request = processQueryString(firstLine); // 参数解析 if (firstLine.length() &gt; 4 &amp;&amp; StringUtil.equalsIgnoreCase(\"POST\", firstLine.substring(0, 4))) &#123;// Deal with post method processPostRequest(inputStream, request); // POST请求参数解析 &#125; // Validate the target command. String commandName = HttpCommandUtils.getTarget(request); if (StringUtil.isBlank(commandName)) &#123; writeResponse(printWriter, StatusCode.BAD_REQUEST, INVALID_COMMAND_MESSAGE); return; &#125; // Find the matching command handler. CommandHandler&lt;?&gt; commandHandler = SimpleHttpCommandCenter.getHandler(commandName); if (commandHandler != null) &#123; CommandResponse&lt;?&gt; response = commandHandler.handle(request); handleResponse(response, printWriter); &#125; else &#123; // No matching command handler. writeResponse(printWriter, StatusCode.BAD_REQUEST, \"Unknown command `\" + commandName + '`'); &#125; long cost = System.currentTimeMillis() - start; &#125; catch (RequestException e) &#123; writeResponse(printWriter, e.getStatusCode(), e.getMessage()); &#125; catch (Throwable e) &#123; try &#123; if (printWriter != null) &#123; String errorMessage = SERVER_ERROR_MESSAGE; e.printStackTrace(); if (!writtenHead) &#123; writeResponse(printWriter, StatusCode.INTERNAL_SERVER_ERROR, errorMessage); &#125; else &#123; printWriter.println(errorMessage); &#125; printWriter.flush(); &#125; &#125; catch (Exception e1) &#123; &#125; &#125; finally &#123; closeResource(inputStream); closeResource(printWriter); closeResource(socket); &#125; &#125;&#125; 对于规则的设置是通过ModifyRulesCommandHandler来完成的，不同的规则设置根据规则类型走不同的逻辑，都是通过对应规则Manager类的loadRules方法将规则加载到内存中，然后通过writeToDataSource方法来实现持久化。也可以通过该处对持久化功能进行扩展。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@CommandMapping(name = \"setRules\", desc = \"modify the rules, accept param: type=&#123;ruleType&#125;&amp;data=&#123;ruleJson&#125;\")public class ModifyRulesCommandHandler implements CommandHandler&lt;String&gt; &#123; private static final int FASTJSON_MINIMAL_VER = 0x01020C00; @Override public CommandResponse&lt;String&gt; handle(CommandRequest request) &#123; if (VersionUtil.fromVersionString(JSON.VERSION) &lt; FASTJSON_MINIMAL_VER) &#123;// fastjson too old return CommandResponse.ofFailure(new RuntimeException(\"The \\\"fastjson-\" + JSON.VERSION + \"\\\" introduced in application is too old, you need fastjson-1.2.12 at least.\")); &#125; String type = request.getParam(\"type\"); String data = request.getParam(\"data\"); // rule data in get parameter if (StringUtil.isNotEmpty(data)) &#123; try &#123; data = URLDecoder.decode(data, \"utf-8\"); &#125; catch (Exception e) &#123; return CommandResponse.ofFailure(e, \"decode rule data error\"); &#125; &#125; String result = \"success\"; if (FLOW_RULE_TYPE.equalsIgnoreCase(type)) &#123; List&lt;FlowRule&gt; flowRules = JSONArray.parseArray(data, FlowRule.class); FlowRuleManager.loadRules(flowRules); if (!writeToDataSource(getFlowDataSource(), flowRules)) &#123; // 获取写数据源，做持久化 result = WRITE_DS_FAILURE_MSG; &#125; return CommandResponse.ofSuccess(result); &#125; else if (AUTHORITY_RULE_TYPE.equalsIgnoreCase(type)) &#123; List&lt;AuthorityRule&gt; rules = JSONArray.parseArray(data, AuthorityRule.class); AuthorityRuleManager.loadRules(rules); if (!writeToDataSource(getAuthorityDataSource(), rules)) &#123; result = WRITE_DS_FAILURE_MSG; &#125; return CommandResponse.ofSuccess(result); &#125; else if (DEGRADE_RULE_TYPE.equalsIgnoreCase(type)) &#123; List&lt;DegradeRule&gt; rules = JSONArray.parseArray(data, DegradeRule.class); DegradeRuleManager.loadRules(rules); if (!writeToDataSource(getDegradeDataSource(), rules)) &#123; result = WRITE_DS_FAILURE_MSG; &#125; return CommandResponse.ofSuccess(result); &#125; else if (SYSTEM_RULE_TYPE.equalsIgnoreCase(type)) &#123; List&lt;SystemRule&gt; rules = JSONArray.parseArray(data, SystemRule.class); SystemRuleManager.loadRules(rules); if (!writeToDataSource(getSystemSource(), rules)) &#123; result = WRITE_DS_FAILURE_MSG; &#125; return CommandResponse.ofSuccess(result); &#125; return CommandResponse.ofFailure(new IllegalArgumentException(\"invalid type\")); &#125; private &lt;T&gt; boolean writeToDataSource(WritableDataSource&lt;T&gt; dataSource, T value) &#123; if (dataSource != null) &#123; try &#123; dataSource.write(value); &#125; catch (Exception e) &#123; return false; &#125; &#125; return true; &#125;&#125; 使用Sentinel时一定要配置暴露actuator端点，否则可能在dashboard上找不到对应的服务 123456# 暴露actuator端点management: endpoints: web: exposure: include: '*'","tags":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://yaoyinglong.github.io/tags/Sentinel/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Sentinel","slug":"Cloud/Sentinel","permalink":"https://yaoyinglong.github.io/categories/Cloud/Sentinel/"}]},{"title":"Ribbon集成原理","date":"2021-11-01T16:00:00.000Z","path":"Blog/Cloud/Ribbon集成原理/","text":"主流的负载方案分为集中式负载均衡，在消费者和服务提供方中间使用独立的代理方式进行负载，如硬件的F5，软件的Nginx；客户端负载均衡，客户端会有一个服务器地址列表，在发送请求前通过负载均衡算法选择一个服务器，然后进行访问。 Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡工具，Ribbon客户端组件提供一系列的完善的配置如超时，重试等。通过Load Balancer获取到服务提供的所有机器实例，Ribbon会自动基于某种负载策略去调用这些服务，Ribbon也可以实现自己的负载均衡算法。 对于RestTemplate通过Ribbon实现负载均衡调用，需要在声明RestTemplate Bean时加上@LoadBalanced注解。调用时直接通过服务名称即可。@LoadBalanced利用@Qualifier作为restTemplates注入的筛选条件，筛选出具有负载均衡标识的RestTemplate，被@LoadBalanced注解的restTemplate会被定制，添加LoadBalancerInterceptor拦截器。 123456789@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125;@Autowiredprivate RestTemplate restTemplate;String url = \"http://mall-order/order/findOrderByUserId/\" + userId;Object result = restTemplate.getForObject(url, Object.class); Ribbon集成到RestTemplate中是通过RibbonAutoConfiguration配置类中导入LoadBalancerClient，然后通过LoadBalancerAutoConfiguration配置类将LoadBalancerClient封装到LoadBalancerInterceptor拦截器中，再通过RestTemplateCustomizer和SmartInitializingSingleton在Bean初始化完成后将该拦截器封装到RestTemplate拦截器集合中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Configuration@Conditional(RibbonAutoConfiguration.RibbonClassesConditions.class)@RibbonClients@AutoConfigureAfter(name = \"org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration\")@AutoConfigureBefore(&#123; LoadBalancerAutoConfiguration.class, AsyncLoadBalancerAutoConfiguration.class &#125;)@EnableConfigurationProperties(&#123; RibbonEagerLoadProperties.class, ServerIntrospectorProperties.class &#125;)public class RibbonAutoConfiguration &#123; @Autowired(required = false) private List&lt;RibbonClientSpecification&gt; configurations = new ArrayList&lt;&gt;(); @Bean @ConditionalOnMissingBean public SpringClientFactory springClientFactory() &#123; SpringClientFactory factory = new SpringClientFactory(); factory.setConfigurations(this.configurations); return factory; &#125; @Bean @ConditionalOnMissingBean(LoadBalancerClient.class) public LoadBalancerClient loadBalancerClient() &#123; return new RibbonLoadBalancerClient(springClientFactory()); &#125;&#125;@Configuration(proxyBeanMethods = false)@ConditionalOnClass(RestTemplate.class)@ConditionalOnBean(LoadBalancerClient.class)@EnableConfigurationProperties(LoadBalancerRetryProperties.class)public class LoadBalancerAutoConfiguration &#123; @LoadBalanced // 该注解被@Qualifier注解修饰，这里会导入所有被@LoadBalanced注解标记的RestTemplate @Autowired(required = false) private List&lt;RestTemplate&gt; restTemplates = Collections.emptyList(); @Autowired(required = false) private List&lt;LoadBalancerRequestTransformer&gt; transformers = Collections.emptyList(); @Bean @ConditionalOnMissingBean public LoadBalancerRequestFactory loadBalancerRequestFactory(LoadBalancerClient loadBalancerClient) &#123; return new LoadBalancerRequestFactory(loadBalancerClient, this.transformers); &#125; @Configuration(proxyBeanMethods = false) @ConditionalOnMissingClass(\"org.springframework.retry.support.RetryTemplate\") static class LoadBalancerInterceptorConfig &#123; @Bean // 将LoadBalancerClient封装到LoadBalancerInterceptor拦截器中 public LoadBalancerInterceptor ribbonInterceptor(LoadBalancerClient loadBalancerClient, LoadBalancerRequestFactory requestFactory) &#123; return new LoadBalancerInterceptor(loadBalancerClient, requestFactory); &#125; @Bean @ConditionalOnMissingBean public RestTemplateCustomizer restTemplateCustomizer(final LoadBalancerInterceptor loadBalancerInterceptor) &#123; return restTemplate -&gt; &#123; // 将拦截器添加到RestTemplate的拦截器链中 List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList&lt;&gt;(restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); &#125;; &#125; &#125; @Bean public SmartInitializingSingleton loadBalancedRestTemplateInitializerDeprecated(final ObjectProvider&lt;List&lt;RestTemplateCustomizer&gt;&gt; restTemplateCustomizers) &#123; return () -&gt; restTemplateCustomizers.ifAvailable(customizers -&gt; &#123; for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) &#123; for (RestTemplateCustomizer customizer : customizers) &#123; customizer.customize(restTemplate); // 在所有Bean初始化完成后被调用 &#125; &#125; &#125;); &#125;&#125; 在调用RestTemplate的方法请求时，会被LoadBalancerInterceptor拦截器拦截从而调用RibbonLoadBalancerClient的execute方法，通过getLoadBalancer获取负载均衡器，通过获取到的负载均衡器根据负载均衡算法挑选一个Server。 1234567891011121314151617181920212223242526272829303132public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor &#123; private LoadBalancerClient loadBalancer; private LoadBalancerRequestFactory requestFactory; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer, LoadBalancerRequestFactory requestFactory) &#123; this.loadBalancer = loadBalancer; this.requestFactory = requestFactory; &#125; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer) &#123; this(loadBalancer, new LoadBalancerRequestFactory(loadBalancer)); &#125; @Override public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException &#123; final URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, \"Request URI does not contain a valid hostname: \" + originalUri); return this.loadBalancer.execute(serviceName, this.requestFactory.createRequest(request, body, execution)); &#125;&#125;public class RibbonLoadBalancerClient implements LoadBalancerClient &#123; public &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException &#123; return execute(serviceId, request, null); &#125; public &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request, Object hint) throws IOException &#123; ILoadBalancer loadBalancer = getLoadBalancer(serviceId); // 获取负载均衡器 Server server = getServer(loadBalancer, hint); // 负载均衡器LoadBalancer根据负载均衡算法挑选一个Server if (server == null) &#123; throw new IllegalStateException(\"No instances available for \" + serviceId); &#125; RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); return execute(serviceId, ribbonServer, request); &#125;&#125; 获取负载均衡器ILoadBalancer负载均衡器是通过RibbonClientConfiguration配置类导入的。 12345678910111213141516171819202122232425262728293031323334353637383940@Configuration(proxyBeanMethods = false)@EnableConfigurationProperties@Import(&#123; HttpClientConfiguration.class, OkHttpRibbonConfiguration.class, RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class &#125;)public class RibbonClientConfiguration &#123; @Bean @ConditionalOnMissingBean public ILoadBalancer ribbonLoadBalancer(IClientConfig config, ServerList&lt;Server&gt; serverList, ServerListFilter&lt;Server&gt; serverListFilter, IRule rule, IPing ping, ServerListUpdater serverListUpdater) &#123; if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) &#123; return this.propertiesFactory.get(ILoadBalancer.class, config, name); &#125; return new ZoneAwareLoadBalancer&lt;&gt;(config, rule, ping, serverList, serverListFilter, serverListUpdater); &#125;&#125;public class ZoneAwareLoadBalancer&lt;T extends Server&gt; extends DynamicServerListLoadBalancer&lt;T&gt; &#123; public ZoneAwareLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter, ServerListUpdater serverListUpdater) &#123; super(clientConfig, rule, ping, serverList, filter, serverListUpdater); &#125;&#125;public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123; public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter, ServerListUpdater serverListUpdater) &#123; super(clientConfig, rule, ping); this.serverListImpl = serverList; this.filter = filter; this.serverListUpdater = serverListUpdater; if (filter instanceof AbstractServerListFilter) &#123; ((AbstractServerListFilter) filter).setLoadBalancerStats(getLoadBalancerStats()); &#125; restOfInit(clientConfig); &#125; void restOfInit(IClientConfig clientConfig) &#123; boolean primeConnection = this.isEnablePrimingConnections(); this.setEnablePrimingConnections(false); enableAndInitLearnNewServersFeature(); // Ribbon定时更新Nacos实例列表 updateListOfServers(); // 获取所有Nacos实例列表 if (primeConnection &amp;&amp; this.getPrimeConnections() != null) &#123; this.getPrimeConnections().primeConnections(getReachableServers()); &#125; this.setEnablePrimingConnections(primeConnection); &#125;&#125; 定时更新Nacos实例列表最终调用PollingServerListUpdater的start方法，将更新任务添加到周期延时线程池中，且每30s执行一次该任务。该任务最终调用DynamicServerListLoadBalancer的updateListOfServers方法完成实例列表的更新，最终通过updateAllServerList方法将服务实例列表设置到父类BaseLoadBalancer的allServerList中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123; protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123; @Override public void doUpdate() &#123; updateListOfServers(); // 真正去做定时更新的方法 &#125; &#125;; public void enableAndInitLearnNewServersFeature() &#123; serverListUpdater.start(updateAction); &#125; public void updateListOfServers() &#123; List&lt;T&gt; servers = new ArrayList&lt;T&gt;(); if (serverListImpl != null) &#123; servers = serverListImpl.getUpdatedListOfServers(); if (filter != null) &#123; servers = filter.getFilteredListOfServers(servers); &#125; &#125; updateAllServerList(servers); // 将服务实例俩表设置到父类BaseLoadBalancer的allServerList中 &#125; protected void updateAllServerList(List&lt;T&gt; ls) &#123; if (serverListUpdateInProgress.compareAndSet(false, true)) &#123; try &#123; for (T s : ls) &#123; s.setAlive(true); // set so that clients can start using these &#125; setServersList(ls); super.forceQuickPing(); &#125; finally &#123; serverListUpdateInProgress.set(false); &#125; &#125; &#125; public void setServersList(List lsrv) &#123; super.setServersList(lsrv); List&lt;T&gt; serverList = (List&lt;T&gt;) lsrv; Map&lt;String, List&lt;Server&gt;&gt; serversInZones = new HashMap&lt;String, List&lt;Server&gt;&gt;(); for (Server server : serverList) &#123; getLoadBalancerStats().getSingleServerStat(server); String zone = server.getZone(); if (zone != null) &#123; zone = zone.toLowerCase(); List&lt;Server&gt; servers = serversInZones.get(zone); if (servers == null) &#123; servers = new ArrayList&lt;Server&gt;(); serversInZones.put(zone, servers); &#125; servers.add(server); &#125; &#125; setServerListForZones(serversInZones); &#125;&#125;public class PollingServerListUpdater implements ServerListUpdater &#123; public synchronized void start(final UpdateAction updateAction) &#123; if (isActive.compareAndSet(false, true)) &#123; final Runnable wrapperRunnable = new Runnable() &#123; @Override public void run() &#123; if (!isActive.get()) &#123; // 不是存活状态 if (scheduledFuture != null) &#123; scheduledFuture.cancel(true); &#125; return; &#125; try &#123; updateAction.doUpdate(); // 调用定义时创建的匿名方法从而调用updateListOfServers lastUpdated = System.currentTimeMillis(); &#125; catch (Exception e) &#123; &#125; &#125; &#125;; // 第一次1s后开始执行，后续每30s执行一次 scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(wrapperRunnable, initialDelayMs, refreshIntervalMs, TimeUnit.MILLISECONDS); &#125; &#125;&#125; 若集成了Nacos最终会调用NacosServerList的getServers方法，从Nacos服务获取最新的实例列表。 1234567891011121314151617181920212223242526272829public class NacosServerList extends AbstractServerList&lt;NacosServer&gt; &#123; public List&lt;NacosServer&gt; getUpdatedListOfServers() &#123; return getServers(); &#125; private List&lt;NacosServer&gt; getServers() &#123; try &#123; String group = discoveryProperties.getGroup(); // 调用Nacos的方法获取最新的实例列表 List&lt;Instance&gt; instances = discoveryProperties.namingServiceInstance().selectInstances(serviceId, group, true); return instancesToServerList(instances); &#125; catch (Exception e) &#123; throw new IllegalStateException(\"Can not get service instances from nacos, serviceId=\" + serviceId, e); &#125; &#125;&#125;public class NacosNamingService implements NamingService &#123; public List&lt;Instance&gt; selectInstances(String serviceName, String groupName, boolean healthy) throws NacosException &#123; return selectInstances(serviceName, groupName, healthy, true); &#125; public List&lt;Instance&gt; selectInstances(String serviceName, String groupName, List&lt;String&gt; clusters, boolean healthy, boolean subscribe) throws NacosException &#123; ServiceInfo serviceInfo; if (subscribe) &#123; serviceInfo = hostReactor.getServiceInfo(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; else &#123; serviceInfo = hostReactor .getServiceInfoDirectlyFromServer(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; return selectInstances(serviceInfo, healthy); &#125;&#125; 负载均衡算法选择负载均衡策略IRule，默认采用ZoneAvoidanceRule实现，在多区域环境下选出最佳区域的实例进行访问。实例检查策略IPing，默认采用DummyPing实现，是一个特殊的实现始终返回true，并不会检查实例是否可用。服务实例清单的维护机制ServerList，默认采用ConfigurationBasedServerList实现。服务实例清单过滤机制ServerListFilter，默认采ZonePreferenceServerListFilter，该策略能够优先过滤出与请求方处于同区域的服务实例。负载均衡器ILoadBalancer，默认采用ZoneAwareLoadBalancer实现，它具备了区域感知的能力。 RandomRule： 随机选择一个Server。 RetryRule： 对选定的负载均衡策略机上重试机制，在一个配置时间段内当选择Server不成功，则一直尝试使用subRule的方式选择一个可用的server。 RoundRobinRule： 轮询选择， 轮询index，选择index对应位置的Server。 AvailabilityFilteringRule： 过滤一直连接失败被标记为Circuit Tripped的后端Server，并过滤高并发的后端Server或使用一个AvailabilityPredicate来包含过滤Server的逻辑，其实就是检查status里记录的各个Server的运行状态。 BestAvailableRule： 选择一个最小的并发请求的Server，逐个考察Server若Server被tripped了则跳过。 WeightedResponseTimeRule： 根据响应时间加权，响应时间越长，权重越小，被选中的可能性越低。 ZoneAvoidanceRule： 默认的负载均衡策略，复合判断Server所在区域的性能和Server的可用性选择Server，在没有区域的环境下，类似于RandomRule轮询 NacosRule: 同集群优先调用 可通过主动注入IRule Bean的方式修改全局的负载均衡策略 1234@Beanpublic IRule ribbonRule() &#123; return new NacosRule();&#125; 同在在配置文件中指定调用指定微服务提供的服务时，使用对应的负载均衡算法 123mall-order: # 被调用的微服务名 ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class RibbonLoadBalancerClient implements LoadBalancerClient &#123; protected Server getServer(ILoadBalancer loadBalancer, Object hint) &#123; if (loadBalancer == null) &#123; return null; &#125; return loadBalancer.chooseServer(hint != null ? hint : \"default\"); &#125;&#125;public class BaseLoadBalancer extends AbstractLoadBalancer implements PrimeConnections.PrimeConnectionListener, IClientConfigAware &#123; public Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); // 调用具体规则的choose方法 &#125; catch (Exception e) &#123; return null; &#125; &#125; &#125;&#125;public class NacosRule extends AbstractLoadBalancerRule &#123; public Server choose(Object key) &#123; try &#123; String clusterName = this.nacosDiscoveryProperties.getClusterName(); String group = this.nacosDiscoveryProperties.getGroup(); DynamicServerListLoadBalancer loadBalancer = (DynamicServerListLoadBalancer) getLoadBalancer(); String name = loadBalancer.getName(); NamingService namingService = nacosServiceManager.getNamingService(nacosDiscoveryProperties.getNacosProperties()); List&lt;Instance&gt; instances = namingService.selectInstances(name, group, true); if (CollectionUtils.isEmpty(instances)) &#123; return null; &#125; List&lt;Instance&gt; instancesToChoose = instances; if (StringUtils.isNotBlank(clusterName)) &#123; List&lt;Instance&gt; sameClusterInstances = instances.stream().filter(instance -&gt; Objects.equals(clusterName, instance.getClusterName())).collect(Collectors.toList()); if (!CollectionUtils.isEmpty(sameClusterInstances)) &#123; instancesToChoose = sameClusterInstances; &#125; &#125; Instance instance = ExtendBalancer.getHostByRandomWeight2(instancesToChoose); return new NacosServer(instance); &#125; catch (Exception e) &#123; return null; &#125; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Ribbon","slug":"Ribbon","permalink":"https://yaoyinglong.github.io/tags/Ribbon/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"}]},{"title":"Nacos配置中心Server原理","date":"2021-10-30T16:00:00.000Z","path":"Blog/Cloud/Nacos/Nacos配置中心Server原理/","text":"服务端配置加载Nacos启动时通过DumpService的子类ExternalDumpService在初始化时调用dumpOperate来完成配置从数据库加载到缓存和写入磁盘中缓存文件中。先会通过dumpConfigInfo方法执行DumpAllProcessor的process方法将数据库中的数据刷到内存中，且将变化的数据通知客户端。且会每10分钟执行一次数据库逾期数据清理，默认逾期时间30天。且每6小时会将数据库中数据再刷一遍到内存中以及磁盘缓存文件中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class ExternalDumpService extends DumpService &#123; @PostConstruct protected void init() throws Throwable &#123; dumpOperate(processor, dumpAllProcessor, dumpAllBetaProcessor, dumpAllTagProcessor); &#125;&#125;public abstract class DumpService &#123; protected DumpProcessor processor; protected DumpAllProcessor dumpAllProcessor; protected DumpAllBetaProcessor dumpAllBetaProcessor; protected DumpAllTagProcessor dumpAllTagProcessor; protected final PersistService persistService; protected final ServerMemberManager memberManager; public DumpService(PersistService persistService, ServerMemberManager memberManager) &#123; this.persistService = persistService; this.memberManager = memberManager; this.processor = new DumpProcessor(this); this.dumpAllProcessor = new DumpAllProcessor(this); // 全量Dump配置信息的Processor this.dumpAllBetaProcessor = new DumpAllBetaProcessor(this); this.dumpAllTagProcessor = new DumpAllTagProcessor(this); this.dumpTaskMgr = new TaskManager(\"com.alibaba.nacos.server.DumpTaskManager\"); this.dumpTaskMgr.setDefaultTaskProcessor(processor); this.dumpAllTaskMgr = new TaskManager(\"com.alibaba.nacos.server.DumpAllTaskManager\"); this.dumpAllTaskMgr.setDefaultTaskProcessor(dumpAllProcessor); this.dumpAllTaskMgr.addProcessor(DumpAllTask.TASK_ID, dumpAllProcessor); this.dumpAllTaskMgr.addProcessor(DumpAllBetaTask.TASK_ID, dumpAllBetaProcessor); this.dumpAllTaskMgr.addProcessor(DumpAllTagTask.TASK_ID, dumpAllTagProcessor); DynamicDataSource.getInstance().getDataSource(); &#125; protected void dumpOperate(DumpProcessor processor, DumpAllProcessor dumpAllProcessor, DumpAllBetaProcessor dumpAllBetaProcessor, DumpAllTagProcessor dumpAllTagProcessor) throws NacosException &#123; try &#123; Runnable dumpAll = () -&gt; dumpAllTaskMgr.addTask(DumpAllTask.TASK_ID, new DumpAllTask()); Runnable dumpAllBeta = () -&gt; dumpAllTaskMgr.addTask(DumpAllBetaTask.TASK_ID, new DumpAllBetaTask()); Runnable dumpAllTag = () -&gt; dumpAllTaskMgr.addTask(DumpAllTagTask.TASK_ID, new DumpAllTagTask()); Runnable clearConfigHistory = () -&gt; &#123; // 清理数据库过期的数据 if (canExecute()) &#123; // 若服务端成员列表中第一个成员是本机 try &#123; // 默认过期时间为30天 Timestamp startTime = getBeforeStamp(TimeUtils.getCurrentTime(), 24 * getRetentionDays()); int totalCount = persistService.findConfigHistoryCountByTime(startTime); // 查询数据库逾期数据条数(超过30天) if (totalCount &gt; 0) &#123; // 若逾期数据条数大于0 int pageSize = 1000; int removeTime = (totalCount + pageSize - 1) / pageSize; while (removeTime &gt; 0) &#123; // 分页处理 persistService.removeConfigHistory(startTime, pageSize); // 将数据从数据库批量删除 removeTime--; &#125; &#125; &#125; catch (Throwable e) &#123; &#125; &#125; &#125;; try &#123; dumpConfigInfo(dumpAllProcessor); // 全量Dump配置信息 DiskUtil.clearAllBeta(); // update Beta cache if (persistService.isExistTable(BETA_TABLE_NAME)) &#123; dumpAllBetaProcessor.process(new DumpAllBetaTask()); &#125; DiskUtil.clearAllTag(); // update Tag cache if (persistService.isExistTable(TAG_TABLE_NAME)) &#123; dumpAllTagProcessor.process(new DumpAllTagTask()); &#125; List&lt;ConfigInfoChanged&gt; configList = persistService.findAllAggrGroup(); // add to dump aggr if (configList != null &amp;&amp; !configList.isEmpty()) &#123; total = configList.size(); List&lt;List&lt;ConfigInfoChanged&gt;&gt; splitList = splitList(configList, INIT_THREAD_COUNT); for (List&lt;ConfigInfoChanged&gt; list : splitList) &#123; MergeAllDataWorker work = new MergeAllDataWorker(list); work.start(); &#125; &#125; &#125; catch (Exception e) &#123; throw new NacosException(NacosException.SERVER_ERROR, \"Nacos Server did not start because dumpservice bean construction failure :\\n\" + e.getMessage(), e); &#125; if (!EnvUtil.getStandaloneMode()) &#123; Runnable heartbeat = () -&gt; &#123; // 更新心跳检测文件中的时间 String heartBeatTime = TimeUtils.getCurrentTime().toString(); // 或去当前心跳的时间 try &#123; // write disk DiskUtil.saveHeartBeatToDisk(heartBeatTime); &#125; catch (IOException e) &#123; &#125; &#125;; ConfigExecutor.scheduleConfigTask(heartbeat, 0, 10, TimeUnit.SECONDS); // 10s执行一次心跳 long initialDelay = new Random().nextInt(INITIAL_DELAY_IN_MINUTE) + 10; // 第一次随机时间执行 ConfigExecutor.scheduleConfigTask(dumpAll, initialDelay, DUMP_ALL_INTERVAL_IN_MINUTE, TimeUnit.MINUTES); // 每6小时执行一次，将dumpAll添加到任务队列中 ConfigExecutor.scheduleConfigTask(dumpAllBeta, initialDelay, DUMP_ALL_INTERVAL_IN_MINUTE, TimeUnit.MINUTES); ConfigExecutor.scheduleConfigTask(dumpAllTag, initialDelay, DUMP_ALL_INTERVAL_IN_MINUTE, TimeUnit.MINUTES); &#125; ConfigExecutor.scheduleConfigTask(clearConfigHistory, 10, 10, TimeUnit.MINUTES); // 每10分钟执行一次清理数据库过期的数据 &#125; finally &#123; TimerContext.end(dumpFileContext, LogUtil.DUMP_LOG); &#125; &#125;&#125; 若不是通过isQuickStart方式启动的，或通过isQuickStart方式启动但最后心跳时间大于6小时，则先清理磁盘中的缓存文件，再通过DumpAllProcessor将数据从数据库加载到磁盘和和缓存中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public abstract class DumpService &#123; private void dumpConfigInfo(DumpAllProcessor dumpAllProcessor) throws IOException &#123; int timeStep = 6; Boolean isAllDump = true; // initial dump all FileInputStream fis = null; Timestamp heartheatLastStamp = null; try &#123; if (isQuickStart()) &#123; // 默认为false File heartbeatFile = DiskUtil.heartBeatFile(); // 心跳文件 if (heartbeatFile.exists()) &#123; fis = new FileInputStream(heartbeatFile); String heartheatTempLast = IoUtils.toString(fis, Constants.ENCODE); heartheatLastStamp = Timestamp.valueOf(heartheatTempLast); if (TimeUtils.getCurrentTime().getTime() - heartheatLastStamp.getTime() &lt; timeStep * 60 * 60 * 1000) &#123; isAllDump = false; // 若当前时间减最近心跳时间小于6小时则不全量更新 &#125; &#125; &#125; if (isAllDump) &#123; // 若当前时间减最近心跳时间大于6小时则全量更新 DiskUtil.clearAll(); // 清理磁盘缓存的配置信息文件 dumpAllProcessor.process(new DumpAllTask()); &#125; else &#123; // 若当前时间减最近心跳时间小于6小时则不全量更新 Timestamp beforeTimeStamp = getBeforeStamp(heartheatLastStamp, timeStep); // 6小时前 DumpChangeProcessor dumpChangeProcessor = new DumpChangeProcessor(this, beforeTimeStamp, TimeUtils.getCurrentTime()); dumpChangeProcessor.process(new DumpChangeTask()); // 处理6小时前到现在有变更的配置 Runnable checkMd5Task = () -&gt; &#123; List&lt;String&gt; diffList = ConfigCacheService.checkMd5(); for (String groupKey : diffList) &#123; // 查询数据库中配置与缓存中配置对比，若发生变更，则写入磁盘缓存以及更新缓存通知客户端 String[] dg = GroupKey.parseKey(groupKey); String dataId = dg[0]; String group = dg[1]; String tenant = dg[2]; ConfigInfoWrapper configInfo = persistService.queryConfigInfo(dataId, group, tenant); ConfigCacheService.dumpChange(dataId, group, tenant, configInfo.getContent(), configInfo.getLastModified()); &#125; &#125;; ConfigExecutor.scheduleConfigTask(checkMd5Task, 0, 12, TimeUnit.HOURS); // 每12小时执行一次checkMd5Task &#125; &#125; catch (IOException e) &#123; throw e; &#125; &#125;&#125; 会通过分页查询数据库将数据批量加载到磁盘和内存中，通过ConfigCacheService的dump方法将数据写入磁盘，且缓存配置信息的md5到内存中，并发布LocalDataChangeEvent。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class DumpAllProcessor implements NacosTaskProcessor &#123; public boolean process(NacosTask task) &#123; long currentMaxId = persistService.findConfigMaxId(); // 查询MySQL获取最大的主键值，用于分页查询 long lastMaxId = 0; while (lastMaxId &lt; currentMaxId) &#123; // 从MySQL分页查询所有配置 Page&lt;ConfigInfoWrapper&gt; page = persistService.findAllConfigInfoFragment(lastMaxId, PAGE_SIZE); // 每页大小默认为1000条配置 if (page != null &amp;&amp; page.getPageItems() != null &amp;&amp; !page.getPageItems().isEmpty()) &#123; for (ConfigInfoWrapper cf : page.getPageItems()) &#123; long id = cf.getId(); lastMaxId = id &gt; lastMaxId ? id : lastMaxId; if (cf.getDataId().equals(AggrWhitelist.AGGRIDS_METADATA)) &#123; // dataId == com.alibaba.nacos.metadata.aggrIDs AggrWhitelist.load(cf.getContent()); &#125; if (cf.getDataId().equals(ClientIpWhiteList.CLIENT_IP_WHITELIST_METADATA)) &#123; // com.alibaba.nacos.metadata.clientIpWhitelist ClientIpWhiteList.load(cf.getContent()); &#125; if (cf.getDataId().equals(SwitchService.SWITCH_META_DATAID)) &#123; SwitchService.load(cf.getContent()); &#125; // 将数据写入磁盘，缓存配置信息的md5到内存中，并发布LocalDataChangeEvent boolean result = ConfigCacheService.dump(cf.getDataId(), cf.getGroup(), cf.getTenant(), cf.getContent(), cf.getLastModified(), cf.getType()); final String content = cf.getContent(); final String md5 = MD5Utils.md5Hex(content, Constants.ENCODE); &#125; &#125; else &#123; lastMaxId += PAGE_SIZE; &#125; &#125; return true; &#125;&#125;public class ConfigCacheService &#123; public static boolean dump(String dataId, String group, String tenant, String content, long lastModifiedTs, String type) &#123; String groupKey = GroupKey2.getKey(dataId, group, tenant); CacheItem ci = makeSure(groupKey); ci.setType(type); final int lockResult = tryWriteLock(groupKey); // 获取写锁 assert (lockResult != 0); if (lockResult &lt; 0) &#123; return false; &#125; try &#123; final String md5 = MD5Utils.md5Hex(content, Constants.ENCODE); if (md5.equals(ConfigCacheService.getContentMd5(groupKey))) &#123; &#125; else if (!PropertyUtil.isDirectRead()) &#123; // 非Standalone模式启动且非内嵌数据库 DiskUtil.saveToDisk(dataId, group, tenant, content); // 将配置保存到磁盘文件中 &#125; updateMd5(groupKey, md5, lastModifiedTs);// 缓存配置信息的md5到内存中，并发布LocalDataChangeEvent return true; &#125; catch (IOException ioe) &#123; if (ioe.getMessage() != null) &#123; String errMsg = ioe.getMessage(); if (NO_SPACE_CN.equals(errMsg) || NO_SPACE_EN.equals(errMsg) || errMsg.contains(DISK_QUATA_CN) || errMsg.contains(DISK_QUATA_EN)) &#123; System.exit(0); // 磁盘满自杀退出 &#125; &#125; return false; &#125; finally &#123; releaseWriteLock(groupKey); &#125; &#125; public static void updateMd5(String groupKey, String md5, long lastModifiedTs) &#123; CacheItem cache = makeSure(groupKey); if (cache.md5 == null || !cache.md5.equals(md5)) &#123; // 为空说明没有，不相等说明更新了 cache.md5 = md5; cache.lastModifiedTs = lastModifiedTs; // 更新最新更新时间 NotifyCenter.publishEvent(new LocalDataChangeEvent(groupKey)); // 发布更新事件，最终被LongPollingService订阅者监听 &#125; &#125;&#125; 配置变更监听器触发发布的LocalDataChangeEvent事件会被LongPollingService监听到，最终异步执行DataChangeTask任务，遍历所有的客户端长连接，这些长连接是客户启动时通过监听数据变化而创建的，每10ms执行一次，长连接超时时间为30s，服务端会持有长连接29.5s后才执行，比较客户端长链接请求的数据中否包含该groupKey，若包含直接响应长连接。客户端长连接请求时间间隔很短，即使更新时漏掉了某个长连接，但当常链接请求过来时，会发现数据变更了会立即返回。从而达到不漏掉任务客户端，且接近实时的效果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public LongPollingService() &#123; // 初始化LocalDataChangeEvent事件订阅者 allSubs = new ConcurrentLinkedQueue&lt;ClientLongPolling&gt;(); ConfigExecutor.scheduleLongPolling(new StatTask(), 0L, 10L, TimeUnit.SECONDS); // Register LocalDataChangeEvent to NotifyCenter. NotifyCenter.registerToPublisher(LocalDataChangeEvent.class, NotifyCenter.ringBufferSize); // Register A Subscriber to subscribe LocalDataChangeEvent. NotifyCenter.registerSubscriber(new Subscriber() &#123; @Override public void onEvent(Event event) &#123; if (isFixedPolling()) &#123; &#125; else &#123; if (event instanceof LocalDataChangeEvent) &#123; LocalDataChangeEvent evt = (LocalDataChangeEvent) event; ConfigExecutor.executeLongPolling(new DataChangeTask(evt.groupKey, evt.isBeta, evt.betaIps)); &#125; &#125; &#125; @Override public Class&lt;? extends Event&gt; subscribeType() &#123; return LocalDataChangeEvent.class; &#125; &#125;);&#125;class DataChangeTask implements Runnable &#123; @Override public void run() &#123; // 服务的push模式 try &#123; ConfigCacheService.getContentBetaMd5(groupKey); for (Iterator&lt;ClientLongPolling&gt; iter = allSubs.iterator(); iter.hasNext(); ) &#123; ClientLongPolling clientSub = iter.next(); if (clientSub.clientMd5Map.containsKey(groupKey)) &#123; // If published tag is not in the beta list, then it skipped. if (isBeta &amp;&amp; !CollectionUtils.contains(betaIps, clientSub.ip)) &#123; continue; &#125; // If published tag is not in the tag list, then it skipped. if (StringUtils.isNotBlank(tag) &amp;&amp; !tag.equals(clientSub.tag)) &#123; continue; &#125; getRetainIps().put(clientSub.ip, System.currentTimeMillis()); iter.remove(); // Delete subscribers' relationships. clientSub.sendResponse(Arrays.asList(groupKey)); // 响应配置发送变化的key，调用长连接中的sendResponse方法给客户响应数据 &#125; &#125; &#125; catch (Throwable t) &#123; &#125; &#125;&#125; 服务端配置发布服务端配置的发布是通过控制界面修改了配置点击发布，从而调用ConfigController的publishConfig方法完成配置的发布。首先会通过PersistService的insertOrUpdate方法将数据持久化到数据库。然后发布ConfigDataChangeEvent事件被订阅者AsyncNotifyService感知，从而通知其他成员节点。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@PostMapping // 用户通过nacos-console控制界面修改了配置，点击发布调用该接口@Secured(action = ActionTypes.WRITE, parser = ConfigResourceParser.class)public Boolean publishConfig(HttpServletRequest request, HttpServletResponse response, @RequestParam(value = \"dataId\") String dataId, @RequestParam(value = \"group\") String group, @RequestParam(value = \"tenant\", required = false, defaultValue = StringUtils.EMPTY) String tenant, @RequestParam(value = \"content\") String content, @RequestParam(value = \"tag\", required = false) String tag, @RequestParam(value = \"appName\", required = false) String appName, @RequestParam(value = \"src_user\", required = false) String srcUser, @RequestParam(value = \"config_tags\", required = false) String configTags, @RequestParam(value = \"desc\", required = false) String desc, @RequestParam(value = \"use\", required = false) String use, @RequestParam(value = \"effect\", required = false) String effect, @RequestParam(value = \"type\", required = false) String type, @RequestParam(value = \"schema\", required = false) String schema) throws NacosException &#123; final String srcIp = RequestUtil.getRemoteIp(request); // 获取远程调用者IP final String requestIpApp = RequestUtil.getAppName(request); srcUser = RequestUtil.getSrcUserName(request); if (!ConfigType.isValidType(type)) &#123; //check type type = ConfigType.getDefaultType().getType(); &#125; ParamUtils.checkTenant(tenant); // check tenant ParamUtils.checkParam(dataId, group, \"datumId\", content); ParamUtils.checkParam(tag); Map&lt;String, Object&gt; configAdvanceInfo = new HashMap&lt;String, Object&gt;(10); MapUtils.putIfValNoNull(configAdvanceInfo, \"config_tags\", configTags); MapUtils.putIfValNoNull(configAdvanceInfo, \"desc\", desc); MapUtils.putIfValNoNull(configAdvanceInfo, \"use\", use); MapUtils.putIfValNoNull(configAdvanceInfo, \"effect\", effect); MapUtils.putIfValNoNull(configAdvanceInfo, \"type\", type); MapUtils.putIfValNoNull(configAdvanceInfo, \"schema\", schema); ParamUtils.checkParam(configAdvanceInfo); if (AggrWhitelist.isAggrDataId(dataId)) &#123; throw new NacosException(NacosException.NO_RIGHT, \"dataId:\" + dataId + \" is aggr\"); &#125; final Timestamp time = TimeUtils.getCurrentTime(); String betaIps = request.getHeader(\"betaIps\"); ConfigInfo configInfo = new ConfigInfo(dataId, group, tenant, appName, content); configInfo.setType(type); if (StringUtils.isBlank(betaIps)) &#123; if (StringUtils.isBlank(tag)) &#123; persistService.insertOrUpdate(srcIp, srcUser, configInfo, time, configAdvanceInfo, true); // 持久化数据到MySQL // ConfigDataChangeEvent事件被订阅者AsyncNotifyService感知 ConfigChangePublisher.notifyConfigChange(new ConfigDataChangeEvent(false, dataId, group, tenant, time.getTime())); &#125; else &#123; persistService.insertOrUpdateTag(configInfo, tag, srcIp, srcUser, time, true); // 持久化数据到MySQL // ConfigDataChangeEvent事件被订阅者AsyncNotifyService感知 ConfigChangePublisher.notifyConfigChange(new ConfigDataChangeEvent(false, dataId, group, tenant, tag, time.getTime())); &#125; &#125; else &#123; persistService.insertOrUpdateBeta(configInfo, betaIps, srcIp, srcUser, time, true); // beta publish // ConfigDataChangeEvent事件被订阅者AsyncNotifyService感知 ConfigChangePublisher.notifyConfigChange(new ConfigDataChangeEvent(true, dataId, group, tenant, time.getTime())); &#125; ConfigTraceService.logPersistenceEvent(dataId, group, tenant, requestIpApp, time.getTime(), InetUtils.getSelfIP(), ConfigTraceService.PERSISTENCE_EVENT_PUB, content); return true;&#125; 当接收到ConfigDataChangeEvent变更事件后，首先遍历所有服务端成员，将变更配置的KEY以及成员信息封装到NotifySingleTask中，并放入阻塞队列中，通过AsyncTask中执行执行executeAsyncInvoke方法将更变数据通过调用服务端成员的/v1/cs/communication/dataChange接口同步给对方。若成员不是健康状态则延迟执行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class AsyncNotifyService &#123; public AsyncNotifyService(ServerMemberManager memberManager) &#123; this.memberManager = memberManager; NotifyCenter.registerToPublisher(ConfigDataChangeEvent.class, NotifyCenter.ringBufferSize); NotifyCenter.registerSubscriber(new Subscriber() &#123; @Override public void onEvent(Event event) &#123; if (event instanceof ConfigDataChangeEvent) &#123; ConfigDataChangeEvent evt = (ConfigDataChangeEvent) event; long dumpTs = evt.lastModifiedTs; String dataId = evt.dataId; String group = evt.group; String tenant = evt.tenant; String tag = evt.tag; Collection&lt;Member&gt; ipList = memberManager.allMembers(); Queue&lt;NotifySingleTask&gt; queue = new LinkedList&lt;NotifySingleTask&gt;(); for (Member member : ipList) &#123; // 将变更的配置信息同步给集群其它节点，包括自己 queue.add(new NotifySingleTask(dataId, group, tenant, tag, dumpTs, member.getAddress(), evt.isBeta)); &#125; ConfigExecutor.executeAsyncNotify(new AsyncTask(nacosAsyncRestTemplate, queue)); &#125; &#125; @Override public Class&lt;? extends Event&gt; subscribeType() &#123; return ConfigDataChangeEvent.class; &#125; &#125;); &#125;&#125;static class NotifySingleTask extends NotifyTask &#123; private String target; public String url; private boolean isBeta; private static final String URL_PATTERN = \"http://&#123;0&#125;&#123;1&#125;\" + Constants.COMMUNICATION_CONTROLLER_PATH + \"/dataChange\" + \"?dataId=&#123;2&#125;&amp;group=&#123;3&#125;\"; private static final String URL_PATTERN_TENANT = \"http://&#123;0&#125;&#123;1&#125;\" + Constants.COMMUNICATION_CONTROLLER_PATH + \"/dataChange?dataId=&#123;2&#125;&amp;group=&#123;3&#125;&amp;tenant=&#123;4&#125;\"; private int failCount; public NotifySingleTask(String dataId, String group, String tenant, String tag, long lastModified, String target, boolean isBeta) &#123; super(dataId, group, tenant, lastModified); this.target = target; this.isBeta = isBeta; try &#123; dataId = URLEncoder.encode(dataId, Constants.ENCODE); group = URLEncoder.encode(group, Constants.ENCODE); &#125; catch (UnsupportedEncodingException e) &#123; &#125; if (StringUtils.isBlank(tenant)) &#123; this.url = MessageFormat.format(URL_PATTERN, target, EnvUtil.getContextPath(), dataId, group); &#125; else &#123; this.url = MessageFormat.format(URL_PATTERN_TENANT, target, EnvUtil.getContextPath(), dataId, group, tenant); &#125; if (StringUtils.isNotEmpty(tag)) &#123; url = url + \"&amp;tag=\" + tag; &#125; failCount = 0; &#125;&#125;class AsyncTask implements Runnable &#123; public void run() &#123; executeAsyncInvoke(); &#125; private void executeAsyncInvoke() &#123; // 将更变数据通过调用其他成员的/v1/cs/communication/dataChange接口同步给对方 while (!queue.isEmpty()) &#123; NotifySingleTask task = queue.poll(); String targetIp = task.getTargetIP(); if (memberManager.hasMember(targetIp)) &#123; boolean unHealthNeedDelay = memberManager.isUnHealth(targetIp); if (unHealthNeedDelay) &#123; // 若成员不健康 ConfigTraceService.logNotifyEvent(task.getDataId(), task.getGroup(), task.getTenant(), null, task.getLastModified(), InetUtils.getSelfIP(), ConfigTraceService.NOTIFY_EVENT_UNHEALTH, 0, task.target); asyncTaskExecute(task); &#125; else &#123; Header header = Header.newInstance(); header.addParam(NotifyService.NOTIFY_HEADER_LAST_MODIFIED, String.valueOf(task.getLastModified())); header.addParam(NotifyService.NOTIFY_HEADER_OP_HANDLE_IP, InetUtils.getSelfIP()); if (task.isBeta) &#123; header.addParam(\"isBeta\", \"true\"); &#125; AuthHeaderUtil.addIdentityToHeader(header); restTemplate.get(task.url, header, Query.EMPTY, String.class, new AsyncNotifyCallBack(task)); &#125; &#125; &#125; &#125;&#125; 最终调用CommunicationController的notifyConfigInfo方法接收变更数据，最终调用DumpService的dump方法将任务放入NacosDelayTaskExecuteEngine的任务队列中。最终通过在DumpService构造方法中设置好的DumpProcessor处理器来处理该任务。 1234567891011121314151617181920212223242526@GetMapping(\"/dataChange\")public Boolean notifyConfigInfo(HttpServletRequest request, @RequestParam(\"dataId\") String dataId, @RequestParam(\"group\") String group, @RequestParam(value = \"tenant\", required = false, defaultValue = StringUtils.EMPTY) String tenant, @RequestParam(value = \"tag\", required = false) String tag) &#123; dataId = dataId.trim(); group = group.trim(); String lastModified = request.getHeader(NotifyService.NOTIFY_HEADER_LAST_MODIFIED); long lastModifiedTs = StringUtils.isEmpty(lastModified) ? -1 : Long.parseLong(lastModified); String handleIp = request.getHeader(NotifyService.NOTIFY_HEADER_OP_HANDLE_IP); String isBetaStr = request.getHeader(\"isBeta\"); if (StringUtils.isNotBlank(isBetaStr) &amp;&amp; trueStr.equals(isBetaStr)) &#123; dumpService.dump(dataId, group, tenant, lastModifiedTs, handleIp, true); &#125; else &#123; dumpService.dump(dataId, group, tenant, tag, lastModifiedTs, handleIp); &#125; return true;&#125;public abstract class DumpService &#123; public void dump(String dataId, String group, String tenant, long lastModified, String handleIp) &#123; dump(dataId, group, tenant, lastModified, handleIp, false); &#125; public void dump(String dataId, String group, String tenant, long lastModified, String handleIp, boolean isBeta) &#123; String groupKey = GroupKey2.getKey(dataId, group, tenant); dumpTaskMgr.addTask(groupKey, new DumpTask(groupKey, lastModified, handleIp, isBeta)); &#125;&#125; 在DumpProcessor处理器中，首先通过PersistService的findConfigInfo方法从数据库查询最新的数据，然后将变更信息即最新数据封装成了ConfigDumpEvent事件，通过DumpConfigHandler的configDump方法最终调用ConfigCacheService的dump方法将最新的数据更新到磁盘缓存文件中，以及缓存中并发布LocalDataChangeEvent。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class DumpProcessor implements NacosTaskProcessor &#123; public boolean process(NacosTask task) &#123; final PersistService persistService = dumpService.getPersistService(); DumpTask dumpTask = (DumpTask) task; String[] pair = GroupKey2.parseKey(dumpTask.getGroupKey()); String dataId = pair[0]; String group = pair[1]; String tenant = pair[2]; long lastModified = dumpTask.getLastModified(); String handleIp = dumpTask.getHandleIp(); boolean isBeta = dumpTask.isBeta(); String tag = dumpTask.getTag(); ConfigDumpEvent.ConfigDumpEventBuilder build = ConfigDumpEvent.builder().namespaceId(tenant).dataId(dataId) .group(group).isBeta(isBeta).tag(tag).lastModifiedTs(lastModified).handleIp(handleIp); if (isBeta) &#123; // beta发布，则dump数据，更新beta缓存，从数据库加载最新数据 ConfigInfo4Beta cf = persistService.findConfigInfo4Beta(dataId, group, tenant); build.remove(Objects.isNull(cf)); build.betaIps(Objects.isNull(cf) ? null : cf.getBetaIps()); build.content(Objects.isNull(cf) ? null : cf.getContent()); return DumpConfigHandler.configDump(build.build()); &#125; else &#123; if (StringUtils.isBlank(tag)) &#123; ConfigInfo cf = persistService.findConfigInfo(dataId, group, tenant); // 从数据库加载最新数据 build.remove(Objects.isNull(cf)); build.content(Objects.isNull(cf) ? null : cf.getContent()); build.type(Objects.isNull(cf) ? null : cf.getType()); return DumpConfigHandler.configDump(build.build()); &#125; else &#123; ConfigInfo4Tag cf = persistService.findConfigInfo4Tag(dataId, group, tenant, tag); // 从数据库加载最新数据 build.remove(Objects.isNull(cf)); build.content(Objects.isNull(cf) ? null : cf.getContent()); return DumpConfigHandler.configDump(build.build()); &#125; &#125; &#125;&#125;public class DumpConfigHandler extends Subscriber&lt;ConfigDumpEvent&gt; &#123; public static boolean configDump(ConfigDumpEvent event) &#123; // 该方法删除了多余代码逻辑 final String dataId = event.getDataId(); final String group = event.getGroup(); final String namespaceId = event.getNamespaceId(); final String content = event.getContent(); final String type = event.getType(); final long lastModified = event.getLastModifiedTs(); if (StringUtils.isBlank(event.getTag())) &#123; if (dataId.equals(AggrWhitelist.AGGRIDS_METADATA)) &#123; AggrWhitelist.load(content); &#125; if (dataId.equals(ClientIpWhiteList.CLIENT_IP_WHITELIST_METADATA)) &#123; ClientIpWhiteList.load(content); &#125; if (dataId.equals(SwitchService.SWITCH_META_DATAID)) &#123; SwitchService.load(content); &#125; boolean result; if (!event.isRemove()) &#123; result = ConfigCacheService.dump(dataId, group, namespaceId, content, lastModified, type); if (result) &#123; ConfigTraceService.logDumpEvent(dataId, group, namespaceId, null, lastModified, event.getHandleIp(), ConfigTraceService.DUMP_EVENT_OK, System.currentTimeMillis() - lastModified, content.length()); &#125; &#125; else &#123; result = ConfigCacheService.remove(dataId, group, namespaceId); if (result) &#123; ConfigTraceService.logDumpEvent(dataId, group, namespaceId, null, lastModified, event.getHandleIp(), ConfigTraceService.DUMP_EVENT_REMOVE_OK, System.currentTimeMillis() - lastModified, 0); &#125; &#125; return result; &#125; &#125;&#125;","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://yaoyinglong.github.io/tags/Nacos/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Nacos","slug":"Cloud/Nacos","permalink":"https://yaoyinglong.github.io/categories/Cloud/Nacos/"}]},{"title":"Nacos配置中心Client原理","date":"2021-10-30T16:00:00.000Z","path":"Blog/Cloud/Nacos/Nacos配置中心Client原理/","text":"客户端配置拉取对于客户端配置的拉取主要是通过NacosConfigBootstrapConfiguration配置类中注册的NacosPropertySourceLocator来完成的。 123456789101112131415161718@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(name = \"spring.cloud.nacos.config.enabled\", matchIfMissing = true)public class NacosConfigBootstrapConfiguration &#123; @Bean @ConditionalOnMissingBean public NacosConfigProperties nacosConfigProperties() &#123; return new NacosConfigProperties(); // 配置中心属性配置类，对应Bootstrap.properties中的配置信息 &#125; @Bean @ConditionalOnMissingBean public NacosConfigManager nacosConfigManager(NacosConfigProperties nacosConfigProperties) &#123; return new NacosConfigManager(nacosConfigProperties); // 持有NacosConfigProperties和ConfigService &#125; @Bean public NacosPropertySourceLocator nacosPropertySourceLocator(NacosConfigManager nacosConfigManager) &#123; return new NacosPropertySourceLocator(nacosConfigManager); // 加载nacos配置中心的配置信息 &#125;&#125; 在SpringBoot容器启动时首选通过在SpringApplication的prepareEnvironment中调用SpringApplicationRunListeners的environmentPrepared方法，从而调用NacosDefaultPropertySourceEnvironmentPostProcessor的postProcessEnvironment方法完成Nacos的默认配置的加载。 12345678910111213141516171819202122232425262728293031323334public class NacosDefaultPropertySourceEnvironmentPostProcessor implements EnvironmentPostProcessor, Ordered &#123; public static final String PROPERTY_SOURCE_NAME = \"nacos-default\"; public static final String RESOURCE_LOCATION_PATTERN = CLASSPATH_ALL_URL_PREFIX + \"META-INF/nacos-default.properties\"; public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) &#123; ResourceLoader resourceLoader = getResourceLoader(application); processPropertySource(environment, resourceLoader); &#125; private void processPropertySource(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; try &#123; PropertySource nacosDefaultPropertySource = buildPropertySource(resourceLoader); MutablePropertySources propertySources = environment.getPropertySources(); propertySources.addLast(nacosDefaultPropertySource); &#125; catch (IOException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; private PropertySource buildPropertySource(ResourceLoader resourceLoader) throws IOException &#123; CompositePropertySource propertySource = new CompositePropertySource(PROPERTY_SOURCE_NAME); appendPropertySource(propertySource, resourceLoader); return propertySource; &#125; private void appendPropertySource(CompositePropertySource propertySource, ResourceLoader resourceLoader) throws IOException &#123; ResourcePatternResolver resourcePatternResolver = new PathMatchingResourcePatternResolver(resourceLoader); Resource[] resources = resourcePatternResolver.getResources(RESOURCE_LOCATION_PATTERN); for (Resource resource : resources) &#123; // Add if exists if (resource.exists()) &#123; String internalName = String.valueOf(resource.getURL()); propertySource.addPropertySource(new ResourcePropertySource(internalName, new EncodedResource(resource, FILE_ENCODING))); &#125; &#125; &#125;&#125; 然后在SpringApplication的prepareContext中的applyInitializers调用在spring-cloud-context包中实现的，通过SpringFactoriesLoader加载的ApplicationContextInitializer的实现类PropertySourceBootstrapConfiguration，从而调用NacosPropertySourceLocator的locate，从服务端加载配置数据。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class SpringApplication &#123; protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, \"Unable to call initializer.\"); initializer.initialize(context); &#125; &#125;&#125;@Configuration(proxyBeanMethods = false)@EnableConfigurationProperties(PropertySourceBootstrapProperties.class)public class PropertySourceBootstrapConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered &#123; public void initialize(ConfigurableApplicationContext applicationContext) &#123; List&lt;PropertySource&lt;?&gt;&gt; composite = new ArrayList&lt;&gt;(); AnnotationAwareOrderComparator.sort(this.propertySourceLocators); boolean empty = true; ConfigurableEnvironment environment = applicationContext.getEnvironment(); for (PropertySourceLocator locator : this.propertySourceLocators) &#123; Collection&lt;PropertySource&lt;?&gt;&gt; source = locator.locateCollection(environment); if (source == null || source.size() == 0) &#123; continue; &#125; List&lt;PropertySource&lt;?&gt;&gt; sourceList = new ArrayList&lt;&gt;(); for (PropertySource&lt;?&gt; p : source) &#123; if (p instanceof EnumerablePropertySource) &#123; EnumerablePropertySource&lt;?&gt; enumerable = (EnumerablePropertySource&lt;?&gt;) p; sourceList.add(new BootstrapPropertySource&lt;&gt;(enumerable)); &#125; else &#123; sourceList.add(new SimpleBootstrapPropertySource(p)); &#125; &#125; composite.addAll(sourceList); empty = false; &#125; if (!empty) &#123; MutablePropertySources propertySources = environment.getPropertySources(); String logConfig = environment.resolvePlaceholders(\"$&#123;logging.config:&#125;\"); LogFile logFile = LogFile.get(environment); for (PropertySource&lt;?&gt; p : environment.getPropertySources()) &#123; if (p.getName().startsWith(BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; propertySources.remove(p.getName()); &#125; &#125; insertPropertySources(propertySources, composite); reinitializeLoggingSystem(environment, logConfig, logFile); setLogLevels(applicationContext, environment); handleIncludedProfiles(environment); &#125; &#125;&#125;public interface PropertySourceLocator &#123; default Collection&lt;PropertySource&lt;?&gt;&gt; locateCollection(Environment environment) &#123; return locateCollection(this, environment); &#125; static Collection&lt;PropertySource&lt;?&gt;&gt; locateCollection(PropertySourceLocator locator, Environment environment) &#123; PropertySource&lt;?&gt; propertySource = locator.locate(environment); // 最终调用实现类NacosPropertySourceLocator的locate方法 if (propertySource == null) &#123; return Collections.emptyList(); &#125; if (CompositePropertySource.class.isInstance(propertySource)) &#123; Collection&lt;PropertySource&lt;?&gt;&gt; sources = ((CompositePropertySource) propertySource).getPropertySources(); List&lt;PropertySource&lt;?&gt;&gt; filteredSources = new ArrayList&lt;&gt;(); for (PropertySource&lt;?&gt; p : sources) &#123; if (p != null) &#123; filteredSources.add(p); &#125; &#125; return filteredSources; &#125; else &#123; return Arrays.asList(propertySource); &#125; &#125;&#125;public class NacosPropertySourceLocator implements PropertySourceLocator &#123; public PropertySource&lt;?&gt; locate(Environment env) &#123; nacosConfigProperties.setEnvironment(env); // 将Spring容器中的Environment设置到nacosConfigProperties ConfigService configService = nacosConfigManager.getConfigService(); if (null == configService) &#123; return null; &#125; long timeout = nacosConfigProperties.getTimeout(); // 获取超时时间，默认3000 nacosPropertySourceBuilder = new NacosPropertySourceBuilder(configService, timeout); String name = nacosConfigProperties.getName(); // spring.cloud.nacos.config.name配置的名称 String dataIdPrefix = nacosConfigProperties.getPrefix(); // spring.cloud.nacos.config.prefix配置的值 if (StringUtils.isEmpty(dataIdPrefix)) &#123; dataIdPrefix = name; &#125; if (StringUtils.isEmpty(dataIdPrefix)) &#123; dataIdPrefix = env.getProperty(\"spring.application.name\"); // 获取应用名称 &#125; CompositePropertySource composite = new CompositePropertySource(NACOS_PROPERTY_SOURCE_NAME); // 名称为NACOS loadSharedConfiguration(composite); // 加载共享的配置文件，对应配置spring.cloud.nacos.config.sharedConfigs loadExtConfiguration(composite); // 加载扩展的配置文件，对应配置spring.cloud.nacos.config.extensionConfigs // 加载当前应用的配置，加载顺序：1.文件名（微服务名称）；2.文件名.文件扩展名；3.文件名-profile.文件扩展名，但使用优先级是3&gt;2&gt;1 loadApplicationConfiguration(composite, dataIdPrefix, nacosConfigProperties, env); return composite; &#125;&#125; 配置文件的加载顺序是共享配置文件、扩展配置文件、当前应用配置文件，而当前应用配置文件加载顺序又分为文件名、文件名.文件扩展名、文件名-profile.文件扩展名。但使用的优先顺序是反过来的。最终都是调用loadNacosDataIfPresent方法来完成配置信息的加载。 1234567891011121314151617181920212223242526272829303132private void loadSharedConfiguration(CompositePropertySource compositePropertySource) &#123; List&lt;NacosConfigProperties.Config&gt; sharedConfigs = nacosConfigProperties.getSharedConfigs(); if (!CollectionUtils.isEmpty(sharedConfigs)) &#123; checkConfiguration(sharedConfigs, \"shared-configs\"); // 校验共享配置文件的dataId loadNacosConfiguration(compositePropertySource, sharedConfigs); &#125;&#125;private void loadExtConfiguration(CompositePropertySource compositePropertySource) &#123; List&lt;NacosConfigProperties.Config&gt; extConfigs = nacosConfigProperties.getExtensionConfigs(); if (!CollectionUtils.isEmpty(extConfigs)) &#123; checkConfiguration(extConfigs, \"extension-configs\"); loadNacosConfiguration(compositePropertySource, extConfigs); &#125;&#125;private void loadNacosConfiguration(final CompositePropertySource composite, List&lt;NacosConfigProperties.Config&gt; configs) &#123; for (NacosConfigProperties.Config config : configs) &#123; // 若存在多个则遍历加载 loadNacosDataIfPresent(composite, config.getDataId(), config.getGroup(), NacosDataParserHandler.getInstance().getFileExtension(config.getDataId()), config.isRefresh()); &#125;&#125;private void loadApplicationConfiguration(CompositePropertySource compositePropertySource, String dataIdPrefix, NacosConfigProperties properties, Environment environment) &#123; String fileExtension = properties.getFileExtension(); // 获取文件扩展名 String nacosGroup = properties.getGroup(); // load directly once by default：文件名（微服务名称）, 注意这里的isRefreshable都是传的true都支持动态刷新配置 loadNacosDataIfPresent(compositePropertySource, dataIdPrefix, nacosGroup, fileExtension, true); // load with suffix, which have a higher priority than the default：文件名.文件扩展名 loadNacosDataIfPresent(compositePropertySource, dataIdPrefix + DOT + fileExtension, nacosGroup, fileExtension, true); // Loaded with profile, which have a higher priority than the suffix：文件名-profile.文件扩展名 for (String profile : environment.getActiveProfiles()) &#123; String dataId = dataIdPrefix + SEP1 + profile + DOT + fileExtension; loadNacosDataIfPresent(compositePropertySource, dataId, nacosGroup, fileExtension, true); &#125;&#125; 从这里也可以看出由于会将加载的propertySource添加到composite中队列首部，所以加载顺序与使用顺序是相反的。对于扩展和共享配置，默认不支持动态刷新，但当前应用配置是支持动态刷新的。最终通过ConfigService的getConfig方法从服务端拉取配置。 1234567891011121314151617181920212223242526272829303132333435363738private void loadNacosDataIfPresent(final CompositePropertySource composite, final String dataId, final String group, String fileExtension, boolean isRefreshable) &#123; if (null == dataId || dataId.trim().length() &lt; 1) &#123; return; // dataId为空则直接跳过 &#125; if (null == group || group.trim().length() &lt; 1) &#123; return; // group为空则直接跳过，一般有默认值 &#125; NacosPropertySource propertySource = this.loadNacosPropertySource(dataId, group, fileExtension, isRefreshable); this.addFirstPropertySource(composite, propertySource, false); // 将加载的propertySource添加到composite中队列首部&#125;private NacosPropertySource loadNacosPropertySource(final String dataId, final String group, String fileExtension, boolean isRefreshable) &#123; if (NacosContextRefresher.getRefreshCount() != 0) &#123; // 若已经被加载过了 if (!isRefreshable) &#123; // 对于扩展和共享配置，默认不支持动态刷新 return NacosPropertySourceRepository.getNacosPropertySource(dataId, group); &#125; &#125; return nacosPropertySourceBuilder.build(dataId, group, fileExtension, isRefreshable); // 默认扩展名fileExtension为properties&#125;public class NacosPropertySourceBuilder &#123; NacosPropertySource build(String dataId, String group, String fileExtension, boolean isRefreshable) &#123; List&lt;PropertySource&lt;?&gt;&gt; propertySources = loadNacosData(dataId, group, fileExtension); NacosPropertySource nacosPropertySource = new NacosPropertySource(propertySources, group, dataId, new Date(), isRefreshable); NacosPropertySourceRepository.collectNacosPropertySource(nacosPropertySource); // 将配置加载到缓存中 return nacosPropertySource; &#125; private List&lt;PropertySource&lt;?&gt;&gt; loadNacosData(String dataId, String group, String fileExtension) &#123; String data = null; try &#123; data = configService.getConfig(dataId, group, timeout); if (StringUtils.isEmpty(data)) &#123; return Collections.emptyList(); &#125; return NacosDataParserHandler.getInstance().parseNacosData(dataId, data, fileExtension); // 从服务端请求回的数据的解析 &#125; catch (Exception e) &#123; &#125; return Collections.emptyList(); &#125;&#125; 最终调用ConfigService的实现类NacosConfigService，首先从本地换存的配置文件中加载配置数据，加载到数据直接返回，后续是通过定时更新机制来更新数据。若从本地未获取到数据，则通过ClientWorker的getServerConfig从服务端拉取数据，若请求失败还是使用本地缓存。 123456789101112131415161718192021222324252627282930313233343536public class NacosConfigService implements ConfigService &#123; public String getConfig(String dataId, String group, long timeoutMs) throws NacosException &#123; return getConfigInner(namespace, dataId, group, timeoutMs); &#125; private String getConfigInner(String tenant, String dataId, String group, long timeoutMs) throws NacosException &#123; group = null2defaultGroup(group); // 若group为空，则设置为DEFAULT_GROUP ParamUtils.checkKeyParam(dataId, group); // 校验dataId和group是否合法 ConfigResponse cr = new ConfigResponse(); cr.setDataId(dataId); cr.setTenant(tenant); // namespace cr.setGroup(group); String content = LocalConfigInfoProcessor.getFailover(agent.getName(), dataId, group, tenant); // 优先使用本地配置 if (content != null) &#123; // 若从本地文件中读取到配置 cr.setContent(content); configFilterChainManager.doFilter(null, cr); content = cr.getContent(); return content; &#125; try &#123; // 若未获取到配置信息，则远程调用配置中心获取配置信息 String[] ct = worker.getServerConfig(dataId, group, tenant, timeoutMs); cr.setContent(ct[0]); configFilterChainManager.doFilter(null, cr); content = cr.getContent(); return content; &#125; catch (NacosException ioe) &#123; if (NacosException.NO_RIGHT == ioe.getErrCode()) &#123; throw ioe; &#125; &#125; content = LocalConfigInfoProcessor.getSnapshot(agent.getName(), dataId, group, tenant); // 若请求远程失败则从本地缓存文件获取数据 cr.setContent(content); configFilterChainManager.doFilter(null, cr); content = cr.getContent(); return content; &#125;&#125; ClientWorker中通过HTTP请求调用服务端/v1/cs/configs接口获取最新的配置信息，最终调用ConfigController的getConfig方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ClientWorker implements Closeable &#123; public String[] getServerConfig(String dataId, String group, String tenant, long readTimeout) throws NacosException &#123; String[] ct = new String[2]; if (StringUtils.isBlank(group)) &#123; group = Constants.DEFAULT_GROUP; // 若group为空则设置为默认值DEFAULT_GROUP &#125; HttpRestResult&lt;String&gt; result = null; try &#123; Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(3); if (StringUtils.isBlank(tenant)) &#123; params.put(\"dataId\", dataId); params.put(\"group\", group); &#125; else &#123; params.put(\"dataId\", dataId); params.put(\"group\", group); params.put(\"tenant\", tenant); &#125; // 调用服务端/v1/cs/configs接口获取最新的配置信息 result = agent.httpGet(Constants.CONFIG_CONTROLLER_PATH, null, params, agent.getEncode(), readTimeout); &#125; catch (Exception ex) &#123; throw new NacosException(NacosException.SERVER_ERROR, ex); &#125; switch (result.getCode()) &#123; case HttpURLConnection.HTTP_OK: // 保存结果到本地文件中 LocalConfigInfoProcessor.saveSnapshot(agent.getName(), dataId, group, tenant, result.getData()); ct[0] = result.getData(); if (result.getHeader().getValue(CONFIG_TYPE) != null) &#123; ct[1] = result.getHeader().getValue(CONFIG_TYPE); &#125; else &#123; ct[1] = ConfigType.TEXT.getType(); &#125; return ct; case HttpURLConnection.HTTP_NOT_FOUND: LocalConfigInfoProcessor.saveSnapshot(agent.getName(), dataId, group, tenant, null); return ct; case HttpURLConnection.HTTP_CONFLICT: &#123; throw new NacosException(NacosException.CONFLICT, \"data being modified, dataId=\" + dataId + \",group=\" + group + \",tenant=\" + tenant); &#125; case HttpURLConnection.HTTP_FORBIDDEN: &#123; throw new NacosException(result.getCode(), result.getMessage()); &#125; default: &#123; throw new NacosException(result.getCode(), \"http error, code=\" + result.getCode() + \",dataId=\" + dataId + \",group=\" + group + \",tenant=\" + tenant); &#125; &#125; &#125;&#125; 集群模式下并不是去数据库查询而是通过DiskUtil#targetTagFile方法查询本地磁盘的缓存，修改配置需要发布ConfigDataChangeEvent事件，触发本地文件和内存更新。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142@GetMapping@Secured(action = ActionTypes.READ, parser = ConfigResourceParser.class)public void getConfig(HttpServletRequest request, HttpServletResponse response, @RequestParam(\"dataId\") String dataId, @RequestParam(\"group\") String group, @RequestParam(value = \"tenant\", required = false, defaultValue = StringUtils.EMPTY) String tenant, @RequestParam(value = \"tag\", required = false) String tag) throws IOException, ServletException, NacosException &#123; ParamUtils.checkTenant(tenant); // check tenant tenant = NamespaceUtil.processNamespaceParameter(tenant); ParamUtils.checkParam(dataId, group, \"datumId\", \"content\"); // check params ParamUtils.checkParam(tag); final String clientIp = RequestUtil.getRemoteIp(request); inner.doGetConfig(request, response, dataId, group, tenant, tag, clientIp);&#125;public class ConfigServletInner &#123; public String doGetConfig(HttpServletRequest request, HttpServletResponse response, String dataId, String group, String tenant, String tag, String clientIp) throws IOException, ServletException &#123; final String groupKey = GroupKey2.getKey(dataId, group, tenant); String autoTag = request.getHeader(\"Vipserver-Tag\"); String requestIpApp = RequestUtil.getAppName(request); int lockResult = tryConfigReadLock(groupKey); // 获取配置读取锁 final String requestIp = RequestUtil.getRemoteIp(request); // 获取请求方法IP boolean isBeta = false; if (lockResult &gt; 0) &#123; // 这里并不是去mysql而是查询本地磁盘的缓存，修改配置需要发布ConfigDataChangeEvent事件，触发本地文件和内存更新 FileInputStream fis = null; try &#123; String md5 = Constants.NULL; long lastModified = 0L; CacheItem cacheItem = ConfigCacheService.getContentCache(groupKey); if (cacheItem != null) &#123; // 若缓存cacheItem不为空 if (cacheItem.isBeta()) &#123; // 若isBeta为true if (cacheItem.getIps4Beta().contains(clientIp)) &#123; // ips4Beta列表中包含请求方ip isBeta = true; &#125; &#125; final String configType = (null != cacheItem.getType()) ? cacheItem.getType() : FileTypeEnum.TEXT.getFileType(); response.setHeader(\"Config-Type\", configType); FileTypeEnum fileTypeEnum = FileTypeEnum.getFileTypeEnumByFileExtensionOrFileType(configType); // 获取配置文件类型 String contentTypeHeader = fileTypeEnum.getContentType(); response.setHeader(HttpHeaderConsts.CONTENT_TYPE, contentTypeHeader); &#125; File file = null; ConfigInfoBase configInfoBase = null; PrintWriter out = null; if (isBeta) &#123; // 若isBeta为true 说明缓存cacheItem存在 md5 = cacheItem.getMd54Beta(); lastModified = cacheItem.getLastModifiedTs4Beta(); // 最后修改时间 if (PropertyUtil.isDirectRead()) &#123; // 是单例部署，或使用内嵌存储 configInfoBase = persistService.findConfigInfo4Beta(dataId, group, tenant); &#125; else &#123; // 集群部署 file = DiskUtil.targetBetaFile(dataId, group, tenant); // 获取到数据文件 &#125; response.setHeader(\"isBeta\", \"true\"); &#125; else &#123; // 若isBeta为false if (StringUtils.isBlank(tag)) &#123; // 一般tag为null if (isUseTag(cacheItem, autoTag)) &#123; if (cacheItem != null) &#123; if (cacheItem.tagMd5 != null) &#123; md5 = cacheItem.tagMd5.get(autoTag); &#125; if (cacheItem.tagLastModifiedTs != null) &#123; lastModified = cacheItem.tagLastModifiedTs.get(autoTag); &#125; &#125; if (PropertyUtil.isDirectRead()) &#123; // 是单例部署，或使用内嵌存储 configInfoBase = persistService.findConfigInfo4Tag(dataId, group, tenant, autoTag); &#125; else &#123; file = DiskUtil.targetTagFile(dataId, group, tenant, autoTag); // 获取到数据文件 &#125; response.setHeader(\"Vipserver-Tag\", URLEncoder.encode(autoTag, StandardCharsets.UTF_8.displayName())); &#125; else &#123; md5 = cacheItem.getMd5(); lastModified = cacheItem.getLastModifiedTs(); if (PropertyUtil.isDirectRead()) &#123; // 是单例部署，或使用内嵌存储 configInfoBase = persistService.findConfigInfo(dataId, group, tenant); &#125; else &#123; file = DiskUtil.targetFile(dataId, group, tenant); // 获取到数据文件 &#125; if (configInfoBase == null &amp;&amp; fileNotExist(file)) &#123; // 若配置文件不存在 response.setStatus(HttpServletResponse.SC_NOT_FOUND); response.getWriter().println(\"config data not exist\"); return HttpServletResponse.SC_NOT_FOUND + \"\"; &#125; &#125; &#125; else &#123; // tag不为null if (cacheItem != null) &#123; if (cacheItem.tagMd5 != null) &#123; md5 = cacheItem.tagMd5.get(tag); &#125; if (cacheItem.tagLastModifiedTs != null) &#123; Long lm = cacheItem.tagLastModifiedTs.get(tag); if (lm != null) &#123; lastModified = lm; &#125; &#125; &#125; if (PropertyUtil.isDirectRead()) &#123; configInfoBase = persistService.findConfigInfo4Tag(dataId, group, tenant, tag); &#125; else &#123; file = DiskUtil.targetTagFile(dataId, group, tenant, tag); &#125; if (configInfoBase == null &amp;&amp; fileNotExist(file)) &#123; response.setStatus(HttpServletResponse.SC_NOT_FOUND); response.getWriter().println(\"config data not exist\"); return HttpServletResponse.SC_NOT_FOUND + \"\"; &#125; &#125; &#125; response.setHeader(Constants.CONTENT_MD5, md5); response.setHeader(\"Pragma\", \"no-cache\"); response.setDateHeader(\"Expires\", 0); response.setHeader(\"Cache-Control\", \"no-cache,no-store\"); if (PropertyUtil.isDirectRead()) &#123; // 是单例部署，或使用内嵌存储 response.setDateHeader(\"Last-Modified\", lastModified); &#125; else &#123; fis = new FileInputStream(file); response.setDateHeader(\"Last-Modified\", file.lastModified()); &#125; if (PropertyUtil.isDirectRead()) &#123; // 是单例部署，或使用内嵌存储 out = response.getWriter(); out.print(configInfoBase.getContent()); out.flush(); out.close(); &#125; else &#123; fis.getChannel().transferTo(0L, fis.getChannel().size(), Channels.newChannel(response.getOutputStream())); &#125; &#125; finally &#123; releaseConfigReadLock(groupKey); IoUtils.closeQuietly(fis); &#125; &#125; else if (lockResult == 0) &#123; response.setStatus(HttpServletResponse.SC_NOT_FOUND); response.getWriter().println(\"config data not exist\"); return HttpServletResponse.SC_NOT_FOUND + \"\"; &#125; else &#123; // 未获取读取数据的锁 response.setStatus(HttpServletResponse.SC_CONFLICT); response.getWriter().println(\"requested file is being modified, please try later.\"); return HttpServletResponse.SC_CONFLICT + \"\"; &#125; return HttpServletResponse.SC_OK + \"\"; &#125;&#125; 客户端数据监听数据的监听是通过NacosConfigBootstrapConfiguration配置类中注册的NacosConfigManager中创建的NacosConfigService来完成的。 123456789101112131415161718192021public class NacosConfigManager &#123; public NacosConfigManager(NacosConfigProperties nacosConfigProperties) &#123; this.nacosConfigProperties = nacosConfigProperties; createConfigService(nacosConfigProperties); &#125; static ConfigService createConfigService(NacosConfigProperties nacosConfigProperties) &#123; if (Objects.isNull(service)) &#123; synchronized (NacosConfigManager.class) &#123; try &#123; if (Objects.isNull(service)) &#123; // 若ConfigService为null则通过反射的方式调用NacosConfigService的构造器进行实例化 service = NacosFactory.createConfigService(nacosConfigProperties.assembleConfigServiceProperties()); &#125; &#125; catch (NacosException e) &#123; log.error(e.getMessage()); throw new NacosConnectionFailureException(nacosConfigProperties.getServerAddr(), e.getMessage(), e); &#125; &#125; &#125; return service; &#125;&#125; NacosConfigService主要是通过构造方法创建的ClientWorker客户端工作类，为需要刷新的配置创建用来监听配置更新的长轮训LongPollingRunnable，该任务周期执行，正常情况执行周期是任务执行完后10ms，若发送异常则2s后执行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class NacosConfigService implements ConfigService &#123; public NacosConfigService(Properties properties) throws NacosException &#123; // 被ConfigFactory.createConfigService反射调用实例化 ValidatorUtils.checkInitParam(properties); String encodeTmp = properties.getProperty(PropertyKeyConst.ENCODE); if (StringUtils.isBlank(encodeTmp)) &#123; this.encode = Constants.ENCODE; &#125; else &#123; this.encode = encodeTmp.trim(); &#125; initNamespace(properties); this.agent = new MetricsHttpAgent(new ServerHttpAgent(properties)); // 用来向Nacos Server即配置的注册中心发起请求的代理 this.agent.start(); this.worker = new ClientWorker(this.agent, this.configFilterChainManager, properties); // 客户端工作类创建一个LongPollingRunnable用来监听配置更新 &#125;&#125;public class ClientWorker implements Closeable &#123; public ClientWorker(final HttpAgent agent, final ConfigFilterChainManager configFilterChainManager, final Properties properties) &#123; this.agent = agent; this.configFilterChainManager = configFilterChainManager; init(properties); // Initialize the timeout parameter this.executor = Executors.newScheduledThreadPool(1, new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setName(\"com.alibaba.nacos.client.Worker.\" + agent.getName()); t.setDaemon(true); return t; &#125; &#125;); // 线程数等于处理器个数的线程池，用来执行LongPollingRunnable#run方法，在checkConfigInfo方法中被放入线程中 this.executorService = Executors.newScheduledThreadPool(Runtime.getRuntime().availableProcessors(), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setName(\"com.alibaba.nacos.client.Worker.longPolling.\" + agent.getName()); t.setDaemon(true); return t; &#125; &#125;); this.executor.scheduleWithFixedDelay(new Runnable() &#123; @Override public void run() &#123; try &#123; checkConfigInfo(); // 每10ms执行一次定时任务，将cacheMap中的数量以3000分一个组，分别创建一个LongPollingRunnable用来监听配置更新 &#125; catch (Throwable e) &#123; &#125; &#125; &#125;, 1L, 10L, TimeUnit.MILLISECONDS); &#125; public void checkConfigInfo() &#123; // Dispatch taskes. cacheMap中缓存着需要刷新的配置，将cacheMap中的数量以3000分一个组，分别创建一个LongPollingRunnable用来监听配置更新 int listenerSize = cacheMap.size(); int longingTaskCount = (int) Math.ceil(listenerSize / ParamUtil.getPerTaskConfigSize()); // perTaskConfigSize默认为3000 if (longingTaskCount &gt; currentLongingTaskCount) &#123; for (int i = (int) currentLongingTaskCount; i &lt; longingTaskCount; i++) &#123; executorService.execute(new LongPollingRunnable(i)); // 创建一个长轮训 &#125; currentLongingTaskCount = longingTaskCount; &#125; &#125;&#125; 长轮训首先检查本地配置，若存在本地配置，且与缓存中的本地配置版本不一致，把本地配置内容更新到缓存中，并触发事件，然后向服务端发送长连接，30s超时，服务端会返回变化的dataIds，让后客户端根据变化的dataId，从服务端拉取最新的配置内容，并更新本地快照和缓存，对有变化的配置触发监听事件类处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class LongPollingRunnable implements Runnable &#123; private final int taskId; public LongPollingRunnable(int taskId) &#123; this.taskId = taskId; &#125; @Override public void run() &#123; // 客户端pull长轮询，出现异常延迟2s执行 List&lt;CacheData&gt; cacheDatas = new ArrayList&lt;CacheData&gt;(); List&lt;String&gt; inInitializingCacheList = new ArrayList&lt;String&gt;(); try &#123; for (CacheData cacheData : cacheMap.values()) &#123; if (cacheData.getTaskId() == taskId) &#123; cacheDatas.add(cacheData); try &#123; checkLocalConfig(cacheData); // 容错配置，用于检测本地的配置，若本地配置更新则更新缓存 if (cacheData.isUseLocalConfigInfo()) &#123; cacheData.checkListenerMd5(); // 对于变化的配置调用对应的监听器去处理 &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; // check server config，向Nacos Server发一个长连接30s超时，返回Nacos Server中有更新过的dataIds List&lt;String&gt; changedGroupKeys = checkUpdateDataIds(cacheDatas, inInitializingCacheList); for (String groupKey : changedGroupKeys) &#123; // 遍历变更列表 String[] key = GroupKey.parseKey(groupKey); String dataId = key[0]; String group = key[1]; String tenant = null; if (key.length == 3) &#123; tenant = key[2]; &#125; try &#123; // 根据变化的dataId调用Nacos Config服务端获取配置信息，并更新本地快照 String[] ct = getServerConfig(dataId, group, tenant, 3000L); CacheData cache = cacheMap.get(GroupKey.getKeyTenant(dataId, group, tenant)); cache.setContent(ct[0]); // 更新缓存数据 if (null != ct[1]) &#123; cache.setType(ct[1]); &#125; &#125; catch (NacosException ioe) &#123; &#125; &#125; for (CacheData cacheData : cacheDatas) &#123; if (!cacheData.isInitializing() || inInitializingCacheList.contains(GroupKey.getKeyTenant(cacheData.dataId, cacheData.group, cacheData.tenant))) &#123; cacheData.checkListenerMd5(); // 对于变化的配置调用对应的监听器去处理 cacheData.setInitializing(false); &#125; &#125; inInitializingCacheList.clear(); executorService.execute(this); // 若正常则延迟10ms执行 &#125; catch (Throwable e) &#123; executorService.schedule(this, taskPenaltyTime, TimeUnit.MILLISECONDS); // 若异常则延迟2s执行 &#125; &#125;&#125; 最终通过调用注册中心的/v1/cs/configs/listener接口来发送长连接。最终调用ConfigController的listener方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ClientWorker implements Closeable &#123; List&lt;String&gt; checkUpdateDataIds(List&lt;CacheData&gt; cacheDatas, List&lt;String&gt; inInitializingCacheList) throws Exception &#123; StringBuilder sb = new StringBuilder(); for (CacheData cacheData : cacheDatas) &#123; if (!cacheData.isUseLocalConfigInfo()) &#123; sb.append(cacheData.dataId).append(WORD_SEPARATOR); sb.append(cacheData.group).append(WORD_SEPARATOR); if (StringUtils.isBlank(cacheData.tenant)) &#123; // 若不存在namespace sb.append(cacheData.getMd5()).append(LINE_SEPARATOR); &#125; else &#123; sb.append(cacheData.getMd5()).append(WORD_SEPARATOR); sb.append(cacheData.getTenant()).append(LINE_SEPARATOR); &#125; if (cacheData.isInitializing()) &#123; // isInitializing默认为true // It updates when cacheData occours in cacheMap by first time. inInitializingCacheList.add(GroupKey.getKeyTenant(cacheData.dataId, cacheData.group, cacheData.tenant)); &#125; &#125; &#125; boolean isInitializingCacheList = !inInitializingCacheList.isEmpty(); return checkUpdateConfigStr(sb.toString(), isInitializingCacheList); &#125; List&lt;String&gt; checkUpdateConfigStr(String probeUpdateString, boolean isInitializingCacheList) throws Exception &#123; Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(2); params.put(Constants.PROBE_MODIFY_REQUEST, probeUpdateString); // Listening-Configs Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(2); headers.put(\"Long-Pulling-Timeout\", \"\" + timeout); // timeout默认为30000ms即30s if (isInitializingCacheList) &#123; headers.put(\"Long-Pulling-Timeout-No-Hangup\", \"true\"); &#125; if (StringUtils.isBlank(probeUpdateString)) &#123; return Collections.emptyList(); // 若没有数据则直接返回 &#125; try &#123; long readTimeoutMs = timeout + (long) Math.round(timeout &gt;&gt; 1); // 默认为45s // 调用注册中心的/v1/cs/configs/listener接口 HttpRestResult&lt;String&gt; result = agent.httpPost(Constants.CONFIG_CONTROLLER_PATH + \"/listener\", headers, params, agent.getEncode(), readTimeoutMs); if (result.ok()) &#123; setHealthServer(true); return parseUpdateDataIdResponse(result.getData()); // 解析服务端返回的数据 &#125; else &#123; setHealthServer(false); &#125; &#125; catch (Exception e) &#123; setHealthServer(false); throw e; &#125; return Collections.emptyList(); &#125;&#125; 服务端接受到请求后，首先遍历从缓存中获取数据比较缓存内容的的MD5值是否相等，若存在MD5不一致则生成响应信息直接返回给客户端，最终在ClientLongPolling异步任务中保持长连接，服务端最多处理时长为29.5s，需留0.5s来返回，以免客户端超时。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@PostMapping(\"/listener\")@Secured(action = ActionTypes.READ, parser = ConfigResourceParser.class)public void listener(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; request.setAttribute(\"org.apache.catalina.ASYNC_SUPPORTED\", true); String probeModify = request.getParameter(\"Listening-Configs\"); if (StringUtils.isBlank(probeModify)) &#123; throw new IllegalArgumentException(\"invalid probeModify\"); &#125; probeModify = URLDecoder.decode(probeModify, Constants.ENCODE); Map&lt;String, String&gt; clientMd5Map; try &#123; clientMd5Map = MD5Util.getClientMd5Map(probeModify); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(\"invalid probeModify\"); &#125; inner.doPollingConfig(request, response, clientMd5Map, probeModify.length());&#125;public class ConfigServletInner &#123; public String doPollingConfig(HttpServletRequest request, HttpServletResponse response, Map&lt;String, String&gt; clientMd5Map, int probeRequestSize) throws IOException &#123; if (LongPollingService.isSupportLongPolling(request)) &#123; // 若支持长连接 longPollingService.addLongPollingClient(request, response, clientMd5Map, probeRequestSize); return HttpServletResponse.SC_OK + \"\"; &#125; // // 遍历从缓存中获取数据比较缓存内容的的MD5值是否相等，返回不相等的groupKey列表，最终将有变更的配置返给请求方 List&lt;String&gt; changedGroups = MD5Util.compareMd5(request, response, clientMd5Map); String oldResult = MD5Util.compareMd5OldResult(changedGroups); // Compatible with short polling result. String newResult = MD5Util.compareMd5ResultString(changedGroups); String version = request.getHeader(Constants.CLIENT_VERSION_HEADER); if (version == null) &#123; version = \"2.0.0\"; &#125; int versionNum = Protocol.getVersionNumber(version); if (versionNum &lt; START_LONG_POLLING_VERSION_NUM) &#123; response.addHeader(Constants.PROBE_MODIFY_RESPONSE, oldResult); response.addHeader(Constants.PROBE_MODIFY_RESPONSE_NEW, newResult); &#125; else &#123; request.setAttribute(\"content\", newResult); &#125; Loggers.AUTH.info(\"new content:\" + newResult); response.setHeader(\"Pragma\", \"no-cache\"); // Disable cache. response.setDateHeader(\"Expires\", 0); response.setHeader(\"Cache-Control\", \"no-cache,no-store\"); response.setStatus(HttpServletResponse.SC_OK); return HttpServletResponse.SC_OK + \"\"; &#125;&#125;public class LongPollingService &#123; public void addLongPollingClient(HttpServletRequest req, HttpServletResponse rsp, Map&lt;String, String&gt; clientMd5Map, int probeRequestSize) &#123; String str = req.getHeader(LongPollingService.LONG_POLLING_HEADER); String noHangUpFlag = req.getHeader(LongPollingService.LONG_POLLING_NO_HANG_UP_HEADER); String appName = req.getHeader(RequestUtil.CLIENT_APPNAME_HEADER); String tag = req.getHeader(\"Vipserver-Tag\"); // 服务端这边最多处理时长为29.5s，需留0.5s来返回，以免客户端超时 int delayTime = SwitchService.getSwitchInteger(SwitchService.FIXED_DELAY_TIME, 500); // delayTime默认为500 long timeout = Math.max(10000, Long.parseLong(str) - delayTime); // timeout默认为 30000 - 500 = 29500 if (isFixedPolling()) &#123; // 默认为false timeout = Math.max(10000, getFixedPollingInterval()); &#125; else &#123; long start = System.currentTimeMillis(); // 遍历从缓存中获取数据比较缓存内容的的MD5值是否相等, 返回变更列表 List&lt;String&gt; changedGroups = MD5Util.compareMd5(req, rsp, clientMd5Map); if (changedGroups.size() &gt; 0) &#123; generateResponse(req, rsp, changedGroups); // 若有MD5不一致则生成响应信息直接返回 return; &#125; else if (noHangUpFlag != null &amp;&amp; noHangUpFlag.equalsIgnoreCase(TRUE_STR)) &#123; return; &#125; &#125; String ip = RequestUtil.getRemoteIp(req); final AsyncContext asyncContext = req.startAsync(); // Must be called by http thread, or send response. asyncContext.setTimeout(0L); // AsyncContext.setTimeout() is incorrect, Control by oneself ConfigExecutor.executeLongPolling(new ClientLongPolling(asyncContext, clientMd5Map, ip, probeRequestSize, timeout, appName, tag)); &#125;&#125; 首先将任务添加到延时线程池中，延时时间为29.5s，若存在变化的数据则直接返回变化的数据，客户端在发起下一次长连接。 123456789101112131415161718192021222324252627class ClientLongPolling implements Runnable &#123; @Override public void run() &#123; asyncTimeoutFuture = ConfigExecutor.scheduleLongPolling(new Runnable() &#123; // 1.创建一个调度任务，任务的延迟时间为29.5s @Override public void run() &#123; // 执行长链接任务，延迟29.5s后执行 try &#123; getRetainIps().put(ClientLongPolling.this.ip, System.currentTimeMillis()); allSubs.remove(ClientLongPolling.this); // 3.从队列中移除当前任务 if (isFixedPolling()) &#123; // 从服务端本机上获取保存的对应客户端请求的groupKeys，检查是否发生变更，并将变更结果返回给客户端 List&lt;String&gt; changedGroups = MD5Util.compareMd5((HttpServletRequest) asyncContext.getRequest(), (HttpServletResponse) asyncContext.getResponse(), clientMd5Map); if (changedGroups.size() &gt; 0) &#123; sendResponse(changedGroups); // 有变更则返回变更列表 &#125; else &#123; sendResponse(null); // 若无变更则返回null &#125; &#125; else &#123; sendResponse(null); &#125; &#125; catch (Throwable t) &#123; &#125; &#125; &#125;, timeoutTime, TimeUnit.MILLISECONDS); allSubs.add(this); // 2.无论配置是否更新，最终都会进行响应，延迟29.5s执行，然后把自己添加到一个队列中 &#125;&#125; 客户端数刷新在SpringApplication的run方法中调用SpringApplicationRunListeners的running方法，从而调用EventPublishingRunListener的running方法发布ApplicationReadyEvent事件，在NacosConfigAutoConfiguration配置类中注入的NacosContextRefresher实现了ApplicationListener接口且监听了ApplicationReadyEvent事件。 1234567891011121314public class EventPublishingRunListener implements SpringApplicationRunListener, Ordered &#123; public void running(ConfigurableApplicationContext context) &#123; context.publishEvent(new ApplicationReadyEvent(this.application, this.args, context)); AvailabilityChangeEvent.publish(context, ReadinessState.ACCEPTING_TRAFFIC); &#125;&#125;@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(name = \"spring.cloud.nacos.config.enabled\", matchIfMissing = true)public class NacosConfigAutoConfiguration &#123; @Bean public NacosContextRefresher nacosContextRefresher(NacosConfigManager nacosConfigManager, NacosRefreshHistory nacosRefreshHistory) &#123; return new NacosContextRefresher(nacosConfigManager, nacosRefreshHistory); &#125;&#125; 在接收到ApplicationReadyEvent事件后，遍历所有的配置为每个dataId注册一个AbstractSharedListener监听器，通过NacosConfigService的addListener方法最终将监听器添加到CacheData中，这里监听器的作用是在配置发送变更是会调用该监听器进行配置的刷新。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class NacosContextRefresher implements ApplicationListener&lt;ApplicationReadyEvent&gt;, ApplicationContextAware &#123; public NacosContextRefresher(NacosConfigManager nacosConfigManager, NacosRefreshHistory refreshHistory) &#123; this.nacosConfigProperties = nacosConfigManager.getNacosConfigProperties(); this.nacosRefreshHistory = refreshHistory; this.configService = nacosConfigManager.getConfigService(); this.isRefreshEnabled = this.nacosConfigProperties.isRefreshEnabled(); // 刷新配置的主开关，默认打开 &#125; public void onApplicationEvent(ApplicationReadyEvent event) &#123; if (this.ready.compareAndSet(false, true)) &#123; // many Spring context this.registerNacosListenersForApplications(); &#125; &#125; private void registerNacosListenersForApplications() &#123; if (isRefreshEnabled()) &#123; // 默认为true for (NacosPropertySource propertySource : NacosPropertySourceRepository.getAll()) &#123; // 遍历所有的配置 if (!propertySource.isRefreshable()) &#123; continue; // 若单个的配置不支持刷新配置 &#125; String dataId = propertySource.getDataId(); registerNacosListener(propertySource.getGroup(), dataId); // 为每个dataId注册监听器 &#125; &#125; &#125; private void registerNacosListener(final String groupKey, final String dataKey) &#123; String key = NacosPropertySourceRepository.getMapKey(dataKey, groupKey); Listener listener = listenerMap.computeIfAbsent(key, lst -&gt; new AbstractSharedListener() &#123; @Override public void innerReceive(String dataId, String group, String configInfo) &#123; refreshCountIncrement(); // 增加刷新次数 nacosRefreshHistory.addRefreshRecord(dataId, group, configInfo); // 添加刷新记录 // 发布RefreshEvent事件，对应的监听器为RefreshEventListener applicationContext.publishEvent(new RefreshEvent(this, null, \"Refresh Nacos config\")); &#125; &#125;); try &#123; configService.addListener(dataKey, groupKey, listener); &#125; catch (NacosException e) &#123; &#125; &#125;&#125;public class NacosConfigService implements ConfigService &#123; private final ClientWorker worker; public void addListener(String dataId, String group, Listener listener) throws NacosException &#123; // 在NacosContextRefresher中onApplicationEvent中监听ApplicationReadyEvent事件时为每一个dataId注册了一个监听器，调用本方法添加创建的监听器 worker.addTenantListeners(dataId, group, Arrays.asList(listener)); &#125;&#125;public class ClientWorker implements Closeable &#123; public void addTenantListeners(String dataId, String group, List&lt;? extends Listener&gt; listeners) throws NacosException &#123; // 被NacosConfigService的addListener方法调用， group = null2defaultGroup(group); String tenant = agent.getTenant(); CacheData cache = addCacheDataIfAbsent(dataId, group, tenant); // 这里的Listener是在NacosContextRefresher中onApplicationEvent中监听ApplicationReadyEvent事件时为每一个dataId注册了一个AbstractSharedListener监听器 for (Listener listener : listeners) &#123; cache.addListener(listener); &#125; &#125;&#125;public class CacheData &#123; public void addListener(Listener listener) &#123; if (null == listener) &#123; throw new IllegalArgumentException(\"listener is null\"); &#125; // 这里的Listener是在NacosContextRefresher中onApplicationEvent中监听ApplicationReadyEvent事件时为每一个dataId注册了一个AbstractSharedListener监听器 ManagerListenerWrap wrap = (listener instanceof AbstractConfigChangeListener) ? new ManagerListenerWrap(listener, md5, content) : new ManagerListenerWrap(listener, md5); if (listeners.addIfAbsent(wrap)) &#123; &#125; &#125;&#125; 发布的RefreshEvent事件会被监听器RefreshEventListener监听到，把原来的Environment中的参数方法放到一个临时的Spring容器中重新加载，加载完毕后关闭临时容器，就将最新的参数加载到了容器中了，将新值与之前得到的值进行对比，找出变化的参数，并将变化的数据通过EnvironmentChangeEvent事件通知监听器。 123456789101112131415161718192021222324252627282930public class RefreshEventListener implements SmartApplicationListener &#123; public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ApplicationReadyEvent) &#123; handle((ApplicationReadyEvent) event); &#125; else if (event instanceof RefreshEvent) &#123; handle((RefreshEvent) event); &#125; &#125; public void handle(RefreshEvent event) &#123; if (this.ready.get()) &#123; // don't handle events before app is ready Set&lt;String&gt; keys = this.refresh.refresh(); // 刷新容器中标记了@RefreshScope的Bean &#125; &#125;&#125; public class ContextRefresher &#123; public synchronized Set&lt;String&gt; refresh() &#123; Set&lt;String&gt; keys = refreshEnvironment(); this.scope.refreshAll(); // 处理所有带有@RefreshScope注解的类将其销毁 return keys; &#125; public synchronized Set&lt;String&gt; refreshEnvironment() &#123; // 抽取除了system、jndi、servlet之外的所有参数变量 Map&lt;String, Object&gt; before = extract(this.context.getEnvironment().getPropertySources()); addConfigFilesToEnvironment(); // 把原来的Environment中的参数方法放到一个临时的Spring容器中重新加载，加载完毕后关闭临时容器，就将最新的参数加载到了容器中 // 获取新的参数值，将其与之前得到的值进行对比，找出变化的参数 Set&lt;String&gt; keys = changes(before, extract(this.context.getEnvironment().getPropertySources())).keySet(); this.context.publishEvent(new EnvironmentChangeEvent(this.context, keys)); // 发布变更时间，并带上改变的参数值。 return keys; &#125;&#125; 最终EnvironmentChangeEvent事件会被ConfigurationPropertiesRebinder监听，最终会将所有带有@ConfigurationProperties注解的配置类的Bean销毁，然后重新创建。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ConfigurationPropertiesRebinder implements ApplicationContextAware, ApplicationListener&lt;EnvironmentChangeEvent&gt; &#123; public void onApplicationEvent(EnvironmentChangeEvent event) &#123; if (this.applicationContext.equals(event.getSource()) || event.getKeys().equals(event.getSource())) &#123; rebind(); &#125; &#125; public void rebind() &#123; this.errors.clear(); for (String name : this.beans.getBeanNames()) &#123; rebind(name); &#125; &#125; public boolean rebind(String name) &#123; if (!this.beans.getBeanNames().contains(name)) &#123; return false; &#125; if (this.applicationContext != null) &#123; try &#123; Object bean = this.applicationContext.getBean(name); if (AopUtils.isAopProxy(bean)) &#123; bean = ProxyUtils.getTargetObject(bean); &#125; if (bean != null) &#123; if (getNeverRefreshable().contains(bean.getClass().getName())) &#123; return false; // ignore &#125; this.applicationContext.getAutowireCapableBeanFactory().destroyBean(bean); this.applicationContext.getAutowireCapableBeanFactory().initializeBean(bean, name); return true; &#125; &#125; catch (RuntimeException e) &#123; this.errors.put(name, e); throw e; &#125; catch (Exception e) &#123; this.errors.put(name, e); throw new IllegalStateException(\"Cannot rebind to \" + name, e); &#125; &#125; return false; &#125;&#125;public class ConfigurationPropertiesBeans implements BeanPostProcessor, ApplicationContextAware &#123; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if (isRefreshScoped(beanName)) &#123; return bean; &#125; ConfigurationPropertiesBean propertiesBean = ConfigurationPropertiesBean.get(this.applicationContext, bean, beanName); if (propertiesBean != null) &#123; this.beans.put(beanName, propertiesBean); &#125; return bean; &#125;&#125; 被@RefreshScope注解标注的Bean，在RefreshAutoConfiguration配置类中注册了RefreshScopeBeanDefinitionEnhancer后置处理器，在其postProcessBeanDefinitionRegistry将Bean的scope作用于设置为了refresh，在通过getBean创建Bean时，会通过判断Bean的作用域走相应的逻辑。最终会调用GenericScope的get方法，将Bean放入BeanLifecycleWrapperCache中，在调用RefreshScope的refreshAll方法是会被销毁。 12345678910111213141516171819202122232425262728293031323334353637383940public class GenericScope implements Scope, BeanFactoryPostProcessor, BeanDefinitionRegistryPostProcessor, DisposableBean &#123; private BeanLifecycleWrapperCache cache = new BeanLifecycleWrapperCache(new StandardScopeCache()); public Object get(String name, ObjectFactory&lt;?&gt; objectFactory) &#123; BeanLifecycleWrapper value = this.cache.put(name, new BeanLifecycleWrapper(name, objectFactory)); this.locks.putIfAbsent(name, new ReentrantReadWriteLock()); try &#123; return value.getBean(); &#125; catch (RuntimeException e) &#123; this.errors.put(name, e); throw e; &#125; &#125; public void destroy() &#123; List&lt;Throwable&gt; errors = new ArrayList&lt;Throwable&gt;(); Collection&lt;BeanLifecycleWrapper&gt; wrappers = this.cache.clear(); for (BeanLifecycleWrapper wrapper : wrappers) &#123; try &#123; Lock lock = this.locks.get(wrapper.getName()).writeLock(); lock.lock(); try &#123; wrapper.destroy(); &#125; finally &#123; lock.unlock(); &#125; &#125; catch (RuntimeException e) &#123; errors.add(e); &#125; &#125; if (!errors.isEmpty()) &#123; throw wrapIfNecessary(errors.get(0)); &#125; this.errors.clear(); &#125;&#125;public class RefreshScope extends GenericScope implements ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, Ordered &#123; public void refreshAll() &#123; super.destroy(); // 调用超类GenericScope的destroy方法 this.context.publishEvent(new RefreshScopeRefreshedEvent()); &#125;&#125;","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://yaoyinglong.github.io/tags/Nacos/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Nacos","slug":"Cloud/Nacos","permalink":"https://yaoyinglong.github.io/categories/Cloud/Nacos/"}]},{"title":"SpringBoot资源加载","date":"2021-10-26T16:00:00.000Z","path":"Blog/Spring/SpringBoot/SpringBoot资源加载/","text":"@ConfigurationProperties被@ConfigurationProperties注解修饰的类的属性注入，可通过@ConfigurationPropertiesScan和@EnableConfigurationProperties注解将@ConfigurationProperties修饰的类注册到Spring容器中，且注册处理属性注入的BeanPostProcessor后置处理器及相关的类。 @EnableConfigurationProperties注解通过@Import注解导入EnableConfigurationPropertiesRegistrar。能讲该注解value属性中配置的加了@ConfigurationProperties注解的类注册到Spring容器中。 12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(EnableConfigurationPropertiesRegistrar.class)public @interface EnableConfigurationProperties &#123; String VALIDATOR_BEAN_NAME = \"configurationPropertiesValidator\"; Class&lt;?&gt;[] value() default &#123;&#125;;&#125; EnableConfigurationPropertiesRegistrar实现了ImportBeanDefinitionRegistrar接口，在扫描BeanDefinition时被调用registerBeanDefinitions方法，从而完成ConfigurationPropertiesBindingPostProcessor、BoundConfigurationProperties、ConfigurationPropertiesBinder等处理属性注入的Bean的注册。 通过getTypes方法获取@EnableConfigurationProperties注解中value属性配置的类，遍历这些类通过ConfigurationPropertiesBeanRegistrar#register将这些类注册到Spring容器中。 1234567891011121314151617class EnableConfigurationPropertiesRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; registerInfrastructureBeans(registry); ConfigurationPropertiesBeanRegistrar beanRegistrar = new ConfigurationPropertiesBeanRegistrar(registry); getTypes(metadata).forEach(beanRegistrar::register); &#125; static void registerInfrastructureBeans(BeanDefinitionRegistry registry) &#123; ConfigurationPropertiesBindingPostProcessor.register(registry); BoundConfigurationProperties.register(registry); ConfigurationBeanFactoryMetadata.register(registry); &#125; private Set&lt;Class&lt;?&gt;&gt; getTypes(AnnotationMetadata metadata) &#123; return metadata.getAnnotations().stream(EnableConfigurationProperties.class) .flatMap((annotation) -&gt; Arrays.stream(annotation.getClassArray(MergedAnnotation.VALUE))) .filter((type) -&gt; void.class != type).collect(Collectors.toSet()); &#125;&#125; 在通过ConfigurationPropertiesBeanRegistrar将其注册到Spring容器前会检查该类上是否存在@ConfigurationProperties注解，且通过该方式生成Bean的名称和通过@Component等注解生成Bean不一样。这里会将@ConfigurationProperties注解prefix属性配置的值加上-再加上类的全限定名。 12345678910111213141516171819202122232425262728final class ConfigurationPropertiesBeanRegistrar &#123; void register(Class&lt;?&gt; type) &#123; MergedAnnotation&lt;ConfigurationProperties&gt; annotation = MergedAnnotations .from(type, SearchStrategy.TYPE_HIERARCHY).get(ConfigurationProperties.class); register(type, annotation); &#125; void register(Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; String name = getName(type, annotation); // 特殊化Bean的名称 if (!containsBeanDefinition(name)) &#123;// 判断该Bean是否注册到容器中 registerBeanDefinition(name, type, annotation); // 注册BeanDefinition到容器中 &#125; &#125; private String getName(Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; String prefix = annotation.isPresent() ? annotation.getString(\"prefix\") : \"\"; return (StringUtils.hasText(prefix) ? prefix + \"-\" + type.getName() : type.getName()); &#125; private void registerBeanDefinition(String beanName, Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; this.registry.registerBeanDefinition(beanName, createBeanDefinition(beanName, type)); &#125; private BeanDefinition createBeanDefinition(String beanName, Class&lt;?&gt; type) &#123; if (BindMethod.forType(type) == BindMethod.VALUE_OBJECT) &#123; // 根据该类是否有构造函数，且构造函数上是否有ConstructorBinding注解 return new ConfigurationPropertiesValueObjectBeanDefinition(this.beanFactory, beanName, type); &#125; GenericBeanDefinition definition = new GenericBeanDefinition(); definition.setBeanClass(type); return definition; &#125;&#125; ConfigurationPropertiesBindingPostProcessor实现了BeanPostProcessor后置处理器，在Bean创建过程中会调用该Bean的后置处理器的postProcessBeforeInitialization最终通过ConfigurationPropertiesBinder完成属性的注入。 12345678910111213141516171819202122232425262728293031public class ConfigurationPropertiesBindingPostProcessor implements BeanPostProcessor, PriorityOrdered, ApplicationContextAware, InitializingBean &#123; public static void register(BeanDefinitionRegistry registry) &#123; Assert.notNull(registry, \"Registry must not be null\"); if (!registry.containsBeanDefinition(BEAN_NAME)) &#123; GenericBeanDefinition definition = new GenericBeanDefinition(); definition.setBeanClass(ConfigurationPropertiesBindingPostProcessor.class); definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(BEAN_NAME, definition); &#125; ConfigurationPropertiesBinder.register(registry); &#125; public void afterPropertiesSet() throws Exception &#123; this.registry = (BeanDefinitionRegistry) this.applicationContext.getAutowireCapableBeanFactory(); this.binder = ConfigurationPropertiesBinder.get(this.applicationContext); &#125; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; bind(ConfigurationPropertiesBean.get(this.applicationContext, bean, beanName)); return bean; &#125; private void bind(ConfigurationPropertiesBean bean) &#123; if (bean == null || hasBoundValueObject(bean.getName())) &#123; return; &#125; Assert.state(bean.getBindMethod() == BindMethod.JAVA_BEAN, \"Cannot bind @ConfigurationProperties for bean '\" + bean.getName() + \"'. Ensure that @ConstructorBinding has not been applied to regular bean\"); try &#123; this.binder.bind(bean); &#125; catch (Exception ex) &#123; throw new ConfigurationPropertiesBindException(bean, ex); &#125; &#125;&#125; 最终通过层层调用将从PropertySources匹配到的属性值通过set方法将属性赋值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class ConfigurationPropertiesBinder &#123; BindResult&lt;?&gt; bind(ConfigurationPropertiesBean propertiesBean) &#123; Bindable&lt;?&gt; target = propertiesBean.asBindTarget(); ConfigurationProperties annotation = propertiesBean.getAnnotation(); BindHandler bindHandler = getBindHandler(target, annotation); return getBinder().bind(annotation.prefix(), target, bindHandler); &#125; private Binder getBinder() &#123; if (this.binder == null) &#123; this.binder = new Binder(getConfigurationPropertySources(), getPropertySourcesPlaceholdersResolver(), getConversionService(), getPropertyEditorInitializer(), null, ConfigurationPropertiesBindConstructorProvider.INSTANCE); &#125; return this.binder; &#125;&#125;public class Binder &#123; public &lt;T&gt; BindResult&lt;T&gt; bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, BindHandler handler) &#123; T bound = bind(name, target, handler, false); return BindResult.of(bound); &#125; private &lt;T&gt; T bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, BindHandler handler, Context context, boolean allowRecursiveBinding, boolean create) &#123; try &#123; Bindable&lt;T&gt; replacementTarget = handler.onStart(name, target, context); if (replacementTarget == null) &#123; return handleBindResult(name, target, handler, context, null, create); &#125; target = replacementTarget; Object bound = bindObject(name, target, handler, context, allowRecursiveBinding); return handleBindResult(name, target, handler, context, bound, create); &#125; catch (Exception ex) &#123; return handleBindError(name, target, handler, context, ex); &#125; &#125; private Object bindDataObject(ConfigurationPropertyName name, Bindable&lt;?&gt; target, BindHandler handler, Context context, boolean allowRecursiveBinding) &#123; if (isUnbindableBean(name, target, context)) &#123; return null; &#125; Class&lt;?&gt; type = target.getType().resolve(Object.class); if (!allowRecursiveBinding &amp;&amp; context.isBindingDataObject(type)) &#123; return null; &#125; DataObjectPropertyBinder propertyBinder = (propertyName, propertyTarget) -&gt; bind(name.append(propertyName), propertyTarget, handler, context, false, false); return context.withDataObject(type, () -&gt; &#123; for (DataObjectBinder dataObjectBinder : this.dataObjectBinders) &#123; Object instance = dataObjectBinder.bind(name, target, context, propertyBinder); if (instance != null) &#123; return instance; &#125; &#125; return null; &#125;); &#125;&#125;class JavaBeanBinder implements DataObjectBinder &#123; public &lt;T&gt; T bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, Context context, DataObjectPropertyBinder propertyBinder) &#123; boolean hasKnownBindableProperties = target.getValue() != null &amp;&amp; hasKnownBindableProperties(name, context); Bean&lt;T&gt; bean = Bean.get(target, hasKnownBindableProperties); if (bean == null) &#123; return null; &#125; BeanSupplier&lt;T&gt; beanSupplier = bean.getSupplier(target); boolean bound = bind(propertyBinder, bean, beanSupplier, context); return (bound ? beanSupplier.get() : null); &#125; private &lt;T&gt; boolean bind(DataObjectPropertyBinder propertyBinder, Bean&lt;T&gt; bean, BeanSupplier&lt;T&gt; beanSupplier, Context context) &#123; boolean bound = false; for (BeanProperty beanProperty : bean.getProperties().values()) &#123; bound |= bind(beanSupplier, propertyBinder, beanProperty); context.clearConfigurationProperty(); &#125; return bound; &#125; private &lt;T&gt; boolean bind(BeanSupplier&lt;T&gt; beanSupplier, DataObjectPropertyBinder propertyBinder, BeanProperty property) &#123; String propertyName = property.getName(); ResolvableType type = property.getType(); Supplier&lt;Object&gt; value = property.getValue(beanSupplier); Annotation[] annotations = property.getAnnotations(); Object bound = propertyBinder.bindProperty(propertyName, Bindable.of(type).withSuppliedValue(value).withAnnotations(annotations)); if (bound == null) &#123; return false; &#125; if (property.isSettable()) &#123; property.setValue(beanSupplier, bound); &#125; else if (value == null || !bound.equals(value.get())) &#123; throw new IllegalStateException(\"No setter found for property: \" + property.getName()); &#125; return true; &#125;&#125;static class BeanProperty &#123; private Method getter; private Method setter; private Field field; void setValue(Supplier&lt;?&gt; instance, Object value) &#123; try &#123; this.setter.setAccessible(true); this.setter.invoke(instance.get(), value); &#125; catch (Exception ex) &#123; throw new IllegalStateException(\"Unable to set value for property \" + this.name, ex); &#125; &#125;&#125; @ConfigurationPropertiesScan注解的作用是扫描所有带有@ConfigurationProperties注解的类将其注册到Spring容器中。且该注解上被@EnableConfigurationProperties注解标记。 123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(ConfigurationPropertiesScanRegistrar.class)@EnableConfigurationPropertiespublic @interface ConfigurationPropertiesScan &#123; @AliasFor(\"basePackages\") String[] value() default &#123;&#125;; @AliasFor(\"value\") String[] basePackages() default &#123;&#125;; Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;&#125; ConfigurationPropertiesScanRegistrar同样实现了ImportBeanDefinitionRegistrar接口，首先获取需要扫描的包，若未指定则以当前注解所在类所在的包作为扫描包，通过ClassPathScanningCandidateComponentProvider遍历扫描所有的包，扫描出包中被@ConfigurationProperties注解标注，但是未被@Component注解及其派生注解标注的类，注册到Spring容器中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class ConfigurationPropertiesScanRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; Set&lt;String&gt; packagesToScan = getPackagesToScan(importingClassMetadata); // 获取扫描的包 scan(registry, packagesToScan); // 扫描出包中所有带有@ConfigurationProperties注解的类，注册到Spring容器中 &#125; private Set&lt;String&gt; getPackagesToScan(AnnotationMetadata metadata) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(ConfigurationPropertiesScan.class.getName())); String[] basePackages = attributes.getStringArray(\"basePackages\"); Class&lt;?&gt;[] basePackageClasses = attributes.getClassArray(\"basePackageClasses\"); Set&lt;String&gt; packagesToScan = new LinkedHashSet&lt;&gt;(Arrays.asList(basePackages)); for (Class&lt;?&gt; basePackageClass : basePackageClasses) &#123; packagesToScan.add(ClassUtils.getPackageName(basePackageClass)); &#125; if (packagesToScan.isEmpty()) &#123; // 若未指定则以当前注解所在类所在的包作为扫描包 packagesToScan.add(ClassUtils.getPackageName(metadata.getClassName())); &#125; packagesToScan.removeIf((candidate) -&gt; !StringUtils.hasText(candidate)); return packagesToScan; &#125; private void scan(BeanDefinitionRegistry registry, Set&lt;String&gt; packages) &#123; ConfigurationPropertiesBeanRegistrar registrar = new ConfigurationPropertiesBeanRegistrar(registry); ClassPathScanningCandidateComponentProvider scanner = getScanner(registry); for (String basePackage : packages) &#123; for (BeanDefinition candidate : scanner.findCandidateComponents(basePackage)) &#123; register(registrar, candidate.getBeanClassName()); &#125; &#125; &#125; private ClassPathScanningCandidateComponentProvider getScanner(BeanDefinitionRegistry registry) &#123; ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false); scanner.setEnvironment(this.environment); scanner.setResourceLoader(this.resourceLoader); scanner.addIncludeFilter(new AnnotationTypeFilter(ConfigurationProperties.class)); // 添加过滤器，过滤出带有@ConfigurationProperties注解的类 TypeExcludeFilter typeExcludeFilter = new TypeExcludeFilter(); typeExcludeFilter.setBeanFactory((BeanFactory) registry); scanner.addExcludeFilter(typeExcludeFilter); return scanner; &#125; private void register(ConfigurationPropertiesBeanRegistrar registrar, String className) throws LinkageError &#123; try &#123; register(registrar, ClassUtils.forName(className, null)); &#125; catch (ClassNotFoundException ex) &#123; &#125; &#125; private void register(ConfigurationPropertiesBeanRegistrar registrar, Class&lt;?&gt; type) &#123; if (!isComponent(type)) &#123; // 该类没有被@Component注解修饰 registrar.register(type); // 注册过程和上面一样 &#125; &#125; private boolean isComponent(Class&lt;?&gt; type) &#123; return MergedAnnotations.from(type, SearchStrategy.TYPE_HIERARCHY).isPresent(Component.class); &#125;&#125; EnviromentEnviroment是Spring为运行环境提供的高度抽象接口，项目运行中的所有相关配置都基于此接口，在SpringApplication的prepareEnvironment方法中完成了配置文件的加载。通过发布环境准备就绪事件ApplicationEnvironmentPreparedEvent，从而加载项目中的配置文件。 123456789101112131415private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) &#123; // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); // 获取或创建ConfigurableEnvironment，会调用超类AbstractEnvironment的无参构造方法 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 加载默认配置 ConfigurationPropertySources.attach(environment); listeners.environmentPrepared(bootstrapContext, environment); // 发布环境准备就绪事件ApplicationEnvironmentPreparedEvent，从而加载项目中的配置文件 DefaultPropertiesPropertySource.moveToEnd(environment); // 将defaultProperties移到列表最后，即将其优先级降到最低 Assert.state(!environment.containsProperty(\"spring.main.environment-prefix\"), \"Environment prefix cannot be set via properties.\"); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; 在getOrCreateEnvironment方法中对Environment初始化，以ApplicationServletEnvironment为例，其初始化时会调用超类AbstractEnvironment的无参构造函数，然后调用子类StandardServletEnvironment实现的customizePropertySources方法，添加类型为StubPropertySource的servletConfigInitParams和servletContextInitParams，然后再调用其父类StandardEnvironment的customizePropertySources方法，将systemProperties和systemEnvironment加载到Environment中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class SpringApplication &#123; private ConfigurableEnvironment getOrCreateEnvironment() &#123; if (this.environment != null) &#123; return this.environment; &#125; switch (this.webApplicationType) &#123; case SERVLET: return new ApplicationServletEnvironment(); case REACTIVE: return new ApplicationReactiveWebEnvironment(); default: return new ApplicationEnvironment(); &#125; &#125;&#125;class ApplicationServletEnvironment extends StandardServletEnvironment &#123; protected ConfigurablePropertyResolver createPropertyResolver(MutablePropertySources propertySources) &#123; return ConfigurationPropertySources.createPropertyResolver(propertySources); &#125;&#125;public class StandardServletEnvironment extends StandardEnvironment implements ConfigurableWebEnvironment &#123; public static final String SERVLET_CONTEXT_PROPERTY_SOURCE_NAME = \"servletContextInitParams\"; public static final String SERVLET_CONFIG_PROPERTY_SOURCE_NAME = \"servletConfigInitParams\"; public static final String JNDI_PROPERTY_SOURCE_NAME = \"jndiProperties\"; protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new StubPropertySource(SERVLET_CONFIG_PROPERTY_SOURCE_NAME)); propertySources.addLast(new StubPropertySource(SERVLET_CONTEXT_PROPERTY_SOURCE_NAME)); if (JndiLocatorDelegate.isDefaultJndiEnvironmentAvailable()) &#123; propertySources.addLast(new JndiPropertySource(JNDI_PROPERTY_SOURCE_NAME)); &#125; super.customizePropertySources(propertySources); &#125;&#125;public class StandardEnvironment extends AbstractEnvironment &#123; public static final String SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME = \"systemEnvironment\"; public static final String SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME = \"systemProperties\"; protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new PropertiesPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME, getSystemProperties())); propertySources.addLast(new SystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, getSystemEnvironment())); &#125;&#125;public abstract class AbstractEnvironment implements ConfigurableEnvironment &#123; public AbstractEnvironment() &#123; this(new MutablePropertySources()); &#125; protected AbstractEnvironment(MutablePropertySources propertySources) &#123; this.propertySources = propertySources; this.propertyResolver = createPropertyResolver(propertySources); customizePropertySources(propertySources); &#125; protected void customizePropertySources(MutablePropertySources propertySources) &#123; &#125;&#125; 发布环境准备就绪事件ApplicationEnvironmentPreparedEvent是通过getRunListeners中从spring.factories配置文件加载的EventPublishingRunListener来完成的。 123# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener 123456public class SpringApplication &#123; private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args)); &#125;&#125; 故最终会调用EventPublishingRunListener的environmentPrepared方法来发布ApplicationEnvironmentPreparedEvent事件。 12345678910class SpringApplicationRunListeners &#123; void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; doWithListeners(\"spring.boot.application.environment-prepared\", (listener) -&gt; listener.environmentPrepared(bootstrapContext, environment)); &#125;&#125;public class EventPublishingRunListener implements SpringApplicationRunListener, Ordered &#123; public void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; this.initialMulticaster.multicastEvent(new ApplicationEnvironmentPreparedEvent(bootstrapContext, this.application, this.args, environment)); &#125;&#125; 监听了ApplicationEnvironmentPreparedEvent事件的类很多个，旧版本中是通过ConfigFileApplicationListener来加载配置文件，该监听器的加载是通过SpringApplication构造方法中通过getSpringFactoriesInstances方法从spring.factories配置文件中加载ApplicationListener时加载的。新版本是通过ConfigDataEnvironmentPostProcessor来加载的配置文件，其是通过加载ApplicationListener时加载的EnvironmentPostProcessorApplicationListener监听器时该类的构造方法中又加载了一系列EnvironmentPostProcessor后置处理器中的一个。这里DEFAULT_SEARCH_LOCATIONS体现了配置文件加载顺序。 1234567891011121314151617181920212223242526272829303132public class ConfigFileApplicationListener implements EnvironmentPostProcessor, SmartApplicationListener, Ordered &#123; private static final String DEFAULT_SEARCH_LOCATIONS = \"classpath:/,classpath:/config/,file:./,file:./config/*/,file:./config/\"; private static final String DEFAULT_PROPERTIES = \"defaultProperties\"; private static final String DEFAULT_NAMES = \"application\"; public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ApplicationEnvironmentPreparedEvent) &#123; onApplicationEnvironmentPreparedEvent((ApplicationEnvironmentPreparedEvent) event); &#125; if (event instanceof ApplicationPreparedEvent) &#123; onApplicationPreparedEvent(event); &#125; &#125; private void onApplicationEnvironmentPreparedEvent(ApplicationEnvironmentPreparedEvent event) &#123; List&lt;EnvironmentPostProcessor&gt; postProcessors = loadPostProcessors(); postProcessors.add(this); AnnotationAwareOrderComparator.sort(postProcessors); for (EnvironmentPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessEnvironment(event.getEnvironment(), event.getSpringApplication()); &#125; &#125; List&lt;EnvironmentPostProcessor&gt; loadPostProcessors() &#123; // 加载spring.factories配置文件中以EnvironmentPostProcessor为key配置的类 return SpringFactoriesLoader.loadFactories(EnvironmentPostProcessor.class, getClass().getClassLoader()); &#125; public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) &#123; addPropertySources(environment, application.getResourceLoader()); &#125; protected void addPropertySources(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; RandomValuePropertySource.addToEnvironment(environment); new Loader(environment, resourceLoader).load(); // 最终通过该处去加载配置文件 &#125;&#125; ConfigFileApplicationListener也实现了EnvironmentPostProcessor故最终会执行其postProcessEnvironment方法最终通过Loader类来加载配置文件。构造方法中会加载PropertySourceLoader，主要是PropertiesPropertySourceLoader和YamlPropertySourceLoader 12345678private class Loader &#123; Loader(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; this.environment = environment; this.placeholdersResolver = new PropertySourcesPlaceholdersResolver(this.environment); this.resourceLoader = (resourceLoader != null) ? resourceLoader : new DefaultResourceLoader(null); this.propertySourceLoaders = SpringFactoriesLoader.loadFactories(PropertySourceLoader.class, getClass().getClassLoader()); &#125;&#125; 1234# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\\org.springframework.boot.env.PropertiesPropertySourceLoader,\\org.springframework.boot.env.YamlPropertySourceLoader 最终调用load方法来加载配置文件，首先获取需要遍历的目录，其实就是将DEFAULT_SEARCH_LOCATIONS中的目录拆分成数组，并进行反序，若为Cloud项目会在BootstrapApplicationListener中添加MapPropertySource配置，从而会获取spring.config.name设置的值，默认是bootstrap，故默认会先加载各个目录下的bootstrap配置文件。然后再加载application配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061void load() &#123; FilteredPropertySource.apply(this.environment, DEFAULT_PROPERTIES, LOAD_FILTERED_PROPERTY, (defaultProperties) -&gt; &#123; this.profiles = new LinkedList&lt;&gt;(); this.processedProfiles = new LinkedList&lt;&gt;(); this.activatedProfiles = false; this.loaded = new LinkedHashMap&lt;&gt;(); initializeProfiles(); while (!this.profiles.isEmpty()) &#123; Profile profile = this.profiles.poll(); if (isDefaultProfile(profile)) &#123; addProfileToEnvironment(profile.getName()); &#125; load(profile, this::getPositiveProfileFilter, addToLoaded(MutablePropertySources::addLast, false)); this.processedProfiles.add(profile); &#125; load(null, this::getNegativeProfileFilter, addToLoaded(MutablePropertySources::addFirst, true)); addLoadedPropertySources(); applyActiveProfiles(defaultProperties); &#125;);&#125;class FilteredPropertySource extends PropertySource&lt;PropertySource&lt;?&gt;&gt; &#123; static void apply(ConfigurableEnvironment environment, String propertySourceName, Set&lt;String&gt; filteredProperties, Consumer&lt;PropertySource&lt;?&gt;&gt; operation) &#123; MutablePropertySources propertySources = environment.getPropertySources(); PropertySource&lt;?&gt; original = propertySources.get(propertySourceName); if (original == null) &#123; operation.accept(null); return; &#125; propertySources.replace(propertySourceName, new FilteredPropertySource(original, filteredProperties)); try &#123; operation.accept(original); &#125; finally &#123; propertySources.replace(propertySourceName, original); &#125; &#125;&#125;private void load(Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; getSearchLocations().forEach((location) -&gt; &#123; boolean isDirectory = location.endsWith(\"/\"); Set&lt;String&gt; names = isDirectory ? getSearchNames() : NO_SEARCH_NAMES; names.forEach((name) -&gt; load(location, name, profile, filterFactory, consumer)); &#125;);&#125;private Set&lt;String&gt; getSearchLocations() &#123; Set&lt;String&gt; locations = getSearchLocations(CONFIG_ADDITIONAL_LOCATION_PROPERTY); if (this.environment.containsProperty(CONFIG_LOCATION_PROPERTY)) &#123; locations.addAll(getSearchLocations(CONFIG_LOCATION_PROPERTY)); &#125; else &#123; // 将DEFAULT_SEARCH_LOCATIONS中的目录拆分成数组，并进行反序 locations.addAll(asResolvedSet(ConfigFileApplicationListener.this.searchLocations, DEFAULT_SEARCH_LOCATIONS)); &#125; return locations;&#125;private Set&lt;String&gt; getSearchNames() &#123; if (this.environment.containsProperty(CONFIG_NAME_PROPERTY)) &#123; String property = this.environment.getProperty(CONFIG_NAME_PROPERTY); Set&lt;String&gt; names = asResolvedSet(property, null); names.forEach(this::assertValidConfigName); return names; &#125; return asResolvedSet(ConfigFileApplicationListener.this.names, DEFAULT_NAMES);&#125; 遍历propertySourceLoaders依次通过PropertiesPropertySourceLoader和YamlPropertySourceLoader去加载解析配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private void load(String location, String name, Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; if (!StringUtils.hasText(name)) &#123; for (PropertySourceLoader loader : this.propertySourceLoaders) &#123; if (canLoadFileExtension(loader, location)) &#123; load(loader, location, profile, filterFactory.getDocumentFilter(profile), consumer); return; &#125; &#125; throw new IllegalStateException(\"File extension of config file location '\" + location + \"' is not known to any PropertySourceLoader. If the location is meant to reference \" + \"a directory, it must end in '/'\"); &#125; Set&lt;String&gt; processed = new HashSet&lt;&gt;(); for (PropertySourceLoader loader : this.propertySourceLoaders) &#123; for (String fileExtension : loader.getFileExtensions()) &#123; if (processed.add(fileExtension)) &#123; loadForFileExtension(loader, location + name, \".\" + fileExtension, profile, filterFactory, consumer); &#125; &#125; &#125;&#125;private void loadForFileExtension(PropertySourceLoader loader, String prefix, String fileExtension, Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; DocumentFilter defaultFilter = filterFactory.getDocumentFilter(null); DocumentFilter profileFilter = filterFactory.getDocumentFilter(profile); if (profile != null) &#123; // 若设置了环境则加载对应环境的配置文件 String profileSpecificFile = prefix + \"-\" + profile + fileExtension; load(loader, profileSpecificFile, profile, defaultFilter, consumer); load(loader, profileSpecificFile, profile, profileFilter, consumer); for (Profile processedProfile : this.processedProfiles) &#123; if (processedProfile != null) &#123; String previouslyLoaded = prefix + \"-\" + processedProfile + fileExtension; load(loader, previouslyLoaded, profile, profileFilter, consumer); &#125; &#125; &#125; load(loader, prefix + fileExtension, profile, profileFilter, consumer);&#125;private void load(PropertySourceLoader loader, String location, Profile profile, DocumentFilter filter, DocumentConsumer consumer) &#123; Resource[] resources = getResources(location); for (Resource resource : resources) &#123; try &#123; if (resource == null || !resource.exists()) &#123; continue; &#125; if (!StringUtils.hasText(StringUtils.getFilenameExtension(resource.getFilename()))) &#123; continue; &#125; String name = \"applicationConfig: [\" + getLocationName(location, resource) + \"]\"; List&lt;Document&gt; documents = loadDocuments(loader, name, resource); if (CollectionUtils.isEmpty(documents)) &#123; continue; &#125; List&lt;Document&gt; loaded = new ArrayList&lt;&gt;(); for (Document document : documents) &#123; if (filter.match(document)) &#123; addActiveProfiles(document.getActiveProfiles()); addIncludedProfiles(document.getIncludeProfiles()); loaded.add(document); &#125; &#125; Collections.reverse(loaded); if (!loaded.isEmpty()) &#123; loaded.forEach((document) -&gt; consumer.accept(profile, document)); &#125; &#125; catch (Exception ex) &#123; StringBuilder description = getDescription(\"Failed to load property source from \", location, resource, profile); throw new IllegalStateException(description.toString(), ex); &#125; &#125;&#125;private List&lt;Document&gt; loadDocuments(PropertySourceLoader loader, String name, Resource resource) throws IOException &#123; DocumentsCacheKey cacheKey = new DocumentsCacheKey(loader, resource); List&lt;Document&gt; documents = this.loadDocumentsCache.get(cacheKey); if (documents == null) &#123; // 调用具体的PropertySourceLoader去加载解析配置文件 List&lt;PropertySource&lt;?&gt;&gt; loaded = loader.load(name, resource); documents = asDocuments(loaded); this.loadDocumentsCache.put(cacheKey, documents); &#125; return documents;&#125; 若是在Spring Cloud项目中会通过ApplicationListener加载BootstrapApplicationListener，在该监听器中的bootstrapServiceContext方法中添加了MapPropertySource配置，将spring.config.name值设置为configName，configName默认值为bootstrap。 1234org.springframework.context.ApplicationListener=\\org.springframework.cloud.bootstrap.BootstrapApplicationListener,\\org.springframework.cloud.bootstrap.LoggingSystemShutdownListener,\\org.springframework.cloud.context.restart.RestartListener 12345678910111213141516171819202122232425public class BootstrapApplicationListener implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt;, Ordered &#123; public static final String BOOTSTRAP_PROPERTY_SOURCE_NAME = \"bootstrap\"; public void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) &#123; ConfigurableEnvironment environment = event.getEnvironment(); if (!environment.getProperty(\"spring.cloud.bootstrap.enabled\", Boolean.class, true)) &#123; return; &#125; if (environment.getPropertySources().contains(BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; return; &#125; ConfigurableApplicationContext context = null; // 很明显configName默认值为bootstrap String configName = environment.resolvePlaceholders(\"$&#123;spring.cloud.bootstrap.name:bootstrap&#125;\"); for (ApplicationContextInitializer&lt;?&gt; initializer : event.getSpringApplication().getInitializers()) &#123; if (initializer instanceof ParentContextApplicationContextInitializer) &#123; context = findBootstrapContext((ParentContextApplicationContextInitializer) initializer, configName); &#125; &#125; if (context == null) &#123; context = bootstrapServiceContext(environment, event.getSpringApplication(), configName); event.getSpringApplication().addListeners(new CloseContextOnFailureApplicationListener(context)); &#125; apply(context, event.getSpringApplication(), environment); &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yaoyinglong.github.io/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://yaoyinglong.github.io/categories/Spring/SpringBoot/"}]},{"title":"Nacos集群CP模式","date":"2021-10-24T16:00:00.000Z","path":"Blog/Cloud/Nacos/Nacos集群CP模式/","text":"在RaftPeerSet组件初始化时，会将所有集群成员遍历初始化成RaftPeer，即完成peers初始化以及将ready设置为true。 123456789101112131415161718192021222324252627public class RaftPeerSet extends MemberChangeListener implements Closeable &#123; @PostConstruct public void init() &#123; NotifyCenter.registerSubscriber(this); // 注册当前RaftPeerSet为MemberChangeEvent事件的订阅者 changePeers(memberManager.allMembers()); // 传入所有服务端成员初始化peers &#125; protected void changePeers(Collection&lt;Member&gt; members) &#123; Map&lt;String, RaftPeer&gt; tmpPeers = new HashMap&lt;&gt;(members.size()); for (Member member : members) &#123; final String address = member.getAddress(); if (peers.containsKey(address)) &#123; // 若已包含则获取原来的设置到tmpPeers中 tmpPeers.put(address, peers.get(address)); continue; &#125; RaftPeer raftPeer = new RaftPeer(); // 若不存在则创建一个RaftPeer raftPeer.ip = address; // 初始化ip为当前成员的地址 // first time meet the local server: if (EnvUtil.getLocalAddress().equals(address)) &#123; raftPeer.term.set(localTerm.get()); // 若当前成员为本机则设置周期term，localTerm起始为0 &#125; tmpPeers.put(address, raftPeer); &#125; peers = tmpPeers; // replace raft peer set: ready = true; Loggers.RAFT.info(\"raft peers changed: \" + members); &#125;&#125; Leader选举在RaftCore初始化时会首先从文件中加载持久化的节点数据，然后从{nacos_home}\\data\\naming\\meta.properties文件中加载选举周期，然后添加每500ms定期执行集群leader选举的MasterElection任务和集群节点心跳检测的HeartBeat任务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class RaftCore implements Closeable &#123; @PostConstruct public void init() throws Exception &#123; final long start = System.currentTimeMillis(); raftStore.loadDatums(notifier, datums); // 加载持久化数据 setTerm(NumberUtils.toLong(raftStore.loadMeta().getProperty(\"term\"), 0L)); // 加载&#123;nacos_home&#125;\\data\\naming\\meta.properties文件中的周期 initialized = true; masterTask = GlobalExecutor.registerMasterElection(new MasterElection()); // 定期执行集群leader选举的MasterElection任务 heartbeatTask = GlobalExecutor.registerHeartbeat(new HeartBeat()); // 定时执行集群节点心跳检测的HeartBeat任务 versionJudgement.registerObserver(isAllNewVersion -&gt; &#123; stopWork = isAllNewVersion; if (stopWork) &#123; try &#123; shutdown(); raftListener.removeOldRaftMetadata(); &#125; catch (NacosException e) &#123; throw new NacosRuntimeException(NacosException.SERVER_ERROR, e); &#125; &#125; &#125;, 100); NotifyCenter.registerSubscriber(notifier); // 注册PersistentNotifier订阅者 &#125; public synchronized void loadDatums(PersistentNotifier notifier, Map&lt;String, Datum&gt; datums) throws Exception &#123; Datum datum; long start = System.currentTimeMillis(); for (File cache : listCaches()) &#123; if (cache.isDirectory() &amp;&amp; cache.listFiles() != null) &#123; for (File datumFile : cache.listFiles()) &#123; datum = readDatum(datumFile, cache.getName()); // 读取文件中缓存的数据 if (datum != null) &#123; datums.put(datum.key, datum); if (notifier != null) &#123; // 通知PersistentNotifier订阅者 NotifyCenter.publishEvent(ValueChangeEvent.builder().key(datum.key).action(DataOperation.CHANGE).build()); &#125; &#125; &#125; continue; &#125; datum = readDatum(cache, StringUtils.EMPTY); if (datum != null) &#123; datums.put(datum.key, datum); &#125; &#125; &#125;&#125; 虽然MasterElection选举任务是每500ms执行一次，但会对leaderDueMs初始时默认从0到15s随机一个时间，然后每500ms执行时减去500ms直到leaderDueMs小于0，然后将leaderDueMs重置为15s + 0到5s的随机时间即15s - 20s，且将heartbeatDueMs重置为5s，然后发起集群leader投票。 第一个被唤醒的节点，将重置leader为null，且将所有节点RaftPeer的选票voteFor置为null，然后先将选票投给自己，然后给其它服务端成员的/raft/vote接口发送投票数据，最后回收投票信息，计算并决定哪个节点是leader节点。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class MasterElection implements Runnable &#123; @Override public void run() &#123; try &#123; if (stopWork) &#123; return; &#125; if (!peers.isReady()) &#123; // RaftPeerSet初始化方法中changePeers完成peers初始化将ready置为true return; &#125; RaftPeer local = peers.local(); // 获取本机对应的RaftPeer local.leaderDueMs -= GlobalExecutor.TICK_PERIOD_MS; // leaderDueMs默认是从0到15s随机一个时间，减去500ms if (local.leaderDueMs &gt; 0) &#123; // 若leaderDueMs&gt;0继续等待下次执行 return; &#125; local.resetLeaderDue(); // 将leaderDueMs重置为15s + (0到5秒的随机时间) = 15s - 20s local.resetHeartbeatDue(); // 将heartbeatDueMs重置为5s sendVote(); // 发起集群leader投票 &#125; catch (Exception e) &#123; &#125; &#125; private void sendVote() &#123; RaftPeer local = peers.get(NetUtils.localServer()); // 获取本机对应的RaftPeer peers.reset(); // 将leader和所有的RaftPeer的voteFor字段置null local.term.incrementAndGet(); // 将本机选举周期加一 local.voteFor = local.ip; // 将本机的voteFor设置为本机IP local.state = RaftPeer.State.CANDIDATE; // 将本机状态由FOLLOWER变更为CANDIDATE状态 Map&lt;String, String&gt; params = new HashMap&lt;&gt;(1); params.put(\"vote\", JacksonUtils.toJson(local)); for (final String server : peers.allServersWithoutMySelf()) &#123; // 给所有其他成员发送投票请求 final String url = buildUrl(server, API_VOTE); // 目标服务成员的/raft/vote接口 try &#123; HttpClient.asyncHttpPost(url, null, params, new Callback&lt;String&gt;() &#123; @Override public void onReceive(RestResult&lt;String&gt; result) &#123; if (!result.ok()) &#123; return; &#125; RaftPeer peer = JacksonUtils.toObj(result.getData(), RaftPeer.class); peers.decideLeader(peer); // 计算并决定哪个节点是领导者，若有新的peer超过半数投票，则将leader更换为新peer &#125; &#125;); &#125; catch (Exception e) &#123; &#125; &#125; &#125;&#125; 当收到响应的投票信息后遍历所有节点统计投票结果，并记录被选举次数最多的节点和次数，若某个节点票数超过一半，则将该节点置为leader节点，并发布选举结果事件，在RaftListener中更新本机对应节点的数据。 123456789101112131415161718192021222324252627public class RaftPeerSet extends MemberChangeListener implements Closeable &#123; public RaftPeer decideLeader(RaftPeer candidate) &#123; peers.put(candidate.ip, candidate); SortedBag ips = new TreeBag(); int maxApproveCount = 0; String maxApprovePeer = null; for (RaftPeer peer : peers.values()) &#123; // 遍历所有节点，若voteFor不为null，则将节点的voteFor添加到ips中，并记录被选举次数最多的节点和次数 if (StringUtils.isEmpty(peer.voteFor)) &#123; continue; // 若投票结果为null则直接跳过 &#125; ips.add(peer.voteFor); // 将投票添加到ips中 if (ips.getCount(peer.voteFor) &gt; maxApproveCount) &#123; maxApproveCount = ips.getCount(peer.voteFor); maxApprovePeer = peer.voteFor; &#125; &#125; if (maxApproveCount &gt;= majorityCount()) &#123; // 若票数超过一半 RaftPeer peer = peers.get(maxApprovePeer); // 获取出该节点 peer.state = RaftPeer.State.LEADER; // 将该节点状态设置为leader节点 if (!Objects.equals(leader, peer)) &#123; leader = peer; // 若leader节点不是该节点，将leader节点设置为该节点 ApplicationUtils.publishEvent(new LeaderElectFinishedEvent(this, leader, local())); // 发布选举结果事件，RaftListener &#125; &#125; return leader; &#125;&#125; 当其它成员接收到投票信息后，若remote节点的选举周期小于或等于本机节点的选举周期，且本机的选票为空，则将选票投给自己，本机选票不为空则直接返回已投出的选票。若remote节点选举周期大于本机节点选举周期则将选票投给remote节点，并将本机的选举周期设置为remote节点的选举周期。 1234567891011121314151617181920212223242526272829303132public class RaftController &#123; @PostMapping(\"/vote\") public JsonNode vote(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (versionJudgement.allMemberIsNewVersion()) &#123; throw new IllegalStateException(\"old raft protocol already stop\"); &#125; RaftPeer peer = raftCore.receivedVote(JacksonUtils.toObj(WebUtils.required(request, \"vote\"), RaftPeer.class)); return JacksonUtils.transferToJsonNode(peer); &#125;&#125;public class RaftCore implements Closeable &#123; public synchronized RaftPeer receivedVote(RaftPeer remote) &#123; if (stopWork) &#123; throw new IllegalStateException(\"old raft protocol already stop work\"); &#125; if (!peers.contains(remote)) &#123; throw new IllegalStateException(\"can not find peer: \" + remote.ip); &#125; RaftPeer local = peers.get(NetUtils.localServer()); if (remote.term.get() &lt;= local.term.get()) &#123; // 若remote节点的选举周期小于或等于本机节点的选举周期 if (StringUtils.isEmpty(local.voteFor)) &#123; local.voteFor = local.ip; // 若本机的选票为空，则将选票投给自己 &#125; return local; &#125; local.resetLeaderDue(); // 将leaderDueMs重置为15s + (0到5秒的随机时间) = 15s - 20s local.state = RaftPeer.State.FOLLOWER; // 将本机节点状态置为FOLLOWER local.voteFor = remote.ip; // 将本机的选票投给remote节点 local.term.set(remote.term.get()); // 将本机的选举周期设置为remote节点的选举周期 return local; &#125;&#125; 心跳检查虽然HeartBeat是每500ms执行一次，但跟MasterElection选举任务一样，其内部进行了逻辑处理，第一次是从0到5s随机一个时间后开始执行，后续是每5s执行一次，若Leader没有被选举出来也不会发送心跳包。且当leader被选举出来后，每一次执行心跳检查时都将leaderDueMs重置为15s + 0到5s的随机时间即15s - 20s，leaderDueMs大于heartbeatDueMs，从而保证了选举不会重复执行。由于只有leader节点能往其它成员节点发送心跳，且其它成员节点收到心跳数据后会重置leaderDueMs时间，若leader节点挂掉了，则其他节点的leaderDueMs是不能被重置的，则会再次发起投票选举新的leader。 进行心跳检测时会将本节点即leader节点上的所有数据的key以及本节点对应的RaftPeer数据通过Gzip压缩后发送给其它所有从节点的/raft/beat接口，从节点会检查其数据是否为最新的数据，若不是会调用leader的/raft/datum接口拉取最新数据进行更新。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class HeartBeat implements Runnable &#123; @Override public void run() &#123; try &#123; if (stopWork) &#123; return; &#125; if (!peers.isReady()) &#123; // RaftPeerSet初始化方法中changePeers完成peers初始化将ready置为true return; &#125; RaftPeer local = peers.local(); // 获取本机对应的RaftPeer local.heartbeatDueMs -= GlobalExecutor.TICK_PERIOD_MS; // heartbeatDueMs默认是从0到5s随机一个时间，减去500ms if (local.heartbeatDueMs &gt; 0) &#123; // 若leaderDueMs&gt;0继续等待下次执行 return; &#125; local.resetHeartbeatDue(); // 将heartbeatDueMs重置为5s sendBeat(); &#125; catch (Exception e) &#123; &#125; &#125; private void sendBeat() throws IOException, InterruptedException &#123; RaftPeer local = peers.local(); if (EnvUtil.getStandaloneMode() || local.state != RaftPeer.State.LEADER) &#123; return; // 若是Standalone模式启动或本机不是leader则不发送心跳检查，若Leader没有选出来也不会发送 &#125; local.resetLeaderDue(); // 将leaderDueMs重置为15s + (0到5秒的随机时间) = 15s - 20s ObjectNode packet = JacksonUtils.createEmptyJsonNode(); // build data packet.replace(\"peer\", JacksonUtils.transferToJsonNode(local)); ArrayNode array = JacksonUtils.createEmptyArrayNode(); if (!switchDomain.isSendBeatOnly()) &#123; // 不仅仅只发送心跳包 for (Datum datum : datums.values()) &#123; // 将KEY和对应的版本放入element中，最终添加到array中 ObjectNode element = JacksonUtils.createEmptyJsonNode(); if (KeyBuilder.matchServiceMetaKey(datum.key)) &#123; // key以com.alibaba.nacos.naming.domains.meta.或meta.开头 element.put(\"key\", KeyBuilder.briefServiceMetaKey(datum.key)); &#125; else if (KeyBuilder.matchInstanceListKey(datum.key)) &#123; // key以com.alibaba.nacos.naming.iplist.或iplist.开头 element.put(\"key\", KeyBuilder.briefInstanceListkey(datum.key)); &#125; element.put(\"timestamp\", datum.timestamp.get()); array.add(element); &#125; &#125; packet.replace(\"datums\", array); // 将array放入数据包 Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(1); // broadcast params.put(\"beat\", JacksonUtils.toJson(packet)); String content = JacksonUtils.toJson(params); ByteArrayOutputStream out = new ByteArrayOutputStream(); // 使用GZIP将数据进行压缩 GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(content.getBytes(StandardCharsets.UTF_8)); gzip.close(); byte[] compressedBytes = out.toByteArray(); String compressedContent = new String(compressedBytes, StandardCharsets.UTF_8); for (final String server : peers.allServersWithoutMySelf()) &#123; // 遍历每一个从节点（除开自己，自己是leader） try &#123; final String url = buildUrl(server, API_BEAT); // 调用从节点的/raft/beat接口发送心跳数据 HttpClient.asyncHttpPostLarge(url, null, compressedBytes, new Callback&lt;String&gt;() &#123; @Override public void onReceive(RestResult&lt;String&gt; result) &#123; if (!result.ok()) &#123; // 若发送失败 MetricsMonitor.getLeaderSendBeatFailedException().increment(); return; &#125; peers.update(JacksonUtils.toObj(result.getData(), RaftPeer.class)); // 更新对应IP的RaftPeer &#125; &#125;); &#125; catch (Exception e) &#123; MetricsMonitor.getLeaderSendBeatFailedException().increment(); &#125; &#125; &#125;&#125; 当其它成员接收到心跳数据后，首先会对leader信息进行校验，判断发送心跳的节点是否是leader节点，以及当前节点的选举周期是大于leader节点的选举周期，若是一次收到心跳，还会将设置其voteFor为leader的ip，然后通过RaftPeerSet#makeLeader方法更新本节点上leader信息。 然后遍历心跳发送过来的数据，若收到的key在本节点上没有，或本节点上该数据版本小于或等于收到的版本，将其放入List然后调用/raft/datum接口批量从Leader中拉取最新的数据，然后将其写入磁盘文件中并覆盖datums中的数据，更新本节点的选举周期。最后对于未覆盖到的key，说明已被删除，将其从datums中删除且将磁盘文件也删除。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236public class RaftController &#123; @PostMapping(\"/beat\") public JsonNode beat(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (versionJudgement.allMemberIsNewVersion()) &#123; throw new IllegalStateException(\"old raft protocol already stop\"); &#125; String entity = new String(IoUtils.tryDecompress(request.getInputStream()), StandardCharsets.UTF_8); // Gzip解压 String value = URLDecoder.decode(entity, \"UTF-8\"); value = URLDecoder.decode(value, \"UTF-8\"); JsonNode json = JacksonUtils.toObj(value); RaftPeer peer = raftCore.receivedBeat(JacksonUtils.toObj(json.get(\"beat\").asText())); return JacksonUtils.transferToJsonNode(peer); &#125;&#125;public class RaftCore implements Closeable &#123; public RaftPeer receivedBeat(JsonNode beat) throws Exception &#123; if (stopWork) &#123; throw new IllegalStateException(\"old raft protocol already stop work\"); &#125; final RaftPeer local = peers.local(); final RaftPeer remote = new RaftPeer(); JsonNode peer = beat.get(\"peer\"); // 存放的leader的RaftPeer数据 remote.ip = peer.get(\"ip\").asText(); // leader的ip remote.state = RaftPeer.State.valueOf(peer.get(\"state\").asText()); // leader的state remote.term.set(peer.get(\"term\").asLong()); // leader的选举周期 remote.heartbeatDueMs = peer.get(\"heartbeatDueMs\").asLong(); remote.leaderDueMs = peer.get(\"leaderDueMs\").asLong(); remote.voteFor = peer.get(\"voteFor\").asText(); if (remote.state != RaftPeer.State.LEADER) &#123; // 若接收到的不是leader发送的心跳数据直接抛出异常 throw new IllegalArgumentException(\"invalid state from master, state: \" + remote.state); &#125; if (local.term.get() &gt; remote.term.get()) &#123; // 若本机的选举周期大于leader节点的选举周期直接抛出异常 throw new IllegalArgumentException(\"out of date beat, beat-from-term: \" + remote.term.get() + \", beat-to-term: \" + local.term.get()); &#125; if (local.state != RaftPeer.State.FOLLOWER) &#123; // 若本机的状态不是FOLLOWER，则将其置为FOLLOWER并将选票投给当前的leader节点 local.state = RaftPeer.State.FOLLOWER; // mk follower local.voteFor = remote.ip; &#125; final JsonNode beatDatums = beat.get(\"datums\"); local.resetLeaderDue(); // 将leaderDueMs重置为15s + (0到5秒的随机时间) = 15s - 20s local.resetHeartbeatDue(); // 将heartbeatDueMs重置为5s peers.makeLeader(remote); // 更新leader信息，将remote设置为新leader，更新原有leader的节点信息 if (!switchDomain.isSendBeatOnly()) &#123; Map&lt;String, Integer&gt; receivedKeysMap = new HashMap&lt;&gt;(datums.size()); for (Map.Entry&lt;String, Datum&gt; entry : datums.entrySet()) &#123; receivedKeysMap.put(entry.getKey(), 0); // 将当前节点的可以放到一个map中，value都置为0 &#125; List&lt;String&gt; batch = new ArrayList&lt;&gt;(); // now check datums int processedCount = 0; for (Object object : beatDatums) &#123; // 遍历心跳数据 processedCount = processedCount + 1; JsonNode entry = (JsonNode) object; String key = entry.get(\"key\").asText(); final String datumKey; if (KeyBuilder.matchServiceMetaKey(key)) &#123; // key以com.alibaba.nacos.naming.domains.meta.或meta.开头 datumKey = KeyBuilder.detailServiceMetaKey(key); &#125; else if (KeyBuilder.matchInstanceListKey(key)) &#123; // key以com.alibaba.nacos.naming.iplist.或iplist.开头 datumKey = KeyBuilder.detailInstanceListkey(key); &#125; else &#123; continue; // ignore corrupted key: &#125; long timestamp = entry.get(\"timestamp\").asLong(); receivedKeysMap.put(datumKey, 1); // 将心跳数据覆盖receivedKeysMap中的数据，且其值置为1 try &#123; if (datums.containsKey(datumKey) &amp;&amp; datums.get(datumKey).timestamp.get() &gt;= timestamp &amp;&amp; processedCount &lt; beatDatums.size()) &#123; continue; // 若收到的心跳数据在本地存在，且本地的版本大于等于收到的版本，且还有数据未处理完，则直接continue跳过 &#125; if (!(datums.containsKey(datumKey) &amp;&amp; datums.get(datumKey).timestamp.get() &gt;= timestamp)) &#123; batch.add(datumKey); // 若收到的key在本地没有，或本地版本小于收到的版本，放入批量处理 &#125; if (batch.size() &lt; 50 &amp;&amp; processedCount &lt; beatDatums.size()) &#123; continue; // 只有batch的数量超过50或接收的数据已处理完毕，才进行获取数据操作 &#125; String keys = StringUtils.join(batch, \",\"); if (batch.size() &lt;= 0) &#123; // 若没有数据需要处理直接跳过 continue; &#125; String url = buildUrl(remote.ip, API_GET); // 调用leader的/raft/datum接口获取最新数据 Map&lt;String, String&gt; queryParam = new HashMap&lt;&gt;(1); queryParam.put(\"keys\", URLEncoder.encode(keys, \"UTF-8\")); HttpClient.asyncHttpGet(url, null, queryParam, new Callback&lt;String&gt;() &#123; // 批量从leader节点获取keys对应的数据更新到本地 @Override public void onReceive(RestResult&lt;String&gt; result) &#123; if (!result.ok()) &#123; return; &#125; List&lt;JsonNode&gt; datumList = JacksonUtils.toObj(result.getData(), new TypeReference&lt;List&lt;JsonNode&gt;&gt;() &#123; &#125;); for (JsonNode datumJson : datumList) &#123; // 保证集群节点间的数据最终一致性 Datum newDatum = null; OPERATE_LOCK.lock(); try &#123; Datum oldDatum = getDatum(datumJson.get(\"key\").asText()); // 或去当前机器上的旧的数据 if (oldDatum != null &amp;&amp; datumJson.get(\"timestamp\").asLong() &lt;= oldDatum.timestamp.get()) &#123; continue; // 若旧数据不为null且旧数据的版本大于或等于新数据的版本，则不需要更新直接跳过 &#125; if (KeyBuilder.matchServiceMetaKey(datumJson.get(\"key\").asText())) &#123; // key以com.alibaba.nacos.naming.domains.meta.或meta.开头 Datum&lt;Service&gt; serviceDatum = new Datum&lt;&gt;(); serviceDatum.key = datumJson.get(\"key\").asText(); serviceDatum.timestamp.set(datumJson.get(\"timestamp\").asLong()); serviceDatum.value = JacksonUtils.toObj(datumJson.get(\"value\").toString(), Service.class); newDatum = serviceDatum; &#125; if (KeyBuilder.matchInstanceListKey(datumJson.get(\"key\").asText())) &#123; // key以com.alibaba.nacos.naming.iplist.或iplist.开头 Datum&lt;Instances&gt; instancesDatum = new Datum&lt;&gt;(); instancesDatum.key = datumJson.get(\"key\").asText(); instancesDatum.timestamp.set(datumJson.get(\"timestamp\").asLong()); instancesDatum.value = JacksonUtils.toObj(datumJson.get(\"value\").toString(), Instances.class); newDatum = instancesDatum; &#125; if (newDatum == null || newDatum.value == null) &#123; continue; // 跳过空数据 &#125; raftStore.write(newDatum); // 将数据写入磁盘缓存中 datums.put(newDatum.key, newDatum); // 将新的数据添加到缓存中 notifier.notify(newDatum.key, DataOperation.CHANGE, newDatum.value); // 更新注册表中的数据 local.resetLeaderDue(); // 将leaderDueMs重置为15s + (0到5秒的随机时间) = 15s - 20s if (local.term.get() + 100 &gt; remote.term.get()) &#123; // 若本地的选举周期加100大于leader节点的选举周期 getLeader().term.set(remote.term.get()); // 将同步leader节点的选举周期 local.term.set(getLeader().term.get()); // 将本地节点的选举周期也置为leader节点的周期 &#125; else &#123; local.term.addAndGet(100); // 将本地节点的选举周期加100 &#125; raftStore.updateTerm(local.term.get()); // 更新本地缓存文件meta.properties中的选举周期 &#125; catch (Throwable e) &#123; &#125; finally &#123; OPERATE_LOCK.unlock(); &#125; &#125; try &#123; TimeUnit.MILLISECONDS.sleep(200); &#125; catch (InterruptedException e) &#123; &#125; return; &#125; @Override public void onError(Throwable throwable) &#123; &#125; @Override public void onCancel() &#123; &#125; &#125;); batch.clear(); &#125; catch (Exception e) &#123; &#125; &#125; List&lt;String&gt; deadKeys = new ArrayList&lt;&gt;(); for (Map.Entry&lt;String, Integer&gt; entry : receivedKeysMap.entrySet()) &#123; if (entry.getValue() == 0) &#123; // 未被覆盖的key，说明是已经被删除的数据 deadKeys.add(entry.getKey()); &#125; &#125; for (String deadKey : deadKeys) &#123; try &#123; deleteDatum(deadKey); // 删除数据以及清理key对应的缓存文件 &#125; catch (Exception e) &#123; &#125; &#125; &#125; return local; &#125; private void deleteDatum(String key) &#123; Datum deleted; try &#123; deleted = datums.remove(URLDecoder.decode(key, \"UTF-8\")); if (deleted != null) &#123; // 若key对应的数据未被删除 raftStore.delete(deleted); // 删除缓存数据文件 &#125; NotifyCenter.publishEvent(ValueChangeEvent.builder().key(URLDecoder.decode(key, \"UTF-8\")).action(DataOperation.DELETE).build()); &#125; catch (UnsupportedEncodingException e) &#123; &#125; &#125;&#125;public class RaftPeerSet extends MemberChangeListener implements Closeable &#123; public RaftPeer makeLeader(RaftPeer candidate) &#123; // 更新leader信息，将remote设置为新leader，更新原有leader的节点信息 if (!Objects.equals(leader, candidate)) &#123; // 若leader不是candidate，则将leader设置为candidate leader = candidate; ApplicationUtils.publishEvent(new MakeLeaderEvent(this, leader, local())); // 调用RaftListener的onApplicationEvent方法响应事件 Loggers.RAFT.info(\"&#123;&#125; has become the LEADER, local: &#123;&#125;, leader: &#123;&#125;\", leader.ip, JacksonUtils.toJson(local()), JacksonUtils.toJson(leader)); &#125; for (final RaftPeer peer : peers.values()) &#123; Map&lt;String, String&gt; params = new HashMap&lt;&gt;(1); if (!Objects.equals(peer, candidate) &amp;&amp; peer.state == RaftPeer.State.LEADER) &#123; // 若存在纯在旧的leader，则将旧的leader信息更新 try &#123; String url = RaftCore.buildUrl(peer.ip, RaftCore.API_GET_PEER); // 调用成员的/raft/peer接口 HttpClient.asyncHttpGet(url, null, params, new Callback&lt;String&gt;() &#123; @Override public void onReceive(RestResult&lt;String&gt; result) &#123; if (!result.ok()) &#123; // 若请求失败则将其状态置为FOLLOWER Loggers.RAFT.error(\"[NACOS-RAFT] get peer failed: &#123;&#125;, peer: &#123;&#125;\", result.getCode(), peer.ip); peer.state = RaftPeer.State.FOLLOWER; return; &#125; update(JacksonUtils.toObj(result.getData(), RaftPeer.class)); // 更新当前peer的信息 &#125; @Override public void onError(Throwable throwable) &#123; &#125; @Override public void onCancel() &#123; &#125; &#125;); &#125; catch (Exception e) &#123; peer.state = RaftPeer.State.FOLLOWER; Loggers.RAFT.error(\"[NACOS-RAFT] error while getting peer from peer: &#123;&#125;\", peer.ip); &#125; &#125; &#125; return update(candidate); // 更新leader的信息 &#125; public RaftPeer update(RaftPeer peer) &#123; peers.put(peer.ip, peer); return peer; &#125;&#125;public class RaftController &#123; @GetMapping(\"/datum\") public String get(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (versionJudgement.allMemberIsNewVersion()) &#123; throw new IllegalStateException(\"old raft protocol already stop\"); &#125; response.setHeader(\"Content-Type\", \"application/json; charset=\" + getAcceptEncoding(request)); response.setHeader(\"Cache-Control\", \"no-cache\"); response.setHeader(\"Content-Encode\", \"gzip\"); String keysString = WebUtils.required(request, \"keys\"); keysString = URLDecoder.decode(keysString, \"UTF-8\"); String[] keys = keysString.split(\",\"); List&lt;Datum&gt; datums = new ArrayList&lt;Datum&gt;(); for (String key : keys) &#123; Datum datum = raftCore.getDatum(key); datums.add(datum); &#125; return JacksonUtils.toJson(datums); &#125;&#125; 实例注册与AP模式注册实例的区别在调用ConsistencyService#put方法时是调用RaftConsistencyServiceImpl或PersistentServiceProcessor的put方法。 12345678910public class RaftConsistencyServiceImpl implements PersistentConsistencyService &#123; public void put(String key, Record value) throws NacosException &#123; checkIsStopWork(); try &#123; raftCore.signalPublish(key, value); &#125; catch (Exception e) &#123; throw new NacosException(NacosException.SERVER_ERROR, \"Raft put failed, key:\" + key + \", value:\" + value, e); &#125; &#125;&#125; 若当前节点不是leader节点，会将请求转发给leader节点的/raft/datum接口，若当前节点是leader节点则首先将数据更新到缓存datums以及通过发布ValueChangeEvent事件，最终订阅者PersistentNotifier会收到该事件变更执行onEvent方法异步更新注册表，然后遍历调用从节点的/raft/datum/commit接口同步数据给其它从节点，且利用CountDownLatch实现一个简单的raft协议写入数据的逻辑，必须集群半数以上节点写入成功才会给客户端返回成功。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class RaftCore implements Closeable &#123; public void signalPublish(String key, Record value) throws Exception &#123; if (stopWork) &#123; throw new IllegalStateException(\"old raft protocol already stop work\"); &#125; if (!isLeader()) &#123; // 若本节点不是leader节点则将注册请求转发到集群的leader节点 ObjectNode params = JacksonUtils.createEmptyJsonNode(); params.put(\"key\", key); params.replace(\"value\", JacksonUtils.transferToJsonNode(value)); Map&lt;String, String&gt; parameters = new HashMap&lt;&gt;(1); parameters.put(\"key\", key); final RaftPeer leader = getLeader(); raftProxy.proxyPostLarge(leader.ip, API_PUB, params.toString(), parameters); // 将数据发送到leader节点的/raft/datum接口 return; &#125; OPERATE_LOCK.lock(); try &#123; final long start = System.currentTimeMillis(); final Datum datum = new Datum(); datum.key = key; datum.value = value; if (getDatum(key) == null) &#123; // 若key对应的数据不存在 datum.timestamp.set(1L); // 将更新版本设置为1 &#125; else &#123; // 若key已存在，则将已有版本加一 datum.timestamp.set(getDatum(key).timestamp.incrementAndGet()); &#125; ObjectNode json = JacksonUtils.createEmptyJsonNode(); json.replace(\"datum\", JacksonUtils.transferToJsonNode(datum)); // 需要更新的数据 json.replace(\"source\", JacksonUtils.transferToJsonNode(peers.local())); // leader节点信息 onPublish(datum, peers.local()); final String content = json.toString(); // 利用CountDownLatch实现一个简单的raft协议写入数据的逻辑，必须集群半数以上节点写入成功才会给客户端返回成功 final CountDownLatch latch = new CountDownLatch(peers.majorityCount()); for (final String server : peers.allServersIncludeMyself()) &#123; if (isLeader(server)) &#123; // 若是leader直接减一，因为上面已更新了数据 latch.countDown(); continue; &#125; final String url = buildUrl(server, API_ON_PUB); // 调用/raft/datum/commit接口同步数据给其他从节点 HttpClient.asyncHttpPostLarge(url, Arrays.asList(\"key\", key), content, new Callback&lt;String&gt;() &#123; @Override public void onReceive(RestResult&lt;String&gt; result) &#123; if (!result.ok()) &#123; return; &#125; latch.countDown(); &#125; &#125;); &#125; if (!latch.await(UtilsAndCommons.RAFT_PUBLISH_TIMEOUT, TimeUnit.MILLISECONDS)) &#123; throw new IllegalStateException(\"data publish failed, caused failed to notify majority, key=\" + key); &#125; &#125; finally &#123; OPERATE_LOCK.unlock(); &#125; &#125;&#125; 其它从节点收到leader节点发送的数据后调用RaftCore的onPublish方法将数据更新到本节点的缓存datums以及通过发布ValueChangeEvent事件，最终订阅者PersistentNotifier会收到该事件变更执行onEvent方法异步更新注册表。 123456789101112131415161718192021222324252627282930313233343536373839public class RaftController &#123; @PostMapping(\"/datum/commit\") public String onPublish(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (versionJudgement.allMemberIsNewVersion()) &#123; throw new IllegalStateException(\"old raft protocol already stop\"); &#125; response.setHeader(\"Content-Type\", \"application/json; charset=\" + getAcceptEncoding(request)); response.setHeader(\"Cache-Control\", \"no-cache\"); response.setHeader(\"Content-Encode\", \"gzip\"); String entity = IoUtils.toString(request.getInputStream(), \"UTF-8\"); String value = URLDecoder.decode(entity, \"UTF-8\"); JsonNode jsonObject = JacksonUtils.toObj(value); String key = \"key\"; RaftPeer source = JacksonUtils.toObj(jsonObject.get(\"source\").toString(), RaftPeer.class); JsonNode datumJson = jsonObject.get(\"datum\"); Datum datum = null; if (KeyBuilder.matchInstanceListKey(datumJson.get(key).asText())) &#123; datum = JacksonUtils.toObj(jsonObject.get(\"datum\").toString(), new TypeReference&lt;Datum&lt;Instances&gt;&gt;() &#123; &#125;); &#125; else if (KeyBuilder.matchSwitchKey(datumJson.get(key).asText())) &#123; datum = JacksonUtils.toObj(jsonObject.get(\"datum\").toString(), new TypeReference&lt;Datum&lt;SwitchDomain&gt;&gt;() &#123; &#125;); &#125; else if (KeyBuilder.matchServiceMetaKey(datumJson.get(key).asText())) &#123; datum = JacksonUtils.toObj(jsonObject.get(\"datum\").toString(), new TypeReference&lt;Datum&lt;Service&gt;&gt;() &#123; &#125;); &#125; raftConsistencyService.onPut(datum, source); return \"ok\"; &#125;&#125;public class RaftConsistencyServiceImpl implements PersistentConsistencyService &#123; public void onPut(Datum datum, RaftPeer source) throws NacosException &#123; try &#123; raftCore.onPublish(datum, source); &#125; catch (Exception e) &#123; throw new NacosException(NacosException.SERVER_ERROR, \"Raft onPut failed, datum:\" + datum + \", source: \" + source, e); &#125; &#125;&#125; 不仅从节点更新数据是调用的该方法，上面leader节点更新数据同样是通过该方法，首先校验source是否为leader节点，然后重置leaderDueMs，然后将数据写入磁盘，然后将数据更新到缓存datums中，然后更新选举周期以及将其写入磁盘文件meta.properties中，最后发布发布ValueChangeEvent事件异步更新注册表。 12345678910111213141516171819202122232425262728293031323334353637public class RaftCore implements Closeable &#123; public void onPublish(Datum datum, RaftPeer source) throws Exception &#123; if (stopWork) &#123; throw new IllegalStateException(\"old raft protocol already stop work\"); &#125; RaftPeer local = peers.local(); if (datum.value == null) &#123; // 若接收数据为null抛出异常 throw new IllegalStateException(\"received empty datum\"); &#125; if (!peers.isLeader(source.ip)) &#123; // 非leader节点这里直接抛出异常 throw new IllegalStateException(\"peer(\" + source.ip + \") tried to publish \" + \"data but wasn't leader\"); &#125; if (source.term.get() &lt; local.term.get()) &#123; // 若发布超时则直接抛出异常 throw new IllegalStateException(\"out of date publish, pub-term:\" + source.term.get() + \", cur-term: \" + local.term.get()); &#125; local.resetLeaderDue(); // 将leaderDueMs重置为15s + (0到5秒的随机时间) = 15s - 20s // if data should be persisted, usually this is true: if (KeyBuilder.matchPersistentKey(datum.key)) &#123; // 若key不是以com.alibaba.nacos.naming.iplist.ephemeral.开头的数据数据 raftStore.write(datum); // 同步写实例数据到文件 &#125; datums.put(datum.key, datum); // 更新缓存中的数据 if (isLeader()) &#123; // 若本机是leader节点 local.term.addAndGet(PUBLISH_TERM_INCREASE_COUNT); // 将leader的选举周期加100 &#125; else &#123; if (local.term.get() + PUBLISH_TERM_INCREASE_COUNT &gt; source.term.get()) &#123; //set leader term: getLeader().term.set(source.term.get()); local.term.set(getLeader().term.get()); &#125; else &#123; // 若本机不是的选举周期+100小于leader的选举周期 local.term.addAndGet(PUBLISH_TERM_INCREASE_COUNT); // 本机选举周期加100 &#125; &#125; raftStore.updateTerm(local.term.get()); // 更新缓存文件meta.properties中选举周期 // 最终订阅者PersistentNotifier会收到该事件变更执行onEvent方法异步更新注册表 NotifyCenter.publishEvent(ValueChangeEvent.builder().key(datum.key).action(DataOperation.CHANGE).build()); &#125;&#125; 在PersistentNotifier订阅者中最终还是调用Service的onChange方法将实例数据更新到注册表中。 1234567891011121314151617181920212223242526272829303132333435363738public final class PersistentNotifier extends Subscriber&lt;ValueChangeEvent&gt; &#123; public void onEvent(ValueChangeEvent event) &#123; notify(event.getKey(), event.getAction(), find.apply(event.getKey())); &#125; public &lt;T extends Record&gt; void notify(final String key, final DataOperation action, final T value) &#123; if (listenerMap.containsKey(KeyBuilder.SERVICE_META_KEY_PREFIX)) &#123; // key以com.alibaba.nacos.naming.domains.meta.或meta.开头但不以00-00---000-NACOS_SWITCH_DOMAIN-000---00-00结尾 if (KeyBuilder.matchServiceMetaKey(key) &amp;&amp; !KeyBuilder.matchSwitchKey(key)) &#123; for (RecordListener listener : listenerMap.get(KeyBuilder.SERVICE_META_KEY_PREFIX)) &#123; try &#123; if (action == DataOperation.CHANGE) &#123; listener.onChange(key, value); // 调用Service的onChange方法将实例数据更新到注册表中 &#125; if (action == DataOperation.DELETE) &#123; listener.onDelete(key); // Service总onDelete方法是空实现 &#125; &#125; catch (Throwable e) &#123; &#125; &#125; &#125; &#125; if (!listenerMap.containsKey(key)) &#123; return; &#125; for (RecordListener listener : listenerMap.get(key)) &#123; try &#123; if (action == DataOperation.CHANGE) &#123; listener.onChange(key, value); // 调用Service的onChange方法将实例数据更新到注册表中 continue; &#125; if (action == DataOperation.DELETE) &#123; listener.onDelete(key); // Service总onDelete方法是空实现 &#125; &#125; catch (Throwable e) &#123; &#125; &#125; &#125;&#125; 心跳检测对于CP模式服务实例的心跳的健康检查是通过HealthCheckTask来完成的，该任务是在Cluster初始化时注册的。 12345678910111213141516171819public class Service extends com.alibaba.nacos.api.naming.pojo.Service implements Record, RecordListener&lt;Instances&gt; &#123; public void init() &#123; HealthCheckReactor.scheduleCheck(clientBeatCheckTask); for (Map.Entry&lt;String, Cluster&gt; entry : clusterMap.entrySet()) &#123; entry.getValue().setService(this); entry.getValue().init(); &#125; &#125;&#125;public class Cluster extends com.alibaba.nacos.api.naming.pojo.Cluster implements Cloneable &#123; public void init() &#123; if (inited) &#123; return; &#125; checkTask = new HealthCheckTask(this); // 创建CP模式心跳监控检查任务 HealthCheckReactor.scheduleCheck(checkTask); inited = true; &#125;&#125; 和AP模式一样的健康检查一样，只注册在本机上的实例才执行健康检查，最终调用TcpSuperSenseProcessor的process方法。且执行完成后将再次将任务放入延时任务中。 123456789101112131415161718192021222324252627282930313233public class HealthCheckTask implements Runnable &#123; public HealthCheckTask(Cluster cluster) &#123; this.cluster = cluster; distroMapper = ApplicationUtils.getBean(DistroMapper.class); switchDomain = ApplicationUtils.getBean(SwitchDomain.class); healthCheckProcessor = ApplicationUtils.getBean(HealthCheckProcessorDelegate.class); initCheckRT(); &#125; private void initCheckRT() &#123; // 第一次健康检查的延迟时间，2000 + （0 ~ 5000）对0到5000进行了嵌套取随机数 checkRtNormalized = 2000 + RandomUtils.nextInt(0, RandomUtils.nextInt(0, switchDomain.getTcpHealthParams().getMax())); checkRtBest = Long.MAX_VALUE; checkRtWorst = 0L; &#125; public void run() &#123; try &#123; if (distroMapper.responsible(cluster.getService().getName()) &amp;&amp; switchDomain.isHealthCheckEnabled(cluster.getService().getName())) &#123; healthCheckProcessor.process(this); // 注册在本机上的实例，才执行健康检查，调用TcpSuperSenseProcessor的process方法 &#125; &#125; catch (Throwable e) &#123; &#125; finally &#123; if (!cancelled) &#123; HealthCheckReactor.scheduleCheck(this); if (this.getCheckRtWorst() &gt; 0 &amp;&amp; switchDomain.isHealthCheckEnabled(cluster.getService().getName()) &amp;&amp; distroMapper.responsible(cluster.getService().getName())) &#123; long diff = ((this.getCheckRtLast() - this.getCheckRtLastLast()) * 10000) / this.getCheckRtLastLast(); this.setCheckRtLastLast(this.getCheckRtLast()); Cluster cluster = this.getCluster(); &#125; &#125; &#125; &#125;&#125; 在process中会将任务封装为Beat，然后放入阻塞队列中，TcpSuperSenseProcessor本身就是一个线程类，其初始化时就会被启动，在run方法中调用processTask方法对阻塞队列消费，再将beat任务封装成TaskProcessor。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class TcpSuperSenseProcessor implements HealthCheckProcessor, Runnable &#123; private BlockingQueue&lt;Beat&gt; taskQueue = new LinkedBlockingQueue&lt;Beat&gt;(); public TcpSuperSenseProcessor() &#123; try &#123; selector = Selector.open(); GlobalExecutor.submitTcpCheck(this); &#125; catch (Exception e) &#123; throw new IllegalStateException(\"Error while initializing SuperSense(TM).\"); &#125; &#125; public void process(HealthCheckTask task) &#123; List&lt;Instance&gt; ips = task.getCluster().allIPs(false); // 获取所有持久化实例 if (CollectionUtils.isEmpty(ips)) &#123; return; // 若注册在本机上的持久化实例为null &#125; for (Instance ip : ips) &#123; if (ip.isMarked()) &#123; continue; &#125; if (!ip.markChecking()) &#123; healthCheckCommon.reEvaluateCheckRT(task.getCheckRtNormalized() * 2, task, switchDomain.getTcpHealthParams()); continue; &#125; Beat beat = new Beat(ip, task); taskQueue.add(beat); // 将需要进行监控检查的服务放入阻塞对列中 MetricsMonitor.getTcpHealthCheckMonitor().incrementAndGet(); &#125; &#125; private void processTask() throws Exception &#123; Collection&lt;Callable&lt;Void&gt;&gt; tasks = new LinkedList&lt;&gt;(); do &#123; Beat beat = taskQueue.poll(CONNECT_TIMEOUT_MS / 2, TimeUnit.MILLISECONDS); if (beat == null) &#123; return; &#125; tasks.add(new TaskProcessor(beat)); &#125; while (taskQueue.size() &gt; 0 &amp;&amp; tasks.size() &lt; NIO_THREAD_COUNT * 64); for (Future&lt;?&gt; f : GlobalExecutor.invokeAllTcpSuperSenseTask(tasks)) &#123; f.get(); &#125; &#125; public void run() &#123; while (true) &#123; try &#123; processTask(); int readyCount = selector.selectNow(); if (readyCount &lt;= 0) &#123; continue; &#125; Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); GlobalExecutor.executeTcpSuperSense(new PostProcessor(key)); &#125; &#125; catch (Throwable e) &#123; &#125; &#125; &#125;&#125; 最终再通过PostProcessor、TaskProcessor、TimeOutTask等异步任务发送TCP请求来完成健康检查。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public class PostProcessor implements Runnable &#123; public void run() &#123; Beat beat = (Beat) key.attachment(); SocketChannel channel = (SocketChannel) key.channel(); try &#123; if (!beat.isHealthy()) &#123; //invalid beat means this server is no longer responsible for the current service key.cancel(); key.channel().close(); beat.finishCheck(); return; &#125; if (key.isValid() &amp;&amp; key.isConnectable()) &#123; channel.finishConnect(); beat.finishCheck(true, false, System.currentTimeMillis() - beat.getTask().getStartTime(), \"tcp:ok+\"); &#125; if (key.isValid() &amp;&amp; key.isReadable()) &#123; ByteBuffer buffer = ByteBuffer.allocate(128); if (channel.read(buffer) == -1) &#123; key.cancel(); key.channel().close(); &#125; &#125; &#125; catch (ConnectException e) &#123; beat.finishCheck(false, true, switchDomain.getTcpHealthParams().getMax(), \"tcp:unable2connect:\" + e.getMessage()); &#125; catch (Exception e) &#123; beat.finishCheck(false, false, switchDomain.getTcpHealthParams().getMax(), \"tcp:error:\" + e.getMessage()); try &#123; key.cancel(); key.channel().close(); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125;&#125;private class TaskProcessor implements Callable&lt;Void&gt; &#123; public Void call() &#123; long waited = System.currentTimeMillis() - beat.getStartTime(); if (waited &gt; MAX_WAIT_TIME_MILLISECONDS) &#123; Loggers.SRV_LOG.warn(\"beat task waited too long: \" + waited + \"ms\"); &#125; SocketChannel channel = null; try &#123; Instance instance = beat.getIp(); BeatKey beatKey = keyMap.get(beat.toString()); if (beatKey != null &amp;&amp; beatKey.key.isValid()) &#123; if (System.currentTimeMillis() - beatKey.birthTime &lt; TCP_KEEP_ALIVE_MILLIS) &#123; instance.setBeingChecked(false); return null; &#125; beatKey.key.cancel(); beatKey.key.channel().close(); &#125; channel = SocketChannel.open(); channel.configureBlocking(false); // only by setting this can we make the socket close event asynchronous channel.socket().setSoLinger(false, -1); channel.socket().setReuseAddress(true); channel.socket().setKeepAlive(true); channel.socket().setTcpNoDelay(true); Cluster cluster = beat.getTask().getCluster(); int port = cluster.isUseIPPort4Check() ? instance.getPort() : cluster.getDefCkport(); channel.connect(new InetSocketAddress(instance.getIp(), port)); SelectionKey key = channel.register(selector, SelectionKey.OP_CONNECT | SelectionKey.OP_READ); key.attach(beat); keyMap.put(beat.toString(), new BeatKey(key)); beat.setStartTime(System.currentTimeMillis()); GlobalExecutor.scheduleTcpSuperSenseTask(new TimeOutTask(key), CONNECT_TIMEOUT_MS, TimeUnit.MILLISECONDS); &#125; catch (Exception e) &#123; beat.finishCheck(false, false, switchDomain.getTcpHealthParams().getMax(), \"tcp:error:\" + e.getMessage()); if (channel != null) &#123; try &#123; channel.close(); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125; return null; &#125;&#125;private static class TimeOutTask implements Runnable &#123; public void run() &#123; if (key != null &amp;&amp; key.isValid()) &#123; SocketChannel channel = (SocketChannel) key.channel(); Beat beat = (Beat) key.attachment(); if (channel.isConnected()) &#123; return; &#125; try &#123; channel.finishConnect(); &#125; catch (Exception ignore) &#123; &#125; try &#123; beat.finishCheck(false, false, beat.getTask().getCheckRtNormalized() * 2, \"tcp:timeout\"); key.cancel(); key.channel().close(); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125;&#125; 最终调用Beat的finishCheck方法更新实例的健康状态。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263private class Beat &#123; public void finishCheck(boolean success, boolean now, long rt, String msg) &#123; ip.setCheckRt(System.currentTimeMillis() - startTime); if (success) &#123; healthCheckCommon.checkOK(ip, task, msg); &#125; else &#123; if (now) &#123; healthCheckCommon.checkFailNow(ip, task, msg); &#125; else &#123; healthCheckCommon.checkFail(ip, task, msg); &#125; keyMap.remove(task.toString()); &#125; healthCheckCommon.reEvaluateCheckRT(rt, task, switchDomain.getTcpHealthParams()); &#125;&#125;public class HealthCheckCommon &#123; public void checkOK(Instance ip, HealthCheckTask task, String msg) &#123; Cluster cluster = task.getCluster(); try &#123; if (!ip.isHealthy() || !ip.isMockValid()) &#123; if (ip.getOkCount().incrementAndGet() &gt;= switchDomain.getCheckTimes()) &#123; if (distroMapper.responsible(cluster, ip)) &#123; ip.setHealthy(true); ip.setMockValid(true); Service service = cluster.getService(); service.setLastModifiedMillis(System.currentTimeMillis()); pushService.serviceChanged(service); addResult(new HealthCheckResult(service.getName(), ip)); &#125; else &#123; if (!ip.isMockValid()) &#123; ip.setMockValid(true); &#125; &#125; &#125; &#125; &#125; catch (Throwable t) &#123; &#125; ip.getFailCount().set(0); ip.setBeingChecked(false); &#125; public void checkFail(Instance ip, HealthCheckTask task, String msg) &#123; Cluster cluster = task.getCluster(); try &#123; if (ip.isHealthy() || ip.isMockValid()) &#123; if (ip.getFailCount().incrementAndGet() &gt;= switchDomain.getCheckTimes()) &#123; if (distroMapper.responsible(cluster, ip)) &#123; ip.setHealthy(false); ip.setMockValid(false); Service service = cluster.getService(); service.setLastModifiedMillis(System.currentTimeMillis()); addResult(new HealthCheckResult(service.getName(), ip)); pushService.serviceChanged(service); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; &#125; ip.getOkCount().set(0); ip.setBeingChecked(false); &#125;&#125;","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://yaoyinglong.github.io/tags/Nacos/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Nacos","slug":"Cloud/Nacos","permalink":"https://yaoyinglong.github.io/categories/Cloud/Nacos/"}]},{"title":"Nacos集群注册服务同步","date":"2021-10-21T16:00:00.000Z","path":"Blog/Cloud/Nacos/Nacos集群注册服务同步/","text":"服务注册同步客户端在调用服务端接口注册实例时，会调用ConsistencyService#put方法将实例对象添加到注册表，以及同步给其它服务端成员。注册服务的同步是通过调用DistroProtocol的sync同步方法来完成的，然后调用NacosDelayTaskExecuteEngine的addTask方法将同步任务添加到ConcurrentHashMap中。 1234567891011121314151617public class DistroConsistencyServiceImpl implements EphemeralConsistencyService, DistroDataProcessor &#123; public void put(String key, Record value) throws NacosException &#123; onPut(key, value); // 若是ephemeral实例将其添加到DataStore缓存中，然后通过一部任务替换注册表中实例列表 // 同步实例数据到其它服务端成员列表中，是将当前服务名称下所有实例同步到其他服务端，最终是通过异步任务加队列的方式，调用HTTP接口最终在其他服务上也是通过onPut方法来完成 distroProtocol.sync(new DistroKey(key, KeyBuilder.INSTANCE_LIST_KEY_PREFIX), DataOperation.CHANGE, globalConfig.getTaskDispatchPeriod() / 2); &#125;&#125;public class DistroProtocol &#123; public void sync(DistroKey distroKey, DataOperation action, long delay) &#123; // delay默认值为1000 for (Member each : memberManager.allMembersWithoutSelf()) &#123; // 遍历每个除自己以外的其它成员 // DistroKey的resourceKey对应的是DataStore中dataMap的key用于获取缓存Service信息的Datum DistroKey distroKeyWithTarget = new DistroKey(distroKey.getResourceKey(), distroKey.getResourceType(), each.getAddress()); DistroDelayTask distroDelayTask = new DistroDelayTask(distroKeyWithTarget, action, delay); distroTaskEngineHolder.getDelayTaskExecuteEngine().addTask(distroKeyWithTarget, distroDelayTask); &#125; &#125;&#125; NacosDelayTaskExecuteEngine初始化时向延时线程池中添加了一个延时任务ProcessRunnable，该任务每100ms执行一次调用processTasks将添加到ConcurrentHashMap中的任务取出调用NacosTaskProcessor#process方法进行同步操作。addTask时若已存在同步任务，则调用DistroDelayTask#merge方法进行任务合并，其实就是替换为最新任务的action和createTime。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class NacosDelayTaskExecuteEngine extends AbstractNacosTaskExecuteEngine&lt;AbstractDelayTask&gt; &#123; protected final ConcurrentHashMap&lt;Object, AbstractDelayTask&gt; tasks; // 在DistroDelayTaskExecuteEngine中实例化是代用该构造函数实例化 public NacosDelayTaskExecuteEngine(String name, Logger logger) &#123; this(name, 32, logger, 100L); &#125; public NacosDelayTaskExecuteEngine(String name, int initCapacity, Logger logger, long processInterval) &#123; super(logger); tasks = new ConcurrentHashMap&lt;Object, AbstractDelayTask&gt;(initCapacity); processingExecutor = ExecutorFactory.newSingleScheduledExecutorService(new NameThreadFactory(name)); processingExecutor.scheduleWithFixedDelay(new ProcessRunnable(), processInterval, processInterval, TimeUnit.MILLISECONDS); &#125; public void addTask(Object key, AbstractDelayTask newTask) &#123; lock.lock(); try &#123; AbstractDelayTask existTask = tasks.get(key); if (null != existTask) &#123; newTask.merge(existTask); // 若同步任务已存在，则合并同步任务 &#125; tasks.put(key, newTask); &#125; finally &#123; lock.unlock(); &#125; &#125; protected void processTasks() &#123; Collection&lt;Object&gt; keys = getAllTaskKeys(); for (Object taskKey : keys) &#123; AbstractDelayTask task = removeTask(taskKey); if (null == task) &#123; continue; &#125; NacosTaskProcessor processor = getProcessor(taskKey); if (null == processor) &#123; getEngineLog().error(\"processor not found for task, so discarded. \" + task); continue; &#125; try &#123; if (!processor.process(task)) &#123; retryFailedTask(taskKey, task); // ReAdd task if process failed &#125; &#125; catch (Throwable e) &#123; getEngineLog().error(\"Nacos task execute error : \" + e.toString(), e); retryFailedTask(taskKey, task); &#125; &#125; &#125; private class ProcessRunnable implements Runnable &#123; @Override public void run() &#123; // 100毫秒执行一次 try &#123; processTasks(); &#125; catch (Throwable e) &#123; getEngineLog().error(e.toString(), e); &#125; &#125; &#125;&#125;public class DistroDelayTask extends AbstractDelayTask &#123; public void merge(AbstractDelayTask task) &#123; if (!(task instanceof DistroDelayTask)) &#123; return; &#125; DistroDelayTask newTask = (DistroDelayTask) task; if (!action.equals(newTask.getAction()) &amp;&amp; createTime &lt; newTask.getCreateTime()) &#123; action = newTask.getAction(); createTime = newTask.getCreateTime(); &#125; setLastProcessTime(newTask.getLastProcessTime()); &#125;&#125; 具体NacosTaskProcessor是在DistroTaskEngineHolder中实例化DistroDelayTaskExecuteEngine时设置了默认的DistroDelayTaskProcessor，以及在DistroHttpRegistry中添加了具体的KeyBuilder.INSTANCE_LIST_KEY_PREFIX的DistroHttpDelayTaskProcessor。 123456789101112131415161718192021public class DistroTaskEngineHolder &#123; private final DistroDelayTaskExecuteEngine delayTaskExecuteEngine = new DistroDelayTaskExecuteEngine(); private final DistroExecuteTaskExecuteEngine executeWorkersManager = new DistroExecuteTaskExecuteEngine(); public DistroTaskEngineHolder(DistroComponentHolder distroComponentHolder) &#123; DistroDelayTaskProcessor defaultDelayTaskProcessor = new DistroDelayTaskProcessor(this, distroComponentHolder); delayTaskExecuteEngine.setDefaultTaskProcessor(defaultDelayTaskProcessor); &#125; public void registerNacosTaskProcessor(Object key, NacosTaskProcessor nacosTaskProcessor) &#123; this.delayTaskExecuteEngine.addProcessor(key, nacosTaskProcessor); &#125;&#125;public class DistroHttpRegistry &#123; @PostConstruct public void doRegister() &#123; componentHolder.registerDataStorage(KeyBuilder.INSTANCE_LIST_KEY_PREFIX, new DistroDataStorageImpl(dataStore, distroMapper)); componentHolder.registerTransportAgent(KeyBuilder.INSTANCE_LIST_KEY_PREFIX, new DistroHttpAgent(memberManager)); componentHolder.registerFailedTaskHandler(KeyBuilder.INSTANCE_LIST_KEY_PREFIX, new DistroHttpCombinedKeyTaskFailedHandler(globalConfig, taskEngineHolder)); taskEngineHolder.registerNacosTaskProcessor(KeyBuilder.INSTANCE_LIST_KEY_PREFIX, new DistroHttpDelayTaskProcessor(globalConfig, taskEngineHolder)); componentHolder.registerDataProcessor(consistencyService); &#125;&#125; 很明显NacosTaskProcessor#process具体执行的是DistroHttpDelayTaskProcessor#process，上面DistroTaskEngineHolder中实例化了DistroExecuteTaskExecuteEngine，最终调用其父类NacosExecuteTaskExecuteEngine#addTask方法。 12345678910public class DistroHttpDelayTaskProcessor implements NacosTaskProcessor &#123; private final DistroTaskEngineHolder distroTaskEngineHolder; public boolean process(NacosTask task) &#123; DistroDelayTask distroDelayTask = (DistroDelayTask) task; DistroKey distroKey = distroDelayTask.getDistroKey(); DistroHttpCombinedKeyExecuteTask executeTask = new DistroHttpCombinedKeyExecuteTask(globalConfig, distroTaskEngineHolder.getDelayTaskExecuteEngine(), distroKey, distroDelayTask.getAction()); distroTaskEngineHolder.getExecuteWorkersManager().addTask(distroKey, executeTask); return true; &#125;&#125; 调用TaskExecuteWorker#process将DistroHttpCombinedKeyExecuteTask添加到阻塞队列中，TaskExecuteWorker实例化时创建并启动了InnerWorker线程，该线程对阻塞队列消费取出DistroDelayTask并执行其run方法。1234567891011121314151617181920212223242526272829303132333435363738394041424344public class NacosExecuteTaskExecuteEngine extends AbstractNacosTaskExecuteEngine&lt;AbstractExecuteTask&gt; &#123; public void addTask(Object tag, AbstractExecuteTask task) &#123; NacosTaskProcessor processor = getProcessor(tag); if (null != processor) &#123; processor.process(task); return; &#125; TaskExecuteWorker worker = getWorker(tag); worker.process(task); &#125;&#125;public final class TaskExecuteWorker implements NacosTaskProcessor, Closeable &#123; private final BlockingQueue&lt;Runnable&gt; queue; public TaskExecuteWorker(final String name, final int mod, final int total, final Logger logger) &#123; this.name = name + \"_\" + mod + \"%\" + total; this.queue = new ArrayBlockingQueue&lt;Runnable&gt;(QUEUE_CAPACITY); this.closed = new AtomicBoolean(false); new InnerWorker(name).start(); &#125; public boolean process(NacosTask task) &#123; if (task instanceof AbstractExecuteTask) &#123; putTask((Runnable) task); // 将任务添加到阻塞对列中 &#125; return true; &#125; private void putTask(Runnable task) &#123; try &#123; queue.put(task); // 该对列最终通过InnerWorker类消费 &#125; catch (InterruptedException ire) &#123; &#125; &#125; private class InnerWorker extends Thread &#123; @Override public void run() &#123; while (!closed.get()) &#123; try &#123; Runnable task = queue.take(); task.run(); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; &#125;&#125; 最终会将任务封装成DistroHttpCombinedKeyDelayTask，并重新生成一个DistroKey，其实就是再一次执行了上面的入队操作，然后调用DistroDelayTaskProcessor#process方法，最终调用DistroSyncChangeTask#run方法。 1234567891011121314151617181920212223242526272829303132333435363738394041public class DistroHttpCombinedKeyExecuteTask extends AbstractExecuteTask &#123; public void run() &#123; try &#123; DistroKey newKey = new DistroKey(DistroHttpCombinedKey.getSequenceKey(), DistroHttpCombinedKeyDelayTask.class.getSimpleName(), singleDistroKey.getTargetServer()); DistroHttpCombinedKeyDelayTask combinedTask = new DistroHttpCombinedKeyDelayTask(newKey, taskAction, globalConfig.getTaskDispatchPeriod() / 2, globalConfig.getBatchSyncKeyCount()); combinedTask.getActualResourceKeys().add(singleDistroKey.getResourceKey()); distroDelayTaskExecuteEngine.addTask(newKey, combinedTask); &#125; catch (Exception e) &#123; &#125; &#125;&#125;public class DistroDelayTaskProcessor implements NacosTaskProcessor &#123; public boolean process(NacosTask task) &#123; if (!(task instanceof DistroDelayTask)) &#123; return true; &#125; DistroDelayTask distroDelayTask = (DistroDelayTask) task; DistroKey distroKey = distroDelayTask.getDistroKey(); if (DataOperation.CHANGE.equals(distroDelayTask.getAction())) &#123; DistroSyncChangeTask syncChangeTask = new DistroSyncChangeTask(distroKey, distroComponentHolder); distroTaskEngineHolder.getExecuteWorkersManager().addTask(distroKey, syncChangeTask); return true; &#125; return false; &#125;&#125;public class DistroSyncChangeTask extends AbstractDistroExecuteTask &#123; public void run() &#123; // 最终客户端服务同步是通过该线程来完成的 try &#123; String type = getDistroKey().getResourceType(); DistroData distroData = distroComponentHolder.findDataStorage(type).getDistroData(getDistroKey()); distroData.setType(DataOperation.CHANGE); // DistroData其实就是序列化好的Datum boolean result = distroComponentHolder.findTransportAgent(type).syncData(distroData, getDistroKey().getTargetServer()); if (!result) &#123; handleFailedTask(); // 失败重试 &#125; &#125; catch (Exception e) &#123; handleFailedTask(); &#125; &#125;&#125; 最终通过调用HTTP接口/v1/ns/distro/datum来实现数据的同步，这里是直接将整个serviceName对应的实例数据列表全部进行了同步。 12345678910111213141516171819202122232425262728293031public class DistroHttpAgent implements DistroTransportAgent &#123; public boolean syncData(DistroData data, String targetServer) &#123; if (!memberManager.hasMember(targetServer)) &#123; return true; // 若不存在该成员，则直接跳过 &#125; byte[] dataContent = data.getContent(); return NamingProxy.syncData(dataContent, data.getDistroKey().getTargetServer()); &#125;&#125;public class NamingProxy &#123; public static boolean syncData(byte[] data, String curServer) &#123; // 调用/v1/ns/distro/datum接口即DistroController#onSyncDatum Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(128); headers.put(HttpHeaderConsts.CLIENT_VERSION_HEADER, VersionUtils.version); headers.put(HttpHeaderConsts.USER_AGENT_HEADER, UtilsAndCommons.SERVER_VERSION); headers.put(HttpHeaderConsts.ACCEPT_ENCODING, \"gzip,deflate,sdch\"); headers.put(HttpHeaderConsts.CONNECTION, \"Keep-Alive\"); headers.put(HttpHeaderConsts.CONTENT_ENCODING, \"gzip\"); try &#123; RestResult&lt;String&gt; result = HttpClient.httpPutLarge(\"http://\" + curServer + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + DATA_ON_SYNC_URL, headers, data); if (result.ok()) &#123; return true; &#125; if (HttpURLConnection.HTTP_NOT_MODIFIED == result.getCode()) &#123; return true; &#125; throw new IOException(\"failed to req API:\" + \"http://\" + curServer + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + DATA_ON_SYNC_URL + \". code:\" + result.getCode() + \" msg: \" + result.getData()); &#125; catch (Exception e) &#123; &#125; return false; &#125;&#125; 在其他成员的HTTP接口接收到数据后进行遍历将Datum中的数据通过onPut方法将数据设置到自身的DataStore中，以及更新到注册表中。 123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping(UtilsAndCommons.NACOS_NAMING_CONTEXT + \"/distro\")public class DistroController &#123; @PutMapping(\"/datum\") public ResponseEntity onSyncDatum(@RequestBody Map&lt;String, Datum&lt;Instances&gt;&gt; dataMap) throws Exception &#123; if (dataMap.isEmpty()) &#123; Loggers.DISTRO.error(\"[onSync] receive empty entity!\"); throw new NacosException(NacosException.INVALID_PARAM, \"receive empty entity!\"); &#125; for (Map.Entry&lt;String, Datum&lt;Instances&gt;&gt; entry : dataMap.entrySet()) &#123; if (KeyBuilder.matchEphemeralInstanceListKey(entry.getKey())) &#123; String namespaceId = KeyBuilder.getNamespace(entry.getKey()); String serviceName = KeyBuilder.getServiceName(entry.getKey()); if (!serviceManager.containService(namespaceId, serviceName) &amp;&amp; switchDomain.isDefaultInstanceEphemeral()) &#123; serviceManager.createEmptyService(namespaceId, serviceName, true); &#125; DistroHttpData distroHttpData = new DistroHttpData(createDistroKey(entry.getKey()), entry.getValue()); distroProtocol.onReceive(distroHttpData); &#125; &#125; return ResponseEntity.ok(\"ok\"); &#125;&#125;public class DistroProtocol &#123; public boolean onReceive(DistroData distroData) &#123; String resourceType = distroData.getDistroKey().getResourceType(); DistroDataProcessor dataProcessor = distroComponentHolder.findDataProcessor(resourceType); if (null == dataProcessor) &#123; Loggers.DISTRO.warn(\"[DISTRO] Can't find data process for received data &#123;&#125;\", resourceType); return false; &#125; return dataProcessor.processData(distroData); &#125;&#125;public class DistroConsistencyServiceImpl implements EphemeralConsistencyService, DistroDataProcessor &#123; public boolean processData(DistroData distroData) &#123; DistroHttpData distroHttpData = (DistroHttpData) distroData; Datum&lt;Instances&gt; datum = (Datum&lt;Instances&gt;) distroHttpData.getDeserializedContent(); onPut(datum.key, datum.value); return true; &#125;&#125; 服务启动同步在服务启动时会去其它成员服务中同步注册的实例数据，通过DistroProtocol实例化时通过startLoadTask方法将同步任务封装成DistroLoadDataTask对象异步来完成。 123456789101112131415161718192021222324252627282930public class DistroProtocol &#123; public DistroProtocol(ServerMemberManager memberManager, DistroComponentHolder distroComponentHolder, DistroTaskEngineHolder distroTaskEngineHolder, DistroConfig distroConfig) &#123; this.memberManager = memberManager; this.distroComponentHolder = distroComponentHolder; this.distroTaskEngineHolder = distroTaskEngineHolder; this.distroConfig = distroConfig; startDistroTask(); &#125; private void startDistroTask() &#123; if (EnvUtil.getStandaloneMode()) &#123; isInitialized = true; return; &#125; startVerifyTask(); // 注册的客户端服务校验5s后开始，每5s执行一次 startLoadTask(); // 注册的客户端服务数据同步 &#125; private void startLoadTask() &#123; DistroCallback loadCallback = new DistroCallback() &#123; @Override public void onSuccess() &#123; isInitialized = true; &#125; @Override public void onFailed(Throwable throwable) &#123; isInitialized = false; &#125; &#125;; GlobalExecutor.submitLoadDataTask(new DistroLoadDataTask(memberManager, distroComponentHolder, distroConfig, loadCallback)); &#125;&#125; 若数据加载失败会再次将任务放入线程池中延时30s后再重试同步任务，通过调用目标成员的HTTP接口获取目标成员中全量的注册服务数据。并解析更新到缓存和注册表中，只要有一个成员更新成功则退出循环。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class DistroLoadDataTask implements Runnable &#123; public void run() &#123; try &#123; load(); // 加载数据 if (!checkCompleted()) &#123; // 若数据加载失败则重试 GlobalExecutor.submitLoadDataTask(this, distroConfig.getLoadDataRetryDelayMillis()); &#125; else &#123; loadCallback.onSuccess(); // 加载成功将isInitialized设置为true &#125; &#125; catch (Exception e) &#123; loadCallback.onFailed(e); // 异常将isInitialized设置为false &#125; &#125; private void load() throws Exception &#123; while (memberManager.allMembersWithoutSelf().isEmpty()) &#123; // 等待成员数据加载完成 TimeUnit.SECONDS.sleep(1); &#125; while (distroComponentHolder.getDataStorageTypes().isEmpty()) &#123; // 等待缓存实例加载完成 TimeUnit.SECONDS.sleep(1); &#125; for (String each : distroComponentHolder.getDataStorageTypes()) &#123; if (!loadCompletedMap.containsKey(each) || !loadCompletedMap.get(each)) &#123; loadCompletedMap.put(each, loadAllDataSnapshotFromRemote(each)); // 从其他服务端成员加载数据镜像 &#125; &#125; &#125; private boolean loadAllDataSnapshotFromRemote(String resourceType) &#123; DistroTransportAgent transportAgent = distroComponentHolder.findTransportAgent(resourceType); DistroDataProcessor dataProcessor = distroComponentHolder.findDataProcessor(resourceType); if (null == transportAgent || null == dataProcessor) &#123; return false; &#125; for (Member each : memberManager.allMembersWithoutSelf()) &#123; // 遍历除自己以外的所有其它服务端成员 try &#123; DistroData distroData = transportAgent.getDatumSnapshot(each.getAddress()); // 通过HTTP接口获取目标成员中的注册服务数据 boolean result = dataProcessor.processSnapshot(distroData); // 解析数据并更新到缓存和注册表中 if (result) &#123; return true; // 只要有一个成功则退出循环 &#125; &#125; catch (Exception e) &#123; &#125; &#125; return false; &#125; private boolean checkCompleted() &#123; if (distroComponentHolder.getDataStorageTypes().size() != loadCompletedMap.size()) &#123; return false; &#125; for (Boolean each : loadCompletedMap.values()) &#123; if (!each) &#123; return false; &#125; &#125; return true; &#125;&#125; 最终通过DistroHttpAgent调用NamingProxy#getAllData方法从而调用目标成员的/v1/ns/distro/datums接口即DistroController#getAllDatums获取数据列表。 1234567891011121314151617181920public class DistroHttpAgent implements DistroTransportAgent &#123; public DistroData getDatumSnapshot(String targetServer) &#123; // 通过HTTP接口获取目标成员中的注册服务数据 try &#123; byte[] allDatum = NamingProxy.getAllData(targetServer); return new DistroData(new DistroKey(\"snapshot\", KeyBuilder.INSTANCE_LIST_KEY_PREFIX), allDatum); &#125; catch (Exception e) &#123; throw new DistroException(String.format(\"Get snapshot from %s failed.\", targetServer), e); &#125; &#125;&#125;public class NamingProxy &#123; public static byte[] getAllData(String server) throws Exception &#123; // 调用目标成员的HTTP接口/v1/ns/distro/datums获取数据列表 Map&lt;String, String&gt; params = new HashMap&lt;&gt;(8); RestResult&lt;String&gt; result = HttpClient.httpGet(\"http://\" + server + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + ALL_DATA_GET_URL, new ArrayList&lt;&gt;(), params); if (result.ok()) &#123; return result.getData().getBytes(); &#125; throw new IOException(\"failed to req API: \" + \"http://\" + server + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + ALL_DATA_GET_URL + \". code: \" + result.getCode() + \" msg: \" + result.getMessage()); &#125;&#125; 其它成员接收到请求后，直接从DataStore缓存中获取到数据进行序列化后返回。 1234567891011121314151617181920212223242526@RestController@RequestMapping(UtilsAndCommons.NACOS_NAMING_CONTEXT + \"/distro\")public class DistroController &#123; @GetMapping(\"/datums\") public ResponseEntity getAllDatums() &#123; DistroData distroData = distroProtocol.onSnapshot(KeyBuilder.INSTANCE_LIST_KEY_PREFIX); return ResponseEntity.ok(distroData.getContent()); &#125;&#125;public class DistroProtocol &#123; public DistroData onSnapshot(String type) &#123; DistroDataStorage distroDataStorage = distroComponentHolder.findDataStorage(type); if (null == distroDataStorage) &#123; return new DistroData(new DistroKey(\"snapshot\", type), new byte[0]); &#125; return distroDataStorage.getDatumSnapshot(); &#125;&#125;public class DistroDataStorageImpl implements DistroDataStorage &#123; public DistroData getDatumSnapshot() &#123; Map&lt;String, Datum&gt; result = dataStore.getDataMap(); byte[] dataContent = ApplicationUtils.getBean(Serializer.class).serialize(result); DistroKey distroKey = new DistroKey(\"snapshot\", KeyBuilder.INSTANCE_LIST_KEY_PREFIX); return new DistroData(distroKey, dataContent); &#125;&#125; 对于ephemeral为true的实例数据，会首先直接添加到缓存中，然后判断若当前没有则创建添加更新到注册表中，对于ephemeral为false的实例数据，若不存在则跳过，若存在则更新注册表数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class DistroConsistencyServiceImpl implements EphemeralConsistencyService, DistroDataProcessor &#123; public boolean processSnapshot(DistroData distroData) &#123; try &#123; return processData(distroData.getContent()); &#125; catch (Exception e) &#123; return false; &#125; &#125; private boolean processData(byte[] data) throws Exception &#123; if (data.length &gt; 0) &#123; Map&lt;String, Datum&lt;Instances&gt;&gt; datumMap = serializer.deserializeMap(data, Instances.class); // 反序列化 for (Map.Entry&lt;String, Datum&lt;Instances&gt;&gt; entry : datumMap.entrySet()) &#123; dataStore.put(entry.getKey(), entry.getValue()); // 替换缓存中的数据 if (!listeners.containsKey(entry.getKey())) &#123; // 若serviceList中不包含该数据则创建一个并更新到注册表中 // pretty sure the service not exist: if (switchDomain.isDefaultInstanceEphemeral()) &#123; // ephemeral为true的实例，默认为true // create empty service Loggers.DISTRO.info(\"creating service &#123;&#125;\", entry.getKey()); Service service = new Service(); String serviceName = KeyBuilder.getServiceName(entry.getKey()); String namespaceId = KeyBuilder.getNamespace(entry.getKey()); service.setName(serviceName); service.setNamespaceId(namespaceId); service.setGroupName(Constants.DEFAULT_GROUP); // now validate the service. if failed, exception will be thrown service.setLastModifiedMillis(System.currentTimeMillis()); service.recalculateChecksum(); // The Listener corresponding to the key value must not be empty RecordListener listener = listeners.get(KeyBuilder.SERVICE_META_KEY_PREFIX).peek(); if (Objects.isNull(listener)) &#123; return false; &#125; listener.onChange(KeyBuilder.buildServiceMetaKey(namespaceId, serviceName), service); // 更新注册表数据 &#125; &#125; &#125; for (Map.Entry&lt;String, Datum&lt;Instances&gt;&gt; entry : datumMap.entrySet()) &#123; // 处理ephemeral为false的实例 if (!listeners.containsKey(entry.getKey())) &#123;// Should not happen: 若实例不存在则直接跳过 Loggers.DISTRO.warn(\"listener of &#123;&#125; not found.\", entry.getKey()); continue; &#125; try &#123; for (RecordListener listener : listeners.get(entry.getKey())) &#123; listener.onChange(entry.getKey(), entry.getValue().value); // 更新注册表数据 &#125; &#125; catch (Exception e) &#123; continue; &#125; dataStore.put(entry.getKey(), entry.getValue()); // 更新缓存中的数据 &#125; &#125; return true; &#125;&#125; 服务状态定时同步注册的实例数据的定时同步是通过DistroProtocol构造方法中startDistroTask中调用startVerifyTask将同步任务封装成DistroVerifyTask添加到周期定时执行线程中。 12345public class DistroProtocol &#123; private void startVerifyTask() &#123; GlobalExecutor.schedulePartitionDataTimedSync(new DistroVerifyTask(memberManager, distroComponentHolder), distroConfig.getVerifyIntervalMillis()); &#125;&#125; 首先会获取注册在本机上的所有客户端注册数据计算的checksum放入列表中封装成DistroKey，然后将该数据发送到每一个服务端成员进行校验。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class DistroVerifyTask implements Runnable &#123; public void run() &#123; try &#123; List&lt;Member&gt; targetServer = serverMemberManager.allMembersWithoutSelf(); // 获取所有除开自己的其它服务端成员 for (String each : distroComponentHolder.getDataStorageTypes()) &#123; verifyForDataStorage(each, targetServer); &#125; &#125; catch (Exception e) &#123; &#125; &#125; private void verifyForDataStorage(String type, List&lt;Member&gt; targetServer) &#123; DistroData distroData = distroComponentHolder.findDataStorage(type).getVerifyData(); // 获取本机上所有客户端服务的注册keyChecksums if (null == distroData) &#123; return; // 若没有任何客户端注册在本实例上 &#125; distroData.setType(DataOperation.VERIFY); for (Member member : targetServer) &#123; try &#123; distroComponentHolder.findTransportAgent(type).syncVerifyData(distroData, member.getAddress()); &#125; catch (Exception e) &#123; &#125; &#125; &#125;&#125;public class DistroDataStorageImpl implements DistroDataStorage &#123; public DistroData getVerifyData() &#123; Map&lt;String, String&gt; keyChecksums = new HashMap&lt;&gt;(64); for (String key : dataStore.keys()) &#123; if (!distroMapper.responsible(KeyBuilder.getServiceName(key))) &#123; continue; // 若key对应的客户端服务不是注册在当前的服务端上，则跳过 &#125; Datum datum = dataStore.get(key); if (datum == null) &#123; continue; // 若当前Key获取到的Service缓存数据为null &#125; keyChecksums.put(key, datum.value.getChecksum()); &#125; if (keyChecksums.isEmpty()) &#123; return null; // 若没有找到注册的服务信息 &#125; DistroKey distroKey = new DistroKey(\"checksum\", KeyBuilder.INSTANCE_LIST_KEY_PREFIX); return new DistroData(distroKey, ApplicationUtils.getBean(Serializer.class).serialize(keyChecksums)); &#125;&#125; 最终挨个调用目标成员的/v1/ns/distro/checksum接口进行数据校验，这里localServer的目的是用于目标成员回调，获取更新的服务实例数据。 12345678910111213141516171819202122232425262728293031public class DistroHttpAgent implements DistroTransportAgent &#123; public boolean syncVerifyData(DistroData verifyData, String targetServer) &#123; if (!memberManager.hasMember(targetServer)) &#123; return true; // 若当前服务端实例不在成员列表中 &#125; NamingProxy.syncCheckSums(verifyData.getContent(), targetServer); return true; &#125;&#125;public class NamingProxy &#123; public static void syncCheckSums(byte[] checksums, String server) &#123; try &#123; // 调用/v1/ns/distro/checksum?source=localServer接口校验 Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(128); headers.put(HttpHeaderConsts.CLIENT_VERSION_HEADER, VersionUtils.version); headers.put(HttpHeaderConsts.USER_AGENT_HEADER, UtilsAndCommons.SERVER_VERSION); headers.put(HttpHeaderConsts.CONNECTION, \"Keep-Alive\"); HttpClient.asyncHttpPutLarge(\"http://\" + server + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + TIMESTAMP_SYNC_URL + \"?source=\" + NetUtils.localServer(), headers, checksums, new Callback&lt;String&gt;() &#123; @Override public void onReceive(RestResult&lt;String&gt; result) &#123; &#125; @Override public void onError(Throwable throwable) &#123; &#125; @Override public void onCancel() &#123; &#125; &#125;); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 若上一次任务还没有执行完成又接收到了新的任务会直接跳过，若接收的实例列表存在注册在当前机器上发送者是本机则直接中断，让后将新增和更新的服务实例的Key添加到toUpdateKeys中，然后遍历本机中注册在发送请求验证的服务成员上的实例列表，判断实例是否已删除。最后通过onRemove异步执行更新注册表，对于需要更新的数据会回调/v1/ns/distro/datum接口获取最新的实例数据然后解析更新缓存和注册表中的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119@RestController@RequestMapping(UtilsAndCommons.NACOS_NAMING_CONTEXT + \"/distro\")public class DistroController &#123; @PutMapping(\"/checksum\") public ResponseEntity syncChecksum(@RequestParam String source, @RequestBody Map&lt;String, String&gt; dataMap) &#123; DistroHttpData distroHttpData = new DistroHttpData(createDistroKey(source), dataMap); distroProtocol.onVerify(distroHttpData); return ResponseEntity.ok(\"ok\"); &#125;&#125;public class DistroProtocol &#123; public boolean onVerify(DistroData distroData) &#123; String resourceType = distroData.getDistroKey().getResourceType(); DistroDataProcessor dataProcessor = distroComponentHolder.findDataProcessor(resourceType); if (null == dataProcessor) &#123; return false; &#125; return dataProcessor.processVerifyData(distroData); &#125;&#125;public class DistroConsistencyServiceImpl implements EphemeralConsistencyService, DistroDataProcessor &#123; public boolean processVerifyData(DistroData distroData) &#123; DistroHttpData distroHttpData = (DistroHttpData) distroData; String sourceServer = distroData.getDistroKey().getResourceKey(); Map&lt;String, String&gt; verifyData = (Map&lt;String, String&gt;) distroHttpData.getDeserializedContent(); onReceiveChecksums(verifyData, sourceServer); return true; &#125; public void onReceiveChecksums(Map&lt;String, String&gt; checksumMap, String server) &#123; if (syncChecksumTasks.containsKey(server)) &#123; // Already in process of this server: return; &#125; syncChecksumTasks.put(server, \"1\"); // 将任务添加到syncChecksumTasks中 try &#123; List&lt;String&gt; toUpdateKeys = new ArrayList&lt;&gt;(); // 需要更新的列表，包括更新和添加的数据 List&lt;String&gt; toRemoveKeys = new ArrayList&lt;&gt;(); // 需要移除的列表 for (Map.Entry&lt;String, String&gt; entry : checksumMap.entrySet()) &#123; if (distroMapper.responsible(KeyBuilder.getServiceName(entry.getKey()))) &#123;// this key should not be sent from remote server: return; // abort the procedure: 当前客户端服务注册在当前的服务端上 &#125; if (!dataStore.contains(entry.getKey()) || dataStore.get(entry.getKey()).value == null || !dataStore.get(entry.getKey()).value.getChecksum().equals(entry.getValue())) &#123; toUpdateKeys.add(entry.getKey()); // 若DataStore缓存中key不存在或key对应的值不存在或值的checksum不相等 &#125; &#125; for (String key : dataStore.keys()) &#123; if (!server.equals(distroMapper.mapSrv(KeyBuilder.getServiceName(key)))) &#123; continue; // 若当前客户端服务不是注册在发送校验请求的服务端成员上 &#125; if (!checksumMap.containsKey(key)) &#123; toRemoveKeys.add(key); // 若当前客户端服务不在接收列表中，说明已被删除 &#125; &#125; for (String key : toRemoveKeys) &#123; onRemove(key); // 将需要删除的service数据从缓存中移除 &#125; if (toUpdateKeys.isEmpty()) &#123; return; // 若更新列表为空 &#125; try &#123; DistroHttpCombinedKey distroKey = new DistroHttpCombinedKey(KeyBuilder.INSTANCE_LIST_KEY_PREFIX, server); distroKey.getActualResourceTypes().addAll(toUpdateKeys); DistroData remoteData = distroProtocol.queryFromRemote(distroKey); // 调用对应的服务端成员查询数据 if (null != remoteData) &#123; processData(remoteData.getContent()); &#125; &#125; catch (Exception e) &#123; &#125; &#125; finally &#123;// Remove this 'in process' flag: syncChecksumTasks.remove(server); &#125; &#125; public DistroData queryFromRemote(DistroKey distroKey) &#123; if (null == distroKey.getTargetServer()) &#123; Loggers.DISTRO.warn(\"[DISTRO] Can't query data from empty server\"); return null; &#125; String resourceType = distroKey.getResourceType(); DistroTransportAgent transportAgent = distroComponentHolder.findTransportAgent(resourceType); if (null == transportAgent) &#123; Loggers.DISTRO.warn(\"[DISTRO] Can't find transport agent for key &#123;&#125;\", resourceType); return null; &#125; return transportAgent.getData(distroKey, distroKey.getTargetServer()); &#125; public void onRemove(String key) &#123; dataStore.remove(key); // 从缓存中移除 if (!listeners.containsKey(key)) &#123; return; &#125; notifier.addTask(key, DataOperation.DELETE); // 更注册表 &#125;&#125;public class DistroHttpAgent implements DistroTransportAgent &#123; public DistroData getData(DistroKey key, String targetServer) &#123; try &#123; List&lt;String&gt; toUpdateKeys = null; if (key instanceof DistroHttpCombinedKey) &#123; toUpdateKeys = ((DistroHttpCombinedKey) key).getActualResourceTypes(); &#125; else &#123; toUpdateKeys = new ArrayList&lt;&gt;(1); toUpdateKeys.add(key.getResourceKey()); &#125; byte[] queriedData = NamingProxy.getData(toUpdateKeys, key.getTargetServer()); return new DistroData(key, queriedData); &#125; catch (Exception e) &#123; &#125; &#125;&#125;public class NamingProxy &#123; public static byte[] getData(List&lt;String&gt; keys, String server) throws Exception &#123; // 回调/v1/ns/distro/datum接口获取最新的实例数据 Map&lt;String, String&gt; params = new HashMap&lt;&gt;(8); params.put(\"keys\", StringUtils.join(keys, \",\")); RestResult&lt;String&gt; result = HttpClient.httpGetLarge(\"http://\" + server + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + DATA_GET_URL, new HashMap&lt;&gt;(8), JacksonUtils.toJson(params)); if (result.ok()) &#123; return result.getData().getBytes(); &#125; throw new IOException(\"failed to req API: \" + \"http://\" + server + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + DATA_GET_URL + \". code: \" + result.getCode() + \" msg: \" + result.getMessage()); &#125;&#125; 最终会将最新的数据批量从缓存中获取然后返给请求方。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@RestController@RequestMapping(UtilsAndCommons.NACOS_NAMING_CONTEXT + \"/distro\")public class DistroController &#123; @GetMapping(\"/datum\") public ResponseEntity get(@RequestBody String body) throws Exception &#123; JsonNode bodyNode = JacksonUtils.toObj(body); String keys = bodyNode.get(\"keys\").asText(); String keySplitter = \",\"; DistroHttpCombinedKey distroKey = new DistroHttpCombinedKey(KeyBuilder.INSTANCE_LIST_KEY_PREFIX, \"\"); for (String key : keys.split(keySplitter)) &#123; distroKey.getActualResourceTypes().add(key); &#125; DistroData distroData = distroProtocol.onQuery(distroKey); return ResponseEntity.ok(distroData.getContent()); &#125;&#125;public class DistroProtocol &#123; public DistroData onQuery(DistroKey distroKey) &#123; String resourceType = distroKey.getResourceType(); DistroDataStorage distroDataStorage = distroComponentHolder.findDataStorage(resourceType); if (null == distroDataStorage) &#123; return new DistroData(distroKey, new byte[0]); &#125; return distroDataStorage.getDistroData(distroKey); &#125;&#125;public class DistroDataStorageImpl implements DistroDataStorage &#123; public DistroData getDistroData(DistroKey distroKey) &#123; Map&lt;String, Datum&gt; result = new HashMap&lt;&gt;(1); if (distroKey instanceof DistroHttpCombinedKey) &#123; result = dataStore.batchGet(((DistroHttpCombinedKey) distroKey).getActualResourceTypes()); &#125; else &#123; Datum datum = dataStore.get(distroKey.getResourceKey()); result.put(distroKey.getResourceKey(), datum); &#125; byte[] dataContent = ApplicationUtils.getBean(Serializer.class).serialize(result); return new DistroData(distroKey, dataContent); &#125;&#125;public class DataStore &#123; public Map&lt;String, Datum&gt; batchGet(List&lt;String&gt; keys) &#123; Map&lt;String, Datum&gt; map = new HashMap&lt;&gt;(128); for (String key : keys) &#123; Datum datum = dataMap.get(key); if (datum == null) &#123; continue; &#125; map.put(key, datum); &#125; return map; &#125;&#125;","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://yaoyinglong.github.io/tags/Nacos/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Nacos","slug":"Cloud/Nacos","permalink":"https://yaoyinglong.github.io/categories/Cloud/Nacos/"}]},{"title":"Nacos集群成员信息同步","date":"2021-10-20T16:00:00.000Z","path":"Blog/Cloud/Nacos/Nacos集群成员信息同步/","text":"成员列表初始化Nacos集群模式启动时，会加载nacos.home文件夹下conf/cluster.conf集群节点列表。然后通过周期延时任务对每个节点发送心跳检查集群成员的健康状况。集群成员的管理是通过ServerMemberManager来完成的，在该Bean通过构造函数初始化时首先会将当前机器加入到集群成员列表中，然后通过initAndStartLookup()加载其它的集群成员列表。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ServerMemberManager implements ApplicationListener&lt;WebServerInitializedEvent&gt; &#123; private volatile ConcurrentSkipListMap&lt;String, Member&gt; serverList; // 集群成员列表 private MemberLookup lookup; public ServerMemberManager(ServletContext servletContext) throws Exception &#123; this.serverList = new ConcurrentSkipListMap&lt;&gt;(); EnvUtil.setContextPath(servletContext.getContextPath()); init(); &#125; protected void init() throws NacosException &#123; Loggers.CORE.info(\"Nacos-related cluster resource initialization\"); this.port = EnvUtil.getProperty(\"server.port\", Integer.class, 8848); this.localAddress = InetUtils.getSelfIP() + \":\" + port; this.self = MemberUtil.singleParse(this.localAddress); this.self.setExtendVal(MemberMetaDataConstants.VERSION, VersionUtils.version); serverList.put(self.getAddress(), self); // 将本机添加到服务端列表中 registerClusterEvent(); // 注册MembersChangeEvent服务端节点变更事件和IP变更事件IPChangeEvent initAndStartLookup(); // Initializes the lookup mode if (serverList.isEmpty()) &#123; throw new NacosException(NacosException.SERVER_ERROR, \"cannot get serverlist, so exit.\"); &#125; &#125; private void initAndStartLookup() throws NacosException &#123; this.lookup = LookupFactory.createLookUp(this); this.lookup.start(); &#125; private void registerClusterEvent() &#123; // Register node change events 注册服务端节点变更事件 NotifyCenter.registerToPublisher(MembersChangeEvent.class, EnvUtil.getProperty(\"nacos.member-change-event.queue.size\", Integer.class, 128)); // The address information of this node needs to be dynamically modified when registering the IP change of this node NotifyCenter.registerSubscriber(new Subscriber&lt;InetUtils.IPChangeEvent&gt;() &#123; @Override public void onEvent(InetUtils.IPChangeEvent event) &#123; // 注册节点IP变更时需要动态修改该节点地址信息 String newAddress = event.getNewIP() + \":\" + port; ServerMemberManager.this.localAddress = newAddress; EnvUtil.setLocalAddress(localAddress); Member self = ServerMemberManager.this.self; self.setIp(event.getNewIP()); String oldAddress = event.getOldIP() + \":\" + port; ServerMemberManager.this.serverList.remove(oldAddress); ServerMemberManager.this.serverList.put(newAddress, self); ServerMemberManager.this.memberAddressInfos.remove(oldAddress); ServerMemberManager.this.memberAddressInfos.add(newAddress); &#125; @Override public Class&lt;? extends Event&gt; subscribeType() &#123; return InetUtils.IPChangeEvent.class; &#125; &#125;); &#125;&#125; 若是集群模式启动会根据lookupType来创建具体的MemberLookup来加载集群成员列表。lookupType默认为null，默认若在nacos.home文件夹下有conf/cluster.conf集群配置文件则通过FileConfigMemberLookup来加载该配置文件内容。若是单机模式则直接创建StandaloneMemberLookup。 1234567891011121314151617181920212223242526272829303132333435363738394041public final class LookupFactory &#123; public static MemberLookup createLookUp(ServerMemberManager memberManager) throws NacosException &#123; if (!EnvUtil.getStandaloneMode()) &#123; // 集群模式启动 String lookupType = EnvUtil.getProperty(LOOKUP_MODE_TYPE); // 默认为null LookupType type = chooseLookup(lookupType); // 默认为FILE_CONFIG LOOK_UP = find(type); currentLookupType = type; &#125; else &#123; LOOK_UP = new StandaloneMemberLookup(); // Standalone模式启动 &#125; LOOK_UP.injectMemberManager(memberManager); return LOOK_UP; &#125; private static LookupType chooseLookup(String lookupType) &#123; if (StringUtils.isNotBlank(lookupType)) &#123; // 默认lookupType传入的null LookupType type = LookupType.sourceOf(lookupType); if (Objects.nonNull(type)) &#123; return type; &#125; &#125; File file = new File(EnvUtil.getClusterConfFilePath()); if (file.exists() || StringUtils.isNotBlank(EnvUtil.getMemberList())) &#123; return LookupType.FILE_CONFIG; // 默认返回 &#125; return LookupType.ADDRESS_SERVER; &#125; private static MemberLookup find(LookupType type) &#123; if (LookupType.FILE_CONFIG.equals(type)) &#123; LOOK_UP = new FileConfigMemberLookup(); return LOOK_UP; // 默认返回 &#125; if (LookupType.ADDRESS_SERVER.equals(type)) &#123; LOOK_UP = new AddressServerMemberLookup(); return LOOK_UP; &#125; throw new IllegalArgumentException(); &#125;&#125;public static String getClusterConfFilePath() &#123; return Paths.get(getNacosHome(), \"conf\", \"cluster.conf\").toString();&#125; 最终调用具体的MemberLookup的start方法，对于单机模式是直接获取本机地址作为集群列表，对于FileConfigMemberLookup首先读取配置文件中的成员列表，让后通过MemberUtil工具类的singleParse方法构造Member对象且默认状态为UP。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class FileConfigMemberLookup extends AbstractMemberLookup &#123; private FileWatcher watcher = new FileWatcher() &#123; @Override public void onChange(FileChangeEvent event) &#123; readClusterConfFromDisk(); // 若文件发生改变，则重新加载文件内容 &#125; @Override public boolean interest(String context) &#123; return StringUtils.contains(context, \"cluster.conf\"); &#125; &#125;; public void start() throws NacosException &#123; if (start.compareAndSet(false, true)) &#123; readClusterConfFromDisk(); // 从磁盘读取集群配置文件 try &#123; // 注册配置文件变更监听器 WatchFileCenter.registerWatcher(EnvUtil.getConfPath(), watcher); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; private void readClusterConfFromDisk() &#123; Collection&lt;Member&gt; tmpMembers = new ArrayList&lt;&gt;(); try &#123; List&lt;String&gt; tmp = EnvUtil.readClusterConf(); tmpMembers = MemberUtil.readServerConf(tmp); &#125; catch (Throwable e) &#123; &#125; afterLookup(tmpMembers); // 调用ServerMemberManager的memberChange方法发布MembersChangeEvent事件 &#125;&#125;public void afterLookup(Collection&lt;Member&gt; members) &#123; this.memberManager.memberChange(members);&#125;public class WatchFileCenter &#123; public static synchronized boolean registerWatcher(final String paths, FileWatcher watcher) throws NacosException &#123; checkState(); if (NOW_WATCH_JOB_CNT == MAX_WATCH_FILE_JOB) &#123; return false; &#125; WatchDirJob job = MANAGER.get(paths); if (job == null) &#123; job = new WatchDirJob(paths); job.start(); MANAGER.put(paths, job); NOW_WATCH_JOB_CNT++; &#125; job.addSubscribe(watcher); return true; &#125;&#125; 通过WatchDirJob对目标路径的文件进行监听，当发生覆盖、修改、创建、数据删除时会触发FileWatcher的onChange方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586private static class WatchDirJob extends Thread &#123; private WatchService watchService; private Set&lt;FileWatcher&gt; watchers = new ConcurrentHashSet&lt;&gt;(); public WatchDirJob(String paths) throws NacosException &#123; setName(paths); this.paths = paths; final Path p = Paths.get(paths); if (!p.toFile().isDirectory()) &#123; throw new IllegalArgumentException(\"Must be a file directory : \" + paths); &#125; this.callBackExecutor = ExecutorFactory.newSingleExecutorService(new NameThreadFactory(\"com.alibaba.nacos.sys.file.watch-\" + paths)); try &#123; // 监听指定路径的文件的覆盖、修改、创建、数据删除 WatchService service = FILE_SYSTEM.newWatchService(); p.register(service, StandardWatchEventKinds.OVERFLOW, StandardWatchEventKinds.ENTRY_MODIFY, StandardWatchEventKinds.ENTRY_CREATE, StandardWatchEventKinds.ENTRY_DELETE); this.watchService = service; &#125; catch (Throwable ex) &#123; throw new NacosException(NacosException.SERVER_ERROR, ex); &#125; &#125; void addSubscribe(final FileWatcher watcher) &#123; watchers.add(watcher); &#125; public void run() &#123; while (watch) &#123; try &#123; final WatchKey watchKey = watchService.take(); final List&lt;WatchEvent&lt;?&gt;&gt; events = watchKey.pollEvents(); watchKey.reset(); if (callBackExecutor.isShutdown()) &#123; return; &#125; if (events.isEmpty()) &#123; continue; &#125; callBackExecutor.execute(new Runnable() &#123; @Override public void run() &#123; for (WatchEvent&lt;?&gt; event : events) &#123; WatchEvent.Kind&lt;?&gt; kind = event.kind(); // Since the OS's event cache may be overflow, a backstop is needed if (StandardWatchEventKinds.OVERFLOW.equals(kind)) &#123; eventOverflow(); &#125; else &#123; eventProcess(event.context()); &#125; &#125; &#125; &#125;); &#125; catch (InterruptedException ignore) &#123; Thread.interrupted(); &#125; catch (Throwable ex) &#123; &#125; &#125; &#125; private void eventProcess(Object context) &#123; final FileChangeEvent fileChangeEvent = FileChangeEvent.builder().paths(paths).context(context).build(); final String str = String.valueOf(context); for (final FileWatcher watcher : watchers) &#123; if (watcher.interest(str)) &#123; Runnable job = new Runnable() &#123; @Override public void run() &#123; watcher.onChange(fileChangeEvent); &#125; &#125;; Executor executor = watcher.executor(); if (executor == null) &#123; try &#123; job.run(); &#125; catch (Throwable ex) &#123; &#125; &#125; else &#123; executor.execute(job); &#125; &#125; &#125; &#125; private void eventOverflow() &#123; File dir = Paths.get(paths).toFile(); for (File file : Objects.requireNonNull(dir.listFiles())) &#123; if (file.isDirectory()) &#123; continue; &#125; eventProcess(file.getName()); &#125; &#125;&#125; 当成员列表实例化完成后，会通过订阅发布模式将MembersChangeEvent放入DefaultPublisher的队列中。 12345678910111213141516171819202122232425262728293031323334353637public class ServerMemberManager implements ApplicationListener&lt;WebServerInitializedEvent&gt; &#123; synchronized boolean memberChange(Collection&lt;Member&gt; members) &#123; if (members == null || members.isEmpty()) &#123; return false; &#125; // 是否包含本机地址 boolean isContainSelfIp = members.stream().anyMatch(ipPortTmp -&gt; Objects.equals(localAddress, ipPortTmp.getAddress())); if (isContainSelfIp) &#123; isInIpList = true; // 包含本机地址 &#125; else &#123; isInIpList = false; // 不包含本机地址 members.add(this.self); // 添加本机到成员列表中 &#125; boolean hasChange = members.size() != serverList.size(); ConcurrentSkipListMap&lt;String, Member&gt; tmpMap = new ConcurrentSkipListMap&lt;&gt;(); Set&lt;String&gt; tmpAddressInfo = new ConcurrentHashSet&lt;&gt;(); for (Member member : members) &#123; final String address = member.getAddress(); if (!serverList.containsKey(address)) &#123; hasChange = true; &#125; tmpMap.put(address, member); if (NodeState.UP.equals(member.getState())) &#123; tmpAddressInfo.add(address); &#125; &#125; serverList = tmpMap; memberAddressInfos = tmpAddressInfo; Collection&lt;Member&gt; finalMembers = allMembers(); if (hasChange) &#123; MemberUtil.syncToFile(finalMembers); Event event = MembersChangeEvent.builder().members(finalMembers).build(); NotifyCenter.publishEvent(event); &#125; return hasChange; &#125;&#125; MembersChangeEvent事件最终被MemberChangeListener的子类DistroMapper订阅者消费，DistroMapper的init方法中会将自身注册为MembersChangeEvent事件订阅者，发生MembersChangeEvent事件变更后会更新健康成员列表healthyList，该列表在客户端节点做心跳时起比较重要的作用。 123456789101112131415161718192021222324public abstract class MemberChangeListener extends Subscriber&lt;MembersChangeEvent&gt; &#123; @Override public Class&lt;? extends Event&gt; subscribeType() &#123; return MembersChangeEvent.class; &#125; @Override public boolean ignoreExpireEvent() &#123; return true; &#125;&#125;public class DistroMapper extends MemberChangeListener &#123; private volatile List&lt;String&gt; healthyList = new ArrayList&lt;&gt;(); @PostConstruct public void init() &#123; NotifyCenter.registerSubscriber(this); this.healthyList = MemberUtil.simpleMembers(memberManager.allMembers()); &#125; public void onEvent(MembersChangeEvent event) &#123; // 当有服务端成员信息更新时 List&lt;String&gt; list = MemberUtil.simpleMembers(MemberUtil.selectTargetMembers(event.getMembers(), member -&gt; NodeState.UP.equals(member.getState()) || NodeState.SUSPICIOUS.equals(member.getState()))); Collections.sort(list); Collection&lt;String&gt; old = healthyList; healthyList = Collections.unmodifiableList(list); &#125;&#125; 成员状态检查通过周期延时任务对集群每个成员发送心跳检查并更新集群节点状态，该任务是通过MemberInfoReportTask来完成的，ServerMemberManager实现了ApplicationListener接口，在onApplicationEvent方法中添加了该任务。 1234567891011public class ServerMemberManager implements ApplicationListener&lt;WebServerInitializedEvent&gt; &#123; private final MemberInfoReportTask infoReportTask = new MemberInfoReportTask(); public void onApplicationEvent(WebServerInitializedEvent event) &#123; getSelf().setState(NodeState.UP); if (!EnvUtil.getStandaloneMode()) &#123; GlobalExecutor.scheduleByCommon(this.infoReportTask, 5_000L); // 5s后开始执行 &#125; EnvUtil.setPort(event.getWebServer().getPort()); EnvUtil.setLocalAddress(this.localAddress); &#125;&#125; MemberInfoReportTask继承自Task，Task实现了Runnable接口。 1234567891011121314151617181920public abstract class Task implements Runnable &#123; protected volatile boolean shutdown = false; @Override public void run() &#123; if (shutdown) &#123; return; &#125; try &#123; executeBody(); &#125; catch (Throwable t) &#123; &#125; finally &#123; if (!shutdown) &#123; after(); &#125; &#125; &#125; protected abstract void executeBody(); protected void after() &#123; &#125;&#125; 循环向除开自己的其他成员的HTTP接口/v1/core/cluster/report发送自己Member信息，且每一个任务周期只向一个成员发送数据。再根据接口的返回情况更新成员的状态，其实这里做了两件事，即检查更新其他成员的状态，也更新其他成员节点上自己的状态。executeBody执行完后再通过after方法递归将任务丢回延时线程池中。第一次是5s后执行，后续是每2s执行一次。 123456789101112131415161718192021222324252627282930313233343536373839404142class MemberInfoReportTask extends Task &#123; private final GenericType&lt;RestResult&lt;String&gt;&gt; reference = new GenericType&lt;RestResult&lt;String&gt;&gt;() &#123; &#125;; private int cursor = 0; @Override protected void executeBody() &#123; // 请求其他成员的HTTP接口/v1/core/cluster/report List&lt;Member&gt; members = ServerMemberManager.this.allMembersWithoutSelf(); if (members.isEmpty()) &#123; return; &#125; this.cursor = (this.cursor + 1) % members.size(); // 遍历每个周期向一个成员发送HTTP请求 Member target = members.get(cursor); final String url = HttpUtils.buildUrl(false, target.getAddress(), EnvUtil.getContextPath(), Commons.NACOS_CORE_CONTEXT, \"/cluster/report\"); try &#123; asyncRestTemplate.post(url, Header.newInstance().addParam(Constants.NACOS_SERVER_HEADER, VersionUtils.version), Query.EMPTY, getSelf(), reference.getType(), new Callback&lt;String&gt;() &#123; @Override public void onReceive(RestResult&lt;String&gt; result) &#123; if (result.getCode() == HttpStatus.NOT_IMPLEMENTED.value() || result.getCode() == HttpStatus.NOT_FOUND.value()) &#123; return; // 返回码为403或404 &#125; if (result.ok()) &#123; // 请求成功 MemberUtil.onSuccess(ServerMemberManager.this, target); // 更新成员信息 &#125; else &#123; // 请求失败 MemberUtil.onFail(ServerMemberManager.this, target); // 更新成员信息 &#125; &#125; @Override public void onError(Throwable throwable) &#123; // 请求错误 MemberUtil.onFail(ServerMemberManager.this, target, throwable); // 更新成员信息 &#125; @Override public void onCancel() &#123; &#125; &#125;); &#125; catch (Throwable ex) &#123; &#125; &#125; @Override protected void after() &#123; // executeBody执行完成后，递归将任务在放入延时线程池中 GlobalExecutor.scheduleByCommon(this, 2_000L); &#125;&#125; 若请求接口成功直接将成员状态设置为UP且重置失败访问次数，若请求接口失败直接将当前成员状态设置为SUSPICIOUS，若访问失败次数大于最大失败访问次数，或Connection refused则将当前成员状态置为DOWN。若状态发生变化则发送MembersChangeEvent事件。 12345678910111213141516171819202122232425262728public class MemberUtil &#123; public static void onSuccess(final ServerMemberManager manager, final Member member) &#123; final NodeState old = member.getState(); manager.getMemberAddressInfos().add(member.getAddress()); member.setState(NodeState.UP); member.setFailAccessCnt(0); if (!Objects.equals(old, member.getState())) &#123; manager.notifyMemberChange(); // 状态若发送变化则发送MembersChangeEvent事件 &#125; &#125; public static void onFail(final ServerMemberManager manager, final Member member) &#123; onFail(manager, member, ExceptionUtil.NONE_EXCEPTION); &#125; public static void onFail(final ServerMemberManager manager, final Member member, Throwable ex) &#123; manager.getMemberAddressInfos().remove(member.getAddress()); final NodeState old = member.getState(); member.setState(NodeState.SUSPICIOUS); member.setFailAccessCnt(member.getFailAccessCnt() + 1); // 最大访问失败次数，默认为3次 int maxFailAccessCnt = EnvUtil.getProperty(\"nacos.core.member.fail-access-cnt\", Integer.class, 3); if (member.getFailAccessCnt() &gt; maxFailAccessCnt || StringUtils.containsIgnoreCase(ex.getMessage(), TARGET_MEMBER_CONNECT_REFUSE_ERRMSG)) &#123; member.setState(NodeState.DOWN); // 若访问失败次数大于最大失败访问次数，或Connection refused则将当前成员状态置为DOWN &#125; if (!Objects.equals(old, member.getState())) &#123; manager.notifyMemberChange(); // 状态若发送变化则发送MembersChangeEvent事件 &#125; &#125;&#125; 其他服务端成员的NacosClusterController会接收到该信息，从而将收到的成员状态置为UP，失败访问次数置为0，之所以这样是因为接收到的是发送服务本身，相当于接收到了一个心跳。然后调用ServerMemberManager的update方法将信息更新到serverList和healthyList中。 12345678910111213141516171819202122232425262728293031323334public class NacosClusterController &#123; @PostMapping(value = &#123;\"/report\"&#125;) public RestResult&lt;String&gt; report(@RequestBody Member node) &#123; if (!node.check()) &#123; return RestResultUtils.failedWithMsg(400, \"Node information is illegal\"); &#125; node.setState(NodeState.UP); node.setFailAccessCnt(0); boolean result = memberManager.update(node); return RestResultUtils.success(Boolean.toString(result)); &#125;&#125;public class ServerMemberManager implements ApplicationListener&lt;WebServerInitializedEvent&gt; &#123; public boolean update(Member newMember) &#123; Loggers.CLUSTER.debug(\"member information update : &#123;&#125;\", newMember); String address = newMember.getAddress(); if (!serverList.containsKey(address)) &#123; return false; // 若当前地址不在服务列表中 &#125; serverList.computeIfPresent(address, (s, member) -&gt; &#123; if (NodeState.DOWN.equals(newMember.getState())) &#123; memberAddressInfos.remove(newMember.getAddress()); // 若服务已下线，则从memberAddressInfos移除 &#125; boolean isPublishChangeEvent = MemberUtil.isBasicInfoChanged(newMember, member); // 若有属性变更则为true newMember.setExtendVal(MemberMetaDataConstants.LAST_REFRESH_TIME, System.currentTimeMillis()); MemberUtil.copy(newMember, member); // 将新信息更新到旧Member上 if (isPublishChangeEvent) &#123; // 若接收到的服务端成员存在信息变更 notifyMemberChange(); // 通过发布订阅模式通知DistroMapper更新healthyList &#125; return member; &#125;); return true; &#125;&#125;","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://yaoyinglong.github.io/tags/Nacos/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Nacos","slug":"Cloud/Nacos","permalink":"https://yaoyinglong.github.io/categories/Cloud/Nacos/"}]},{"title":"Nacos Client原理","date":"2021-10-19T16:00:00.000Z","path":"Blog/Cloud/Nacos/Nacos Client原理/","text":"Nacos客户端需要引入spring-cloud-starter-alibaba-nacos-discovery依赖。 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 在配置文件中加上注册中心地址： 12spring.application.name=mall-user #微服务名称spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 #配置nacos注册中心地址 服务注册在NacosAutoServiceRegistration中继承了AbstractAutoServiceRegistration，而该抽象类实现了ApplicationListener监听器。在容器启动时通过WebServerStartStopLifecycle的start()发布ServletWebServerInitializedEvent事件。最终通过调用NacosServiceRegistry的register来完成服务注册。 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class AbstractAutoServiceRegistration&lt;R extends Registration&gt; implements AutoServiceRegistration, ApplicationContextAware, ApplicationListener&lt;WebServerInitializedEvent&gt; &#123; public void onApplicationEvent(WebServerInitializedEvent event) &#123; bind(event); &#125; public void bind(WebServerInitializedEvent event) &#123; ApplicationContext context = event.getApplicationContext(); if (context instanceof ConfigurableWebServerApplicationContext) &#123; if (\"management\".equals(((ConfigurableWebServerApplicationContext) context).getServerNamespace())) &#123; return; &#125; &#125; this.port.compareAndSet(0, event.getWebServer().getPort()); this.start(); &#125; public void start() &#123; if (!isEnabled()) &#123; return; &#125; if (!this.running.get()) &#123; this.context.publishEvent(new InstancePreRegisteredEvent(this, getRegistration())); register(); // 调用子类NacosAutoServiceRegistration的register方法 if (shouldRegisterManagement()) &#123; registerManagement(); &#125; this.context.publishEvent(new InstanceRegisteredEvent&lt;&gt;(this, getConfiguration())); this.running.compareAndSet(false, true); &#125; &#125; protected void register() &#123; this.serviceRegistry.register(getRegistration()); &#125;&#125;public class NacosAutoServiceRegistration extends AbstractAutoServiceRegistration&lt;Registration&gt; &#123; protected void register() &#123; if (!this.registration.getNacosDiscoveryProperties().isRegisterEnabled()) &#123; return; &#125; if (this.registration.getPort() &lt; 0) &#123; this.registration.setPort(getPort().get()); &#125; super.register(); // 调用超类AbstractAutoServiceRegistration的register &#125;&#125; 将当前实例封装为一个Instance对象，最终通过调用NamingService的registerInstance来完成服务注册。serviceId默认为应用名称，group默认为DEFAULT_GROUP。ephemeral用于决定是使用AP模式还是CP模式，默认为true即AP模式。 12345678910111213141516171819202122232425262728public class NacosServiceRegistry implements ServiceRegistry&lt;Registration&gt; &#123; public void register(Registration registration) &#123; if (StringUtils.isEmpty(registration.getServiceId())) &#123; return; &#125; // 从缓存中获取，若NacosNamingService不存在，则通过通过NacosDiscoveryProperties反射创建实例 NamingService namingService = namingService(); String serviceId = registration.getServiceId(); // 默认是应用名称 String group = nacosDiscoveryProperties.getGroup(); // 默认为DEFAULT_GROUP Instance instance = getNacosInstanceFromRegistration(registration); // 创建应用实例 try &#123; // 调用NacosNamingService的registerInstance方法 namingService.registerInstance(serviceId, group, instance); &#125; catch (Exception e) &#123; rethrowRuntimeException(e); &#125; &#125; private Instance getNacosInstanceFromRegistration(Registration registration) &#123; Instance instance = new Instance(); instance.setIp(registration.getHost()); // 当前实例应用机器IP instance.setPort(registration.getPort()); // 当前实例应用端口 instance.setWeight(nacosDiscoveryProperties.getWeight()); // 权重默认为1.0 instance.setClusterName(nacosDiscoveryProperties.getClusterName()); // 默认DEFAULT instance.setEnabled(nacosDiscoveryProperties.isInstanceEnabled()); // 实例是否可用，默认true instance.setMetadata(registration.getMetadata()); // 默认preserved.register.source = SPRING_CLOUD instance.setEphemeral(nacosDiscoveryProperties.isEphemeral()); // 是否为临时实例即AP模式：默认true return instance; &#125;&#125; 对于NamingService的实现类NacosNamingService的实例化，其实是通过NacosWatch中实现SmartLifecycle的start()方法，在refresh()中的finishRefresh()中调用getLifecycleProcessor().onRefresh()即调用Lifecycle的start()来完成的。从而完成了NamingService的实例化。首先创建一个NamingEvent事件监听器注册到InstancesChangeNotifier的listenerMap中，当发送数据变更时执行该监听事件。UpdateTask定时任务会每10s检查一次服务是否变更。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174public class NacosWatch implements ApplicationEventPublisherAware, SmartLifecycle &#123; public void start() &#123; if (this.running.compareAndSet(false, true)) &#123; EventListener eventListener = listenerMap.computeIfAbsent(buildKey(), event -&gt; new EventListener() &#123; @Override public void onEvent(Event event) &#123; if (event instanceof NamingEvent) &#123; List&lt;Instance&gt; instances = ((NamingEvent) event).getInstances(); // 从实例列表通过IP和端口中找到当前实例 Optional&lt;Instance&gt; instanceOptional = selectCurrentInstance(instances); instanceOptional.ifPresent(currentInstance -&gt; &#123; resetIfNeeded(currentInstance); // 若实例存在则重置实例metadata数据 &#125;); &#125; &#125; &#125;); // 从缓存中获取，若NacosNamingService不存在，则通过通过NacosDiscoveryProperties反射创建实例 NamingService namingService = nacosServiceManager.getNamingService(properties.getNacosProperties()); try &#123; // 将上面创建的NamingEvent事件监听器注册到InstancesChangeNotifier的listenerMap中，当发送数据变更时执行该监听事件 namingService.subscribe(properties.getService(), properties.getGroup(), Arrays.asList(properties.getClusterName()), eventListener); &#125; catch (Exception e) &#123; &#125; // 30s后发布HeartbeatEvent事件 this.watchFuture = this.taskScheduler.scheduleWithFixedDelay(this::nacosServicesWatch, this.properties.getWatchDelay()); &#125; &#125; public void nacosServicesWatch() &#123; // nacos doesn't support watch now , publish an event every 30 seconds. this.publisher.publishEvent(new HeartbeatEvent(this, nacosWatchIndex.getAndIncrement())); &#125;&#125;public class NacosServiceManager &#123; public NamingService getNamingService(Properties properties) &#123; if (Objects.isNull(this.namingService)) &#123; buildNamingService(properties); &#125; return namingService; &#125; private NamingService buildNamingService(Properties properties) &#123; if (Objects.isNull(namingService)) &#123; synchronized (NacosServiceManager.class) &#123; if (Objects.isNull(namingService)) &#123; namingService = createNewNamingService(properties); &#125; &#125; &#125; return namingService; &#125; private NamingService createNewNamingService(Properties properties) &#123; try &#123; return createNamingService(properties); &#125; catch (NacosException e) &#123; throw new RuntimeException(e); &#125; &#125; public static NamingService createNamingService(Properties properties) throws NacosException &#123; return NamingFactory.createNamingService(properties); &#125; public static NamingService createNamingService(Properties properties) throws NacosException &#123; try &#123; // 通过反射创建NacosNamingService实例 Class&lt;?&gt; driverImplClass = Class.forName(\"com.alibaba.nacos.client.naming.NacosNamingService\"); Constructor constructor = driverImplClass.getConstructor(Properties.class); NamingService vendorImpl = (NamingService) constructor.newInstance(properties); return vendorImpl; &#125; catch (Throwable e) &#123; throw new NacosException(NacosException.CLIENT_INVALID_PARAM, e); &#125; &#125;&#125;public class NacosNamingService implements NamingService &#123; // NacosServiceManager中通过反射调用NacosNamingService该实例方法实例化NacosNamingService public NacosNamingService(Properties properties) throws NacosException &#123; init(properties); &#125; private void init(Properties properties) throws NacosException &#123; ValidatorUtils.checkInitParam(properties); this.namespace = InitUtils.initNamespaceForNaming(properties); InitUtils.initSerialization(); initServerAddr(properties); InitUtils.initWebRootContext(properties); initCacheDir(); initLogName(properties); this.serverProxy = new NamingProxy(this.namespace, this.endpoint, this.serverList, properties); this.beatReactor = new BeatReactor(this.serverProxy, initClientBeatThreadCount(properties)); this.hostReactor = new HostReactor(this.serverProxy, beatReactor, this.cacheDir, isLoadCacheAtStart(properties), isPushEmptyProtect(properties), initPollingThreadCount(properties)); &#125;&#125;public class NamingProxy implements Closeable &#123; public NamingProxy(String namespaceId, String endpoint, String serverList, Properties properties) &#123; this.securityProxy = new SecurityProxy(properties, nacosRestTemplate); this.properties = properties; this.setServerPort(DEFAULT_SERVER_PORT); this.namespaceId = namespaceId; this.endpoint = endpoint; this.maxRetry = ConvertUtils.toInt(properties.getProperty(PropertyKeyConst.NAMING_REQUEST_DOMAIN_RETRY_COUNT, String.valueOf(UtilAndComs.REQUEST_DOMAIN_RETRY_COUNT))); if (StringUtils.isNotEmpty(serverList)) &#123; this.serverList = Arrays.asList(serverList.split(\",\")); if (this.serverList.size() == 1) &#123; this.nacosDomain = serverList; &#125; &#125; this.initRefreshTask(); &#125; private void initRefreshTask() &#123; this.executorService = new ScheduledThreadPoolExecutor(2, new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setName(\"com.alibaba.nacos.client.naming.updater\"); t.setDaemon(true); return t; &#125; &#125;); this.executorService.scheduleWithFixedDelay(new Runnable() &#123; @Override public void run() &#123; // 默认30s执行一次 refreshSrvIfNeed(); // 刷新服务列表 &#125; &#125;, 0, vipSrvRefInterMillis, TimeUnit.MILLISECONDS); this.executorService.scheduleWithFixedDelay(new Runnable() &#123; @Override public void run() &#123; securityProxy.login(getServerList()); &#125; &#125;, 0, securityInfoRefreshIntervalMills, TimeUnit.MILLISECONDS); refreshSrvIfNeed(); this.securityProxy.login(getServerList()); &#125; private void refreshSrvIfNeed() &#123; try &#123; if (!CollectionUtils.isEmpty(serverList)) &#123; return; // 若服务列表不为null则返回 &#125; if (System.currentTimeMillis() - lastSrvRefTime &lt; vipSrvRefInterMillis) &#123; return; &#125; List&lt;String&gt; list = getServerListFromEndpoint(); serversFromEndpoint = list; lastSrvRefTime = System.currentTimeMillis(); &#125; catch (Throwable e) &#123; &#125; &#125;&#125;public class HostReactor implements Closeable &#123; public HostReactor(NamingProxy serverProxy, BeatReactor beatReactor, String cacheDir, boolean loadCacheAtStart, boolean pushEmptyProtection, int pollingThreadCount) &#123; // init executorService this.executor = new ScheduledThreadPoolExecutor(pollingThreadCount, new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"com.alibaba.nacos.client.naming.updater\"); return thread; &#125; &#125;); this.beatReactor = beatReactor; this.serverProxy = serverProxy; this.cacheDir = cacheDir; if (loadCacheAtStart) &#123; this.serviceInfoMap = new ConcurrentHashMap&lt;String, ServiceInfo&gt;(DiskCache.read(this.cacheDir)); &#125; else &#123; this.serviceInfoMap = new ConcurrentHashMap&lt;String, ServiceInfo&gt;(16); &#125; this.pushEmptyProtection = pushEmptyProtection; this.updatingMap = new ConcurrentHashMap&lt;String, Object&gt;(); this.failoverReactor = new FailoverReactor(this, cacheDir); this.pushReceiver = new PushReceiver(this); this.notifier = new InstancesChangeNotifier(); // 实例化一个实例变更通知 NotifyCenter.registerToPublisher(InstancesChangeEvent.class, 16384); // 发布一个实例变更事件 NotifyCenter.registerSubscriber(notifier); // 注册为InstancesChange事件订阅者 &#125;&#125; 当UpdateTask定时任务检查到有服务变更时通过调用InstancesChangeNotifier的onEvent事件从而调用NacosWatch中注册的NamingEvent事件监听器，从而完成服务信息更新。 12345678910111213141516171819202122232425262728293031323334353637public class InstancesChangeNotifier extends Subscriber&lt;InstancesChangeEvent&gt; &#123; private final Map&lt;String, ConcurrentHashSet&lt;EventListener&gt;&gt; listenerMap = new ConcurrentHashMap&lt;String, ConcurrentHashSet&lt;EventListener&gt;&gt;(); public void registerListener(String serviceName, String clusters, EventListener listener) &#123; String key = ServiceInfo.getKey(serviceName, clusters); ConcurrentHashSet&lt;EventListener&gt; eventListeners = listenerMap.get(key); if (eventListeners == null) &#123; synchronized (lock) &#123; eventListeners = listenerMap.get(key); if (eventListeners == null) &#123; eventListeners = new ConcurrentHashSet&lt;EventListener&gt;(); listenerMap.put(key, eventListeners); &#125; &#125; &#125; eventListeners.add(listener); &#125; public void onEvent(InstancesChangeEvent event) &#123; String key = ServiceInfo.getKey(event.getServiceName(), event.getClusters()); ConcurrentHashSet&lt;EventListener&gt; eventListeners = listenerMap.get(key); if (CollectionUtils.isEmpty(eventListeners)) &#123; return; &#125; for (final EventListener listener : eventListeners) &#123; final com.alibaba.nacos.api.naming.listener.Event namingEvent = transferToNamingEvent(event); if (listener instanceof AbstractEventListener &amp;&amp; ((AbstractEventListener) listener).getExecutor() != null) &#123; ((AbstractEventListener) listener).getExecutor().execute(new Runnable() &#123; @Override public void run() &#123; listener.onEvent(namingEvent); &#125; &#125;); continue; &#125; listener.onEvent(namingEvent); &#125; &#125;&#125; 若当前是一个ephemeral实例，则会通过BeatReactor#addBeatInfo添加心跳检测，然后通过NamingProxy调用Nacos服务端的HTTP接口/v1/ns/instance完成服务注册。若是AP模式则通过BeatReactor的addBeatInfo方法添加心跳定时任务默认每5s执行一次，向服务端发送心跳信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class NacosNamingService implements NamingService &#123; public void registerInstance(String serviceName, String groupName, Instance instance) throws NacosException &#123; NamingUtils.checkInstanceIsLegal(instance); String groupedServiceName = NamingUtils.getGroupedName(serviceName, groupName); if (instance.isEphemeral()) &#123; // 若是AP模式 BeatInfo beatInfo = beatReactor.buildBeatInfo(groupedServiceName, instance); // 构建心跳信息 beatReactor.addBeatInfo(groupedServiceName, beatInfo); // 添加心跳定时任务每5s执行一次 &#125; serverProxy.registerService(groupedServiceName, groupName, instance); // 将服务实例注册到服务端 &#125;&#125;public class NamingProxy implements Closeable &#123; public void registerService(String serviceName, String groupName, Instance instance) throws NacosException &#123; final Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(16); params.put(CommonParams.NAMESPACE_ID, namespaceId); params.put(CommonParams.SERVICE_NAME, serviceName); params.put(CommonParams.GROUP_NAME, groupName); params.put(CommonParams.CLUSTER_NAME, instance.getClusterName()); params.put(\"ip\", instance.getIp()); params.put(\"port\", String.valueOf(instance.getPort())); params.put(\"weight\", String.valueOf(instance.getWeight())); params.put(\"enable\", String.valueOf(instance.isEnabled())); params.put(\"healthy\", String.valueOf(instance.isHealthy())); params.put(\"ephemeral\", String.valueOf(instance.isEphemeral())); params.put(\"metadata\", JacksonUtils.toJson(instance.getMetadata())); reqApi(UtilAndComs.nacosUrlInstance, params, HttpMethod.POST); // 调用/v1/ns/instance接口 &#125; public String reqApi(String api, Map&lt;String, String&gt; params, String method) throws NacosException &#123; return reqApi(api, params, Collections.EMPTY_MAP, method); &#125; public String reqApi(String api, Map&lt;String, String&gt; params, Map&lt;String, String&gt; body, String method) throws NacosException &#123; return reqApi(api, params, body, getServerList(), method); &#125; public String reqApi(String api, Map&lt;String, String&gt; params, Map&lt;String, String&gt; body, List&lt;String&gt; servers, String method) throws NacosException &#123; params.put(CommonParams.NAMESPACE_ID, getNamespaceId()); if (CollectionUtils.isEmpty(servers) &amp;&amp; StringUtils.isBlank(nacosDomain)) &#123; throw new NacosException(NacosException.INVALID_PARAM, \"no server available\"); &#125; NacosException exception = new NacosException(); if (StringUtils.isNotBlank(nacosDomain)) &#123; for (int i = 0; i &lt; maxRetry; i++) &#123; try &#123; return callServer(api, params, body, nacosDomain, method); &#125; catch (NacosException e) &#123; exception = e; &#125; &#125; &#125; else &#123; Random random = new Random(System.currentTimeMillis()); int index = random.nextInt(servers.size()); for (int i = 0; i &lt; servers.size(); i++) &#123; String server = servers.get(index); try &#123; return callServer(api, params, body, server, method); &#125; catch (NacosException e) &#123; exception = e; &#125; index = (index + 1) % servers.size(); &#125; &#125; throw new NacosException(exception.getErrCode(), \"failed to req API:\" + api + \" after all servers(\" + servers + \") tried: \" + exception.getMessage()); &#125;&#125; 健康检查心跳默认的心跳检测时间为5s，通过ScheduledExecutorService创建延时任务5秒后执行BeatTask的run方法，其实现了Runnable接口。且若服务发送变更，停掉原来的心跳检测任务，重新注册一个新的心跳任务。 12345678910111213141516171819202122232425262728public class BeatReactor implements Closeable &#123; public BeatInfo buildBeatInfo(String groupedServiceName, Instance instance) &#123; BeatInfo beatInfo = new BeatInfo(); beatInfo.setServiceName(groupedServiceName); beatInfo.setIp(instance.getIp()); beatInfo.setPort(instance.getPort()); beatInfo.setCluster(instance.getClusterName()); beatInfo.setWeight(instance.getWeight()); beatInfo.setMetadata(instance.getMetadata()); beatInfo.setScheduled(false); beatInfo.setPeriod(instance.getInstanceHeartBeatInterval()); return beatInfo; &#125; public void addBeatInfo(String serviceName, BeatInfo beatInfo) &#123; String key = buildKey(serviceName, beatInfo.getIp(), beatInfo.getPort()); BeatInfo existBeat = null; if ((existBeat = dom2Beat.remove(key)) != null) &#123; // 若服务发送变更，停掉原来的心跳检测任务，重新注册一个新的心跳任务 existBeat.setStopped(true); &#125; dom2Beat.put(key, beatInfo); executorService.schedule(new BeatTask(beatInfo), beatInfo.getPeriod(), TimeUnit.MILLISECONDS); MetricsMonitor.getDom2BeatSizeMonitor().set(dom2Beat.size()); &#125;&#125;public static final long DEFAULT_HEART_BEAT_INTERVAL = TimeUnit.SECONDS.toMillis(5);public long getInstanceHeartBeatInterval() &#123; return getMetaDataByKeyWithDefault(PreservedMetadataKeys.HEART_BEAT_INTERVAL, Constants.DEFAULT_HEART_BEAT_INTERVAL);&#125; 首先通过NamingProxy向Nacos服务端HTTP接口/v1/ns/instance/beat发送心跳请求，若当前实例未被注册，服务端会返回code为20404，会再次向服务端发送注册实例请求HTTP请求，当心跳发送完成后通过递归的方式再次向ScheduledExecutorService延时线程池中添加当前心跳任务。 1234567891011121314151617181920212223242526272829303132333435363738394041class BeatTask implements Runnable &#123; public void run() &#123; if (beatInfo.isStopped()) &#123; return; // 若心跳任务被停止则直接结束，且不在重复注册 &#125; long nextTime = beatInfo.getPeriod(); try &#123;// 向服务端发送心跳请求 JsonNode result = serverProxy.sendBeat(beatInfo, BeatReactor.this.lightBeatEnabled); long interval = result.get(\"clientBeatInterval\").asLong(); boolean lightBeatEnabled = false; if (result.has(CommonParams.LIGHT_BEAT_ENABLED)) &#123; lightBeatEnabled = result.get(CommonParams.LIGHT_BEAT_ENABLED).asBoolean(); &#125; BeatReactor.this.lightBeatEnabled = lightBeatEnabled; if (interval &gt; 0) &#123; nextTime = interval; &#125; int code = NamingResponseCode.OK; if (result.has(CommonParams.CODE)) &#123; code = result.get(CommonParams.CODE).asInt(); &#125; if (code == NamingResponseCode.RESOURCE_NOT_FOUND) &#123; // 若未找到服务则重新注册到服务端 Instance instance = new Instance(); instance.setPort(beatInfo.getPort()); instance.setIp(beatInfo.getIp()); instance.setWeight(beatInfo.getWeight()); instance.setMetadata(beatInfo.getMetadata()); instance.setClusterName(beatInfo.getCluster()); instance.setServiceName(beatInfo.getServiceName()); instance.setInstanceId(instance.getInstanceId()); instance.setEphemeral(true); try &#123; // 注册实例到Nacos注册中心 serverProxy.registerService(beatInfo.getServiceName(), NamingUtils.getGroupName(beatInfo.getServiceName()), instance); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125; catch (NacosException ex) &#123; &#125; executorService.schedule(new BeatTask(beatInfo), nextTime, TimeUnit.MILLISECONDS); &#125;&#125; 获取调用服务列表在通过Ribbon实现客户端负载均衡时，在RibbonClientConfiguration中注册了ILoadBalancer，在初始化LoadBalancer时调用了DynamicServerListLoadBalancer的updateListOfServers方法，最终通过NacosServerList获取Nacos服务中注册的实例列表。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Configuration(proxyBeanMethods = false)@EnableConfigurationProperties@Import(&#123; HttpClientConfiguration.class, OkHttpRibbonConfiguration.class, RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class &#125;)public class RibbonClientConfiguration &#123; @Bean @ConditionalOnMissingBean public ILoadBalancer ribbonLoadBalancer(IClientConfig config, ServerList&lt;Server&gt; serverList, ServerListFilter&lt;Server&gt; serverListFilter, IRule rule, IPing ping, ServerListUpdater serverListUpdater) &#123; if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) &#123; return this.propertiesFactory.get(ILoadBalancer.class, config, name); &#125; return new ZoneAwareLoadBalancer&lt;&gt;(config, rule, ping, serverList, serverListFilter, serverListUpdater); &#125;&#125;public class ZoneAwareLoadBalancer&lt;T extends Server&gt; extends DynamicServerListLoadBalancer&lt;T&gt; &#123; public ZoneAwareLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter, ServerListUpdater serverListUpdater) &#123; super(clientConfig, rule, ping, serverList, filter, serverListUpdater); &#125;&#125;public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123; public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter, ServerListUpdater serverListUpdater) &#123; super(clientConfig, rule, ping); this.serverListImpl = serverList; this.filter = filter; this.serverListUpdater = serverListUpdater; if (filter instanceof AbstractServerListFilter) &#123; ((AbstractServerListFilter) filter).setLoadBalancerStats(getLoadBalancerStats()); &#125; restOfInit(clientConfig); &#125; void restOfInit(IClientConfig clientConfig) &#123; boolean primeConnection = this.isEnablePrimingConnections(); this.setEnablePrimingConnections(false); enableAndInitLearnNewServersFeature(); updateListOfServers(); if (primeConnection &amp;&amp; this.getPrimeConnections() != null) &#123; this.getPrimeConnections().primeConnections(getReachableServers()); &#125; this.setEnablePrimingConnections(primeConnection); &#125; public void updateListOfServers() &#123; List&lt;T&gt; servers = new ArrayList&lt;T&gt;(); if (serverListImpl != null) &#123; servers = serverListImpl.getUpdatedListOfServers(); if (filter != null) &#123; servers = filter.getFilteredListOfServers(servers); &#125; &#125; updateAllServerList(servers); &#125;&#125; 最终调用NacosNamingService的selectInstances，这里会通过HostReactor注册一个服务信息更新的心跳任务。 1234567891011121314151617181920212223242526272829public class NacosServerList extends AbstractServerList&lt;NacosServer&gt; &#123; public List&lt;NacosServer&gt; getUpdatedListOfServers() &#123; return getServers(); &#125; private List&lt;NacosServer&gt; getServers() &#123; try &#123; String group = discoveryProperties.getGroup(); List&lt;Instance&gt; instances = discoveryProperties.namingServiceInstance().selectInstances(serviceId, group, true); return instancesToServerList(instances); &#125; catch (Exception e) &#123; throw new IllegalStateException(\"Can not get service instances from nacos, serviceId=\" + serviceId, e); &#125; &#125;&#125;public class NacosNamingService implements NamingService &#123; public List&lt;Instance&gt; selectInstances(String serviceName, String groupName, boolean healthy) throws NacosException &#123; return selectInstances(serviceName, groupName, healthy, true); &#125; public List&lt;Instance&gt; selectInstances(String serviceName, String groupName, List&lt;String&gt; clusters, boolean healthy, boolean subscribe) throws NacosException &#123; ServiceInfo serviceInfo; if (subscribe) &#123; // subscribe为true serviceInfo = hostReactor.getServiceInfo(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; else &#123; serviceInfo = hostReactor.getServiceInfoDirectlyFromServer(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; return selectInstances(serviceInfo, healthy); &#125;&#125; 服务列表拉取心跳若当前服务不存在则通过updateServiceNow调用updateService，最终调用NamingProxy的queryList调用Nacos服务端的HTTP接口/v1/ns/instance/list获取服务列表。最终将更新心跳任务UpdateTask添加到ScheduledExecutorService延时任务线程池中。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class HostReactor implements Closeable &#123; public ServiceInfo getServiceInfo(final String serviceName, final String clusters) &#123; String key = ServiceInfo.getKey(serviceName, clusters); if (failoverReactor.isFailoverSwitch()) &#123; return failoverReactor.getService(key); &#125; ServiceInfo serviceObj = getServiceInfo0(serviceName, clusters); if (null == serviceObj) &#123; // 若通过服务名称从缓存列表中未获取到信息 serviceObj = new ServiceInfo(serviceName, clusters); serviceInfoMap.put(serviceObj.getKey(), serviceObj); updatingMap.put(serviceName, new Object()); updateServiceNow(serviceName, clusters); updatingMap.remove(serviceName); &#125; else if (updatingMap.containsKey(serviceName)) &#123; // 若服务正在更新 if (UPDATE_HOLD_INTERVAL &gt; 0) &#123; synchronized (serviceObj) &#123; try &#123; serviceObj.wait(UPDATE_HOLD_INTERVAL); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; &#125; scheduleUpdateIfAbsent(serviceName, clusters); return serviceInfoMap.get(serviceObj.getKey()); &#125; public void scheduleUpdateIfAbsent(String serviceName, String clusters) &#123; if (futureMap.get(ServiceInfo.getKey(serviceName, clusters)) != null) &#123; return; &#125; synchronized (futureMap) &#123; if (futureMap.get(ServiceInfo.getKey(serviceName, clusters)) != null) &#123; return; &#125; ScheduledFuture&lt;?&gt; future = addTask(new UpdateTask(serviceName, clusters)); futureMap.put(ServiceInfo.getKey(serviceName, clusters), future); &#125; &#125; private static final long DEFAULT_DELAY = 1000L; public synchronized ScheduledFuture&lt;?&gt; addTask(UpdateTask task) &#123; return executor.schedule(task, DEFAULT_DELAY, TimeUnit.MILLISECONDS); &#125;&#125; 心跳更新任务会每10s向服务端发送一次请求，获取当前用到的实例列表最新信息，最终通过递归的方式不断的发送心跳。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class UpdateTask implements Runnable &#123; public void run() &#123; long delayTime = DEFAULT_DELAY; try &#123; ServiceInfo serviceObj = serviceInfoMap.get(ServiceInfo.getKey(serviceName, clusters)); if (serviceObj == null) &#123; updateService(serviceName, clusters); return; &#125; if (serviceObj.getLastRefTime() &lt;= lastRefTime) &#123; updateService(serviceName, clusters); serviceObj = serviceInfoMap.get(ServiceInfo.getKey(serviceName, clusters)); &#125; else &#123; refreshOnly(serviceName, clusters); &#125; lastRefTime = serviceObj.getLastRefTime(); if (!notifier.isSubscribed(serviceName, clusters) &amp;&amp; !futureMap.containsKey(ServiceInfo.getKey(serviceName, clusters))) &#123; return; &#125; if (CollectionUtils.isEmpty(serviceObj.getHosts())) &#123; incFailCount(); return; &#125; delayTime = serviceObj.getCacheMillis(); resetFailCount(); &#125; catch (Throwable e) &#123; incFailCount(); &#125; finally &#123; executor.schedule(this, Math.min(delayTime &lt;&lt; failCount, DEFAULT_DELAY * 60), TimeUnit.MILLISECONDS); &#125; &#125;&#125;public void updateService(String serviceName, String clusters) throws NacosException &#123; ServiceInfo oldService = getServiceInfo0(serviceName, clusters); try &#123; String result = serverProxy.queryList(serviceName, clusters, pushReceiver.getUdpPort(), false); if (StringUtils.isNotEmpty(result)) &#123; processServiceJson(result); &#125; &#125; finally &#123; if (oldService != null) &#123; synchronized (oldService) &#123; oldService.notifyAll(); &#125; &#125; &#125;&#125; 这里会将请求回的服务列表解析，并与旧的列表对表，若有变更则发布变更事件InstancesChangeEvent且将新的数据写到磁盘中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class HostReactor implements Closeable &#123; public ServiceInfo processServiceJson(String json) &#123; ServiceInfo serviceInfo = JacksonUtils.toObj(json, ServiceInfo.class); ServiceInfo oldService = serviceInfoMap.get(serviceInfo.getKey()); if (pushEmptyProtection &amp;&amp; !serviceInfo.validate()) &#123; //empty or error push, just ignore return oldService; &#125; boolean changed = false; if (oldService != null) &#123; // 一般正常逻辑oldService不为null serviceInfoMap.put(serviceInfo.getKey(), serviceInfo); // 将新获取到的serviceInfo放入serviceInfoMap缓存中 Map&lt;String, Instance&gt; oldHostMap = new HashMap&lt;String, Instance&gt;(oldService.getHosts().size()); for (Instance host : oldService.getHosts()) &#123; // 旧实例列表 oldHostMap.put(host.toInetAddr(), host); &#125; Map&lt;String, Instance&gt; newHostMap = new HashMap&lt;String, Instance&gt;(serviceInfo.getHosts().size()); for (Instance host : serviceInfo.getHosts()) &#123; // 新实例列表 newHostMap.put(host.toInetAddr(), host); &#125; Set&lt;Instance&gt; modHosts = new HashSet&lt;Instance&gt;(); Set&lt;Instance&gt; newHosts = new HashSet&lt;Instance&gt;(); Set&lt;Instance&gt; remvHosts = new HashSet&lt;Instance&gt;(); List&lt;Map.Entry&lt;String, Instance&gt;&gt; newServiceHosts = new ArrayList&lt;Map.Entry&lt;String, Instance&gt;&gt;(newHostMap.entrySet()); for (Map.Entry&lt;String, Instance&gt; entry : newServiceHosts) &#123; Instance host = entry.getValue(); String key = entry.getKey(); if (oldHostMap.containsKey(key) &amp;&amp; !StringUtils.equals(host.toString(), oldHostMap.get(key).toString())) &#123; modHosts.add(host); // 被修改实例：新实例ip+port在旧实例列表中，但实例不相等 continue; &#125; if (!oldHostMap.containsKey(key)) &#123; newHosts.add(host); // 新增实例：旧实例列表不存在 &#125; &#125; for (Map.Entry&lt;String, Instance&gt; entry : oldHostMap.entrySet()) &#123; Instance host = entry.getValue(); String key = entry.getKey(); if (newHostMap.containsKey(key)) &#123; continue; &#125; if (!newHostMap.containsKey(key)) &#123; remvHosts.add(host); // 被删除的实例列表：新实例列表中不包含的旧实例 &#125; &#125; if (newHosts.size() &gt; 0) &#123; // 存在新增实例将changed置为true，输出相应日志 changed = true; &#125; if (remvHosts.size() &gt; 0) &#123; // 存在删除实例将changed置为true，输出相应日志 changed = true; &#125; if (modHosts.size() &gt; 0) &#123; // 存在修改实例将changed置为true，输出相应日志 changed = true; updateBeatInfo(modHosts); &#125; serviceInfo.setJsonFromServer(json); if (newHosts.size() &gt; 0 || remvHosts.size() &gt; 0 || modHosts.size() &gt; 0) &#123; NotifyCenter.publishEvent(new InstancesChangeEvent(serviceInfo.getName(), serviceInfo.getGroupName(), serviceInfo.getClusters(), serviceInfo.getHosts())); DiskCache.write(serviceInfo, cacheDir); &#125; &#125; else &#123; changed = true; serviceInfoMap.put(serviceInfo.getKey(), serviceInfo); NotifyCenter.publishEvent(new InstancesChangeEvent(serviceInfo.getName(), serviceInfo.getGroupName(), serviceInfo.getClusters(), serviceInfo.getHosts())); serviceInfo.setJsonFromServer(json); DiskCache.write(serviceInfo, cacheDir); // 写入磁盘缓存 &#125; MetricsMonitor.getServiceInfoMapSizeMonitor().set(serviceInfoMap.size()); return serviceInfo; &#125; private void updateBeatInfo(Set&lt;Instance&gt; modHosts) &#123; for (Instance instance : modHosts) &#123; String key = beatReactor.buildKey(instance.getServiceName(), instance.getIp(), instance.getPort()); // 若变更的实例时当前实例则停止原来的心跳任务重新注册心跳任务 if (beatReactor.dom2Beat.containsKey(key) &amp;&amp; instance.isEphemeral()) &#123; BeatInfo beatInfo = beatReactor.buildBeatInfo(instance); beatReactor.addBeatInfo(instance.getServiceName(), beatInfo); &#125; &#125; &#125;&#125;","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://yaoyinglong.github.io/tags/Nacos/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Nacos","slug":"Cloud/Nacos","permalink":"https://yaoyinglong.github.io/categories/Cloud/Nacos/"}]},{"title":"Nacos Server原理","date":"2021-10-19T16:00:00.000Z","path":"Blog/Cloud/Nacos/Nacos Server原理/","text":"服务注册：Nacos Client通过发送REST请求的方式向Nacos Server注册自己的服务，提供自身元数据，如ip地址、端口等信息。Nacos Server接收到注册请求后，把这些元数据信息存储在一个双层的内存Map中 服务心跳：在服务注册后，Nacos Client会维护一个定时心跳来持续通知Nacos Server，说明服务一直处于可用状态，防止被剔除。默认5s发送一次心跳 服务健康检查：Nacos Server会开启一个定时任务用来检查注册服务实例的健康情况，对于超过15s没有收到客户端心跳的实例会将它的healthy属性置为false，若某个实例超过30s没收到心跳，直接剔除该实例，被剔除实例若恢复发送心跳则重新注册 服务发现：Nacos Client调用服务提供者服务时，会发送一个REST请求给Nacos Server，获取注册服务清单，且缓存在Nacos Client本地，同时会在Nacos Client本地开启一个定时任务定时拉取服务端最新注册表信息更新到本地缓存 服务同步：Nacos Server集群之间会互相同步服务实例，用来保证服务信息的一致性。 服务注册客户端服务注册调用的InstanceController的register最终调用ServiceManager的registerInstance注册服务实例。首先判断当前命名空间下该服务名称的服务是否存在若不存在这创建一个服务，将其放入服务注册表serviceMap中，添加心跳监控检查，以及创建RecordListener，将当前实例添加到服务中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@CanDistro@PostMapping@Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE)public String register(HttpServletRequest request) throws Exception &#123; final String namespaceId = WebUtils.optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); final Instance instance = parseInstance(request); // 解析请求参数为Instance serviceManager.registerInstance(namespaceId, serviceName, instance); return \"ok\";&#125;public class ServiceManager implements RecordListener&lt;Service&gt; &#123; private final Map&lt;String, Map&lt;String, Service&gt;&gt; serviceMap = new ConcurrentHashMap&lt;&gt;(); public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException &#123; createEmptyService(namespaceId, serviceName, instance.isEphemeral()); // 若对应的Service不存在，则先创建 Service service = getService(namespaceId, serviceName); // 从缓存中获取Service if (service == null) &#123; throw new NacosException(NacosException.INVALID_PARAM, \"service not found, namespace: \" + namespaceId + \", service: \" + serviceName); &#125; addInstance(namespaceId, serviceName, instance.isEphemeral(), instance); // 将实例对象添加到注册表，以及同步给其它服务端成员 &#125; public void createEmptyService(String namespaceId, String serviceName, boolean local) throws NacosException &#123; createServiceIfAbsent(namespaceId, serviceName, local, null); &#125; public void createServiceIfAbsent(String namespaceId, String serviceName, boolean local, Cluster cluster) throws NacosException &#123; Service service = getService(namespaceId, serviceName); if (service == null) &#123; // 若缓存中namespaceId下无serviceName对应的Service service = new Service(); service.setName(serviceName); // 设置serviceName service.setNamespaceId(namespaceId); // 设置namespaceId service.setGroupName(NamingUtils.getGroupName(serviceName)); service.setLastModifiedMillis(System.currentTimeMillis()); // 设置服务最新更新时间为当前时间 service.recalculateChecksum(); if (cluster != null) &#123; // cluster传入的是null，故这里Service中clusterMap为空 cluster.setService(service); service.getClusterMap().put(cluster.getName(), cluster); &#125; service.validate(); putServiceAndInit(service); // 将Service添加到注册表中，添加心跳监控检查，以及创建RecordListener if (!local) &#123; // AP模式local为true，CP模式local为false addOrReplaceService(service); // CP模式添加或替换服务 &#125; &#125; &#125; public Service getService(String namespaceId, String serviceName) &#123; if (serviceMap.get(namespaceId) == null) &#123; return null; // 若namespaceId对应的Service Map都不存在 &#125; return chooseServiceMap(namespaceId).get(serviceName); // 从缓存serviceMap中获取serviceName的Service &#125;&#125; 首先通过putService方法将当前Service添加到注册表中，然后通过Service的init方法为当前服务注册AP模式的健康检查心跳任务ClientBeatCheckTask，该心跳任务5s后执行，且任务执行完后每5s执行。以及CP模式的健康检查心跳任务HealthCheckTask。 123456789101112131415161718192021222324252627282930313233343536373839404142private void putServiceAndInit(Service service) throws NacosException &#123; putService(service); // 将服务添加到注册表 service.init(); // 心跳检查注册，创建时不会创建CP模式心跳监控检查任务 // 给AP模式的服务注册监听器，以便服务变更时将服务同步给其他服务端成员 consistencyService.listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), true), service); // 给CP模式的服务注册监听器，以便服务变更时将服务同步给其他服务端成员 consistencyService.listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), false), service);&#125;public void putService(Service service) &#123; if (!serviceMap.containsKey(service.getNamespaceId())) &#123; synchronized (putServiceLock) &#123; // 若namespaceId对应的Map不存在，则先创建一个ConcurrentSkipListMap if (!serviceMap.containsKey(service.getNamespaceId())) &#123; serviceMap.put(service.getNamespaceId(), new ConcurrentSkipListMap&lt;&gt;()); &#125; &#125; &#125; serviceMap.get(service.getNamespaceId()).put(service.getName(), service); // 将服务添加到注册表&#125;public class Service extends com.alibaba.nacos.api.naming.pojo.Service implements Record, RecordListener&lt;Instances&gt; &#123; public void init() &#123; HealthCheckReactor.scheduleCheck(clientBeatCheckTask); // CP模式心跳检测 for (Map.Entry&lt;String, Cluster&gt; entry : clusterMap.entrySet()) &#123; entry.getValue().setService(this); entry.getValue().init(); // 创建CP模式心跳监控检查任务 &#125; &#125;&#125;public class HealthCheckReactor &#123; public static void scheduleCheck(ClientBeatCheckTask task) &#123; futureMap.putIfAbsent(task.taskKey(), GlobalExecutor.scheduleNamingHealth(task, 5000, 5000, TimeUnit.MILLISECONDS)); &#125;&#125;public class Cluster extends com.alibaba.nacos.api.naming.pojo.Cluster implements Cloneable &#123; public void init() &#123; if (inited) &#123; return; &#125; checkTask = new HealthCheckTask(this); // 创建CP模式心跳监控检查任务 HealthCheckReactor.scheduleCheck(checkTask); inited = true; &#125;&#125; 首先获取该Service下所有实例对象，然后遍历通过当前时间减去客户端最后发送心跳时间若大于15s则将当前实例健康状态设置为false。若当前时间减去客户端最后发送心跳时间大于30s，则异步调用自身的HTTP接口/v1/ns/instance将其踢出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class ClientBeatCheckTask implements Runnable &#123; public void run() &#123; // 客户端心跳检测 try &#123; if (!getDistroMapper().responsible(service.getName())) &#123; return;// 当前客户端服务不是注册在当前的服务端上 &#125; if (!getSwitchDomain().isHealthCheckEnabled()) &#123; return; // 若不允许健康检查则跳过 &#125; List&lt;Instance&gt; instances = service.allIPs(true); // 获取所有ephemeralInstances实例，即AP模式的实例 for (Instance instance : instances) &#123; if (System.currentTimeMillis() - instance.getLastBeat() &gt; instance.getInstanceHeartBeatTimeOut()) &#123; if (!instance.isMarked()) &#123; // 判断最后心跳时间是否大于15s，marked默认为false if (instance.isHealthy()) &#123; instance.setHealthy(false); // 若当前节点状态是健康的则置为非健康状态 getPushService().serviceChanged(service); ApplicationUtils.publishEvent(new InstanceHeartbeatTimeoutEvent(this, instance)); // 发布实例健康检查超时事件 &#125; &#125; &#125; &#125; if (!getGlobalConfig().isExpireInstance()) &#123;// expireInstance默认为true return; &#125; for (Instance instance : instances) &#123; if (instance.isMarked()) &#123; // marked默认为false continue; &#125; if (System.currentTimeMillis() - instance.getLastBeat() &gt; instance.getIpDeleteTimeout()) &#123; deleteIp(instance); // 判断最后心跳时间是否大于30s，若是则移除该实例 &#125; &#125; &#125; catch (Exception e) &#123; &#125; &#125;&#125;public List&lt;Instance&gt; allIPs(boolean ephemeral) &#123; List&lt;Instance&gt; result = new ArrayList&lt;&gt;(); for (Map.Entry&lt;String, Cluster&gt; entry : clusterMap.entrySet()) &#123; result.addAll(entry.getValue().allIPs(ephemeral)); &#125; return result;&#125;public List&lt;Instance&gt; allIPs(boolean ephemeral) &#123; return ephemeral ? new ArrayList&lt;&gt;(ephemeralInstances) : new ArrayList&lt;&gt;(persistentInstances);&#125;private void deleteIp(Instance instance) &#123; try &#123;// 通过异步调用/v1/ns/instance接口的deregister来删除实例 NamingProxy.Request request = NamingProxy.Request.newRequest(); request.appendParam(\"ip\", instance.getIp()).appendParam(\"port\", String.valueOf(instance.getPort())) .appendParam(\"ephemeral\", \"true\").appendParam(\"clusterName\", instance.getClusterName()) .appendParam(\"serviceName\", service.getName()).appendParam(\"namespaceId\", service.getNamespaceId()); String url = \"http://\" + IPUtil.localHostIP() + IPUtil.IP_PORT_SPLITER + EnvUtil.getPort() + EnvUtil.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + \"/instance?\" + request.toUrl(); HttpClient.asyncHttpDelete(url, null, null, new Callback&lt;String&gt;() &#123; @Override public void onReceive(RestResult&lt;String&gt; result) &#123;&#125; @Override public void onError(Throwable throwable) &#123;&#125; @Override public void onCancel() &#123;&#125; &#125;); &#125; catch (Exception e) &#123;&#125;&#125;public class DistroMapper extends MemberChangeListener &#123; public boolean responsible(String serviceName) &#123; // 当前客户端服务是否注册在当前的服务端上，在返回true final List&lt;String&gt; servers = healthyList; // 健康的服务端成员列表 if (!switchDomain.isDistroEnabled() || EnvUtil.getStandaloneMode()) &#123; return true; // 若是standalone启动模式 &#125; if (CollectionUtils.isEmpty(servers)) &#123; // 健康的服务端成员列表为空 return false; &#125; int index = servers.indexOf(EnvUtil.getLocalAddress()); int lastIndex = servers.lastIndexOf(EnvUtil.getLocalAddress()); if (lastIndex &lt; 0 || index &lt; 0) &#123; return true; // 若本机不在健康的服务端成员列表中 &#125; int target = distroHash(serviceName) % servers.size(); return target &gt;= index &amp;&amp; target &lt;= lastIndex; &#125;&#125; 添加实例时将DataStore缓存中数据获取出来，与注册表中的数据进行对比，并更新健康状态和最后心跳时间，将新增实例添加到Map中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void addInstance(String namespaceId, String serviceName, boolean ephemeral, Instance... ips) throws NacosException &#123; String key = KeyBuilder.buildInstanceListKey(namespaceId, serviceName, ephemeral); Service service = getService(namespaceId, serviceName); synchronized (service) &#123; List&lt;Instance&gt; instanceList = addIpAddresses(service, ephemeral, ips); // 获取实例最新实例列表 Instances instances = new Instances(); instances.setInstanceList(instanceList); consistencyService.put(key, instances); // 将实例对象添加到注册表，以及同步给其它服务端成员 &#125;&#125;private List&lt;Instance&gt; addIpAddresses(Service service, boolean ephemeral, Instance... ips) throws NacosException &#123; return updateIpAddresses(service, UtilsAndCommons.UPDATE_INSTANCE_ACTION_ADD, ephemeral, ips);&#125;public List&lt;Instance&gt; updateIpAddresses(Service service, String action, boolean ephemeral, Instance... ips) throws NacosException &#123; // 首先从缓存中获取客户端服务缓存 Datum datum = consistencyService.get(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), ephemeral)); List&lt;Instance&gt; currentIPs = service.allIPs(ephemeral); // 从注册表中获取该服务下的实例列表 Map&lt;String, Instance&gt; currentInstances = new HashMap&lt;&gt;(currentIPs.size()); Set&lt;String&gt; currentInstanceIds = Sets.newHashSet(); for (Instance instance : currentIPs) &#123; currentInstances.put(instance.toIpAddr(), instance); currentInstanceIds.add(instance.getInstanceId()); &#125; Map&lt;String, Instance&gt; instanceMap; if (datum != null &amp;&amp; null != datum.value) &#123; // 若存在缓存数据，则用注册表中的实例数据更新缓存中实例的健康状态和最后心跳时间 instanceMap = setValid(((Instances) datum.value).getInstanceList(), currentInstances); &#125; else &#123; instanceMap = new HashMap&lt;&gt;(ips.length); // 不存在缓存数据，创建一个空的Map &#125; for (Instance instance : ips) &#123; // 遍历传入的实例列表，创建是一个 if (!service.getClusterMap().containsKey(instance.getClusterName())) &#123; Cluster cluster = new Cluster(instance.getClusterName(), service); cluster.init(); // 若实例集群不存在，则创建集群，且创建CP模式心跳监控检查任务 service.getClusterMap().put(instance.getClusterName(), cluster); &#125; if (UtilsAndCommons.UPDATE_INSTANCE_ACTION_REMOVE.equals(action)) &#123; instanceMap.remove(instance.getDatumKey()); // 若是删除实例，则直接从移除 &#125; else &#123; // 若是添加实例 Instance oldInstance = instanceMap.get(instance.getDatumKey()); if (oldInstance != null) &#123; // 若存在旧实例，则将新增实例的instanceId替换为旧实例的instanceId instance.setInstanceId(oldInstance.getInstanceId()); &#125; else &#123; // 若不存在旧实例则构建一个instanceId，默认ip#port#clusterName#serviceName instance.setInstanceId(instance.generateInstanceId(currentInstanceIds)); &#125; instanceMap.put(instance.getDatumKey(), instance); // 将新增实例放入instanceMap &#125; &#125; // 若是添加实例，且添加实例失败抛出异常 if (instanceMap.size() &lt;= 0 &amp;&amp; UtilsAndCommons.UPDATE_INSTANCE_ACTION_ADD.equals(action)) &#123; throw new IllegalArgumentException(\"ip list can not be empty, service: \" + service.getName() + \", ip list: \" + JacksonUtils.toJson(instanceMap.values())); &#125; return new ArrayList&lt;&gt;(instanceMap.values());&#125; 获取到最新的实例列表后通过调用DistroConsistencyServiceImpl的put方法将实例列表放入缓存，然后将其添加到Notifier中的阻塞队列。同步实例数据到其它服务端成员列表中，是将当前服务名称下所有实例同步到其他服务端，最终是通过异步任务加队列的方式，调用HTTP接口最终在其他服务上也是通过onPut方法来完成。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class DistroConsistencyServiceImpl implements EphemeralConsistencyService, DistroDataProcessor &#123; public void put(String key, Record value) throws NacosException &#123; onPut(key, value); // 若是ephemeral实例将其添加到DataStore缓存中，然后通过异步任务替换注册表中实例列表 // 同步实例数据到其它服务端成员列表中，是将当前服务名称下所有实例同步到其他服务端，最终是通过异步任务加队列的方式，调用HTTP接口最终在其他服务上也是通过onPut方法来完成 distroProtocol.sync(new DistroKey(key, KeyBuilder.INSTANCE_LIST_KEY_PREFIX), DataOperation.CHANGE, globalConfig.getTaskDispatchPeriod() / 2); &#125; public void onPut(String key, Record value) &#123; if (KeyBuilder.matchEphemeralInstanceListKey(key)) &#123; // 若是ephemeral实例记录 Datum&lt;Instances&gt; datum = new Datum&lt;&gt;(); datum.value = (Instances) value; datum.key = key; datum.timestamp.incrementAndGet(); dataStore.put(key, datum); // 更新缓存数据 &#125; if (!listeners.containsKey(key)) &#123; return; // 若对应的RecordListener不存在则直接跳过，一般在创建实例时会添加该监听器 &#125; notifier.addTask(key, DataOperation.CHANGE);// 将当前任务放入阻塞队列 &#125;&#125;public class Notifier implements Runnable &#123; public void addTask(String datumKey, DataOperation action) &#123; if (services.containsKey(datumKey) &amp;&amp; action == DataOperation.CHANGE) &#123; return; // 若当前Task已存在则直接忽略 &#125; if (action == DataOperation.CHANGE) &#123; services.put(datumKey, StringUtils.EMPTY); // 将当前任务添加到services列表中 &#125; tasks.offer(Pair.with(datumKey, action)); // 将当前任务放入阻塞队列 &#125; public void run() &#123; for (; ; ) &#123; try &#123; Pair&lt;String, DataOperation&gt; pair = tasks.take(); // 阻塞消费队列 handle(pair); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; private void handle(Pair&lt;String, DataOperation&gt; pair) &#123; try &#123; String datumKey = pair.getValue0(); DataOperation action = pair.getValue1(); services.remove(datumKey); // 从任务列表移除 int count = 0; if (!listeners.containsKey(datumKey)) &#123; return; &#125; // 这里的获取到的RecordListener是在创建实例对象时在putServiceAndInit中通过ConsistencyService#listen方法添加的 for (RecordListener listener : listeners.get(datumKey)) &#123; // listener就是一个Service对象 count++; try &#123; if (action == DataOperation.CHANGE) &#123; // 将最新的实例列表数据通过Service的onChange方法进行注册表更新 listener.onChange(datumKey, dataStore.get(datumKey).value); continue; &#125; if (action == DataOperation.DELETE) &#123; // 通过Service的onDelete方法进行删除 listener.onDelete(datumKey); // 在Service中是空实现 continue; &#125; &#125; catch (Throwable e) &#123; &#125; &#125; &#125; catch (Throwable e) &#123; &#125; &#125;&#125; 最终调用Service的onChange方法来，最终替换注册表中Cluster的实例列表。这里更新注册表内存方法中，为了防止读写并发冲突，大量运用了CopyOnWrite思想防止并发冲突。这里也会使用PushService将服务变动通过UDP的方式通知给订阅的客户端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Service extends com.alibaba.nacos.api.naming.pojo.Service implements Record, RecordListener&lt;Instances&gt; &#123; public void onChange(String key, Instances value) throws Exception &#123; for (Instance instance : value.getInstanceList()) &#123; // 遍历实例列表 if (instance == null) &#123; // 若实例为null抛出异常 throw new RuntimeException(\"got null instance \" + key); &#125; if (instance.getWeight() &gt; 10000.0D) &#123; instance.setWeight(10000.0D); // 权重最大值为10000 &#125; if (instance.getWeight() &lt; 0.01D &amp;&amp; instance.getWeight() &gt; 0.0D) &#123; instance.setWeight(0.01D); // 权重最小值为0.01 &#125; &#125; updateIPs(value.getInstanceList(), KeyBuilder.matchEphemeralInstanceListKey(key)); // 更新注册表中实例列表 recalculateChecksum(); // 根据最新实例列表重新计算checksum &#125; public void updateIPs(Collection&lt;Instance&gt; instances, boolean ephemeral) &#123; Map&lt;String, List&lt;Instance&gt;&gt; ipMap = new HashMap&lt;&gt;(clusterMap.size()); for (String clusterName : clusterMap.keySet()) &#123; // 构造一个空的Map来存放最新的实例列表 ipMap.put(clusterName, new ArrayList&lt;&gt;()); &#125; for (Instance instance : instances) &#123; // 遍历最新的实例列表 try &#123; if (instance == null) &#123; // 跳过为null的实例 continue; &#125; if (StringUtils.isEmpty(instance.getClusterName())) &#123; // 若实例集群名称为null则设置为DEFAULT集群 instance.setClusterName(UtilsAndCommons.DEFAULT_CLUSTER_NAME); &#125; if (!clusterMap.containsKey(instance.getClusterName())) &#123; Cluster cluster = new Cluster(instance.getClusterName(), this); cluster.init(); // 若当前实例集群在注册表中不存在，则创建一个服务集群并初始化 getClusterMap().put(instance.getClusterName(), cluster); &#125; List&lt;Instance&gt; clusterIPs = ipMap.get(instance.getClusterName()); if (clusterIPs == null) &#123; clusterIPs = new LinkedList&lt;&gt;(); ipMap.put(instance.getClusterName(), clusterIPs); &#125; clusterIPs.add(instance); // 将实例分集群放入ipMap中 &#125; catch (Exception e) &#123; &#125; &#125; for (Map.Entry&lt;String, List&lt;Instance&gt;&gt; entry : ipMap.entrySet()) &#123; List&lt;Instance&gt; entryIPs = entry.getValue(); //make every ip mine clusterMap.get(entry.getKey()).updateIps(entryIPs, ephemeral); // 真正更新注册表中实例列表 &#125; setLastModifiedMillis(System.currentTimeMillis()); // 设置服务最后更新时间为当前时间 getPushService().serviceChanged(this); // 发布服务变更事件 &#125;&#125; 当服务实例发生变更会发送ServiceChangeEvent监听事件，该事件会给客户端发送UDP请求通知服务信息变更。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class PushService implements ApplicationContextAware, ApplicationListener&lt;ServiceChangeEvent&gt; &#123; public void serviceChanged(Service service) &#123; if (futureMap.containsKey(UtilsAndCommons.assembleFullServiceName(service.getNamespaceId(), service.getName()))) &#123; return; &#125; this.applicationContext.publishEvent(new ServiceChangeEvent(this, service)); &#125; public void onApplicationEvent(ServiceChangeEvent event) &#123; Service service = event.getService(); String serviceName = service.getName(); String namespaceId = service.getNamespaceId(); Future future = GlobalExecutor.scheduleUdpSender(() -&gt; &#123; // 每1s执行一次 try &#123;// // 客户端拉取某个服务时，会将客户端记录下来 ConcurrentMap&lt;String, PushClient&gt; clients = clientMap.get(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName)); if (MapUtils.isEmpty(clients)) &#123; return; &#125; Map&lt;String, Object&gt; cache = new HashMap&lt;&gt;(16); long lastRefTime = System.nanoTime(); for (PushClient client : clients.values()) &#123; if (client.zombie()) &#123; clients.remove(client.toString()); continue; &#125; Receiver.AckEntry ackEntry; String key = getPushCacheKey(serviceName, client.getIp(), client.getAgent()); byte[] compressData = null; Map&lt;String, Object&gt; data = null; if (switchDomain.getDefaultPushCacheMillis() &gt;= 20000 &amp;&amp; cache.containsKey(key)) &#123; org.javatuples.Pair pair = (org.javatuples.Pair) cache.get(key); compressData = (byte[]) (pair.getValue0()); data = (Map&lt;String, Object&gt;) pair.getValue1(); &#125; if (compressData != null) &#123; ackEntry = prepareAckEntry(client, compressData, data, lastRefTime); &#125; else &#123; ackEntry = prepareAckEntry(client, prepareHostsData(client), lastRefTime); if (ackEntry != null) &#123; cache.put(key, new org.javatuples.Pair&lt;&gt;(ackEntry.origin.getData(), ackEntry.data)); &#125; &#125; udpPush(ackEntry); // 发送UDP通知客户端 &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; futureMap.remove(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName)); &#125; &#125;, 1000, TimeUnit.MILLISECONDS); futureMap.put(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName), future); &#125; private static Receiver.AckEntry udpPush(Receiver.AckEntry ackEntry) &#123; if (ackEntry == null) &#123; return null; &#125; if (ackEntry.getRetryTimes() &gt; MAX_RETRY_TIMES) &#123; ackMap.remove(ackEntry.key); udpSendTimeMap.remove(ackEntry.key); failedPush += 1; return ackEntry; &#125; try &#123; if (!ackMap.containsKey(ackEntry.key)) &#123; totalPush++; &#125; ackMap.put(ackEntry.key, ackEntry); udpSendTimeMap.put(ackEntry.key, System.currentTimeMillis()); udpSocket.send(ackEntry.origin); ackEntry.increaseRetryTime(); GlobalExecutor.scheduleRetransmitter(new Retransmitter(ackEntry), TimeUnit.NANOSECONDS.toMillis(ACK_TIMEOUT_NANOS), TimeUnit.MILLISECONDS); return ackEntry; &#125; catch (Exception e) &#123; ackMap.remove(ackEntry.key); udpSendTimeMap.remove(ackEntry.key); failedPush += 1; return null; &#125; &#125;&#125; 更新注册表中实例列表是通过Cluster的updateIps方法，使用CopyOnWrite思想来完成注册表的更新。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class Cluster extends com.alibaba.nacos.api.naming.pojo.Cluster implements Cloneable &#123; public void updateIps(List&lt;Instance&gt; ips, boolean ephemeral) &#123; Set&lt;Instance&gt; toUpdateInstances = ephemeral ? ephemeralInstances : persistentInstances; HashMap&lt;String, Instance&gt; oldIpMap = new HashMap&lt;&gt;(toUpdateInstances.size()); for (Instance ip : toUpdateInstances) &#123; // 注册表中旧实例列表 oldIpMap.put(ip.getDatumKey(), ip); &#125; // updatedIPs为即在旧实例列表中也在新实例列表中的实例替换为新实例后的数据 List&lt;Instance&gt; updatedIPs = updatedIps(ips, oldIpMap.values()); if (updatedIPs.size() &gt; 0) &#123; // 主要逻辑是打印日志和简健康状态替换为旧的健康状态 for (Instance ip : updatedIPs) &#123; Instance oldIP = oldIpMap.get(ip.getDatumKey()); // 获取到旧的实例数据 if (!ip.isMarked()) &#123; // marked默认为false ip.setHealthy(oldIP.isHealthy()); // 将新实例对象的健康状态设置为旧实例的健康状态 &#125; &#125; &#125; List&lt;Instance&gt; newIPs = subtract(ips, oldIpMap.values()); // 返回新增的实例列表 if (newIPs.size() &gt; 0) &#123; for (Instance ip : newIPs) &#123; HealthCheckStatus.reset(ip); &#125; &#125; List&lt;Instance&gt; deadIPs = subtract(oldIpMap.values(), ips); // 返回需删除的实例列表 if (deadIPs.size() &gt; 0) &#123; for (Instance ip : deadIPs) &#123; HealthCheckStatus.remv(ip); &#125; &#125; toUpdateInstances = new HashSet&lt;&gt;(ips); // 通过CopyOnWrite将新的实例列表覆盖注册表中的实例列表 if (ephemeral) &#123; ephemeralInstances = toUpdateInstances; &#125; else &#123; persistentInstances = toUpdateInstances; &#125; &#125; private List&lt;Instance&gt; updatedIps(Collection&lt;Instance&gt; newInstance, Collection&lt;Instance&gt; oldInstance) &#123; // 旧实例列表与新实例列表的交集，即未发送变化的实例列表 List&lt;Instance&gt; intersects = (List&lt;Instance&gt;) CollectionUtils.intersection(newInstance, oldInstance); Map&lt;String, Instance&gt; stringIpAddressMap = new ConcurrentHashMap&lt;&gt;(intersects.size()); for (Instance instance : intersects) &#123; // 将未变化的实例列表放入stringIpAddressMap中 stringIpAddressMap.put(instance.getIp() + \":\" + instance.getPort(), instance); &#125; // 新实例和就实例总和 Map&lt;String, Integer&gt; intersectMap = new ConcurrentHashMap&lt;&gt;(newInstance.size() + oldInstance.size()); Map&lt;String, Instance&gt; updatedInstancesMap = new ConcurrentHashMap&lt;&gt;(newInstance.size()); Map&lt;String, Instance&gt; newInstancesMap = new ConcurrentHashMap&lt;&gt;(newInstance.size()); for (Instance instance : oldInstance) &#123; if (stringIpAddressMap.containsKey(instance.getIp() + \":\" + instance.getPort())) &#123; intersectMap.put(instance.toString(), 1); // 将旧实例放入intersectMap中，且值设置为1 &#125; &#125; for (Instance instance : newInstance) &#123; if (stringIpAddressMap.containsKey(instance.getIp() + \":\" + instance.getPort())) &#123; if (intersectMap.containsKey(instance.toString())) &#123; intersectMap.put(instance.toString(), 2); // 将新实例放入intersectMap中，且值设置为2 &#125; else &#123; intersectMap.put(instance.toString(), 1); // 将即在旧实例列表中也在新实例列表中放入intersectMap中，且值设置为1 &#125; &#125; newInstancesMap.put(instance.toString(), instance); // 新实例方法newInstancesMap &#125; for (Map.Entry&lt;String, Integer&gt; entry : intersectMap.entrySet()) &#123; String key = entry.getKey(); Integer value = entry.getValue(); if (value == 1) &#123; // 若是旧实例 if (newInstancesMap.containsKey(key)) &#123; // 即在旧实例列表中也在新实例列表中 updatedInstancesMap.put(key, newInstancesMap.get(key)); // 将即在旧实例列表中也在新实例列表中的实例替换为新实例 &#125; &#125; &#125; return new ArrayList&lt;&gt;(updatedInstancesMap.values()); // 返回即在旧实例列表中也在新实例列表中 &#125; private List&lt;Instance&gt; subtract(Collection&lt;Instance&gt; oldIp, Collection&lt;Instance&gt; ips) &#123; Map&lt;String, Instance&gt; ipsMap = new HashMap&lt;&gt;(ips.size()); for (Instance instance : ips) &#123; ipsMap.put(instance.getIp() + \":\" + instance.getPort(), instance); &#125; List&lt;Instance&gt; instanceResult = new ArrayList&lt;&gt;(); for (Instance instance : oldIp) &#123; if (!ipsMap.containsKey(instance.getIp() + \":\" + instance.getPort())) &#123; instanceResult.add(instance); // 将新的实例列表中不包含的实例添加到instanceResult &#125; &#125; return instanceResult; // 获取需要删除的实例列表，即新的实例列表中不包含旧的实例列表中存在的实例 &#125;&#125; 删除下线实例删除已下线实例是通过对客户端做心跳健康检查时，判断心跳时间，若超过30s表示服务已下线，则通过异步调用/v1/ns/instance接口来完成已下线实例的删除。最终调用InstanceController接口的deregister方法。最终通过substractIpAddresses方法将已下线服务实例从列表中删除。 12345678910111213141516171819202122232425262728@CanDistro@DeleteMapping@Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE)public String deregister(HttpServletRequest request) throws Exception &#123; Instance instance = getIpAddress(request); String namespaceId = WebUtils.optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); Service service = serviceManager.getService(namespaceId, serviceName); if (service == null) &#123; return \"ok\"; &#125; serviceManager.removeInstance(namespaceId, serviceName, instance.isEphemeral(), instance); return \"ok\";&#125;public void removeInstance(String namespaceId, String serviceName, boolean ephemeral, Instance... ips) throws NacosException &#123; Service service = getService(namespaceId, serviceName); // 从注册表中获取服务 synchronized (service) &#123; removeInstance(namespaceId, serviceName, ephemeral, service, ips); &#125;&#125;private void removeInstance(String namespaceId, String serviceName, boolean ephemeral, Service service, Instance... ips) throws NacosException &#123; String key = KeyBuilder.buildInstanceListKey(namespaceId, serviceName, ephemeral); List&lt;Instance&gt; instanceList = substractIpAddresses(service, ephemeral, ips); // 返回最新的实例列表 Instances instances = new Instances(); instances.setInstanceList(instanceList); consistencyService.put(key, instances);&#125; 最终调用updateIpAddresses方法，该方法既可以完成实例的添加也可以完成实例的删除。首先从缓存中获取该服务下的实例列表，然后从注册表中获取该服务下的实例列表，若存在缓存数据，则用注册表中的实例数据更新缓存中实例的健康状态和最后心跳时间，遍历传入的实例列表，判断若是删除实例，则直接移除。最终返回最新的服务实例列表。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ServiceManager implements RecordListener&lt;Service&gt; &#123; private List&lt;Instance&gt; substractIpAddresses(Service service, boolean ephemeral, Instance... ips) throws NacosException &#123; return updateIpAddresses(service, UtilsAndCommons.UPDATE_INSTANCE_ACTION_REMOVE, ephemeral, ips); &#125; public List&lt;Instance&gt; updateIpAddresses(Service service, String action, boolean ephemeral, Instance... ips) throws NacosException &#123; // 首先从缓存中获取客户端服务缓存 Datum datum = consistencyService.get(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), ephemeral)); List&lt;Instance&gt; currentIPs = service.allIPs(ephemeral); // 从注册表中获取该服务下的实例列表 Map&lt;String, Instance&gt; currentInstances = new HashMap&lt;&gt;(currentIPs.size()); Set&lt;String&gt; currentInstanceIds = Sets.newHashSet(); for (Instance instance : currentIPs) &#123; currentInstances.put(instance.toIpAddr(), instance); currentInstanceIds.add(instance.getInstanceId()); &#125; Map&lt;String, Instance&gt; instanceMap; if (datum != null &amp;&amp; null != datum.value) &#123; // 若存在缓存数据，则用注册表中的实例数据更新缓存中实例的健康状态和最后心跳时间 instanceMap = setValid(((Instances) datum.value).getInstanceList(), currentInstances); &#125; else &#123; instanceMap = new HashMap&lt;&gt;(ips.length); // 不存在缓存数据，创建一个空的Map &#125; for (Instance instance : ips) &#123; if (!service.getClusterMap().containsKey(instance.getClusterName())) &#123; Cluster cluster = new Cluster(instance.getClusterName(), service); cluster.init(); // 若实例集群不存在，则创建集群 service.getClusterMap().put(instance.getClusterName(), cluster); &#125; if (UtilsAndCommons.UPDATE_INSTANCE_ACTION_REMOVE.equals(action)) &#123; instanceMap.remove(instance.getDatumKey()); // 若是删除实例，则直接从移除 &#125; else &#123; // 若是添加实例 Instance oldInstance = instanceMap.get(instance.getDatumKey()); if (oldInstance != null) &#123; // 若存在旧实例，则将新增实例的instanceId替换为旧实例的instanceId instance.setInstanceId(oldInstance.getInstanceId()); &#125; else &#123; // 若不存在旧实例则构建一个instanceId instance.setInstanceId(instance.generateInstanceId(currentInstanceIds)); &#125; instanceMap.put(instance.getDatumKey(), instance); // 将新增实例放入instanceMap &#125; &#125; // 若是添加实例，且添加实例失败抛出异常 if (instanceMap.size() &lt;= 0 &amp;&amp; UtilsAndCommons.UPDATE_INSTANCE_ACTION_ADD.equals(action)) &#123; throw new IllegalArgumentException(\"ip list can not be empty, service: \" + service.getName() + \", ip list: \" + JacksonUtils.toJson(instanceMap.values())); &#125; return new ArrayList&lt;&gt;(instanceMap.values()); &#125;&#125; 最后通过DistroConsistencyServiceImpl的put方法将实例，将其添加到DataStore缓存中，然后通过异步任务替换注册表中实例列表，以及同步实例数据到其它服务端成员列表中。","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yaoyinglong.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://yaoyinglong.github.io/tags/Nacos/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"},{"name":"Nacos","slug":"Cloud/Nacos","permalink":"https://yaoyinglong.github.io/categories/Cloud/Nacos/"}]},{"title":"SpringBoot Jar包启动原理","date":"2021-10-14T16:00:00.000Z","path":"Blog/Spring/SpringBoot/SpringBoot Jar包启动原理/","text":"在执行java -jar命令时会在Jar包中找到META-INF/MANIFEST.MF文件，在该文件中通过Main-Class指定了应用的启动类，在SpringBoot的Jar包中Main-Class指定的是JarLauncher而非是正在的启动类，因为在Java中没有提供任何标准方式来加载jar文件中的jar文件，故SpringBoot通过JarLauncher来执行启动类，同时加载jar包中依赖的jar文件。 123456789101112Manifest-Version: 1.0Spring-Boot-Classpath-Index: BOOT-INF/classpath.idxImplementation-Title: eleven-springbootImplementation-Version: 0.0.1-SNAPSHOTSpring-Boot-Layers-Index: BOOT-INF/layers.idxStart-Class: com.icode.eleven.elevenspringboot.ElevenSpringbootApplicationSpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Build-Jdk-Spec: 1.8Spring-Boot-Version: 2.5.5Created-By: Maven Jar Plugin 3.2.0Main-Class: org.springframework.boot.loader.JarLauncher Spring-Boot-Classes指定的BOOT-INF/classes/中是应用程序类，Spring-Boot-Lib指定的BOOT-INF/lib/是第三方依赖jar路径。在Jar包中的org/springframework/boot/loader是SpringBoot的启动程序，JarLauncher就在该目录下。JarLauncher可以加载内部/BOOT-INF/lib下的jar及/BOOT-INF/classes下的应用class。 1234567891011public class JarLauncher extends ExecutableArchiveLauncher &#123; static final EntryFilter NESTED_ARCHIVE_ENTRY_FILTER = (entry) -&gt; &#123; if (entry.isDirectory()) &#123; return entry.getName().equals(\"BOOT-INF/classes/\"); &#125; return entry.getName().startsWith(\"BOOT-INF/lib/\"); &#125;; public static void main(String[] args) throws Exception &#123; new JarLauncher().launch(args); &#125;&#125; 实例化JarLauncher时会先调用父类ExecutableArchiveLauncher的构造方法，最终调用超类Launcher中的createArchive()创建一个归档文件Archive。通过获取当前执行类所在的的磁盘路径，然后通过该路径打开一个文件，判断文件是否为目录来决定创建ExplodedArchive还是JarFileArchive。若是Jar文件这里的classPathIndex为null。 123456789101112131415161718192021222324252627282930public abstract class ExecutableArchiveLauncher extends Launcher &#123; private static final String START_CLASS_ATTRIBUTE = \"Start-Class\"; private final Archive archive; private final ClassPathIndexFile classPathIndex; public ExecutableArchiveLauncher() &#123; try &#123; this.archive = createArchive(); this.classPathIndex = getClassPathIndex(this.archive); &#125; catch (Exception ex) &#123; throw new IllegalStateException(ex); &#125; &#125;&#125;public abstract class Launcher &#123; protected final Archive createArchive() throws Exception &#123; ProtectionDomain protectionDomain = getClass().getProtectionDomain(); CodeSource codeSource = protectionDomain.getCodeSource(); URI location = (codeSource != null) ? codeSource.getLocation().toURI() : null; String path = (location != null) ? location.getSchemeSpecificPart() : null; if (path == null) &#123; throw new IllegalStateException(\"Unable to determine code source archive\"); &#125; File root = new File(path); if (!root.exists()) &#123; throw new IllegalStateException(\"Unable to determine code source archive from \" + root); &#125; return (root.isDirectory() ? new ExplodedArchive(root) : new JarFileArchive(root)); &#125;&#125; Archive有处理文件目录资源的ExplodedArchive和处理Jar包资源的JarFileArchive两个实现类。对Jar包的封装每个JarFileArchive都会对应一个JarFile，JarFile被构造时会解析内部结构去获取jar包里的各个文件或文件夹，这些文件或文件夹会被封装到Entry中，也存储在JarFileArchive中。若Entry是个jar会解析成JarFileArchive。 1234567public interface Archive extends Iterable&lt;Archive.Entry&gt;, AutoCloseable &#123; URL getUrl() throws MalformedURLException; // 获取该归档的url // 获取jar!/META-INF/MANIFEST.MF或[ArchiveDir]/META-INF/MANIFEST.MF Manifest getManifest() throws IOException; // 获取jar!/BOOT-INF/lib/*.jar或[ArchiveDir]/BOOT-INF/lib/*.jar List&lt;Archive&gt; getNestedArchives(EntryFilter filter) throws IOException;&#125; 执行launch方法最终调用超类Launcher中的launch方法。createClassLoader方法会遍历出满足条件的jar包，并通过其创建一个LaunchedURLClassLoader。 12345678910111213141516171819202122232425262728public abstract class Launcher &#123; protected void launch(String[] args) throws Exception &#123; if (!isExploded()) &#123; JarFile.registerUrlProtocolHandler(); &#125; ClassLoader classLoader = createClassLoader(getClassPathArchivesIterator()); String jarMode = System.getProperty(\"jarmode\"); String launchClass = (jarMode != null &amp;&amp; !jarMode.isEmpty()) ? JAR_MODE_LAUNCHER : getMainClass(); launch(args, launchClass, classLoader); &#125;&#125;public abstract class ExecutableArchiveLauncher extends Launcher &#123; protected ClassLoader createClassLoader(Iterator&lt;Archive&gt; archives) throws Exception &#123; List&lt;URL&gt; urls = new ArrayList&lt;&gt;(guessClassPathSize()); while (archives.hasNext()) &#123; urls.add(archives.next().getUrl()); &#125; if (this.classPathIndex != null) &#123; urls.addAll(this.classPathIndex.getUrls()); &#125; return createClassLoader(urls.toArray(new URL[0])); &#125;&#125;public abstract class Launcher &#123; protected ClassLoader createClassLoader(URL[] urls) throws Exception &#123; return new LaunchedURLClassLoader(isExploded(), getArchive(), urls, getClass().getClassLoader()); &#125;&#125; 会将BOOT-INF/lib/目录下的所有文件过滤出来。 12345678910111213141516171819202122232425262728293031323334353637public abstract class ExecutableArchiveLauncher extends Launcher &#123; protected Iterator&lt;Archive&gt; getClassPathArchivesIterator() throws Exception &#123; Archive.EntryFilter searchFilter = this::isSearchCandidate; Iterator&lt;Archive&gt; archives = this.archive.getNestedArchives(searchFilter, (entry) -&gt; isNestedArchive(entry) &amp;&amp; !isEntryIndexed(entry)); if (isPostProcessingClassPathArchives()) &#123; archives = applyClassPathArchivePostProcessing(archives); &#125; return archives; &#125; protected ClassLoader createClassLoader(Iterator&lt;Archive&gt; archives) throws Exception &#123; List&lt;URL&gt; urls = new ArrayList&lt;&gt;(guessClassPathSize()); while (archives.hasNext()) &#123; urls.add(archives.next().getUrl()); &#125; if (this.classPathIndex != null) &#123; urls.addAll(this.classPathIndex.getUrls()); &#125; return createClassLoader(urls.toArray(new URL[0])); &#125;&#125;public class JarLauncher extends ExecutableArchiveLauncher &#123; static final EntryFilter NESTED_ARCHIVE_ENTRY_FILTER = (entry) -&gt; &#123; if (entry.isDirectory()) &#123; return entry.getName().equals(\"BOOT-INF/classes/\"); &#125; return entry.getName().startsWith(\"BOOT-INF/lib/\"); &#125;; protected boolean isSearchCandidate(Archive.Entry entry) &#123; return entry.getName().startsWith(\"BOOT-INF/\"); &#125; protected boolean isNestedArchive(Archive.Entry entry) &#123; return NESTED_ARCHIVE_ENTRY_FILTER.matches(entry); &#125; protected boolean isPostProcessingClassPathArchives() &#123; return false; &#125;&#125; 创建一个NestedArchiveIterator迭代器，迭代时调用超类AbstractIterator的next方法会回调adapt方法，最终调用getNestedArchive对于comment为UNPACK:开头的文件，会进行解压。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class JarFileArchive implements Archive &#123; private static final String UNPACK_MARKER = \"UNPACK:\"; public Iterator&lt;Archive&gt; getNestedArchives(EntryFilter searchFilter, EntryFilter includeFilter) throws IOException &#123; return new NestedArchiveIterator(this.jarFile.iterator(), searchFilter, includeFilter); &#125; protected Archive getNestedArchive(Entry entry) throws IOException &#123; JarEntry jarEntry = ((JarFileEntry) entry).getJarEntry(); if (jarEntry.getComment().startsWith(UNPACK_MARKER)) &#123; return getUnpackedNestedArchive(jarEntry); &#125; try &#123; JarFile jarFile = this.jarFile.getNestedJarFile(jarEntry); return new JarFileArchive(jarFile); &#125; catch (Exception ex) &#123; throw new IllegalStateException(\"Failed to get nested archive for entry \" + entry.getName(), ex); &#125; &#125; private Archive getUnpackedNestedArchive(JarEntry jarEntry) throws IOException &#123; String name = jarEntry.getName(); if (name.lastIndexOf('/') != -1) &#123; name = name.substring(name.lastIndexOf('/') + 1); &#125; Path path = getTempUnpackDirectory().resolve(name); if (!Files.exists(path) || Files.size(path) != jarEntry.getSize()) &#123; unpack(jarEntry, path); &#125; return new JarFileArchive(path.toFile(), path.toUri().toURL()); &#125;&#125;private class NestedArchiveIterator extends AbstractIterator&lt;Archive&gt; &#123; NestedArchiveIterator(Iterator&lt;JarEntry&gt; iterator, EntryFilter searchFilter, EntryFilter includeFilter) &#123; super(iterator, searchFilter, includeFilter); &#125; @Override protected Archive adapt(Entry entry) &#123; try &#123; return getNestedArchive(entry); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125; &#125;&#125;private abstract static class AbstractIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; public T next() &#123; T result = adapt(this.current); this.current = poll(); return result; &#125;&#125; 然后调用ExecutableArchiveLauncher的getMainClass或者正在的启动类，即META-INF/MANIFEST.MF文件中配置的Start-Class。Manifest就是用来接收解析META-INF/MANIFEST.MF出来的数据。 1234567891011121314public abstract class ExecutableArchiveLauncher extends Launcher &#123; private static final String START_CLASS_ATTRIBUTE = \"Start-Class\"; protected String getMainClass() throws Exception &#123; Manifest manifest = this.archive.getManifest(); String mainClass = null; if (manifest != null) &#123; mainClass = manifest.getMainAttributes().getValue(START_CLASS_ATTRIBUTE); &#125; if (mainClass == null) &#123; throw new IllegalStateException(\"No 'Start-Class' manifest entry specified in \" + this); &#125; return mainClass; &#125;&#125; 获取到启动类后通过反射调用启动类的main方法，即最终调用ElevenSpringbootApplication的main方法，从而去完成SpringBoot的启动。 1234567891011121314151617181920212223public abstract class Launcher &#123; protected void launch(String[] args, String launchClass, ClassLoader classLoader) throws Exception &#123; Thread.currentThread().setContextClassLoader(classLoader); createMainMethodRunner(launchClass, args, classLoader).run(); &#125; protected MainMethodRunner createMainMethodRunner(String mainClass, String[] args, ClassLoader classLoader) &#123; return new MainMethodRunner(mainClass, args); &#125;&#125;public class MainMethodRunner &#123; private final String mainClassName; private final String[] args; public MainMethodRunner(String mainClass, String[] args) &#123; this.mainClassName = mainClass; this.args = (args != null) ? args.clone() : null; &#125; public void run() throws Exception &#123; Class&lt;?&gt; mainClass = Class.forName(this.mainClassName, false, Thread.currentThread().getContextClassLoader()); Method mainMethod = mainClass.getDeclaredMethod(\"main\", String[].class); mainMethod.setAccessible(true); mainMethod.invoke(null, new Object[] &#123; this.args &#125;); &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yaoyinglong.github.io/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://yaoyinglong.github.io/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot自动装配原理","date":"2021-10-14T16:00:00.000Z","path":"Blog/Spring/SpringBoot/SpringBoot自动装配原理/","text":"SpringBoot容器启动时最终会调用refresh()方法来扫描项目中的Bean注册为BeanDefinition然后将其加载到容器中。扫描注册过程还是在invokeBeanFactoryPostProcessors中来完成的。首先通过启动类上@SpringBootApplication中的@ComponentScan来确定扫描的包来扫描包下所有的类，然后通过条件筛选出符合的Bean。 12345678910111213141516171819202122@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @AliasFor(annotation = EnableAutoConfiguration.class) Class&lt;?&gt;[] exclude() default &#123;&#125;; @AliasFor(annotation = EnableAutoConfiguration.class) String[] excludeName() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = \"basePackages\") String[] scanBasePackages() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = \"basePackageClasses\") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = \"nameGenerator\") Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; @AliasFor(annotation = Configuration.class) boolean proxyBeanMethods() default true;&#125; 在@ComponentScan中配置了一个两个excludeFilters，TypeExcludeFilter适用于提供的扩展点，AutoConfigurationExcludeFilter的作用是排除被@Configuration注解标注的且在所有META-INF/spring.factories文件中的KEY为org.springframework.boot.autoconfigure.EnableAutoConfiguration的自动配置类。 1234567891011121314151617181920public class AutoConfigurationExcludeFilter implements TypeFilter, BeanClassLoaderAware &#123; public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; return isConfiguration(metadataReader) &amp;&amp; isAutoConfiguration(metadataReader); &#125; private boolean isConfiguration(MetadataReader metadataReader) &#123; return metadataReader.getAnnotationMetadata().isAnnotated(Configuration.class.getName()); &#125; private boolean isAutoConfiguration(MetadataReader metadataReader) &#123; return getAutoConfigurations().contains(metadataReader.getClassMetadata().getClassName()); &#125; protected List&lt;String&gt; getAutoConfigurations() &#123; if (this.autoConfigurations == null) &#123; this.autoConfigurations = SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class, this.beanClassLoader); &#125; return this.autoConfigurations; &#125;&#125; 若@ComponentScan未指定basePackages和basePackageClasses，则默认使用当前配置类所在的包。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class ComponentScanAnnotationParser &#123; public Set&lt;BeanDefinitionHolder&gt; parse(AnnotationAttributes componentScan, final String declaringClass) &#123; ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean(\"useDefaultFilters\"), this.environment, this.resourceLoader); // 为扫描器设置beanName的生成器对象 Class&lt;? extends BeanNameGenerator&gt; generatorClass = componentScan.getClass(\"nameGenerator\"); boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass); scanner.setBeanNameGenerator(useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass)); // 解析@Scope的ProxyMode属性，该属性可以将Bean创建问jdk代理或cglib代理 ScopedProxyMode scopedProxyMode = componentScan.getEnum(\"scopedProxy\"); if (scopedProxyMode != ScopedProxyMode.DEFAULT) &#123; scanner.setScopedProxyMode(scopedProxyMode); &#125; else &#123; Class&lt;? extends ScopeMetadataResolver&gt; resolverClass = componentScan.getClass(\"scopeResolver\"); scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass)); &#125; scanner.setResourcePattern(componentScan.getString(\"resourcePattern\")); // 设置CompentScan对象的includeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(\"includeFilters\")) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addIncludeFilter(typeFilter); &#125; &#125; // 设置CompentScan对象的excludeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(\"excludeFilters\")) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addExcludeFilter(typeFilter); &#125; &#125; // 是否懒加载，此懒加载为componentScan延迟加载所有类 boolean lazyInit = componentScan.getBoolean(\"lazyInit\"); if (lazyInit) &#123; scanner.getBeanDefinitionDefaults().setLazyInit(true); &#125; // 包路径配置类中componentScan设置的路径 Set&lt;String&gt; basePackages = new LinkedHashSet&lt;&gt;(); String[] basePackagesArray = componentScan.getStringArray(\"basePackages\"); for (String pkg : basePackagesArray) &#123; String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized); &#125; for (Class&lt;?&gt; clazz : componentScan.getClassArray(\"basePackageClasses\")) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); &#125; if (basePackages.isEmpty()) &#123; // 若未指定则使用当前配置所在的包 basePackages.add(ClassUtils.getPackageName(declaringClass)); &#125; scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) &#123; @Override protected boolean matchClassName(String className) &#123; return declaringClass.equals(className); &#125; &#125;); return scanner.doScan(StringUtils.toStringArray(basePackages)); // 真正的进行扫描解析 &#125;&#125;public static String getPackageName(String fqClassName) &#123; // 截取出当前类所在的文件夹 Assert.notNull(fqClassName, \"Class name must not be null\"); int lastDotIndex = fqClassName.lastIndexOf(PACKAGE_SEPARATOR); return (lastDotIndex != -1 ? fqClassName.substring(0, lastDotIndex) : \"\");&#125; 将所有的@Component注解标注的类扫描出来，将其注册到容器中，对于@Import注解导入的类，总的来说分为三种，第一种是普通的类，第二种是实现了ImportSelector接口，这里面有两种类型，若是一个延时的DeferredImportSelector则只将该类添加到deferredImportSelectors后续解析后统一处理。否则调用selectImports递归调用processImports，第三中是实现了ImportBeanDefinitionRegistrar接口，这种会将其添加到当前ConfigurationClass的importBeanDefinitionRegistrars列表中后续统一处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass, Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123; if (importCandidates.isEmpty()) &#123; return; &#125; if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123; this.problemReporter.error(new CircularImportProblem(configClass, this.importStack)); &#125; else &#123; this.importStack.push(configClass); try &#123; for (SourceClass candidate : importCandidates) &#123; // 获取我们Import导入进来的所有组件 if (candidate.isAssignable(ImportSelector.class)) &#123; // 判断该组件是不是实现了ImportSelector // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化我们的SelectImport组件 ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); // 调用相关的aware方法 ParserStrategyUtils.invokeAwareMethods(selector, this.environment, this.resourceLoader, this.registry); // 判断是不是延时的DeferredImportSelectors，是这个类型不进行处理 if (this.deferredImportSelectors != null &amp;&amp; selector instanceof DeferredImportSelector) &#123; this.deferredImportSelectors.add(new DeferredImportSelectorHolder(configClass, (DeferredImportSelector) selector)); &#125; else &#123; // 不是延时的， 调用selector的selectImports String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata()); // 所以递归解析-- 直到成普通组件 Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames); processImports(configClass, currentSourceClass, importSourceClasses, false); &#125; &#125; // 判断导入的组件是不是ImportBeanDefinitionRegistrar，这里不直接调用，只是解析 else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化ImportBeanDefinitionRegistrar对象 ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); ParserStrategyUtils.invokeAwareMethods(registrar, this.environment, this.resourceLoader, this.registry); // 保存ImportBeanDefinitionRegistrar对象currentSourceClass=所在配置类 configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125; else &#123; // 当做配置类再解析，注意这里会标记：importedBy，表示这是Import的配置的类，再执行之前的processConfigurationClass()方法 ， this.importStack.registerImport(currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); processConfigurationClass(candidate.asConfigClass(configClass)); &#125; &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(\"Failed to process import candidates for configuration class [\" + configClass.getMetadata().getClassName() + \"]\", ex); &#125; finally &#123; this.importStack.pop(); &#125; &#125;&#125; 对于DeferredImportSelector的处理在processImports中会通过handle方法将其添加到ConfigurationClassParser的deferredImportSelectors列表中。在parse解析完所有Bean后调用process方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class ConfigurationClassParser &#123; public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; for (BeanDefinitionHolder holder : configCandidates) &#123; BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(\"Failed to parse configuration class [\" + bd.getBeanClassName() + \"]\", ex); &#125; &#125; this.deferredImportSelectorHandler.process(); &#125;&#125;private class DeferredImportSelectorHandler &#123; private List&lt;DeferredImportSelectorHolder&gt; deferredImportSelectors = new ArrayList&lt;&gt;(); public void handle(ConfigurationClass configClass, DeferredImportSelector importSelector) &#123; DeferredImportSelectorHolder holder = new DeferredImportSelectorHolder(configClass, importSelector); if (this.deferredImportSelectors == null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); handler.register(holder); handler.processGroupImports(); &#125; else &#123; this.deferredImportSelectors.add(holder); &#125; &#125; public void process() &#123; List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors; this.deferredImportSelectors = null; try &#123; if (deferredImports != null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); deferredImports.sort(DEFERRED_IMPORT_COMPARATOR); deferredImports.forEach(handler::register); handler.processGroupImports(); &#125; &#125; finally &#123; this.deferredImportSelectors = new ArrayList&lt;&gt;(); &#125; &#125;&#125; 通过DeferredImportSelectorGroupingHandler的register方法遍历，首先调用其getImportGroup获取Group，然后再将其封装添加到grouping，最后通过processGroupImports遍历getImports()再遍历每个导入的类执行processImports。 123456789101112131415161718192021222324252627282930313233private class DeferredImportSelectorGroupingHandler &#123; private final Map&lt;Object, DeferredImportSelectorGrouping&gt; groupings = new LinkedHashMap&lt;&gt;(); private final Map&lt;AnnotationMetadata, ConfigurationClass&gt; configurationClasses = new HashMap&lt;&gt;(); public void register(DeferredImportSelectorHolder deferredImport) &#123; Class&lt;? extends Group&gt; group = deferredImport.getImportSelector().getImportGroup(); DeferredImportSelectorGrouping grouping = this.groupings.computeIfAbsent( (group != null ? group : deferredImport), key -&gt; new DeferredImportSelectorGrouping(createGroup(group))); grouping.add(deferredImport); this.configurationClasses.put(deferredImport.getConfigurationClass().getMetadata(), deferredImport.getConfigurationClass()); &#125; public void processGroupImports() &#123; for (DeferredImportSelectorGrouping grouping : this.groupings.values()) &#123; Predicate&lt;String&gt; exclusionFilter = grouping.getCandidateFilter(); grouping.getImports().forEach(entry -&gt; &#123; ConfigurationClass configurationClass = this.configurationClasses.get(entry.getMetadata()); try &#123; processImports(configurationClass, asSourceClass(configurationClass, exclusionFilter), Collections.singleton(asSourceClass(entry.getImportClassName(), exclusionFilter)), exclusionFilter, false); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(\"Failed to process import candidates for configuration class [\" + configurationClass.getMetadata().getClassName() + \"]\", ex); &#125; &#125;); &#125; &#125; private Group createGroup(@Nullable Class&lt;? extends Group&gt; type) &#123; Class&lt;? extends Group&gt; effectiveType = (type != null ? type : DefaultDeferredImportSelectorGroup.class); return ParserStrategyUtils.instantiateClass(effectiveType, Group.class, ConfigurationClassParser.this.environment, ConfigurationClassParser.this.resourceLoader, ConfigurationClassParser.this.registry); &#125;&#125; 当处理完所有的Bean后通过调用ConfigurationClassBeanDefinitionReader的loadBeanDefinitions方法，按照解析Bean的顺序再次解析Bean中用@Bean注解标注的方法，以及对@Import中导入的实现了ImportBeanDefinitionRegistrar接口的类。 123456789101112131415161718private void loadBeanDefinitionsForConfigurationClass(ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123; if (trackedConditionEvaluator.shouldSkip(configClass)) &#123; String beanName = configClass.getBeanName(); if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) &#123; this.registry.removeBeanDefinition(beanName); &#125; this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName()); return; &#125; if (configClass.isImported()) &#123; registerBeanDefinitionForImportedConfigurationClass(configClass); &#125; for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123; loadBeanDefinitionsForBeanMethod(beanMethod); &#125; loadBeanDefinitionsFromImportedResources(configClass.getImportedResources()); loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());&#125; SpringBoot的自动装配主要体现在@EnableAutoConfiguration中。在该注解上导入了AutoConfigurationImportSelector，该类实现了延时的DeferredImportSelector，从而延时加载自动配置的类，达到自动配置的效果。 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 对于@AutoConfigurationPackages注解的作用是保存当前配置类所在的包路径作为扫描路径，提供给spring-data-jpa需要扫描@Entity。 123456789101112131415161718192021222324252627282930public abstract class AutoConfigurationPackages &#123; static class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports &#123; @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; register(registry, new PackageImports(metadata).getPackageNames().toArray(new String[0])); &#125; @Override public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123; return Collections.singleton(new PackageImports(metadata)); &#125; &#125;&#125;private static final class PackageImports &#123; private final List&lt;String&gt; packageNames; PackageImports(AnnotationMetadata metadata) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(AutoConfigurationPackage.class.getName(), false)); List&lt;String&gt; packageNames = new ArrayList&lt;&gt;(Arrays.asList(attributes.getStringArray(\"basePackages\"))); for (Class&lt;?&gt; basePackageClass : attributes.getClassArray(\"basePackageClasses\")) &#123; packageNames.add(basePackageClass.getPackage().getName()); &#125; if (packageNames.isEmpty()) &#123; packageNames.add(ClassUtils.getPackageName(metadata.getClassName())); &#125; this.packageNames = Collections.unmodifiableList(packageNames); &#125; List&lt;String&gt; getPackageNames() &#123; return this.packageNames; &#125;&#125; 通过调用AutoConfigurationImportSelector的getImportGroup()获取到AutoConfigurationGroup，在解析完成所有Bean后调用AutoConfigurationGroup的process方法，最终调用getAutoConfigurationEntry去加载系统中所有META-INF/spring.factories文件中的KEY为org.springframework.boot.autoconfigure.EnableAutoConfiguration的自动配置类列表。 加载自动配置类的过程中会排除掉@EnableAutoConfiguration注解中exclude和excludeName配置的类，以及spring.autoconfigure.exclude配置的类过滤掉，还会根据配置类上的@Conditional派生注解进行配置类的过滤；在加载Bean方法时通过ConditionEvaluator的shouldSkip根据Bean上的@Conditional派生注解来判断是否加载该Bean。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123; public Class&lt;? extends Group&gt; getImportGroup() &#123; return AutoConfigurationGroup.class; &#125; protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); // 从META-INF/spring.factories中获得候选的自动配置类 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations);// 排重 //根据EnableAutoConfiguration注解中属性，获取不需要自动装配的类名单 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); // 根据:@EnableAutoConfiguration.exclude，@EnableAutoConfiguration.excludeName，spring.autoconfigure.exclude进行排除 checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); // exclusions 也排除 // 通过读取spring.factories中的OnBeanCondition\\OnClassCondition\\OnWebApplicationCondition进行配置类的过滤 configurations = getConfigurationClassFilter().filter(configurations); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions); &#125; protected boolean isEnabled(AnnotationMetadata metadata) &#123; if (getClass() == AutoConfigurationImportSelector.class) &#123; return getEnvironment().getProperty(EnableAutoConfiguration.ENABLED_OVERRIDE_PROPERTY, Boolean.class, true); &#125; return true; &#125; protected Class&lt;?&gt; getAnnotationClass() &#123; return EnableAutoConfiguration.class; &#125; protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" + \"are using a custom packaging, make sure that file is correct.\"); return configurations; &#125; protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class; &#125;&#125;private static class AutoConfigurationGroup implements DeferredImportSelector.Group, BeanClassLoaderAware, BeanFactoryAware, ResourceLoaderAware &#123; public void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) &#123; Assert.state(deferredImportSelector instanceof AutoConfigurationImportSelector, () -&gt; String.format(\"Only %s implementations are supported, got %s\", AutoConfigurationImportSelector.class.getSimpleName(), deferredImportSelector.getClass().getName())); AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector).getAutoConfigurationEntry(annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) &#123; this.entries.putIfAbsent(importClassName, annotationMetadata); &#125; &#125; @Override public Iterable&lt;Entry&gt; selectImports() &#123; if (this.autoConfigurationEntries.isEmpty()) &#123; return Collections.emptyList(); &#125; Set&lt;String&gt; allExclusions = this.autoConfigurationEntries.stream() .map(AutoConfigurationEntry::getExclusions).flatMap(Collection::stream).collect(Collectors.toSet()); Set&lt;String&gt; processedConfigurations = this.autoConfigurationEntries.stream() .map(AutoConfigurationEntry::getConfigurations).flatMap(Collection::stream) .collect(Collectors.toCollection(LinkedHashSet::new)); processedConfigurations.removeAll(allExclusions); return sortAutoConfigurations(processedConfigurations, getAutoConfigurationMetadata()).stream() .map((importClassName) -&gt; new Entry(this.entries.get(importClassName), importClassName)) .collect(Collectors.toList()); &#125;&#125; @Conditional有很多扩展注解，最终这些扩展注解是通过@Conditional中指定的类来处理具体的逻辑的。最终都是通过SpringBootCondition的matches方法。 @Conditional扩展注解 判断件 具体处理类 @ConditionalOnJava 系统的java版本是否符合要求 OnJavaCondition @ConditionalOnBean 容器中存在指定Bean OnBeanCondition @ConditionalOnMissingBean 容器中不存在指定Bean OnBeanCondition @ConditionalOnExpression 满足SpEL表达式指定 OnExpressionCondition @ConditionalOnClass 系统中有指定的类 OnClassCondition @ConditionalOnMissingClass 系统中没有指定的类 OnClassCondition @ConditionalOnSingleCandidate 容器中只有一个指定的Bean或者该Bean是首选Bean OnBeanCondition @ConditionalOnProperty 系统中指定的属性是否有指定的值 OnPropertyCondition @ConditionalOnResource 类路径下是否存在指定资源文件 OnResourceCondition @ConditionalOnNotWebApplication 不是Web应用 OnWebApplicationCondition @ConditionalOnWebApplication 是Web应用 OnWebApplicationCondition getMatchOutcome方法是提供给具体的处理类去实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class SpringBootCondition implements Condition &#123; public final boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; String classOrMethodName = getClassOrMethodName(metadata); try &#123; ConditionOutcome outcome = getMatchOutcome(context, metadata); logOutcome(classOrMethodName, outcome); recordEvaluation(context, classOrMethodName, outcome); return outcome.isMatch(); &#125; catch (NoClassDefFoundError ex) &#123; throw new IllegalStateException(ex.getMessage(), ex); &#125; catch (RuntimeException ex) &#123; throw new IllegalStateException(\"Error processing condition on \" + getName(metadata), ex); &#125; &#125; public abstract ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata);&#125;class OnClassCondition extends FilteringSpringBootCondition &#123; public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; ClassLoader classLoader = context.getClassLoader(); ConditionMessage matchMessage = ConditionMessage.empty(); List&lt;String&gt; onClasses = getCandidates(metadata, ConditionalOnClass.class); if (onClasses != null) &#123; List&lt;String&gt; missing = filter(onClasses, ClassNameFilter.MISSING, classLoader); if (!missing.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnClass.class) .didNotFind(\"required class\", \"required classes\").items(Style.QUOTE, missing)); &#125; matchMessage = matchMessage.andCondition(ConditionalOnClass.class) .found(\"required class\", \"required classes\") .items(Style.QUOTE, filter(onClasses, ClassNameFilter.PRESENT, classLoader)); &#125; List&lt;String&gt; onMissingClasses = getCandidates(metadata, ConditionalOnMissingClass.class); if (onMissingClasses != null) &#123; List&lt;String&gt; present = filter(onMissingClasses, ClassNameFilter.PRESENT, classLoader); if (!present.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnMissingClass.class).found(\"unwanted class\", \"unwanted classes\").items(Style.QUOTE, present)); &#125; matchMessage = matchMessage.andCondition(ConditionalOnMissingClass.class) .didNotFind(\"unwanted class\", \"unwanted classes\") .items(Style.QUOTE, filter(onMissingClasses, ClassNameFilter.MISSING, classLoader)); &#125; return ConditionOutcome.match(matchMessage); &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yaoyinglong.github.io/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://yaoyinglong.github.io/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot启动原理","date":"2021-10-14T16:00:00.000Z","path":"Blog/Spring/SpringBoot/SpringBoot启动原理/","text":"SpringBoot的启动是SpringApplication.run(ElevenApplication.class, args)来完成的，首先在实例化SpringApplication时会去加载项目中所有的spring.factories配置文件数据到缓存中，并将所有的ApplicationContextInitializer和ApplicationListener筛选出来并实例化，其作用是对外扩张，以及对内的解耦，全局配置文件以及热部署插件就是通过这两个Initializer和Listener来完成的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class SpringApplication &#123; private List&lt;ApplicationContextInitializer&lt;?&gt;&gt; initializers; private List&lt;ApplicationListener&lt;?&gt;&gt; listeners; public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources); &#125; public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));/ 将启动类放入primarySources this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 根据classpath下的类确定Web类型NONE、SERVLET、REACTIVE this.bootstrapRegistryInitializers = getBootstrapRegistryInitializersFromSpringFactories(); // 去spring.factories中去获取所有key:org.springframework.context.ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 去spring.factories中去获取所有key: org.springframework.context.ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); // 根据main方法推算出mainApplicationClass &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;); &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // 根据类型筛选出spring.factories中配置的满足条件的类名列表 Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); // 将满足条件的类实例化 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; &#125;&#125;public final class SpringFactoriesLoader &#123; // 加载Jar包中所有的spring.factories文件中配置的数据到缓存中 public static final String FACTORIES_RESOURCE_LOCATION = \"META-INF/spring.factories\"; public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; ClassLoader classLoaderToUse = classLoader; if (classLoaderToUse == null) &#123; classLoaderToUse = SpringFactoriesLoader.class.getClassLoader(); &#125; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoaderToUse).getOrDefault(factoryTypeName, Collections.emptyList()); &#125; private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(ClassLoader classLoader) &#123; Map&lt;String, List&lt;String&gt;&gt; result = cache.get(classLoader); if (result != null) &#123; // 若已加载过直接跳过 return result; &#125; result = new HashMap&lt;&gt;(); try &#123; Enumeration&lt;URL&gt; urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); String[] factoryImplementationNames = StringUtils.commaDelimitedListToStringArray((String) entry.getValue()); for (String factoryImplementationName : factoryImplementationNames) &#123; result.computeIfAbsent(factoryTypeName, key -&gt; new ArrayList&lt;&gt;()).add(factoryImplementationName.trim()); &#125; &#125; &#125; result.replaceAll((factoryType, implementations) -&gt; implementations.stream().distinct().collect(Collectors.collectingAndThen(Collectors.toList(), Collections::unmodifiableList))); cache.put(classLoader, result); &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(\"Unable to load factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); &#125; return result; &#125;&#125; 通过run方法完成SpringBoot的启动 123456789101112131415161718192021222324252627282930313233343536373839public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); // 用来记录当前springboot启动耗时 stopWatch.start(); // 记录启动开始时间 DefaultBootstrapContext bootstrapContext = createBootstrapContext(); ConfigurableApplicationContext context = null; // // 它是任何spring上下文的接口，可接收任何ApplicationContext实现 configureHeadlessProperty(); // 开启了Headless模式 SpringApplicationRunListeners listeners = getRunListeners(args); // 去spring.factroies中读取SpringApplicationRunListener组件，用来发布事件或者运行监听器 listeners.starting(bootstrapContext, this.mainApplicationClass); // ApplicationStartingEvent事件，在运行开始时发送 try &#123; // 根据命令行参数实例化一个ApplicationArguments ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 基于监听器预初始化环境：读取环境变量，读取配置文件信息 ConfigurableEnvironment environment = prepareEnvironment(listeners, bootstrapContext, applicationArguments); configureIgnoreBeanInfo(environment); // 忽略beaninfo的bean Banner printedBanner = printBanner(environment); // 打印Banner横幅 context = createApplicationContext(); context.setApplicationStartup(this.applicationStartup); // 预初始化spring上下文 prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); // 加载spring ioc容器 afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, null); throw new IllegalStateException(ex); &#125; return context;&#125; 预初始化环境是基于监听器来读取环境变量和读取配置文件信息，首先根据webApplicationType创建Environment，创建就会读取Java环境变量和系统环境变量。然后将命令行参数读取环境变量中，通过发布ApplicationEnvironmentPreparedEvent监听器读取全局配置文件。 12345678910111213141516171819private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) &#123; // 根据webApplicationType创建Environment，创建就会读取：java环境变量和系统环境变量 ConfigurableEnvironment environment = getOrCreateEnvironment(); // 将命令行参数读取环境变量中 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 将@PropertieSource的配置信息放在第一位，读取配置文件@PropertieSource优先级是最低的 ConfigurationPropertySources.attach(environment); // 发布了ApplicationEnvironmentPreparedEvent的监听器读取全局配置文件 listeners.environmentPrepared(bootstrapContext, environment); // 将所有spring.main开头的配置信息绑定SpringApplication DefaultPropertiesPropertySource.moveToEnd(environment); Assert.state(!environment.containsProperty(\"spring.main.environment-prefix\"), \"Environment prefix cannot be set via properties.\"); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); // 更新PropertySources return environment;&#125; 根据应用类型创建Spring IoC上下文 1234567891011121314151617181920protected ConfigurableApplicationContext createApplicationContext() &#123; return this.applicationContextFactory.create(this.webApplicationType);&#125;public interface ApplicationContextFactory &#123; ApplicationContextFactory DEFAULT = (webApplicationType) -&gt; &#123; try &#123; switch (webApplicationType) &#123; case SERVLET: return new AnnotationConfigServletWebServerApplicationContext(); case REACTIVE: return new AnnotationConfigReactiveWebServerApplicationContext(); default: return new AnnotationConfigApplicationContext(); &#125; &#125; catch (Exception ex) &#123; throw new IllegalStateException(\"Unable create a default ApplicationContext instance, \" + \"you may need a custom ApplicationContextFactory\", ex); &#125; &#125;; ConfigurableApplicationContext create(WebApplicationType webApplicationType);&#125; 预初始化上下文，这里会发布ApplicationContextInitializedEvent事件，且设置重名的Bean不允许覆盖直接抛出异常，设置当前Spring容器是否要将所有bean设置为懒加载，然后通过AnnotatedBeanDefinitionReader的register方法将SpringApplication#run中传入的类注册到IoC容器中，读取完配置类后发布ApplicationPreparedEvent事件。 12345678910111213141516171819202122232425262728293031private void prepareContext(DefaultBootstrapContext bootstrapContext, ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); // 拿到之前读取到所有ApplicationContextInitializer的组件， 循环调用initialize方法 listeners.contextPrepared(context); // 发布了ApplicationContextInitializedEvent bootstrapContext.close(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // 获取当前spring上下文beanFactory，负责创建bean ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(\"springBootBanner\", printedBanner); &#125; // 若Spring下出现2个重名的bean, 则后读取到的会覆盖前面，SpringBoot在这里设置了不允许覆盖，当出现2个重名的bean会抛出异常 if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory).setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // 设置当前spring容器是不是要将所有的bean设置为懒加载 if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // 即传入的ElevenApplication Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); // 读取主启动类将它注册为BD、就和以前register启动类一个意思，因为后续要根据配置类解析配置的所有bean load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context); // 读取完配置类后发送ApplicationPreparedEvent&#125; 最后调用容器启动最重要的refresh()方法来完成Bean的扫描注册和实例化等工作。 123456789private void refreshContext(ConfigurableApplicationContext context) &#123; if (this.registerShutdownHook) &#123; shutdownHook.registerApplicationContext(context); &#125; refresh(context);&#125;protected void refresh(ConfigurableApplicationContext applicationContext) &#123; applicationContext.refresh();&#125; 内嵌Web容器启动内嵌Web容器的启动是在refresh()中的onRefresh()中完成的，最终调用子容器ServletWebServerApplicationContext的onRefresh()方法，从而调用createWebServer()创建Web容器。 12345678910111213141516171819202122232425262728293031public class ServletWebServerApplicationContext extends GenericWebApplicationContext implements ConfigurableWebServerApplicationContext &#123; protected void onRefresh() &#123; super.onRefresh(); try &#123; createWebServer(); &#125; catch (Throwable ex) &#123; throw new ApplicationContextException(\"Unable to start web server\", ex); &#125; &#125; private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; StartupStep createWebServer = this.getApplicationStartup().start(\"spring.boot.webserver.create\"); ServletWebServerFactory factory = getWebServerFactory(); createWebServer.tag(\"factory\", factory.getClass().toString()); this.webServer = factory.getWebServer(getSelfInitializer()); createWebServer.end(); getBeanFactory().registerSingleton(\"webServerGracefulShutdown\", new WebServerGracefulShutdownLifecycle(this.webServer)); getBeanFactory().registerSingleton(\"webServerStartStop\", new WebServerStartStopLifecycle(this, this.webServer)); &#125; else if (servletContext != null) &#123; try &#123; getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException(\"Cannot initialize servlet context\", ex); &#125; &#125; initPropertySources(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class TomcatServletWebServerFactory extends AbstractServletWebServerFactory implements ConfigurableTomcatWebServerFactory, ResourceLoaderAware &#123; public WebServer getWebServer(ServletContextInitializer... initializers) &#123; if (this.disableMBeanRegistry) &#123; Registry.disableRegistry(); &#125; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(\"tomcat\"); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); connector.setThrowOnFailure(true); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat); &#125; protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) &#123; return new TomcatWebServer(tomcat, getPort() &gt;= 0, getShutdown()); &#125;&#125;public class TomcatWebServer implements WebServer &#123; public TomcatWebServer(Tomcat tomcat, boolean autoStart, Shutdown shutdown) &#123; Assert.notNull(tomcat, \"Tomcat Server must not be null\"); this.tomcat = tomcat; this.autoStart = autoStart; this.gracefulShutdown = (shutdown == Shutdown.GRACEFUL) ? new GracefulShutdown(tomcat) : null; initialize(); &#125; private void initialize() throws WebServerException &#123; synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) &#123; removeServiceConnectors(); &#125; &#125;); this.tomcat.start(); rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; catch (NamingException ex) &#123; &#125; startDaemonAwaitThread(); &#125; catch (Exception ex) &#123; stopSilently(); destroySilently(); throw new WebServerException(\"Unable to start embedded Tomcat\", ex); &#125; &#125; &#125; private void startDaemonAwaitThread() &#123; Thread awaitThread = new Thread(\"container-\" + (containerCounter.get())) &#123; @Override public void run() &#123; TomcatWebServer.this.tomcat.getServer().await(); &#125; &#125;; awaitThread.setContextClassLoader(getClass().getClassLoader()); awaitThread.setDaemon(false); awaitThread.start(); &#125;&#125; 外部Servlet容器启动外部Servlet容器启动是通过war包以及SPI机制来完成的，SPI是一种服务发现机制，它通过在ClassPath路径下的META-INF/services文件夹查找文件，自动加载文件里所定义的类。需要将打包方式改成war包，然后将POM中Tomcat的依赖设置为不参与打包。 12345&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 当Servlet启动时回去META-INF/services文件夹中找到javax.servlet.ServletContainerInitializer，当Servlet容器启动时会去找到ServletContainerInitializer的实现类，从而创建它的实例调用onStartup方法。在Spring中ServletContainerInitializer 的实现类为SpringServletContainerInitializer，且通过@HandlesTypes(WebApplicationInitializer.class)注解将ServletContainerInitializer感兴趣的类WebApplicationInitializer传入到onStartup方法的参数中。 123456789101112131415161718192021222324252627282930313233343536public abstract class SpringBootServletInitializer implements WebApplicationInitializer &#123; protected WebApplicationContext createRootApplicationContext(ServletContext servletContext) &#123; SpringApplicationBuilder builder = createSpringApplicationBuilder(); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers(new ServletContextApplicationContextInitializer(servletContext)); builder.contextFactory((webApplicationType) -&gt; new AnnotationConfigServletWebServerApplicationContext()); builder = configure(builder); builder.listeners(new WebEnvironmentPropertySourceInitializer(servletContext)); SpringApplication application = builder.build(); if (application.getAllSources().isEmpty() &amp;&amp; MergedAnnotations.from(getClass(), SearchStrategy.TYPE_HIERARCHY).isPresent(Configuration.class)) &#123; application.addPrimarySources(Collections.singleton(getClass())); &#125; Assert.state(!application.getAllSources().isEmpty(), \"No SpringApplication sources have been defined. Either override the \" + \"configure method or add an @Configuration annotation\"); if (this.registerErrorPageFilter) &#123; application.addPrimarySources(Collections.singleton(ErrorPageFilterConfiguration.class)); &#125; application.setRegisterShutdownHook(false); return run(application); &#125; protected SpringApplicationBuilder createSpringApplicationBuilder() &#123; return new SpringApplicationBuilder(); &#125;&#125;public class SpringApplicationBuilder &#123; public SpringApplicationBuilder(Class&lt;?&gt;... sources) &#123; this.application = createSpringApplication(sources); &#125; protected SpringApplication createSpringApplication(Class&lt;?&gt;... sources) &#123; return new SpringApplication(sources); &#125;&#125; 由代码可以明显看到Tomcat不会主动去启动SpringBoot应用，而默认创建SpringApplication时什么都没有传入，故需要通过继承SpringBootServletInitializer重写configure来指定SpringBoot启动类。 123456public class TomcatStartSpringBoot extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(ElevenSpringbootApplication.class); &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yaoyinglong.github.io/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://yaoyinglong.github.io/categories/Spring/SpringBoot/"}]},{"title":"Mybatis执行SQL原理","date":"2021-10-12T16:00:00.000Z","path":"Blog/中间件/Mybatis/Mybatis执行SQL原理/","text":"Mybatis执行SQL时首先从SqlSessionFactory中获取一个SqlSession然后由SqlSession去执行具体的Mapper中映射的SQL方法。 12345678910String resource = \"mybatis-config.xml\";// 将XML配置文件构建为Configuration配置类Reader reader = Resources.getResourceAsReader(resource);// 通过加载配置文件流构建一个SqlSessionFactory DefaultSqlSessionFactorySqlSessionFactory sqlMapper = new SqlSessionFactoryBuilder().build(reader);SqlSession session = sqlMapper.openSession(); // 数据源执行器DefaultSqlSessionUser user = session.selectOne(\"com.eleven.mapper.UserMapper.selectById\", 1);// 还可以通过SqlSession获取具体的Mapper接口然后调用具体的方法。UserMapper mapper = session.getMapper(UserMapper.class);mapper.selectById(1L); 首先获取环境变量Environment，从环境变量中获取事务工厂默认的事务工厂是JdbcTransactionFactory，在通过事务工厂创建事务默认是创建JdbcTransaction。然后通过事务创建SQL执行器，默认创建SimpleExecutor。由于默认是开启二级缓存的，故这里会用CachingExecutor将SimpleExecutor装饰一遍。 1234567891011121314151617181920212223242526272829303132333435363738public class DefaultSqlSessionFactory implements SqlSessionFactory &#123; public SqlSession openSession() &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false); &#125; private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); // 获取环境变量 final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); // 获取事务工厂 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 创建一个sql执行器对象，一般情况下若Mybaits全局配置文件的cacheEnabled默认为ture就返回cacheExecutor，否则返回的就是一个SimpleExecutor final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); // 创建返回一个DefaultSqlSession对象返回 &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125;&#125;public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; // 判断执行器的类型批量的执行器 executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); // 可重复使用的执行器 &#125; else &#123; executor = new SimpleExecutor(this, transaction); // 简单的sql执行器对象 &#125; if (cacheEnabled) &#123; // 判断mybatis的全局配置文件是否开启缓存，默认开启 executor = new CachingExecutor(executor); //把当前的简单的执行器包装成一个CachingExecutor &#125; executor = (Executor) interceptorChain.pluginAll(executor); // 调用所有的拦截器对象plugin方法 return executor;&#125; 创建Executor时最终会调用超类BaseExecutor的构造方法从而创建类型为PerpetualCache的一级缓存localCache。12345678910111213141516public class SimpleExecutor extends BaseExecutor &#123; public SimpleExecutor(Configuration configuration, Transaction transaction) &#123; super(configuration, transaction); &#125;&#125;public abstract class BaseExecutor implements Executor &#123; protected BaseExecutor(Configuration configuration, Transaction transaction) &#123; this.transaction = transaction; this.deferredLoads = new ConcurrentLinkedQueue&lt;&gt;(); this.localCache = new PerpetualCache(\"LocalCache\"); this.localOutputParameterCache = new PerpetualCache(\"LocalOutputParameterCache\"); this.closed = false; this.configuration = configuration; this.wrapper = this; &#125;&#125; Executor分成CacheExecutor和普通Executor两大类，普通Executor又分SimpleExecutor、ReuseExecutor、BatchExecutor三种基本的Executor执行器。 SimpleExecutor：每执行一次update或select就开启一个Statement对象，用完立刻关闭Statement对象。 ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在则使用不存在则创建，用完后不关闭Statement对象，而是放置于Map内供下一次使用。可重复使用Statement对象。 BatchExecutor：JDBC批处理不支持select，执行update，将所有sql都添加到批处理中等待统一执行，它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理，与JDBC批处理相同。 CacheExecutor其实是封装了普通的Executor，和普通Executor区别是查询前先会查询缓存中是否存在结果，若存在则使用缓存中的结果，若不存在则使用普通Executor进行查询，再将查询出来的结果存入缓存。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class InterceptorChain &#123; private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125;&#125;public interface Interceptor &#123; default Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125;&#125;public class Plugin implements InvocationHandler &#123; private final Object target; private final Interceptor interceptor; private final Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap; private Plugin(Object target, Interceptor interceptor, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; this.target = target; this.interceptor = interceptor; this.signatureMap = signatureMap; &#125; public static Object wrap(Object target, Interceptor interceptor) &#123; Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); // 获得interceptor配置的@Signature的type Class&lt;?&gt; type = target.getClass(); // 当前代理类型 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); // 根据当前代理类型和@signature指定的type进行配对，配对成功则可以代理 if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance(type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &#123; return interceptor.intercept(new Invocation(target, method, args)); &#125; return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125; &#125; private static Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; getSignatureMap(Interceptor interceptor) &#123; Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class); if (interceptsAnnotation == null) &#123; throw new PluginException(\"No @Intercepts annotation was found in interceptor \" + interceptor.getClass().getName()); &#125; Signature[] sigs = interceptsAnnotation.value(); Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = new HashMap&lt;&gt;(); for (Signature sig : sigs) &#123; Set&lt;Method&gt; methods = signatureMap.computeIfAbsent(sig.type(), k -&gt; new HashSet&lt;&gt;()); try &#123; Method method = sig.type().getMethod(sig.method(), sig.args()); methods.add(method); &#125; catch (NoSuchMethodException e) &#123; throw new PluginException(\"Could not find method on \" + sig.type() + \" named \" + sig.method() + \". Cause: \" + e, e); &#125; &#125; return signatureMap; &#125;&#125; 创建好了SQL执行器后，通过InterceptorChain#pluginAll为SQL执行器创建拦截器代理对象，拦截器链是在全局配置文件中通过plugins标签配置的，在XML文件解析是就解析好放到Configuration#interceptorChain中。最后调用时通过责任链的方式依次调用。拦截器示例：123456789101112131415161718192021@Intercepts(&#123;@Signature(type = Executor.class, method = \"query\", args = &#123; MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;)&#125;)//@Intercepts(&#123;@Signature( type= StatementHandler.class, method = \"update\", args =&#123;Statement.class&#125;)&#125;)public class ExamplePlugin implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; System.out.println(\"代理\"); Object[] args = invocation.getArgs(); MappedStatement ms = (MappedStatement) args[0]; return invocation.proceed(); &#125; @Override public Object plugin(Object target) &#123; // new4大对象的时候调用，所以4大对象都会被代理到Plugin return Plugin.wrap(target, this); &#125; @Override public void setProperties(Properties properties) &#123; // 加载的时候调用， 设置属性初始化 System.out.println(111); &#125;&#125; sqlSession.getMapper方法，会调用Configration对象的getMapper方法，直接从缓存knownMappers中通过Mapper的class类型得到MapperProxyFactory，通过MapperProxyFactory来创建Mapper接口的动态代理类MapperProxy，MapperProxy实现了InvocationHandler接口。 1234567891011121314151617181920212223242526public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return configuration.getMapper(type, this);&#125;public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; return mapperRegistry.getMapper(type, sqlSession); // mapperRegistry实质上是一个Map，里面注册了启动过程中解析的各种Mapper.xml&#125;public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; // 直接去缓存knownMappers中通过Mapper的class类型去找mapperProxyFactory final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; // 若缓存中没有获取到，直接抛出异常 throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); // 通过MapperProxyFactory来创建实例 &#125; catch (Exception e) &#123; throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); &#125;&#125;public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); // 创建代理对象 return newInstance(mapperProxy); // 创建Mapper代理对象返回&#125;protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; // 生成Mapper接口的动态代理类MapperProxy，MapperProxy实现了InvocationHandler接口 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);&#125; 调用Mapper接口的所有方法都会先调用到动态代理类MapperProxy的invoke方法，由于Mybatis中Mapper接口没有实现类，故MapperProxy代理对象中没有委托类，MapperProxy干了代理类和委托类的事情。首先从缓存中获取调用方法的信息，若获取不到则将当前方法封装为一个MapperMethod并保存到缓存中，在构造MapperMethod时会对Mapper接口及方法进行解析，并保存到SqlCommand中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); // 判断方法是不是Object类定义的方法，若是直接通过反射调用 &#125; else if (method.isDefault()) &#123; // 是否接口的默认方法 return invokeDefaultMethod(proxy, method, args); // 调用接口中的默认方法 &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); // 把方法对象封装成一个MapperMethod对象，带有缓存作用的 return mapperMethod.execute(sqlSession, args); &#125; private MapperMethod cachedMapperMethod(Method method) &#123; return methodCache.computeIfAbsent(method, k -&gt; new MapperMethod(mapperInterface, method, sqlSession.getConfiguration())); &#125;&#125;public class MapperMethod &#123; private final SqlCommand command; // 用于保存Mapper接口方法信息 private final MethodSignature method; public MapperMethod(Class&lt;?&gt; mapperInterface, Method method, Configuration config) &#123; this.command = new SqlCommand(config, mapperInterface, method); // 创建的SqlCommand对象 this.method = new MethodSignature(config, mapperInterface, method); // 创建的方法签名对象 &#125;&#125;public static class SqlCommand &#123; // 用户保存Mapper接口方法信息 private final String name; // 接口的方法名全路径比如:com.eleven.mapper.DeptMapper.findDepts private final SqlCommandType type; // 对应接口方法操作的sql类型(是insert|update|delte|select) public SqlCommand(Configuration configuration, Class&lt;?&gt; mapperInterface, Method method) &#123; final String methodName = method.getName(); //获取的方法的名称 final Class&lt;?&gt; declaringClass = method.getDeclaringClass(); //方法所在接口的类型 // 根据接口，方法名称解析出对应的mapperStatment对象 MappedStatement ms = resolveMappedStatement(mapperInterface, methodName, declaringClass, configuration); if (ms == null) &#123; if (method.getAnnotation(Flush.class) != null) &#123; name = null; type = SqlCommandType.FLUSH; &#125; else &#123; throw new BindingException(\"Invalid bound statement (not found): \" + mapperInterface.getName() + \".\" + methodName); &#125; &#125; else &#123; name = ms.getId(); //把的mappedStatmentID（com.eleven.mapper.EmpMapper.findEmp） type = ms.getSqlCommandType(); //sql操作的类型(比如insert|delete|update|select) if (type == SqlCommandType.UNKNOWN) &#123; throw new BindingException(\"Unknown execution method for: \" + name); &#125; &#125; &#125; private MappedStatement resolveMappedStatement(Class&lt;?&gt; mapperInterface, String methodName, Class&lt;?&gt; declaringClass, Configuration configuration) &#123; String statementId = mapperInterface.getName() + \".\" + methodName; // 获取的sql对应的statmentId(com.eleven.mapper.DeptMapper.findDepts) if (configuration.hasStatement(statementId)) &#123; // 根据的statmentId判断的主配置类是否包含了的mapperStatment对象 return configuration.getMappedStatement(statementId); // 存在通过key获取对应的mapperStatment对象返回 &#125; else if (mapperInterface.equals(declaringClass)) &#123; return null; &#125; for (Class&lt;?&gt; superInterface : mapperInterface.getInterfaces()) &#123; // 获取mapper接口的父类接口 if (declaringClass.isAssignableFrom(superInterface)) &#123;//判断方法所在的类是否实现了superInterface MappedStatement ms = resolveMappedStatement(superInterface, methodName, declaringClass, configuration); //解析父类的MappedStatment对象 if (ms != null) &#123; return ms; &#125; &#125; &#125; return null; &#125;&#125; 根据解析出的SQL命令类型执行不同的逻辑，但最终都是调用SqlSession中定义的方法来完成具体的操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class MapperMethod &#123; private final SqlCommand command; // 用于保存Mapper接口方法信息 private final MethodSignature method; public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; // 判断执行sql命令的类型 case INSERT: &#123; // insert操作 Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; //update操作 Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; //delete操作 Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: //select操作 if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; //返回值为空 &#125; else if (method.returnsMany()) &#123;//返回值是一个List result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123;//返回值是一个map result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123;//返回游标 result = executeForCursor(sqlSession, args); &#125; else &#123;//查询返回单个 Object param = method.convertArgsToSqlCommandParam(args); // 解析参数 result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) &#123; result = Optional.ofNullable(result); &#125; &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\"Unknown execution method for: \" + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException(\"Mapper method '\" + command.getName() + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\"); &#125; return result; &#125;&#125; 执行具体的SQL时，首先通过statement获取启动时解析到Configuration#mappedStatements中的MappedStatement，然后调用具体SQL执行器去执行。 123456789101112131415161718192021222324252627public class DefaultSqlSession implements SqlSession &#123; public &lt;T&gt; T selectOne(String statement, Object parameter) &#123; List&lt;T&gt; list = this.selectList(statement, parameter); // 这里selectOne调用也是调用selectList方法 if (list.size() == 1) &#123; //若查询出来有且有一个一个对象，直接返回要给 return list.get(0); &#125; else if (list.size() &gt; 1) &#123; // 查询的有多个，则抛出异常 throw new TooManyResultsException(\"Expected one result (or null) to be returned by selectOne(), but found: \" + list.size()); &#125; else &#123; return null; &#125; &#125; public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter) &#123; return this.selectList(statement, parameter, RowBounds.DEFAULT); &#125; public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; // 第一步：通过statement去全局配置类中获取MappedStatement MappedStatement ms = configuration.getMappedStatement(statement); // 通过执行器去执行sql对象 第一步:包装集合类参数 第二步:一般情况下是executor为cacheExetory对象 return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125;&#125; 这里默认是CachingExecutor执行器，在通过执行器执行SQL之前，首先通过MappedStatement#getBoundSql对SQL进行解析，实际调用在解析Mapper文件阶段解析好的SqlSource的getBoundSql方法。 1234567891011121314151617181920212223242526public class CachingExecutor implements Executor &#123; public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameterObject); // 通过参数对象解析sql详细信息 CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125;&#125;public final class MappedStatement &#123; public BoundSql getBoundSql(Object parameterObject) &#123; BoundSql boundSql = sqlSource.getBoundSql(parameterObject); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings == null || parameterMappings.isEmpty()) &#123; boundSql = new BoundSql(configuration, boundSql.getSql(), parameterMap.getParameterMappings(), parameterObject); &#125; for (ParameterMapping pm : boundSql.getParameterMappings()) &#123; String rmId = pm.getResultMapId(); if (rmId != null) &#123; ResultMap rm = configuration.getResultMap(rmId); if (rm != null) &#123; hasNestedResultMaps |= rm.hasNestedResultMaps(); &#125; &#125; &#125; return boundSql; &#125;&#125; 对于SqlSource主要是封装动态SQL的DynamicSqlSource、封装@SelectProvider等一些类注解方法解析的SQL的ProviderSqlSource、封装静态SQL的RawSqlSource、封装静态SQL的StaticSqlSource四个实现类。对于静态SQL是使用RawSqlSource来进行封装，但RawSqlSource内部通过SqlSourceBuilder将其转换成了StaticSqlSource，转换过程中会将#{..}解析替换成?，并将参数映射关系保存到StaticSqlSource#parameterMappings中。 12345678910111213141516171819202122232425262728public class RawSqlSource implements SqlSource &#123; private final SqlSource sqlSource; public RawSqlSource(Configuration configuration, SqlNode rootSqlNode, Class&lt;?&gt; parameterType) &#123; this(configuration, getSql(configuration, rootSqlNode), parameterType); &#125; public RawSqlSource(Configuration configuration, String sql, Class&lt;?&gt; parameterType) &#123; SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; clazz = parameterType == null ? Object.class : parameterType; sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;&gt;()); &#125; private static String getSql(Configuration configuration, SqlNode rootSqlNode) &#123; DynamicContext context = new DynamicContext(configuration, null); rootSqlNode.apply(context); return context.getSql(); &#125; @Override public BoundSql getBoundSql(Object parameterObject) &#123; return sqlSource.getBoundSql(parameterObject); &#125;&#125;public class SqlSourceBuilder extends BaseBuilder &#123; public SqlSource parse(String originalSql, Class&lt;?&gt; parameterType, Map&lt;String, Object&gt; additionalParameters) &#123; ParameterMappingTokenHandler handler = new ParameterMappingTokenHandler(configuration, parameterType, additionalParameters); GenericTokenParser parser = new GenericTokenParser(\"#&#123;\", \"&#125;\", handler); String sql = parser.parse(originalSql); return new StaticSqlSource(configuration, sql, handler.getParameterMappings()); &#125;&#125; 对于动态SQL被封装为DynamicSqlSource，然后通过SqlNode的apply进行SQL解析，对于动态SQL来说最外层的SqlNode一般为MixedSqlNode，最终遍历调用具体SqlNode的apply方法，主要完成将动态SQL根据传入的参数值确定为静态SQL，且将${...}替换为具体的值，从而完成动态SQL的解析。接下来通过SqlSourceBuilder#parse将#{..}解析替换成?，并将参数映射关系保存到StaticSqlSource#parameterMappings中。 1234567891011121314151617181920public class DynamicSqlSource implements SqlSource &#123; private final Configuration configuration; private final SqlNode rootSqlNode; public BoundSql getBoundSql(Object parameterObject) &#123; DynamicContext context = new DynamicContext(configuration, parameterObject); rootSqlNode.apply(context); SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); BoundSql boundSql = sqlSource.getBoundSql(parameterObject); context.getBindings().forEach(boundSql::setAdditionalParameter); return boundSql; &#125;&#125;public class MixedSqlNode implements SqlNode &#123; public boolean apply(DynamicContext context) &#123; contents.forEach(node -&gt; node.apply(context)); return true; &#125;&#125; 当SQL解析成静态SQL后，则开始通过CachingExecutor先判断是否开启了二级缓存，若开启了二级缓存，先判断是否需要刷新缓存，判断依据是在解析阶段判断SQL的类型是否为SELECT查询，若不为查询则需要刷新缓存，然后从缓存中获取数据，若缓存中没有获取到数据再通过执行器去查询数据，并将数据缓存到二级缓存中。 123456789101112131415161718public class CachingExecutor implements Executor &#123; public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); // 判断mapper中是否开启了二级缓存&lt;cache&gt;&lt;/cache&gt; if (cache != null) &#123; // 判断是否配置了cache flushCacheIfRequired(ms); // 判断是否需要刷新缓存 if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, boundSql); List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); // 先去二级缓存中获取 if (list == null) &#123; // 二级缓存中没有获取到，通过查询数据库去查询 list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // 加入到二级缓存中 &#125; return list; &#125; &#125; return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); // 没有整合二级缓存，直接去查询 &#125;&#125; 会先判断是否为SELECT查询，若不是则需要清空一级缓存中的数据，然后从一级换中获取数据，若获取不到再真正通过执行器获取数据，且将查询后的数据缓存到一级缓存中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class BaseExecutor implements Executor &#123; public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); if (closed) &#123; // 已经关闭，则抛出 ExecutorException 异常 throw new ExecutorException(\"Executor was closed.\"); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); // 清空本地缓存，若queryStack为零，并要求清空本地缓存 &#125; List&lt;E&gt; list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; // 从一级缓存中，获取查询结果 if (list != null) &#123; // 获取到，则进行处理 handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123;// 获得不到，则从数据库中查询 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; if (queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; clearLocalCache(); &#125; &#125; return list; &#125; private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list; &#125;&#125; 最终调用SimpleExecutor中的执行方法，首先会先创建一个StatementHandler其封装了JDBC Statement操作，负责对JDBC statement如设置参数将Statement结果集转换成List集合等操作。具体的StatementHandler的创建是委托给RoutingStatementHandler通过statementType去创建具体的StatementHandler。支持SimpleStatementHandler、PreparedStatementHandler、CallableStatementHandler三种StatementHandler。Mybatis默认使用PreparedStatementHandler。创建完成StatementHandler后会为其创建拦截器链。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class SimpleExecutor extends BaseExecutor &#123; public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125; &#125; private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; Connection connection = getConnection(statementLog); stmt = handler.prepare(connection, transaction.getTimeout()); handler.parameterize(stmt); return stmt; &#125;&#125;public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125;public class RoutingStatementHandler implements StatementHandler &#123; private final StatementHandler delegate; public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; switch (ms.getStatementType()) &#123; case STATEMENT: delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case PREPARED: delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case CALLABLE: delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; default: throw new ExecutorException(\"Unknown statement type: \" + ms.getStatementType()); &#125; &#125;&#125;public class PreparedStatementHandler extends BaseStatementHandler &#123; public PreparedStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; super(executor, mappedStatement, parameter, rowBounds, resultHandler, boundSql); &#125;&#125; 通过StatementHandler的prepare生成具体的Statement。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public abstract class BaseStatementHandler implements StatementHandler &#123; protected BaseStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; this.configuration = mappedStatement.getConfiguration(); this.executor = executor; this.mappedStatement = mappedStatement; this.rowBounds = rowBounds; this.typeHandlerRegistry = configuration.getTypeHandlerRegistry(); this.objectFactory = configuration.getObjectFactory(); if (boundSql == null) &#123; // issue #435, get the key before calculating the statement generateKeys(parameterObject); boundSql = mappedStatement.getBoundSql(parameterObject); &#125; this.boundSql = boundSql; this.parameterHandler = configuration.newParameterHandler(mappedStatement, parameterObject, boundSql); this.resultSetHandler = configuration.newResultSetHandler(executor, mappedStatement, rowBounds, parameterHandler, resultHandler, boundSql); &#125; public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException &#123; ErrorContext.instance().sql(boundSql.getSql()); Statement statement = null; try &#123; statement = instantiateStatement(connection); setStatementTimeout(statement, transactionTimeout); setFetchSize(statement); return statement; &#125; catch (SQLException e) &#123; closeStatement(statement); throw e; &#125; catch (Exception e) &#123; closeStatement(statement); throw new ExecutorException(\"Error preparing statement. Cause: \" + e, e); &#125; &#125;&#125;public class PreparedStatementHandler extends BaseStatementHandler &#123; protected Statement instantiateStatement(Connection connection) throws SQLException &#123; String sql = boundSql.getSql(); if (mappedStatement.getKeyGenerator() instanceof Jdbc3KeyGenerator) &#123; String[] keyColumnNames = mappedStatement.getKeyColumns(); if (keyColumnNames == null) &#123; return connection.prepareStatement(sql, PreparedStatement.RETURN_GENERATED_KEYS); &#125; else &#123; return connection.prepareStatement(sql, keyColumnNames); &#125; &#125; else if (mappedStatement.getResultSetType() == ResultSetType.DEFAULT) &#123; return connection.prepareStatement(sql); &#125; else &#123; return connection.prepareStatement(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); &#125; &#125;&#125; 对于参数的设置以及结果的处理，StatementHandler的parameterize为Statement设置具体SQL执行的参数，在执行查询方法时对结果进行处理，是通过在实例化具体的StatementHandler时，调用超类BaseStatementHandler中的构造方法去创建ParameterHandler和ResultSetHandler分别对参数和结果数据进行处理。 123456789101112131415161718192021222324252627public class PreparedStatementHandler extends BaseStatementHandler &#123; public PreparedStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; super(executor, mappedStatement, parameter, rowBounds, resultHandler, boundSql); &#125; public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement) statement; ps.execute(); return resultSetHandler.handleResultSets(ps); &#125;&#125;public abstract class BaseStatementHandler implements StatementHandler &#123; protected BaseStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; this.configuration = mappedStatement.getConfiguration(); this.executor = executor; this.mappedStatement = mappedStatement; this.rowBounds = rowBounds; this.typeHandlerRegistry = configuration.getTypeHandlerRegistry(); this.objectFactory = configuration.getObjectFactory(); if (boundSql == null) &#123; generateKeys(parameterObject); boundSql = mappedStatement.getBoundSql(parameterObject); &#125; this.boundSql = boundSql; this.parameterHandler = configuration.newParameterHandler(mappedStatement, parameterObject, boundSql); this.resultSetHandler = configuration.newResultSetHandler(executor, mappedStatement, rowBounds, parameterHandler, resultHandler, boundSql); &#125;&#125; ParameterHandler负责将传递的参数转换成JDBC Statement所需参数，创建ParameterHandler是通过LanguageDriver中的方法来创建的，在进行参数处理时是通过setParameters来完成的，在该方法中会先确定参数类型，最终通过TypeHandler调用具体TypeHandler的setNonNullParameter方法，创建完成后跟执行器一样会创建拦截器链。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class Configuration &#123; public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler; &#125;&#125;public class XMLLanguageDriver implements LanguageDriver &#123; public ParameterHandler createParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; return new DefaultParameterHandler(mappedStatement, parameterObject, boundSql); &#125;&#125;public class DefaultParameterHandler implements ParameterHandler &#123; public DefaultParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; this.mappedStatement = mappedStatement; this.configuration = mappedStatement.getConfiguration(); this.typeHandlerRegistry = mappedStatement.getConfiguration().getTypeHandlerRegistry(); this.parameterObject = parameterObject; this.boundSql = boundSql; &#125; public void setParameters(PreparedStatement ps) &#123; ErrorContext.instance().activity(\"setting parameters\").object(mappedStatement.getParameterMap().getId()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings != null) &#123; for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; // issue #448 ask first for additional params value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; TypeHandler typeHandler = parameterMapping.getTypeHandler(); JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null &amp;&amp; jdbcType == null) &#123; jdbcType = configuration.getJdbcTypeForNull(); &#125; try &#123; typeHandler.setParameter(ps, i + 1, value, jdbcType); &#125; catch (TypeException | SQLException e) &#123; throw new TypeException(\"Could not set parameters for mapping: \" + parameterMapping + \". Cause: \" + e, e); &#125; &#125; &#125; &#125; &#125;&#125;public void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException &#123; if (parameter == null) &#123; if (jdbcType == null) &#123; throw new TypeException(\"JDBC requires that the JdbcType must be specified for all nullable parameters.\"); &#125; try &#123; ps.setNull(i, jdbcType.TYPE_CODE); &#125; catch (SQLException e) &#123; throw new TypeException(\"Error setting null for parameter #\" + i + \" with JdbcType \" + jdbcType + \" . Try setting a different JdbcType for this parameter or a different jdbcTypeForNull configuration property. Cause: \" + e, e); &#125; &#125; else &#123; try &#123; setNonNullParameter(ps, i, parameter, jdbcType); &#125; catch (Exception e) &#123; throw new TypeException(\"Error setting non null for parameter #\" + i + \" with JdbcType \" + jdbcType + \" . Try setting a different JdbcType for this parameter or a different configuration property. Cause: \" + e, e); &#125; &#125;&#125;public class LongTypeHandler extends BaseTypeHandler&lt;Long&gt; &#123; public void setNonNullParameter(PreparedStatement ps, int i, Long parameter, JdbcType jdbcType) throws SQLException &#123; ps.setLong(i, parameter); &#125;&#125; ResultSetHandler负责将JDBC返回的ResultSet结果集对象转换成具体设置的对象，创建ResultSetHandler是直接new一个默认的DefaultResultSetHandler，对结果数据的处理是最终会调用handleResultSets来完成，创建完成后同样会创建拦截器链。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Configuration &#123; public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler; &#125;&#125;public class DefaultResultSetHandler implements ResultSetHandler &#123; public DefaultResultSetHandler(Executor executor, MappedStatement mappedStatement, ParameterHandler parameterHandler, ResultHandler&lt;?&gt; resultHandler, BoundSql boundSql, RowBounds rowBounds) &#123; this.executor = executor; this.configuration = mappedStatement.getConfiguration(); this.mappedStatement = mappedStatement; this.rowBounds = rowBounds; this.parameterHandler = parameterHandler; this.boundSql = boundSql; this.typeHandlerRegistry = configuration.getTypeHandlerRegistry(); this.objectFactory = configuration.getObjectFactory(); this.reflectorFactory = configuration.getReflectorFactory(); this.resultHandler = resultHandler; &#125; public List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException &#123; ErrorContext.instance().activity(\"handling results\").object(mappedStatement.getId()); final List&lt;Object&gt; multipleResults = new ArrayList&lt;&gt;(); int resultSetCount = 0; ResultSetWrapper rsw = getFirstResultSet(stmt); List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) &#123; ResultMap resultMap = resultMaps.get(resultSetCount); handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; String[] resultSets = mappedStatement.getResultSets(); if (resultSets != null) &#123; while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) &#123; ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) &#123; String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); &#125; rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; &#125; return collapseSingleResultList(multipleResults); &#125;&#125;","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://yaoyinglong.github.io/tags/Mybatis/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Mybatis","slug":"中间件/Mybatis","permalink":"https://yaoyinglong.github.io/categories/中间件/Mybatis/"}]},{"title":"Mybatis集成到Spring原理","date":"2021-10-12T16:00:00.000Z","path":"Blog/中间件/Mybatis/Mybatis集成到Spring原理/","text":"Spring中集成Mybatis主要有两个难点，一是事务的集成，二是Mapper接口注册到Spring容器中，Spring中集成Mybatis需要引入mybatis和mybatis-spring依赖包。 12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt; 通过配置导入将SqlSessionFactoryBean注册到Spring容器中，以及通过@MapperScan或@MapperScans确定将哪些Mapper接口注册到Spring容器中。 123456789101112@Configuration@MapperScan(basePackages = &#123;\"com.eleven.icode.ispring.mapper\"&#125;)public class MyBatisConfig &#123; @Bean public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource) throws IOException &#123; SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(dataSource); factoryBean.setConfigLocation(new ClassPathResource(\"mybatis-config.xml\")); factoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\"classpath:mapper/*.xml\")); return factoryBean; &#125;&#125; SqlSessionFactoryBean是一个FactoryBean，且重写了getObjectType方法将代理的Bean的类型设置为了原始的SqlSessionFactory类型，且其实现了InitializingBean接口，主要逻辑都在其实例化完成时调用的afterPropertiesSet()，其作用就是创建Mybatis的SqlSessionFactory，其可以代替全局配置文件，若设置了配置文件可对配置文件内容做一个补充。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123; private SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); public void afterPropertiesSet() throws Exception &#123; notNull(dataSource, \"Property 'dataSource' is required\"); notNull(sqlSessionFactoryBuilder, \"Property 'sqlSessionFactoryBuilder' is required\"); state((configuration == null &amp;&amp; configLocation == null) || !(configuration != null &amp;&amp; configLocation != null), \"Property 'configuration' and 'configLocation' can not specified with together\"); this.sqlSessionFactory = buildSqlSessionFactory(); // 通过sqlSessionFactoryBuilder来构建我们的sqlSessionFactory &#125; protected SqlSessionFactory buildSqlSessionFactory() throws Exception &#123; final Configuration targetConfiguration; // 声明一个Configuration对象用于保存mybatis的所有的配置信息 XMLConfigBuilder xmlConfigBuilder = null; // 初始化configuration对象，和设置其 `configuration.variables` 属性 if (this.configuration != null) &#123; // 把配置的SqlSessionFactoryBean配置的configuration赋值给targetConfiguration targetConfiguration = this.configuration; if (targetConfiguration.getVariables() == null) &#123; targetConfiguration.setVariables(this.configurationProperties); &#125; else if (this.configurationProperties != null) &#123; targetConfiguration.getVariables().putAll(this.configurationProperties); &#125; &#125; else if (this.configLocation != null) &#123; // 创建xml配置构建器对象，对全局配置文件mybatis-config.xml配置文件进行解析 xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties); targetConfiguration = xmlConfigBuilder.getConfiguration(); &#125; else &#123; targetConfiguration = new Configuration(); // 判断configurationProperties不为空，则调用targetConfiguration.set方法把configurationProperties注入到Configuration对象中 Optional.ofNullable(this.configurationProperties).ifPresent(targetConfiguration::setVariables); &#125; Optional.ofNullable(this.objectFactory).ifPresent(targetConfiguration::setObjectFactory); Optional.ofNullable(this.objectWrapperFactory).ifPresent(targetConfiguration::setObjectWrapperFactory); Optional.ofNullable(this.vfs).ifPresent(targetConfiguration::setVfsImpl); // typeAliasesPackage配置情况分为二种：在mybaits-config.xml中配置，在配置SqlSessionFactoryBean时配置 if (hasLength(this.typeAliasesPackage)) &#123; // 扫描typeAliasesPackage包路径下所有实体类class类型进行过滤注册到Configuration的别名映射器中 scanClasses(this.typeAliasesPackage, this.typeAliasesSuperType).stream() .filter(clazz -&gt; !clazz.isAnonymousClass()).filter(clazz -&gt; !clazz.isInterface()) .filter(clazz -&gt; !clazz.isMemberClass()).forEach(targetConfiguration.getTypeAliasRegistry()::registerAlias); &#125; // 判断SqlSessionFactory是否配置了typeAliases，一般typeAliasesPackage配置了就没有必要配置typeAliases，注册到Configuration的别名映射器中 if (!isEmpty(this.typeAliases)) &#123; Stream.of(this.typeAliases).forEach(typeAlias -&gt; &#123; targetConfiguration.getTypeAliasRegistry().registerAlias(typeAlias);&#125;); &#125; // 把自定义的插件注册到的mybatis的配置类上 if (!isEmpty(this.plugins)) &#123; Stream.of(this.plugins).forEach(plugin -&gt; &#123; targetConfiguration.addInterceptor(plugin);&#125;); &#125; // 扫描自定义的类型处理器(用来处理的java类型和数据库类型的转化) 并且注册到的 targetConfiguration(批量注册) if (hasLength(this.typeHandlersPackage)) &#123; scanClasses(this.typeHandlersPackage, TypeHandler.class).stream().filter(clazz -&gt; !clazz.isAnonymousClass()) .filter(clazz -&gt; !clazz.isInterface()).filter(clazz -&gt; !Modifier.isAbstract(clazz.getModifiers())) .forEach(targetConfiguration.getTypeHandlerRegistry()::register); &#125; if (!isEmpty(this.typeHandlers)) &#123; // 通过配置&lt;TypeHandlers&gt;&lt;/TypeHandlers&gt;的形式来注册的类型处理器对象 Stream.of(this.typeHandlers).forEach(typeHandler -&gt; &#123; targetConfiguration.getTypeHandlerRegistry().register(typeHandler);&#125;); &#125; // Mybatis从3.2开始支持可插拔的脚本语言，因此可插入一种语言的驱动来写基于这种语言的动态SQL查询 if (!isEmpty(this.scriptingLanguageDrivers)) &#123; Stream.of(this.scriptingLanguageDrivers).forEach(languageDriver -&gt; &#123; targetConfiguration.getLanguageRegistry().register(languageDriver);&#125;); &#125; Optional.ofNullable(this.defaultScriptingLanguageDriver).ifPresent(targetConfiguration::setDefaultScriptingLanguage); if (this.databaseIdProvider != null) &#123; // 设置数据库厂商 try &#123; targetConfiguration.setDatabaseId(this.databaseIdProvider.getDatabaseId(this.dataSource)); &#125; catch (SQLException e) &#123; throw new NestedIOException(\"Failed getting a databaseId\", e); &#125; &#125; Optional.ofNullable(this.cache).ifPresent(targetConfiguration::addCache); // 若二级缓存不为空，注册二级缓存 if (xmlConfigBuilder != null) &#123; try &#123; xmlConfigBuilder.parse(); // 真正的解析的配置(mybatis-config.xml)的document对象 &#125; catch (Exception ex) &#123; throw new NestedIOException(\"Failed to parse config resource: \" + this.configLocation, ex); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; // 为的configuration设置一个环境变量 targetConfiguration.setEnvironment(new Environment(this.environment, this.transactionFactory == null ? new SpringManagedTransactionFactory() : this.transactionFactory, this.dataSource)); if (this.mapperLocations != null) &#123; // 循环遍历解析mapper.xml文件 if (this.mapperLocations.length == 0) &#123; &#125; else &#123; for (Resource mapperLocation : this.mapperLocations) &#123; if (mapperLocation == null) &#123; continue; &#125; try &#123; XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(mapperLocation.getInputStream(), targetConfiguration, mapperLocation.toString(), targetConfiguration.getSqlFragments()); xmlMapperBuilder.parse(); // 真正的解析mapper.xml文件 &#125; catch (Exception e) &#123; throw new NestedIOException(\"Failed to parse mapping resource: '\" + mapperLocation + \"'\", e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; &#125; &#125; return this.sqlSessionFactoryBuilder.build(targetConfiguration); // 通过建造者模式构建的SqlSessionFactory对象 默认是DefaultSqlSessionFactory &#125; private Set&lt;Class&lt;?&gt;&gt; scanClasses(String packagePatterns, Class&lt;?&gt; assignableType) throws IOException &#123; Set&lt;Class&lt;?&gt;&gt; classes = new HashSet&lt;&gt;(); // 把的多个配置报路径转换成字符串数组 String[] packagePatternArray = tokenizeToStringArray(packagePatterns, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); for (String packagePattern : packagePatternArray) &#123; // 循环的包路径 // 把包路径下的class解析成的Resouce数组 Resource[] resources = RESOURCE_PATTERN_RESOLVER.getResources(ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + ClassUtils.convertClassNameToResourcePath(packagePattern) + \"/**/*.class\"); for (Resource resource : resources) &#123; try &#123;// 挨个解析成的class类型 ClassMetadata classMetadata = METADATA_READER_FACTORY.getMetadataReader(resource).getClassMetadata(); Class&lt;?&gt; clazz = Resources.classForName(classMetadata.getClassName()); if (assignableType == null || assignableType.isAssignableFrom(clazz)) &#123; // 判断当前的class类型是不是被支持 classes.add(clazz); // 加入到结合中 &#125; &#125; catch (Throwable e) &#123; LOGGER.warn(() -&gt; \"Cannot load the '\" + resource + \"'. Cause by \" + e.toString()); &#125; &#125; &#125; return classes; &#125; public Class&lt;? extends SqlSessionFactory&gt; getObjectType() &#123; return this.sqlSessionFactory == null ? SqlSessionFactory.class : this.sqlSessionFactory.getClass(); &#125;&#125; 事务集成事务集成是在SqlSessionFactoryBean中完成的，在为configuration设置环境变量时创建传入SpringManagedTransactionFactory，在Mybatis中是使用的ManagedTransactionFactory创建一个ManagedTransaction，其是直接从DataSource中获取的Connection。 123456789101112131415161718192021222324252627282930public class DefaultSqlSessionFactory implements SqlSessionFactory &#123; private TransactionFactory getTransactionFactoryFromEnvironment(Environment environment) &#123; if (environment == null || environment.getTransactionFactory() == null) &#123; return new ManagedTransactionFactory(); &#125; return environment.getTransactionFactory(); &#125;&#125;public class ManagedTransactionFactory implements TransactionFactory &#123; public Transaction newTransaction(Connection conn) &#123; return new ManagedTransaction(conn, closeConnection); &#125; public Transaction newTransaction(DataSource ds, TransactionIsolationLevel level, boolean autoCommit) &#123; return new ManagedTransaction(ds, level, closeConnection); &#125;&#125;public class ManagedTransaction implements Transaction &#123; public Connection getConnection() throws SQLException &#123; if (this.connection == null) &#123; openConnection(); &#125; return this.connection; &#125; protected void openConnection() throws SQLException &#123; this.connection = this.dataSource.getConnection(); if (this.level != null) &#123; this.connection.setTransactionIsolation(this.level.getLevel()); &#125; &#125;&#125; SpringManagedTransactionFactory中创建的是SpringManagedTransaction，起获取的数据库连接是通过DataSourceUtils工具类从事务同步管理器TransactionSynchronizationManager中获取的连接，从而达到与Spring事务集成的目的。 123456789101112131415161718public class SpringManagedTransactionFactory implements TransactionFactory &#123; public Transaction newTransaction(DataSource dataSource, TransactionIsolationLevel level, boolean autoCommit) &#123; return new SpringManagedTransaction(dataSource); &#125;&#125;public class SpringManagedTransaction implements Transaction &#123; public Connection getConnection() throws SQLException &#123; if (this.connection == null) &#123; openConnection(); &#125; return this.connection; &#125; private void openConnection() throws SQLException &#123; this.connection = DataSourceUtils.getConnection(this.dataSource); this.autoCommit = this.connection.getAutoCommit(); this.isConnectionTransactional = DataSourceUtils.isConnectionTransactional(this.connection, this.dataSource); &#125;&#125; Mapper接口注册Mapper接口扫描是通过@MapperScan和@MapperScans注解中导入了MapperScannerRegistrar来完成的，Mapper接口注册到Spring容器中是借助FactoryBean来完成的，注解中设置了factoryBean注册Mapper接口的默认值为MapperFactoryBean。 123456789101112131415161718192021222324@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.class)@Repeatable(MapperScans.class)public @interface MapperScan &#123; String[] value() default &#123;&#125;; String[] basePackages() default &#123;&#125;; Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;; Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; Class&lt;? extends Annotation&gt; annotationClass() default Annotation.class; Class&lt;?&gt; markerInterface() default Class.class; String sqlSessionTemplateRef() default \"\"; String sqlSessionFactoryRef() default \"\"; Class&lt;? extends MapperFactoryBean&gt; factoryBean() default MapperFactoryBean.class; String lazyInitialization() default \"\";&#125;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.RepeatingRegistrar.class)public @interface MapperScans &#123; MapperScan[] value();&#125; MapperScannerRegistrar实现了ImportBeanDefinitionRegistrar在容器扫描BeanDefinition时会调用registerBeanDefinitions。其作用其实就是为容器注册一个或多个MapperScannerConfigurer以及给该类设置一些从@MapperScan注解上解析出来的属性。@MapperScans注解上可以配置多个@MapperScan注解在导入时通过RepeatingRegistrar遍历注册多个MapperScannerConfigurer。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 从传入的配置类中解析@MapperScan注解信息，把MapperScan注解的属性转化为AnnotationAttributes类型 AnnotationAttributes mapperScanAttrs = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); if (mapperScanAttrs != null) &#123; // 若上一步解析出来的mapperScanAttrs不为空，说明配置类上加了@MapperScan注解 // 调用重写的方法registerBeanDefinitions#generateBaseBeanName(importingClassMetadata, 0)即将注册的bean定义的名称进行处理 registerBeanDefinitions(mapperScanAttrs, registry, generateBaseBeanName(importingClassMetadata, 0)); &#125; &#125; void registerBeanDefinitions(AnnotationAttributes annoAttrs, BeanDefinitionRegistry registry, String beanName) &#123; // 创建bean定义构造器通过够构造器来构建出的bean定义&lt;MapperScannerConfigurer&gt;应用到的设计模式[建造者模式] BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class); // 手动为MapperScannerConfigurer开启processPropertyPlaceHolders属性为true，需要着重研究下MapperScannerConfigurer类的继承结构 builder.addPropertyValue(\"processPropertyPlaceHolders\", true); // 为的MapperScannerConfigurer解析@MapperScanner指定扫描的的注解类型 Class&lt;? extends Annotation&gt; annotationClass = annoAttrs.getClass(\"annotationClass\"); if (!Annotation.class.equals(annotationClass)) &#123; builder.addPropertyValue(\"annotationClass\", annotationClass); &#125; Class&lt;?&gt; markerInterface = annoAttrs.getClass(\"markerInterface\"); if (!Class.class.equals(markerInterface)) &#123; // 是否配置了标记接口 builder.addPropertyValue(\"markerInterface\", markerInterface); &#125; Class&lt;? extends BeanNameGenerator&gt; generatorClass = annoAttrs.getClass(\"nameGenerator\"); if (!BeanNameGenerator.class.equals(generatorClass)) &#123; // 是否设置了MapperScannerConfigurer的beanName生成器对象 builder.addPropertyValue(\"nameGenerator\", BeanUtils.instantiateClass(generatorClass)); &#125; // 解析@MapperScan注解属性MapperFactoryBean设置到MapperScannerConfigurer声明一个自定义的MapperFactoryBean返回一个代理对象 Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = annoAttrs.getClass(\"factoryBean\"); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) &#123; builder.addPropertyValue(\"mapperFactoryBeanClass\", mapperFactoryBeanClass); &#125; // 解析@MapperScan的sqlSessionTemplateRef到底使用是哪个sqlSessionTemplate设置到MapperScannerConfigurer多数据源的情况下需要指定 String sqlSessionTemplateRef = annoAttrs.getString(\"sqlSessionTemplateRef\"); if (StringUtils.hasText(sqlSessionTemplateRef)) &#123; builder.addPropertyValue(\"sqlSessionTemplateBeanName\", annoAttrs.getString(\"sqlSessionTemplateRef\")); &#125; // 解析@MapperScan的sqlSessionFactoryRef属性 设置到 MapperScannerConfigurer 多数据情况下的话 ，需要指定使用哪个 sqlSessionFactory String sqlSessionFactoryRef = annoAttrs.getString(\"sqlSessionFactoryRef\"); if (StringUtils.hasText(sqlSessionFactoryRef)) &#123; builder.addPropertyValue(\"sqlSessionFactoryBeanName\", annoAttrs.getString(\"sqlSessionFactoryRef\")); &#125; // 解析@MapperScan扫描的的包或者是class对象 List&lt;String&gt; basePackages = new ArrayList&lt;&gt;(); basePackages.addAll(Arrays.stream(annoAttrs.getStringArray(\"value\")).filter(StringUtils::hasText).collect(Collectors.toList())); basePackages.addAll(Arrays.stream(annoAttrs.getStringArray(\"basePackages\")).filter(StringUtils::hasText).collect(Collectors.toList())); basePackages.addAll(Arrays.stream(annoAttrs.getClassArray(\"basePackageClasses\")).map(ClassUtils::getPackageName).collect(Collectors.toList())); String lazyInitialization = annoAttrs.getString(\"lazyInitialization\"); if (StringUtils.hasText(lazyInitialization)) &#123;// 指定MapperScannerConfigurer是否为懒加载 builder.addPropertyValue(\"lazyInitialization\", lazyInitialization); &#125; builder.addPropertyValue(\"basePackage\", StringUtils.collectionToCommaDelimitedString(basePackages)); registry.registerBeanDefinition(beanName, builder.getBeanDefinition()); // 为的容器中注册了MapperScannerConfigurer的接口 &#125; private static String generateBaseBeanName(AnnotationMetadata importingClassMetadata, int index) &#123; return importingClassMetadata.getClassName() + \"#\" + MapperScannerRegistrar.class.getSimpleName() + \"#\" + index; &#125; static class RepeatingRegistrar extends MapperScannerRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AnnotationAttributes mapperScansAttrs = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(MapperScans.class.getName())); if (mapperScansAttrs != null) &#123; AnnotationAttributes[] annotations = mapperScansAttrs.getAnnotationArray(\"value\"); for (int i = 0; i &lt; annotations.length; i++) &#123; registerBeanDefinitions(annotations[i], registry, generateBaseBeanName(importingClassMetadata, i)); &#125; &#125; &#125; &#125;&#125; MapperScannerConfigurer中显示创建了ClassPathMapperScanner包扫描器对象，其继承自ClassPathBeanDefinitionScanner，其作用是为了扫描@MapperScan注解中配置包路径下的目标类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware &#123; public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; if (this.processPropertyPlaceHolders) &#123; processPropertyPlaceHolders(); // 若MapperScannerConfigurer属性的processPropertyPlaceHolders为ture时则执行processPropertyPlaceHolders()，解析动态参数 &#125; // 显示的new一个ClassPathMapperScanner包扫描器对象该对象继承了spring的ClassPathBeanDefinitionScanner为了扫描器指定@MapperScan属性 ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass); if (StringUtils.hasText(lazyInitialization)) &#123; scanner.setLazyInitialization(Boolean.valueOf(lazyInitialization)); &#125; scanner.registerFilters(); // 注册扫描规则过滤器 // 真正的去扫描@MapperScan指定的路径下的bean定义信息，先会去调用ClassPathMapperScanner.scan()方法 scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS)); &#125; private void processPropertyPlaceHolders() &#123; // 因为postProcessBeanDefinitionRegistry是为注册bean定义的，但注册bean定义时需要解析$&#123;basepackaage&#125;，但PropertyResourceConfigurer类型的bean定义还没有实例化成bean对象 ，故不能提供解析$&#123;basepackaage&#125;的能力 // 故显示的设置processPropertyPlaceHolders为ture，即想通过applicationContext.getBeansOfType(PropertyResourceConfigurer.class)，提前把PropertyResourceConfigurer组件实例化出来从而解析$&#123;basepackaage&#125; Map&lt;String, PropertyResourceConfigurer&gt; prcs = applicationContext.getBeansOfType(PropertyResourceConfigurer.class); // 判断PropertyResourceConfigurer的集合不为空，且applicationContext是ConfigurableApplicationContext if (!prcs.isEmpty() &amp;&amp; applicationContext instanceof ConfigurableApplicationContext) &#123; // 通过名称去容器中获取MapperScannerConfigurer组件 BeanDefinition mapperScannerBean = ((ConfigurableApplicationContext) applicationContext).getBeanFactory().getBeanDefinition(beanName); // PropertyResourceConfigurer类没有暴露任何的方法来处理的property placeholder substitution即$&#123;basepackaage&#125;，有且只有提供一个BeanFactoryPostProcessor接口来处理的bean定义 // 但调用BeanFactoryPostProcessor.postProcessBeanFactory()方法需要一个beanFactory，若从外面传入一个Ioc的容器进来会提前破坏ioc容器，故这里创建了一个临时的ioc容器，然后把mapperScannerBean注册到该临时ioc容器中 DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); factory.registerBeanDefinition(beanName, mapperScannerBean); for (PropertyResourceConfigurer prc : prcs.values()) &#123; prc.postProcessBeanFactory(factory); //这时就可以大胆放心的处理临时的ioc容器factory中的bean定义，即当前的mapperScannerBean &#125; PropertyValues values = mapperScannerBean.getPropertyValues(); // 处理完之后重新获取通过PropertyResourceConfigurer解析后的mapperScannerBean的属性 this.basePackage = updatePropertyValue(\"basePackage\", values); // 更新MapperScannerBean属性可能有$&#123;&#125;包裹的字段 this.sqlSessionFactoryBeanName = updatePropertyValue(\"sqlSessionFactoryBeanName\", values); this.sqlSessionTemplateBeanName = updatePropertyValue(\"sqlSessionTemplateBeanName\", values); this.lazyInitialization = updatePropertyValue(\"lazyInitialization\", values); &#125; this.basePackage = Optional.ofNullable(this.basePackage).map(getEnvironment()::resolvePlaceholders).orElse(null); this.sqlSessionFactoryBeanName = Optional.ofNullable(this.sqlSessionFactoryBeanName).map(getEnvironment()::resolvePlaceholders).orElse(null); this.sqlSessionTemplateBeanName = Optional.ofNullable(this.sqlSessionTemplateBeanName).map(getEnvironment()::resolvePlaceholders).orElse(null); this.lazyInitialization = Optional.ofNullable(this.lazyInitialization).map(getEnvironment()::resolvePlaceholders).orElse(null); &#125;&#125; 首先会根据在@MapperScan注解上设置的注解类annotationClass、以及markerInterface来添加过滤器，若未设置将会将包下的所有接口扫描出来。 在调用超类ClassPathBeanDefinitionScanner的scan方法扫描包时会调用子类ClassPathMapperScanner中的doScan，而该类又去调用了超类的doScan方法，但有一点不同的是这复写了isCandidateComponent方法只扫描接口，而Spring中默认恰好相反。 当将所有符合条件的Mapper接口的BeanDefinition信息扫描出来后，进行遍历将beanClass设置成MapperFactoryBean的Class，从而达到偷天换日将Mapper接口通过MapperFactoryBean来创建生成Bean。因为接口是不能被实例化生成Bean的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class ClassPathMapperScanner extends ClassPathBeanDefinitionScanner &#123; public void registerFilters() &#123; // 注册扫描规则过滤器 boolean acceptAllInterfaces = true; // 若annotationClass不为空，表示用户设置了此属性，则根据此属性生成过滤器以保证达到用户想要的效果，而封装此属性的过滤器就是 AnnotationTypeFiter，其保证在扫描对应Java文件时只接受标记有注解为annotationClass的接口 if (this.annotationClass != null) &#123; addIncludeFilter(new AnnotationTypeFilter(this.annotationClass)); acceptAllInterfaces = false; &#125; // 如果markerlnterface不为空，表示要根据此属性生成过滤器以保证达到用户想要的效果，而封装此属性的过滤器就是实现AssignableTypeFiter接口的局部类，扫描过程中只有实现markerIntrface接口的接口才会被接受 if (this.markerInterface != null) &#123; addIncludeFilter(new AssignableTypeFilter(this.markerInterface) &#123; @Override protected boolean matchClassName(String className) &#123; return false; &#125; &#125;); acceptAllInterfaces = false; &#125; if (acceptAllInterfaces) &#123; // 若接受所有接口，则添加自定义INCLUDE过滤器TypeFilter，全部返回true // default include filter that accepts all classes addIncludeFilter((metadataReader, metadataReaderFactory) -&gt; true); &#125; // 对于命名为package-info Java文件，默认不作为逻辑实现接口，将其排除掉，使用TypeFiltler接口的局部类实现match 法 addExcludeFilter((metadataReader, metadataReaderFactory) -&gt; &#123; String className = metadataReader.getClassMetadata().getClassName(); return className.endsWith(\"package-info\"); &#125;); &#125; public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); // 调用父类ClassPathBeanDefinitionScanner来进行扫描 if (beanDefinitions.isEmpty()) &#123; // 若扫描后mapper包下有接口类，则扫描bean定义就不会为空 LOGGER.warn(() -&gt; \"No MyBatis mapper was found in '\" + Arrays.toString(basePackages) + \"' package. Please check your configuration.\"); &#125; else &#123; processBeanDefinitions(beanDefinitions); // 这里是将Mapper接口注册到Spring容器中的关键 &#125; return beanDefinitions; &#125; private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &#123; // 循环所有扫描出mapper的bean定义出来 definition = (GenericBeanDefinition) holder.getBeanDefinition(); // 获取的bean定义 String beanClassName = definition.getBeanClassName(); // 获取的bean定义的名称 definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); // 设置ConstructorArgumentValues会通过构造器初始化对象 // 进行真的偷天换日操作，将当前Bean的Class设置成MapperFactoryBean的Class definition.setBeanClass(this.mapperFactoryBeanClass); definition.getPropertyValues().add(\"addToConfig\", this.addToConfig); // 为的Mapper对象绑定sqlSessionFactory引用，实际上是为MapperFactoryBean添加一个sqlSessionFactory的属性 // 然后SpringIoc在实例化MapperFactoryBean时为通过populate()为UserMapper(MapperFactoryBean)的sqlSessionFactory属性赋值，调用set方法 boolean explicitFactoryUsed = false; if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) &#123; definition.getPropertyValues().add(\"sqlSessionFactory\", new RuntimeBeanReference(this.sqlSessionFactoryBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionFactory != null) &#123; definition.getPropertyValues().add(\"sqlSessionFactory\", this.sqlSessionFactory); explicitFactoryUsed = true; &#125; if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) &#123; // 同上sqlSessionFactory definition.getPropertyValues().add(\"sqlSessionTemplate\", new RuntimeBeanReference(this.sqlSessionTemplateBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionTemplate != null) &#123; definition.getPropertyValues().add(\"sqlSessionTemplate\", this.sqlSessionTemplate); // 将sqlSessionTemplate通过AUTOWIRE_BY_TYPE自动装配 explicitFactoryUsed = true; &#125; // 设置UserMapper&lt;MapperFactoryBean&gt;定义的注入模型是通过包扫描进来的，所有默认注入模型为AutowireCapableBeanFactory.AUTOWIRE_NO=0标识通过@Autowire注解注入 // 因为字段上是没有@AutoWired注解，则MapperFactoryBean的字段属性永远自动注入不了值，故需要把UserMapper&lt;MapperFactoryBean&gt;bean定义的注入模型给改成的AUTOWIRE_BY_TYPE=1表示根据类型自动装配 if (!explicitFactoryUsed) &#123; definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); &#125; definition.setLazyInit(lazyInitialization); // 设置bean定义的加载模型(是否为懒加载) &#125; &#125; protected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) &#123; return beanDefinition.getMetadata().isInterface() &amp;&amp; beanDefinition.getMetadata().isIndependent(); &#125;&#125; 对于MapperFactoryBean代码就比较简单了，上面在给BeanDefinition设置属性时，给构造函数参数列表中添加了一个参数即原始Mapper类名，故实例化MapperFactoryBean时会调用有参构造函数。 123456789101112131415161718public class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; &#123; private Class&lt;T&gt; mapperInterface; public MapperFactoryBean(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface); &#125; public Class&lt;T&gt; getObjectType() &#123; return this.mapperInterface; &#125;&#125;public class SqlSessionTemplate implements SqlSession, DisposableBean &#123; public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; // 最终去sqlSessionFactory.Configuration.mapperRegistry去获取我们的Mapper对象 return getConfiguration().getMapper(type, this); &#125;&#125;","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://yaoyinglong.github.io/tags/Mybatis/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Mybatis","slug":"中间件/Mybatis","permalink":"https://yaoyinglong.github.io/categories/中间件/Mybatis/"}]},{"title":"Mybatis缓存原理","date":"2021-10-11T16:00:00.000Z","path":"Blog/中间件/Mybatis/Mybatis缓存原理/","text":"一级缓存一级缓存是SqlSession级别的缓存，每个HTTP请求都会创建一个新的SqlSession即DefaultSqlSession，默认开启，可通过localCacheScope=STATEMENT关闭一级缓存，参数不一致会导致缓存失效，在查询过程中发生了数据的修改也会导致缓存失效。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class BaseExecutor implements Executor &#123; public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); if (closed) &#123; // 已经关闭，则抛出 ExecutorException 异常 throw new ExecutorException(\"Executor was closed.\"); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); // 清空本地缓存，若queryStack为零，并要求清空本地缓存 &#125; List&lt;E&gt; list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; // 从一级缓存中，获取查询结果 if (list != null) &#123; // 获取到，则进行处理 handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123;// 获得不到，则从数据库中查询 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; if (queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; clearLocalCache(); &#125; &#125; return list; &#125; private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list; &#125;&#125; 二级缓存二级缓存是全局作用域缓存，Mybatis提供二级缓存的接口及实现，缓存实现时必需实体类实现Serializable接口，二级缓存在sqlSession关闭或提交之后才会生效。二级缓存使用是通过全局配置文件中的cacheEnabled，cacheEnabled默认为true，且需要在Mapper.xml映射文件中出使用cache标签标注，实体类必须要实现Serializable接口： 1&lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; 或者使用@CacheNamespace与@Select或@SelectProvider注解配合使用 12345@CacheNamespacepublic interface UserMapper &#123; @Select(value = \"select * from t_user\") List&lt;User&gt; selectAllUser();&#125; 解析二级缓存在结构设计上采用装饰器+责任链模式。从最内层到最外层依次是PerpetualCache、LruCache、SerializedCache、LoggingCache、SynchronizedCache。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071private void cacheElement(XNode context) &#123; if (context != null) &#123; String type = context.getStringAttribute(\"type\", \"PERPETUAL\");// 解析cache节点的type属性 Class&lt;? extends Cache&gt; typeClass = typeAliasRegistry.resolveAlias(type);// 根据type的String获取class类型 String eviction = context.getStringAttribute(\"eviction\", \"LRU\"); // 获取缓存过期策略:默认是LRU Class&lt;? extends Cache&gt; evictionClass = typeAliasRegistry.resolveAlias(eviction); // flushInterval刷新间隔，可被设置为任意正整数，设置的值应该是一个以毫秒为单位的合理时间量。默认不设置即没有刷新间隔，缓存仅在调用语句时刷新 Long flushInterval = context.getLongAttribute(\"flushInterval\"); // size引用数目，可被设置为任意正整数，要注意缓存对象的大小和运行环境中可用的内存资源。默认值是1024 Integer size = context.getIntAttribute(\"size\"); // readOnly只读，可被设置为true或false。只读的缓存会给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。 // 而可读写的缓存会通过序列化返回缓存对象的拷贝，速度上会慢一些，但更安全默认值false boolean readWrite = !context.getBooleanAttribute(\"readOnly\", false); boolean blocking = context.getBooleanAttribute(\"blocking\", false); Properties props = context.getChildrenAsProperties(); // 把缓存节点加入到Configuration中 builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); &#125;&#125;public Cache useNewCache(Class&lt;? extends Cache&gt; typeClass, Class&lt;? extends Cache&gt; evictionClass, Long flushInterval, Integer size, boolean readWrite, boolean blocking, Properties props) &#123; Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); configuration.addCache(cache); currentCache = cache; return cache;&#125;public Cache build() &#123; setDefaultImplementations(); Cache cache = newBaseCacheInstance(implementation, id); setCacheProperties(cache); if (PerpetualCache.class.equals(cache.getClass())) &#123; for (Class&lt;? extends Cache&gt; decorator : decorators) &#123; // 通过LruCache对PerpetualCache进行装饰 cache = newCacheDecoratorInstance(decorator, cache); setCacheProperties(cache); &#125; cache = setStandardDecorators(cache); // 剩余集中Cache对LruCache依次装饰 &#125; else if (!LoggingCache.class.isAssignableFrom(cache.getClass())) &#123; cache = new LoggingCache(cache); &#125; return cache;&#125;private Cache setStandardDecorators(Cache cache) &#123; try &#123; MetaObject metaCache = SystemMetaObject.forObject(cache); if (size != null &amp;&amp; metaCache.hasSetter(\"size\")) &#123; metaCache.setValue(\"size\", size); &#125; if (clearInterval != null) &#123; cache = new ScheduledCache(cache);//ScheduledCache：调度缓存，负责定时清空缓存 ((ScheduledCache) cache).setClearInterval(clearInterval); &#125; if (readWrite) &#123; // 将LRU 装饰到Serialized cache = new SerializedCache(cache); //SerializedCache：缓存序列化和反序列化存储 &#125; cache = new LoggingCache(cache); cache = new SynchronizedCache(cache); if (blocking) &#123; cache = new BlockingCache(cache); &#125; return cache; &#125; catch (Exception e) &#123; throw new CacheException(\"Error building standard cache decorators. Cause: \" + e, e); &#125;&#125; SynchronizedCache线程同步缓存区实现了线程同步功能，与序列化缓存区共同保证二级缓存线程安全。若blocking=false关闭则SynchronizedCache位于责任链的最前端，否则就位于BlockingCache后面而BlockingCache位于责任链的最前端，从而保证了整条责任链是线程同步的。 1234567891011121314151617181920212223242526public class SynchronizedCache implements Cache &#123; private final Cache delegate; public SynchronizedCache(Cache delegate) &#123; this.delegate = delegate; &#125; @Override public synchronized int getSize() &#123; return delegate.getSize(); &#125; @Override public synchronized void putObject(Object key, Object object) &#123; delegate.putObject(key, object); &#125; @Override public synchronized Object getObject(Object key) &#123; return delegate.getObject(key); &#125; @Override public synchronized Object removeObject(Object key) &#123; return delegate.removeObject(key); &#125; @Override public synchronized void clear() &#123; delegate.clear(); &#125;&#125; LoggingCache统计命中率以及打印日志，若日志中出现了Cache Hit Ratio便表示命中了二级缓存 1234567891011121314151617181920212223242526272829303132333435363738394041public class LoggingCache implements Cache &#123; private final Log log; private final Cache delegate; protected int requests = 0; protected int hits = 0; public LoggingCache(Cache delegate) &#123; this.delegate = delegate; this.log = LogFactory.getLog(getId()); &#125; @Override public int getSize() &#123; return delegate.getSize(); &#125; @Override public void putObject(Object key, Object object) &#123; delegate.putObject(key, object); &#125; @Override public Object getObject(Object key) &#123; requests++; final Object value = delegate.getObject(key); if (value != null) &#123; hits++; &#125; if (log.isDebugEnabled()) &#123; log.debug(\"Cache Hit Ratio [\" + getId() + \"]: \" + getHitRatio()); &#125; return value; &#125; @Override public Object removeObject(Object key) &#123; return delegate.removeObject(key); &#125; @Override public void clear() &#123; delegate.clear(); &#125; private double getHitRatio() &#123; return (double) hits / (double) requests; &#125;&#125; ScheduledCache过期清理缓存区，@CacheNamespace(flushInterval=100L)设置过期清理时间默认1个小时，若设置flushInterval为0代表永远不清除，操作缓存时都会进行检查缓存是否过期。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ScheduledCache implements Cache &#123; private final Cache delegate; protected long clearInterval; protected long lastClear; public ScheduledCache(Cache delegate) &#123; this.delegate = delegate; this.clearInterval = 60 * 60 * 1000; // 1 hour this.lastClear = System.currentTimeMillis(); &#125; public void setClearInterval(long clearInterval) &#123; this.clearInterval = clearInterval; &#125; @Override public int getSize() &#123; clearWhenStale(); return delegate.getSize(); &#125; @Override public void putObject(Object key, Object object) &#123; clearWhenStale(); delegate.putObject(key, object); &#125; @Override public Object getObject(Object key) &#123; return clearWhenStale() ? null : delegate.getObject(key); &#125; @Override public Object removeObject(Object key) &#123; clearWhenStale(); return delegate.removeObject(key); &#125; @Override public void clear() &#123; lastClear = System.currentTimeMillis(); delegate.clear(); &#125; private boolean clearWhenStale() &#123; if (System.currentTimeMillis() - lastClear &gt; clearInterval) &#123; clear(); return true; &#125; return false; &#125;&#125; LruCache防溢出缓冲区，内部使用链表实现最近最少使用防溢出机制 1234567891011121314151617181920212223242526272829303132333435363738394041public class LoggingCache implements Cache &#123; private final Log log; private final Cache delegate; protected int requests = 0; protected int hits = 0; public LoggingCache(Cache delegate) &#123; this.delegate = delegate; this.log = LogFactory.getLog(getId()); &#125; @Override public int getSize() &#123; return delegate.getSize(); &#125; @Override public void putObject(Object key, Object object) &#123; delegate.putObject(key, object); &#125; @Override public Object getObject(Object key) &#123; requests++; final Object value = delegate.getObject(key); if (value != null) &#123; hits++; &#125; if (log.isDebugEnabled()) &#123; log.debug(\"Cache Hit Ratio [\" + getId() + \"]: \" + getHitRatio()); &#125; return value; &#125; @Override public Object removeObject(Object key) &#123; return delegate.removeObject(key); &#125; @Override public void clear() &#123; delegate.clear(); &#125; private double getHitRatio() &#123; return (double) hits / (double) requests; &#125;&#125; SerializedCache序列化缓存实现类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class SerializedCache implements Cache &#123; private final Cache delegate; public SerializedCache(Cache delegate) &#123; this.delegate = delegate; &#125; @Override public int getSize() &#123; return delegate.getSize(); &#125; @Override public void putObject(Object key, Object object) &#123; if (object == null || object instanceof Serializable) &#123; delegate.putObject(key, serialize((Serializable) object)); &#125; else &#123; throw new CacheException(\"SharedCache failed to make a copy of a non-serializable object: \" + object); &#125; &#125; @Override public Object getObject(Object key) &#123; Object object = delegate.getObject(key); return object == null ? null : deserialize((byte[]) object); &#125; @Override public Object removeObject(Object key) &#123; return delegate.removeObject(key); &#125; @Override public void clear() &#123; delegate.clear(); &#125; private byte[] serialize(Serializable value) &#123; try (ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos)) &#123; oos.writeObject(value); oos.flush(); return bos.toByteArray(); &#125; catch (Exception e) &#123; throw new CacheException(\"Error serializing object. Cause: \" + e, e); &#125; &#125; private Serializable deserialize(byte[] value) &#123; Serializable result; try (ByteArrayInputStream bis = new ByteArrayInputStream(value); ObjectInputStream ois = new CustomObjectInputStream(bis)) &#123; result = (Serializable) ois.readObject(); &#125; catch (Exception e) &#123; throw new CacheException(\"Error deserializing object. Cause: \" + e, e); &#125; return result; &#125; public static class CustomObjectInputStream extends ObjectInputStream &#123; public CustomObjectInputStream(InputStream in) throws IOException &#123; super(in); &#125; @Override protected Class&lt;?&gt; resolveClass(ObjectStreamClass desc) throws ClassNotFoundException &#123; return Resources.classForName(desc.getName()); &#125; &#125;&#125; PerpetualCache缓存默认实现类 123456789101112131415161718192021222324252627public class PerpetualCache implements Cache &#123; private final String id; private Map&lt;Object, Object&gt; cache = new HashMap&lt;&gt;(); public PerpetualCache(String id) &#123; this.id = id; &#125; @Override public int getSize() &#123; return cache.size(); &#125; @Override public void putObject(Object key, Object value) &#123; cache.put(key, value); &#125; @Override public Object getObject(Object key) &#123; return cache.get(key); &#125; @Override public Object removeObject(Object key) &#123; return cache.remove(key); &#125; @Override public void clear() &#123; cache.clear(); &#125;&#125; 查询缓存二级缓存使用命中条件：会话提交后，SQL语句和参数相同，相关的statementId，RowBounds相同，且设置为自动提交事务并不会命中二级缓存。同一命名空间进行了增删改操作会导致二级缓存失效，在查询的select标签上设置useCache=false不缓存数据到二级缓存中。 对于flushCache参数，当update、insert、delete标签设置该参数为false时，做数据更改不会导致缓存失效，该标签在select标签上与增删改标签语义相反。 由于二级索引是对同一命名空间生效，对于类似联合查询表，若更新了其他几个表，会导致缓存不能及时更新，可使用cache-ref来指定引用mapper映射文件的缓存机制，但cache-ref只能指定一个命名空间。 若会话一与会话二是两条隔离的事务，但由于二级缓存的存在导致彼此可能发生脏读。若会话二的修改直接填充到二级缓存，会话一查询时缓存中存在即直接返回数据，此时会话二回滚会话一读到的数据就是脏数据。为了解决这一问题Mybatis二级缓存机制就引入了事务管理器暂存区，所有变动的数据都会暂时存放到事务管理器的暂存区中，只有执行提交动作后才会真正的将数据从暂存区中填充到二级缓存中。 12345678910111213141516171819202122232425262728public class CachingExecutor implements Executor &#123; public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); // 判断mapper中是否开启了二级缓存&lt;cache&gt;&lt;/cache&gt; if (cache != null) &#123; // 判断是否配置了cache flushCacheIfRequired(ms); // 判断是否需要刷新缓存 if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, boundSql); List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); // 先去二级缓存中获取 if (list == null) &#123; // 二级缓存中没有获取到，通过查询数据库去查询 list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // 加入到二级缓存中 &#125; return list; &#125; &#125; return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); // 没有整合二级缓存，直接去查询 &#125; private void flushCacheIfRequired(MappedStatement ms) &#123; Cache cache = ms.getCache(); if (cache != null &amp;&amp; ms.isFlushCacheRequired()) &#123; tcm.clear(cache); &#125; &#125; public int update(MappedStatement ms, Object parameterObject) throws SQLException &#123; flushCacheIfRequired(ms); return delegate.update(ms, parameterObject); &#125;&#125; 整合第三方缓存整合Redis，首先添加依赖，然后将全局配置文件中cache标签中type属性设置为org.mybatis.caches.redis.RedisCache 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-redis&lt;/artifactId&gt; &lt;version&gt;1.0.0-beta2&lt;/version&gt;&lt;/dependency&gt; 整合ehcache，将全局配置文件中cache标签中type属性设置为org.mybatis.caches.ehcache.EhcacheCache 12345678910&lt;dependency&gt; &lt;groupId&gt;org.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt;","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://yaoyinglong.github.io/tags/Mybatis/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Mybatis","slug":"中间件/Mybatis","permalink":"https://yaoyinglong.github.io/categories/中间件/Mybatis/"}]},{"title":"Mybatis配置文件解析原理","date":"2021-10-11T16:00:00.000Z","path":"Blog/中间件/Mybatis/Mybatis配置文件解析原理/","text":"Mybatis通过加载配置文件流构建一个DefaultSqlSessionFactory，是通过SqlSessionFactoryBuilder的build方法进行解析，包括属性配置、别名配置、拦截器配置、环境（数据源和事务管理器）、Mapper配置等；解析完这些配置后会生成一个Configration对象，该对象中包含了Mybatis需要的所有配置，然后用Configration对象创建SqlSessionFactory对象。 12345String resource = \"mybatis-config.xml\";// 将XML配置文件构建为Configuration配置类Reader reader = Resources.getResourceAsReader(resource);// 通过加载配置文件流构建一个SqlSessionFactory DefaultSqlSessionFactorySqlSessionFactory sqlMapper = new SqlSessionFactoryBuilder().build(reader); build方法内部会使用XMLConfigBuilder解析属性configLocation中配置的路径，首先解析&lt;configuration&gt;标签，所有XML文件中的内容以及注解中的内容都会解析到Configuration中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class SqlSessionFactoryBuilder &#123; public SqlSessionFactory build(Reader reader, String environment, Properties properties) &#123; try &#123; XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties); return build(parser.parse()); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; reader.close(); &#125; catch (IOException e) &#123;&#125; &#125; &#125;&#125;public class XMLConfigBuilder extends BaseBuilder &#123; public Configuration parse() &#123; if (parsed) &#123; // 若已经解析过则抛出异常 throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\"); &#125; parsed = true; // 设置解析标志位 parseConfiguration(parser.evalNode(\"/configuration\")); // 解析mybatis-config.xml的节点&lt;configuration&gt;...&lt;/configuration&gt; return configuration; &#125; private void parseConfiguration(XNode root) &#123; try &#123; // 解析properties节点&lt;properties resource=\"mybatis/db.properties\" /&gt;，解析到XPathParser#variables，Configuration#variables propertiesElement(root.evalNode(\"properties\")); // 解析setting标签的配置 Properties settings = settingsAsProperties(root.evalNode(\"settings\")); // VFS是虚拟文件系统，主要是通过程序能方便读取本地文件系统、FTP文件系统等系统中的文件资源，解析到Configuration#vfsImpl loadCustomVfs(settings); // 配置了vfsImpl属性 // 指定Mybatis所用日志的具体实现，未指定时将自动查找，解析到Configuration#logImpl loadCustomLogImpl(settings); // 配置了logImpl属性 // 解析别名标签数据&lt;typeAliases&gt;，配置后就可以用别名来替代全限定名，解析到Configuration#typeAliasRegistry.typeAliases typeAliasesElement(root.evalNode(\"typeAliases\")); // 解析拦截器和拦截器的属性，如分页插件，解析到Configuration#interceptorChain.interceptors，允许在已映射语句执行过程中的某一点进行拦截调用 // 允许使用插件来拦截的方法调用包括Executor(update, query, flushStatements, commit, rollback, getTransaction, close, isClosed)， // ParameterHandler(getParameterObject, setParameters)，ResultSetHandler (handleResultSets, handleOutputParameters) // StatementHandler(prepare, parameterize, batch, update, query) pluginElement(root.evalNode(\"plugins\")); objectFactoryElement(root.evalNode(\"objectFactory\")); objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); reflectorFactoryElement(root.evalNode(\"reflectorFactory\")); settingsElement(settings); // 设置settings若没有则设置默认值 //解析环境信息，包括事物管理器和数据源，SqlSessionFactoryBuilder在解析时需要指定环境id，如果不指定的话，会选择默认的环境 environmentsElement(root.evalNode(\"environments\")); // 解析数据库厂商&lt;databaseIdProvider type=\"DB_VENDOR\"&gt;，解析到Configuration#databaseId databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); // 无论是在预处理语句PreparedStatement中设置参数，还是从结果集中取值时，都会用类型处理器将获取值以合适的方式转换成Java类型 typeHandlerElement(root.evalNode(\"typeHandlers\")); mapperElement(root.evalNode(\"mappers\")); // 解析mapper &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); &#125; &#125;&#125; 具体的Mapper文件解析是通过XMLConfigBuilder的mapperElement来遍历解析mappers节点下的所有mapper子节点。这里有四种配置方式，可通过package标签批量注册Mapper接口，通过mapper标签的resource属性配置具体的xml文件，通过mapper标签的url属性配置网络上的xml文件，，通过mapper标签的class属性配置具体的Mapper接口。 123456789101112131415161718192021222324252627282930313233343536373839public class XMLConfigBuilder extends BaseBuilder &#123; private void mapperElement(XNode parent) throws Exception &#123; if (parent != null) &#123; for (XNode child : parent.getChildren()) &#123; // 遍历解析mappers节点下的所有mapper子节点 // 判断mapper是否通过批量注册的&lt;package name=\"com.eleven.mapper\"&gt;&lt;/package&gt; if (\"package\".equals(child.getName())) &#123; String mapperPackage = child.getStringAttribute(\"name\"); configuration.addMappers(mapperPackage); &#125; else &#123; // 从classpath下读取mapper &lt;mapper resource=\"mybatis/mapper/EmployeeMapper.xml\"/&gt; String resource = child.getStringAttribute(\"resource\"); // 判断是否从网络或本地磁盘读取&lt;mapper url=\"D:/mapper/EmployeeMapper.xml\"/&gt; String url = child.getStringAttribute(\"url\"); // class属性配置要求接口和xml在同一个包下)&lt;mapper class=\"com.tuling.mapper.DeptMapper\"&gt;&lt;/mapper&gt; String mapperClass = child.getStringAttribute(\"class\"); // mappers节点只配置了&lt;mapper resource=\"mybatis/mapper/EmployeeMapper.xml\"/&gt; if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) &#123; ErrorContext.instance().resource(resource); InputStream inputStream = Resources.getResourceAsStream(resource); // 把文件读取出一个流 // 创建读取XmlMapper构建器对象，用于来解析mapper.xml文件 XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); // 真正的解析mapper.xml配置文件，就是解析sql mapperParser.parse(); &#125; else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) &#123; ErrorContext.instance().resource(url); InputStream inputStream = Resources.getUrlAsStream(url); XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments()); mapperParser.parse(); &#125; else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) &#123; Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass); configuration.addMapper(mapperInterface); &#125; else &#123; throw new BuilderException(\"A mapper element may only specify a url, resource or class, but not more than one.\"); &#125; &#125; &#125; &#125; &#125;&#125; 对于Mapper通过XML配置文件的方法配置的，首先会通过parse方法先去解析mapper.xml文件内容，然后再通过调用bindMapperForNamespace从而调用configuration#addMapper去触发解析Mapper接口中的注解。 1234567891011121314151617181920212223242526public void parse() &#123; if (!configuration.isResourceLoaded(resource)) &#123;// 判断当前的Mapper XML是否被加载过 configurationElement(parser.evalNode(\"/mapper\")); // 真正的解析mapper.xml文件内容 configuration.addLoadedResource(resource); // 把mapper.xml全限定名保存到已被加载列表 bindMapperForNamespace(); // 解析Mapper接口中SQL注解 &#125; parsePendingResultMaps(); parsePendingCacheRefs(); parsePendingStatements();&#125;private void bindMapperForNamespace() &#123; String namespace = builderAssistant.getCurrentNamespace(); if (namespace != null) &#123; Class&lt;?&gt; boundType = null; try &#123; boundType = Resources.classForName(namespace); &#125; catch (ClassNotFoundException e) &#123; &#125; if (boundType != null) &#123; if (!configuration.hasMapper(boundType)) &#123; configuration.addLoadedResource(\"namespace:\" + namespace); configuration.addMapper(boundType); &#125; &#125; &#125;&#125; 对于Mapper接口的配置以及上面的bindMapperForNamespace，都是通过MapperAnnotationBuilder对注解进行解析，解析注解前会先去判断XML文件是否被解析，若没有被解析会先解析XML文件，若解析过了则直接解析SQL注解。 12345678910111213141516171819202122public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; mapperRegistry.addMapper(type);&#125;public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; // 判断传入进来的type类型是不是接口 if (hasMapper(type)) &#123; // 判断的缓存中有没有该类型 throw new BindingException(\"Type \" + type + \" is already known to the MapperRegistry.\"); &#125; boolean loadCompleted = false; try &#123; // 创建一个MapperProxyFactory把的Mapper接口保存到工厂类中 knownMappers.put(type, new MapperProxyFactory&lt;&gt;(type)); MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); // 解析mapper.xml以及Mapper接口中的SQL注解 loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125;&#125; 对于XML文件的解析是通过XMLMapperBuilder#parse来完成的，最终通过configurationElement来完成各个子节点的解析工作。 123456789101112131415161718192021222324252627282930313233private void loadXmlResource() &#123; if (!configuration.isResourceLoaded(\"namespace:\" + type.getName())) &#123; String xmlResource = type.getName().replace('.', '/') + \".xml\"; InputStream inputStream = type.getResourceAsStream(\"/\" + xmlResource); if (inputStream == null) &#123; try &#123; inputStream = Resources.getResourceAsStream(type.getClassLoader(), xmlResource); &#125; catch (IOException e2) &#123; &#125; &#125; if (inputStream != null) &#123; XMLMapperBuilder xmlParser = new XMLMapperBuilder(inputStream, assistant.getConfiguration(), xmlResource, configuration.getSqlFragments(), type.getName()); xmlParser.parse(); &#125; &#125;&#125;private void configurationElement(XNode context) &#123; try &#123; String namespace = context.getStringAttribute(\"namespace\"); // 解析namespace属性 if (namespace == null || namespace.equals(\"\")) &#123; throw new BuilderException(\"Mapper's namespace cannot be empty\"); &#125; builderAssistant.setCurrentNamespace(namespace); // 保存当前的namespace cacheRefElement(context.evalNode(\"cache-ref\")); // 解析缓存引用,说明当前的缓存引用和DeptMapper的缓存引用一致 cacheElement(context.evalNode(\"cache\")); // 解析cache节点 parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); // 解析paramterMap节点 resultMapElements(context.evalNodes(\"/mapper/resultMap\")); // 解析resultMap节点 sqlElement(context.evalNodes(\"/mapper/sql\")); // 解析sql标签节点 buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); // 解析select | insert |update |delete节点 &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing Mapper XML. The XML location is '\" + resource + \"'. Cause: \" + e, e); &#125;&#125; 对于缓存cache节点的解析，这里其实是对二级缓存的构建，二级缓存在结构设计上采用装饰器+责任链模式。从最内层到最外层依次是PerpetualCache、LruCache、ScheduledCache、SerializedCache、LoggingCache、SynchronizedCache、BlockingCache。 构建好的Cache缓存对象会被设置到MapperBuilderAssistant的currentCache属性，最后Mapper解析完成后通过MapperBuilderAssistant的addMappedStatement方法将缓存对象设置到对应的MappedStatement的cache属性中。在执行查询操作时会通过判断MappedStatement的cache属性是否为null从而判断是否走二级缓存。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071private void cacheElement(XNode context) &#123; if (context != null) &#123; String type = context.getStringAttribute(\"type\", \"PERPETUAL\");// 解析cache节点的type属性 Class&lt;? extends Cache&gt; typeClass = typeAliasRegistry.resolveAlias(type);// 根据type的String获取class类型 String eviction = context.getStringAttribute(\"eviction\", \"LRU\"); // 获取缓存过期策略:默认是LRU Class&lt;? extends Cache&gt; evictionClass = typeAliasRegistry.resolveAlias(eviction); // flushInterval刷新间隔，可被设置为任意正整数，设置的值应该是一个以毫秒为单位的合理时间量。默认不设置即没有刷新间隔，缓存仅在调用语句时刷新 Long flushInterval = context.getLongAttribute(\"flushInterval\"); // size引用数目，可被设置为任意正整数，要注意缓存对象的大小和运行环境中可用的内存资源。默认值是1024 Integer size = context.getIntAttribute(\"size\"); // readOnly只读，可被设置为true或false。只读的缓存会给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。 // 而可读写的缓存会通过序列化返回缓存对象的拷贝，速度上会慢一些，但更安全默认值false boolean readWrite = !context.getBooleanAttribute(\"readOnly\", false); boolean blocking = context.getBooleanAttribute(\"blocking\", false); Properties props = context.getChildrenAsProperties(); // 把缓存节点加入到Configuration中 builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); &#125;&#125;public Cache useNewCache(Class&lt;? extends Cache&gt; typeClass, Class&lt;? extends Cache&gt; evictionClass, Long flushInterval, Integer size, boolean readWrite, boolean blocking, Properties props) &#123; Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); configuration.addCache(cache); currentCache = cache; return cache;&#125;public Cache build() &#123; setDefaultImplementations(); Cache cache = newBaseCacheInstance(implementation, id); setCacheProperties(cache); if (PerpetualCache.class.equals(cache.getClass())) &#123; for (Class&lt;? extends Cache&gt; decorator : decorators) &#123; // 通过LruCache对PerpetualCache进行装饰 cache = newCacheDecoratorInstance(decorator, cache); setCacheProperties(cache); &#125; cache = setStandardDecorators(cache); // 剩余集中Cache对LruCache依次装饰 &#125; else if (!LoggingCache.class.isAssignableFrom(cache.getClass())) &#123; cache = new LoggingCache(cache); &#125; return cache;&#125;private Cache setStandardDecorators(Cache cache) &#123; try &#123; MetaObject metaCache = SystemMetaObject.forObject(cache); if (size != null &amp;&amp; metaCache.hasSetter(\"size\")) &#123; metaCache.setValue(\"size\", size); &#125; if (clearInterval != null) &#123; cache = new ScheduledCache(cache);//ScheduledCache：调度缓存，负责定时清空缓存 ((ScheduledCache) cache).setClearInterval(clearInterval); &#125; if (readWrite) &#123; // 将LRU 装饰到Serialized cache = new SerializedCache(cache); //SerializedCache：缓存序列化和反序列化存储 &#125; cache = new LoggingCache(cache); cache = new SynchronizedCache(cache); if (blocking) &#123; cache = new BlockingCache(cache); &#125; return cache; &#125; catch (Exception e) &#123; throw new CacheException(\"Error building standard cache decorators. Cause: \" + e, e); &#125;&#125; 对于select、delete、insert、update等标签的解析是通过buildStatementFromContext中创建XMLStatementBuilder来完成解析的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374private void buildStatementFromContext(List&lt;XNode&gt; list, String requiredDatabaseId) &#123; for (XNode context : list) &#123; // 循环select|delte|insert|update节点 // 创建一个XMLStatementBuilder的构建器对象 final XMLStatementBuilder statementParser = new XMLStatementBuilder(configuration, builderAssistant, context, requiredDatabaseId); try &#123; statementParser.parseStatementNode(); &#125; catch (IncompleteElementException e) &#123; configuration.addIncompleteStatement(statementParser); &#125; &#125;&#125;public void parseStatementNode() &#123; String id = context.getStringAttribute(\"id\"); // insert|delete|update|select标签的Id String databaseId = context.getStringAttribute(\"databaseId\"); // 判断insert|delete|update|select节点是否配置了数据库厂商标注 if (!databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) &#123; return; // 匹配当前的数据库厂商id是否匹配当前数据源的厂商id &#125; String nodeName = context.getNode().getNodeName(); // 获得节点名称：select|insert|update|delete // 根据nodeName获得SqlCommandType枚举 SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH)); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; // 判断是不是select语句节点 // 获取flushCache属性，默认值为isSelect的反值：查询：默认flushCache=false，增删改：默认flushCache=true boolean flushCache = context.getBooleanAttribute(\"flushCache\", !isSelect); // 获取useCache属性，默认值为isSelect：查询：默认useCache=true，增删改：默认useCache=false boolean useCache = context.getBooleanAttribute(\"useCache\", isSelect); // resultOrdered：是否需要处理嵌套查询结果group by(使用极少）可将比如30条数据拆分成三组组成一个嵌套的查询结果 boolean resultOrdered = context.getBooleanAttribute(\"resultOrdered\", false); // 解析sql公用片段，将&lt;include refid=\"selectInfo\"&gt;&lt;/include&gt;解析成sql语句放到&lt;select&gt;Node的子节点中 XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant); includeParser.applyIncludes(context.getNode()); String parameterType = context.getStringAttribute(\"parameterType\"); // 解析sql节点的参数类型 Class&lt;?&gt; parameterTypeClass = resolveClass(parameterType); // 把参数类型字符串转化为class String lang = context.getStringAttribute(\"lang\"); // 查看sql是否支撑自定义语言 // 获取自定义sql脚本语言驱动，默认:class org.apache.ibatis.scripting.xmltags.XMLLanguageDriver LanguageDriver langDriver = getLanguageDriver(lang); // 解析insert语句的的selectKey节点, 一般在oracle里面设置自增id processSelectKeyNodes(id, parameterTypeClass, langDriver); KeyGenerator keyGenerator; // insert语句用于主键生成组件 String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX; //selectById!selectKey id+!selectKey keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true); // 把命名空间拼接到keyStatementId中 if (configuration.hasKeyGenerator(keyStatementId)) &#123; // 判断全局的配置类configuration中是否包含以及解析过的组件生成器对象 keyGenerator = configuration.getKeyGenerator(keyStatementId); &#125; else &#123; // 若配置了useGeneratedKeys则去除useGeneratedKeys配置值，否者查找mybatis-config.xml中是否配置了&lt;setting name=\"useGeneratedKeys\" value=\"true\"&gt;&lt;/setting&gt; 默认是false // 并且判断sql操作类型是否为insert若是则使用Jdbc3KeyGenerator.INSTANCE生成策略，否则使用NoKeyGenerator.INSTANCE生产策略 keyGenerator = context.getBooleanAttribute(\"useGeneratedKeys\", configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType)) ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; &#125; // 通过XMLLanguageDriver来解析sql脚本对象，只是解析成一个个的SqlNode，并不会完全解析sql，因为这时参数都没确定，动态sql无法解析 SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); // STATEMENT，PREPARED或CALLABLE中的一个。这会让MyBatis分别使用Statement，PreparedStatement或CallableStatement，默认值：PREPARED StatementType statementType = StatementType.valueOf(context.getStringAttribute(\"statementType\", StatementType.PREPARED.toString())); // 这是一个给驱动的提示，尝试让驱动程序每次批量返回的结果行数和这个设置值相等。 默认值为未设置（unset）（依赖驱动） Integer fetchSize = context.getIntAttribute(\"fetchSize\"); // 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为unset未设置，依赖驱动 Integer timeout = context.getIntAttribute(\"timeout\"); // 将会传入这条语句的参数类的完全限定名或别名。可选属性，可通过类型处理器TypeHandler推断出具体传入语句的参数，默认值为unset未设置 String parameterMap = context.getStringAttribute(\"parameterMap\"); // 从这条语句中返回的期望类型的类的完全限定名或别名，注意若返回的是集合，则应设置为集合包含的类型，而不是集合本身，可使用resultType或resultMap，但不能同时使用 String resultType = context.getStringAttribute(\"resultType\"); Class&lt;?&gt; resultTypeClass = resolveClass(resultType); // 解析查询结果集返回的类型 // 外部resultMap的命名引用，结果集的映射是Mybatis最强大的特性，可使用resultMap或resultType，但不能同时使用。 String resultMap = context.getStringAttribute(\"resultMap\"); String resultSetType = context.getStringAttribute(\"resultSetType\"); ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType); if (resultSetTypeEnum == null) &#123; resultSetTypeEnum = configuration.getDefaultResultSetType(); &#125; // 解析keyProperty keyColumn仅适用于insert和update String keyProperty = context.getStringAttribute(\"keyProperty\"); String keyColumn = context.getStringAttribute(\"keyColumn\"); String resultSets = context.getStringAttribute(\"resultSets\"); // 为insert|delete|update|select节点构建成mappedStatment对象 builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets);&#125; 在这里会通过XMLIncludeTransformer#applyIncludes递归目标标签，将其中的include标签引用的sql替换成文本。 1234567891011121314151617181920212223242526272829303132333435363738public void applyIncludes(Node source) &#123; Properties variablesContext = new Properties(); Properties configurationVariables = configuration.getVariables(); // 拿到之前配置文件解析的&lt;properties&gt; Optional.ofNullable(configurationVariables).ifPresent(variablesContext::putAll); // 放入到variablesContext中 applyIncludes(source, variablesContext, false); // 替换Includes标签为对应的sql标签里面的值&#125;private void applyIncludes(Node source, final Properties variablesContext, boolean included) &#123; if (source.getNodeName().equals(\"include\")) &#123; Node toInclude = findSqlFragment(getStringAttribute(source, \"refid\"), variablesContext); // 拿到之前解析的&lt;sql&gt; Properties toIncludeContext = getVariablesContext(source, variablesContext); applyIncludes(toInclude, toIncludeContext, true); // 递归， included=true if (toInclude.getOwnerDocument() != source.getOwnerDocument()) &#123; toInclude = source.getOwnerDocument().importNode(toInclude, true); &#125; // include的父节点=select将&lt;select&gt;里面的&lt;include&gt;替换成&lt;sql&gt;，那&lt;include&gt;.getParentNode就为Null了 source.getParentNode().replaceChild(toInclude, source); while (toInclude.hasChildNodes()) &#123;// &lt;sql&gt;.getParentNode()=select，在&lt;sql&gt;的前面插入&lt;sql&gt;中的sql语句 toInclude.getParentNode().insertBefore(toInclude.getFirstChild(), toInclude); &#125; toInclude.getParentNode().removeChild(toInclude); // &lt;sql&gt;.getParentNode()=select, 移除select中的&lt;sql&gt; int i = 0; &#125; else if (source.getNodeType() == Node.ELEMENT_NODE) &#123; // 0 if (included &amp;&amp; !variablesContext.isEmpty()) &#123; // replace variables in attribute values NamedNodeMap attributes = source.getAttributes(); for (int i = 0; i &lt; attributes.getLength(); i++) &#123; Node attr = attributes.item(i); attr.setNodeValue(PropertyParser.parse(attr.getNodeValue(), variablesContext)); &#125; &#125; NodeList children = source.getChildNodes(); for (int i = 0; i &lt; children.getLength(); i++) &#123; applyIncludes(children.item(i), variablesContext, included); // 递归 &#125;// included=true 说明是从include递归进来的 &#125; else if (included &amp;&amp; (source.getNodeType() == Node.TEXT_NODE || source.getNodeType() == Node.CDATA_SECTION_NODE) &amp;&amp; !variablesContext.isEmpty()) &#123; source.setNodeValue(PropertyParser.parse(source.getNodeValue(), variablesContext)); // 替换sql片段中的 $&#123;&lt;properties解析到的内容&gt;&#125; &#125;&#125; 对于select、delete、insert、update等标签内容具体解析是通过LanguageDriver#createSqlSource中创建XMLScriptBuilder来完成的，最终将解析出的sqlNode根据是否是动态SQL将其封装成DynamicSqlSource或RawSqlSource。判断是否是动态SQL是根据SQL中是否包含${}以及是否包含动态标签。 123456789101112131415161718192021public SqlSource createSqlSource(Configuration configuration, XNode script, Class&lt;?&gt; parameterType) &#123; XMLScriptBuilder builder = new XMLScriptBuilder(configuration, script, parameterType); return builder.parseScriptNode();&#125;public SqlSource parseScriptNode() &#123; /** * 递归解析selectById这个sql元素会解析成 * 1层 MixedSqlNode &lt;SELECT&gt; * 2层 WhereSqlNode &lt;WHERE&gt; * 2层 IfSqlNode &lt;IF&gt; test=\"条件表达式\" * contexts= sql语句分： 1.TextSqlNode 带$&#123;&#125; 2.StaticTextSqlNode */ MixedSqlNode rootSqlNode = parseDynamicTags(context); SqlSource sqlSource; if (isDynamic) &#123; sqlSource = new DynamicSqlSource(configuration, rootSqlNode); // 动态Sql源 &#125; else &#123; sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType); // 静态Sql源，会在这里解析 &#125; return sqlSource;&#125; 首先会获取当前节点的所有子节点列表，判断子节点类型是否是动态标签节点，若不是则直接获取节点SQL文本，且判断文本中是否包含${}若包含这标识为动态SQL，将SQL文本封装到TextSqlNode中添加到结果列表中，否则将其封装为StaticTextSqlNode添加到结果列表中。 若节点是动态标签的节点即where、if、foreach等标签节点，若是则获取对应处理的handler，handler列表是在XMLScriptBuilder构造函数中调用initNodeHandlerMap就已初始化完成。对于各种动态标签因为可以嵌套，所以handleNode内部也是递归处理的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657protected MixedSqlNode parseDynamicTags(XNode node) &#123; // 解析$&#123;&#125;和动态节点 List&lt;SqlNode&gt; contents = new ArrayList&lt;&gt;(); NodeList children = node.getNode().getChildNodes(); //获得&lt;select&gt;的子节点 for (int i = 0; i &lt; children.getLength(); i++) &#123; XNode child = node.newXNode(children.item(i)); if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE || child.getNode().getNodeType() == Node.TEXT_NODE) &#123; String data = child.getStringBody(\"\"); // 获得sql文本 TextSqlNode textSqlNode = new TextSqlNode(data); if (textSqlNode.isDynamic()) &#123; // 判断sql文本中是否有$&#123;&#125;，有则isDynamic = true contents.add(textSqlNode); isDynamic = true; &#125; else &#123; contents.add(new StaticTextSqlNode(data)); &#125; &#125; else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) &#123; // issue #628 String nodeName = child.getNode().getNodeName(); NodeHandler handler = nodeHandlerMap.get(nodeName); // 根据当前标签名称获取当前动态节点的NodeHandler，构造方法中调用initNodeHandlerMap进行初始化 if (handler == null) &#123; throw new BuilderException(\"Unknown element &lt;\" + nodeName + \"&gt; in SQL statement.\"); &#125; handler.handleNode(child, contents); // 不同动态节点有不用的实现 isDynamic = true; &#125; &#125; return new MixedSqlNode(contents);&#125;public class XMLScriptBuilder extends BaseBuilder &#123; private final Map&lt;String, NodeHandler&gt; nodeHandlerMap = new HashMap&lt;&gt;(); private void initNodeHandlerMap() &#123; nodeHandlerMap.put(\"trim\", new TrimHandler()); nodeHandlerMap.put(\"where\", new WhereHandler()); nodeHandlerMap.put(\"set\", new SetHandler()); nodeHandlerMap.put(\"foreach\", new ForEachHandler()); nodeHandlerMap.put(\"if\", new IfHandler()); nodeHandlerMap.put(\"choose\", new ChooseHandler()); nodeHandlerMap.put(\"when\", new IfHandler()); nodeHandlerMap.put(\"otherwise\", new OtherwiseHandler()); nodeHandlerMap.put(\"bind\", new BindHandler()); &#125;&#125;private class WhereHandler implements NodeHandler &#123; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; MixedSqlNode mixedSqlNode = parseDynamicTags(nodeToHandle); WhereSqlNode where = new WhereSqlNode(configuration, mixedSqlNode); targetContents.add(where); &#125;&#125;private class IfHandler implements NodeHandler &#123; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; MixedSqlNode mixedSqlNode = parseDynamicTags(nodeToHandle); //递归解析 String test = nodeToHandle.getStringAttribute(\"test\"); // 得到表达式 IfSqlNode ifSqlNode = new IfSqlNode(mixedSqlNode, test); targetContents.add(ifSqlNode); &#125;&#125; 将每个增删改查SQL解析完成后都封装成一个MappedStatement并添加到Configuration#mappedStatements中，依次遍历解析完所有的XML文件中的SQL，到此XML解析完成。 解析完XML后就改解析Mapper接口中的注解了，首先解析@CacheNamespace、@CacheNamespaceRef注解。然后解析方法上的SQL注解。在parseStatement中通过getSqlSourceFromAnnotations然后通过LanguageDriver去将注解上的SQL解析成SQLNode列表封装成DynamicSqlSource或RawSqlSource。 对于@SelectProvider、@InsertProvider、@UpdateProvider、@DeleteProvider注解的方法解析最终会封装成一个ProviderSqlSource。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public void parse() &#123; String resource = type.toString(); if (!configuration.isResourceLoaded(resource)) &#123; // 是否已经解析mapper接口 loadXmlResource(); // 根据mapper接口名获取xml文件并解析，解析&lt;mapper&gt;&lt;/mapper&gt;里面所有东西放到configuration configuration.addLoadedResource(resource); // 添加已解析的标记 assistant.setCurrentNamespace(type.getName()); parseCache(); // 解析接口上@CacheNamespace注解 parseCacheRef(); // 解析接口上@CacheNamespaceRef注解 Method[] methods = type.getMethods(); // 获取所有方法看是否使用了注解 for (Method method : methods) &#123; try &#123; if (!method.isBridge()) &#123; parseStatement(method); // 是不是用了注解，用了注解会将注解解析成MappedStatement &#125; &#125; catch (IncompleteElementException e) &#123; configuration.addIncompleteMethod(new MethodResolver(this, method)); &#125; &#125; &#125; parsePendingMethods();&#125;private SqlSource getSqlSourceFromAnnotations(Method method, Class&lt;?&gt; parameterType, LanguageDriver languageDriver) &#123; try &#123; Class&lt;? extends Annotation&gt; sqlAnnotationType = getSqlAnnotationType(method); Class&lt;? extends Annotation&gt; sqlProviderAnnotationType = getSqlProviderAnnotationType(method); if (sqlAnnotationType != null) &#123; if (sqlProviderAnnotationType != null) &#123; throw new BindingException(\"You cannot supply both a static SQL and SqlProvider to method named \" + method.getName()); &#125; Annotation sqlAnnotation = method.getAnnotation(sqlAnnotationType); final String[] strings = (String[]) sqlAnnotation.getClass().getMethod(\"value\").invoke(sqlAnnotation); return buildSqlSourceFromStrings(strings, parameterType, languageDriver); &#125; else if (sqlProviderAnnotationType != null) &#123; Annotation sqlProviderAnnotation = method.getAnnotation(sqlProviderAnnotationType); return new ProviderSqlSource(assistant.getConfiguration(), sqlProviderAnnotation, type, method); &#125; return null; &#125; catch (Exception e) &#123; throw new BuilderException(\"Could not find value method on SQL annotation. Cause: \" + e, e); &#125;&#125;private SqlSource buildSqlSourceFromStrings(String[] strings, Class&lt;?&gt; parameterTypeClass, LanguageDriver languageDriver) &#123; final StringBuilder sql = new StringBuilder(); for (String fragment : strings) &#123; sql.append(fragment); sql.append(\" \"); &#125; return languageDriver.createSqlSource(configuration, sql.toString().trim(), parameterTypeClass);&#125;public SqlSource createSqlSource(Configuration configuration, String script, Class&lt;?&gt; parameterType) &#123; // issue #3 if (script.startsWith(\"&lt;script&gt;\")) &#123; XPathParser parser = new XPathParser(script, false, configuration.getVariables(), new XMLMapperEntityResolver()); return createSqlSource(configuration, parser.evalNode(\"/script\"), parameterType); &#125; else &#123; // issue #127 script = PropertyParser.parse(script, configuration.getVariables()); TextSqlNode textSqlNode = new TextSqlNode(script); if (textSqlNode.isDynamic()) &#123; return new DynamicSqlSource(configuration, textSqlNode); &#125; else &#123; return new RawSqlSource(configuration, script, parameterType); &#125; &#125;&#125;","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://yaoyinglong.github.io/tags/Mybatis/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Mybatis","slug":"中间件/Mybatis","permalink":"https://yaoyinglong.github.io/categories/中间件/Mybatis/"}]},{"title":"SpringMvc处理分发请求原理","date":"2021-10-06T16:00:00.000Z","path":"Blog/Spring/SpringMvc处理分发请求原理/","text":"在Spring MVC中是通过DispatcherServlet前端控制器来完成所有Web请求的转发、匹配、数据处理后，并转由页面进行展示，是MVC实现中最核心的部分。 DispatcherServlet是继承的FrameworkServlet，而FrameworkServlet是HttpServlet的子类，FrameworkServlet对诸如doGet、doPost等所有放法进行了重写，都调用processRequest方法，让后调用子类DispatcherServlet中doService方法，最终调用doDispatch方法处理转发。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public class DispatcherServlet extends FrameworkServlet &#123; protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; logRequest(request); Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); // 把Spring上下文对象存放到Request的attribute中 request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); // 把Spring国际化支持解析器对象存放到Request的attribute中 request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); // 主题解析器对象 request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); // 主题对象 if (this.flashMapManager != null) &#123; FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); &#125; try &#123; doDispatch(request, response); // 真正的进行处理转发 &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125; &#125; protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; // 声明一个处理器执行链 boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); // 检查request对象判断请求是不是文件上传的请求 // 判断是不是文件上传请求，若是则返回的processedRequest是MultipartHttpServletRequest，显然和原始的request对象不是同一个对象 multipartRequestParsed = (processedRequest != request); // 从当前的请求中推断出HandlerExecuteChain处理器执行链对象 mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // 根据Handler选择HandlerAdpater对象，默认是@RequestMappingHandlerAdapter对象 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; //触发拦截器的pre方法，返回false，就不进行处理了 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 通过适配器真正的调用目标方法，RequestMappingHandlerAdapter.handle=&gt;AbstractHandlerMethodAdapter#handle(HttpServletRequest, HttpServletResponse,Object) mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); // 触发拦截器链的post方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; // 处理目标方法返回的结果，主要是渲染视图 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123;// 抛出异常:处理拦截器的afterCompletion方法 triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123;// 抛出异常:处理拦截器的afterCompletion方法 triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); // 清除文件上传时候生成的临时文件 &#125; &#125; &#125; &#125;&#125; 处理器映射器HandlerMapping在初始化完成时，在上下文环境中已定义的所有HandlerMapping都已被加载放到一个排好序的List中，存储着HTTP请求对应的映射数据，每个HandlerMapping可持有一系列从URL请求到Controller的映射。对于不同Web请求的映射，Spring MVC提供了不同的HandlerMapping的实现，可让应用开发选取不同的映射策略，XML方式通过在web.xml中配置的方式注册Bean默认使用BeanNameUrlHandlerMapping映射策略，通过@Controller、@RequestMapping注解的方式使用RequestMappingHandlerMapping映射策略。 123456789101112131415161718protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // Web容器中配置的所有的handlerMapping集合对象在本类中的initHandlerMappings()方法为DispatcherServlet类初始化赋值handlerMappings集合 if (this.handlerMappings != null) &#123; // 循环遍历所有的handlerMappings对象，依次调用handlerMappings的getHandler(request)来获取处理器执行链对象 for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Testing handler map [\" + hm + \"] in DispatcherServlet with name '\" + getServletName() + \"'\"); &#125; // 依次循环调用HandlerMapping的getHandler方法进行获取HandlerExecutionChain，调用所有的HandlerMapping的父类的AbstractHandlerMapping#getHandler(request) HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; &#125; // 通过所有的handlerMapping对象 还没有获取到对应的HandlerExecutionChain，则认为该请求无法匹配 return null;&#125; 首先通过UrlPathHelper对象解析出request中请求路径，让后通过该路径到RequestMappingHanlderMapping的路径映射注册表mappingRegistry中匹配，匹配到后通过getHandlerExecutionChain将其封装成一个HandlerExecutionChain，然后匹配拦截器规则，将满足条件的拦截器添加到该封装对象中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public abstract class AbstractHandlerMapping extends WebApplicationObjectSupport implements HandlerMapping, Ordered &#123; public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 找到处理器对象，在本子类的AbstractHandlerMapping的子类RequestMappingHanlderMapping的生命周期回调接口InitializingBean中会把@RequestMapping注解信息和方法映射对象保存到路径映射注册表中 Object handler = getHandlerInternal(request); if (handler == null) &#123; // 判断上一步的handler是否为空 handler = getDefaultHandler(); // 返回默认的handler &#125; if (handler == null) &#123; return null; &#125; if (handler instanceof String) &#123; // 若解析出的handler是String则通过Web容器创建handler对象 String handlerName = (String) handler; handler = obtainApplicationContext().getBean(handlerName); &#125; // 根据处理器来构建处理器执行链对象 HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; // 处理跨域 CorsConfiguration globalConfig = this.globalCorsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain; &#125; protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; // 创建处理器执行链对象 HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler)); // 从请求中获取请求映射路径 String lookupPath = this.urlPathHelper.getLookupPathForRequest(request); // 循环获取所有的拦截器对象 for (HandlerInterceptor interceptor : this.adaptedInterceptors) &#123; // 判断拦截器对象是不是实现HandlerInterceptor if (interceptor instanceof MappedInterceptor) &#123; MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor; // 通过路径匹配看该拦截器是否会拦截本次请求路径 if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; else &#123; chain.addInterceptor(interceptor); &#125; &#125; return chain; // 返回我们的拦截器链执行器对象 &#125;&#125;public abstract class AbstractHandlerMethodMapping&lt;T&gt; extends AbstractHandlerMapping implements InitializingBean &#123; protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; // 获取UrlPathHelper对象，用于解析从request中解析出请求映射路径 String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); this.mappingRegistry.acquireReadLock(); // 通过映射注册表获取lock对象 try &#123;// 通过从Request对象中解析出来的lookupPath然后通过lookupPath获取HandlerMethod对象 HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &#125; finally &#123;// 释放锁对象 this.mappingRegistry.releaseReadLock(); &#125; &#125; protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches = new ArrayList&lt;&gt;(); // 根据路径去MappingRegistry注册表中的urlLookup的map对象中获取RequestMappingInfo对象，mappingRegistry在RequestMappingHandlerMapping的bean的初始化方法就进行解析保存到注册表中 List&lt;T&gt; directPathMatches = this.mappingRegistry.getMappingsByUrl(lookupPath); // 判断通过解析出来的lookUpPath解析出来的RequestMappingInfo不为空 把RequestMappingInfo封装成为Match保存到集合中 if (directPathMatches != null) &#123; addMatchingMappings(directPathMatches, matches, request); &#125; if (matches.isEmpty()) &#123; addMatchingMappings(this.mappingRegistry.getMappings().keySet(), matches, request); &#125; if (!matches.isEmpty()) &#123; Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request)); // 创建Match的匹配器对象 matches.sort(comparator); // 对匹配器进行排序 Match bestMatch = matches.get(0); // 默认选择第一个为最匹配的 if (matches.size() &gt; 1) &#123; if (CorsUtils.isPreFlightRequest(request)) &#123; return PREFLIGHT_AMBIGUOUS_MATCH; &#125; Match secondBestMatch = matches.get(1); // 获取第二最匹配的 if (comparator.compare(bestMatch, secondBestMatch) == 0) &#123; // 若第一个和第二个是一样的则抛出异常 Method m1 = bestMatch.handlerMethod.getMethod(); Method m2 = secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException(\"Ambiguous handler methods mapped for HTTP path '\" + request.getRequestURL() + \"': &#123;\" + m1 + \", \" + m2 + \"&#125;\"); &#125; &#125; request.setAttribute(BEST_MATCHING_HANDLER_ATTRIBUTE, bestMatch.handlerMethod); // 把最匹配的设置到request中 handleMatch(bestMatch.mapping, lookupPath, request); return bestMatch.handlerMethod; // 返回最匹配的 &#125; else &#123; return handleNoMatch(this.mappingRegistry.getMappings().keySet(), lookupPath, request); &#125; &#125;&#125; 处理器适配器HandlerAdapter1234567891011121314151617181920212223public class DispatcherServlet extends FrameworkServlet &#123; protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; if (this.handlerAdapters != null) &#123; // 循环系统配置配置的handlerAdapters for (HandlerAdapter ha : this.handlerAdapters) &#123; if (ha.supports(handler)) &#123; return ha; &#125; &#125; &#125; throw new ServletException(\"No adapter for handler [\" + handler + \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\"); &#125;&#125;public abstract class AbstractHandlerMethodAdapter extends WebContentGenerator implements HandlerAdapter, Ordered &#123; public final boolean supports(Object handler) &#123; // 判断hanlder是不是HandlerMethod实现类或者子类 &amp;&amp; 默认返回true return (handler instanceof HandlerMethod &amp;&amp; supportsInternal((HandlerMethod) handler)); &#125;&#125;public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; protected boolean supportsInternal(HandlerMethod handlerMethod) &#123; return true; &#125;&#125; Spring MVC采用适配器模式来适配调用指定Handler，根据Handler的不同种类采用不同的Adapter，其对应关系如下： Handler类别 对应适配器 描述 Controller SimpleControllerHandlerAdapter 标准控制器，返回ModelAndView，实现Controller接口 HttpRequestHandler HttpRequestHandlerAdapter 实现HttpRequestHandler接口 Servlet SimpleServletHandlerAdapter 基于标准的Servlet处理，继承HttpServlet HandlerMethod RequestMappingHandlerAdapter 基于@RequestMapping对应方法处理 12345678910111213141516171819202122232425262728public class SimpleController implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; return null; &#125;&#125;public class HttpRequestController implements HttpRequestHandler &#123; @Override public void handleRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; &#125;&#125;public class ServletController extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; super.doGet(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; super.doPost(req, resp); &#125;&#125;@Controllerpublic class RequestController &#123; @RequestMapping(value = \"/hello\") public String hello() &#123; return \"a\"; &#125;&#125; 执行处理器方法过程通过上面获取的具体的HandlerAdapter调用具体的handle方法，RequestMappingHandlerAdapter是调用超类AbstractHandlerMethodAdapter的handle方法从而调用自身的handleInternal方法。 1234567891011121314151617181920212223242526272829303132333435public abstract class AbstractHandlerMethodAdapter extends WebContentGenerator implements HandlerAdapter, Ordered &#123; public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler); // 调用到具体子类的方法 &#125;&#125;public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ModelAndView mav; checkRequest(request); // 检查请求对象 // 判断当前是否需要支持在同一个session中只能线性地处理请求，synchronized是JVM进程级，故分布式环境下，无法达到同步Session的功能。默认情况下synchronizeOnSession为false if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); // 获取当前请求的session对象 if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); // 为当前session生成一个唯一的可用于锁定的key synchronized (mutex) &#123; mav = invokeHandlerMethod(request, response, handlerMethod); // 对HandlerMethod进行参数等的适配处理，并调用目标handler &#125; &#125; else &#123;// 若当前不存在session，则直接对HandlerMethod进行适配 mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // 若当前不需要对session进行同步处理，则直接对HandlerMethod进行适配 mav = invokeHandlerMethod(request, response, handlerMethod); &#125; // 判断当前请求头中是否包含Cache-Control请求头，如果不包含，则对当前response进行处理 if (!response.containsHeader(HEADER_CACHE_CONTROL)) &#123; // 若当前SessionAttribute中存在配置的attributes，则为其设置过期时间。这里SessionAttribute主要是通过@SessionAttribute注解生成的 if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); &#125; else &#123; // 若当前不存在SessionAttributes，则判断当前是否存在Cache-Control设置，若存在则按照该设置进行response处理，若不存在则设置response中的Cache的过期时间为-1，即立即失效 prepareResponse(response); &#125; &#125; return mav; &#125;&#125; 首先获取容器中全局配置的InitBinder和当前HandlerMethod所对应的Controller中配置的InitBinder，用于参数的绑定，然后获取容器中全局配置的ModelAttribute和当前HandlerMethod所对应的Controller中配置的ModelAttribute，这些配置的方法将会在目标方法调用之前进行调用。 将handlerMethod封装为一个ServletInvocableHandlerMethod对象，该对象用于对当前request的整体调用流程进行了封装，设置参数解析器对象，设置返回值解析对象，并将前面创建的WebDataBinderFactory也设置到ServletInvocableHandlerMethod中，然后通过initModel()方法调用前面获取到的@ModelAttribute标注的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); // 把请求req resp包装成ServletWebRequest try &#123; // 获取容器中全局配置的InitBinder和当前HandlerMethod所对应的Controller中配置的InitBinder，用于参数的绑定 WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod); // 获取容器中全局配置的ModelAttribute和当前HandlerMethod所对应的Controller中配置的ModelAttribute，这些配置的方法将会在目标方法调用之前进行调用 ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory); // 将handlerMethod封装为一个ServletInvocableHandlerMethod对象，该对象用于对当前request的整体调用流程进行了封装HanlderMethod：InvocableHandlerMethod:invokeForRequest()，ServletInvocableHandlerMethod:invokeAndHandle() ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); // 为invocableMethod(ServletInvocableHandlerMethod)设置参数解析器对象argumentResolvers的初始化就是在RequestMappingHandlerAdapter的生命周期回调afterPropertiesSet()方法进行对argumentResolvers初始化赋值，用于解析参数 if (this.argumentResolvers != null) &#123; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); &#125; // 为invocableMethod(ServletInvocableHandlerMethod)设置参数解析器对象argumentResolvers的初始化就是在RequestMappingHandlerAdapter的生命周期回调afterPropertiesSet()方法进行对returnValueHandlers初始化赋值，用于解析返回值 if (this.returnValueHandlers != null) &#123; invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); &#125; // 将前面创建的WebDataBinderFactory设置到ServletInvocableHandlerMethod中 invocableMethod.setDataBinderFactory(binderFactory); // 设置ParameterNameDiscoverer，该对象将按照一定的规则获取当前参数的名称 invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); // 这里initModel()方法主要作用是调用前面获取到的@ModelAttribute标注的方法，从而达到@ModelAttribute标注的方法能够在目标Handler调用之前调用的目的 ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); // 调用我们标注了@ModelAttribute的方法,主要是为目标方法预加载 modelFactory.initModel(webRequest, mavContainer, invocableMethod); // 重定向时，忽略model中的数据 mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); // 获取当前AsyncWebRequest，主要作用是判断目标handler返回值是否为WebAsyncTask或DefferredResult，若是则说明当前请求的处理应该是异步的。 AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); // 封装异步任务的线程池，request和interceptors到WebAsyncManager中 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); // 这里就是用于判断当前请求是否有异步任务结果的，如果存在，则对异步任务结果进行封装 if (asyncManager.hasConcurrentResult()) &#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Found concurrent result value [\" + result + \"]\"); &#125; invocableMethod = invocableMethod.wrapConcurrentResult(result); &#125; // 对请求参数进行处理，调用目标HandlerMethod，并且将返回值封装为一个ModelAndView对象 invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) &#123; return null; &#125; // 对封装的ModelAndView进行处理，主要是判断当前请求是否进行了重定向，如果进行了重定向，还会判断是否需要将FlashAttributes封装到新的请求中 return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123;// 调用request destruction callbacks和对SessionAttributes进行处理 webRequest.requestCompleted(); &#125;&#125;private WebDataBinderFactory getDataBinderFactory(HandlerMethod handlerMethod) throws Exception &#123; Class&lt;?&gt; handlerType = handlerMethod.getBeanType(); // 获取HandlerMethod的class类型 Set&lt;Method&gt; methods = this.initBinderCache.get(handlerType); // 尝试从缓存中加载Controller中的标注了@InitBinder注解的方法 if (methods == null) &#123; // 缓存中没有，则查找Controller中标注@InitBinder注解的方法 methods = MethodIntrospector.selectMethods(handlerType, INIT_BINDER_METHODS); this.initBinderCache.put(handlerType, methods); // 加入到局部缓存initBinder中 &#125; List&lt;InvocableHandlerMethod&gt; initBinderMethods = new ArrayList&lt;&gt;(); // 定义一个initBinderMethod的集合 // 全局的initBinder注解全局一般是在@ControllerAdvice的类中，initBinderAdviceCache缓存变量在RequestMappingHandlerAdapter类的afterPropertiesSet方法中去加载的 this.initBinderAdviceCache.forEach((clazz, methodSet) -&gt; &#123; if (clazz.isApplicableToBeanType(handlerType)) &#123; // 判断全局的webInitBinder能否作用到当前的controller中 Object bean = clazz.resolveBean(); for (Method method : methodSet) &#123; // 把方法加入到集合中 initBinderMethods.add(createInitBinderMethod(bean, method)); &#125; &#125; &#125;); for (Method method : methods) &#123; // 合并局部的initbinder和全局的initbinder Object bean = handlerMethod.getBean(); initBinderMethods.add(createInitBinderMethod(bean, method)); &#125; return createDataBinderFactory(initBinderMethods); // 创建数据绑定器工厂&#125;private ModelFactory getModelFactory(HandlerMethod handlerMethod, WebDataBinderFactory binderFactory) &#123; // 获取SessionAttributesHandler，解析类上标注的@SessionAttributes注解 // 若类上标注了@SessionAttributes注解，则目标返回模型数据就回被放到session中 SessionAttributesHandler sessionAttrHandler = getSessionAttributesHandler(handlerMethod); Class&lt;?&gt; handlerType = handlerMethod.getBeanType(); // 获取目标controller的class对象 Set&lt;Method&gt; methods = this.modelAttributeCache.get(handlerType); // 尝试从modelAttributeCache缓存中获取对象 if (methods == null) &#123; // 缓存中没有该对象 // 若缓存中没有相关属性，则在当前bean中查找所有使用@ModelAttribute标注，但是没使用@RequestMapping标注的方法，并将这些方法缓存起来 methods = MethodIntrospector.selectMethods(handlerType, MODEL_ATTRIBUTE_METHODS); this.modelAttributeCache.put(handlerType, methods); // 加入到缓存中 &#125; List&lt;InvocableHandlerMethod&gt; attrMethods = new ArrayList&lt;&gt;(); this.modelAttributeAdviceCache.forEach((clazz, methodSet) -&gt; &#123; // 获取全局的标注了@ControllerAdivce中的@ModelAttribute注解的方法 // 判断标注了@ControllerAdivce类型全局@ModelAttribute注解的能否匹配当前的class对象 if (clazz.isApplicableToBeanType(handlerType)) &#123; Object bean = clazz.resolveBean(); for (Method method : methodSet) &#123; // 创建InvocableHandlerMethod加入到缓存中 attrMethods.add(createModelAttributeMethod(binderFactory, bean, method)); &#125; &#125; &#125;); for (Method method : methods) &#123; // 合并全局和局部的@ModelAttribute方法 Object bean = handlerMethod.getBean(); attrMethods.add(createModelAttributeMethod(binderFactory, bean, method)); &#125; return new ModelFactory(attrMethods, binderFactory, sessionAttrHandler);//创建ModelFactory返回&#125; 最终通过invokeAndHandle中调用invokeForRequest对InitBinder配置的方法和具体的Controller方法进行调用，对于InitBinder方法的具体调用是在getMethodArgumentValues方法中resolveArgument调用具体的参数解析器来完成的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); // 真正的调用目标对象 setResponseStatus(webRequest); // 设置相关的返回状态 if (returnValue == null) &#123; // 如果请求处理完成，则设置requestHandled属性 if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123; mavContainer.setRequestHandled(true); return; &#125; &#125; else if (StringUtils.hasText(getResponseStatusReason())) &#123; mavContainer.setRequestHandled(true); return; // 如果请求失败，但是有错误原因，那么也会设置requestHandled属性 &#125; mavContainer.setRequestHandled(false); Assert.state(this.returnValueHandlers != null, \"No return value handlers\"); try &#123;// 遍历当前容器中所有ReturnValueHandler，判断哪种handler支持当前返回值的处理，若支持，则使用该handler处理该返回值 this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(getReturnValueHandlingErrorMessage(\"Error handling return value\", returnValue), ex); &#125; throw ex; &#125;&#125;public Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); // 获取目标方法入参的值 Object returnValue = doInvoke(args); // 真的的调用目标方法 return returnValue;&#125;private Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; MethodParameter[] parameters = getMethodParameters(); // 获取目标方法参数的描述数组对象 Object[] args = new Object[parameters.length]; // 用来初始化对应参数名称的参数值得数组 for (int i = 0; i &lt; parameters.length; i++) &#123; //循环参数名数组 MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); // 为MethodParameter设置参数名称探测器对象 args[i] = resolveProvidedArgument(parameter, providedArgs); if (args[i] != null) &#123; continue; &#125; if (this.argumentResolvers.supportsParameter(parameter)) &#123; // 获取所有的参数解析器，然后筛选出合适的解析器 try &#123;//通过参数解析器来解析参数 args[i] = this.argumentResolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); continue; &#125; catch (Exception ex) &#123; throw ex; &#125; &#125; if (args[i] == null) &#123; throw new IllegalStateException(\"Could not resolve method parameter at index \" + parameter.getParameterIndex() + \" in \" + parameter.getExecutable().toGenericString() + \": \" + getArgumentResolutionErrorMessage(\"No suitable resolver for\", i)); &#125; &#125; return args;&#125;public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123; HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); // 通过参数筛选出参数解析器对象 if (resolver == null) &#123; throw new IllegalArgumentException(\"Unknown parameter type [\" + parameter.getParameterType().getName() + \"]\"); &#125; // 挑选参数解析器来解析真正的参数值 return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);&#125;public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; // 获取能够处理当前返回值的Handler，比如如果返回值是ModelAndView类型，那么这里的handler就是ModelAndViewMethodReturnValueHandler HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType); if (handler == null) &#123; throw new IllegalArgumentException(\"Unknown return value type: \" + returnType.getParameterType().getName()); &#125; // 通过获取到的handler处理返回值，并将其封装到ModelAndViewContainer中 handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);&#125; 视图解析器视图解析器ViewResolver负责将处理结果生成View视图，首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示。视图对象是由视图解析器负责实例化。 视图解析器的作用是将逻辑视图转为物理视图，所有的视图解析器都必须实现ViewResolver接口。SpringMVC为逻辑视图名的解析提供了不同的策略，可在Spring WEB上下文中配置一种或多种解析策略，并指定他们之间的先后顺序。每一种映射策略对应一个具体的视图解析器实现类。可选择一种视图解析器或混用多种视图解析器。可通过order属性指定解析器的优先顺序，order越小优先级越高，SpringMVC会按视图解析器的优先顺序对逻辑视图名进行解析，直到解析成功并返回视图对象，否则抛出ServletException异常。 分类 解析器类型 说明 解析为Bean的名称 BeanNameViewResolver Bean的id即为逻辑视图名称。 解析为URL文件 InternalResourceViewResolver 将视图名解析成一个 URL 文件。 解析指定XML文件 XmlViewResolver 解析指定位置的XML文件，默认在/WEB-INF/views.xml 解析指定属性文件 ResourceBundleViewResolver 解析properties文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception &#123; boolean errorView = false; if (exception != null) &#123; // 异常页面处理 if (exception instanceof ModelAndViewDefiningException) &#123; mv = ((ModelAndViewDefiningException) exception).getModelAndView(); &#125; else &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); &#125; &#125; if (mv != null &amp;&amp; !mv.wasCleared()) &#123; //渲染视图 render(mv, request, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; return; &#125; if (mappedHandler != null) &#123; mappedHandler.triggerAfterCompletion(request, response, null); &#125;&#125;protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //获取国际化语言解析器对象 Locale locale = (this.localeResolver != null ? this.localeResolver.resolveLocale(request) : request.getLocale()); response.setLocale(locale); View view; String viewName = mv.getViewName();//获取视图名称 if (viewName != null) &#123;// 根据的视图名称通过视图解析器对象解析成为真正的物理视图 view = resolveViewName(viewName, mv.getModelInternal(), locale, request); if (view == null) &#123; throw new ServletException(\"Could not resolve view with name '\" + mv.getViewName() + \"' in servlet with name '\" + getServletName() + \"'\"); &#125; &#125; else &#123; view = mv.getView(); if (view == null) &#123; throw new ServletException(\"ModelAndView [\" + mv + \"] neither contains a view name nor a View object in servlet with name '\" + getServletName() + \"'\"); &#125; &#125; try &#123; if (mv.getStatus() != null) &#123; response.setStatus(mv.getStatus().value()); &#125; view.render(mv.getModelInternal(), request, response); //渲染模型视图 &#125; catch (Exception ex) &#123; throw ex; &#125;&#125; 根据的视图名称通过视图解析器对象解析成为真正的物理视图，最终调用AbstractCachingViewResolver的createView然后调用具体的视图解析器去创建物理视图。 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected View resolveViewName(String viewName, @Nullable Map&lt;String, Object&gt; model, Locale locale, HttpServletRequest request) throws Exception &#123; if (this.viewResolvers != null) &#123; //判断当前的视图解析器集合是否为空 for (ViewResolver viewResolver : this.viewResolvers) &#123; //循环调用的视图解析器对象解析视图 // 一旦有的视图解析器能够解析出视图，后面的视图解析器不在参与解析直接返回 View view = viewResolver.resolveViewName(viewName, locale); if (view != null) &#123; return view; &#125; &#125; &#125; return null;&#125;public View resolveViewName(String viewName, Locale locale) throws Exception &#123; // 是否启用缓存，可通过setCache()方法或setCacheLimit()方法开启缓存，是一个ConcurrentHashMap，默认缓存大小1024，可在配置视图解析器的时候，配置是否启用缓存默认情况下为了提升性能是开启的 if (!isCache()) &#123; return createView(viewName, locale); &#125; else &#123; Object cacheKey = getCacheKey(viewName, locale); // 获取缓存的key:viewName + '_' + locale; View view = this.viewAccessCache.get(cacheKey); // 尝试去缓存中加载 if (view == null) &#123; // dcl,防止并发解析 synchronized (this.viewCreationCache) &#123; view = this.viewCreationCache.get(cacheKey); if (view == null) &#123; view = createView(viewName, locale); // 调用子类去创建视图对象 if (view == null &amp;&amp; this.cacheUnresolved) &#123; view = UNRESOLVED_VIEW; &#125; if (view != null) &#123; this.viewAccessCache.put(cacheKey, view); this.viewCreationCache.put(cacheKey, view); if (logger.isTraceEnabled()) &#123; logger.trace(\"Cached view [\" + cacheKey + \"]\"); &#125; &#125; &#125; &#125; &#125; return (view != UNRESOLVED_VIEW ? view : null); &#125;&#125;public abstract class AbstractCachingViewResolver extends WebApplicationObjectSupport implements ViewResolver &#123; protected View createView(String viewName, Locale locale) throws Exception &#123; return loadView(viewName, locale); //加载一个视图 &#125;&#125; 分类 视图类型 说明 URL视图 InternalResourceView 将JSP或者其他资源封装成一个视图，InternaleResourceViewResolver默认视图类型。 JstlView 当在页面中使用了JSTL标签库的国际化标签后，需要采用的类型。 文档类视图 AbstractPdfView PDF文档视图的抽象类 AbstarctXlsView 4.2之后加入，Excel文档视图的抽象类之前使用AbstractExcelView JSON视图 MappingJackson2JsonView 将模型数据封装成Json格式数据输出需借助Jackson开源框架。 XML视图 MappingJackson2XmlView 4.1后加入，将模型数据封装成XML格式数据 视图的作用是渲染模型数据，将模型里的数据以某种形式呈现。为了实现视图模型和具体实现技术的解耦，Spring在org.springframework.web.servlet包中定义了一个高度抽象的View接口。通过renderMergedOutputModel调用具体的视图类去渲染视图。 123456789public void render(@Nullable Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Rendering view with name '\" + this.beanName + \"' with model \" + model + \" and static attributes \" + this.staticAttributes); &#125; Map&lt;String, Object&gt; mergedModel = createMergedOutputModel(model, request, response); // 获取模型数据 prepareResponse(request, response); // 设置响应头 renderMergedOutputModel(mergedModel, getRequestToExpose(request), response);&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"SpringMvc加载机制","date":"2021-10-04T16:00:00.000Z","path":"Blog/Spring/SpringMvc加载机制/","text":"Web容器启动时会调用ServletContainerInitializer的onStartup方法，以Tomcat容器为例，其调用实际是在StandardContext容器的startInternal()方法中被调用的，且可在该接口的实现类上标注@HandlesTypes注解，该注解配置的接口的实现类都会被传递到onStartup方法的入参中，并通过反射调用生成对象，Spring MVC中通过SpringServletContainerInitializer实现了ServletContainerInitializer接口，并在该类上通过@HandlesTypes注解导入了WebApplicationInitializer。 1234567891011121314151617181920212223242526272829@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer &#123; // 容器启动的时会调用该方法，且传入@HandlesTypes(WebApplicationInitializer.class) public void onStartup(@Nullable Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext) throws ServletException &#123; List&lt;WebApplicationInitializer&gt; initializers = new LinkedList&lt;&gt;(); if (webAppInitializerClasses != null) &#123; // 传入的webAppInitializerClasses类的所有子类 for (Class&lt;?&gt; waiClass : webAppInitializerClasses) &#123; //进行循环敢兴趣的类 // 判断类不是接口，不是抽象类 if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp; WebApplicationInitializer.class.isAssignableFrom(waiClass)) &#123; try &#123;// 通过反射调用创建类的实例，然后加入到initializers initializers.add((WebApplicationInitializer) ReflectionUtils.accessibleConstructor(waiClass).newInstance()); &#125; catch (Throwable ex) &#123; throw new ServletException(\"Failed to instantiate WebApplicationInitializer class\", ex); &#125; &#125; &#125; &#125; if (initializers.isEmpty()) &#123; servletContext.log(\"No Spring WebApplicationInitializer types detected on classpath\"); return; &#125; servletContext.log(initializers.size() + \" Spring WebApplicationInitializers detected on classpath\"); // 若WebApplicationInitializer的实现类实现了Orderd接口或者是标注了@Order注解，会进行排序 AnnotationAwareOrderComparator.sort(initializers); for (WebApplicationInitializer initializer : initializers) &#123; initializer.onStartup(servletContext); // 依次循环调用类的实例的onStartup方法 &#125; &#125;&#125; 最终会调用AbstractDispatcherServletInitializer抽象类的onStartup方法，该方法会先调用超类的onStartup方法创建rootAppContext，且将rootAppContext设置到ContextLoaderListener，并将创建的ContextLoaderListener设置到ServletContext中，在Tomcat的StandardContext容器调用listenerStart()方法中调用ContextLoaderListener的contextInitialized方法；然后创建webAppContext，并将其设置到新创建的DispatcherServlet中。 创建AnnotationConfigWebApplicationContext上下文仅仅调用register方法将创世纪的类和自定义的配置的注册到容器中，并没有启动容器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public abstract class AbstractDispatcherServletInitializer extends AbstractContextLoaderInitializer &#123; public void onStartup(ServletContext servletContext) throws ServletException &#123; super.onStartup(servletContext); registerDispatcherServlet(servletContext); &#125; protected void registerDispatcherServlet(ServletContext servletContext) &#123; String servletName = getServletName(); Assert.hasLength(servletName, \"getServletName() must not return null or empty\"); WebApplicationContext servletAppContext = createServletApplicationContext(); Assert.notNull(servletAppContext, \"createServletApplicationContext() must not return null\"); FrameworkServlet dispatcherServlet = createDispatcherServlet(servletAppContext); Assert.notNull(dispatcherServlet, \"createDispatcherServlet(WebApplicationContext) must not return null\"); dispatcherServlet.setContextInitializers(getServletApplicationContextInitializers()); ServletRegistration.Dynamic registration = servletContext.addServlet(servletName, dispatcherServlet); if (registration == null) &#123; throw new IllegalStateException(\"Failed to register servlet with name '\" + servletName + \"'. \" + \"Check if there is another servlet registered under the same name.\"); &#125; registration.setLoadOnStartup(1); registration.addMapping(getServletMappings()); registration.setAsyncSupported(isAsyncSupported()); Filter[] filters = getServletFilters(); if (!ObjectUtils.isEmpty(filters)) &#123; for (Filter filter : filters) &#123; registerServletFilter(servletContext, filter); &#125; &#125; customizeRegistration(registration); &#125;&#125;public abstract class AbstractContextLoaderInitializer implements WebApplicationInitializer &#123; public void onStartup(ServletContext servletContext) throws ServletException &#123; registerContextLoaderListener(servletContext); &#125; protected void registerContextLoaderListener(ServletContext servletContext) &#123; WebApplicationContext rootAppContext = createRootApplicationContext(); if (rootAppContext != null) &#123; ContextLoaderListener listener = new ContextLoaderListener(rootAppContext); listener.setContextInitializers(getRootApplicationContextInitializers()); servletContext.addListener(listener); &#125; &#125;&#125;public abstract class AbstractAnnotationConfigDispatcherServletInitializer extends AbstractDispatcherServletInitializer &#123; protected WebApplicationContext createRootApplicationContext() &#123; Class&lt;?&gt;[] configClasses = getRootConfigClasses(); if (!ObjectUtils.isEmpty(configClasses)) &#123; AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(configClasses); return context; &#125; else &#123; return null; &#125; &#125; protected WebApplicationContext createServletApplicationContext() &#123; AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); Class&lt;?&gt;[] configClasses = getServletConfigClasses(); if (!ObjectUtils.isEmpty(configClasses)) &#123; context.register(configClasses); &#125; return context; &#125;&#125; 故可通过继承AbstractAnnotationConfigDispatcherServletInitializer重写getRootConfigClasses、getServletConfigClasses方法来自定义设置Root容器的配置类和Web容器的配置类。 1234567891011121314public class ElevenStarterInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class[]&#123;RootConfig.class&#125;; &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[]&#123;WebAppConfig.class&#125;; &#125; @Override protected String[] getServletMappings() &#123; return new String[]&#123;\"/\"&#125;; &#125;&#125; 1234567@Configuration@ComponentScan(basePackages = \"com.eleven.icode.imvc\", excludeFilters = &#123; @ComponentScan.Filter(type = FilterType.ANNOTATION, value = &#123;RestController.class, Controller.class&#125;), @ComponentScan.Filter(type = ASSIGNABLE_TYPE, value = WebAppConfig.class),&#125;)public class RootConfig &#123;&#125; 12345678910111213141516171819202122@Configuration@ComponentScan(basePackages = &#123;\"com.eleven.icode.imvc\"&#125;, includeFilters = &#123; @ComponentScan.Filter(type = FilterType.ANNOTATION, value = &#123;RestController.class, Controller.class&#125;)&#125;, useDefaultFilters = false)@EnableWebMvcpublic class WebAppConfig implements WebMvcConfigurer &#123; @Bean public ElevenInterceptor tulingInterceptor() &#123; return new ElevenInterceptor(); &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(tulingInterceptor()).addPathPatterns(\"/*\"); &#125; @Bean public InternalResourceViewResolver internalResourceViewResolver() &#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setSuffix(\".jsp\"); viewResolver.setPrefix(\"/\"); return viewResolver; &#125;&#125; ContextLoaderListener实现了ServletContextListener接口，该接口是在Servlet API中定义的，提供了与Servlet生命周期结合的回调contextInitialized和contextDestroyed。这里只是去启动Root容器。通过注解方式在创建ContextLoaderListener就已将context传递进来了，这里不需要再创建了，只有通过xml方式的context才为空，需要在这里创建根容器对象。 当Root容器初始化完成后会将其保存到ServletContext应用上下文对象中，方便在Web容器实例化过程从ServletContext取出来设置为父容器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext()); &#125;&#125;public class ContextLoader &#123; public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException(\"Cannot initialize context because there is already a root application context present - check whether you have multiple ContextLoader* definitions in your web.xml!\"); &#125; try &#123; if (this.context == null) &#123; // 通过注解方式在外面就已经传递进来了，通过xml方式context为空，需要在这里创建根容器对象 this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; // 强制转化成ConfigurableWebApplicationContext ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; // 判断ConfigurableWebApplicationContext配置上下文版本的是不是激活了 if (!cwac.isActive()) &#123; // 没有激活 if (cwac.getParent() == null) &#123; // 若此时ConfigurableWebApplicationContext对象的父容器为空 ApplicationContext parent = loadParentContext(servletContext); // 为Root Context加载我们的父容器 cwac.setParent(parent); // parent == null &#125; configureAndRefreshWebApplicationContext(cwac, servletContext); // 配置和刷新根容器对象 &#125; &#125; // 把Spring上下文保存到应用上下文对象中，方便在Spring web上下文对象实例化过程会从servletContext取出来 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; return this.context; &#125; catch (RuntimeException ex) &#123; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125; &#125; protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; String idParam = sc.getInitParameter(CONTEXT_ID_PARAM); // 去ServletContext获取contextId if (idParam != null) &#123; wac.setId(idParam); // 若web.xml配置了该参数就设置到容器中 &#125; else &#123; //若没有配置，就使用默认的 wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; wac.setServletContext(sc); // 把当前工程的应用上下文设置到spring上下文中 String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM); if (configLocationParam != null) &#123; // 把配置文件的路径保存到上下文中 wac.setConfigLocation(configLocationParam); &#125; ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(sc, null); &#125; customizeContext(sc, wac); // 定制spring上下文对象 wac.refresh(); // 会触发IOC根容器的刷新 &#125;&#125; 对于Web容器的初始化工作是在DispatcherServlet的超类FrameworkServlet中的initServletBean()方法中完成的，该方法是Servlet的init方法中被调用。首先将之前初始化好的Root容器设置到当前Web容器中，然后将Web容器进行初始化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; protected final void initServletBean() throws ServletException &#123; try &#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException | RuntimeException ex) &#123; throw ex; &#125; &#125; protected WebApplicationContext initWebApplicationContext() &#123; // 从ServletContext对象中获取到Spring Root上下文对象，在Spring根容器上下文创建成功后放入到ServletContext对象中 WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // webApplicationContext对象是在创建DispatcherServlet对象时，存放进来的一个springmvc web的上下文对象 wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; // 判断是否激活 if (cwac.getParent() == null) &#123; // 设置父的上下文对象 cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); // 作为SpringMvc上下文刷新 &#125; &#125; &#125; if (wac == null) &#123; wac = findWebApplicationContext(); &#125; if (wac == null) &#123; wac = createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; synchronized (this.onRefreshMonitor) &#123; onRefresh(wac); &#125; &#125; if (this.publishContext) &#123; String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); &#125; return wac; &#125; protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; if (this.contextId != null) &#123; wac.setId(this.contextId); &#125; else &#123; wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(getServletContext().getContextPath()) + '/' + getServletName()); &#125; &#125; wac.setServletContext(getServletContext()); wac.setServletConfig(getServletConfig()); wac.setNamespace(getNamespace()); wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener())); ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(getServletContext(), getServletConfig()); &#125; postProcessWebApplicationContext(wac); applyInitializers(wac); wac.refresh(); &#125;&#125; 启动Web容器与启动Root容器基本类似，唯一比较大的区别是在Web容器启动前添加了一个ContextRefreshListener监听器，在容器启动完成时会进行调用，初始化Spring MVC九大组件。 123456789101112131415161718192021222324252627282930private class ContextRefreshListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; FrameworkServlet.this.onApplicationEvent(event); &#125;&#125;public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; public void onApplicationEvent(ContextRefreshedEvent event) &#123; this.refreshEventReceived = true; synchronized (this.onRefreshMonitor) &#123; onRefresh(event.getApplicationContext()); &#125; &#125;&#125;public class DispatcherServlet extends FrameworkServlet &#123; protected void onRefresh(ApplicationContext context) &#123; initStrategies(context); &#125; protected void initStrategies(ApplicationContext context) &#123; initMultipartResolver(context); // 初始化用于文件上传下载的解析器对象 initLocaleResolver(context); // 初始化用于处理国际化资源的解析器对象 initThemeResolver(context); // 主题解析器对象初始化 initHandlerMappings(context); // 初始化HandlerMapping initHandlerAdapters(context); // 初始化HandlerAdapters initHandlerExceptionResolvers(context); // 初始化处理器异常解析器对象 initRequestToViewNameTranslator(context); initViewResolvers(context); // 初始化给DispatcherSerlvet的ViewResolvers处理器 initFlashMapManager(context); &#125;&#125; 在@EnableWebMvc注解中导入了DelegatingWebMvcConfiguration配置类，该类的超类WebMvcConfigurationSupport中导入了很多Mvc请求处理相关的Bean。这里会导入一系列处理器映射器其中比较常用和重要的是RequestMappingHandlerMapping和BeanNameUrlHandlerMapping，前者是使用注解@Controller和@RequestMapping时默认映射策略，后者是XML方式通过在web.xml中配置的方式注册Bean默认映射策略。且RequestMappingHandlerMapping的Order为0，而BeanNameUrlHandlerMapping的Order为1。 123456789101112131415161718192021222324252627282930313233343536373839404142public class WebMvcConfigurationSupport implements ApplicationContextAware, ServletContextAware &#123; @Bean public RequestMappingHandlerMapping requestMappingHandlerMapping() &#123; RequestMappingHandlerMapping mapping = createRequestMappingHandlerMapping(); mapping.setOrder(0); mapping.setInterceptors(getInterceptors()); mapping.setContentNegotiationManager(mvcContentNegotiationManager()); mapping.setCorsConfigurations(getCorsConfigurations()); PathMatchConfigurer configurer = getPathMatchConfigurer(); Boolean useSuffixPatternMatch = configurer.isUseSuffixPatternMatch(); if (useSuffixPatternMatch != null) &#123; mapping.setUseSuffixPatternMatch(useSuffixPatternMatch); &#125; Boolean useRegisteredSuffixPatternMatch = configurer.isUseRegisteredSuffixPatternMatch(); if (useRegisteredSuffixPatternMatch != null) &#123; mapping.setUseRegisteredSuffixPatternMatch(useRegisteredSuffixPatternMatch); &#125; Boolean useTrailingSlashMatch = configurer.isUseTrailingSlashMatch(); if (useTrailingSlashMatch != null) &#123; mapping.setUseTrailingSlashMatch(useTrailingSlashMatch); &#125; UrlPathHelper pathHelper = configurer.getUrlPathHelper(); if (pathHelper != null) &#123; mapping.setUrlPathHelper(pathHelper); &#125; PathMatcher pathMatcher = configurer.getPathMatcher(); if (pathMatcher != null) &#123; mapping.setPathMatcher(pathMatcher); &#125; return mapping; &#125; public BeanNameUrlHandlerMapping beanNameHandlerMapping() &#123; BeanNameUrlHandlerMapping mapping = new BeanNameUrlHandlerMapping(); mapping.setOrder(2); mapping.setInterceptors(getInterceptors()); mapping.setCorsConfigurations(getCorsConfigurations()); return mapping; &#125;&#125; RequestMappingHandlerMapping实现了InitializingBean接口，在初始化时会调用afterPropertiesSet方法来进行初始化操作，该方法会调用父类AbstractHandlerMethodMapping的afterPropertiesSet方法来把Controller中的RequestMapping注解的路径和方法进行一一映射保存。 1234567891011121314151617181920212223242526272829303132333435363738394041public class RequestMappingHandlerMapping extends RequestMappingInfoHandlerMapping implements MatchableHandlerMapping, EmbeddedValueResolverAware &#123; public void afterPropertiesSet() &#123; // 构建RequestMappingInfo.BuilderConfiguration静态类部类对象 this.config = new RequestMappingInfo.BuilderConfiguration(); // 调用当前父类AbstractHandlerMapping.getUrlPathHelper()获取UrlPathHelper对象 this.config.setUrlPathHelper(getUrlPathHelper()); // 调用父类的AbstractHandlerMapping.getPathMatcher()的ant匹配器对象 this.config.setPathMatcher(getPathMatcher()); this.config.setSuffixPatternMatch(this.useSuffixPatternMatch); // 设置前缀匹配 this.config.setTrailingSlashMatch(this.useTrailingSlashMatch); // 末尾不带/的匹配 this.config.setRegisteredSuffixPatternMatch(this.useRegisteredSuffixPatternMatch); // 设置内容协商管理器，一个请求路径返回多种数据格式 this.config.setContentNegotiationManager(getContentNegotiationManager()); // 调用父类AbstractHandlerMethodMapping#afterPropertiesSet()方法来处理器路径和控制器映射 super.afterPropertiesSet(); &#125; protected boolean isHandler(Class&lt;?&gt; beanType) &#123; return (AnnotatedElementUtils.hasAnnotation(beanType, Controller.class) || AnnotatedElementUtils.hasAnnotation(beanType, RequestMapping.class)); &#125;&#125;public abstract class AbstractHandlerMethodMapping&lt;T&gt; extends AbstractHandlerMapping implements InitializingBean &#123; public void afterPropertiesSet() &#123; initHandlerMethods(); &#125; protected void initHandlerMethods() &#123; // 去web容器中获取出所有组件的beanNames获取出来 String[] beanNames = (this.detectHandlerMethodsInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(obtainApplicationContext(), Object.class) : obtainApplicationContext().getBeanNamesForType(Object.class)); for (String beanName : beanNames) &#123; if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123; Class&lt;?&gt; beanType = null; try &#123; // 通过beanName去web容器中获取beanType即class对象 beanType = obtainApplicationContext().getType(beanName); &#125; // 通过Class对象判断是不是一个controller对象判断类上面有没有@Controller||@RequestMapping注解 if (beanType != null &amp;&amp; isHandler(beanType)) &#123; detectHandlerMethods(beanName); // 探测我们的处理器方法对象 &#125; &#125; &#125; handlerMethodsInitialized(getHandlerMethods()); // 空方法 &#125;&#125; 把Controller中标注的@RequestMapping的方法对象做为key，配置的路径作为value设置到Map对象中，最终将把method和path的映射关系保存到MappingRegistry对象中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697public abstract class AbstractHandlerMethodMapping&lt;T&gt; extends AbstractHandlerMapping implements InitializingBean &#123; protected void detectHandlerMethods(Object handler) &#123; // 判断传入handler是不是beanName，若是则通过beanName从web容器中获取beanName对应的bean的class对象，否则直接获取handler的class对象 Class&lt;?&gt; handlerType = (handler instanceof String ? obtainApplicationContext().getType((String) handler) : handler.getClass()); if (handlerType != null) &#123; // 获取目标的class对象，防止class对象被cglib增强的 Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType); // 把Controller中标注的@RequestMapping的方法对象做为key，配置的路径作为value设置到Map对象中 // 使用lambda表达式，把getMappingForMethod(method,userType)方法注入到MethodIntrospector.MetadataLookup接口中的inspect方法中，真正调用inspect()方法时会调用getMappingForMethod方法 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, (MethodIntrospector.MetadataLookup&lt;T&gt;) method -&gt; &#123; try &#123; return getMappingForMethod(method, userType); &#125; catch (Throwable ex) &#123; throw new IllegalStateException(\"Invalid mapping on handler class [\" + userType.getName() + \"]: \" + method, ex); &#125; &#125;); // 循环上一步解析的map,把method---path 的映射关系保存到MappingRegistry对象中 methods.forEach((method, mapping) -&gt; &#123; // 解析map中的key（method）对象，获取method对象是不是一个可执行的method对象 Method invocableMethod = AopUtils.selectInvocableMethod(method, userType); // 把映射关系保存到MappingRegistry中 registerHandlerMethod(handler, invocableMethod, mapping); &#125;); &#125; &#125; protected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method); &#125; class MappingRegistry &#123; public void register(T mapping, Object handler, Method method) &#123; this.readWriteLock.writeLock().lock(); // 加写锁，写操作有且只有一个线程能操作 try &#123; // 根据controller对象和被调用的method对象来创建HandlerMethod HandlerMethod handlerMethod = createHandlerMethod(handler, method); assertUniqueMethodMapping(handlerMethod, mapping); // 判断处理器映射是否唯一 // 把url，和handlerMethod保存到mappingLookup map中mappingLookup&lt;RequestMappingInfo,HandlerMethod&gt; this.mappingLookup.put(mapping, handlerMethod); // 从RequestMappingInfo中解析出直接的url，@RequestMapping(value = &#123;\"/tuling\",\"/angle\"&#125;) urlLookUp(tuling,RequestMappingInfo) urlLookUp(angle,RequestMappingInfo) List&lt;String&gt; directUrls = getDirectUrls(mapping); for (String url : directUrls) &#123; this.urlLookup.add(url, mapping); &#125; String name = null; // 策略模式：生成name&#123;ElevenController&#125;TC#方法名===&gt;TC#testEleven Map&lt;String, List&lt;HandlerMethod&gt;&gt; if (getNamingStrategy() != null) &#123; name = getNamingStrategy().getName(handlerMethod, mapping); addMappingName(name, handlerMethod); &#125; CorsConfiguration corsConfig = initCorsConfiguration(handler, method, mapping); if (corsConfig != null) &#123; this.corsLookup.put(handlerMethod, corsConfig); &#125; // 映射表注册MappingRegistration对象 this.registry.put(mapping, new MappingRegistration&lt;&gt;(mapping, handlerMethod, directUrls, name)); &#125; finally &#123; this.readWriteLock.writeLock().unlock(); // 释放锁对象 &#125; &#125; &#125;&#125;public class RequestMappingHandlerMapping extends RequestMappingInfoHandlerMapping implements MatchableHandlerMapping, EmbeddedValueResolverAware &#123; protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) &#123; //解析method方法上的@ReuqestMapping注解，解析出对应的RequestMappingInfo对象 RequestMappingInfo info = createRequestMappingInfo(method); //方法级别上的RequestMapping注解不为空 if (info != null) &#123; // 创建类级别的RequestMappingInfo对象 RequestMappingInfo typeInfo = createRequestMappingInfo(handlerType); if (typeInfo != null) &#123; // 若Controller类上也标注了@RequestMapping info = typeInfo.combine(info); // 把类级别的RequestMappingInfo和方法级别的RequestMappingInfo连接起来 &#125; &#125; return info; &#125; private RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123; // 从element对象上找出request注解 RequestMapping requestMapping = AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class); // 获取@RequestMapping注解上的各个条件 RequestCondition&lt;?&gt; condition = (element instanceof Class ? getCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element)); // 判断requestMapping注解是否为空，不为空则真正的创建createRequestMappingInfo(requestMapping,condition) return (requestMapping != null ? createRequestMappingInfo(requestMapping, condition) : null); &#125; protected RequestMappingInfo createRequestMappingInfo(RequestMapping requestMapping, @Nullable RequestCondition&lt;?&gt; customCondition) &#123; RequestMappingInfo.Builder builder = RequestMappingInfo .paths(resolveEmbeddedValuesInPatterns(requestMapping.path())) //构建路径 .methods(requestMapping.method()) //构建方法(get还是post等) .params(requestMapping.params())//参数 对应http request parameter .headers(requestMapping.headers())//头部 .consumes(requestMapping.consumes())//request的提交内容类型content type,如application/json, text/html .produces(requestMapping.produces())//指定返回的内容类型的content type，仅当request请求头中的(Accept)类型中包含该指定类型才返回 .mappingName(requestMapping.name()); if (customCondition != null) &#123; builder.customCondition(customCondition); &#125; return builder.options(this.config).build(); // 真正的构建RequestMappingInfo对象 &#125;&#125; BeanNameUrlHandlerMapping是ApplicationContextAware的子类，对于映射关系的解析是在其加载完毕后通过调用Aware接口的setApplicationContext方法触发调用initApplicationContext()方法从而进行映射关系的解析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class BeanNameUrlHandlerMapping extends AbstractDetectingUrlHandlerMapping &#123; protected String[] determineUrlsForHandler(String beanName) &#123; List&lt;String&gt; urls = new ArrayList&lt;&gt;(); if (beanName.startsWith(\"/\")) &#123; urls.add(beanName); &#125; String[] aliases = obtainApplicationContext().getAliases(beanName); for (String alias : aliases) &#123; if (alias.startsWith(\"/\")) &#123; urls.add(alias); &#125; &#125; return StringUtils.toStringArray(urls); &#125;&#125;public abstract class AbstractDetectingUrlHandlerMapping extends AbstractUrlHandlerMapping &#123; public void initApplicationContext() throws ApplicationContextException &#123; super.initApplicationContext(); detectHandlers(); &#125; protected void detectHandlers() throws BeansException &#123; ApplicationContext applicationContext = obtainApplicationContext(); String[] beanNames = (this.detectHandlersInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class) : applicationContext.getBeanNamesForType(Object.class)); for (String beanName : beanNames) &#123; String[] urls = determineUrlsForHandler(beanName); if (!ObjectUtils.isEmpty(urls)) &#123; registerHandler(urls, beanName); &#125; &#125; &#125; protected void registerHandler(String[] urlPaths, String beanName) throws BeansException, IllegalStateException &#123; for (String urlPath : urlPaths) &#123; registerHandler(urlPath, beanName); &#125; &#125; protected void registerHandler(String urlPath, Object handler) throws BeansException, IllegalStateException &#123; Object resolvedHandler = handler; if (!this.lazyInitHandlers &amp;&amp; handler instanceof String) &#123; String handlerName = (String) handler; ApplicationContext applicationContext = obtainApplicationContext(); if (applicationContext.isSingleton(handlerName)) &#123; resolvedHandler = applicationContext.getBean(handlerName); &#125; &#125; Object mappedHandler = this.handlerMap.get(urlPath); if (mappedHandler != null) &#123; if (mappedHandler != resolvedHandler) &#123; throw new IllegalStateException(\"Cannot map \" + getHandlerDescription(handler) + \" to URL path [\" + urlPath + \"]: There is already \" + getHandlerDescription(mappedHandler) + \" mapped.\"); &#125; &#125; else &#123; if (urlPath.equals(\"/\")) &#123; setRootHandler(resolvedHandler); &#125; else if (urlPath.equals(\"/*\")) &#123; setDefaultHandler(resolvedHandler); &#125; else &#123; this.handlerMap.put(urlPath, resolvedHandler); &#125; &#125; &#125;&#125; 在WebMvcConfigurationSupport中也会导入一系列处理器适配器RequestMappingHandlerAdapter、HttpRequestHandlerAdapter、SimpleControllerHandlerAdapter 123456789101112131415161718192021222324252627282930313233343536public class WebMvcConfigurationSupport implements ApplicationContextAware, ServletContextAware &#123; @Bean public RequestMappingHandlerAdapter requestMappingHandlerAdapter() &#123; RequestMappingHandlerAdapter adapter = createRequestMappingHandlerAdapter(); adapter.setContentNegotiationManager(mvcContentNegotiationManager()); adapter.setMessageConverters(getMessageConverters()); adapter.setWebBindingInitializer(getConfigurableWebBindingInitializer()); adapter.setCustomArgumentResolvers(getArgumentResolvers()); adapter.setCustomReturnValueHandlers(getReturnValueHandlers()); if (jackson2Present) &#123; adapter.setRequestBodyAdvice(Collections.singletonList(new JsonViewRequestBodyAdvice())); adapter.setResponseBodyAdvice(Collections.singletonList(new JsonViewResponseBodyAdvice())); &#125; AsyncSupportConfigurer configurer = new AsyncSupportConfigurer(); configureAsyncSupport(configurer); if (configurer.getTaskExecutor() != null) &#123; adapter.setTaskExecutor(configurer.getTaskExecutor()); &#125; if (configurer.getTimeout() != null) &#123; adapter.setAsyncRequestTimeout(configurer.getTimeout()); &#125; adapter.setCallableInterceptors(configurer.getCallableInterceptors()); adapter.setDeferredResultInterceptors(configurer.getDeferredResultInterceptors()); return adapter; &#125; @Bean public HttpRequestHandlerAdapter httpRequestHandlerAdapter() &#123; return new HttpRequestHandlerAdapter(); &#125; @Bean public SimpleControllerHandlerAdapter simpleControllerHandlerAdapter() &#123; return new SimpleControllerHandlerAdapter(); &#125;&#125; RequestMappingHandlerAdapter实现了InitializingBean接口，在初始化时会调用afterPropertiesSet方法来进行初始化操作，主要是解析标注了@ControllerAdvice、@InitBinder、@ModelAttribute等注解的类和方法，并将解析后的数据放入缓存中。以及添加一系列的参数解析器、标注@InitBinder注解方法的参数解析器、返回值解析器。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; public static final MethodFilter INIT_BINDER_METHODS = method -&gt; (AnnotationUtils.findAnnotation(method, InitBinder.class) != null); public static final MethodFilter MODEL_ATTRIBUTE_METHODS = method -&gt; (AnnotationUtils.findAnnotation(method, RequestMapping.class) == null &amp;&amp; AnnotationUtils.findAnnotation(method, ModelAttribute.class) != null); public void afterPropertiesSet() &#123; initControllerAdviceCache(); // 实例化标注了@ControllerAdvice等组件 if (this.argumentResolvers == null) &#123; // 加入容器中各种参数解析器对象 List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultArgumentResolvers(); this.argumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.initBinderArgumentResolvers == null) &#123; // 解析@InitBinder注解标注的方法的参数解析器对象 List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultInitBinderArgumentResolvers(); this.initBinderArgumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.returnValueHandlers == null) &#123; // 返回值解析器对象 List&lt;HandlerMethodReturnValueHandler&gt; handlers = getDefaultReturnValueHandlers(); this.returnValueHandlers = new HandlerMethodReturnValueHandlerComposite().addHandlers(handlers); &#125; &#125; private void initControllerAdviceCache() &#123; if (getApplicationContext() == null) &#123; return; &#125; // 传入web上下文对象，查找容器中标注了@ControllerAdvice组件的bean List&lt;ControllerAdviceBean&gt; adviceBeans = ControllerAdviceBean.findAnnotatedBeans(getApplicationContext()); AnnotationAwareOrderComparator.sort(adviceBeans); // 排序 List&lt;Object&gt; requestResponseBodyAdviceBeans = new ArrayList&lt;&gt;(); for (ControllerAdviceBean adviceBean : adviceBeans) &#123; // 循环所有的@ControllerAdvice的集合 Class&lt;?&gt; beanType = adviceBean.getBeanType(); // 获取bean的class类型 if (beanType == null) &#123; throw new IllegalStateException(\"Unresolvable type for ControllerAdviceBean: \" + adviceBean); &#125; // 获取class类中所有标注了@ModelAttribute注解 Set&lt;Method&gt; attrMethods = MethodIntrospector.selectMethods(beanType, MODEL_ATTRIBUTE_METHODS); if (!attrMethods.isEmpty()) &#123; // 标注了@ModelAttribute标注的方法不为空 this.modelAttributeAdviceCache.put(adviceBean, attrMethods); // 加入到缓存中 &#125; // 查找全局的@InitBinder注解标标注的方法 Set&lt;Method&gt; binderMethods = MethodIntrospector.selectMethods(beanType, INIT_BINDER_METHODS); if (!binderMethods.isEmpty()) &#123; // 不为空加入到缓存中 this.initBinderAdviceCache.put(adviceBean, binderMethods); &#125; boolean isRequestBodyAdvice = RequestBodyAdvice.class.isAssignableFrom(beanType); boolean isResponseBodyAdvice = ResponseBodyAdvice.class.isAssignableFrom(beanType); if (isRequestBodyAdvice || isResponseBodyAdvice) &#123; requestResponseBodyAdviceBeans.add(adviceBean); &#125; &#125; if (!requestResponseBodyAdviceBeans.isEmpty()) &#123; this.requestResponseBodyAdvice.addAll(0, requestResponseBodyAdviceBeans); &#125; &#125;&#125;public class ControllerAdviceBean implements Ordered &#123; public static List&lt;ControllerAdviceBean&gt; findAnnotatedBeans(ApplicationContext applicationContext) &#123; List&lt;ControllerAdviceBean&gt; beans = new ArrayList&lt;&gt;(); for (String name : BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class)) &#123; if (applicationContext.findAnnotationOnBean(name, ControllerAdvice.class) != null) &#123; // 若组件上标注了@ControllerAdvice，则加入到集合中返回 beans.add(new ControllerAdviceBean(name, applicationContext)); &#125; &#125; return beans; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"事务解析原理","date":"2021-09-28T16:00:00.000Z","path":"Blog/Spring/事务解析原理/","text":"事务的解析与执行是依赖AOP实现的，Spring中开启事务是通过@EnableTransactionManagement注解来完成的，在该注解上通过@Import为容器导入了一个组件TransactionManagementConfigurationSelector，该组件是一个ImportSelector其为容器注册一个为AutoProxyRegistrar的ImportBeanDefinitionRegistrar开启AOP代理，以及一个事务代理的配置类ProxyTransactionManagementConfiguration导入关于事务的切面信息。 12345678910111213141516171819public class TransactionManagementConfigurationSelector extends AdviceModeImportSelector&lt;EnableTransactionManagement&gt; &#123; // 在容器中加载Bean定义时回调selectImports方法，该方法返回值需要导入类的全类名路径，然后这个类会被加载到容器中 @Override protected String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; // 为容器中导入AutoProxyRegistrar、ProxyTransactionManagementConfiguration case PROXY: return new String[] &#123;AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()&#125;; case ASPECTJ: // 绝大部分情况下，不会使用AspectJ的静态代理的 return new String[] &#123;TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME&#125;; default: return null; &#125; &#125; private String determineTransactionAspectClass() &#123; return (ClassUtils.isPresent(\"javax.transaction.Transactional\", getClass().getClassLoader()) ? TransactionManagementConfigUtils.JTA_TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME : TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME); &#125;&#125; AdviceModeImportSelector目前所知有AsyncConfigurationSelector、TransactionManagementConfigurationSelector、CachingConfigurationSelector三个子类。明显缓存体系@EnableCaching和异步@EnableAsync模式也是和这个极其类似的。自动代理注册AutoProxyRegistrar的作用是向容器注册一个解析事务的后置处理器InfrastructureAdvisorAutoProxyCreator。首先获取到所有的注解类型，而不是只获取@EnableAspectJAutoProxy注解，因为mode、proxyTargetClass等属性会直接影响到代理得方式，而@EnableTransactionManagement、@EnableAsync、@EnableCaching、@EnableAspectJAutoProxy等注解都拥有这些属性。 1234567891011121314151617181920212223242526public class AutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; boolean candidateFound = false; Set&lt;String&gt; annTypes = importingClassMetadata.getAnnotationTypes(); // 获取所有的注解类型 for (String annType : annTypes) &#123; AnnotationAttributes candidate = AnnotationConfigUtils.attributesFor(importingClassMetadata, annType); if (candidate == null) &#123; continue; &#125; Object mode = candidate.get(\"mode\"); // 默认PROXY Object proxyTargetClass = candidate.get(\"proxyTargetClass\"); // 是否强制使用Cglib代理 // 存在mode且存在proxyTargetClass属性，且两个属性的class类型也是对的 if (mode != null &amp;&amp; proxyTargetClass != null &amp;&amp; AdviceMode.class == mode.getClass() &amp;&amp; Boolean.class == proxyTargetClass.getClass()) &#123; candidateFound = true; // 标志找到候选注解 if (mode == AdviceMode.PROXY) &#123; // 注册了internalAutoProxyCreator，但若出现多次，这里不是覆盖而是以第一次的为主 AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); if ((Boolean) proxyTargetClass) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); return; &#125; &#125; &#125; &#125; &#125;&#125; 和开启AOP代理类似这里通过AopConfigUtils的registerAutoProxyCreatorIfNecessary真正去注册该后置处理器。最终调用registerOrEscalateApcAsRequired该方法和开启AOP代理时调用的是同一个方法，且向容器中注册的Bean的名称都是同一个internalAutoProxyCreator。这里会根据优先级来确定注册哪个类。AOP的会覆盖事务的， 因为AOP优先级更大。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class AopConfigUtils &#123; private static final List&lt;Class&lt;?&gt;&gt; APC_PRIORITY_LIST = new ArrayList&lt;&gt;(3); static &#123; APC_PRIORITY_LIST.add(InfrastructureAdvisorAutoProxyCreator.class); APC_PRIORITY_LIST.add(AspectJAwareAdvisorAutoProxyCreator.class); APC_PRIORITY_LIST.add(AnnotationAwareAspectJAutoProxyCreator.class); &#125; public static BeanDefinition registerAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry) &#123; return registerAutoProxyCreatorIfNecessary(registry, null); &#125; public static BeanDefinition registerAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, @Nullable Object source) &#123; return registerOrEscalateApcAsRequired(InfrastructureAdvisorAutoProxyCreator.class, registry, source); &#125; private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; apcDefinition.setBeanClassName(cls.getName()); &#125; &#125; return null; &#125; RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(\"order\", Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition; &#125; private static int findPriorityForClass(Class&lt;?&gt; clazz) &#123; return APC_PRIORITY_LIST.indexOf(clazz); &#125; private static int findPriorityForClass(@Nullable String className) &#123; for (int i = 0; i &lt; APC_PRIORITY_LIST.size(); i++) &#123; Class&lt;?&gt; clazz = APC_PRIORITY_LIST.get(i); if (clazz.getName().equals(className)) &#123; return i; &#125; &#125; throw new IllegalArgumentException(\"Class name [\" + className + \"] is not a known auto-proxy creator class\"); &#125;&#125; 若同时开启AOP和事务则根据优先级最终还是加载的解析和创建AOP代理的后置处理器AnnotationAwareAspectJAutoProxyCreator，且其与InfrastructureAdvisorAutoProxyCreator都是上层接口都是一样的。这里重写了isEligibleAdvisorBean方法。 12345678public class InfrastructureAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator &#123; @Override protected boolean isEligibleAdvisorBean(String beanName) &#123; // 容器中包含了这个bean定义，并且bean定义角色为BeanDefinition.ROLE_INFRASTRUCTURE return (this.beanFactory != null &amp;&amp; this.beanFactory.containsBeanDefinition(beanName) &amp;&amp; this.beanFactory.getBeanDefinition(beanName).getRole() == BeanDefinition.ROLE_INFRASTRUCTURE); &#125;&#125; ProxyTransactionManagementConfiguration是一个@Configuration事务配置类，其主要作用是配置一个处理事务的Advisor。配置的事务拦截器是一个MethodInterceptor，也可以自定义一个同名的TransactionInterceptor来覆盖此Bean。 1234567891011121314151617181920212223242526272829@Configurationpublic class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration &#123; @Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor() &#123; BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor(); advisor.setTransactionAttributeSource(transactionAttributeSource()); advisor.setAdvice(transactionInterceptor()); if (this.enableTx != null) &#123; advisor.setOrder(this.enableTx.&lt;Integer&gt;getNumber(\"order\")); &#125; return advisor; // 导入了关于事务的切面信息 &#125; @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionAttributeSource transactionAttributeSource() &#123; return new AnnotationTransactionAttributeSource(); // 事务属性源对象，用于获取事务属性对象 &#125; @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionInterceptor transactionInterceptor() &#123; // 用户拦截事务方法执行的 TransactionInterceptor interceptor = new TransactionInterceptor(); interceptor.setTransactionAttributeSource(transactionAttributeSource()); if (this.txManager != null) &#123; interceptor.setTransactionManager(this.txManager); &#125; return interceptor; &#125;&#125; AnnotationTransactionAttributeSource是基于注解驱动的事务管理的事务属性源，其作用是解析@Transactional注解，将其解析成TransactionAttribute后后续调用，也可如下自定义事务属性源，通过名称匹配的方式。 1234567891011121314151617181920212223@Beanpublic TransactionAttributeSource transactionAttributeSource() &#123; Map&lt;String, TransactionAttribute&gt; txMap = new HashMap&lt;&gt;(); // required事务适用于增删改场景 RuleBasedTransactionAttribute requiredTx = new RuleBasedTransactionAttribute(); requiredTx.setRollbackRules(Collections.singletonList(new RollbackRuleAttribute(RuntimeException.class))); requiredTx.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); txMap.put(\"add*\", requiredTx); txMap.put(\"save*\", requiredTx); txMap.put(\"insert*\", requiredTx); txMap.put(\"update*\", requiredTx); txMap.put(\"delete*\", requiredTx); // 查询 使用只读事务 RuleBasedTransactionAttribute readOnlyTx = new RuleBasedTransactionAttribute(); readOnlyTx.setReadOnly(true); readOnlyTx.setPropagationBehavior(TransactionDefinition.PROPAGATION_NOT_SUPPORTED); txMap.put(\"get*\", readOnlyTx); txMap.put(\"query*\", readOnlyTx); NameMatchTransactionAttributeSource source = new NameMatchTransactionAttributeSource(); source.setNameMap(txMap); return source;&#125; BeanFactoryTransactionAttributeSourceAdvisor会在切面解析时第一个被实例化的Bean调用时被BeanFactoryAdvisorRetrievalHelper的findAdvisorBeans中被解析出来并将其名称放入cachedAdvisorBeanNames缓存中。 12345678910111213141516171819public class BeanFactoryTransactionAttributeSourceAdvisor extends AbstractBeanFactoryPointcutAdvisor &#123; @Nullable private TransactionAttributeSource transactionAttributeSource; // 事务属性源切点 private final TransactionAttributeSourcePointcut pointcut = new TransactionAttributeSourcePointcut() &#123; @Override @Nullable protected TransactionAttributeSource getTransactionAttributeSource() &#123; return transactionAttributeSource; &#125; &#125;; public void setTransactionAttributeSource(TransactionAttributeSource transactionAttributeSource) &#123; this.transactionAttributeSource = transactionAttributeSource; // 可手动设置一个事务属性源 &#125; @Override public Pointcut getPointcut() &#123; return this.pointcut; &#125;&#125; 事务切面解析时和AOP的切面相同的逻辑，同样调用的是canApply方法经过了初筛和精筛，事务这初筛一般是通过的。初筛时调用TransactionAttributeSourceClassFilter的matches方法，精筛最终是通过MethodMatcher的matches方法，实际调用TransactionAttributeSourcePointcut的matches方法。 1234567891011121314151617181920212223242526abstract class TransactionAttributeSourcePointcut extends StaticMethodMatcherPointcut implements Serializable &#123; @Override public boolean matches(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; if (targetClass != null &amp;&amp; TransactionalProxy.class.isAssignableFrom(targetClass)) &#123; return false; &#125; // 获取我们@EnableTransactionManagement注解为容器中导入的ProxyTransactionManagementConfiguration配置类中的TransactionAttributeSource对象 TransactionAttributeSource tas = getTransactionAttributeSource(); // 通过getTransactionAttribute看是否有@Transactional注解 return (tas == null || tas.getTransactionAttribute(method, targetClass) != null); &#125; @Nullable protected abstract TransactionAttributeSource getTransactionAttributeSource(); private class TransactionAttributeSourceClassFilter implements ClassFilter &#123; @Override public boolean matches(Class&lt;?&gt; clazz) &#123; if (TransactionalProxy.class.isAssignableFrom(clazz) || PlatformTransactionManager.class.isAssignableFrom(clazz) || PersistenceExceptionTranslator.class.isAssignableFrom(clazz)) &#123; return false; &#125; TransactionAttributeSource tas = getTransactionAttributeSource(); return (tas == null || tas.isCandidateClass(clazz)); &#125; &#125;&#125; 最终调用AnnotationTransactionAttributeSource的超类AbstractFallbackTransactionAttributeSource中的getTransactionAttribute方法。若method所在的类是Object则直接返回空，否则先从缓存中获取，若缓存为空说明没有被解析过，则通过computeTransactionAttribute去解析，无论是否解析到事务属性都将其放入缓存中。还会把方法描述设置到事务属性descriptor上去，调用的时候会从事务属性中获取。 1234567891011121314151617181920212223242526272829public abstract class AbstractFallbackTransactionAttributeSource implements TransactionAttributeSource &#123; public TransactionAttribute getTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; if (method.getDeclaringClass() == Object.class) &#123; return null; // 判断method所在的class是否为Object类型 &#125; Object cacheKey = getCacheKey(method, targetClass);// 构建缓存key TransactionAttribute cached = this.attributeCache.get(cacheKey);// 先去缓存中获取 if (cached != null) &#123;// 缓存中不为空 if (cached == NULL_TRANSACTION_ATTRIBUTE) &#123;// 判断缓存中的对象是不是空事务属性的对象 return null; &#125; else &#123; return cached;// 若缓存存在则返回 &#125; &#125; else &#123; TransactionAttribute txAttr = computeTransactionAttribute(method, targetClass);// 查找事务注解 if (txAttr == null) &#123;// 若解析出来的事务注解属性为空 this.attributeCache.put(cacheKey, NULL_TRANSACTION_ATTRIBUTE);//往缓存中存放空事务注解属性 &#125; else &#123; // 执行方法的描述符：全类名+方法名 String methodIdentification = ClassUtils.getQualifiedMethodName(method, targetClass); if (txAttr instanceof DefaultTransactionAttribute) &#123;// 把方法描述设置到事务属性上去 ((DefaultTransactionAttribute) txAttr).setDescriptor(methodIdentification); &#125; this.attributeCache.put(cacheKey, txAttr);//加入到缓存 &#125; return txAttr; &#125; &#125;&#125; 首先去目标类的当前方法上去找事务注解，若找到直接解析返回，若找不到再去目标类上去找事务注解，若找不到，再判断若具体方法不是当前的方法说明当前方法是接口方法，再去实现类的接口上的方法去找事务注解，最后再去实现类的接口上去找事务注解。 getMostSpecificMethod是得到具体的方法，若method是接口方法将从targetClass得到实现类的方法，故无论传的是接口还是实现，都会先解析实现类。可从该代码逻辑看出，@Transactional注解既可以用在方法上还可以用在类上甚至是接口方法和接口上，但若这些地方都有该注解，则方法上的该注解会覆盖类上的。 1234567891011121314151617181920212223242526272829public abstract class AbstractFallbackTransactionAttributeSource implements TransactionAttributeSource &#123; protected TransactionAttribute computeTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null; // 判断事务方法上的修饰符是不是public的 &#125; Method specificMethod = AopUtils.getMostSpecificMethod(method, targetClass); // 去目标class的方法上去找事务注解 TransactionAttribute txAttr = findTransactionAttribute(specificMethod); if (txAttr != null) &#123; return txAttr; &#125; // 去目标类即实现类上找事务注解 txAttr = findTransactionAttribute(specificMethod.getDeclaringClass()); if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; if (specificMethod != method) &#123; // 具体方法不是当前的方法说明当前方法是接口方法 txAttr = findTransactionAttribute(method); // 去实现类的接口上的方法去找事务注解 if (txAttr != null) &#123; return txAttr; &#125; txAttr = findTransactionAttribute(method.getDeclaringClass()); // 去实现类的接口上去找事务注解 if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; &#125; return null; &#125;&#125; 这里的findTransactionAttribute调用是AnnotationTransactionAttributeSource的方法，最终会调用SpringTransactionAnnotationParser的parseTransactionAnnotation。初筛的matches方法实际调用的是该类的isCandidateClass。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class AnnotationTransactionAttributeSource extends AbstractFallbackTransactionAttributeSource implements Serializable &#123; private final Set&lt;TransactionAnnotationParser&gt; annotationParsers; public AnnotationTransactionAttributeSource() &#123; this(true); &#125; public AnnotationTransactionAttributeSource(boolean publicMethodsOnly) &#123; this.publicMethodsOnly = publicMethodsOnly; if (jta12Present || ejb3Present) &#123; // 是否支持 jta和 ejb的事务解析 this.annotationParsers = new LinkedHashSet&lt;&gt;(4); this.annotationParsers.add(new SpringTransactionAnnotationParser()); if (jta12Present) &#123; this.annotationParsers.add(new JtaTransactionAnnotationParser()); &#125; if (ejb3Present) &#123; this.annotationParsers.add(new Ejb3TransactionAnnotationParser()); &#125; &#125; else &#123; this.annotationParsers = Collections.singleton(new SpringTransactionAnnotationParser()); &#125; &#125; protected TransactionAttribute findTransactionAttribute(Class&lt;?&gt; clazz) &#123; return determineTransactionAttribute(clazz); &#125; protected TransactionAttribute findTransactionAttribute(Method method) &#123; return determineTransactionAttribute(method); &#125; protected TransactionAttribute determineTransactionAttribute(AnnotatedElement element) &#123; for (TransactionAnnotationParser annotationParser : this.annotationParsers) &#123; // 获取注解解析器 // 通过注解解析器去解析方法或类上的注解 TransactionAttribute attr = annotationParser.parseTransactionAnnotation(element); if (attr != null) &#123; return attr; &#125; &#125; return null; &#125; public boolean isCandidateClass(Class&lt;?&gt; targetClass) &#123; for (TransactionAnnotationParser parser : this.annotationParsers) &#123; if (parser.isCandidateClass(targetClass)) &#123; return true; &#125; &#125; return false; &#125;&#125; 若在目标元素上找到@Transactional注解，则通过parseTransactionAnnotation方法对该注解属性进行解析。 123456789101112131415161718192021222324252627282930313233343536373839404142public class SpringTransactionAnnotationParser implements TransactionAnnotationParser, Serializable &#123; public boolean isCandidateClass(Class&lt;?&gt; targetClass) &#123; return AnnotationUtils.isCandidateClass(targetClass, Transactional.class); &#125; public TransactionAttribute parseTransactionAnnotation(AnnotatedElement element) &#123; // 从element对象中获取@Transactional注解，然后把注解属性封装到了AnnotationAttributes AnnotationAttributes attributes = AnnotatedElementUtils.findMergedAnnotationAttributes(element, Transactional.class, false, false); if (attributes != null) &#123;// 解析出真正的事务属性对象 return parseTransactionAnnotation(attributes); &#125; else &#123; return null; &#125; &#125; public TransactionAttribute parseTransactionAnnotation(Transactional ann) &#123; return parseTransactionAnnotation(AnnotationUtils.getAnnotationAttributes(ann, false, false)); &#125; protected TransactionAttribute parseTransactionAnnotation(AnnotationAttributes attributes) &#123; RuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute(); // 创建一个基础规则的事务属性对象 Propagation propagation = attributes.getEnum(\"propagation\"); // 解析@Transactionl上的传播行为 rbta.setPropagationBehavior(propagation.value()); Isolation isolation = attributes.getEnum(\"isolation\"); // 解析@Transactionl上的隔离级别 rbta.setIsolationLevel(isolation.value()); rbta.setTimeout(attributes.getNumber(\"timeout\").intValue()); // 解析@Transactionl上的事务超时事件 rbta.setReadOnly(attributes.getBoolean(\"readOnly\")); rbta.setQualifier(attributes.getString(\"value\")); // 解析@Transactionl上的事务管理器的名称 List&lt;RollbackRuleAttribute&gt; rollbackRules = new ArrayList&lt;&gt;(); for (Class&lt;?&gt; rbRule : attributes.getClassArray(\"rollbackFor\")) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); // 针对哪种异常回滚 &#125; for (String rbRule : attributes.getStringArray(\"rollbackForClassName\")) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); // 对哪种异常进行回滚 &#125; for (Class&lt;?&gt; rbRule : attributes.getClassArray(\"noRollbackFor\")) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); // 对哪种异常不回滚 &#125; for (String rbRule : attributes.getStringArray(\"noRollbackForClassName\")) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); // 对哪种类型不回滚 &#125; rbta.setRollbackRules(rollbackRules); return rbta; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"事务调用原理","date":"2021-09-28T16:00:00.000Z","path":"Blog/Spring/事务调用原理/","text":"@Transactional生效的方法的调用，还是走AOP代理调用逻辑，即通过ReflectiveMethodInvocation的proceed()调用逻辑，不过这里调用的拦截器链不是通过注解自定义配置的，而是在ProxyTransactionManagementConfiguration配置类中配置的TransactionInterceptor。 12345678public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable &#123; public Object invoke(MethodInvocation invocation) throws Throwable &#123; // 获取代理对象的class属性 Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // 在事务中执行目标方法，在这埋了一个钩子函数invocation::proceed，用来回调目标方法 return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); &#125;&#125; 这里解释事务的核心逻辑，首先通过事务属性主要是传播属性是否为嵌套事务等判断是否有必要创建事务，然后通过invocation.proceedWithInvocation()函数式接口回到ReflectiveMethodInvocation的proceed()中去调用真正的目标方法，若调用目标方法抛出异常，则会走事务回滚逻辑，否则提交事务。 TransactionAttributeSource配置类中导入的，TransactionAttribute做切点匹配时已经解析完成其包含事务属性，PlatformTransactionManager是配置类中添加其包含数据源，连接点标识符joinpointIdentification是匹配事务时得到的并设置到事务属性的descriptor中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // 获取在配置类中添加的事务属源对象，在创建代理进行匹配时将解析的事务属性赋值 TransactionAttributeSource tas = getTransactionAttributeSource(); // 获取解析后的事务属性信息，创建代理时已调用getTransactionAttribute，这里从解析后的缓存中获取 final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); // 获取配置的事务管理器对象 final PlatformTransactionManager tm = determineTransactionManager(txAttr); // 从tx属性对象中获取出标注了@Transactionl的方法描述符 final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // 处理声明式事务 // 若有必要创建事务 TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal; try &#123; retVal = invocation.proceedWithInvocation(); // 调用钩子函数进行回调目标方法 &#125; catch (Throwable ex) &#123; // 抛出异常进行回滚处理 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); // 清空我们的线程变量中transactionInfo的值 &#125; commitTransactionAfterReturning(txInfo); // 提交事务 return retVal; &#125; else &#123; // 编程式事务：（回调偏向） final ThrowableHolder throwableHolder = new ThrowableHolder(); try &#123; Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, status -&gt; &#123; TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); try &#123; return invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; if (txAttr.rollbackOn(ex)) &#123; if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new ThrowableHolderException(ex); &#125; &#125; else &#123; throwableHolder.throwable = ex; return null; &#125; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; &#125;); if (throwableHolder.throwable != null) &#123; throw throwableHolder.throwable; &#125; return result; &#125; catch (ThrowableHolderException ex) &#123; throw ex.getCause(); &#125; catch (TransactionSystemException ex2) &#123; if (throwableHolder.throwable != null) &#123; ex2.initApplicationException(throwableHolder.throwable); &#125; throw ex2; &#125; catch (Throwable ex2) &#123; throw ex2; &#125; &#125; &#125;&#125; 若事务没有定义名称，则把连接点的名称定义成事务的名称，然后获取当前事务状态，并将事物状态和事物属性等信息封装成一个TransactionInfo对象便于后续使用。 1234567891011121314151617181920212223242526272829public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123; // 若没定义名字，把连接点的名称定义成事务的名称 if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123; txAttr = new DelegatingTransactionAttribute(txAttr) &#123; @Override public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123;//获取一个事务状态 status = tm.getTransaction(txAttr); &#125; &#125; // 把事物状态和事物属性等信息封装成一个TransactionInfo对象 return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); &#125; protected TransactionInfo prepareTransactionInfo(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, String joinpointIdentification, @Nullable TransactionStatus status) &#123; TransactionInfo txInfo = new TransactionInfo(tm, txAttr, joinpointIdentification); if (txAttr != null) &#123; txInfo.newTransactionStatus(status); &#125; txInfo.bindToThread(); //把事务信息对象绑定到当前线程变量中 return txInfo; &#125;&#125; 在执行事务前会将上层事务状态，从事务信息线程本地变量中获取存入oldTransactionInfo，若为顶层事务该值肯定为null，但嵌套事务肯定不为null，当执行完用户代码逻辑后在finally中调用cleanupTransactionInfo从而调用restoreThreadLocalStatus将上层事务信息再返回线程本地变量中。 123456789101112protected static final class TransactionInfo &#123; public void newTransactionStatus(@Nullable TransactionStatus status) &#123; this.transactionStatus = status; &#125; private void bindToThread() &#123; this.oldTransactionInfo = transactionInfoHolder.get(); transactionInfoHolder.set(this); &#125; private void restoreThreadLocalStatus() &#123; transactionInfoHolder.set(this.oldTransactionInfo); &#125;&#125; 首先New一个事务对象DataSourceTransactionObject，其实主要是看数据库连接持有者ConnectionHolder是否存在，然后判断是否已存在事务对象，判断依据是通过事务对象中的是否存在ConnectionHolder，以及ConnectionHolder中事务是否已经激活，若已经存在事务说明是嵌套事务，则走handleExistingTransaction单独的嵌套事务逻辑。若不存在说明是新事务，则根据事务的传播属性进行相关的逻辑处理。 当事务传播行为是MANDATORY直接抛出异常，当事务传播行为是REQUIRED、REQUIRES_NEW、NESTED将开启一个新事务，首先挂起当前事务，由于顶层事务当前还没创建事务不需要挂起，故suspend(null)传入null。newSynchronization允许开启同步事务，status构造事务状态对象并将事务信息封装进去，然后doBegin开启一个新事务，最后将当前事务信息绑定到线程本地变量中，为嵌套事务提供支持。 事务传播行为类型 外部不存在事务 外部存在事务 备注 REQUIRED（默认） 开启新事务 融合到外部事务中 外层影响内层，内层影响外层 SUPPORTS 不开启新事务 融合到外部事务中 外层影响内层，内层影响外层 REQUIRES_NEW 开启新事务 挂起外部事务，创建新的事务 外层不影响内层，内层影响外层 NOT_SUPPORTED 不开启新事务 挂起外部事务，不开启事务 外层不影响内层，内层影响外层且内层没有事务，即使异常也不滚 NEVER 不开启新事务 抛出异常 不常用 MANDATORY 抛出异常 融合到外部事务中 外层影响内层，内层影响外层 NESTED 开启新事务 融合到外部事务中，SavePoint机制 外层影响内层，内层不会影响外层 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException &#123; Object transaction = doGetTransaction(); // 尝试获取一个事务对象 // Cache debug flag to avoid repeated checks. boolean debugEnabled = logger.isDebugEnabled(); if (definition == null) &#123; // 判断从上一个方法传递进来的事务属性是不是为空 definition = new DefaultTransactionDefinition(); &#125; if (isExistingTransaction(transaction)) &#123; // 判断是不是已经存在了事务对象（事务嵌套） return handleExistingTransaction(definition, transaction, debugEnabled);//处理存在的事务 &#125; if (definition.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) &#123;//检查事务设置的超时时间 throw new InvalidTimeoutException(\"Invalid transaction timeout\", definition.getTimeout()); &#125; // 若当前的事务属性为PROPAGATION_MANDATORY表示必须运行在事务中，若当前没有事务就抛出异常 // 由于isExistingTransaction(transaction)跳过了这里，说明当前是不存在事务的，那么就会抛出异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) &#123; throw new IllegalTransactionStateException(\"No existing transaction found for transaction marked with propagation 'mandatory'\"); &#125; // PROPAGATION_REQUIRED：当前存在事务就加入到当前的事务，没有就新开一个 // PROPAGATION_REQUIRES_NEW：新开一个事务,若当前存在事务就挂起当前事务 // PROPAGATION_NESTED： 表示若当前正有一个事务在运行中，则该方法应该运行在一个嵌套的事务中， // 被嵌套的事务可独立于封装事务进行提交或回滚(保存点)，若封装事务不存在，行为就像PROPAGATION_REQUIRES_NEW else if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; // 经过上面的isExistingTransaction(transaction)判断当前是不存在事务的，故在此处是挂起当前事务传递一个null进去 SuspendedResourcesHolder suspendedResources = suspend(null); try &#123; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); // 可进行同步 // 构造事务状态对象，newTransaction=true代表是一个新事务 DefaultTransactionStatus status = newTransactionStatus(definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); doBegin(transaction, definition); //开启一个新的事物 prepareSynchronization(status, definition);// 把当前的事务信息绑定到线程本地变量中 return status; &#125; catch (RuntimeException | Error ex) &#123; resume(null, suspendedResources); throw ex; &#125; &#125; else &#123; //创建一个空的事务 boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); return prepareTransactionStatus(definition, null, true, newSynchronization, debugEnabled, null); &#125; &#125;&#125; TransactionSynchronizationManager事务同步管理器对象，该类中都是局部线程变量，用来保存当前事务的信息，第一次从这里去线程变量中获取事务连接持有器对象，通过数据源为key去获取，由于第一次进来开始事务，事务同步管理器中没有被存放，所以此时获取出来的conHolder为null。 doBegin中首先判断事务对象有没有数据库连接持有器，对于顶层事务明显是没有，则从数据源中获取一个Connection连接，然后新建一个将ConnectionHolder并将其设置其中，将synchronizedWithTransaction属性设置为true，通过将autoCommit属性这是为false来开启一个事务，将ConnectionHolder的transactionActive属性设置为true，为嵌套事务做准备，最后将该数据源的该连接存入事务同步管理器中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; protected Object doGetTransaction() &#123; DataSourceTransactionObject txObject = new DataSourceTransactionObject(); // 创建一个数据源事务对象 txObject.setSavepointAllowed(isNestedTransactionAllowed()); // 是否允许当前事务设置保持点 ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource()); txObject.setConnectionHolder(conHolder, false); return txObject; //返回事务对象 &#125; protected boolean isExistingTransaction(Object transaction) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; // 若第一次进来开始事务，txObject.hasConnectionHolder()返回的null，表示不存在事务 return (txObject.hasConnectionHolder() &amp;&amp; txObject.getConnectionHolder().isTransactionActive()); &#125; protected void doBegin(Object transaction, TransactionDefinition definition) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; // 强制转换事物对象 Connection con = null; try &#123; // 判断事务对象没有数据库连接持有器 if (!txObject.hasConnectionHolder() || txObject.getConnectionHolder().isSynchronizedWithTransaction()) &#123; Connection newCon = obtainDataSource().getConnection(); // 若没有，则通过数据源获取一个数据库连接对象 // 把数据库连接包装成一个ConnectionHolder对象，然后设置到txObject对象中去 txObject.setConnectionHolder(new ConnectionHolder(newCon), true); &#125; // 标记当前的连接是一个同步事务 txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); // 设置isReadOnly、隔离级别 Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); // setAutoCommit默认为true，即每条SQL语句在各自的一个事务中执行。 if (con.getAutoCommit()) &#123; txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) &#123; logger.debug(\"Switching JDBC Connection [\" + con + \"] to manual commit\"); &#125; con.setAutoCommit(false); // 开启事务 &#125; prepareTransactionalConnection(con, definition); // 判断事务为只读事务 txObject.getConnectionHolder().setTransactionActive(true); // 设置事务激活 int timeout = determineTimeout(definition); // 设置事务超时时间 if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) &#123; txObject.getConnectionHolder().setTimeoutInSeconds(timeout); &#125; // 绑定数据源和连接到同步管理器上，把数据源作为key，数据库连接作为value，设置到线程本地变量中 if (txObject.isNewConnectionHolder()) &#123; TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder()); &#125; &#125; catch (Throwable ex) &#123; if (txObject.isNewConnectionHolder()) &#123; DataSourceUtils.releaseConnection(con, obtainDataSource()); // 释放数据库连接 txObject.setConnectionHolder(null, false); &#125; throw new CannotCreateTransactionException(\"Could not open JDBC Connection for transaction\", ex); &#125; &#125;&#125; 123456789101112131415public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; protected void prepareSynchronization(DefaultTransactionStatus status, TransactionDefinition definition) &#123; if (status.isNewSynchronization()) &#123; //绑定事务激活 TransactionSynchronizationManager.setActualTransactionActive(status.hasTransaction()); //当前事务的隔离级别 TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT ? definition.getIsolationLevel() : null); //是否为只读事务 TransactionSynchronizationManager.setCurrentTransactionReadOnly(definition.isReadOnly()); //事务的名称 TransactionSynchronizationManager.setCurrentTransactionName(definition.getName()); TransactionSynchronizationManager.initSynchronization(); &#125; &#125;&#125; 若执行异常则回滚事务，否则提交事务，不论是提交事务还是回滚事务之前都做了一个判断，当status.isNewTransaction()为false时不会去执行响应的提交或回滚逻辑，主要是为了支持融合事务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; private void processRollback(DefaultTransactionStatus status, boolean unexpected) &#123; try &#123; boolean unexpectedRollback = unexpected; try &#123; triggerBeforeCompletion(status); if (status.hasSavepoint()) &#123; status.rollbackToHeldSavepoint(); &#125; else if (status.isNewTransaction()) &#123; doRollback(status); &#125; else &#123; if (status.hasTransaction()) &#123; if (status.isLocalRollbackOnly() || isGlobalRollbackOnParticipationFailure()) &#123; doSetRollbackOnly(status); &#125; &#125; if (!isFailEarlyOnGlobalRollbackOnly()) &#123; unexpectedRollback = false; &#125; &#125; &#125; catch (RuntimeException | Error ex) &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN); throw ex; &#125; triggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK); if (unexpectedRollback) &#123; throw new UnexpectedRollbackException(\"Transaction rolled back because it has been marked as rollback-only\"); &#125; &#125; finally &#123; cleanupAfterCompletion(status); &#125; &#125; private void processCommit(DefaultTransactionStatus status) throws TransactionException &#123; try &#123; boolean beforeCompletionInvoked = false; try &#123; boolean unexpectedRollback = false; prepareForCommit(status); triggerBeforeCommit(status); triggerBeforeCompletion(status); beforeCompletionInvoked = true; if (status.hasSavepoint()) &#123; unexpectedRollback = status.isGlobalRollbackOnly(); status.releaseHeldSavepoint(); &#125; else if (status.isNewTransaction()) &#123; unexpectedRollback = status.isGlobalRollbackOnly(); doCommit(status); &#125; else if (isFailEarlyOnGlobalRollbackOnly()) &#123; unexpectedRollback = status.isGlobalRollbackOnly(); &#125; if (unexpectedRollback) &#123; throw new UnexpectedRollbackException(\"Transaction silently rolled back because it has been marked as rollback-only\"); &#125; &#125; catch (UnexpectedRollbackException ex) &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK); throw ex; &#125; catch (TransactionException ex) &#123; if (isRollbackOnCommitFailure()) &#123; doRollbackOnCommitException(status, ex); &#125; else &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN); &#125; throw ex; &#125; catch (RuntimeException | Error ex) &#123; if (!beforeCompletionInvoked) &#123; triggerBeforeCompletion(status); &#125; doRollbackOnCommitException(status, ex); throw ex; &#125; try &#123; triggerAfterCommit(status); &#125; finally &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_COMMITTED); &#125; &#125; finally &#123; cleanupAfterCompletion(status); &#125; &#125;&#125;public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; protected void doRollback(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); try &#123; con.rollback(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException(\"Could not roll back JDBC transaction\", ex); &#125; &#125; protected void doCommit(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); try &#123; con.commit(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException(\"Could not commit JDBC transaction\", ex); &#125; &#125;&#125; 存在嵌套事务要触发嵌套事务，若调用的是本类方法一点要保证将动态代理暴露在线程中并结合AopContext使用。嵌套事务的处理同样是根据事务的传播性来处理的。若事务传播性为NEVER则嵌套事务直接抛出异常； 若事务传播性为REQUIRES_NEW则挂起外部事务，然后创建一个新的事务，并将旧的事务信息暂存，执行事务和顶层事务没什么区别； 若事务传播性为SUPPORTS则融合到外部事务中，返回的事务状态中newTransaction和newSynchronization属性都为false，事务的newConnectionHolder和mustRestoreAutoCommit属性也为默认值false，由于newSynchronization属性为false这内部事务执行完后提交事务triggerAfterCommit中不会做任务处理，当内部事务执行完毕后交由外部事务处理相关提交事务和回滚事务逻辑； 若事务传播性为NOT_SUPPORTED则挂起外部事务，返回的事务状态中transaction属性为null，newTransaction属性为false，newSynchronization属性为true，故执行完后也不会有事务的提交。 若事务传播性为NESTED则融合到外部事务中，且创建一个保存点，返回的事务状态中，newTransaction和newSynchronization属性为false。这里的内层不影响外层指的是可将内层异常捕获，内层事务回滚，外层事务正常提交，若是其他几种融合到外部事务的传播属性捕获异常会导致程序异常，因为其在回滚时会通过doSetRollbackOnly(status)将事务设置为只能回滚的，若捕获内层异常，在外层事务提交时将抛出异常。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; private TransactionStatus handleExistingTransaction(TransactionDefinition definition, Object transaction, boolean debugEnabled) throws TransactionException &#123; // NEVER存在外部事务则抛出异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) &#123; throw new IllegalTransactionStateException(\"Existing transaction found for transaction marked with propagation 'never'\"); &#125; // NOT_SUPPORTED存在外部事务则挂起外部事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) &#123; // 挂起存在的事物 Object suspendedResources = suspend(transaction); boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); // 创建一个新的非事物状态，保存了上一个存在事物状态的属性 return prepareTransactionStatus(definition, null, false, newSynchronization, debugEnabled, suspendedResources); &#125; // REQUIRES_NEW存在外部事务则挂起外部事务，创建新的事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) &#123; // 挂起已经存在的事物 SuspendedResourcesHolder suspendedResources = suspend(transaction); try &#123; // 是否需要新开启同步 boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); //创建一个新的事物状态(包含了挂起的事务的属性) DefaultTransactionStatus status = newTransactionStatus(definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); //开启新的事物 doBegin(transaction, definition); //把新的事物状态设置到当前的线程变量中去 prepareSynchronization(status, definition); return status; &#125; catch (RuntimeException | Error beginEx) &#123; resumeAfterBeginException(transaction, suspendedResources, beginEx); throw beginEx; &#125; &#125; // NESTED存在外部事务则融合到外部事务中，应用层面和REQUIRED一样，源码层面 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; if (!isNestedTransactionAllowed()) &#123; throw new NestedTransactionNotSupportedException(\"Transaction manager does not allow nested transactions by default - specify 'nestedTransactionAllowed' property with value 'true'\"); &#125; // 是否支持保存点：非JTA事务走这个分支。AbstractPlatformTransactionManager默认是true，JtaTransactionManager复写了该方法false，DataSourceTransactionManager没有复写，还是true, if (useSavepointForNestedTransaction()) &#123; //开启一个新的事物 DefaultTransactionStatus status = prepareTransactionStatus(definition, transaction, false, false, debugEnabled, null); // 为事物设置一个回退点，savepoint可以在一组事务中，设置一个回滚点，点以上的不受影响，点以下的回滚。即外层影响内层，内层不会影响外层 status.createAndHoldSavepoint(); return status; &#125; else &#123; // JTA事务走这个分支，创建新事务 boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus(definition, transaction, true, newSynchronization, debugEnabled, null); doBegin(transaction, definition); prepareSynchronization(status, definition); return status; &#125; &#125; // Assumably PROPAGATION_SUPPORTS or PROPAGATION_REQUIRED. if (isValidateExistingTransaction()) &#123; if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) &#123; Integer currentIsolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel(); if (currentIsolationLevel == null || currentIsolationLevel != definition.getIsolationLevel()) &#123; Constants isoConstants = DefaultTransactionDefinition.constants; throw new IllegalTransactionStateException(\"Participating transaction with definition [\" + definition + \"] specifies isolation level which is incompatible with existing transaction: \" + (currentIsolationLevel != null ? isoConstants.toCode(currentIsolationLevel, DefaultTransactionDefinition.PREFIX_ISOLATION) : \"(unknown)\")); &#125; &#125; if (!definition.isReadOnly()) &#123; if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) &#123; throw new IllegalTransactionStateException(\"Participating transaction with definition [\" + definition + \"] is not marked as read-only but existing transaction is\"); &#125; &#125; &#125; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); return prepareTransactionStatus(definition, transaction, false, newSynchronization, debugEnabled, null); &#125;&#125; 挂起外部事务其实就是将外部事务的从事务同步管理器即线程本地变量中获取到封装成一个SuspendedResourcesHolder，然后清空事务同步管理器中的数据。顶层事务这里返回null。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; protected final SuspendedResourcesHolder suspend(@Nullable Object transaction) throws TransactionException &#123; // 嵌套事务 已经激活，在doBegin后激活 if (TransactionSynchronizationManager.isSynchronizationActive()) &#123; List&lt;TransactionSynchronization&gt; suspendedSynchronizations = doSuspendSynchronization(); try &#123; Object suspendedResources = null; if (transaction != null) &#123; suspendedResources = doSuspend(transaction); &#125; //获取已存在的事物的名称 String name = TransactionSynchronizationManager.getCurrentTransactionName(); //清空线程变量的 TransactionSynchronizationManager.setCurrentTransactionName(null); //获取出只读事务的名称 boolean readOnly = TransactionSynchronizationManager.isCurrentTransactionReadOnly(); //清空线程变量的 TransactionSynchronizationManager.setCurrentTransactionReadOnly(false); //获取已存在事务的隔离级别 Integer isolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel(); //清空隔离级别 TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(null); //获取激活标志 boolean wasActive = TransactionSynchronizationManager.isActualTransactionActive(); //清空标记Actual=外层事务 TransactionSynchronizationManager.setActualTransactionActive(false); //把上诉从线程变量中获取出来的存在事务属性封装为挂起的事务属性返回出去 return new SuspendedResourcesHolder(suspendedResources, suspendedSynchronizations, name, readOnly, isolationLevel, wasActive); &#125; catch (RuntimeException | Error ex) &#123; doResumeSynchronization(suspendedSynchronizations); throw ex; &#125; &#125; else if (transaction != null) &#123; Object suspendedResources = doSuspend(transaction); return new SuspendedResourcesHolder(suspendedResources); &#125; else &#123; return null; &#125; &#125;&#125;public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; protected Object doSuspend(Object transaction) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; txObject.setConnectionHolder(null); return TransactionSynchronizationManager.unbindResource(obtainDataSource()); &#125;&#125; 若为融合事务则status.isNewSynchronization()一定为false，则prepareSynchronization中不会做任何事情。 1234567891011121314151617181920public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; protected final DefaultTransactionStatus prepareTransactionStatus(TransactionDefinition definition, @Nullable Object transaction, boolean newTransaction, boolean newSynchronization, boolean debug, @Nullable Object suspendedResources) &#123; DefaultTransactionStatus status = newTransactionStatus(definition, transaction, newTransaction, newSynchronization, debug, suspendedResources); prepareSynchronization(status, definition); return status; &#125; protected void prepareSynchronization(DefaultTransactionStatus status, TransactionDefinition definition) &#123; if (status.isNewSynchronization()) &#123; //绑定事务激活 TransactionSynchronizationManager.setActualTransactionActive(status.hasTransaction()); //当前事务的隔离级别 TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT ? definition.getIsolationLevel() : null); //是否为只读事务 TransactionSynchronizationManager.setCurrentTransactionReadOnly(definition.isReadOnly()); //事务的名称 TransactionSynchronizationManager.setCurrentTransactionName(definition.getName()); TransactionSynchronizationManager.initSynchronization(); &#125; &#125;&#125; 在执行完嵌套事务的内层事务后在finally中会调用cleanupAfterCompletion方法，并将上层事务resume，即将事务的相关信息放回事务同步管理器中。 12345678910111213141516171819202122232425262728293031323334353637private void cleanupAfterCompletion(DefaultTransactionStatus status) &#123; status.setCompleted(); if (status.isNewSynchronization()) &#123; TransactionSynchronizationManager.clear(); &#125; if (status.isNewTransaction()) &#123; doCleanupAfterCompletion(status.getTransaction()); &#125; if (status.getSuspendedResources() != null) &#123; if (status.isDebug()) &#123; logger.debug(\"Resuming suspended transaction after completion of inner transaction\"); &#125; Object transaction = (status.hasTransaction() ? status.getTransaction() : null); resume(transaction, (SuspendedResourcesHolder) status.getSuspendedResources()); &#125;&#125;protected final void resume(@Nullable Object transaction, @Nullable SuspendedResourcesHolder resourcesHolder) throws TransactionException &#123; if (resourcesHolder != null) &#123; Object suspendedResources = resourcesHolder.suspendedResources; if (suspendedResources != null) &#123; doResume(transaction, suspendedResources); &#125; List&lt;TransactionSynchronization&gt; suspendedSynchronizations = resourcesHolder.suspendedSynchronizations; if (suspendedSynchronizations != null) &#123; TransactionSynchronizationManager.setActualTransactionActive(resourcesHolder.wasActive); TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(resourcesHolder.isolationLevel); TransactionSynchronizationManager.setCurrentTransactionReadOnly(resourcesHolder.readOnly); TransactionSynchronizationManager.setCurrentTransactionName(resourcesHolder.name); doResumeSynchronization(suspendedSynchronizations); &#125; &#125;&#125;protected void doResume(@Nullable Object transaction, Object suspendedResources) &#123; TransactionSynchronizationManager.bindResource(obtainDataSource(), suspendedResources);&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"AOP创建代理与调用","date":"2021-09-27T16:00:00.000Z","path":"Blog/Spring/AOP创建代理与调用/","text":"创建代理给Bean创建代理的地方有两个，存在循环依赖的Bean会调用实现了SmartInstantiationAwareBeanPostProcessor接口的getEarlyBeanReference方法，即Bean的生命周期中第四次调用后置处理器的地方，给有AOP代理的且产生循环依赖且先被加载的对象创建AOP代理。若在该处已经设置了动态代理会将beanName加入到earlyProxyReferences集合中，防止第八次调用后置处理器时重复添加动态代理。 1234567public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey); &#125;&#125; 若Bean有AOP代理，但不存在循环依赖或存在循环依赖但后被加载，则AOP代理是在第八次调用后置处理器时，给该Bean创建动态代理的。 1234567891011public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName);// 获取缓存key if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123;// 若之前循环依赖已创建的动态代理则不再创建且移除 return wrapIfNecessary(bean, beanName, cacheKey);// 若存在动态代理将返回创建动态代理后实例 &#125; &#125; return bean; &#125;&#125; 这两个地方其实都是调用的wrapIfNecessary方法为加载的Bean创建动态代理的，advisedBeans中对于AOP基础类或被标记跳过的类会直接返回原始对象。shouldSkip在切面解析时就已经对所有切面类进行了解析，这里会走缓存。接着找到当前Bean的所有匹配切点规则的advisor，然后对当前Bean创建代理对象，不管是否创建代理对象都将其缓存到advisedBeans中。 12345678910111213141516171819202122232425protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 已被处理过即解析切面时targetSourcedBeans出现过，则是自实现创建动态代理逻辑 if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; // 不需要增强直接返回 return bean; &#125; // 是否基础的Bean、是否需要跳过的重复判断，因为循环依赖是可以改变bean的，若把bean改成了advisor if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 根据当前Bean找到匹配的advisor列表 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; // 当前Bean匹配到了advisor this.advisedBeans.put(cacheKey, Boolean.TRUE); // 标记为已处理 // 真正创建代理对象 Object proxy = createProxy(bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); // 加入到缓存 return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 从候选通知器中找到当前Bean关联的Advisor列表，然后对Advisor进行一个排序，按照AfterThrowing、AfterReturning、After、Around、Before的顺序排列，若有多个切面每个切面内还是按照前面的排序，然后再进行切面之间的排序。因为实际调用的时候是方法递归调用，所以排在前面的方法会后执行。 12345678910111213141516171819202122232425262728public abstract class AbstractAdvisorAutoProxyCreator extends AbstractAutoProxyCreator &#123; protected Object[] getAdvicesAndAdvisorsForBean(Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123; List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); // 找到和当前Bean匹配的advisor if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; // 若没找到则不创建代理 &#125; return advisors.toArray(); &#125; protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 获取所有切面的所有Advisor，这里是从缓存获取 // 切点是否命中当前Bean List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; // 对advisor进行排序 eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors; &#125; protected List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; // 记录当前正在创建的被代理对象的名称 ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123;// 从候选通知器中找到当前Bean关联的advisors return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123;//从线程局部变量中清除当前正在创建的beanName的代理对象名称 ProxyCreationContext.setCurrentProxiedBeanName(null); &#125; &#125;&#125; 首先通过AspectJ进行类级别的过滤即初筛，若不匹配则直接返回，若Pointcut的getMethodMatcher()为TrueMethodMatcher则匹配所有方法。这里其实就是将Advisor中的切点表达式与Bean进行匹配。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public abstract class AopUtils &#123; public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; if (advisor instanceof IntroductionAdvisor) &#123;// 判断advisor是否为IntroductionAdvisor return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass); &#125; else if (advisor instanceof PointcutAdvisor) &#123; // 判断advisor是否实现了PointcutAdvisor PointcutAdvisor pca = (PointcutAdvisor) advisor; return canApply(pca.getPointcut(), targetClass, hasIntroductions); // 找到真正能用的增强器 &#125; else &#123; return true; &#125; &#125; public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; Assert.notNull(pc, \"Pointcut must not be null\"); if (!pc.getClassFilter().matches(targetClass)) &#123; // 通过AspectJ进行类级别过滤（初筛） return false; &#125; // 进行方法级别过滤（精筛），若pc.getMethodMatcher()返回TrueMethodMatcher则匹配所有方法 MethodMatcher methodMatcher = pc.getMethodMatcher(); if (methodMatcher == MethodMatcher.TRUE) &#123; return true; &#125; // 判断匹配器是否为IntroductionAwareMethodMatcher，只有AspectJExpressionPointCut才会实现这个接口 IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null; if (methodMatcher instanceof IntroductionAwareMethodMatcher) &#123; introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher; &#125; Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;&gt;(); // 用于保存targetClass的class对象 if (!Proxy.isProxyClass(targetClass)) &#123; // 判断当前class是不是代理的class对象 classes.add(ClassUtils.getUserClass(targetClass)); // 加入到集合中去 &#125; // 获取到targetClass所实现的接口的class对象，然后加入到集合中 classes.addAll(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); for (Class&lt;?&gt; clazz : classes) &#123; // 循环所有的class对象 Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); // 通过class获取到所有的方法 for (Method method : methods) &#123; // 遍历方法挨个匹配 // 通过methodMatcher.matches来匹配方法 if (introductionAwareMethodMatcher != null ? // 通过切点表达式进行匹配 AspectJ方式 introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions) : // 通过方法匹配器进行匹配 内置aop接口方式 methodMatcher.matches(method, targetClass)) &#123; // 只要有1个方法匹配上了就创建代理 return true; &#125; &#125; &#125; return false; &#125;&#125; 通过@Before、@Around、@After、@AfterReturning、@AfterThrowing等注解的方法配置的切点，最终的初筛和精筛都是调用的AspectJExpressionPointcut的matches方法，其匹配实现是AspectJ来完成的。初筛是通过couldMatchJoinPointsInType方法，精筛是通过matchesMethodExecution方法，通过切点表达式与类和方法进行匹配。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class AspectJExpressionPointcut extends AbstractExpressionPointcut implements ClassFilter, IntroductionAwareMethodMatcher, BeanFactoryAware &#123; public boolean matches(Class&lt;?&gt; targetClass) &#123; // 初筛 PointcutExpression pointcutExpression = obtainPointcutExpression(); try &#123; try &#123; return pointcutExpression.couldMatchJoinPointsInType(targetClass); &#125; catch (ReflectionWorldException ex) &#123; PointcutExpression fallbackExpression = getFallbackPointcutExpression(targetClass); if (fallbackExpression != null) &#123; return fallbackExpression.couldMatchJoinPointsInType(targetClass); &#125; &#125; &#125; catch (Throwable ex) &#123;&#125; return false; &#125; private PointcutExpression obtainPointcutExpression() &#123; if (getExpression() == null) &#123; throw new IllegalStateException(\"Must set property 'expression' before attempting to match\"); &#125; if (this.pointcutExpression == null) &#123; this.pointcutClassLoader = determinePointcutClassLoader(); this.pointcutExpression = buildPointcutExpression(this.pointcutClassLoader); &#125; return this.pointcutExpression; &#125; private PointcutExpression buildPointcutExpression(@Nullable ClassLoader classLoader) &#123; PointcutParser parser = initializePointcutParser(classLoader); PointcutParameter[] pointcutParameters = new PointcutParameter[this.pointcutParameterNames.length]; for (int i = 0; i &lt; pointcutParameters.length; i++) &#123; pointcutParameters[i] = parser.createPointcutParameter(this.pointcutParameterNames[i], this.pointcutParameterTypes[i]); &#125; return parser.parsePointcutExpression(replaceBooleanOperators(resolveExpression()),this.pointcutDeclarationScope, pointcutParameters); &#125; public boolean matches(Method method, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; // 精筛 obtainPointcutExpression(); ShadowMatch shadowMatch = getTargetShadowMatch(method, targetClass); if (shadowMatch.alwaysMatches()) &#123; return true; &#125; else if (shadowMatch.neverMatches()) &#123; return false; &#125; else &#123; if (hasIntroductions) &#123; return true; &#125; RuntimeTestWalker walker = getRuntimeTestWalker(shadowMatch); return (!walker.testsSubtypeSensitiveVars() || walker.testTargetInstanceOfResidue(targetClass)); &#125; &#125;&#125; 完成该Bean的所有方法和所有的切点匹配工作后，做存在匹配的切点，则通过ProxyFactory代理工厂来为该Bean创建动态代理。若@EnableAspectJAutoProxy(proxyTargetClass = true)则表示无论该Bean是否实现接口都通过Cglib的方式来创建代理。若未设置该属性，则判断该Bean是否继承接口，若继承接口则使用JDK动态代理，否则使用Cglib动态代理。 12345678910111213141516171819202122232425262728public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; ProxyFactory proxyFactory = new ProxyFactory(); //创建一个代理对象工厂 proxyFactory.copyFrom(this); // 为proxyFactory设置创建jdk代理还是cglib代理，若设置了&lt;aop:aspectj-autoproxy proxy-target-class=\"true\"/&gt;不会进if，说明强制使用cglib if (!proxyFactory.isProxyTargetClass()) &#123; if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); // 内部设置的，配置类就会设置这个属性 &#125; else &#123; // 检查有没有接口 evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; // 把specificInterceptors数组中的Advisor转化为数组形式的 Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); proxyFactory.addAdvisors(advisors); // 为代理工厂加入通知器， proxyFactory.setTargetSource(targetSource); // 设置targetSource对象 customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); // 代表之前是否筛选advise，因为继承了AbstractAdvisorAutoProxyCreator，且之前调用了findEligibleAdvisors进行筛选，所以是true if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; return proxyFactory.getProxy(getProxyClassLoader()); //真正的创建代理对象 &#125;&#125; 这里创建动态代理会根据是否指定ProxyTargetClass=true以及有没有接口来决定使用JDK动态代理还是Cglib动态代理。 12345678910111213141516171819202122232425262728293031public class ProxyFactory extends ProxyCreatorSupport &#123; public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader); // createAopProxy()用来获取代理工厂 &#125;&#125;public class ProxyCreatorSupport extends AdvisedSupport &#123; protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; return getAopProxyFactory().createAopProxy(this); &#125;&#125;public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &#123; public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; // 判断是否前置指定使用cglib代理ProxyTargetClass=true或者没有接口 if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); &#125; // 所targetClass是接口则使用jdk代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; return new ObjenesisCglibAopProxy(config); // cglib代理 &#125; else &#123; return new JdkDynamicAopProxy(config); // 动态代理 &#125; &#125;&#125; 代理类调用在代理创建时已经将增强器Advisors赋予了代理类，在执行时只需将这些增强器应用到被代理的类上即可，对于被JDK动态代理的类来说，当执行具体方法时，会调用JdkDynamicAopProxy的invoke方法，对于被Cglib动态代理的类来说，当执行具体方法时，会调用CglibAopProxy中DynamicAdvisedInterceptor的intercept方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource;// 获取到目标对象 Object target = null; try &#123; if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123;// 若执行代理对象的equals方法不需要代理 return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123;// 若执行的是hashCode方法不需要代理 return hashCode(); &#125; // 若执行的class对象是DecoratingProxy则不会对其应用切面进行方法的增强，返回源目标类型 else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; return AopProxyUtils.ultimateTargetClass(this.advised); &#125; // 若目标对象实现的Advised接口，则不会对其应用切面进行方法的增强，直接执行方法 else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; if (this.advised.exposeProxy) &#123; // 暴露代理对象到线程变量中 oldProxy = AopContext.setCurrentProxy(proxy); // 把代理对象暴露到线程变量中 setProxyContext = true; &#125; target = targetSource.getTarget(); // 获取目标对象 Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // 获取目标对象的class // 把AOP的advisor全部转化为拦截器，通过责任链模式依次调用 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123; // 若拦截器链为空，通过反射直接调用执行 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // 创建一个方法调用对象 MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); retVal = invocation.proceed(); // 调用执行 &#125; Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException(\"Null return value from advice does not match primitive return type for: \" + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125;&#125; Cglib动态代理后续调用逻辑与JDK动态代理是一样的 1234567891011121314151617181920212223242526272829303132333435class CglibAopProxy implements AopProxy, Serializable &#123; private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable &#123; public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try &#123; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123; retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; &#125;&#125; 其中的this.advised.exposeProxy判断是暴露代理对象到线程本地变量中，需搭配@EnableAspectJAutoProxy(exposeProxy = true)一起使用，若有两个方法init、transfer都被设置了代理，但在代理方法中通过this来调用另一个代理方法时，该方法不会被代理执行，这时就需要通过AopContext.currentProxy()来配合使用才能是该方法被代理执行，事务方法调用事务方法时就是这样来设置的。 1234567891011@Component@EnableAspectJAutoProxy(exposeProxy = true)public class Car implements CarSuper &#123; public void init() &#123; System.out.println(\"car init ...\"); ((CarSuper)AopContext.currentProxy()).transfer(); &#125; public void transfer() &#123; System.out.println(\"Car transfer...\"); &#125;&#125; 第一次调用代理方法时会将该方法与该类上的Advisor列表一一匹配，并将匹配到的Advisor转换成拦截器MethodInterceptor，然后放入缓存，再次调用时直接从缓存中获取。 1234567891011public class AdvisedSupport extends ProxyConfig implements Advised &#123; public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; MethodCacheKey cacheKey = new MethodCacheKey(method); List&lt;Object&gt; cached = this.methodCache.get(cacheKey); if (cached == null) &#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice(this, method, targetClass); this.methodCache.put(cacheKey, cached); &#125; return cached; &#125;&#125; Advisor中封装的Advice实现了MethodInterceptor拦截器，则直接强制类型转换，否则通过AdvisorAdapter进行转换。内置了MethodBeforeAdviceAdapter、AfterReturningAdviceAdapter、ThrowsAdviceAdapter三个适配器。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class DefaultAdvisorChainFactory implements AdvisorChainFactory, Serializable &#123; private final List&lt;AdvisorAdapter&gt; adapters = new ArrayList&lt;&gt;(3); public DefaultAdvisorAdapterRegistry() &#123; registerAdvisorAdapter(new MethodBeforeAdviceAdapter()); registerAdvisorAdapter(new AfterReturningAdviceAdapter()); registerAdvisorAdapter(new ThrowsAdviceAdapter()); &#125; public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; List&lt;Object&gt; interceptorList = new ArrayList&lt;Object&gt;(config.getAdvisors().length); Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); for (Advisor advisor : config.getAdvisors()) &#123; if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &#123; MethodInterceptor[] interceptors = registry.getInterceptors(advisor); if (mm.isRuntime()) &#123; for (MethodInterceptor interceptor : interceptors) &#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList; &#125; public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList&lt;&gt;(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor) advice); &#125; for (AdvisorAdapter adapter : this.adapters) &#123; if (adapter.supportsAdvice(advice)) &#123; interceptors.add(adapter.getInterceptor(advisor)); &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; return interceptors.toArray(new MethodInterceptor[0]); &#125;&#125; 内置的三个适配器实现都很简单，就是获取到具体的advice然后再转换成具体的拦截器。 1234567891011121314151617181920212223242526272829303132class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof AfterReturningAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice(); return new AfterReturningAdviceInterceptor(advice); &#125;&#125;class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof MethodBeforeAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &#125;&#125;class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof ThrowsAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; return new ThrowsAdviceInterceptor(advisor.getAdvice()); &#125;&#125; 最终将匹配到的拦截器链以及目标方法等信息包装为ReflectiveMethodInvocation执行它的proceed方法，这里的invokeJoinpoint()就是调用连接点即被代理的方法本身。 1234567891011121314151617181920212223public class ReflectiveMethodInvocation implements ProxyMethodInvocation, Cloneable &#123; public Object proceed() throws Throwable &#123; // 从-1开始，结束条件执行目标方法是下标=拦截器的长度-1，即执行到最后一个拦截器时 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); // 当执行到最后一个拦截器的时候才会进入 &#125; // 获取集合当前需要运行的拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; return proceed(); &#125; &#125; else &#123;// 执行拦截器方法 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125; protected Object invokeJoinpoint() throws Throwable &#123; return AopUtils.invokeJoinpointUsingReflection(this.target, this.method, this.arguments); &#125;&#125; 首先调用ExposeInvocationInterceptor，一般AOP代理时都会创建一个，然后加入到列表头部，mi.proceed()又回到了ReflectiveMethodInvocation中。 1234567891011public class ExposeInvocationInterceptor implements MethodInterceptor, PriorityOrdered, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; MethodInvocation oldInvocation = invocation.get(); invocation.set(mi); // 记录当前正在执行的拦截器 try &#123; return mi.proceed(); &#125; finally &#123; invocation.set(oldInvocation); &#125; &#125;&#125; 异常通知AspectJAfterThrowingAdvice 12345678910111213public class AspectJAfterThrowingAdvice extends AbstractAspectJAdvice implements MethodInterceptor, AfterAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; return mi.proceed(); &#125; catch (Throwable ex) &#123; Method handlerMethod = getExceptionHandler(ex); if (handlerMethod != null) &#123; invokeHandlerMethod(mi, ex, handlerMethod); &#125; throw ex; &#125; &#125;&#125; 前置通知MethodBeforeAdviceInterceptor 123456public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; 返回通知AfterReturningAdviceInterceptor 1234567public class AfterReturningAdviceInterceptor implements MethodInterceptor, AfterAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; Object retVal = mi.proceed(); this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal; &#125;&#125; 后置AspectJAfterAdvice 123456789public class AspectJAfterAdvice extends AbstractAspectJAdvice implements MethodInterceptor, AfterAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; return mi.proceed(); &#125; finally &#123; invokeAdviceMethod(getJoinPointMatch(), null, null); &#125; &#125;&#125; 环绕通知AspectJAroundAdvice 1234567891011public class AspectJAroundAdvice extends AbstractAspectJAdvice implements MethodInterceptor, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; if (!(mi instanceof ProxyMethodInvocation)) &#123; throw new IllegalStateException(\"MethodInvocation is not a Spring ProxyMethodInvocation: \" + mi); &#125; ProxyMethodInvocation pmi = (ProxyMethodInvocation) mi; ProceedingJoinPoint pjp = lazyGetProceedingJoinPoint(pmi); JoinPointMatch jpm = getJoinPointMatch(pmi); return invokeAdviceMethod(pjp, jpm, null, null); &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"https://yaoyinglong.github.io/tags/AOP/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"AOP切面类解析","date":"2021-09-26T16:00:00.000Z","path":"Blog/Spring/AOP切面类解析/","text":"Spring AOP是通过给一个类加上@Aspect注解来定义一个切面类，定义一个Pointcut方法，最后定义一系列的增强方法，这样就完成一个对象的切面操作。 通过@EnableAspectJAutoProxy注解开启AOP切面，该注解类上@Import(AspectJAutoProxyRegistrar.class)注解中AspectJAutoProxyRegistrar实现了ImportBeanDefinitionRegistrar，其会通过registerBeanDefinitions方法为容器导入为Bean创建代理beanName为internalAutoProxyCreator的关键beanDefinition。type为AnnotationAwareAspectJAutoProxyCreator。 @Import中ImportBeanDefinitionRegistrar接口registerBeanDefinitions方法调用时机是在invokeBeanFactoryPostProcessors的invokeBeanFactoryPostProcessors中解析完配置类后调用ConfigurationClassBeanDefinitionReader的loadBeanDefinitions方法，即在Bean实例化之前。 123456789101112131415161718class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 注册名字internalAutoProxyCreator的AnnotationAwareAspectJAutoProxyCreator AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); // 获得注解的属性 AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); // 根据其中的proxyTargetClass/exposeProxy设置beanDefinition属性 if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean(\"proxyTargetClass\")) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean(\"exposeProxy\")) &#123; AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728public abstract class AopConfigUtils &#123; public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry) &#123; return registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry, null); &#125; public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, @Nullable Object source) &#123; return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source); &#125; private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; apcDefinition.setBeanClassName(cls.getName()); &#125; &#125; return null; &#125; RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(\"order\", Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition; &#125;&#125; 在finishBeanFactoryInitialization第一个Bean创建时通过resolveBeforeInstantiation第一次调用后置处理器时，调用AnnotationAwareAspectJAutoProxyCreator超类AbstractAutoProxyCreator中的postProcessBeforeInstantiation方法时，对所有的AOP切面类进行解析并将解析后的Advisors列表缓存。 12345678910111213141516171819202122232425262728public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; Object cacheKey = getCacheKey(beanClass, beanName); // 构建缓存key // 没有beanName或没有包含在targetSourcedBeans中，一般都不会包含，因为targetSource需要手动设置，一般情况不会设置 if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) &#123; if (this.advisedBeans.containsKey(cacheKey)) &#123; // 被解析过 直接返回 return null; &#125; // 判断是不是基础的bean即是不是切面类、通知、切点等，判断是不是应该跳过 默认false，切面解析也在其中 if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; &#125; &#125; // TargetSource代理逻辑的实现，在创建代理时默认是SingletonTargetSource，故若指定了TargetSource说明有自己的代理逻辑实现，在这就直接创建代理 TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) &#123; if (StringUtils.hasLength(beanName)) &#123; this.targetSourcedBeans.add(beanName); &#125; Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; return null; &#125;&#125; 通过isInfrastructureClass判断该类是否是切面类、通知、切点等，判断逻辑就是判断当前正在创建的类是否为Advice、Pointcut、Advisor、AopInfrastructureBean的子类，若是则直接跳过解析。或若该类上有@Aspect注解且不是一个被AspectJ编译过的类也跳过解析。 123456789101112131415161718192021222324252627public class AnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator &#123; protected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; return (super.isInfrastructureClass(beanClass) || (this.aspectJAdvisorFactory != null &amp;&amp; this.aspectJAdvisorFactory.isAspect(beanClass))); &#125;&#125;public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; private static final String AJC_MAGIC = \"ajc$\"; protected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; // 若当前正在创建的Bean的class是Advice PointCut Advisor AopInfrastructureBean，直接跳过不需要解析 boolean retVal = Advice.class.isAssignableFrom(beanClass) || Pointcut.class.isAssignableFrom(beanClass) || Advisor.class.isAssignableFrom(beanClass) || AopInfrastructureBean.class.isAssignableFrom(beanClass); return retVal; &#125; public boolean isAspect(Class&lt;?&gt; clazz) &#123; // 有没有切面注解 &amp;&amp; 没有被AspectJ编译过 return (hasAspectAnnotation(clazz) &amp;&amp; !compiledByAjc(clazz)); &#125; private boolean hasAspectAnnotation(Class&lt;?&gt; clazz) &#123; return (AnnotationUtils.findAnnotation(clazz, Aspect.class) != null); &#125; private boolean compiledByAjc(Class&lt;?&gt; clazz) &#123; for (Field field : clazz.getDeclaredFields()) &#123; if (field.getName().startsWith(AJC_MAGIC)) &#123; return true; // 至少一个属性前缀为\"ajc$\" &#125; &#125; return false; &#125;&#125; shouldSkip中的findCandidateAdvisors()会解析出所有的Advisor，这里的AspectJPointcutAdvisor是xml中advisor解析的对象，若aspect是当前beanName就说明当前bean是切面类则跳过。 123456789101112public class AspectJAwareAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator &#123; protected boolean shouldSkip(Class&lt;?&gt; beanClass, String beanName) &#123; List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 找到所有定义的候选Advisors for (Advisor advisor : candidateAdvisors) &#123; // AspectJPointcutAdvisor是xml&lt;aop:advisor解析的对象，若&lt;aop:aspect ref=\"beanName\"&gt;是当前beanName就说明当前bean是切面类则跳过。 if (advisor instanceof AspectJPointcutAdvisor &amp;&amp; ((AspectJPointcutAdvisor) advisor).getAspectName().equals(beanName)) &#123; return true; &#125; &#125; return super.shouldSkip(beanClass, beanName); &#125;&#125; 通过buildAspectJAdvisors去容器中获取所有切面信息保存到缓存中。 12345678910public class AnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator &#123; protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // 找出xml配置的Advisor、原生接口的AOP的Advisor、事务相关的advisor List&lt;Advisor&gt; advisors = super.findCandidateAdvisors(); if (this.aspectJAdvisorsBuilder != null) &#123; // 找出Aspect相关的信息之后封装为一个advisor advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors()); &#125; return advisors; // 返回所有的通知 &#125;&#125; 关于advisorRetrievalHelper的初始化，AbstractAdvisorAutoProxyCreator的父类AbstractAutoProxyCreator实现了BeanFactoryAware接口，而AbstractAutoProxyCreator是事务和AOP导入进来的后置处理器的顶级父类，在实例化AOP和事务导入组件时会调用setBeanFactory的方法来注入Bean工厂，调用setBeanFactory会触发initBeanFactory的调用来实例化通知查找探测器。 1234567891011121314151617public abstract class AbstractAdvisorAutoProxyCreator extends AbstractAutoProxyCreator &#123; private BeanFactoryAdvisorRetrievalHelper advisorRetrievalHelper; protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // 通过通知者探测器帮助找到通知 Assert.state(this.advisorRetrievalHelper != null, \"No BeanFactoryAdvisorRetrievalHelper available\"); return this.advisorRetrievalHelper.findAdvisorBeans(); &#125; public void setBeanFactory(BeanFactory beanFactory) &#123; super.setBeanFactory(beanFactory); if (!(beanFactory instanceof ConfigurableListableBeanFactory)) &#123; throw new IllegalArgumentException(\"AdvisorAutoProxyCreator requires a ConfigurableListableBeanFactory: \" + beanFactory); &#125; initBeanFactory((ConfigurableListableBeanFactory) beanFactory); &#125; protected void initBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; this.advisorRetrievalHelper = new BeanFactoryAdvisorRetrievalHelperAdapter(beanFactory); &#125;&#125; 探测器字段cachedAdvisorBeanNames是用来缓存Advisor全类名，在第一个单实例bean实例化过程中把所有的advisor名称解析出来，若cachedAdvisorBeanNames为空则先获取容器中所有实现了Advisor接口的实现类，典型为事务注解@EnableTransactionManagement导入ProxyTransactionManagementConfiguration配置类。1234567891011121314151617181920212223242526272829303132333435public class BeanFactoryAdvisorRetrievalHelper &#123; public List&lt;Advisor&gt; findAdvisorBeans() &#123; // 探测器字段cachedAdvisorBeanNames是用来缓存Advisor全类名，在第一个单实例bean实例化过程中把该advisor名称解析出来 String[] advisorNames = this.cachedAdvisorBeanNames; if (advisorNames == null) &#123; advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Advisor.class, true, false); this.cachedAdvisorBeanNames = advisorNames; &#125; if (advisorNames.length == 0) &#123; // 若在容器中没有找到，直接返回一个空的集合 return new ArrayList&lt;&gt;(); &#125; List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); for (String name : advisorNames) &#123; // 容器中找到了配置的BeanFactoryTransactionAttributeSourceAdvisor if (isEligibleBean(name)) &#123; // 判断其是不是一个合适的 if (this.beanFactory.isCurrentlyInCreation(name)) &#123; // BeanFactoryTransactionAttributeSourceAdvisor是不是正在创建的bean &#125; else &#123; // 不是的话 try &#123; //显示的调用getBean方法方法创建BeanFactoryTransactionAttributeSourceAdvisor返回去 advisors.add(this.beanFactory.getBean(name, Advisor.class)); &#125; catch (BeanCreationException ex) &#123; Throwable rootCause = ex.getMostSpecificCause(); if (rootCause instanceof BeanCurrentlyInCreationException) &#123; BeanCreationException bce = (BeanCreationException) rootCause; String bceBeanName = bce.getBeanName(); if (bceBeanName != null &amp;&amp; this.beanFactory.isCurrentlyInCreation(bceBeanName)) &#123; continue; &#125; &#125; throw ex; &#125; &#125; &#125; &#125; return advisors; &#125;&#125; 缓存字段aspectNames没有值，会在AnnotationAwareAspectJAutoProxyCreator注册之后，第一个单例执行后置处理器时触发解析切面的操作。这里获取的是Object类型的Bean的名称即获取所有的Bean。遍历解析Advisor的过程十分耗性能，解析后会加入了保存切面信息的缓存，事务模块的功能是直接去容器中获取Advisor类型的，选择范围小，且不消耗性能，故事务模块中没有加入缓存来保存事务相关的advisor。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public List&lt;Advisor&gt; buildAspectJAdvisors() &#123; // 用于保存切面的名称，该aspectNames是类级别的缓存，缓存已解析出的切面信息 List&lt;String&gt; aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; synchronized (this) &#123; // 加上同步锁， 防止多线程同时加载Aspect aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; // 双重检查加锁 List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); // 保存所有通知的集合 aspectNames = new ArrayList&lt;&gt;(); // 保存切面的名称的集合 // 从容器中获取所有Bean，再遍历，该过程十分耗性能，解析后会加入了保存切面信息的缓存 String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Object.class, true, false); for (String beanName : beanNames) &#123; // 遍历从IOC容器中获取的所有bean的名称 if (!isEligibleBean(beanName)) continue; Class&lt;?&gt; beanType = this.beanFactory.getType(beanName); // 通过beanName去容器中获取到对应class对象 if (beanType == null) continue; if (this.advisorFactory.isAspect(beanType)) &#123; // 根据class对象判断是不是切面 aspectNames.add(beanName); // 是切面类，加入到缓存中 // 把beanName和class对象构建成为一个AspectMetadata AspectMetadata amd = new AspectMetadata(beanType, beanName); if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) &#123; //构建切面注解的实例工厂 MetadataAwareAspectInstanceFactory factory = new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName); // 真正的去获取通知对象 List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory); if (this.beanFactory.isSingleton(beanName)) &#123; // 加入到缓存中 this.advisorsCache.put(beanName, classAdvisors); &#125; else &#123; this.aspectFactoryCache.put(beanName, factory); &#125; advisors.addAll(classAdvisors); &#125; else &#123; if (this.beanFactory.isSingleton(beanName)) &#123; throw new IllegalArgumentException(\"Bean with name '\" + beanName + \"' is a singleton, but aspect instantiation model is not singleton\"); &#125; MetadataAwareAspectInstanceFactory factory = new PrototypeAspectInstanceFactory(this.beanFactory, beanName); this.aspectFactoryCache.put(beanName, factory); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; &#125; this.aspectBeanNames = aspectNames; return advisors; &#125; &#125; &#125; if (aspectNames.isEmpty()) &#123; return Collections.emptyList(); &#125; // 真正的创建切面的时候，我们不需要去解析了而是直接去缓存中获取处 List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); for (String aspectName : aspectNames) &#123; List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName); if (cachedAdvisors != null) &#123; advisors.addAll(cachedAdvisors); &#125; else &#123; MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; return advisors;&#125; 遍历切面类中的所有除了被@Pointcut注解标注的方法，并将满足条件的每个方法都封装成一个Advisor。这里getAdvisorMethods方法中对所有获取到的切面方法按照Around、Before、After、AfterReturning、AfterThrowing的顺序进行了排序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ReflectiveAspectJAdvisorFactory extends AbstractAspectJAdvisorFactory implements Serializable &#123; public List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) &#123; Class&lt;?&gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); // 获取标记为Aspect的类 String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName(); // 获取切面类的名称 validate(aspectClass); // 校验切面类 // 使用包装模式来包装MetadataAwareAspectInstanceFactory构建为MetadataAwareAspectInstanceFactory MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory = new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory); List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); // 获取到切面类中的所有方法，但是该方法不会解析标注了@PointCut注解的方法 for (Method method : getAdvisorMethods(aspectClass)) &#123; // 挨个去解析切面中的方法 Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; if (!advisors.isEmpty() &amp;&amp; lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) &#123; Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory); advisors.add(0, instantiationAdvisor); &#125; for (Field field : aspectClass.getDeclaredFields()) &#123; Advisor advisor = getDeclareParentsAdvisor(field); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; return advisors; &#125; public Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrderInAspect, String aspectName) &#123; validate(aspectInstanceFactory.getAspectMetadata().getAspectClass()); // 获得当前通知的切点表达式 AspectJExpressionPointcut expressionPointcut = getPointcut(candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass()); if (expressionPointcut == null) &#123; return null; &#125; // 将切点表达式和通知封装到InstantiationModelAwarePointcutAdvisorImpl对象中 return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod, this, aspectInstanceFactory, declarationOrderInAspect, aspectName); &#125; private AspectJExpressionPointcut getPointcut(Method candidateAdviceMethod, Class&lt;?&gt; candidateAspectClass) &#123; // 找到aspectJ的注解：@Pointcut、@Around、@Before、@After、@AfterReturning、@AfterThrowing AspectJAnnotation&lt;?&gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) &#123; // 没有注解直接忽略 return null; &#125; AspectJExpressionPointcut ajexp = new AspectJExpressionPointcut(candidateAspectClass, new String[0], new Class&lt;?&gt;[0]); ajexp.setExpression(aspectJAnnotation.getPointcutExpression()); if (this.beanFactory != null) &#123; ajexp.setBeanFactory(this.beanFactory); &#125; return ajexp; &#125; private List&lt;Method&gt; getAdvisorMethods(Class&lt;?&gt; aspectClass) &#123; final List&lt;Method&gt; methods = new ArrayList&lt;&gt;(); ReflectionUtils.doWithMethods(aspectClass, method -&gt; &#123; if (AnnotationUtils.getAnnotation(method, Pointcut.class) == null) &#123; methods.add(method); &#125; &#125;); methods.sort(METHOD_COMPARATOR); return methods; &#125; private static final Comparator&lt;Method&gt; METHOD_COMPARATOR; static &#123; Comparator&lt;Method&gt; adviceKindComparator = new ConvertingComparator&lt;&gt;( new InstanceComparator&lt;&gt;(Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class), (Converter&lt;Method, Annotation&gt;) method -&gt; &#123; AspectJAnnotation&lt;?&gt; annotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(method); return (annotation != null ? annotation.getAnnotation() : null); &#125;); Comparator&lt;Method&gt; methodNameComparator = new ConvertingComparator&lt;&gt;(Method::getName); METHOD_COMPARATOR = adviceKindComparator.thenComparing(methodNameComparator); &#125;&#125; 找到方法上是否有@Pointcut、@Around、@Before、@After、@AfterReturning、@AfterThrowing等注解，并获取到注解上切面表达式。 123456789101112public abstract class AbstractAspectJAdvisorFactory implements AspectJAdvisorFactory &#123; private static final Class&lt;?&gt;[] ASPECTJ_ANNOTATION_CLASSES = new Class&lt;?&gt;[] &#123;Pointcut.class, Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class&#125;; protected static AspectJAnnotation&lt;?&gt; findAspectJAnnotationOnMethod(Method method) &#123; for (Class&lt;?&gt; clazz : ASPECTJ_ANNOTATION_CLASSES) &#123; AspectJAnnotation&lt;?&gt; foundAnnotation = findAnnotation(method, (Class&lt;Annotation&gt;) clazz); if (foundAnnotation != null) &#123; return foundAnnotation; &#125; &#125; return null; &#125;&#125; 通过InstantiationModelAwarePointcutAdvisorImpl的instantiateAdvice方法将不同类型的注解方法解析成对应的Advice。 12345678910111213141516171819202122232425262728class InstantiationModelAwarePointcutAdvisorImpl implements InstantiationModelAwarePointcutAdvisor, AspectJPrecedenceInformation, Serializable &#123; public InstantiationModelAwarePointcutAdvisorImpl(AspectJExpressionPointcut declaredPointcut, Method aspectJAdviceMethod, AspectJAdvisorFactory aspectJAdvisorFactory, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) &#123; this.declaredPointcut = declaredPointcut;// 当前的切点 this.declaringClass = aspectJAdviceMethod.getDeclaringClass();// 切面的class对象 this.methodName = aspectJAdviceMethod.getName();// 切面方法的名称 this.parameterTypes = aspectJAdviceMethod.getParameterTypes();// 切面方法的参数类型 this.aspectJAdviceMethod = aspectJAdviceMethod;// 切面方法对象 this.aspectJAdvisorFactory = aspectJAdvisorFactory;// aspectj的通知工厂 this.aspectInstanceFactory = aspectInstanceFactory;// aspect的实例工厂 this.declarationOrder = declarationOrder;// 切面的顺序 this.aspectName = aspectName;// 切面的名称 // 判断当前的切面对象是否需要延时加载 if (aspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) &#123; Pointcut preInstantiationPointcut = Pointcuts.union(aspectInstanceFactory.getAspectMetadata().getPerClausePointcut(), this.declaredPointcut); this.pointcut = new PerTargetInstantiationModelPointcut(this.declaredPointcut, preInstantiationPointcut, aspectInstanceFactory); this.lazy = true; &#125; else &#123; this.pointcut = this.declaredPointcut; this.lazy = false; // 把切面中的通知构造为一个一个的advice通知对象 this.instantiatedAdvice = instantiateAdvice(this.declaredPointcut); &#125; &#125; private Advice instantiateAdvice(AspectJExpressionPointcut pointcut) &#123; Advice advice = this.aspectJAdvisorFactory.getAdvice(this.aspectJAdviceMethod, pointcut, this.aspectInstanceFactory, this.declarationOrder, this.aspectName); return (advice != null ? advice : EMPTY_ADVICE); &#125;&#125; 在instantiateAdvice方法中调用getAdvice方法根据不同类型的注解生成对应的Advice。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ReflectiveAspectJAdvisorFactory extends AbstractAspectJAdvisorFactory implements Serializable &#123; public Advice getAdvice(Method candidateAdviceMethod, AspectJExpressionPointcut expressionPointcut, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) &#123; // 获取切面类的class对象 Class&lt;?&gt; candidateAspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); validate(candidateAspectClass); // 获取切面方法上的注解 AspectJAnnotation&lt;?&gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) &#123; // 解析出来的注解信息是否为null return null; &#125; if (!isAspect(candidateAspectClass)) &#123; // 判断这里的class对象是不是切面信息对象 throw new AopConfigException(\"Advice must be declared inside an aspect type: Offending method '\" + candidateAdviceMethod + \"' in class [\" + candidateAspectClass.getName() + \"]\"); &#125; AbstractAspectJAdvice springAdvice; switch (aspectJAnnotation.getAnnotationType()) &#123; // 判断标注在方法上的注解类型 case AtPointcut: // 是PointCut注解则抛出异常，在外面传递进来的方法已经排除了pointcut的方法 return null; case AtAround: //环绕通知 构建AspectJAroundAdvice springAdvice = new AspectJAroundAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtBefore: //前置通知 构建AspectJMethodBeforeAdvice springAdvice = new AspectJMethodBeforeAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfter: //后置通知 AspectJAfterAdvice springAdvice = new AspectJAfterAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfterReturning: //返回通知 AspectJAfterReturningAdvice springAdvice = new AspectJAfterReturningAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterReturningAnnotation.returning())) &#123; springAdvice.setReturningName(afterReturningAnnotation.returning()); &#125; break; case AtAfterThrowing: //异常通知 AspectJAfterThrowingAdvice springAdvice = new AspectJAfterThrowingAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterThrowingAnnotation.throwing())) &#123; springAdvice.setThrowingName(afterThrowingAnnotation.throwing()); &#125; break; default: throw new UnsupportedOperationException(\"Unsupported advice type on method: \" + candidateAdviceMethod); &#125; springAdvice.setAspectName(aspectName); // 配置构建出来的通知对象 springAdvice.setDeclarationOrder(declarationOrder); String[] argNames = this.parameterNameDiscoverer.getParameterNames(candidateAdviceMethod); if (argNames != null) &#123; springAdvice.setArgumentNamesFromStringArray(argNames); &#125; springAdvice.calculateArgumentBindings(); return springAdvice; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"https://yaoyinglong.github.io/tags/AOP/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"AOP基础","date":"2021-09-25T16:00:00.000Z","path":"Blog/Spring/AOP基础/","text":"AOP面向方面编程或面向切面编程，AOP联盟网站下有以下AOP技术： AspectJ：源代码和字节码级别的编织器，用户需要使用不同于Java的新语言。 AspectWerkz：AOP框架，使用字节码动态编织器和XML配置。 JBoss-AOP：基于拦截器和元数据的AOP框架，运行在JBoss应用服务器上。 BCEL：Java字节码操作类库。 Javassist：Java字节码操作类库，JBoss子项目。 反射、程序预处理、拦截器框架、类装载器框架、元数据处理等技术都可以作为编制逻辑的具体实现方法，Spring AOP是基于动态代理来实现的，默认若使用接口，则用JDK动态代理实现，若没使用接口则用CGLib实现。 Spring3.2以后，spring-core直接把CGLIB和ASM源码包括进来了。Spring AOP需要依赖IoC容器来管理，且Spring AOP只能作用于Spring容器中的Bean。Spring只用到AspectJ切点解析和匹配。 Spring AOP是基于代理实现的，在容器启动时需生成代理实例，在方法调用上也会增加栈的深度，使得Spring AOP性能不如AspectJ好。 @Aspect、@Pointcut、@Before、@After等注解都是来自于AspectJ，但功能实现是纯 Spring AOP自己实现的。 Spring AOP有三种配置方式 Spring 1.2基于接口的配置：最早的Spring AOP是完全基于几个接口的 Spring 2.0schema-based配置：Spring 2.0以后使用XML加命名空间的方式来配置 Spring 2.0注解配置：使用注解的方式来配置。 基于接口的配置通过调用FactoryBean的getObject方法创建一个代理实现，只能指定单一的Bean的AOP，若多个Bean需要创建多个ProxyFactoryBean，拦截器的粒度只控制到了类级别，类中所有的方法都进行了拦截。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public interface Calculate &#123; int sub(int numA, int numB); int div(int numA, int numB);&#125;public class ElevenCalculate implements Calculate &#123; @Override public int sub(int numA, int numB) &#123; System.out.println(\"执行目标方法:reduce\"); return numA - numB; &#125; @Override public int div(int numA, int numB) &#123; System.out.println(\"执行目标方法:div\"); return numA / numB; &#125;&#125;public class ElevenLogAdvice implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; String methodName = method.getName(); System.out.println(\"执行目标方法【\"+methodName+\"】的&lt;前置通知&gt;,入参\"+ Arrays.asList(args)); &#125;&#125;public class ElevenLogInterceptor implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println(getClass() + \"调用方法前\"); Object ret = invocation.proceed(); System.out.println(getClass() + \"调用方法后\"); return ret; &#125;&#125;@Configurationpublic class EealyAopMainConfig &#123; @Bean public Calculate elevenCalculate() &#123; return new ElevenCalculate(); &#125; @Bean public ElevenLogAdvice elevenLogAdvice() &#123; return new ElevenLogAdvice(); &#125; @Bean public ElevenLogInterceptor elevenLogInterceptor() &#123; return new ElevenLogInterceptor(); &#125; @Bean public ProxyFactoryBean calculateProxy() &#123; ProxyFactoryBean userService = new ProxyFactoryBean(); userService.setInterceptorNames(\"elevenLogAdvice\", \"elevenLogInterceptor\"); // 根据指定的顺序执行 userService.setTarget(elevenCalculate()); return userService; &#125;&#125;public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Calculate calculateProxy = context.getBean(\"calculateProxy\", Calculate.class); calculateProxy.div(1, 1);&#125; 配置拦截器时，interceptorNames除了指定为Advice、Interceptor，还可指定为Advisor。Advisor内部需要指定一个Advice，Advisor决定拦截哪些方法，拦截后需要完成的工作还是由Advice来完成。 12345678910111213141516171819@Beanpublic NameMatchMethodPointcutAdvisor elevenLogAspect() &#123; NameMatchMethodPointcutAdvisor advisor=new NameMatchMethodPointcutAdvisor(); advisor.setAdvice(elevenLogAdvice()); advisor.setMappedNames(\"div\"); return advisor;&#125;@Beanpublic ProxyFactoryBean calculateAdvisorProxy()&#123; ProxyFactoryBean userService=new ProxyFactoryBean(); userService.setInterceptorNames(\"elevenLogAspect\"); userService.setTarget(elevenCalculate()); return userService;&#125;public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Calculate calculateProxy = context.getBean(\"calculateAdvisorProxy\", Calculate.class); calculateProxy.div(1, 1);&#125; 自动注入配置1234567891011121314@Beanpublic BeanNameAutoProxyCreator autoProxyCreator() &#123; BeanNameAutoProxyCreator beanNameAutoProxyCreator = new BeanNameAutoProxyCreator(); // 设置要创建代理的那些Bean的名字 beanNameAutoProxyCreator.setBeanNames(\"eleven*\"); // 设置拦截链名字(这些拦截器是有先后顺序的) beanNameAutoProxyCreator.setInterceptorNames(\"elevenLogInterceptor\"); return beanNameAutoProxyCreator;&#125;public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Calculate calculateProxy = context.getBean(\"elevenCalculate\", Calculate.class); calculateProxy.div(1, 1);&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"https://yaoyinglong.github.io/tags/AOP/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"事件监听器","date":"2021-09-24T16:00:00.000Z","path":"Blog/Spring/事件监听器/","text":"Spring事件体系包括事件，事件监听器，事件广播器三个组件，实现原理其实就是观察者模式。Spring内置事件由系统内部进行发布，只需要注入监听器即可： ContextRefreshedEvent：当容器被实例化即所有Bean都已被加载后置处理器都被激活，所有单例bean都已被实例化，所有容器对象都已准备好可使用，如调用refresh()方法。若容器支持热重载，则refresh可以被触发多次，XmlWebApplicatonContext支持热刷新，GenericApplicationContext不支持。 ContextStartedEvent：当容器启动时发布，即调用start()方法，即所有Lifecycle Bean都已显式接收到了start信号 ContextStoppedEvent：当容器停止时发布，即调用stop()方法，即所有Lifecycle Bean都已显式接收到了stop信号，关闭的容器可通过start()方法重启 ContextClosedEvent：当容器关闭时发布，即调用close()方法，即所有单例Bean都已被销毁。关闭的容器不能被重启或refresh RequestHandledEvent：只在使用Spring DispatcherServlet时有效，当一个请求被处理完成时发布 Spring事件机制是观察者模式的一种实现，除了发布者和监听者者两个角色之外，还有一个EventMultiCaster的角色负责把事件转发给监听者，发布者调用context.publishEvent(msg)，会将事件发送给了EventMultiCaster， 而EventMultiCaster注册着所有的Listener，然后根据事件类型决定转发给那个Listener。 源码 在refresh()中的prepareRefresh()方法中创建了一个早期事件监听器对象earlyApplicationListeners，以及用于保存早期待发布的事件集合earlyApplicationEvents，事件监听器还没有注册到多播器上的时候都称为早期事件。早期事件不需要手动publishEvent发布，在registerListeners中会自动发布，发布完早期事件后会将早期事件置空。 1234567891011121314public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; private Set&lt;ApplicationEvent&gt; earlyApplicationEvents; private ApplicationEventMulticaster applicationEventMulticaster; private Set&lt;ApplicationListener&lt;?&gt;&gt; earlyApplicationListeners; protected void prepareRefresh() &#123; if (this.earlyApplicationListeners == null) &#123; // 创建一个早期事件监听器对象 this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); &#125; else &#123; this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); &#125; this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;(); &#125;&#125; 事件广播器初始化applicationEventMulticaster提供了容器监听器的注册表，refresh()中的initApplicationEventMulticaster()中会对事件广播器进行初始化。 12345678910111213protected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // 获取我Bean工厂对象 // 判断容器中是否有applicationEventMulticaster应用多播器组件 if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; // 直接显示的调用getBean获取ApplicationEventMulticaster赋值给applicationContext对象 this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); &#125; else &#123; // 若容器中没有 // spring ioc显示的new一个SimpleApplicationEventMulticaster对象保存在applicatoinContext对象中 this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); // 并且注入到容器中 beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); &#125;&#125; 用户可通过实现ApplicationEventMulticaster接口自定义事件广播器，Spring会将其注册成容器的事件广播器，若没有找到配置的外部事件广播器，默认使用SimpleApplicationEventMulticaster作为事件广播器。 注册事件监听器refresh()的registerListeners()中会获取容器中所有的监听器对象，把监听器挨个的注册到多播器上去，这个时候正常流程是不会有监听器的，在initApplicationEventMulticaster之后，在registerListeners之前，只有一个可能在onRefresh()里面注册了监听器。这里会执行所有的早期发布事件。 1234567891011121314151617181920protected void registerListeners() &#123; // 获取容器中所有的监听器对象，把监听器挨个的注册到多播器上去，这个时候正常流程是不会有监听器的 // 监听器不会在这之前注册，在initApplicationEventMulticaster后在registerListeners之前，只有一个可能在：在onRefresh里面注册了监听器 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // 获取Bean定义中的监听器对象 String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) &#123; // 把监听器的名称注册到多播器上 getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); &#125; // 获取早期事件 Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; // 在这里赋null，也就是值此之后都将没有早期事件了 if (earlyEventsToProcess != null) &#123;// 通过多播器进行播发早期事件 for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123; getApplicationEventMulticaster().multicastEvent(earlyEvent); &#125; &#125;&#125; 这里只是把监听器的名称注册到多播器上，为了防止懒加载的监听器漏掉，因为懒加载的Bean是不会在容器初始化时加载的，只会在使用时才会去加载，且这里只处理实现了ApplicationListener接口的监听器。 123456789101112131415161718192021222324252627282930private class ListenerRetriever &#123; // 存储了所有的Listener，包括实现了ApplicationListener接口和使用了@EventListener的Bean public final Set&lt;ApplicationListener&lt;?&gt;&gt; applicationListeners = new LinkedHashSet&lt;&gt;(); // 只存储实现了ApplicationListener接口的Bean名称 public final Set&lt;String&gt; applicationListenerBeans = new LinkedHashSet&lt;&gt;(); private final boolean preFiltered; public ListenerRetriever(boolean preFiltered) &#123; this.preFiltered = preFiltered; &#125; public Collection&lt;ApplicationListener&lt;?&gt;&gt; getApplicationListeners() &#123; List&lt;ApplicationListener&lt;?&gt;&gt; allListeners = new ArrayList&lt;&gt;(this.applicationListeners.size() + this.applicationListenerBeans.size()); allListeners.addAll(this.applicationListeners); if (!this.applicationListenerBeans.isEmpty()) &#123; BeanFactory beanFactory = getBeanFactory(); for (String listenerBeanName : this.applicationListenerBeans) &#123; try &#123; ApplicationListener&lt;?&gt; listener = beanFactory.getBean(listenerBeanName, ApplicationListener.class); if (this.preFiltered || !allListeners.contains(listener)) &#123; allListeners.add(listener); &#125; &#125; catch (NoSuchBeanDefinitionException ex) &#123; &#125; &#125; &#125; if (!this.preFiltered || !this.applicationListenerBeans.isEmpty()) &#123; AnnotationAwareOrderComparator.sort(allListeners); &#125; return allListeners; &#125;&#125; 发布事件Spring委托ApplicationEventMulticaster将事件通知给所有的事件监听器，这里会发布ContextRefreshedEvent事件，可实现一个ContextRefreshedEvent事件的监听器做一些扩展。 12345678910111213141516171819202122232425262728293031323334353637383940414243protected void finishRefresh() &#123; // 清除上下文级别的资源缓存，如来自扫描的ASM元数据 clearResourceCaches(); // 注册lifecycleProcessor声明周期处理器，作用：当ApplicationContext启动或停止时，它会通过LifecycleProcessor来与所有声明的bean的周期做状态更新 initLifecycleProcessor(); // 为实现了SmartLifecycle并且isAutoStartup 自动启动的Lifecycle调用start()方法 getLifecycleProcessor().onRefresh(); // 发布容器启动完毕事件 publishEvent(new ContextRefreshedEvent(this)); // 注册当前spring容器到LiveBeansView，提供servlet(LiveBeansViewServlet)在线查看所有的bean json 、 为了支持Spring Tool Suite的智能提示 LiveBeansView.registerApplicationContext(this);&#125;public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; public void publishEvent(ApplicationEvent event) &#123; publishEvent(event, null); &#125; protected void publishEvent(Object event, @Nullable ResolvableType eventType) &#123; Assert.notNull(event, \"Event must not be null\"); ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) &#123; applicationEvent = (ApplicationEvent) event; &#125; else &#123; applicationEvent = new PayloadApplicationEvent&lt;&gt;(this, event); if (eventType == null) &#123; eventType = ((PayloadApplicationEvent&lt;?&gt;) applicationEvent).getResolvableType(); &#125; &#125; // 这里是唯一添加早期事件的地方，所以一定要发布事件才能添加早期事件 // 只有当执行力refresh--&gt;registerListeners才会将earlyApplicationEvents赋为null，故registerListeners之前发布的事件都是早期事件 if (this.earlyApplicationEvents != null) &#123; this.earlyApplicationEvents.add(applicationEvent); &#125; else &#123; getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); &#125; if (this.parent != null) &#123; // 若是父容器，也会向父容器里广播一份 if (this.parent instanceof AbstractApplicationContext) &#123; ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); &#125; else &#123; this.parent.publishEvent(event); &#125; &#125; &#125;&#125; Spring默认的事件广播器为SimpleApplicationEventMulticaster，这里其实就是挨个去调用事件监听器的onApplicationEvent方法。默认getTaskExecutor()获取的线程池为null，故默认是同步执行，applicationContext.publishEvent()方法需要同步等待各个监听器处理完之后才返回。若想异步可实现ApplicationEventMulticaster接口，并将其注册beanName为applicationEventMulticaster的Bean。 123456789101112131415161718192021222324252627282930313233public class SimpleApplicationEventMulticaster extends AbstractApplicationEventMulticaster &#123; public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); // 从多播器中获取出所有的监听器 for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; Executor executor = getTaskExecutor(); // 判断多播器中是否支持异步多播的 if (executor != null) &#123; // 异步播发事件 executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; // 同步播发 invokeListener(listener, event); &#125; &#125; &#125; protected void invokeListener(ApplicationListener&lt;?&gt; listener, ApplicationEvent event) &#123; ErrorHandler errorHandler = getErrorHandler(); if (errorHandler != null) &#123; try &#123; doInvokeListener(listener, event); &#125; catch (Throwable err) &#123; errorHandler.handleError(err); &#125; &#125; else &#123; doInvokeListener(listener, event); &#125; &#125; private void doInvokeListener(ApplicationListener listener, ApplicationEvent event) &#123; try &#123; listener.onApplicationEvent(event); &#125; catch (ClassCastException ex) &#123; throw ex; &#125; &#125;&#125; 遍历注册的每个监听器，并启动来调用每个监听器的onApplicationEvent方法。由于SimpleApplicationEventMulticaster的taskExecutor的实现类是SyncTaskExecutor，因此事件监听器对事件的处理是同步进行的。 自定义监听器注册对于用户自定义的监听器的解析是通过ApplicationListenerDetector后置处理器来实现的，该Bean后置处理器是在refresh()的registerBeanPostProcessors(beanFactory)中注册的，在第八次Bean的后置处理器的调用的地方调用。用于解析实现了ApplicationListener接口的方式的监听器。 12345678910111213class ApplicationListenerDetector implements DestructionAwareBeanPostProcessor, MergedBeanDefinitionPostProcessor &#123; public Object postProcessAfterInitialization(Object bean, String beanName) &#123; if (bean instanceof ApplicationListener) &#123; Boolean flag = this.singletonNames.get(beanName); if (Boolean.TRUE.equals(flag)) &#123; this.applicationContext.addApplicationListener((ApplicationListener&lt;?&gt;) bean); &#125; else if (Boolean.FALSE.equals(flag)) &#123; this.singletonNames.remove(beanName); &#125; &#125; return bean; &#125;&#125; 对于注解方式的自定义监听器的解析与执行是通过在IoC容器启动最开始时在AnnotatedBeanDefinitionReader中注册了一系列创世纪的类时，注册了DefaultEventListenerFactory事件监听器工厂和处理监听方法的注解@EventListener解析器EventListenerMethodProcessor。解析是在refresh()的finishBeanFactoryInitialization(beanFactory)的beanFactory.preInstantiateSingletons()中，且是在所有单例Bean都已实例化完成加载到单例池中之后： 12345678910111213141516171819202122public void preInstantiateSingletons() throws BeansException &#123; // 获取容器中所有bean定义的名称 List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // 所有的单实例的bean已经记载到单实例bean到缓存中 for (String beanName : beanNames) &#123; // 从单例缓存池中获取所有的对象 Object singletonInstance = getSingleton(beanName); // 判断当前的bean是否实现了SmartInitializingSingleton接口 if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; // 触发实例化之后的方法afterSingletonsInstantiated smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class EventListenerMethodProcessor implements SmartInitializingSingleton, ApplicationContextAware &#123; protected final Log logger = LogFactory.getLog(getClass()); private final EventExpressionEvaluator evaluator = new EventExpressionEvaluator(); // 没有@EventListener的类 private final Set&lt;Class&lt;?&gt;&gt; nonAnnotatedClasses = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(64)); @Nullable private ConfigurableApplicationContext applicationContext; private ConfigurableApplicationContext getApplicationContext() &#123; Assert.state(this.applicationContext != null, \"No ApplicationContext set\"); return this.applicationContext; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) &#123; Assert.isTrue(applicationContext instanceof ConfigurableApplicationContext, \"ApplicationContext does not implement ConfigurableApplicationContext\"); this.applicationContext = (ConfigurableApplicationContext) applicationContext; &#125; @Override public void afterSingletonsInstantiated() &#123; // 从BeanFactory中获取EventListenerFactory的bean默认情况下的两个实现,DefaultEventListenerFactory：spring自己注入的，TransactionalEventListenerFactory：使用配置进去的 List&lt;EventListenerFactory&gt; factories = getEventListenerFactories(); ConfigurableApplicationContext context = getApplicationContext(); String[] beanNames = context.getBeanNamesForType(Object.class); for (String beanName : beanNames) &#123; // 处理所有bean查找当前bean标注了@EventListener的方法 if (!ScopedProxyUtils.isScopedTarget(beanName)) &#123; Class&lt;?&gt; type = null; try &#123; type = AutoProxyUtils.determineTargetClass(context.getBeanFactory(), beanName); &#125; catch (Throwable ex) &#123; &#125; if (type != null) &#123; if (ScopedObject.class.isAssignableFrom(type)) &#123; try &#123; Class&lt;?&gt; targetClass = AutoProxyUtils.determineTargetClass(context.getBeanFactory(), ScopedProxyUtils.getTargetBeanName(beanName)); if (targetClass != null) &#123; type = targetClass; &#125; &#125; catch (Throwable ex) &#123; &#125; &#125; try &#123; processBean(factories, beanName, type); &#125; catch (Throwable ex) &#123; throw new BeanInitializationException(\"Failed to process @EventListener \" + \"annotation on bean with name '\" + beanName + \"'\", ex); &#125; &#125; &#125; &#125; &#125; protected List&lt;EventListenerFactory&gt; getEventListenerFactories() &#123; Map&lt;String, EventListenerFactory&gt; beans = getApplicationContext().getBeansOfType(EventListenerFactory.class); List&lt;EventListenerFactory&gt; factories = new ArrayList&lt;&gt;(beans.values()); AnnotationAwareOrderComparator.sort(factories); return factories; &#125; protected void processBean(final List&lt;EventListenerFactory&gt; factories, final String beanName, final Class&lt;?&gt; targetType) &#123; if (!this.nonAnnotatedClasses.contains(targetType)) &#123; Map&lt;Method, EventListener&gt; annotatedMethods = null; try &#123; // 查找当前bean标注了@EventListener的方法 annotatedMethods = MethodIntrospector.selectMethods(targetType, (MethodIntrospector.MetadataLookup&lt;EventListener&gt;) method -&gt; AnnotatedElementUtils.findMergedAnnotation(method, EventListener.class)); &#125; catch (Throwable ex) &#123; &#125; if (CollectionUtils.isEmpty(annotatedMethods)) &#123; this.nonAnnotatedClasses.add(targetType); &#125; else &#123; ConfigurableApplicationContext context = getApplicationContext(); for (Method method : annotatedMethods.keySet()) &#123; for (EventListenerFactory factory : factories) &#123; if (factory.supportsMethod(method)) &#123; // ①创建事件监听器 Method methodToUse = AopUtils.selectInvocableMethod(method, context.getType(beanName)); ApplicationListener&lt;?&gt; applicationListener = factory.createApplicationListener(beanName, targetType, methodToUse); if (applicationListener instanceof ApplicationListenerMethodAdapter) &#123; ((ApplicationListenerMethodAdapter) applicationListener).init(context, this.evaluator); &#125; context.addApplicationListener(applicationListener); // ②注册事件到Context中 break; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 注解方式的监听器发布事件是统一走的ApplicationListenerMethodAdapter的onApplicationEvent方法，然后通过反射来调用。 123456789101112131415161718192021public class ApplicationListenerMethodAdapter implements GenericApplicationListener &#123; public void onApplicationEvent(ApplicationEvent event) &#123; processEvent(event); &#125; public void processEvent(ApplicationEvent event) &#123; Object[] args = resolveArguments(event); if (shouldHandle(event, args)) &#123; Object result = doInvoke(args); if (result != null) &#123; handleResult(result); &#125; &#125; &#125; protected Object doInvoke(Object... args) &#123; Object bean = getTargetBean(); ReflectionUtils.makeAccessible(this.method); try &#123; return this.method.invoke(bean, args); &#125; &#125;&#125; 自定义事件事件类继承ApplicationEvent即可 12345678910public class ElevenEvent extends ApplicationEvent &#123; private String name; public ElevenEvent(Object source, String name) &#123; super(source); this.name = name; &#125; public String getName() &#123; return name; &#125;&#125; 监听器可以基于接口，需实现ApplicationListener接口覆写onApplicationEvent方法，也可基于@EventListener注解的方式，同一个事件可有多个监听器 1234567891011121314@Componentpublic class ElevenEventListener implements ApplicationListener&lt;ElevenEvent&gt; &#123; @Override public void onApplicationEvent(ElevenEvent event) &#123; System.out.println(Thread.currentThread().getName() + \", Interface：\" + event.getName()); &#125;&#125;@Componentpublic class ElevenEventAnnotationListener &#123; @EventListener(value = ElevenEvent.class) public void onApplicationEvent(ElevenEvent event) &#123; System.out.println(Thread.currentThread().getName() + \", Annotation：\" + event.getName()); &#125;&#125; 事件的发布通过容器发布即可 12AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class);context.publishEvent(new ElevenEvent(context, \"test\")); 事件监听操作可异步执行，只需配置异步线程池即可 123456@Bean(name = \"applicationEventMulticaster\")public ApplicationEventMulticaster simpleApplicationEventMulticaster() &#123; SimpleApplicationEventMulticaster eventMulticaster = new SimpleApplicationEventMulticaster(); eventMulticaster.setTaskExecutor(new SimpleAsyncTaskExecutor()); return eventMulticaster;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"Bean的生命周期","date":"2021-09-22T16:00:00.000Z","path":"Blog/Spring/Bean的生命周期/","text":"生命周期首先Bean是通过ConfigurationClassPostProcessor解析配置类的后置处理器，将Bean从类中注册到BeanFactory中，然后通过getBean方法加载Bean。 首先调用getSingleton方法从三级缓存中获取，若获取不到，再通过函数式接口调用createBean创建Bean的流程。通过resolveBeforeInstantiation方法去第一次调用Bean的后置处理器，这里调用的是实现了InstantiationAwareBeanPostProcessor接口postProcessBeforeInstantiation方法的后置处理器，这里主要调用AbstractAutoProxyCreator对AOP切面类进行解析，并将解析后的数据缓存，即通过@EnableAspectJAutoProxy开启了AOP代理，且该类为Advice、Pointcut、Advisor、AopInfrastructureBean等接口的子类，或该类上有@Aspect注解且不是一个被AspectJ编译过的类；在这里还可以自定义一个后置处理器返回一个对象来阻断后续流程的执行。 接着调用doCreateBean真正去创建Bean，首先回去创建Bean的简单实例，在创建实例的过程中可能会第二次调用Bean的后置处理器，这里调用的是实现了SmartInstantiationAwareBeanPostProcessor接口determineCandidateConstructors方法的后置处理器，这里主要调用AutowiredAnnotationBeanPostProcessor来指定实例化的的构造函数，通过@Bean注入的对象会跳过该后置处理器。 简单实例化完成后，调用applyMergedBeanDefinitionPostProcessors从而第三次调用Bean的后置处理器，完成@Autowired、@Value、@PostConstruct等注解以及自定义的初始化方法等预解析。调用AutowiredAnnotationBeanPostProcessor将@Autowired、@Value注入信息预解析存入externallyManagedConfigMembers中，调用CommonAnnotationBeanPostProcessor从而调用InitDestroyAnnotationBeanPostProcessor将自定义的初始化方法信息即@Bean(initMethod = &quot;initMethod&quot;)中指定的初始化方法预解析存入externallyManagedInitMethods中。 然后将早期对象通过函数式接口getEarlyBeanReference存入第三级缓存singletonFactories中，这里主要是为了解决循环依赖，若不存在循环依赖，该函数接口不会被调用，故三级缓存不会被升级为二级缓存。在该函数式接口中第四次调用了Bean的后置处理器，调用实现了SmartInstantiationAwareBeanPostProcessor接口的getEarlyBeanReference方法的后置处理器，这里是调用AbstractAutoProxyCreator后置处理器，主要作用是给有AOP代理的且产生循环依赖且先被加载的对象创建AOP代理，若该Bean有AOP代理，但不存在循环依赖或存在循环依赖但后被加载，则AOP代理是在第八次调用后置处理器时，给该Bean创建动态代理的。若在该处已经设置了动态代理会将beanName加入到earlyProxyReferences集合中，防止第八次调用后置处理器时重复添加动态代理。 紧接着调用populateBean方法为Bean的属性进行赋值，在属性设置前第五次调用实现了InstantiationAwareBeanPostProcessor接口postProcessAfterInstantiation的后置处理器，其作用是让用户可以自定义属性，其还可以设置跳过后续的赋值操作。 紧接着调用第六次后置处理器，调用实现了InstantiationAwareBeanPostProcessor接口postProcessProperties的后置处理器，主要是注入PropertyValues对属性进行赋值操作，@Autowired、@Value注解是通过AutowiredAnnotationBeanPostProcessor中postProcessProperties方法调用InjectionMetadata.inject方法，若发现@Autowired注入的Bean未被创建，最终会调用DependencyDescriptor的resolveCandidate方法，通过getBean去创建该Bean。若存在循环依赖，给依赖的Bean进行属性赋值时会再次通过getBean调用当前Bean，从而通过getSingleton方法中对三级缓存中函数式接口的调用，即调用getEarlyBeanReference方法将三级缓存转换为二级缓存，返回给依赖的Bean进行赋值操作。 完成了属性的赋值，接下来就是通过initializeBean对Bean的初始化方法的调用，初始化调用前首先通过invokeAwareMethods方法对BeanNameAware、BeanClassLoaderAware、BeanFactoryAware三个Aware接口的调用。 第七次Bean的后置处理器调用，通过InitDestroyAnnotationBeanPostProcessor接口中调用LifecycleMetadata.invokeInitMethods方法来实现初始化前@PostConstruct注解的方法的调用，以及调用ApplicationContextAwareProcessor后置处理器的postProcessBeforeInitialization方法，完成EnvironmentAware、EmbeddedValueResolverAware、ResourceLoaderAware、ApplicationEventPublisherAware、MessageSourceAware、ApplicationContextAware、ImportAware等Aware接口的调用。 接着调用invokeInitMethods方法，若Bean实现了InitializingBean接口，则调用InitializingBean接口的afterPropertiesSet方法，以及自定义的初始化方法的调用即@Bean(initMethod = &quot;initMethod&quot;)中指定的初始化方法。 在applyBeanPostProcessorsAfterInitialization方法中完成了第八次后置处理器的调用，通过调用实现了BeanPostProcessor接口postProcessAfterInitialization方法的后置处理器，调用AbstractAutoProxyCreator、AbstractAdvisingBeanPostProcessor、AdvisorAdapterRegistrationManager等后置处理器的调用来对初始化完成后的Bean进行AOP代理的创建，调用ApplicationListenerDetector调用来对ApplicationListener的添加。 最终Bean销毁时会调用第九次Bean的后置处理器，即调用InitDestroyAnnotationBeanPostProcessor后置处理器的postProcessBeforeDestruction方法。 循环依赖所谓的循环依赖是指，A依赖B，B又依赖A，它们之间形成了循环依赖。或者A依赖B，B依赖C，C又依赖A： Spring中Bean创建过程中，需要对Bean的属性进行赋值，当发现其属性B是一个Bean时，会先通过getBean(B)去获取依赖的Bean，若B未被穿件会先创建，最终将生成好的依赖的Bean赋值给当前属性。若在通过getBean(B)创建依赖Bean时，给依赖的Bean的属性A赋值时，发现其属性是前一个Bean，这是又通过getBean(A)去获取Bean，但这时A并没有创建完成，这时就会产生死循环。Spring中是通过三级缓存来解决单例Bean的循环依赖问题的。 1234567891011121314public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; // 一级缓存，也是单例缓存池 用于保存所有的单实例bean private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); // 二级缓存，缓存的key为beanName，value为早期对象，即还没进行属性赋值的对象 private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); // 三级缓存，缓存key为beanName，value为函数式接口ObjectFactory private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16); // 已注册的单例名称set private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;&gt;(256); // 该集合用户缓存当前正在创建bean的名称 private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); // 排除当前创建检查的 private final Set&lt;String&gt; inCreationCheckExclusions = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16));&#125; 一级缓存singletonObjects保存所有生成完全的单实例Bean，二级缓存earlySingletonObjects保存还没进行属性赋值的Bean的早期对象，三级缓存singletonFactories中保存是封装了早期对象的函数式接口。 1addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); 123456789101112protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; return exposedObject;&#125; 当Bean实例化完成即早期对象生成完成后，会将早期对象通过函数式接口getEarlyBeanReference存入第三级缓存singletonFactories中，主要就是为了解决循环依赖，若不存在循环依赖，该函数接口不会被调用，故三级缓存不会被升级为二级缓存。若存在循环引用就会在getBean(A)时调用getSingleton方法，从而将三级缓存中的函数式接口getEarlyBeanReference执行，给有AOP代理的且产生循环依赖的对象创建AOP代理，并将代理后的对象放入二级缓存中。1234567891011121314151617protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125; B的属性赋值中就能通过getBean(A)拿到A了，然后B就能完成赋值从而完成Bean的生成，最终A的属性赋值getBean(B)就能获取到B从而A完成属性赋值。 从源码来看其实二级缓存完全可以解决循环依赖的问题，若不使用第三级缓存，那getEarlyBeanReference方法要么在Bean实例化后就立即调用，要么将getEarlyBeanReference放入getSingleton中调用，前者会导致不论是否有循环依赖的Bean创建都会被调用，从而导致大量重复的调用，后者导致getSingleton方法职责不单一，故用到第三级缓存可能主要是为了解耦、方法职责单一、提高阅读性便于维护。 对于循环依赖中先被加载的类A才会用到二级缓存earlySingletonObjects，后被加载的类B其实跟普通Bean加载过程一样，不会调用三级缓存中的函数式接口getEarlyBeanReference。若A存在AOP代理，则B中赋值的A是经过AOP代理过后的对象，但给A属性赋值的时候依旧是赋值给未被代理的A，但是A和代理对象的中的A是同一个，故代理对象中的A属性被赋值了。若不存在AOP代理，这里的bean、earlySingletonReference、exposedObject其实是同一个对象，若存在AOP代理earlySingletonReference与bean、exposedObject不是同一个对象。 12345678if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); // 若存在AOP代理，则返回被代理后的对象 if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; // 将代理后的对象返回 &#125; &#125;&#125; 只有单实例Bean才会放入三级缓存，对于原型模式创建的对象不会放入三级缓存中，而Spring又是通过三级缓存来解决循环依赖的，故原型Bean的循环依赖无法利用缓存，则无法解决循环依赖的问题。 对于构造方法注入的Bean的循环依赖问题，源码中可以很明看到Bean是先通过构造方法实例化后，才会将其放入三级缓存中，故构造方法注入Bean无法利用三级缓存，故也无法解决循环依赖问题。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"Bean的加载过程","date":"2021-09-21T16:00:00.000Z","path":"Blog/Spring/Bean的加载过程/","text":"容器启动去实例化剩余未被加载的非懒加载的单例Bean。在invokeBeanFactoryPostProcessors方法中根据各种注解解析出来的类，在这都会被初始化，实例化的过程各种BeanPostProcessor开始起作用。 12345678910111213141516171819public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // 为我们的bean工厂创建类型转化器Convert if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService(beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal)); &#125; // 处理关于aspectj String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; beanFactory.setTempClassLoader(null); beanFactory.freezeConfiguration(); // 冻结所有bean定义，说明注册的bean定义将不被修改或任何进一步的处理 beanFactory.preInstantiateSingletons(); // 实例化剩余的单实例bean &#125;&#125; 对于FactoryBean可以通过&amp;beanName获取到原始的FactoryBean，若不加&amp;符号是获取的FactoryBean中getObject方法返回的对象作为Bean。不论是普通Bean还是FactoryBean最终都是通过getBean方法加载的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; public void preInstantiateSingletons() throws BeansException &#123; List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // 获取容器中所有bean定义的名称 for (String beanName : beanNames) &#123; // 循环所有的bean定义名称 // 合并的bean定义，转换为统一的RootBeanDefinition类型， 方便后续处理 RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); // 根据bean定义判断，不是抽象的&amp;&amp;是单例的&amp;&amp;不是懒加载的，才会去生成 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; // 是不是工厂bean // 是factoryBean会先生成实际的bean &amp;beanName是用来获取实际bean的 Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;)((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; // 调用真正的getBean的流程 getBean(beanName); &#125; &#125; &#125; else &#123; // 非工厂Bean，就是普通的bean getBean(beanName); &#125; &#125; &#125; //或有的bean的名称，到这里所有的单实例的bean已经记载到单实例bean到缓存中 for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); // 从单例缓存池中获取所有的对象 // 判断当前的bean是否实现了SmartInitializingSingleton接口 if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; // 触发实例化之后的方法afterSingletonsInstantiated smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125; &#125;&#125; 首先尝试去缓存中获取对象，若获取的是普通单例Bean对象，则getObjectForBeanInstance会直接返回。但若sharedInstance是FactoryBean类型，则需调用getObject工厂方法获取真正的bean实例。若用户想获取FactoryBean本身，这里也不会做特别的处理，直接返回即可。毕竟FactoryBean的实现类本身也是一种Bean，只不过具有一点特殊的功能而已。 Spring不能解决单例对象构造器注入和原型模式创建Bean产生的循环依赖问题，isPrototypeCurrentlyInCreation(beanName)判断会直接抛出异常。 判断AbstractBeanFacotry工厂是否有父工厂，一般情况下是没有父工厂因为abstractBeanFactory直接是抽象类，不存在父工厂，一般情况下，只有Spring和Spring MVC整合时才会有父子容器的概念，如Controller中注入Service时，发现依赖的是一个引用对象，则会调用getBean去把service找出来，但当前所在的容器是web子容器，则会在这里的先去父容器找。 若想类A在类B前被加载可以在类B上使用@DependsOn(value = {&quot;dependsA&quot;})注解处理dependsOn的依赖，这不是所谓的循环依赖，而是bean创建前后的依赖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public abstract class AbstractBeanFactory extends FactoryBeanRegistrySupport implements ConfigurableBeanFactory &#123; public Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false); // 真正的获取bean的逻辑 &#125; protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; // 这里传入进来的name可能是别名, 也有可能是工厂bean的name，所以在这里需要转换 final String beanName = transformedBeanName(name); Object bean; Object sharedInstance = getSingleton(beanName); // 尝试去缓存中获取对象 if (sharedInstance != null &amp;&amp; args == null) &#123; // 若sharedInstance是普通的单例bean，下面的方法会直接返回。但若sharedInstance是FactoryBean类型，则需调用getObject工厂方法获取真正的bean实例。 // 若用户想获取FactoryBean本身，这里也不会做特别的处理，直接返回即可。毕竟FactoryBean的实现类本身也是一种bean，只不过具有一点特殊的功能而已。 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // spring只能解决单例对象的setter注入的循环依赖，不能解决构造器注入和原型模式创建Bean产生的循环依赖问题 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // 判断AbstractBeanFacotry工厂是否有父工厂(一般情况下是没有父工厂因为abstractBeanFactory直接是抽象类,不存在父工厂),一般情况下,只有Spring和SpringMvc整合时才会有父子容器的概念 // 如Controller中注入Service时，发现依赖的是一个引用对象，则会调用getBean去把service找出来，但当前所在的容器是web子容器，则会在这里的先去父容器找 BeanFactory parentBeanFactory = getParentBeanFactory(); // 若存在父工厂，且当前bean工厂不存在当前的bean定义，则bean定义是存在于父beanFacotry中 if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; String nameToLookup = originalBeanName(name); // 获取bean的原始名称 // 若为AbstractBeanFactory类型，委托父类处理 if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean(nameToLookup, requiredType, args, typeCheckOnly); &#125; else if (args != null) &#123; // 委托给构造函数getBean()处理 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // 没有args，委托给标准的getBean()处理 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; // 方法参数typeCheckOnly，用来判断调用#getBean(...)方法时，表示是否仅仅进行类型检查获取Bean对象 if (!typeCheckOnly) &#123; // 若不是仅仅做类型检查，而是创建Bean对象，则需要调用#markBeanAsCreated(String beanName)方法，进行记录 markBeanAsCreated(beanName); &#125; try &#123; // 从容器中获取beanName相应的GenericBeanDefinition对象，并将其转换为RootBeanDefinition对象 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 检查当前创建的bean定义是不是抽象的bean定义 // 处理dependsOn的依赖，这个不是所谓的循环依赖，而是bean创建前后的依赖，依赖bean的名称 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; // 若给定的依赖bean已经注册为依赖给定的bean，即循环依赖的情况，抛出BeanCreationException异常 for (String dep : dependsOn) &#123; // beanName是当前正在创建的bean,dep是正在创建的bean的依赖的bean的名称 if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; registerDependentBean(dep, beanName); // 保存的是依赖beanName之间的映射关系：依赖beanName -&gt; beanName的集合 try &#123; getBean(dep); // 获取depentceOn的bean &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); &#125; &#125; &#125; if (mbd.isSingleton()) &#123; // 创建单例bean，把beanName和singletonFactory传入一个回调对象用于回调 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); // 进入创建bean的逻辑 &#125; catch (BeansException ex) &#123; // 创建bean的过程中发生异常，需要销毁关于当前bean的所有信息 destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // Check if required type matches the type of the actual bean instance. if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; return convertedBean; &#125; catch (TypeMismatchException ex) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean; &#125;&#125; 注意上面两次调用的getSingleton方法不是同一个方法，上面第一次调用的getSingleton方法： 1234567891011121314151617181920212223242526272829public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; public Object getSingleton(String beanName) &#123; // 系统一般是允许早期对象引用的allowEarlyReference通过这个参数可以控制解决循环依赖 return getSingleton(beanName, true); &#125; protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 先尝试去一级缓存单例缓存池中去获取对象，一般情况从该map中获取的对象是直接可使用的，IOC容器初始化加载单实例bean时第一次进来时该map中一般返回空 Object singletonObject = this.singletonObjects.get(beanName); // 若一级缓存中没有获取到对象,且singletonsCurrentlyInCreation这个list包含该beanName，IOC容器初始化加载单实例bean时第一次进来时，该list中一般返回空，但循环依赖时可以满足该条件 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 尝试去二级缓存中获取对象，二级缓存中的对象是一个早期对象，就是bean刚刚调用了构造方法，还来不及给bean的属性进行赋值的对象，即纯净态就是早期对象 singletonObject = this.earlySingletonObjects.get(beanName); // 二级缓存中也没有获取到对象,allowEarlyReference为true(参数是有上一个方法传递进来的true) if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 直接从三级缓存中获取ObjectFactory对象 这个对接就是用来解决循环依赖的关键所在，在ioc后期过程中,当bean调用了构造方法时,把早期对象包裹成一个ObjectFactory暴露到三级缓存中 ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123;// 从三级缓存中获取到对象不为空 // 在这里通过暴露的ObjectFactory包装对象中,通过调用他的getObject()来获取早期对象在这个环节中会调用到getEarlyBeanReference()来进行后置处理 singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); //把早期对象放置在二级缓存 this.singletonFactories.remove(beanName); // ObjectFactory包装对象从三级缓存中删除掉 &#125; &#125; &#125; &#125; return singletonObject; &#125;&#125; 上面第二次调用的getSingleton方法，该放法的第二个参数传入的是一个函数式接口，不会立刻执行，而是在下面调用ObjectFactory的getObject才会执行createBean。beforeSingletonCreation方法会将beanName加入到singletonsCurrentlyInCreation集合，即标记当前bean马上就要被创建了，当Bean创建完成会在afterSingletonCreation方法中将beanName从singletonsCurrentlyInCreation集合中移除。 12345678910111213141516171819202122232425262728293031323334353637383940public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, \"Bean name must not be null\"); synchronized (this.singletonObjects) &#123; // 加锁 Object singletonObject = this.singletonObjects.get(beanName); // 尝试从单例缓存池中获取对象 if (singletonObject == null) &#123; if (this.singletonsCurrentlyInDestruction) &#123; throw new BeanCreationNotAllowedException(beanName, \"Singleton bean creation not allowed while singletons of this factory are in destruction \" + \"(Do not request a bean from a BeanFactory in a destroy method implementation!)\"); &#125; // 标记当前bean马上就要被创建了，singletonsCurrentlyInCreation在这里会把beanName加入进来，若第二次循环依赖，构造器注入会抛出异常 beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) &#123; this.suppressedExceptions = new LinkedHashSet&lt;&gt;(); &#125; try &#123; // 初始化bean，这个过程其实是调用上面写的createBean()方法 singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch (IllegalStateException ex) &#123; //回调我们singletonObjects的get方法,进行正在的创建bean的逻辑 singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; throw ex; &#125; &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; finally &#123; // 后置处理，主要做是把singletonsCurrentlyInCreation标记正在创建的bean从集合中移除 afterSingletonCreation(beanName); &#125; if (newSingleton) &#123; addSingleton(beanName, singletonObject); // 加入缓存中 &#125; &#125; return singletonObject; &#125; &#125;&#125; resolveBeforeInstantiation(beanName, mbdToUse)是第一次调用bean后置处理器的地方，主要通过调用AbstractAutoProxyCreator后置处理器来进行后置处理生成代理对象，一般在此处不会生成代理对象，因为真实的对象没有生成，故在这里不会生成代理对象，这一步是AOP和事务的关键，在这里解析AOP切面信息进行缓存。doCreateBean才是真正创建bean实例对象。 12345678910111213141516171819202122232425262728293031323334public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; RootBeanDefinition mbdToUse = mbd; Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); // 确保此时的bean已经被解析了 if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; try &#123; // 验证和准备覆盖方法，仅在XML方式中，lookup-method和replace-method，这两个配置存放在BeanDefinition中的 methodOverrides(仅在XML方式中） // 在XML方式中bean实例化的过程中如果检测到存在methodOverrides，则会动态地为当前bean生成代理并使用对应的拦截器为bean做增强处理。 mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex); &#125; try &#123; // 第1个bean后置处理器，通过bean的后置处理器来进行后置处理生成代理对象，一般在此处不会生成代理对象，因为真实的对象没有生成，故在这里不会生成代理对象，这一步是我们aop和事务的关键，因为在这里解析aop切面信息进行缓存 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); &#125; try &#123; // 该步骤是真正创建bean实例对象的地方 Object beanInstance = doCreateBean(beanName, mbdToUse, args); return beanInstance; &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"Unexpected exception during bean creation\", ex); &#125; &#125;&#125; 上面的resolveBeforeInstantiation中调用的是applyBeanPostProcessorsBeforeInstantiation方法，而该方法中是第一次调用Bean的后置处理器的地方，该方法会执行所有实现了InstantiationAwareBeanPostProcessor接口的后置处理器，对于Spring内部有好几个实现了该接口的后置处理器，但只有AbstractAutoProxyCreator复写了这里调用的postProcessBeforeInstantiation方法。在这里通过该Bean后置处理器主要做的是解析AOP切面信息进行缓存，从上面和下面的代码结合来看若自定义一个Bean后置处理器且实现InstantiationAwareBeanPostProcessor接口复写postProcessBeforeInstantiation方法返回一个对象，可直接停止Bean的后续创建直接返回当前自定义后置处理器中返回的对象。 若返回Bean不为空，则调用所有实现InstantiationAwareBeanPostProcessor接口的后置处理器的postProcessAfterInitialization方法，这里主要是对初始化完成后的Bean进行AOP代理的创建，这也是Bean创建过程第八次调用Bean后置处理器的地方。正常情况上面的resolveBeforeInstantiation方法是不会调用applyBeanPostProcessorsAfterInitialization的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123; Object bean = null; if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123; // 判断容器中是否有InstantiationAwareBeanPostProcessors if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; Class&lt;?&gt; targetType = determineTargetType(beanName, mbd); // 获取当前bean的class对象 if (targetType != null) &#123; // 后置处理器的第一次调用，共有九处调用，事务在这里不会被调用，aop的才会被调用，因为在此处需要解析出对应的切面报错到缓存中 bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); // 若InstantiationAwareBeanPostProcessors后置处理器的postProcessBeforeInstantiation返回不为null，说明生成了代理对象 if (bean != null) &#123; // 后置处理器的第二处调用，该后置处理器若被调用的话，则第一处的处理器肯定返回的不是null，InstantiationAwareBeanPostProcessors后置处理器postProcessAfterInitialization bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); &#125; &#125; &#125; mbd.beforeInstantiationResolved = (bean != null); &#125; return bean; &#125; protected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取容器中的所有后置处理器 if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是不是InstantiationAwareBeanPostProcessor // 把BeanPostProcessor强制转为InstantiationAwareBeanPostProcessor InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // AOP的@EnableAspectJAutoProxy为容器中导入了AnnotationAwareAspectJAutoProxyCreator，事务注解@EnableTransactionManagement为容器导入了InfrastructureAdvisorAutoProxyCreator // 都是实现了BeanPostProcessor接口，InstantiationAwareBeanPostProcessor进行后置处理解析切面 Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null; &#125; public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) &#123; // 获取容器中的所有的bean的后置处理器 // 在这里是后置处理器的第九次调用，aop和事务都会在这里生存代理对象 // AOP的@EnableAspectJAutoProxy为容器中导入了AnnotationAwareAspectJAutoProxyCreator，事务注解@EnableTransactionManagement为容器导入了InfrastructureAdvisorAutoProxyCreator // 都是实现了我们的BeanPostProcessor接口，InstantiationAwareBeanPostProcessor，在这里实现的是BeanPostProcessor接口的postProcessAfterInitialization来生成我们的代理对象 Object current = processor.postProcessAfterInitialization(result, beanName); if (current == null) &#123; // 若只要有一个返回null，则直接返回原始的 return result; &#125; result = current; &#125; return result; &#125;&#125; doCreateBean主要完成的内容是，通过createBeanInstance对Bean进行实例化，通过populateBean对属性进行赋值，通过initializeBean对Bean进行初始化操作。且这三大步中又调用了很多次的Bean的后置处理器，以及一些Aware接口的调用等。 实例化完成后，判断当前Bean是否单例、是否允许循环依赖、是否正在创建，若满足条件则缓存单例到第三级缓存singletonFactories中，以防循环依赖。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // BeanWrapper是对Bean的包装，其接口中所定义的功能很简单包括设置获取被包装的对象，获取被包装bean的属性描述器 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; // 从没有完成的FactoryBean中移除 instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 创建bean实例化，使用合适的实例化策略来创建新的实例：工厂方法、构造函数自动注入、简单初始化，该方法很复杂也很重要 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; // 从beanWrapper中获取早期对象 final Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; //进行后置处理@AutoWired、@Value的注解的预解析 applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Post-processing of merged bean definition failed\", ex); &#125; mbd.postProcessed = true; &#125; &#125; // 缓存单例到三级缓存中，以防循环依赖，判断是否为早期引用的Bean，若是则允许提前暴露引用 // 判断是否能够暴露早期对象的条件：是否单例、是否允许循环依赖、是否正在创建的Bean boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; // 上述条件满足，允许中期暴露对象 // 把早期对象包装成一个singletonFactory对象，该对象提供了一个getObject方法，该方法内部调用getEarlyBeanReference方法 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; populateBean(beanName, mbd, instanceWrapper); // 属性赋值，给属性进行赋值，调用set方法进行赋值 exposedObject = initializeBean(beanName, exposedObject, mbd); // 进行对象初始化操作，在这里可能生成代理对象 &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); &#125; &#125; if (earlySingletonExposure) &#123; // 是早期对象暴露 // 去缓存中获取对象，由于传递的allowEarlyReference是false，要求只能在一级二级缓存中去获取，不存在循环依赖的bean创建过程中，压根不会把三级缓存提升到二级缓存中 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; // 能够获取到 if (exposedObject == bean) &#123; // 经过后置处理的bean和早期的bean引用还相等的话，表示当前的bean没有被代理过 exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; // 处理依赖的bean String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, \"Bean with name '\" + beanName + \"' has been injected into other beans [\" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + \"] in its raw version as part of a circular reference, but has eventually been \" + \"wrapped. This means that said other beans do not use the final version of the \" + \"bean. This is often the result of over-eager type matching - consider using \" + \"'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.\"); &#125; &#125; &#125; &#125; try &#123; //注册销毁的bean的销毁接口 registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); &#125; return exposedObject;&#125; 若使用@Bean方式配置的Bean实例化时直接通过instantiateUsingFactoryMethod工程方法进行实例化，方法名称就是就是工厂方法的名称。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); // 从bean定义中解析出当前bean的class对象 // 检测类的访问权限。默认情况下非public的类是允许访问的。Bean定义默认情况nonPublicAccessAllowed为true，即使不是public的也ok // beanClass不为null且访问修饰符如果不是public且Bean定义的nonPublicAccessAllowed为false，若满足则抛出异常 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Bean class isn't public, and non-public access not allowed: \" + beanClass.getName()); &#125; // 该方法是spring5.0 新增加的 如果存在 Supplier 回调，则使用给定的回调方法初始化策略 Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &#123; return obtainFromSupplier(instanceSupplier, beanName); &#125; // @Bean会在这创建实例，工厂方法，通过配置类来进行配置的话，采用的就是工厂方法，方法名称就是就是工厂方法的名称 if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // 当多次构建同一个bean时，可使用此处的快捷路径，即无需再次推断应该使用哪种方式构造实例，以提高效率。 // 在多次构建同一个prototype类型的bean时，就可以走此处的捷径，这里的resolved和mbd.constructorArgumentsResolved将会在bean第一次实例化的过程中被设置。 //判断当前构造函数是否被解析过 boolean resolved = false; //有没有必须进行依赖注入 boolean autowireNecessary = false; // 通过getBean传入进来的构造函数是否来指定需要推断构造函数，若传递进来的args不为空，则可直接选出对应的构造函数 if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; // 判断bean定义信息中的resolvedConstructorOrFactoryMethod用来缓存已解析的构造函数或者工厂方法 if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; // 修改已经解析过的构造函数的标志 autowireNecessary = mbd.constructorArgumentsResolved; // 修改标记为true标识构造函数或者工厂方法已解析过 &#125; &#125; &#125; if (resolved) &#123; // 若被解析过 if (autowireNecessary) &#123; // 通过有参的构造函数进行反射调用 return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; //调用无参数的构造函数进行创建对象 return instantiateBean(beanName, mbd); &#125; &#125; // 通过bean的后置处理器进行选举出合适的构造函数对象 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); // 自定义了BeanPostProcessor返回了构造器或使用构造器自动装配模式或设置了BeanDefinition构造器参数或有参数:即getBean(String name,Object... args) if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; return autowireConstructor(beanName, mbd, ctors, args); // 使用自定义的构造器初始化 &#125; return instantiateBean(beanName, mbd); // 使用无参数的构造函数调用创建对象&#125; 第二次Bean后置处理器的调用，其作用就是指定实例化的构造函数，主要调用的是AutowiredAnnotationBeanPostProcessor后置处理器determineCandidateConstructors方法。 1234567891011121314151617public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Constructor&lt;?&gt;[] determineConstructorsFromBeanPostProcessors(@Nullable Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; if (beanClass != null &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取到容器中所有的后置处理器BeanPostProcessors if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是否为SmartInstantiationAwareBeanPostProcessor SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; // 调用后置处理器的determineCandidateConstructors来决定构造方法 Constructor&lt;?&gt;[] ctors = ibp.determineCandidateConstructors(beanClass, beanName); if (ctors != null) &#123; return ctors; &#125; &#125; &#125; &#125; return null; &#125;&#125; Bean实例化完成后，调用applyMergedBeanDefinitionPostProcessors从而第三次调用Bean的后置处理器，完成@Autowired、@Value、@PostConstruct等注解以及自定义的初始化方法等预解析。调用AutowiredAnnotationBeanPostProcessor将@Autowired、@Value注入信息预解析存入externallyManagedConfigMembers中，调用CommonAnnotationBeanPostProcessor从而调用InitDestroyAnnotationBeanPostProcessor将自定义的初始化方法信息即@Bean(initMethod = &quot;initMethod&quot;)中指定的初始化方法预解析存入externallyManagedInitMethods中。 12345678910public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof MergedBeanDefinitionPostProcessor) &#123; MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp; bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName); &#125; &#125; &#125;&#125; getEarlyBeanReference中是第四次调用Bean的后置处理器，调用实现了SmartInstantiationAwareBeanPostProcessor接口的getEarlyBeanReference方法的后置处理器，这里是调用AbstractAutoProxyCreator后置处理器，主要作用是给有AOP代理的且产生循环依赖的对象创建AOP代理，若该Bean有AOP代理，但不存在循环依赖，则AOP代理是在第八次调用后置处理器时，给该Bean创建动态代理的。若已经设置了动态代理会将beanName加入到earlyProxyReferences集合中，防止重复添加动态代理。 123456789101112131415public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; // 判读容器中是否有InstantiationAwareBeanPostProcessors类型的后置处理器 if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取所有的后置处理器 if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是否实现了SmartInstantiationAwareBeanPostProcessor接口 SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; // 进行强制转换 exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); // 挨个调用SmartInstantiationAwareBeanPostProcessor的getEarlyBeanReference &#125; &#125; &#125; return exposedObject; &#125;&#125; 属性进行赋值前第五次调用后置处理器，Spring自身没有做相应的事情，调用实现了InstantiationAwareBeanPostProcessor接口postProcessAfterInstantiation的后置处理器，其作用是让用户可以自定义属性，其还可以设置跳过后续的赋值操作。 紧接着调用第六次后置处理器，调用实现了InstantiationAwareBeanPostProcessor接口postProcessProperties的后置处理器，主要是注入PropertyValues对属性进行赋值操作，@Autowired、@Value注解是通过AutowiredAnnotationBeanPostProcessor中postProcessProperties方法调用InjectionMetadata.inject方法，若发现@Autowired注入的Bean未被创建，最终会调用DependencyDescriptor的resolveCandidate方法，通过getBean去创建该Bean。若存在循环依赖，给依赖的Bean进行属性赋值时会再次通过getBean调用当前Bean，从而通过getSingleton方法中对三级缓存中函数式接口的调用，即调用getEarlyBeanReference方法将三级缓存转换为二级缓存，返回给依赖的Bean进行赋值操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; // 若bw为null的话，说明对象没有实例化 if (mbd.hasPropertyValues()) &#123; // 进入if说明对象有属性，bw为空，不能为他设置属性，那就在下面就执行抛出异常 throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\"); &#125; else &#123; return; // Skip property population phase for null instance. &#125; &#125; /** * 在属性被填充前，给InstantiationAwareBeanPostProcessor类型的后置处理器一个修改bean状态的机会。官方的解释是：让用户可以自定义属性注入。 * 若用户实现一个InstantiationAwareBeanPostProcessor类型的后置处理器，并通过postProcessAfterInstantiation方法向bean的成员变量注入自定义的信息。 * 当时发现系统中的InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation没有进行任何处理，若自己实现了该接口，可以自定义处理，直接使用配置中的信息注入即可。 */ boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; // 是否持有InstantiationAwareBeanPostProcessor for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取容器中的所有的BeanPostProcessor if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是不是InstantiationAwareBeanPostProcessor InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 进行强制转化 // 若存在后置处理器给属性赋值了，则返回false可来修改开关变量，就不会走下面的逻辑了 if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; // 返回值为是否继续填充bean // postProcessAfterInstantiation：若应该在bean上面设置属性则返回true，否则返回false，一般情况下返回true // 返回false，将会阻止在此Bean实例上调用任何后续的InstantiationAwareBeanPostProcessor continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; if (!continueWithPropertyPopulation) &#123; // 若后续处理器发出停止填充命令，则终止后续操作 return; &#125; PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); // 获取bean定义的属性 // 判断的bean的属性注入模型AUTOWIRE_BY_NAME根据名称注入，AUTOWIRE_BY_TYPE 根据类型注入 if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 把PropertyValues封装成为MutablePropertyValues if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME) &#123; // 根据bean的属性名称注入 autowireByName(beanName, mbd, bw, newPvs); &#125; if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; // 根据bean的类型进行注入 autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; // 把处理过的属性覆盖原来的 &#125; // 用于在Spring填充属性到bean对象前，对属性的值进行相应的处理，可修改某些属性的值。这时注入到bean中的值就不是配置文件中的内容了，而是经过后置处理器修改后的内容 boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); // 判断是否需要检查依赖 boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; // 提出当前正在创建的beanWrapper依赖的对象 PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取所有的后置处理器 if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; pvs = pvsToUse; &#125; &#125; &#125; if (needsDepCheck) &#123; // 判断是否检查依赖 checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; // 上面只是完成了所有注入属性的获取，将获取的属性封装在PropertyValues的实例对象pvs中，并没有应用到已经实例化的bean中，applyPropertyValues则是完成这一步骤的 if (pvs != null) &#123; applyPropertyValues(beanName, mbd, bw, pvs); &#125;&#125; 这里对Bean进行初始化，首先会调用invokeAwareMethods方法从而调用Bean的BeanNameAware、BeanClassLoaderAware、BeanFactoryAware三个Aware接口。 1234567891011121314151617181920212223protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; invokeAwareMethods(beanName, bean); // 若bean实现了XXXAware接口进行方法的回调 &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 调用bean的后置处理器的postProcessorsBeforeInitialization方法，@PostCust注解的方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; invokeInitMethods(beanName, wrappedBean, mbd); // 调用初始化方法 &#125; catch (Throwable ex) &#123; throw new BeanCreationException((mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; // 调用bean的后置处理器的PostProcessorsAfterInitialization方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 第七次Bean的后置处理器调用，通过InitDestroyAnnotationBeanPostProcessor接口中调用LifecycleMetadata.invokeInitMethods方法来实现初始化前@PostConstruct注解的方法的调用，以及调用ApplicationContextAwareProcessor后置处理器的postProcessBeforeInitialization方法，完成EnvironmentAware、EmbeddedValueResolverAware、ResourceLoaderAware、ApplicationEventPublisherAware、MessageSourceAware、ApplicationContextAware、ImportAware等Aware接口的调用。 1234567891011public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) &#123; // 获取容器中的所有的bean的后置处理器 Object current = processor.postProcessBeforeInitialization(result, beanName); // 挨个调用bean的后置处理器的postProcessBeforeInitialization if (current == null) &#123; // 若只有有一个返回null 那么直接返回原始的 return result; &#125; result = current; &#125; return result;&#125; invokeInitMethods方法中若实现了InitializingBean接口，则调用InitializingBean接口的afterPropertiesSet方法，以及自定义的初始化方法的调用即@Bean(initMethod = &quot;initMethod&quot;)中指定的初始化方法。 123456789101112131415161718192021222324252627protected void invokeInitMethods(String beanName, final Object bean, @Nullable RootBeanDefinition mbd) throws Throwable &#123; boolean isInitializingBean = (bean instanceof InitializingBean); // 判断容器中是否实现了InitializingBean接口 if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); &#125; if (System.getSecurityManager() != null) &#123; try &#123; AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; &#123; ((InitializingBean) bean).afterPropertiesSet(); return null; &#125;, getAccessControlContext()); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; // 回调InitializingBean的afterPropertiesSet()方法 ((InitializingBean) bean).afterPropertiesSet(); &#125; &#125; if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) &#123; // 调用initMethod String initMethodName = mbd.getInitMethodName(); // beanclass中是否有自定义的init方法 // 判断自定义的init方法名称不叫afterPropertiesSet if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; invokeCustomInitMethod(beanName, bean, mbd); // 调用自定义的初始化方法 &#125; &#125;&#125; 在applyBeanPostProcessorsAfterInitialization方法中完成了第八次后置处理器的调用，主要是对初始化完成后的Bean进行AOP代理的创建以及ApplicationListener的添加。最终Bean销毁的时候会调用第九次Bean的后置处理器，即调用InitDestroyAnnotationBeanPostProcessor后置处理器的postProcessBeforeDestruction方法。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"Bean生命周期","date":"2021-09-20T16:00:00.000Z","path":"Blog/Spring/Bean的生命周期 - 副本/","text":"生命周期相关内容 Bean的作用域Bean的作用域通过@Scope注解在来指定，Bean的作用域有以下5个： singleton：单例模式，当创建applicationContext容器时，spring会欲初始化所有的该作用域实例，加上lazy-init就可以避免预处理； prototype：原型模式，每次通过getBean获取该bean就会新产生一个实例，创建后spring将不再对其管理； request：每次请求都新产生一个实例，和prototype不同就是创建后，接下来的管理spring依然在监听； session：每次会话都新产生一个实例，和prototype不同就是创建后，接下来的管理spring依然在监听； global session：全局的web域，类似于servlet中的application BeanDefinitionBean后置处理器Bean工厂后置处理器BeanFactory与ApplicationContextBeanFactory与FactoryBean@Import、@Component、@BeanImportBeanDefinitionRegister作用Bean的扩展点","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"IoC容器加载过程","date":"2021-09-18T16:00:00.000Z","path":"Blog/Spring/IoC容器加载过程/","text":"现在用的比较多的注解的方式，这里仅对于注解的容器即AnnotationConfigApplicationContext的加过程的总结。使用时启动一个容器仅一行或几行代码，看着相当简单，但内部做了非常复杂的处理。这里的MainConfig是一个配置类，带上@Configuration注解的配置类是传统意义上的配置类Spring内部称为Full配置类；还有一种是没有带上@Configuration，但是带有@Component，@Import，@ImportResouce，@Service，@ComponentScan等注解的配置类Spring内部称之为Lite配置类。在解析这些配置类时，会给其加上Full或Lite属性。 12345AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class);// 或者通过下面的方式启动容器AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();context.register(MainStarter.class);context.refresh(); 实例化AnnotationConfigApplicationContext容器的时，首先会隐式调用父类GenericApplicationContext的无参构造函数去实例化Bean工厂DefaultListableBeanFactory。然后调用无参构造方法对读取器AnnotatedBeanDefinitionReader和扫描器ClassPathBeanDefinitionScanner进行了实例化，然后通过register注册自己的配置类为BeanDefinition，最后调用refresh()方法。 12345678910111213141516171819202122232425262728293031323334353637public class AnnotationConfigApplicationContext extends GenericApplicationContext implements AnnotationConfigRegistry &#123; // 注解的bean定义读取器 private final AnnotatedBeanDefinitionReader reader; // 类路径下的bean定义扫描器 private final ClassPathBeanDefinitionScanner scanner; public AnnotationConfigApplicationContext() &#123; // 创建一个读取注解的BeanDefinition读取器，完成spring内部BeanDefinition的注册（主要是后置处理器） this.reader = new AnnotatedBeanDefinitionReader(this); /** * 创建BeanDefinition扫描器，可以用来扫描包或者类，继而转换为BeanDefinition * spring默认的扫描包不是该scanner对象，而是在执行工程后置处理器ConfigurationClassPostProcessor时，去扫描包时会new一个ClassPathBeanDefinitionScanner * 这里的scanner仅仅是为了程序员可以手动调用AnnotationConfigApplicationContext对象的scan方法 */ this.scanner = new ClassPathBeanDefinitionScanner(this); &#125; public AnnotationConfigApplicationContext(DefaultListableBeanFactory beanFactory) &#123; super(beanFactory); this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this); &#125; public AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) &#123; this(); // 调用构造函数 register(annotatedClasses); //注册我们的配置类 refresh(); // IOC容器刷新接口 &#125; public AnnotationConfigApplicationContext(String... basePackages) &#123; this(); scan(basePackages); refresh(); &#125;&#125;public class GenericApplicationContext extends AbstractApplicationContext implements BeanDefinitionRegistry &#123; private final DefaultListableBeanFactory beanFactory; public GenericApplicationContext() &#123; this.beanFactory = new DefaultListableBeanFactory(); &#125;&#125; 实例化DefaultListableBeanFactory工厂DefaultListableBeanFactory是最底层的实现，其中定义很多重要的属性，在后续的容器加载过程会频繁用到： 123456789101112131415161718192021222324252627282930313233public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; /** Map from serialized id to factory instance */ private static final Map&lt;String, Reference&lt;DefaultListableBeanFactory&gt;&gt; serializableFactories = new ConcurrentHashMap&lt;&gt;(8); /** Optional id for this factory, for serialization purposes */ @Nullable private String serializationId; /** Whether to allow re-registration of a different definition with the same name */ private boolean allowBeanDefinitionOverriding = true; /** Whether to allow eager class loading even for lazy-init beans */ private boolean allowEagerClassLoading = true; /** Optional OrderComparator for dependency Lists and arrays */ @Nullable private Comparator&lt;Object&gt; dependencyComparator; /** Resolver to use for checking if a bean definition is an autowire candidate */ private AutowireCandidateResolver autowireCandidateResolver = new SimpleAutowireCandidateResolver(); /** Map from dependency type to corresponding autowired value */ private final Map&lt;Class&lt;?&gt;, Object&gt; resolvableDependencies = new ConcurrentHashMap&lt;&gt;(16); /** 用于保存原始的bean定义信息(没有被mearged) */ private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); /** Map of singleton and non-singleton bean names, keyed by dependency type */ private final Map&lt;Class&lt;?&gt;, String[]&gt; allBeanNamesByType = new ConcurrentHashMap&lt;&gt;(64); /** Map of singleton-only bean names, keyed by dependency type */ private final Map&lt;Class&lt;?&gt;, String[]&gt; singletonBeanNamesByType = new ConcurrentHashMap&lt;&gt;(64); /** List of bean definition names, in registration order */ private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;&gt;(256); /** List of names of manually registered singletons, in registration order */ private volatile Set&lt;String&gt; manualSingletonNames = new LinkedHashSet&lt;&gt;(16); /** Cached array of bean definition names in case of frozen configuration */ @Nullable private volatile String[] frozenBeanDefinitionNames; /** Whether bean definition metadata may be cached for all beans */ private volatile boolean configurationFrozen = false;&#125; 实例化BeanDefinition读取器AnnotatedBeanDefinitionReader主要是注册内置的BeanPostProcessor以及注册相关的BeanDefinition，主要是注册系统内部的一些基础的配置类如：解析配置类的后置处理器ConfigurationClassPostProcessor、处理@Autowired注解的处理器AutowiredAnnotationBeanPostProcessor、处理@Required属性的注解处理器RequiredAnnotationBeanPostProcessor、处理JSR规范的注解处理器CommonAnnotationBeanPostProcessor、处理jpa注解的处理器PersistenceAnnotationBeanPostProcessor、处理监听方法的注解@EventListener解析器EventListenerMethodProcessor、注册事件监听器工厂DefaultEventListenerFactory。 ConfigurationClassPostProcessor是最重要的Bean其实现了BeanDefinitionRegistryPostProcessor和BeanFactoryPostProcessor接口，其作用分别为注册BeanDefinition和修改BeanDefinition，BeanFactoryPostProcessor是Spring扩展点之一。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class AnnotatedBeanDefinitionReader &#123; private final BeanDefinitionRegistry registry; private BeanNameGenerator beanNameGenerator = new AnnotationBeanNameGenerator(); private ScopeMetadataResolver scopeMetadataResolver = new AnnotationScopeMetadataResolver(); private ConditionEvaluator conditionEvaluator; public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; this(registry, getOrCreateEnvironment(registry)); &#125; public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry, Environment environment) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); Assert.notNull(environment, \"Environment must not be null\"); // 把ApplicationContext对象赋值给AnnotatedBeanDefinitionReader this.registry = registry; // 用户处理条件注解 @Conditional os.name this.conditionEvaluator = new ConditionEvaluator(registry, environment, null); // 注册一些内置的后置处理器 AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125;&#125;public class AnnotationConfigUtils &#123; public static void registerAnnotationConfigProcessors(BeanDefinitionRegistry registry) &#123; registerAnnotationConfigProcessors(registry, null); &#125; public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, @Nullable Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; //注册了实现Order接口的排序器 beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; //设置@AutoWired的候选的解析器：ContextAnnotationAutowireCandidateResolver // getLazyResolutionProxyIfNecessary方法，它也是唯一实现。 //如果字段上带有@Lazy注解，表示进行懒加载 Spring不会立即创建注入属性的实例，而是生成代理对象，来代替实例 if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8); // 为我们容器中注册了解析配置类的后置处理器ConfigurationClassPostProcessor:org.springframework.context.annotation.internalConfigurationAnnotationProcessor if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 为容器中注册了处理@Autowired 注解的处理器AutowiredAnnotationBeanPostProcessor:org.springframework.context.annotation.internalAutowiredAnnotationProcessor if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 为容器中注册处理@Required属性的注解处理器RequiredAnnotationBeanPostProcessor:org.springframework.context.annotation.internalRequiredAnnotationProcessor if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 为我们容器注册处理JSR规范的注解处理器CommonAnnotationBeanPostProcessor：org.springframework.context.annotation.internalCommonAnnotationProcessor if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 处理jpa注解的处理器org.springframework.orm.jpa.support.PersistenceAnnotationBeanPostProcessor if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, AnnotationConfigUtils.class.getClassLoader())); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException(\"Cannot load optional framework class: \" + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 处理监听方法的注解@EventListener解析器EventListenerMethodProcessor if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME)); &#125; // 注册事件监听器工厂 if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME)); &#125; return beanDefs; &#125;&#125; 最终是通过registerPostProcessor注册这些BeanDefinition，最终是调用的DefaultListableBeanFactory的registerBeanDefinition将这些BeanDefinition放入保存原始的BeanDefinition信息的beanDefinitionMap及beanDefinitionNames中。这里仅仅是注册，并没有对这些Bean实例化。 创建BeanDefinition扫描器常规使用方式是不会用到AnnotationConfigApplicationContext中的scanner的，这里的scanner仅仅是为了手动调用AnnotationConfigApplicationContext对象的scan方法。 register注册自定义配置类register传入的是一个数组，最终会循环调用doRegisterBean注册传入的配置到DefaultListableBeanFactory中的beanDefinitionMap和beanDefinitionNames中。注意这里是使用AnnotatedGenericBeanDefinition来获得配置类的BeanDefinition而前面注册系统内部的一些基础的配置类时是通过RootBeanDefinition来获得配置类BeanDefinition的。 12345678910111213141516171819202122232425262728293031323334353637&lt;T&gt; void doRegisterBean(Class&lt;T&gt; annotatedClass, @Nullable Supplier&lt;T&gt; instanceSupplier, @Nullable String name, @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) &#123; //存储@Configuration注解注释的类 AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(annotatedClass); //判断是否需要跳过注解，spring中有一个@Condition注解，当不满足条件，这个bean就不会被解析 if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) &#123; return; &#125; abd.setInstanceSupplier(instanceSupplier); //解析bean的作用域和scopedProxyMode，如果没有设置的话，默认为单例，默认scopedProxyMode=ScopedProxyMode.NO ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); abd.setScope(scopeMetadata.getScopeName()); //获得beanName String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry)); //解析通用注解，填充到AnnotatedGenericBeanDefinition，解析的注解为Lazy，Primary，DependsOn，Role，Description AnnotationConfigUtils.processCommonDefinitionAnnotations(abd); if (qualifiers != null) &#123; for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) &#123; if (Primary.class == qualifier) &#123; abd.setPrimary(true); &#125; else if (Lazy.class == qualifier) &#123; abd.setLazyInit(true); &#125; else &#123; abd.addQualifier(new AutowireCandidateQualifier(qualifier)); &#125; &#125; &#125; for (BeanDefinitionCustomizer customizer : definitionCustomizers) &#123; customizer.customize(abd); &#125; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); //注册，最终会调用DefaultListableBeanFactory中的registerBeanDefinition方法去注册， DefaultListableBeanFactory维护着一系列信息，比如beanDefinitionNames，beanDefinitionMap //beanDefinitionNames是一个List&lt;String&gt;,用来保存beanName，beanDefinitionMap是一个Map,用来保存beanName和beanDefinition BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);&#125; refresh刷新容器到这里Spring还没有进行扫描，只是实例化了一个工厂，注册了一些内置的Bean和我们传进去的配置类。refresh是一个模板方法。 123456789101112131415161718192021222324252627282930public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; prepareRefresh(); // 刷新预处理，和主流程关系不大，就是保存了容器的启动时间，启动标志等 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 获取告诉子类初始化Bean工厂，不同工厂不同实现 prepareBeanFactory(beanFactory); // 对bean工厂进行填充属性，添加了两个后置处理器：ApplicationContextAwareProcessor，ApplicationListenerDetector，还设置了忽略自动装配和允许自动装配的接口，若不存在某个bean的时候，spring就自动注册singleton bean，还设置了bean表达式解析器等 try &#123; postProcessBeanFactory(beanFactory); // 留个子类去实现该接口 invokeBeanFactoryPostProcessors(beanFactory); // 调用我们的bean工厂的后置处理器，会在此将class扫描成beanDefinition，bean工厂的后置处理器调用 registerBeanPostProcessors(beanFactory); // 注册bean的后置处理器 initMessageSource(); // 初始化国际化资源处理器 initApplicationEventMulticaster();// 创建事件多播器 onRefresh();// 该方法同样也是留给子类实现的，springboot也是从该方法进行启动tomcat的 registerListeners(); // 把事件监听器注册到多播器上 finishBeanFactoryInitialization(beanFactory); // 实例化我们剩余的单实例bean finishRefresh(); // 最后容器刷新 发布刷新事件(Spring cloud也是从这里启动的) &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); cancelRefresh(ex); throw ex; &#125; finally &#123; resetCommonCaches(); &#125; &#125; &#125;&#125; prepareRefresh主要做了一些刷新前的准备工作，和主流程关系不大，主要是保存了容器的启动时间，启动标志等； 123456789101112131415161718192021222324protected void prepareRefresh() &#123; this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); /** * 相传该方法在网上很多人说该方法没有用,因为这个方法是留个子类实现的,由于是对spring源码的核心 设计理念没有弄清楚,正式由于spring提供了大量的可扩展的接口提供给我们自己来实现 * 比如我们自己写一个类重写了initPropertySources方法，在该方法中设置了一个环境变量的值为A 启动的时候，我的环境变量中没有该值就会启动抛出异常 */ initPropertySources(); // 用来校验我们容器启动必须依赖的环境变量的值 getEnvironment().validateRequiredProperties(); // 创建一个早期事件监听器对象 if (this.earlyApplicationListeners == null) &#123; this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); &#125; else &#123; this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); &#125; /** * 创建一个容器用于保存早期待发布的事件集合，就是我们的事件监听器还没有注册到多播器上的时候都称为早期事件 * 早期事件不需要手动publishEvent发布， 在registerListeners中会自动发布， 发布完早期事件就不存在了。 */ this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;();&#125; obtainFreshBeanFactory和主流程关系也不是很大，可简单认为就是把beanFactory取出来而已，XML模式下会在这里读取BeanDefinition； 1234567protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; // xml加载spring会在这里加载beanDefinition，javaconfig只是刷新了beanFactory refreshBeanFactory(); //返回我们的bean工厂 ConfigurableListableBeanFactory beanFactory = getBeanFactory(); return beanFactory;&#125; prepareBeanFactory做一些准备工作主要是为Bean工厂填充内部属性，添加了ApplicationContextAwareProcessor和ApplicationListenerDetector后置处理器，还设置了忽略自动装配和允许自动装配的接口，若不存在某个Bean时，Spring则自动注册Singleton Bean，还设置了bean表达式解析器等； 1234567891011121314151617181920212223242526272829303132333435363738394041protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; //设置bean工厂的类加载器为当前application应用的加载器 beanFactory.setBeanClassLoader(getClassLoader()); //为bean工厂设置我们标准的SPEL表达式解析器对象StandardBeanExpressionResolver beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); //为我们的bean工厂设置了一个propertityEditor 属性资源编辑器对象(用于后面的给bean对象赋值使用) beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 注册了一个完整的ApplicationContextAwareProcessor 后置处理器用来处理ApplicationContextAware接口的回调方法 beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 忽略以下接口的bean的接口函数方法，在populateBean时以下接口都有setXXX方法，这些方法不特殊处理将会自动注入容器中的bean beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); /** * 当注册了依赖解析后，例如当注册了对BeanFactory.class的解析依赖后，，当bean的属性注入时，一旦检测到属性为BeanFactory 类型便会将beanFactory的实例注入进去。 * 知道为什么可以@Autowired， ApplicationContext applicationContext 就是因为这里设置了 */ beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // 注册了一个事件监听器探测器后置处理器接口 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; // 处理aspectj的 beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // 注册了bean工厂的内部的bean if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; // 环境 beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; //环境系统属性 beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; //系统环境 beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125;&#125; postProcessBeanFactory一个空方法留给子类去实现该接口。 invokeBeanFactoryPostProcessors是目前为止最重要的方法，会在此将Class扫描成BeanDefinition以及Bean工厂后置处理器调用对IoC容器加载BeanDefinition前后进行处理。 123456789protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; // 参数分别是当前Bean工厂，自己调用annotationConfigApplicationContext.addBeanFactoryPostProcessor添加的 PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125;&#125; BeanDefinitionRegistryPostProcessor是BeanDefinition解析前调用，执行的顺序依次是：实现了PriorityOrdered接口的，实现了Ordered接口的，没有实现任何的优先级接口的，BeanDefinitionRegistryPostProcessor是BeanFactoryPostProcessor的子接口。 BeanFactoryPostProcessor是BeanDefinition解析后调用，其执行顺序和BeanDefinitionRegistryPostProcessor是一样的。但是Bean实例还没有被初始化。 很明显当前的beanFactory即AnnotationConfigApplicationContext从前面的类结构图可知明显是BeanDefinitionRegistry的实例，这里一般情况beanFactoryPostProcessors是空的。processedBeans变量是用于将已经处理过的后置处理器过滤掉，防止重复执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134public static void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;(); // 定义已处理的后置处理器 // 判断beanFactory是否实现了BeanDefinitionRegistry，实现了该结构就有注册和获取Bean定义的能力 if (beanFactory instanceof BeanDefinitionRegistry) &#123; //强行把我们的bean工厂转为BeanDefinitionRegistry，因为待会需要注册Bean定义 BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; //保存BeanFactoryPostProcessor类型的后置，BeanFactoryPostProcessor提供修改 List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); //保存BeanDefinitionRegistryPostProcessor类型的后置处理器，BeanDefinitionRegistryPostProcessor提供注册 List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); //循环我们传递进来的beanFactoryPostProcessors for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; // 判断后置处理器是不是BeanDefinitionRegistryPostProcessor if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; // 进行强制转化 BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; // 调用其作为BeanDefinitionRegistryPostProcessor的处理器的后置方法 registryProcessor.postProcessBeanDefinitionRegistry(registry); // 添加到我们用于保存的BeanDefinitionRegistryPostProcessor的集合中 registryProcessors.add(registryProcessor); &#125; else &#123; // 若没实现BeanDefinitionRegistryPostProcessor接口，其就是BeanFactoryPostProcessor其加入到regularPostProcessors中 regularPostProcessors.add(postProcessor); &#125; &#125; // 定义一个集合用户保存当前准备创建的BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;(); // 第一步：去当前容器中获取BeanDefinitionRegistryPostProcessor的bean的处理器名称 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); // 循环筛选出来的匹配BeanDefinitionRegistryPostProcessor的类型名称 for (String ppName : postProcessorNames) &#123; // 判断是否实现了PriorityOrdered接口的 if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; // 显示的调用getBean()的方式获取出该对象然后加入到currentRegistryProcessors集合中去，即实例化 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); // 同时也加入到processedBeans集合中去 processedBeans.add(ppName); &#125; &#125; // 对currentRegistryProcessors集合中BeanDefinitionRegistryPostProcessor进行排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 把当前的加入到总的里面去，因为一开始spring只会执行BeanDefinitionRegistryPostProcessor独有的方法，而不会执行BeanDefinitionRegistryPostProcessor父类的方法 // 即BeanFactoryProcessor接口中的方法，所以需要把这些后置处理器放入一个集合中，后续统一执行BeanFactoryProcessor接口中的方法 registryProcessors.addAll(currentRegistryProcessors); // 在这里典型的BeanDefinitionRegistryPostProcessor就是ConfigurationClassPostProcessor，用于进行bean定义的加载，如包扫描，@import等等 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // 调用完之后，马上clear掉 // 去容器中获取BeanDefinitionRegistryPostProcessor的bean的处理器名称（内置的和上面注册的） postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); // 循环上一步获取的BeanDefinitionRegistryPostProcessor的类型名称 for (String ppName : postProcessorNames) &#123; // 表示没有被处理过，且实现了Ordered接口的 if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // 显示的调用getBean()的方式获取出该对象然后加入到currentRegistryProcessors集合中去 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); // 同时也加入到processedBeans集合中去 processedBeans.add(ppName); &#125; &#125; // 对currentRegistryProcessors集合中BeanDefinitionRegistryPostProcessor进行排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 把他加入到用于保存到registryProcessors中 registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); // 调用他的后置处理方法 currentRegistryProcessors.clear(); // 调用完之后，马上clear掉 // 调用没有实现任何优先级接口的BeanDefinitionRegistryPostProcessor，定义一个重复处理的开关变量 默认值为true boolean reiterate = true; while (reiterate) &#123; // 第一次就可以进来 reiterate = false; // 进入循环马上把开关变量给改为false // 去容器中获取BeanDefinitionRegistryPostProcessor的bean的处理器名称 postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; // 循环上一步获取的BeanDefinitionRegistryPostProcessor的类型名称 if (!processedBeans.contains(ppName)) &#123; //没有被处理过的 //显示的调用getBean()的方式获取出该对象然后加入到currentRegistryProcessors集合中去 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); // 同时也加入到processedBeans集合中去 reiterate = true; //再次设置为true &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // 调用完之后，马上clear掉 &#125; // 调用BeanDefinitionRegistryPostProcessor.postProcessBeanFactory方法 invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); // 调用BeanFactoryPostProcessor自设的 invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // 若当前的beanFactory没有实现BeanDefinitionRegistry说明没有注册Bean定义的能力 // 则直接调用BeanDefinitionRegistryPostProcessor.postProcessBeanFactory方法 invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; // 上面是所有BeanDefinitionRegistryPostProcessor调用完毕，接下来处理BeanFactoryPostProcessor //获取容器中所有的 BeanFactoryPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // 保存BeanFactoryPostProcessor类型实现了priorityOrdered List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); // 保存BeanFactoryPostProcessor类型实现了Ordered接口的 List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); // 保存BeanFactoryPostProcessor没有实现任何优先级接口的 List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; // processedBeans包含的话，表示在上面处理BeanDefinitionRegistryPostProcessor的时候处理过了 if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; // 判断是否实现了PriorityOrdered 优先级最高 priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // 判断是否实现了Ordered 优先级其次 orderedPostProcessorNames.add(ppName); &#125; else &#123; // 没有实现任何的优先级接口的 最后调用 nonOrderedPostProcessorNames.add(ppName); &#125; &#125; sortPostProcessors(priorityOrderedPostProcessors, beanFactory); // 排序 // 先调用BeanFactoryPostProcessor实现了PriorityOrdered接口的 invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // 再调用BeanFactoryPostProcessor实现了Ordered接口的 List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // 调用没有实现任何方法接口的 List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); beanFactory.clearMetadataCache();&#125; invokeBeanDefinitionRegistryPostProcessors执行了三次，执行currentRegistryProcessors变量中装载的BeanDefinitionRegistryPostProcessor，第一次执行currentRegistryProcessors中只有解析配置类的后置处理器ConfigurationClassPostProcessor，这里调用的beanFactory.getBean，将会解析出系统中通过配置类配置的扫描包，扫描出所有Bean，第二次执行currentRegistryProcessors为空，为空的前提是扫描出的Bean中无BeanDefinitionRegistryPostProcessor，第三次执行和第二次执行一样。如下所示若定义一个自定义的BeanDefinitionRegistryPostProcessor，由于这里没有实现PriorityOrdered和Ordered接口，则第三次执行时会执行该BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry方法。 12345678910111213@Componentpublic class MyBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; RootBeanDefinition car = (RootBeanDefinition) beanFactory.getBeanDefinition(\"car\"); &#125; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(Tank.class); registry.registerBeanDefinition(\"car\", beanDefinition); &#125;&#125; 当BeanDefinitionRegistryPostProcessor处理完毕后会将其与registryProcessors合并，因为一开始只会执行BeanDefinitionRegistryPostProcessor独有方法，不会执行其父类方法，即BeanFactoryProcessor接口中的方法，故需要把这些后置处理器放入一个集合中，后续统一执行BeanFactoryProcessor接口中的方法。 可理解为执行currentRegistryProcessors中的ConfigurationClassPostProcessor中的postProcessBeanDefinitionRegistry方法，这就是Spring设计思想的体现了，在这里体现的就是其中的热插拔，插件化开发的思想。Spring中很多东西都是交给插件去处理的，该后置处理器就相当于一个插件。 当通过invokeBeanDefinitionRegistryPostProcessors方法执行过ConfigurationClassPostProcessor后，后续就能获取到项目中自定义的打上@Component注解的后置处理器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private static void invokeBeanFactoryPostProcessors(Collection&lt;? extends BeanFactoryPostProcessor&gt; postProcessors, ConfigurableListableBeanFactory beanFactory) &#123; for (BeanFactoryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanFactory(beanFactory); &#125;&#125;public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware &#123; public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; int factoryId = System.identityHashCode(beanFactory); if (this.factoriesPostProcessed.contains(factoryId)) &#123; throw new IllegalStateException( \"postProcessBeanFactory already called on this post-processor against \" + beanFactory); &#125; this.factoriesPostProcessed.add(factoryId); if (!this.registriesPostProcessed.contains(factoryId)) &#123; processConfigBeanDefinitions((BeanDefinitionRegistry) beanFactory); &#125; // 使用cglib对配置类进行代理，因为@Bean方法到时候要进行创建Bean的实例 enhanceConfigurationClasses(beanFactory); beanFactory.addBeanPostProcessor(new ImportAwareBeanPostProcessor(beanFactory)); &#125; public void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) &#123; Map&lt;String, AbstractBeanDefinition&gt; configBeanDefs = new LinkedHashMap&lt;&gt;(); for (String beanName : beanFactory.getBeanDefinitionNames()) &#123; BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName); // 只有full版配置类才会创建cglib代理 if (ConfigurationClassUtils.isFullConfigurationClass(beanDef)) &#123; if (!(beanDef instanceof AbstractBeanDefinition)) &#123; throw new BeanDefinitionStoreException(\"Cannot enhance @Configuration bean definition '\" + beanName + \"' since it is not stored in an AbstractBeanDefinition subclass\"); &#125; configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef); &#125; &#125; if (configBeanDefs.isEmpty()) &#123; return; // nothing to enhance -&gt; return immediately &#125; ConfigurationClassEnhancer enhancer = new ConfigurationClassEnhancer(); for (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : configBeanDefs.entrySet()) &#123; AbstractBeanDefinition beanDef = entry.getValue(); // If a @Configuration class gets proxied, always proxy the target class beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE); try &#123; // Set enhanced subclass of the user-specified bean class Class&lt;?&gt; configClass = beanDef.resolveBeanClass(this.beanClassLoader); if (configClass != null) &#123; Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, this.beanClassLoader); if (configClass != enhancedClass) &#123; // 重新修改Bean定义的Class，在创建Bean的实例时将会实例cglib的类 beanDef.setBeanClass(enhancedClass); &#125; &#125; &#125; catch (Throwable ex) &#123; &#125; &#125; &#125;&#125; 只有full版配置类才会创建cglib代理，虽然在指定配置时不标注@Configuration也行，所以加不加注解的区别就在这里，当在配置类中一个@Bean使用方法的方式引用另一个Bean若不加注解就会重复加载Bean，若加了@Configuration则会在这里创建cglib代理，当调用@Bean方法时会先检测容器中是否存在。 1234567@Componentpublic class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println(\"MyBeanFactoryPostProcessorNew\"); &#125;&#125; 同样invokeBeanFactoryPostProcessors方法会执行自定义的BeanFactoryPostProcessor的postProcessBeanFactory方法。 registerBeanPostProcessors给容器中注册bean的后置处理器，bean的后置处理器在bean的各个生命周期中都会进行调用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);&#125;public static void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; // 去容器中获取所有的BeanPostProcessor 的名称(还是bean定义) String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // 之前refresh--&gt;prepareBeanFactory()中注册的postProcessorNames.length // bean后置处理器个数beanFactory.getBeanPostProcessorCount()成品个数 beanFactory工厂中bean定义的个数+1在后面又马上注册了BeanPostProcessorChecker的后置处理器 int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); //按照BeanPostProcessor实现的优先级接口来分离我们的后置处理器 List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();// 保存实现了priorityOrdered接口的 List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); // 系统内部的 List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); // 实现了ordered接口的 List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); // 没有优先级的 for (String ppName : postProcessorNames) &#123; // 循环bean定义(BeanPostProcessor) if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; //若实现了PriorityOrdered接口的 BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); // 显示的调用getBean流程创建bean的后置处理器 priorityOrderedPostProcessors.add(pp); // 加入到集合中 if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; // 判断是否实现了MergedBeanDefinitionPostProcessor internalPostProcessors.add(pp); // 加入到集合中 &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // 判断是否实现了Ordered orderedPostProcessorNames.add(ppName); &#125; else &#123; // 没有任何拍下接口的 nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // 把实现了priorityOrdered注册到容器中 sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // 处理实现Ordered的bean定义 List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); //显示调用getBean方法 orderedPostProcessors.add(pp); //加入到集合中 if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; //判断是否实现了MergedBeanDefinitionPostProcessor internalPostProcessors.add(pp); //加入到集合中 &#125; &#125; //排序并且注册我们实现了Order接口的后置处理器 sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; //注册我们普通的没有实现任何排序接口的 registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); //注册MergedBeanDefinitionPostProcessor类型的后置处理器bean合并后的处理，Autowired注解正是通过此方法实现诸如类型的预解析。 sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); //注册ApplicationListenerDetector 应用监听器探测器的后置处理器 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"BeanDefinition解析注册","date":"2021-09-18T16:00:00.000Z","path":"Blog/Spring/BeanDefinition解析注册/","text":"自定义的Bean解析与注册是通过refresh()中invokeBeanFactoryPostProcessors()方法最终调用PostProcessorRegistrationDelegate的invokeBeanFactoryPostProcessors方法，通过invokeBeanDefinitionRegistryPostProcessors调用ConfigurationClassPostProcessor的postProcessBeanDefinitionRegistry方法，对项目的包扫描，然后将所有的Bean解析成BeanDefinition然后注册到IoC容器中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104private static void invokeBeanDefinitionRegistryPostProcessors(Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, BeanDefinitionRegistry registry) &#123; // 获取容器中ConfigurationClassPostProcessor后置处理器进行bean定义的扫描 for (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanDefinitionRegistry(registry); &#125;&#125;public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; int registryId = System.identityHashCode(registry); if (this.registriesPostProcessed.contains(registryId)) &#123; throw new IllegalStateException(\"postProcessBeanDefinitionRegistry already called on this post-processor against \" + registry); &#125; if (this.factoriesPostProcessed.contains(registryId)) &#123; throw new IllegalStateException(\"postProcessBeanFactory already called on this post-processor against \" + registry); &#125; this.registriesPostProcessed.add(registryId); processConfigBeanDefinitions(registry); // 真正的解析BeanDefinition&#125;public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); // 获取IOC容器中目前所有BeanDefinition名称，仅包括之前内置的Bean和传入的配置类 String[] candidateNames = registry.getBeanDefinitionNames(); for (String beanName : candidateNames) &#123; // 循环我们的上一步获取的所有BeanDefinition信息 BeanDefinition beanDef = registry.getBeanDefinition(beanName); // 通过bean的名称来获取我们的bean定义对象 // 判断是否有没有解析过 if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123; &#125; else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; // 进行正在的解析判断是不是完全的配置类，还是一个非正式的配置类，这里是有我们传入的配置类MainConfig进入到改else中 configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); // 加入到候选的配置类集合中 &#125; &#125; if (configCandidates.isEmpty()) &#123; // 若没有找到配置类 直接返回 return; &#125; configCandidates.sort((bd1, bd2) -&gt; &#123; // 对配置类进行Order排序 int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return Integer.compare(i1, i2); &#125;); // 创建通过@CompentScan导入进来的bean name的生成器，创建通过@Import导入进来的bean的名称 SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) &#123; BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) &#123; // 设置@CompentScan导入进来的bean的名称生成器(默认类首字母小写）也可自己定义，一般不会 this.componentScanBeanNameGenerator = generator; // 设置@Import导入进来的bean的名称生成器(默认类首字母小写）也可自己定义，一般不会 this.importBeanNameGenerator = generator; &#125; &#125; &#125; if (this.environment == null) &#123; this.environment = new StandardEnvironment(); &#125; //创建一个配置类解析器对象 ConfigurationClassParser parser = new ConfigurationClassParser(this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); // 用于保存配置类BeanDefinitionHolder放入上面筛选出来的配置类 Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); // 用于保存已解析的配置类，长度默认为解析出来默认的配置类的集合长度 Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; //do while 会进行第一次解析 parser.parse(candidates); //真正的解析我们的配置类 parser.validate(); // 解析出来的配置类 Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); configClasses.removeAll(alreadyParsed); // Read the model and create bean definitions based on its content if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader(registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; // 此处才把@Bean的方法和@Import 注册到BeanDefinitionMap中 this.reader.loadBeanDefinitions(configClasses); alreadyParsed.addAll(configClasses); // 加入到已经解析的集合中 candidates.clear(); // 判断ioc容器中的BeanDefinition是否大于候选原始的BeanDefinition个数 if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123; String[] newCandidateNames = registry.getBeanDefinitionNames(); // 获取所有的bean定义 Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames)); //原始候选bean定义 Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) &#123; // 赋值已经解析的 alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); &#125; for (String candidateName : newCandidateNames) &#123; if (!oldCandidateNames.contains(candidateName)) &#123; // 表示当前循环的还没有被解析过 BeanDefinition bd = registry.getBeanDefinition(candidateName); // 判断有没有被解析过，则放入candidates集合，进行新一轮解析 if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp; !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123; candidates.add(new BeanDefinitionHolder(bd, candidateName)); &#125; &#125; &#125; candidateNames = newCandidateNames; &#125; &#125; while (!candidates.isEmpty()); //存在没有解析过的 需要循环解析 // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123; sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry()); &#125; if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123; // Clear cache in externally provided MetadataReaderFactory; this is a no-op for a shared cache since it'll be cleared by the ApplicationContext. ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); &#125;&#125; this.reader.loadBeanDefinitions(configClasses)这里才把@Bean方法和@Import注解中的类注册到BeanDefinitionMap中，典型的是对AOP的支持将AspectJAutoProxyRegistrar注册到BeanDefinitionMap中。 1234567891011121314151617181920212223242526public void loadBeanDefinitions(Set&lt;ConfigurationClass&gt; configurationModel) &#123; TrackedConditionEvaluator trackedConditionEvaluator = new TrackedConditionEvaluator(); for (ConfigurationClass configClass : configurationModel) &#123; // 注册配置类到容器中 loadBeanDefinitionsForConfigurationClass(configClass, trackedConditionEvaluator); &#125;&#125;private void loadBeanDefinitionsForConfigurationClass(ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123; if (trackedConditionEvaluator.shouldSkip(configClass)) &#123; String beanName = configClass.getBeanName(); if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) &#123; this.registry.removeBeanDefinition(beanName); &#125; this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName()); return; &#125; if (configClass.isImported()) &#123; // 通过@Import导入进来的配置类的处理即@Configuration注解的类 registerBeanDefinitionForImportedConfigurationClass(configClass); &#125; for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123; // 通过@bean导入进来的组件 loadBeanDefinitionsForBeanMethod(beanMethod); &#125; // 通过@ImportResources导入进来 loadBeanDefinitionsFromImportedResources(configClass.getImportedResources()); // 通过ImportBeanDefinitionRegistrar注解导入进来 loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());&#125; 上面通过ConfigurationClassUtils工具类对注册的Bean进行标记，标记配置类是属于Full配置类，还是Lite配置类，当注册配置类时，若加了@Configuration注解，就称之为Full配置类，若直接使用@Component、@ComponentScan、@Import、@ImportResource等注解，Spring把这种配置类称之为Lite配置类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061abstract class ConfigurationClassUtils &#123; private static final String CONFIGURATION_CLASS_FULL = \"full\"; private static final String CONFIGURATION_CLASS_LITE = \"lite\"; private static final Set&lt;String&gt; candidateIndicators = new HashSet&lt;&gt;(8); static &#123; candidateIndicators.add(Component.class.getName()); candidateIndicators.add(ComponentScan.class.getName()); candidateIndicators.add(Import.class.getName()); candidateIndicators.add(ImportResource.class.getName()); &#125; // 该方法通过传入的bean定义字段来判断当前bean是完全的配置类(标注了@Configuration注解) public static boolean isFullConfigurationClass(BeanDefinition beanDef) &#123; /** * 最终会通过方法checkConfigurationClassCandidate来设置CONFIGURATION_CLASS_ATTRIBUTE的属性是完全的配置类还是非正式的配置类 * 第一次进来的时候逻辑CONFIGURATION_CLASS_ATTRIBUTE属性CONFIGURATION_CLASS_ATTRIBUTE是为Null的 */ return CONFIGURATION_CLASS_FULL.equals(beanDef.getAttribute(CONFIGURATION_CLASS_ATTRIBUTE)); &#125; // 该方法通过传入bean定义的字段来判断当前bean是非正式的配置类(没有标注了@Configuration注解,但该类配置了@Bean的配置类) public static boolean isLiteConfigurationClass(BeanDefinition beanDef) &#123; return CONFIGURATION_CLASS_LITE.equals(beanDef.getAttribute(CONFIGURATION_CLASS_ATTRIBUTE)); &#125; public static boolean checkConfigurationClassCandidate(BeanDefinition beanDef, MetadataReaderFactory metadataReaderFactory) &#123; String className = beanDef.getBeanClassName(); if (className == null || beanDef.getFactoryMethodName() != null) &#123; return false; &#125; AnnotationMetadata metadata; if (beanDef instanceof AnnotatedBeanDefinition &amp;&amp; className.equals(((AnnotatedBeanDefinition) beanDef).getMetadata().getClassName())) &#123; metadata = ((AnnotatedBeanDefinition) beanDef).getMetadata(); &#125; else if (beanDef instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) beanDef).hasBeanClass()) &#123; Class&lt;?&gt; beanClass = ((AbstractBeanDefinition) beanDef).getBeanClass(); metadata = new StandardAnnotationMetadata(beanClass, true); &#125; else &#123; try &#123; MetadataReader metadataReader = metadataReaderFactory.getMetadataReader(className); metadata = metadataReader.getAnnotationMetadata(); &#125; catch (IOException ex) &#123; return false; &#125; &#125; // 判断是不是真正的配置类 就是判断当前的bean的class上有没有标注了@Configuration注解 if (isFullConfigurationCandidate(metadata)) &#123; // 设置标记 beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_FULL); &#125; // 这里判断该配置类是一个非正式的配置类(Component ComponentScan Import ImportResource) else if (isLiteConfigurationCandidate(metadata)) &#123; beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_LITE); &#125; else &#123; return false; &#125; //解析配置类上是否标注了@Order注解 Integer order = getOrder(metadata); if (order != null) &#123; beanDef.setAttribute(ORDER_ATTRIBUTE, order); &#125; return true; &#125;&#125; Full配置类在getBean创建时会被被CGLib代理，而Lite配置类getBean创建时不会被代理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110class ConfigurationClassParser &#123; // 具体的解析过程 public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; // 用于保存延时的ImportSelectors，最著名的代表SpringBoot自动装配的的类AutoConfigurationImportSelector this.deferredImportSelectors = new LinkedList&lt;&gt;(); for (BeanDefinitionHolder holder : configCandidates) &#123; // 循环配置类 BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; // 真正的解析bean定义，通过注解元数据解析 parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(\"Failed to parse configuration class [\" + bd.getBeanClassName() + \"]\", ex); &#125; &#125; // 处理延时的DeferredImportSelectors，springboot就是通过这进行记载spring.factories文件中的自定装配的对象 processDeferredImportSelectors(); &#125; // 第一步：把配置类源信息和beanName包装成一个ConfigurationClass对象 protected final void parse(AnnotationMetadata metadata, String beanName) throws IOException &#123; processConfigurationClass(new ConfigurationClass(metadata, beanName)); &#125; protected void processConfigurationClass(ConfigurationClass configClass) throws IOException &#123; if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123; return; &#125; //获取处我们的配置类对象 ConfigurationClass existingClass = this.configurationClasses.get(configClass); if (existingClass != null) &#123; if (configClass.isImported()) &#123; // 传入进来的配置类是通过其他配置类的Import导入进来的 if (existingClass.isImported()) &#123; // 需要合并配置 existingClass.mergeImportedBy(configClass); &#125; return; // 故若通过@Import导入一个已存在的配置类 是不允许的，会忽略。 &#125; else &#123; this.configurationClasses.remove(configClass); this.knownSuperclasses.values().removeIf(configClass::equals); &#125; &#125; // 递归处理配置类及其超类层次结构。 SourceClass sourceClass = asSourceClass(configClass); do &#123; // 真正的进行配置类的解析 sourceClass = doProcessConfigurationClass(configClass, sourceClass); &#125; while (sourceClass != null); this.configurationClasses.put(configClass, configClass); &#125; protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123; // Recursively process any member (nested) classes first processMemberClasses(configClass, sourceClass); // 处理@propertySource注解 for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), PropertySources.class, org.springframework.context.annotation.PropertySource.class)) &#123; if (this.environment instanceof ConfigurableEnvironment) &#123; processPropertySource(propertySource); &#125; &#125; // 从配置类上解析出ComponentScans的对象集合属性 Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; // 循环解析出AnnotationAttributes for (AnnotationAttributes componentScan : componentScans) &#123; // 把我们扫描出来的类变为bean定义的集合，真正的解析 Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); //循环处理我们包扫描出来的bean定义 for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) &#123; bdCand = holder.getBeanDefinition(); &#125; // 判断当前扫描出来的bean定义是不是一个配置类,若是的话直接进行递归解析 if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123; // 递归解析，因为@Component算是lite配置类 parse(bdCand.getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125; &#125; // 处理@Import，@Import三种类：Import普通类、ImportSelector、ImportBeanDefinitionRegistrar processImports(configClass, sourceClass, getImports(sourceClass), true); // 处理 @ImportResource annotations AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class); if (importResource != null) &#123; String[] resources = importResource.getStringArray(\"locations\"); Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(\"reader\"); for (String resource : resources) &#123; String resolvedResource = this.environment.resolveRequiredPlaceholders(resource); configClass.addImportedResource(resolvedResource, readerClass); &#125; &#125; // 处理@Bean方法获取配置类中所有标注了@Bean的方法，不是马上转换成BeanDefinition，而是先用一个set接收 Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass); for (MethodMetadata methodMetadata : beanMethods) &#123; configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass)); &#125; processInterfaces(configClass, sourceClass); // 处理配置类接口 默认方法的@Bean if (sourceClass.getMetadata().hasSuperClass()) &#123; // 处理配置类的父类的 ，循环再解析 String superclass = sourceClass.getMetadata().getSuperClassName(); if (superclass != null &amp;&amp; !superclass.startsWith(\"java\") &amp;&amp; !this.knownSuperclasses.containsKey(superclass)) &#123; this.knownSuperclasses.put(superclass, configClass); // Superclass found, return its annotation metadata and recurse return sourceClass.getSuperClass(); &#125; &#125; return null; // 没有父类解析完成 &#125;&#125; 真正进行扫描和解析的地方，可以明显看到这里并没有使用AnnotationConfigApplicationContext中的scanner而是重新new了一个ClassPathBeanDefinitionScanner。且会创建和添加默认的includeFilters。 123456789101112131415161718192021public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters, Environment environment, @Nullable ResourceLoader resourceLoader) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); this.registry = registry; // 设置默认的扫描规则为true的话 默认是扫描所有的 若使用 includeFilters 来表示只包含需要设置为false if (useDefaultFilters) &#123; registerDefaultFilters(); &#125; setEnvironment(environment); // 设置环境对象 setResourceLoader(resourceLoader); //设置资源加载器&#125;protected void registerDefaultFilters() &#123; // 加入扫描@Component的TypeFilter this.includeFilters.add(new AnnotationTypeFilter(Component.class)); ClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader(); try &#123; // 加入扫描的JSR250规范的TypeFilter this.includeFilters.add(new AnnotationTypeFilter(((Class&lt;? extends Annotation&gt;) ClassUtils.forName(\"javax.annotation.ManagedBean\", cl)), false)); &#125; catch (ClassNotFoundException ex) &#123;&#125; try &#123; // 加入扫描JSR330规范的TypeFilter this.includeFilters.add(new AnnotationTypeFilter(((Class&lt;? extends Annotation&gt;) ClassUtils.forName(\"javax.inject.Named\", cl)), false)); &#125; catch (ClassNotFoundException ex) &#123;&#125;&#125; ComponentScans指定扫描目标，除了最常用的basePackages，还可以指定basePackageClasses，就是指定多个类，只要是与这几个类同级的，或者在这几个类下级的都可以被扫描到，这种方式Spring比较推荐的，指定basePackages没有IDE的检查容易出错，但指定一个类有IDE的检查了，不容易出错，经常会用一个空的类来作为basePackageClasses ，还可以直接不指定，默认会把与配置类同级，或者在配置类下级的作为扫描目标。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class ComponentScanAnnotationParser &#123; public Set&lt;BeanDefinitionHolder&gt; parse(AnnotationAttributes componentScan, final String declaringClass) &#123; ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean(\"useDefaultFilters\"), this.environment, this.resourceLoader); // 为扫描器设置beanName的生成器对象 Class&lt;? extends BeanNameGenerator&gt; generatorClass = componentScan.getClass(\"nameGenerator\"); boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass); scanner.setBeanNameGenerator(useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass)); // 解析@Scope的ProxyMode属性，该属性可以将Bean创建问jdk代理或cglib代理 ScopedProxyMode scopedProxyMode = componentScan.getEnum(\"scopedProxy\"); if (scopedProxyMode != ScopedProxyMode.DEFAULT) &#123; scanner.setScopedProxyMode(scopedProxyMode); &#125; else &#123; Class&lt;? extends ScopeMetadataResolver&gt; resolverClass = componentScan.getClass(\"scopeResolver\"); scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass)); &#125; scanner.setResourcePattern(componentScan.getString(\"resourcePattern\")); // 设置CompentScan对象的includeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(\"includeFilters\")) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addIncludeFilter(typeFilter); &#125; &#125; // 设置CompentScan对象的excludeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(\"excludeFilters\")) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addExcludeFilter(typeFilter); &#125; &#125; // 是否懒加载，此懒加载为componentScan延迟加载所有类 boolean lazyInit = componentScan.getBoolean(\"lazyInit\"); if (lazyInit) &#123; scanner.getBeanDefinitionDefaults().setLazyInit(true); &#125; // 包路径配置类中componentScan设置的路径 Set&lt;String&gt; basePackages = new LinkedHashSet&lt;&gt;(); String[] basePackagesArray = componentScan.getStringArray(\"basePackages\"); for (String pkg : basePackagesArray) &#123; String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized); &#125; for (Class&lt;?&gt; clazz : componentScan.getClassArray(\"basePackageClasses\")) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); &#125; if (basePackages.isEmpty()) &#123; basePackages.add(ClassUtils.getPackageName(declaringClass)); &#125; scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) &#123; @Override protected boolean matchClassName(String className) &#123; return declaringClass.equals(className); &#125; &#125;); return scanner.doScan(StringUtils.toStringArray(basePackages)); // 真正的进行扫描解析 &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class ClassPathBeanDefinitionScanner extends ClassPathScanningCandidateComponentProvider &#123; protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, \"At least one base package must be specified\"); // 创建bean定义的holder对象用于保存扫描后生成的bean定义对象 Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;(); for (String basePackage : basePackages) &#123; // 循环包路径集合 // 到候选的Components Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); // 设置beanName String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); //这是默认配置 autowire-candidate if (candidate instanceof AbstractBeanDefinition) &#123; postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &#125; // 取@Lazy @DependsOn等注解的数据设置到BeanDefinition中 if (candidate instanceof AnnotatedBeanDefinition) &#123; AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &#125; // 解析出来的组件bean定义注册到我们的IOC容器中（容器中没有才注册） if (checkCandidate(beanName, candidate)) &#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions; &#125;&#125; 1234567public Set&lt;BeanDefinition&gt; findCandidateComponents(String basePackage) &#123; if (this.componentsIndex != null &amp;&amp; indexSupportsIncludeFilters()) &#123; return addCandidateComponentsFromIndex(this.componentsIndex, basePackage); &#125; else &#123; return scanCandidateComponents(basePackage); &#125;&#125; Spring支持component索引技术，需要引入一个组件，大部分项目没有引入这个组件，所以会进入scanCandidateComponents方法。注意这里的Bean是包装成一个ScannedGenericBeanDefinition，与内置的和配置类的都是区别开的。123456789101112131415161718192021222324252627282930313233private Set&lt;BeanDefinition&gt; scanCandidateComponents(String basePackage) &#123; Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;&gt;(); try &#123; // 把包路径转为资源路径 cn/test/MainConfig String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + resolveBasePackage(basePackage) + '/' + this.resourcePattern; // 扫描指定包路径下面的所有.class文件 Resource[] resources = getResourcePatternResolver().getResources(packageSearchPath); boolean traceEnabled = logger.isTraceEnabled(); boolean debugEnabled = logger.isDebugEnabled(); for (Resource resource : resources) &#123; // 需要resources集合 //判断当的是不是可读的 if (resource.isReadable()) &#123; try &#123; MetadataReader metadataReader = getMetadataReaderFactory().getMetadataReader(resource); if (isCandidateComponent(metadataReader)) &#123; // 是不是候选的组件 // 包装成为一个ScannedGenericBeanDefinition ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader); sbd.setResource(resource); // 并且设置class资源 sbd.setSource(resource); if (isCandidateComponent(sbd)) &#123; candidates.add(sbd); // 加入到集合中 &#125; &#125; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(\"Failed to read candidate component class: \" + resource, ex); &#125; &#125; &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"I/O failure during classpath scanning\", ex); &#125; return candidates; //返回&#125; @Import解析这里会将@Import注解中的信息解析出来，然后根据类型分别进行处理，Spring AOP的支持就是在该处解析出来的，在@EnableAspectJAutoProxy注解上有@Import(AspectJAutoProxyRegistrar.class)注解，这里的AspectJAutoProxyRegistrar实现了ImportBeanDefinitionRegistrar接口，但这里不会直接调用ImportBeanDefinitionRegistrar的registerBeanDefinitions方法，而是等数据都解析完了才会去调用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass, Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123; if (importCandidates.isEmpty()) &#123; return; &#125; if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123; this.problemReporter.error(new CircularImportProblem(configClass, this.importStack)); &#125; else &#123; this.importStack.push(configClass); try &#123; for (SourceClass candidate : importCandidates) &#123; // 获取我们Import导入进来的所有组件 if (candidate.isAssignable(ImportSelector.class)) &#123; // 判断该组件是不是实现了ImportSelector // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化我们的SelectImport组件 ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); // 调用相关的aware方法 ParserStrategyUtils.invokeAwareMethods(selector, this.environment, this.resourceLoader, this.registry); // 判断是不是延时的DeferredImportSelectors，是这个类型 不进行处理 if (this.deferredImportSelectors != null &amp;&amp; selector instanceof DeferredImportSelector) &#123; this.deferredImportSelectors.add(new DeferredImportSelectorHolder(configClass, (DeferredImportSelector) selector)); &#125; else &#123; // 不是延时的， 调用selector的selectImports String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata()); // 所以递归解析-- 直到成普通组件 Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames); processImports(configClass, currentSourceClass, importSourceClasses, false); &#125; &#125; // 判断导入的组件是不是ImportBeanDefinitionRegistrar，这里不直接调用，只是解析 else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化ImportBeanDefinitionRegistrar对象 ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); ParserStrategyUtils.invokeAwareMethods(registrar, this.environment, this.resourceLoader, this.registry); // 保存ImportBeanDefinitionRegistrar对象currentSourceClass=所在配置类 configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125; else &#123; // 当做配置类再解析，注意这里会标记：importedBy，表示这是Import的配置的类，再执行之前的processConfigurationClass()方法 ， this.importStack.registerImport(currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); processConfigurationClass(candidate.asConfigClass(configClass)); &#125; &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(\"Failed to process import candidates for configuration class [\" + configClass.getMetadata().getClassName() + \"]\", ex); &#125; finally &#123; this.importStack.pop(); &#125; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"ConcurrentHashMap源码JDK8","date":"2021-09-15T16:00:00.000Z","path":"Blog/Java/并发/ConcurrentHashMap源码JDK8/","text":"JDK8中ConcurrentHashMap实现有很大的变化，首先没有了分段锁，所有数据都放在一个大的HashMap中，其次是引入了红黑树。若头结点是Node类型，则其就是一个普通链表，若头结点是TreeNode类型，则其是一颗红黑树，TreeNode是Node的子类。链表和红黑树可以相互转换，初始时是链表，当链表达到一定阈值后，把链表转换成红黑树，反之当红黑树中元素小于某个阈值时，再转回链表。 在JDK7中分段锁的减少了hash冲突，避免了一个槽中有太多元素，提高读和写的并发度，段与段之间相互独立，提供扩容的并发度，扩容时不是把整个ConcurrentHashMap一起扩容，而是每个Segment独立扩容。 JDK8中使用红黑树，当一个槽中有很多元素时，其查询和更新速度会比链表快很多，Hash冲突问题由此得到了很好的解决，加锁的粒度变小了，并非是整个ConcurrentHashMap加锁，而是对每个头结点分别加锁，即提高了并发度，就是Node数组的长度，初始默认长度为16，和JDK7中初始Segment个数相同，且支持并发扩容，JDK7中一旦Segment个数在初始化时确定就不能再修改，并发度被固定，之后只是在每个Segment内部扩容，JDK8中相当于只有一个Segment。 123456789101112131415161718192021222324252627282930public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable &#123; private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 最大容量 private static final int DEFAULT_CAPACITY = 16; // 默认容量 static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; private static final int DEFAULT_CONCURRENCY_LEVEL = 16; // 默认并发度 private static final float LOAD_FACTOR = 0.75f; // 负载因子 static final int TREEIFY_THRESHOLD = 8; // 链表超过该长度走判断转红黑树的逻辑 static final int UNTREEIFY_THRESHOLD = 6; // 红黑树元素个数小于该值，转成链表 static final int MIN_TREEIFY_CAPACITY = 64; // 当数组长度大于该值时，链表长度超过8，转红黑树 private static final int MIN_TRANSFER_STRIDE = 16; // 扩容最小步长，即扩容线程每次最少要迁移16个hash桶 private static int RESIZE_STAMP_BITS = 16; private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1; private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS; static final int MOVED = -1; // hash for forwarding nodes static final int TREEBIN = -2; // hash for roots of trees static final int RESERVED = -3; // hash for transient reservations static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash /** Number of CPUS, to place bounds on some sizings */ static final int NCPU = Runtime.getRuntime().availableProcessors(); transient volatile Node&lt;K,V&gt;[] table; private transient volatile Node&lt;K,V&gt;[] nextTable; // 扩容时将table中元素迁移至nextTable private transient volatile long baseCount; private transient volatile int sizeCtl; // 用于控制在初始化或并发扩容时的线程数，初始值设置为cap private transient volatile int transferIndex; private transient volatile int cellsBusy; private transient volatile CounterCell[] counterCells; private transient KeySetView&lt;K,V&gt; keySet; private transient ValuesView&lt;K,V&gt; values; private transient EntrySetView&lt;K,V&gt; entrySet;&#125; 12345678910111213141516171819public ConcurrentHashMap() &#123;&#125;public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125;public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1);&#125;public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;&#125; cap就是Node数组的长度，保持为2的整数次方，tableSizeFor是根据传入的初始容量，计算出一个合适的数组长度，具体是1.5倍的初始容量+1，再往上取接近2的整数次方，作为数组长度cap的初始值。这里的sizeCtl其含义是用于控制在初始化或并发扩容时的线程数，其初始值设置为cap。 12345678910111213141516171819202122private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // sizeCtl = -1时自旋等待 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; // 把sizeCtl设置为-1 try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; // 初始化 table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); // sizeCtl并非表示数组长度，故初始化成功后，就不在等于数组长度，而是0.75n，表示下一次扩容的阈值 &#125; &#125; finally &#123; sizeCtl = sc; // 重置sizeCtl &#125; break; &#125; &#125; return tab;&#125; 需特别说明spread方法，由于数组大小限制导致高位在索引计算中一直用不到，故在spread方法中将hash的高16位利用起来进行异或转换，最经济的方式，削减系统性能损失，从而使高位也能利用起来，最后与HASH_BITS相与的目的是让得到的hash值总是正数，保证正数的目的是，因为hash值为-1表示哈希表正在扩容中，该哈希桶已经被迁移到了新的临时hash表，此时节点为ForwardingNode类型。 1234static final int HASH_BITS = 0x7fffffff;static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; 在构造函数中并没有对数组进行初始化，当put数据时才进行初始化，多线程竞争是通过对sizeCtl进行CAS操作实现的，若某个线程成功把sizeCtl设置为-1，则其就拥有初始化权利，进入初始化代码模块，等初始化完成，再把sizeCtl设置回去，其他线程一直执行while循环自旋等待，直到数组不为null，即结束初始化时退出整个初始化函数。因为初始化工作量很小，故是让其他线程一直等待，而没有帮助其初始化。 sizeCtl在Hash表处于不同状态时，表达含义不同，当sizeCtl=-1时，表示整个HashMap正在初始化，当sizeCtl=某个其他负数时，表示多个线程在对HashMap做并发扩容，当sizeCtl=cap时，tab=null，表示未初始化之前的初始容量，扩容成功后，sizeCtl存储的是下一次扩容的阈值即0.75n。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); // 数组初始化 // 判断put的对象的Key在数组中是已经存在Hash冲突，若不存在，则直接创建一个节点放入数组中 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 第i个元素初始化 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // 放入成功则退出，若初始化失败，会自旋直到成功 &#125; else if ((fh = f.hash) == MOVED) // 判断当前是否在扩容 tab = helpTransfer(tab, f); // 若在扩容则帮助扩容 else &#123; // 放入元素 V oldVal = null; synchronized (f) &#123; // 加锁，这里的锁是加在链表的头，或红黑树的根节点上的 if (tabAt(tab, i) == f) &#123; // 再次检查，判断f节点是否发生变化，若发生变化再循环一次 if (fh &gt;= 0) &#123; // 若是链表 binCount = 1; // 用来记录链表的长度 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; // 若插入元素的key已存在，则替换value if (!onlyIfAbsent) // onlyIfAbsent默认为false e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; // 已经遍历到链表的尾部，还是没有KEY重复的，则新建Node插入链表尾部 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // 红黑树 Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; // 若插入元素的key已存在，在替换value if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 若是链表，则上面的binCount为从1一直累加 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); // 链表长度超出阈值8，则转换为红黑树 if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125;static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125;static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125; 若发现在扩容，则帮助其扩容，这里加锁的是f，f是对应数组下标位置的头节点，意味着每个链表有一把锁，并发度等于数组的长度。当binCount即链表元素个数超过8时，通过treeifyBin函数把链表转换成红黑树，但该函数内部不一定需要把链表转成红黑树，可能只是进行扩容操作，数组长度小于阈值64直接扩容，否则才转红黑树。 1234567891011121314151617181920212223private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); // 数组长度小于阈值64，直接扩容 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; // 加锁，链表转红黑树 if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; // 遍历链表构建红黑树，改成双向链表 TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; tryPresize是根据期望元素个数对整个Hash表进行扩容，其核心是调用transfer函数，第一次扩容时sizeCtl会被设置为一个很大的负数即U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)，之后每一个线程扩容时，sizeCtl就加一，U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)，待扩容完成后sizeCtl减一。 1234567891011121314151617181920212223242526272829303132333435private final void tryPresize(int size) &#123; // 根据元素个数计算数组大小 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; if (tab == null || (n = tab.length) == 0) &#123; // Hash表初始化，和上面初始化时一样 n = (sc &gt; c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); // 即 n - n/4 = 0.75n，下一次扩容阈值 &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; // 扩容分支 int rs = resizeStamp(n); if (sc &lt; 0) &#123; // 说明多个线程正在进行并发扩容 Node&lt;K,V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 扩容结束 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); // 帮助扩容 &#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); // 第一次扩容 &#125; &#125;&#125; 该函数会被多个线程调用，故每个线程只是扩容旧的HashMap部分，旧数组长度是N，每个线程扩容一段，一段的长度用变量stride步长来表示，transferIndex表示整个数组扩容进度。在单核模式下没有办法多个线程并行扩容，只需要一个线程来扩容整个数组，故stride直接等于n，多核模式下为(n &gt;&gt;&gt; 3) / NCPU，且保证步长的最小值是16，则需要的线程数约为n/stride。 transferIndex是ConcurrentHashMap的一个成员变量，记录了扩容进度，初始值为n，从大到小扩容，每次减stride个位置，最终减至n&lt;=0表示整个扩容完成，因此从[0, transferIndex-1]的位置表示还没分配到线程扩容的部分。因为transferIndex会被多个线程同时修改，每次减需要通过CAS操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; // 扩容前的HashMap，扩容后的HashMap int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // 计算步长，最小步长为16 if (nextTab == null) &#123; // 初始化新HashMap try &#123; Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; // 扩容2倍 nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; // 初始化的transferIndex为旧HashMap的数组长度 &#125; int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; // 当前线程需不需要继续往前找需要帮助扩容的槽位 boolean finishing = false; // 当前线程扩容任务是否已经做完 // i为遍历下标，bound为边界，若成功拿到一个任务，则i=nextIndex-1，bound=nextIndex-stride，若拿不到任务，则i=0,bound=0 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // advance表示从i=nextIndex-1遍历到bound位置的过程中，是否一直继续，每次advance只能进一步 // 三个子分支中都是advance=false，则若三个分支都不执行，才可能一直执行while循环 // 目的在于，当对transferIndex执行CAS操作不成功时，需要自旋以期拿到一个stride的迁移任务 while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) // 通过--i对数组遍历，若成功执行了--i，则不用继续while循环 advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; // transferIndex&lt;=0，整个HashMap完成 i = -1; advance = false; &#125; // 对transferIndex进行CAS操作，即当前线程分配一个stride，若CAS成功，则拿到一个迁移任务，否则继续while自旋 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; // 数组从后往前i到bound advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; // i已越界，整个HashMap已遍历完成 int sc; if (finishing) &#123; // 表示整个HashMap扩容完成 nextTable = null; table = nextTab; // 把nextTab赋值给当前table sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; else if ((f = tabAt(tab, i)) == null) // tab[i]迁移完毕，赋值一个ForwardingNode advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) // tab[i]的位置已经在迁移过程中 advance = true; // already processed else &#123; // 对tab[i]进行迁移操作，tab[i]可能是一个链表或红黑树 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; // 链表 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; // 在lastRun之后的所有元素，hash值都一样，记录下该最后的位置 &#125; &#125; if (runBit == 0) &#123; // 判断lastRun属于高位还是低位 ln = lastRun; // 类是JDK7链表迁移的优化做法 hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) // 判断高低位 ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); // 头插法 else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); // 将拆分后的低位设置到新表的槽中 setTabAt(nextTab, i + n, hn); // 将拆分后的高位设置到新表的槽中 setTabAt(tab, i, fwd); // 将旧的槽的位置设置为fwd advance = true; &#125; else if (f instanceof TreeBin) &#123; // 红黑树，迁移办法和链表类似 TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; // 采用高低位 TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; // 对低位的处理 if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; // 记录低位元素个数 &#125; else &#123; // 对高位的处理 if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; // 记录高位元素个数 &#125; &#125; // 对高低位的元素个数分别判断，其是否需要转回链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); // 低位 setTabAt(nextTab, i + n, hn); // 高位 setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 在扩容完成之前，数组下标对应的槽有的已经迁移到新的HashMap中，有的还没有，这时所有调用get方法的线程还是会访问旧HashMap，若Node[0]已迁移成功，其他Node还在迁移中，若有线程要读取Node[0]中的数据，会访问失败，为此新建一个转发节点ForwardingNode，在该节点中记录的是新的ConcurrentHashMap的引用，当线程访问到ForwardingNode时会查询新的ConcurrentHashMap。 对链表的迁移不需要记录高低位的元素个数，因为链表拆分后高低位肯定都是小于等于原来的链表长度的，故肯定还是链表，不需要判断是否转红黑树。当对红黑树的迁移，拆分后很可能长度打到转链表的临界值了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) // 若正在扩容 return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125;static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; int n; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) return null; for (;;) &#123; int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125; &#125;&#125; ForwardingNode节点只是做一个标记作用，表示其他线程正在扩容，且此节点已经扩容完毕，关联了nextTable，扩容期间可通过find方法，访问到已迁移到nextTable中的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; // 如果counterCells未被初始化，且CAS对baseCount加一成功就不会走if内的逻辑，否则走if内的逻辑 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; // 若counterCells数组不为null，或CAS对baseCount加一失败 if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; // 若counterCells数组为null、或counterCells数组长度为0、或每个线程生成的随机数取余后再取模得到的counterCells数组下标对应的元素为null、或若不为空对该元素value CAS加一失败才执行fullAddCount方法 fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; if (check &gt;= 0) &#123; // 看是否进行扩容 Node&lt;K,V&gt;[] tab, nt; int n, sc; // 若完成一次扩容后继续判断扩容后的HashMap是否需要再次扩容，若需要则再次扩容 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // nextTable是在transfer中赋值的 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125;private final void fullAddCount(long x, boolean wasUncontended) &#123; int h; if ((h = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); // force initialization h = ThreadLocalRandom.getProbe(); wasUncontended = true; &#125; boolean collide = false; // True if last slot nonempty for (;;) &#123; CounterCell[] as; CounterCell a; int n; long v; // 如果CounterCell数组不为空 if ((as = counterCells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; if ((a = as[(n - 1) &amp; h]) == null) &#123; // 当前随机数对应的CounterCell数组下标的CounterCell为null if (cellsBusy == 0) &#123; // 判断当前CounterCell数组是否繁忙 CounterCell r = new CounterCell(x); // 新建一个CounterCell // CAS将cellsBusy标志设置为1即繁忙 if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean created = false; try &#123; // Recheck under lock CounterCell[] rs; int m, j; // 再次判断当前数组下标是否为null，若不为null说明其他线程改变了则继续循环，若为空则将当前数组下标设置为沙面生成的r，且退出循环 if ((rs = counterCells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; rs[j] = r; created = true; &#125; &#125; finally &#123; cellsBusy = 0; &#125; if (created) break; continue; // Slot is now non-empty &#125; &#125; collide = false; &#125; else if (!wasUncontended) // 若wasUncontended为false // 置为true，下面执行ThreadLocalRandom.advanceProbe(h)新的随机数h wasUncontended = true; // Continue after rehash // 若a = as[(n - 1) &amp; h]) != null 则CAS操作a，成功则退出循环 else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; else if (counterCells != as || n &gt;= NCPU) // 若数组长度大于CPU数了，则不再进行扩容 collide = false; // collide设置为false else if (!collide) collide = true; // collide为true时才会触发CounterCell数组扩容 else if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; try &#123; if (counterCells == as) &#123;// 再次校验counterCells是否改变，若改变则继续循环 CounterCell[] rs = new CounterCell[n &lt;&lt; 1]; // 扩容CounterCell数组 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; counterCells = rs; &#125; &#125; finally &#123; cellsBusy = 0; &#125; collide = false; continue; // Retry with expanded table &#125; h = ThreadLocalRandom.advanceProbe(h); // 生成一个新的随机数 &#125; else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; // 若CounterCell数组为空，若cellsBusy=0说明没有其他线程在对CounterCell初始化，cas将cellsBusy设置为1，若成功则对CounterCell数组初始化，且初始化长度为2 boolean init = false; try &#123; // Initialize table if (counterCells == as) &#123; // 再次判断counterCells是否已经改变 CounterCell[] rs = new CounterCell[2]; rs[h &amp; 1] = new CounterCell(x); counterCells = rs; init = true; &#125; &#125; finally &#123; cellsBusy = 0; // 完成则将cellsBusy还原为0 &#125; if (init) // 若初始化完成则直接退出循环 break; &#125; else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; // 在CounterCell数组为空，且cellsBusy为1说明其他线程在对CounterCell初始化，剩余线程不是等待而是对baseCount进行CAS操作，若成功则退出循环 &#125;&#125; 对Size的统计是通过遍历CounterCell数组中存储的value相加的总和。 123456789101112131415public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125;final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125;","tags":[{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"https://yaoyinglong.github.io/tags/ConcurrentHashMap/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"Linux常用技巧","date":"2021-09-15T11:06:33.867Z","path":"Blog/杂记/Linux/Linux常用技巧/","text":"SecureCRT无操作自动登出echo $TMOUT 查看无操作自动登出时间，将该时间稍微调小一点设置到SecureCRT Session中 SecureCRT文件上传下载rz：将文件从本地上传到服务器 sz [file1] [file2] [dir/*]：本地从服务器上下载文件","tags":[{"name":"Linux","slug":"Linux","permalink":"https://yaoyinglong.github.io/tags/Linux/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"Linux","slug":"杂记/Linux","permalink":"https://yaoyinglong.github.io/categories/杂记/Linux/"}]},{"title":"ConcurrentHashMap源码JDK7","date":"2021-09-14T16:00:00.000Z","path":"Blog/Java/并发/ConcurrentHashMap源码JDK7/","text":"为了提高并发度，一个HashMap被拆分成多个子HashMap，每个HashMap被称为Segment，多个线程操作多个Segment相互独立。每个Segment都继承自ReentrantLock，Segment的数量等于锁的数量，这些锁彼此之间相互独立，即所谓的分段锁。 segmentShift和segmentMask是为了方便计算Segment数组下标。segmentShift默认是28，segmentMask默认是15。 1234567891011121314151617181920212223public class ConcurrentHashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements ConcurrentMap&lt;K, V&gt;, Serializable &#123; static final int DEFAULT_INITIAL_CAPACITY = 16; static final float DEFAULT_LOAD_FACTOR = 0.75f; static final int DEFAULT_CONCURRENCY_LEVEL = 16; // Segment数组的默认大小，即默认并发级别 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; static final int MIN_SEGMENT_TABLE_CAPACITY = 2; static final int MAX_SEGMENTS = 1 &lt;&lt; 16; static final int RETRIES_BEFORE_LOCK = 2; final int segmentMask; // 用于方便计算Segment数组下标 final int segmentShift; // 用于方便计算Segment数组下标 final Segment&lt;K,V&gt;[] segments; transient Set&lt;K&gt; keySet; transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; transient Collection&lt;V&gt; values; static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor; &#125;&#125; 构造函数，concurrencyLevel表示并发度，也就是Segment数组的大小，默认大小16，一旦设定之后就不能再扩容了，且为了提升hash的计算性能，会保证数组初始大小始终是2的整数次方，若concurrencyLevel=9，则在构造函数中会找到比9大且最接近9的2的整数次方，也就是ssize=16，对应的segmentShift和segmentMask也是为了方便计算hash使用的。 同样loadFactor为负载因子，传给了Segment内部，当每个Segment的元素个数达到一定阈值时进行rehash，虽然Segment个数不能扩容，但每个Segment内部可以扩容。 123456789101112131415161718192021222324252627282930313233public ConcurrentHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);&#125;public ConcurrentHashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);&#125;public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; // 保证并发度是2的整数次方 ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; // 默认算出来为28 this.segmentMask = ssize - 1; // 默认算出来为15 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; // 除数容量或数组个数，是每个Segment的初始大小，默认为1 if (c * ssize &lt; initialCapacity) // 该循环的作用其实是向上取整，c是每个HashEntry的数组长度 ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; // 默认为2，HashEntry的数组最小容量为2 while (cap &lt; c) // c可能不是一个2的整数次幂的数，这里的作用其实就是获取大于等于c的最小的2的整数次幂的数 cap &lt;&lt;= 1; // 构造第0个Segment Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; // 数组大小为ssize即2的整数次方 UNSAFE.putOrderedObject(ss, SBASE, s0); // 数组的第0个元素赋值为s0 this.segments = ss;&#125; hash值是一个32位的整数，segmentShift默认大小为28， segmentMask默认为15，则(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask的意思是将hash值向右移28位，再和15进行与操作，即以hash值的最高4位作为对应Segment数组下标。该处没有加锁，锁是加在s.put内部，也就是分段加锁。从put方法可以看出ConcurrentHashMap是不允许空值和空健的，这也是和HashMap的另一个区别。 1234567891011public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) // 不允许空值 throw new NullPointerException(); int hash = hash(key); // 把key映射到一个32位的整数 int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; // segmentShift默认大小为28， segmentMask默认为15，segment数组下标 // 获取segment数组中第j个元素，若该元素为null，则对第j个Segment进行初始化 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject(segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) s = ensureSegment(j); // 对第j个Segment进行初始化 return s.put(key, hash, value, false); // 找到对应的Segment[j]，调用put&#125; 多个线程可能同时调用ensureSegment对Segment[j]进行初始化，在该函数中要避免重复初始化。 1234567891011121314151617181920private Segment&lt;K,V&gt; ensureSegment(int k) &#123; final Segment&lt;K,V&gt;[] ss = this.segments; long u = (k &lt;&lt; SSHIFT) + SBASE; // 下标K对应的内存地址的偏移量u Segment&lt;K,V&gt; seg; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // 检查下标为u的segment是否已经被初始化 Segment&lt;K,V&gt; proto = ss[0]; // 以Segment[0]的参数为原型 int cap = proto.table.length; // 直接使用Segment[0]的HashEntry的数组长度 float lf = proto.loadFactor; int threshold = (int)(cap * lf); HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap]; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // 重新检查 Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab); // 真正创建Segment while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // 自旋 if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; &#125; &#125; &#125; return seg;&#125; count表示元素个数，modCount表示修改次数，当待put的元素key或hash值和链表中的某个节点相等时，不会重复插入节点，若onlyIfAbsent为false时修改该节点的value。若遍历到链表尾部，并没有发现可以或hash相等的节点，则在链表头部插入一个新节点，并把table[index]赋值为该节点。值得注意的是这里的锁是加在Segment数组的每个槽上的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); // 执行到该处一定要拿到锁 V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; // tab.length为2的整数次方，该处等价于hash对tab.length取模 HashEntry&lt;K,V&gt; first = entryAt(tab, index); // 定位到第index个HashEntry for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; // 若定位到相同的key if (!onlyIfAbsent) &#123; e.value = value; ++modCount; // 修改次数累加 &#125; break; // key相等或hash值相等，不会重复插入，直接返回 &#125; e = e.next; // 遍历链表 &#125; else &#123; // 已经遍历到链表尾部，没有发现重复元素 if (node != null) // 在上面的scanAndLockForPut已经建好了节点 node.setNext(first); // 把node插入链表头部 else // 新建的node插入链表头部 node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); // 超出阈值，扩容 else setEntryAt(tab, index, node); // 把node赋值给tab[index] ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125;&#125;static final &lt;K,V&gt; HashEntry&lt;K,V&gt; entryAt(HashEntry&lt;K,V&gt;[] tab, int i) &#123; return (tab == null) ? null : (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile(tab, ((long)i &lt;&lt; TSHIFT) + TBASE);&#125;static final &lt;K,V&gt; void setEntryAt(HashEntry&lt;K,V&gt;[] tab, int i, HashEntry&lt;K,V&gt; e) &#123; UNSAFE.putOrderedObject(tab, ((long)i &lt;&lt; TSHIFT) + TBASE, e);&#125; 在函数开始加锁时，进行了优化，若tryLock成功拿到锁，则进入下面代码，否则进入scanAndLockForPut，拿不到锁不立即阻塞先自旋，若自旋到一定次数后任未拿到锁，再调用lock阻塞，且在自旋过程中遍历链表，若发现没有重复节点，则提前新建一个节点，为后面再插入节省时间。 123456789101112131415161718192021222324252627private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // negative while locating node while (!tryLock()) &#123; // 自旋获取锁 HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) &#123; if (e == null) &#123; // 遍历到链表最后一个元素都没有key相同的 if (node == null) // 创建一个新节点 node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0; &#125; else if (key.equals(e.key)) retries = 0; // 若遍历到key相同的，则不需要创建新的HashEntry，则退出遍历 else // 若first不为空，找到链表尾部 e = e.next; // 遍历链表 &#125; else if (++retries &gt; MAX_SCAN_RETRIES) &#123; // 自旋，达到一定次数后，通过锁阻塞，多核为64次 lock(); // 阻塞获取锁 break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123; // 由于是头插法，则只需要判断链表头节点是否发生变化，若发生变化则重新遍历，且只有偶数次才回去检查头结点是否发生变化 e = first = f; // 若该处值变化了，重新赋值e和first retries = -1; &#125; &#125; return node;&#125; 和HashMap一样，超过一定阈值后，Segment内部也会进行扩容，传入的节点，在扩容完成后会被插入到新的hash表中。扩容时进行了一次优化，并没有对元素依次拷贝，而是先找到lastRun位置，也就是for循环。lastRun到链表末尾的所有元素hash值没有改变，故不需要依次拷贝，只需要把这部分链表链接到新链表所对应的位置即可，也就是newTable[lastIdx] = lastRun。lastRun之前的元素则需要依次拷贝。由于前面已经加了分段锁，所以不存在并发问题。 123456789101112131415161718192021222324252627282930313233343536373839404142private void rehash(HashEntry&lt;K,V&gt; node) &#123; HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; int newCapacity = oldCapacity &lt;&lt; 1; // 扩容一倍 threshold = (int)(newCapacity * loadFactor); HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; int sizeMask = newCapacity - 1; for (int i = 0; i &lt; oldCapacity ; i++) &#123; HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; // 若链表不存在，则不需要移动操作 HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; // 节点之前在第i个位置，则新hash表中一定处于i或i+oldCapacity位置 if (next == null) // 若链表只有一个节点，则直接挪到新数组中 newTable[idx] = e; else &#123; // Reuse consecutive sequence at same slot HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; // 找到最后连续的且在新数组的下标都为lastIdx的头节点 lastIdx = k; // 寻找链表中最后一个hash值不等于lastIdx的元素 lastRun = last; &#125; &#125; // 把lastRun之后的链表元素直接链接到新hash表中的lastIdx位置，在lastRun之前的所有链表元素，需要在新的位置逐个拷贝 newTable[lastIdx] = lastRun; // 将lastRun链表直接赋值到新的数组中 // Clone remaining nodes for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; // 遍历旧的链表，将开头到lastRun的元素依次转移到新的数组中 V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); // 依然使用的头插法 &#125; &#125; &#125; &#125; int nodeIndex = node.hash &amp; sizeMask; // 把新节点加入到新的hash表中 node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; table = newTable;&#125; 整个get过程也就是两次hash，第一次hash计算出所在的Segment，第二次hash找到Segment中对应的HashEntry数组下标，然后遍历该位置的链表。整个读的过程没有加锁，而是使用了UNSAFE.getObjectVolatile 123456789101112131415public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; // 第一次hash if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; // 第二次hash K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125;","tags":[{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"https://yaoyinglong.github.io/tags/ConcurrentHashMap/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"Callable与Future","date":"2021-09-13T16:00:00.000Z","path":"Blog/Java/并发/Callable与Future/","text":"JDK只提供了两种线程启动方式，这两种方式中的run()方法的返回值是void类型，Callable不算是线程启动方式，Thread类也并没有接收Callable参数的构造方法，只接收Runnable接口参数的构造方法，若要将结果值返回，需要用到一个包装类FutrueTask将Callable包装成Runnable，然后传递给Thread的构造方法即可： 123456789new Thread().start();new Thread(new Runnable() &#123; @Override public void run() &#123;&#125;&#125;).start();FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(callable);new Thread(futureTask).start();Integer result = futureTask.get(); 对于线程池来说，线程池execute(Runnable command)接口是无返回值的，与之相对应的是一个有返回值的接口Future&lt;T&gt; submit(Callable&lt;T&gt; task)，该方法并不是在ThreadPoolExecutor中直接实现的，而是在其父类AbstractExecutorService中实现的。 1234567891011public abstract class AbstractExecutorService implements ExecutorService &#123; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); // 把Callable转换成Runnable execute(ftask); // 调用ThreadPoolExecutor的execute(Runnable command)接口 return ftask; &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125;&#125; Callable其实是用Runnable实现的，在submit内部把Callable通过FutureTask这个Adapter转换成Runnable，然后通过execute执行。FutureTask是一个Adapter对象，即实现了Runnable接口也实现了Future接口，其内部包含了一个Callable对象，从而实现了Callable转换成Runnable。 FutureTask任务初始运行状态为NEW，是构造函数保证的，INTERRUPTING和INTERRUPTED是任务中间状态，其余四种是任务终止状态，任务的中间状态是一个瞬态，非常短暂。且任务中间态并不代表任务正在执行，而是任务已执行完，正在设置最终返回结果，故只要state不处于NEW状态，就说明任务已经执行完毕，这里的执行完毕是指传入的Callable对象的call方法执行完毕，或者抛出了异常，运行状态仅在set、setException和cancel方法中转换为终止状态。 所有等待任务执行完毕的线程的集合是通过单向链表实现的队列，FutureTask中将WaitNode单向链表当做栈来使用，确切来说是当做Treiber栈来使用的，使用CAS来完成入栈出栈操作。 同时可能有多个线程都在获取任务的执行结果，若任务还在执行过程中，则将获取结果的线程包装成WaitNode扔到Treiber栈的栈顶，即完成入栈操作。由于FutureTask中的队列本质上是一个Treiber栈，则使用该队列只需要一个指向栈顶节点的指针就行了，在FutureTask中waiters属性即是指向栈顶的指针： 123456private volatile WaitNode waiters; // 指向栈顶节点的指针static final class WaitNode &#123; volatile Thread thread; // 记录线程的thread属性 volatile WaitNode next; // 指向下一个节点的指针 WaitNode() &#123; thread = Thread.currentThread(); &#125;&#125; callable表示要执行的任务本身，runner是执行callable的线程，为了中断或取消任务做准备，在运行时执行run方法时通过CAS设置的。outcome是用来存储Callable的执行结果或抛出的异常。 123456789101112131415161718192021222324252627public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125;public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123; private volatile int state; // CAS state变量 + LockSupport.park/unpark private static final int NEW = 0; // 任务初始运行状态 private static final int COMPLETING = 1; // 正在设置任务结果 private static final int NORMAL = 2; // 任务正常执行完毕 private static final int EXCEPTIONAL = 3; // 任务执行过程中发生异常 private static final int CANCELLED = 4; // 任务被取消 private static final int INTERRUPTING = 5; // 正在中断运行任务的线程 private static final int INTERRUPTED = 6; // 任务被中断 private Callable&lt;V&gt; callable; // 要执行的任务本身 private Object outcome; // Callable的执行结果，或抛出的异常 private volatile Thread runner; // 执行callable的线程，为了中断或取消任务做准备 private volatile WaitNode waiters; // 指向栈顶节点的指针 public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // 确保callable的可见性 &#125; public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // 确保callable的可见性 &#125;&#125; 执行run方法时，使用CAS操作将runner属性设置位当前线程，可见runner属性是在运行时被初始化的。putOrderedInt和putIntVolatile是等价的，保证了state状态对其他线程的可见性。handlePossibleCancellationInterrupt方法要结合后面的cancel方法来看，检测发现s = INTERRUPTING，说明cancel方法还没有执行到中断当前线程的地方，那就等待它将state状态设置成INTERRUPTED。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); // 关键点在于把Callable的call转换成Runnable的run ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); // 任务执行异常，把异常栈存入outcome变量 &#125; if (ran) set(result); // 任务执行成功，把返回值存入outcome变量 &#125; &#125; finally &#123; runner = null; int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125;protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125;protected void setException(Throwable t) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); &#125;&#125;private void handlePossibleCancellationInterrupt(int s) &#123; if (s == INTERRUPTING) while (state == INTERRUPTING) Thread.yield(); // wait out pending interrupt&#125; 首先将waiters属性的值由原值设置为null，waiters属性指向了Treiber栈的栈顶节点，将该值设为null的目的就是清空整个栈。 设置不成功则if语句块不会被执行，进行下一轮for循环，而下一轮for循环的判断条件又是waiters!=null ，则说明该方法只是为了确保waiters属性被成功设置成null。若设置成功，内层循环的作用是遍历链表中所有等待的线程，并唤醒他们。 12345678910111213141516171819202122private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint&#125; 任务的取消，若任务已经执行完成、任务已经被取消过了、任务因为某种原因不能被取消cancel操作一定失败。cancel操作返回true并不代表任务真的被取消了，这取决于发起cancel时，任务所处的状态。 若发起cancel时任务还没有开始运行，则随后任务就不会被执行，若发起cancel时任务已经在运行了，若mayInterruptIfRunning为true，则当前在执行的任务会被中断，否则可以允许正在执行的任务继续运行，直到它执行完。 123456789101112131415161718public boolean cancel(boolean mayInterruptIfRunning) &#123; if (!(state == NEW &amp;&amp; UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try &#123; // in case call to interrupt throws exception if (mayInterruptIfRunning) &#123; try &#123; Thread t = runner; if (t != null) t.interrupt(); &#125; finally &#123; // final state UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); &#125; &#125; &#125; finally &#123; finishCompletion(); &#125; return true;&#125; FutureTask中会涉及到两类线程，一类是执行任务的线程只有一个，FutureTask的run方法就由该线程来执行；一类是获取任务执行结果的线程可以有多个，这些线程可并发执行，每一个线程都是独立的，都可以调用get方法来获取任务的执行结果。故FutureTask中使用CAS state变量加LockSupport.park/unpark来实现阻塞唤醒机制。若任务还没有执行完，则这些线程就需要进入Treiber栈中挂起，直到任务执行结束，或者等待的线程自身被中断。 使用awaitDone方法等待任务进入终止态，awaitDone的返回值是任务的状态，而不是任务的结果，最终的结果是通过report方法根据awaitDone放回的状态来判断从而返回具体的响应结果。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125;public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s);&#125;private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; // 先检测当前线程是否被中断了 removeWaiter(q); // 将当前节点从队列中移除，若是被中断唤醒的q!=null throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; // 若任务已经进入终止态，则直接返回任务的状态; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // 若任务正在设置执行结果，则让出当前线程的CPU资源继续等待 Thread.yield(); else if (q == null) // 当前线程还没有进入等待队列，则新建了一个WaitNode q = new WaitNode(); else if (!queued) // 当前线程还没有入队，则入队 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else // 成功将任务放入队列后，将该线程挂起 // 任务执行完毕在finishCompletion方法中会唤醒所有在Treiber栈中等待的线程 // 等待的线程自身因为被中断等原因而被唤醒。 LockSupport.park(this); &#125;&#125;// 它根据当前state状态，返回正常执行的结果，或者抛出指定的异常private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x);&#125;private void removeWaiter(WaitNode node) &#123; if (node != null) &#123; node.thread = null; // 这里将要移除链表的节点持有的线程置空，便于后面将其从链表移除判断 retry: for (;;) &#123; // restart on removeWaiter race for (WaitNode pred = null, q = waiters, s; q != null; q = s) &#123; s = q.next; if (q.thread != null) // 将链表中所有thread == null的节点移除 pred = q; else if (pred != null) &#123; pred.next = s; // 将链表中所有thread == null的节点移除，要移除的节点不在栈顶 if (pred.thread == null) // check for race continue retry; &#125; else if (!UNSAFE.compareAndSwapObject(this, waitersOffset, q, s)) continue retry; &#125; break; &#125; &#125;&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"BlockingQueue阻塞队列二","date":"2021-09-12T16:00:00.000Z","path":"Blog/Java/并发/BlockingQueue阻塞队列二/","text":"SynchronousQueueSynchronousQueue是一种特殊的BlockingQueue，其本身没有容量，先调用put方法线程会阻塞，直到另一个线程调用了take方法，两个线程才同时解锁，反之亦然。通过构造函数可知，和锁一样SynchronousQueue也有公平与非公平模式，若是公平模式，则用TransferQueue实现，若是非公平模式，则用TransferStack实现。 1234567private transient volatile Transferer&lt;E&gt; transferer;public SynchronousQueue() &#123; this(false);&#125;public SynchronousQueue(boolean fair) &#123; transferer = fair ? new TransferQueue&lt;E&gt;() : new TransferStack&lt;E&gt;();&#125; put和take都调用了transfer方法，而TransferQueue和TransferStack分别实现了该接口，若是put第一个参数就是对应元素，若是take则第一个参数为null。 1234567891011121314public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); if (transferer.transfer(e, false, 0) == null) &#123; Thread.interrupted(); throw new InterruptedException(); &#125;&#125;public E take() throws InterruptedException &#123; E e = transferer.transfer(null, false, 0); if (e != null) return e; Thread.interrupted(); throw new InterruptedException();&#125; 若是公平模式，则第一个调用put的线程会在队列头部，第一个来到的take线程和它进行配对，遵循先到先配对原则，若是非公平模式，则最后一个调用put的线程会在栈顶，第一个来到的take线程会和它进行配对，遵循后道先配对原则。 TransferQueueTransferQueue是一个基于单向链表实现的队列，通过head和tail两个指针记录头部和尾部，初始时head和tail会指向一个空节点。 12345678910111213141516static final class TransferQueue&lt;E&gt; extends Transferer&lt;E&gt; &#123; static final class QNode &#123; volatile QNode next; // 单向链表 volatile Object item; // 若是put则item不为空，若是take则item为空 volatile Thread waiter; // put或take对应的阻塞线程 final boolean isData; // 若是put则isData为true否则为false &#125; transient volatile QNode head; // 单向链表的队头 transient volatile QNode tail; // 单向链表的队尾 transient volatile QNode cleanMe; TransferQueue() &#123; QNode h = new QNode(null, false); // initialize to dummy node. head = h; tail = h; &#125;&#125; put节点和take节点一旦相遇，就会配对出队列，故队列中不可能同事存在put节点和take节点，故要么所有节点都是put节点，要么所有节点都是take节点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061E transfer(E e, boolean timed, long nanos) &#123; QNode s = null; // constructed/reused as needed boolean isData = (e != null); for (;;) &#123; QNode t = tail; QNode h = head; if (t == null || h == null) // 队列还未初始化，自旋等待 continue; // spin if (h == t || t.isData == isData) &#123; // 队列为空或当前线程和队列中元素为同一中模式 QNode tn = t.next; if (t != tail) // 不一致读，重新执行for循环 continue; if (tn != null) &#123; // 若t.next不为空，则替换尾部节点 advanceTail(t, tn); continue; &#125; if (timed &amp;&amp; nanos &lt;= 0) // can't wait return null; if (s == null) s = new QNode(e, isData); // 新建一个节点 if (!t.casNext(null, s)) // 加入尾部 continue; advanceTail(t, s); // 后移tail指针 Object x = awaitFulfill(s, e, timed, nanos); // 进入阻塞状态 if (x == s) &#123; // wait was cancelled clean(t, s); return null; &#125; if (!s.isOffList()) &#123; // 从队列中唤醒，确定已经处于队列中的第一个元素 advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; &#125; return (x != null) ? (E)x : e; &#125; else &#123; // 当前线程可以和队列中的第一个元素进行配对 QNode m = h.next; // 取出队列中第一个元素 if (t != tail || m == null || h != head) // 不一致读，重新执行for循环 continue; // inconsistent read Object x = m.item; if (isData == (x != null) || // 已经配对过了 x == m || // m cancelled !m.casItem(x, e)) &#123; // 尝试配对 advanceHead(h, m); // 已经配对过，直接出队列 continue; &#125; advanceHead(h, m); // 配对成功，出队列 LockSupport.unpark(m.waiter); // 唤醒队列中与第一个元素对应的线程 return (x != null) ? (E)x : e; &#125; &#125;&#125;void advanceTail(QNode t, QNode nt) &#123; if (tail == t) UNSAFE.compareAndSwapObject(this, tailOffset, t, nt);&#125; 若当前线程和队列中的元素时同一种模式，则与当前线程对应的节点被加入队列尾部并阻塞，若不是同一种模式，则选取队列头部的第一元素进行配对。这里配对是通过m.casItem(x, e)把自己的item x换成对方的item e，若CAS操作成功，则配对成功，若是put节点，则isData=true,item!=null，若是take节点，则isData=false,item=null，若CAS操作不成功，则isData和item之间将不一致，也就是isData == (x != null)，通过该条件可以判断节点是否已经配对成功过了。 TransferStackTransferStack也是一个单向链表，不同于队列，其只需要一个head指针就能实现入栈和出栈操作，链表中节点有三种状态，REQUEST表示take节点，DATA表示put节点，二者配对成功会生成一个FULFILLING节点，入栈，然后FULFILLING节点和被配对的节点一起出栈。与TransferQueue不同TransferStack没有空的头结点。 1234567891011121314static final class TransferStack&lt;E&gt; extends Transferer&lt;E&gt; &#123; static final int REQUEST = 0; static final int DATA = 1; static final int FULFILLING = 2; static boolean isFulfilling(int m) &#123; return (m &amp; FULFILLING) != 0; &#125; static final class SNode &#123; volatile SNode next; // 单向链表 volatile SNode match; // 配对的节点 volatile Thread waiter; // 对应的阻塞线程 Object item; // data; or null for REQUESTs int mode; // 三种模式 &#125; volatile SNode head;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354E transfer(E e, boolean timed, long nanos) &#123; SNode s = null; // constructed/reused as needed int mode = (e == null) ? REQUEST : DATA; for (;;) &#123; SNode h = head; if (h == null || h.mode == mode) &#123; // 同一种模式 if (timed &amp;&amp; nanos &lt;= 0) &#123; // can't wait if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // pop cancelled node else return null; &#125; else if (casHead(h, s = snode(s, e, h, mode))) &#123; // 入栈 SNode m = awaitFulfill(s, timed, nanos); // 阻塞等待 if (m == s) &#123; // wait was cancelled clean(s); return null; &#125; if ((h = head) != null &amp;&amp; h.next == s) casHead(h, s.next); // help s's fulfiller return (E) ((mode == REQUEST) ? m.item : s.item); &#125; &#125; else if (!isFulfilling(h.mode)) &#123; // 非同一种模式 if (h.isCancelled()) // already cancelled casHead(h, h.next); // pop and retry else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) &#123; for (;;) &#123; // 生成一个FULFILLING节点入栈 SNode m = s.next; // m is s's match if (m == null) &#123; // all waiters are gone casHead(s, null); // pop fulfill node s = null; // use new node next time break; // restart main loop &#125; SNode mn = m.next; if (m.tryMatch(s)) &#123; casHead(s, mn); // 两个节点一起出栈 return (E) ((mode == REQUEST) ? m.item : s.item); &#125; else // lost match s.casNext(m, mn); // help unlink &#125; &#125; &#125; else &#123; // 已经匹配过了，出栈 SNode m = h.next; // m is h's match if (m == null) // waiter is gone casHead(h, null); // pop fulfilling node else &#123; SNode mn = m.next; if (m.tryMatch(h)) // help match casHead(h, mn); // 配对一起出栈 else // lost match h.casNext(m, mn); // help unlink &#125; &#125; &#125;&#125; BlockingDequeBlockingDeque定义了一个阻塞的双端队列，该接口继承了BlockingQueue的同时，增加了对应的双端队列的操作接口，该接口只有一个实现LinkedBlockingDeque。 12345678910111213141516public interface BlockingDeque&lt;E&gt; extends BlockingQueue&lt;E&gt;, Deque&lt;E&gt; &#123; void addFirst(E e); void addLast(E e); boolean offerFirst(E e); boolean offerLast(E e); void putFirst(E e) throws InterruptedException; void putLast(E e) throws InterruptedException; boolean offerFirst(E e, long timeout, TimeUnit unit) throws InterruptedException; boolean offerLast(E e, long timeout, TimeUnit unit) throws InterruptedException; E takeFirst() throws InterruptedException; E takeLast() throws InterruptedException; E pollFirst(long timeout, TimeUnit unit) throws InterruptedException; E pollLast(long timeout, TimeUnit unit) throws InterruptedException; boolean removeFirstOccurrence(Object o); boolean removeLastOccurrence(Object o);&#125; LinkedBlockingDeque的核心数据结构如下，是一个双向链表，对应的原理和LinkedBlockingQueue基本一样，只是LinkedBlockingQueue是单向链表，而LinkedBlockingDeque是双向链表。 1234567891011121314151617public class LinkedBlockingDeque&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingDeque&lt;E&gt;, java.io.Serializable &#123; static final class Node&lt;E&gt; &#123; // 双向链表的Node E item; Node&lt;E&gt; prev; // 前置节点 Node&lt;E&gt; next; // 后置节点 Node(E x) &#123; item = x; &#125; &#125; transient Node&lt;E&gt; first; // 队列的头 transient Node&lt;E&gt; last; // 队列的尾 private transient int count; // 元素个数 private final int capacity; // 容量 final ReentrantLock lock = new ReentrantLock(); private final Condition notEmpty = lock.newCondition(); private final Condition notFull = lock.newCondition();&#125; 入队操作入队的基础操作 1234567891011121314151617181920212223242526272829private boolean linkFirst(Node&lt;E&gt; node) &#123; if (count &gt;= capacity) return false; Node&lt;E&gt; f = first; node.next = f; first = node; if (last == null) last = node; else f.prev = node; ++count; notEmpty.signal(); return true;&#125;private boolean linkLast(Node&lt;E&gt; node) &#123; // assert lock.isHeldByCurrentThread(); if (count &gt;= capacity) return false; Node&lt;E&gt; l = last; node.prev = l; last = node; if (first == null) first = node; else l.next = node; ++count; notEmpty.signal(); return true;&#125; 123456789101112131415161718192021222324public void putFirst(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; while (!linkFirst(node)) notFull.await(); &#125; finally &#123; lock.unlock(); &#125;&#125;public void putLast(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; while (!linkLast(node)) notFull.await(); &#125; finally &#123; lock.unlock(); &#125;&#125; 出队操作出队的基础操作 1234567891011121314151617181920212223242526272829303132333435private E unlinkFirst() &#123; // assert lock.isHeldByCurrentThread(); Node&lt;E&gt; f = first; if (f == null) return null; Node&lt;E&gt; n = f.next; E item = f.item; f.item = null; f.next = f; // help GC first = n; if (n == null) last = null; else n.prev = null; --count; notFull.signal(); return item;&#125;private E unlinkLast() &#123; Node&lt;E&gt; l = last; if (l == null) return null; Node&lt;E&gt; p = l.prev; E item = l.item; l.item = null; l.prev = l; // help GC last = p; if (p == null) first = null; else p.next = null; --count; notFull.signal(); return item;&#125; 123456789101112131415161718192021222324public E takeFirst() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; E x; while ( (x = unlinkFirst()) == null) notEmpty.await(); return x; &#125; finally &#123; lock.unlock(); &#125;&#125;public E takeLast() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; E x; while ( (x = unlinkLast()) == null) notEmpty.await(); return x; &#125; finally &#123; lock.unlock(); &#125;&#125; CopyOnWriteCopyOnWrite机制的核心思想是，读写分离，空间换时间，避免为保证并发安全导致的激烈的锁竞争。适用于读多写少的情况，最大程度的提高读的效率； CopyOnWrite是最终一致性，在写的过程中，原有的读的数据是不会发生更新的，只有新的读才能读到最新数据；写的时候不能并发写，需要对写操作进行加锁；使用volatile变量，使其他线程能够及时读到新的数据； CopyOnWrite机制在Java并发包中有CopyOnWriteArrayList和CopyOnWriteArraySet两种实现。CopyOnWriteArraySet底层也是通过CopyOnWriteArrayList来实现的。 集合框架中的ArrayList是非线程安全的，Vector虽是线程安全的，但由于简单粗暴的锁同步机制，性能较差。CopyOnWriteArrayList容器允许并发读，读操作是无锁的，性能较高。至于写操作，如向容器中添加一个元素，则首先将当前容器复制一份，然后在新副本上执行写操作，结束之后再将原容器的引用指向新容器。 由于每次都要拷贝一份数据，对内存压力较大，甚至可能导致频繁GC，且无法保证实时性。添加的逻辑很简单，先将原容器copy一份，然后在新副本上执行写操作，之后再切换引用。 12345678910111213141516public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; // 拷贝原容器，长度为原容器长度加一 Object[] newElements = Arrays.copyOf(elements, len + 1); // 在新副本上执行添加操作 newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 删除操作同理，将除要删除元素之外的其他元素拷贝到新副本中，然后切换引用，将原容器引用指向新副本。同属写操作，需要加锁。 1234567891011121314151617181920212223public E remove(int index) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) // 如果要删除的是列表末端数据，拷贝前len-1个数据到新副本上，再切换引用 setArray(Arrays.copyOf(elements, len - 1)); else &#123; // 将除要删除元素之外的其他元素拷贝到新副本中，并切换引用 Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125; 读操作是无锁的 123456public E get(int index) &#123; return get(getArray(), index);&#125;private E get(Object[] a, int index) &#123; return (E) a[index];&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"ScheduledThreadPoolExecutor","date":"2021-09-12T16:00:00.000Z","path":"Blog/Java/并发/ScheduledThreadPoolExecutor/","text":"12345678910111213ScheduledThreadPoolExecutor scheduledThreadPoolExecutor = new ScheduledThreadPoolExecutor(1);// 延迟任务，非周期scheduledThreadPoolExecutor.schedule(() -&gt; &#123; System.out.println(\"延迟3s执行\");&#125;, 5000, TimeUnit.MILLISECONDS);// 周期任务，与任务本身执行时间有关scheduledThreadPoolExecutor.scheduleWithFixedDelay(() -&gt; &#123; System.out.println(\"1s后执行然后每2s执行一次\");&#125;, 1000, 2000, TimeUnit.MILLISECONDS);// 周期任务，与任务本身执行时间无关，任务执行时间必须小于间隔时间scheduledThreadPoolExecutor.scheduleAtFixedRate(() -&gt; &#123; System.out.println(\"1s后执行然后每2s执行一次\");&#125;, 1000, 2000, TimeUnit.MILLISECONDS); ScheduledThreadPoolExecutor是用来处理延时任务或定时任务或周期任务。延迟执行任务是依靠DelayQueue，而周期性执行任务是执行完一个任务后，再把任务仍回到任务队列中。任务的执行过程还是复用ThreadPoolExecutor，延迟的过程是在DelayedWorkQueue内部完成。 ScheduledThreadPoolExecutor内部有实现了一个特定的DelayQueue即DelayedWorkQueue，其原理与DelayQueue一样，但对任务的取消进行了优化，DelayedWorkQueue是一个无界队列，内部实现了一个PriorityQueue，它会根据time的先后时间排序，time小的排在前面，若time相同则根据sequenceNumber排序，sequenceNumber小的排在前面； 工作线程会从DelayedWorkQueue取已经到期的任务去执行，执行结束后重新设置任务的到期时间，再次放回DelayedWorkQueue。 123456789101112public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; ScheduledThreadPoolExecutor接收SchduledFutureTask类型的任务，是线程池调度任务的最小单位，提交任务时会将任务封装成SchduledFutureTask类型的任务，然后直接将任务放入DelayedWorkQueue优先级队列中，当然若核心创建的任务线程小于corePoolSize会创建任务线程，但当前线程不会直接执行任务，而非是直接创建限制来直接当前提交的任务。 12345678910111213141516171819202122232425262728public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) &#123; if (callable == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;V&gt; t = decorateTask(callable, new ScheduledFutureTask&lt;V&gt;(callable, triggerTime(delay, unit))); delayedExecute(t); return t;&#125;private void delayedExecute(RunnableScheduledFuture&lt;?&gt; task) &#123; if (isShutdown()) reject(task); else &#123; super.getQueue().add(task); if (isShutdown() &amp;&amp; !canRunInCurrentRunState(task.isPeriodic()) &amp;&amp; remove(task)) task.cancel(false); else ensurePrestart(); &#125;&#125;final void reject(Runnable command) &#123; handler.rejectedExecution(command, this);&#125;void ensurePrestart() &#123; int wc = workerCountOf(ctl.get()); if (wc &lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false);&#125; schedule最终任务的执行是通过ScheduledFutureTask的run方法来完成的。对于周期任务在run方法中通过ScheduledFutureTask.super.runAndReset()的返回值来确实是否要继续将任务添加到下一次周期中，返回false说明执行的周期任务抛出了异常，则不再将其添加到队列中。但不影响其他周期任务的执行。 setNextRunTime中对time的处理差异是scheduleAtFixedRate与scheduleWithFixedDelay的区别所在，当period为正数时是通过time直接加上period，而period为负数时triggerTime方法里面是now()加上-period。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private class ScheduledFutureTask&lt;V&gt; extends FutureTask&lt;V&gt; implements RunnableScheduledFuture&lt;V&gt; &#123; // 序列号，打破FIFO private final long sequenceNumber; // 启用执行任务的时间，即延迟时间 private long time; // 重复任务的周期，正值表示固定速率执行，负值表示固定延迟执行，0表示非重复任务。 private final long period; RunnableScheduledFuture&lt;V&gt; outerTask = this; // 延迟队列的索引 int heapIndex; ScheduledFutureTask(Runnable r, V result, long ns, long period) &#123; super(r, result); this.time = ns; this.period = period; this.sequenceNumber = sequencer.getAndIncrement(); &#125; public long getDelay(TimeUnit unit) &#123; return unit.convert(time - now(), NANOSECONDS); &#125; // 比较两个ScheduledFutureTask的大小，在DelayedWorkQueue的siftUp方法中调用，用于排序 public int compareTo(Delayed other) &#123; if (other == this) // compare zero if same object return 0; if (other instanceof ScheduledFutureTask) &#123; ScheduledFutureTask&lt;?&gt; x = (ScheduledFutureTask&lt;?&gt;)other; long diff = time - x.time; if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; else if (sequenceNumber &lt; x.sequenceNumber) return -1; else return 1; &#125; long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS); return (diff &lt; 0) ? -1 : (diff &gt; 0) ? 1 : 0; &#125; public boolean isPeriodic() &#123; return period != 0; &#125; // 设置下一次执行的时间，scheduleAtFixedRate与scheduleWithFixedDelay的区别所在 private void setNextRunTime() &#123; long p = period; if (p &gt; 0) time += p; // 上一次的时间加上周期时间 else time = triggerTime(-p); // 当前时间加上周期时间 &#125; public boolean cancel(boolean mayInterruptIfRunning) &#123; boolean cancelled = super.cancel(mayInterruptIfRunning); if (cancelled &amp;&amp; removeOnCancel &amp;&amp; heapIndex &gt;= 0) remove(this); return cancelled; &#125; // public void run() &#123; boolean periodic = isPeriodic(); if (!canRunInCurrentRunState(periodic)) cancel(false); else if (!periodic) ScheduledFutureTask.super.run(); // 若为非重复任务，则直接执行 else if (ScheduledFutureTask.super.runAndReset()) &#123; setNextRunTime(); // 若为周期任务，执行完后重新计算延迟时间，再扔回队列 reExecutePeriodic(outerTask); // 将当前任务再次入队 &#125; &#125;&#125;void reExecutePeriodic(RunnableScheduledFuture&lt;?&gt; task) &#123; if (canRunInCurrentRunState(true)) &#123; super.getQueue().add(task); // 将任务重新丢入队列中 if (!canRunInCurrentRunState(true) &amp;&amp; remove(task)) task.cancel(false); else ensurePrestart(); &#125;&#125;long triggerTime(long delay) &#123; return now() + ((delay &lt; (Long.MAX_VALUE &gt;&gt; 1)) ? delay : overflowFree(delay));&#125; 这里需要特别说明的一点是在执行周期任务时，若任务抛出异常，则将不能设置下一次执行时间，则任务将不能正常周期执行。 12345678910111213141516171819202122232425262728293031protected boolean runAndReset() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return false; boolean ran = false; int s = state; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) &#123; try &#123; c.call(); // don't set result ran = true; &#125; catch (Throwable ex) &#123; setException(ex); &#125; &#125; &#125; finally &#123; runner = null; s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; return ran &amp;&amp; s == NEW; // 若执行异常，这里返回false&#125;protected void setException(Throwable t) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); &#125;&#125; scheduleAtFixedRate只能提交固定速率执行任务。与任务本身执行时间无关，任务执行时间必须小于间隔时间。 123456789public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (period &lt;= 0) throw new IllegalArgumentException(); ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(period)); RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft); sft.outerTask = t; delayedExecute(t); return t;&#125; scheduleWithFixedDelay只能提交固定延迟执行任务，这里对delay取了负数，与任务本身执行时间有关，若任务执行时间是10s间隔时间是2s则下一次执行时间为12s。 123456789public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (delay &lt;= 0) throw new IllegalArgumentException(); ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(-delay)); RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft); sft.outerTask = t; delayedExecute(t); return t;&#125; DelayedWorkQueue12345678910static class DelayedWorkQueue extends AbstractQueue&lt;Runnable&gt; implements BlockingQueue&lt;Runnable&gt; &#123; private static final int INITIAL_CAPACITY = 16; // 队列初始容量 // 根据初始容量创建RunnableScheduledFuture类型的数组 private RunnableScheduledFuture&lt;?&gt;[] queue = new RunnableScheduledFuture&lt;?&gt;[INITIAL_CAPACITY]; private final ReentrantLock lock = new ReentrantLock(); private int size = 0; private Thread leader = null; // leader线程 // 当较新的任务在队列的头部可用时，或者新线程可能需要成为leader，则通过该条件发出信号 private final Condition available = lock.newCondition();&#125; 往队列中添加元素是通过add方法，而add方法最终是调用offer方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public boolean add(Runnable e) &#123; return offer(e);&#125;public boolean offer(Runnable x) &#123; if (x == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; e = (RunnableScheduledFuture&lt;?&gt;)x; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = size; if (i &gt;= queue.length) grow(); // 若当前元素数量大于队列长度则进行扩容，扩容50% size = i + 1; // 元素数量加1 if (i == 0) &#123; queue[0] = e; setIndex(e, 0); // 记录索引 &#125; else &#123; //把任务加入堆中，并调整堆结构，这里就会根据任务的触发时间排列 siftUp(i, e); // 把需要最早执行的任务放在前面 &#125; // 若新加入的元素就是队列头：用户提交的第一个任务，或新任务进行堆调整以后，排在队列头 if (queue[0] == e) &#123; // leader设置为null为了使在take方法中的线程在通过available.signal(); // 后会执行available.awaitNanos(delay); leader = null; available.signal(); // 加入元素以后，唤醒worker线程 &#125; &#125; finally &#123; lock.unlock(); &#125; return true;&#125;private void grow() &#123; // 扩容50% int oldCapacity = queue.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // grow 50% if (newCapacity &lt; 0) // overflow newCapacity = Integer.MAX_VALUE; queue = Arrays.copyOf(queue, newCapacity);&#125;// 循环的根据key节点与其父节点来判断，若key节点执行时间小于父节点，则将两个节点交换，使执行时间靠前的节点排列在队列的前面。private void siftUp(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; while (k &gt; 0) &#123; // 找到父节点的索引 int parent = (k - 1) &gt;&gt;&gt; 1; RunnableScheduledFuture&lt;?&gt; e = queue[parent]; // 若key节点的执行时间大于父节点的执行时间，不需要再排序了，直接放数组最后面 if (key.compareTo(e) &gt;= 0) break; // 若key.compareTo(e)&lt;0，说明key节点执行时间小于父节点执行时间，需要把父节点移到后面 queue[k] = e; setIndex(e, k); k = parent; // 设置索引为k &#125; queue[k] = key; // key设置为排序后的位置中 setIndex(key, k);&#125; 在ThreadPoolExecutor中getTask方法，工作线程会循环地调用take方法从workQueue中取任务，但定时任务却不同，若一旦getTask方法取出了任务就开始执行了，而这时可能还没有到执行的时间，故在take方法中要保证只有在到指定的执行时间时任务才可以被取走。 leader是为了减少不必要的定时等待，当一个线程成为leader时，它只等待下一个节点的时间间隔，但其它线程无限期等待。 leader线程必须在从take或poll返回之前signal其它线程，除非其他线程成为了leader。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public RunnableScheduledFuture&lt;?&gt; take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; RunnableScheduledFuture&lt;?&gt; first = queue[0]; if (first == null) // 堆的更节点都为空，说明队列为空需要阻塞 available.await(); else &#123; // 计算当前时间到执行时间的时间间隔 long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return finishPoll(first); first = null; // don't retain ref while waiting if (leader != null) // leader不为空，阻塞线程 available.await(); else &#123; // leader为空，则把leader设置为当前线程 Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; available.awaitNanos(delay); // 阻塞到执行时间 &#125; finally &#123; // 设置leader = null，让其他线程执行available.awaitNanos(delay); if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 如果leader不为空，则说明leader的线程正在执行available.awaitNanos(delay); // 如果queue[0] == null，说明队列为空 if (leader == null &amp;&amp; queue[0] != null) available.signal(); lock.unlock(); &#125;&#125;private RunnableScheduledFuture&lt;?&gt; finishPoll(RunnableScheduledFuture&lt;?&gt; f) &#123; int s = --size; // 数组长度-1 RunnableScheduledFuture&lt;?&gt; x = queue[s]; // 取出最后一个节点 queue[s] = null; if (s != 0) // 长度不为0，则从第一个元素开始排序，目的是要把最后一个节点放到合适的位置上 siftDown(0, x); setIndex(f, -1); return f;&#125;private void siftDown(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; // 使堆从k开始向下调整 int half = size &gt;&gt;&gt; 1; // 根据二叉树的特性，数组长度除以2，表示取有子节点的索引 while (k &lt; half) &#123; // 判断索引为k的节点是否有子节点 int child = (k &lt;&lt; 1) + 1; // 左子节点的索引 RunnableScheduledFuture&lt;?&gt; c = queue[child]; int right = child + 1; // 右子节点的索引 // 如果有右子节点并且左子节点的时间间隔大于右子节点，取时间间隔最小的节点 if (right &lt; size &amp;&amp; c.compareTo(queue[right]) &gt; 0) c = queue[child = right]; if (key.compareTo(c) &lt;= 0) // 如果key的时间间隔小于等于c的时间间隔，跳出循环 break; queue[k] = c; // 设置要移除索引的节点为其子节点 setIndex(c, k); k = child; &#125; queue[k] = key; // 将key放入索引为k的位置 setIndex(key, k);&#125; siftdown方法在执行完并不是有序的，但子节点的下次执行时间一定比父节点的下次执行时间要大，由于每次都会取左子节点和右子节点中下次执行时间最小的节点，故可以保证在take和poll时出队是有序的。 12345678910111213141516171819202122public boolean remove(Object x) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = indexOf(x); if (i &lt; 0) return false; setIndex(queue[i], -1); int s = --size; RunnableScheduledFuture&lt;?&gt; replacement = queue[s]; queue[s] = null; if (s != i) &#123; siftDown(i, replacement); // 从i开始向下调整 if (queue[i] == replacement) // 如果queue[i]==replacement，说明i是叶子节点 siftUp(i, replacement); // 不能保证子节点的下次执行时间比父节点的大，需要进行一次向上调整 &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"BlockingQueue阻塞队列一","date":"2021-09-09T16:00:00.000Z","path":"Blog/Java/并发/BlockingQueue阻塞队列一/","text":"BlockingQueue是一个带阻塞功能的队列，入队时若队列已满则阻塞调用者，出队时若队列为空则阻塞调用者。该接口和JDK中Queue接口是兼容的，在其基础上增加了阻塞功能，add和offer是无阻塞的，offer带超时时间的是阻塞的，put是阻塞的，remove和peek和poll是非阻塞的，poll带超时时间的是阻塞的，take是阻塞的。 123456789101112131415public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; boolean add(E e); // 将元素插入队列，队列没满的话，放入成功。否则抛出异常。非条件阻塞 boolean offer(E e); // 将元素插入队列，若队列可容纳返回true，否则false，非条件阻塞 void put(E e) throws InterruptedException; // 将元素插入队列，若队列已满，条件阻塞 // // 将元素插入队列，若队列可容纳返回true，否则false，指定时间内未能入队抛出异常，条件阻塞 boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; E take() throws InterruptedException; // 取出队列首位的元素，若队列为空，条件阻塞 // 取出队列首位元素，若不能立即取出，则可以等timeout时间，取不到则抛出异常; E poll(long timeout, TimeUnit unit) throws InterruptedException; int remainingCapacity(); boolean remove(Object o); // 将元素从队列中移除，非阻塞 public boolean contains(Object o); int drainTo(Collection&lt;? super E&gt; c); int drainTo(Collection&lt;? super E&gt; c, int maxElements);&#125; 队列的实质是一种存储数据的结构，通常用数组或链表实现，一般而言队列具备FIFO先进先出特性，也有双端队列和优先级队列，主要是入队EnQueue和出队DeQueue操作。队列分为几乎可以无限增长的无限队列和定义了最大容量的优先队列。 ArrayBlockingQueue基于数组的有界阻塞队列实现，在ArrayBlockingQueue内部，维护了一个定长数组，按照FIFO原则对元素进行排序，以便缓存队列中的数据对象，一旦创建就不能再增加容量。由构造函数可以其实现是基于一把锁和两个条件。支持对等待的生产者线程和消费者线程可选公平策略。 12345678public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); // 试图从空队列中检索元素将导致类似阻塞 notFull = lock.newCondition(); // 试图向已满队列中放入元素会导致放入操作受阻塞&#125; 12345678910111213141516public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; // 真正存储数据的数组 final Object[] items; // take、poll、peek、remove的下一个索引 int takeIndex; // put、offer、add的下一个索引 int putIndex; // 队列中元素总个数 int count; // 可重入锁，插入和获取数据都需要获取该锁 final ReentrantLock lock; // 队列不为空的条件 private final Condition notEmpty; // 队列未满的条件 private final Condition notFull;&#125; 入队操作入队操作的基础方法，putIndex相当于是一个环形操作，每调用一次enqueue方法则会给notEmpty条件队列发送一次信号。 12345678private void enqueue(E x) &#123; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) // 入队操作的下一个索引加一 putIndex = 0; // 若下一个索引等于数组长度，则从对头继续插入 count++; // 总数加一 notEmpty.signal(); // 通知消费者线程&#125; add方法最终调用的是offer的无超时时间的方法，若队列已满直接返回false。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public boolean add(E e) &#123; return super.add(e); // 最终也是调用的offer方法&#125;public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); // 获取独占锁，不能被中断 try &#123; if (count == items.length) // 若队列已满则返回false，入队失败 return false; else &#123; enqueue(e); // 将数据插入队列尾部 return true; &#125; &#125; finally &#123; lock.unlock(); // 释放独占锁 &#125;&#125;public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); // 可以被中断 try &#123; while (count == items.length) &#123; // 若队列已满，自旋等待到超时时间结束 if (nanos &lt;= 0) return false; // 若超时时间设置为小于等于0，则直接返回失败 // 条件阻塞，超过等待时间后再次去获取到锁时抛出异常（当队列不再是满队列时被放入队列中排队唤醒） nanos = notFull.awaitNanos(nanos); &#125; enqueue(e); // 插入队列 return true; &#125; finally &#123; lock.unlock(); &#125;&#125;public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); // 条件阻塞，当队列不再是满队列时被放入队列中排队唤醒 enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; 出队操作出队的基础方法，这里的takeIndex也是环形操作，每调用一次dequeue都会给notFull条件队列发送一次信号。 123456789101112private E dequeue() &#123; final Object[] items = this.items; E x = (E) items[takeIndex]; items[takeIndex] = null; // 直接将该索引处的元素置空 if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); notFull.signal(); // 消费元素后队列不再是满的，通知阻塞的生产者 return x;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 若队列中没有元素则返回空，否则将队列中元素出队 return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) &#123; if (nanos &lt;= 0) return null; // 条件阻塞，超过等待时间后再次去获取到锁时抛出异常（当队列不再是空队列时被放入队列中排队唤醒） nanos = notEmpty.awaitNanos(nanos); &#125; return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); // 若队列为空，消费线程进入等待队列 return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;public E peek() &#123; // 只查询队头数据，不删除数据 final ReentrantLock lock = this.lock; lock.lock(); try &#123; return itemAt(takeIndex); // null when queue is empty &#125; finally &#123; lock.unlock(); &#125;&#125; LinkedBlockingQueueLinkedBlockingQueue是一种基于单向链表的阻塞队列，理论上是有界的，队头和队尾是2个指针分开操作，故用了2把锁和2个条件，分别用来控制元素入队和出队的原子性，以及对应的条件变量保证多线程先入队出队操作的线程安全，同时有一个AtomicInteger原子变量记录count数。 1234567891011121314151617181920212223public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; static class Node&lt;E&gt; &#123; // 单向链表 E item; Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125; &#125; // 队列容量 private final int capacity; // 队列元素个数 private final AtomicInteger count = new AtomicInteger(); // 存放首节点 transient Node&lt;E&gt; head; // 存放尾节点 private transient Node&lt;E&gt; last; // 执行take, poll等操作时候需要获取该锁 private final ReentrantLock takeLock = new ReentrantLock(); // 当队列为空时候执行出队操作（比如take）的线程会被放入这个条件队列进行等待 private final Condition notEmpty = takeLock.newCondition(); // 执行put, offer等操作时候需要获取该锁 private final ReentrantLock putLock = new ReentrantLock(); // 当队列满时候执行进队操作（比如put)的线程会被放入这个条件队列进行等待 private final Condition notFull = putLock.newCondition();&#125; 可以很明显看到若不指定队列容量，则默认容量为Integer.MAX_VALUE相当与无界队列了。 12345678public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125;public LinkedBlockingQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null);&#125; 入队操作入队基础函数功能很简单，直接将最后个元素的next指向插入的元素，且将last指向最新的尾节点 123private void enqueue(Node&lt;E&gt; node) &#123; last = last.next = node;&#125; 插入队列的元素不能为null，在往队列中put放数据时，若队列是满的则通过notFull条件阻塞等待，消费线程从队列中取出一个元素后，判断取之前队列是满的，取完后通知生产者从notFull条件阻塞等待中唤醒，然后继续执行添加过程，发现添加后队列还没有满，则继续通知其他生产者从notFull条件阻塞等待中唤醒，添加完成后判断添加之前队列若是空的，则通知消费者notEmpty条件等待队列唤醒，继续出队操作。 为了提高并发度，用2把锁分别控制队头和队尾的操作，意味着put和put之间、take和take之间是互斥的，put和take之间不互斥，因为各自拿了一把锁，故当需要调用对方的condition的signal时，还必须加上对方的锁，也就是signalNotEmpty和signalNotFull方法。不仅put会通知take，take也会通知put，当put发现非满时也会通知其他put线程，当take发现非空时，也会通知其他take线程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; notFull.await(); // 若队列已满，则放入条件队列中排队 &#125; enqueue(node); // 入队 c = count.getAndIncrement(); // 返回入队前队列中元素的个数 if (c + 1 &lt; capacity) notFull.signal(); // 若发现队列未满，发信号去唤醒排队的生产者线程 &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) // 若队列之前元素个数为0，现插入了一个元素则需要通知消费者 signalNotEmpty();&#125;public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); &#125; enqueue(new Node&lt;E&gt;(e)); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return true;&#125;public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; if (count.get() == capacity) return false; // 若队列已经满了，直接返回false int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return c &gt;= 0;&#125;private void signalNotEmpty() &#123; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; notEmpty.signal(); // 通知消费者线程 &#125; finally &#123; takeLock.unlock(); &#125;&#125; 出队操作出队操作与入队操作是相反的，通过take从队列中取数据时，若队列是空的则通过notEmpty条件阻塞等待，生产线程往队列中添加一个元素后，判断添加之前队列是空的，添加后通知生产者从notFull条件阻塞等待中唤醒，然后继续执行添加过程，发现出队前元素个数大于1，则继续通知其他消费者线程notEmpty条件阻塞等待线程唤醒，取出完成后判断取出之前队列若是满的，则通知生产者线程从notFull条件等待队列唤醒，继续入队操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; notEmpty.await(); // 当队列为空是条件阻塞take &#125; x = dequeue(); // 队列非空时，出队 c = count.getAndDecrement(); if (c &gt; 1) // 出队之前队列中元素大于1 notEmpty.signal(); // 通知其他take线程 &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) // 若出队前队列是满的，出队后队列就不是满的了，这时需要通知put线程 signalNotFull(); return x;&#125;public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; E x = null; int c = -1; long nanos = unit.toNanos(timeout); final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; if (nanos &lt;= 0) // 若传入时间小于当前时间，则直接返回空 return null; nanos = notEmpty.awaitNanos(nanos); &#125; x = dequeue(); // 出队 c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125;public E poll() &#123; final AtomicInteger count = this.count; if (count.get() == 0) return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; if (count.get() &gt; 0) &#123; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125;private void signalNotFull() &#123; final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125;&#125; PriorityBlockingQueue队列通常是先进先出的，但PriorityQueue是按照元素的优先级从小到大出队列的，PriorityQueue中的两个元素之间需要可以比较大小，并现实了Comparable接口。 allocationSpinLock是自旋锁，用CAS操作来保证只有一个线程可以扩容队列，状态为0或者1，其中0表示当前没有在进行扩容，1表示当前正在扩容。 123456789101112131415161718192021222324public class PriorityBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; private static final int DEFAULT_INITIAL_CAPACITY = 11; // 默认初始容量 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; private transient Object[] queue; // 用数组实现的二叉小根堆 private transient int size; // 队列中元素个数 private transient Comparator&lt;? super E&gt; comparator; // 比较操作符，若未定义则使用元素自带的比较功能 private final ReentrantLock lock; // 一把锁加一个条件，没有非满的条件 private final Condition notEmpty; // 当队列中元素为空时条件阻塞 private transient volatile int allocationSpinLock; // 自旋锁，用CAS操作来保证只有一个线程可以扩容队列 private PriorityQueue&lt;E&gt; q; public PriorityBlockingQueue() &#123; this(DEFAULT_INITIAL_CAPACITY, null); &#125; public PriorityBlockingQueue(int initialCapacity) &#123; this(initialCapacity, null); &#125; public PriorityBlockingQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) &#123; if (initialCapacity &lt; 1) throw new IllegalArgumentException(); this.lock = new ReentrantLock(); this.notEmpty = lock.newCondition(); this.comparator = comparator; this.queue = new Object[initialCapacity]; &#125;&#125; PriorityBlockingQueue是使用数组实现的二叉小根堆，堆算法保证每次出队都是优先级最高的元素，基于一把锁加一个非空条件，无非满的条件，若不指定初始大小，内部会设定默认大小11，当元素个数超过该大小后，会自动扩容。 在阻塞的实现方面，和ArrayBlockingQueue的机制相似，主要区别是用数组实现了一个二叉最小根堆，从而实现按优先级从小到大出队列，另一个区别是没有notFull条件，当元素个数超出数组长度时进行扩容处理。 入队操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public void put(E e) &#123; offer(e); // never need to block&#125;public boolean offer(E e, long timeout, TimeUnit unit) &#123; return offer(e); // never need to block&#125;public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); int n, cap; Object[] array; while ((n = size) &gt;= (cap = (array = queue).length)) tryGrow(array, cap); // size超出了数组的长度，则扩容 try &#123; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) // 若没定义比较操作符，使用元素自带的比较功能 siftUpComparable(n, e, array); // 执行siftUp操作将元素入堆 else siftUpUsingComparator(n, e, array, cmp); size = n + 1; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; return true;&#125;private void tryGrow(Object[] array, int oldCap) &#123; lock.unlock(); // 必须释放然后重新获取主锁，这里通过CAS来保证并发的扩容的安全性 Object[] newArray = null; if (allocationSpinLock == 0 &amp;&amp; UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)) &#123; try &#123; // 若旧容量小于64则新容量为2*oldCap + 2，否则扩容50% int newCap = oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : (oldCap &gt;&gt; 1)); if (newCap - MAX_ARRAY_SIZE &gt; 0) &#123; // 新的容量可能溢出了，溢出抛出OOM异常 int minCap = oldCap + 1; if (minCap &lt; 0 || minCap &gt; MAX_ARRAY_SIZE) throw new OutOfMemoryError(); newCap = MAX_ARRAY_SIZE; &#125; if (newCap &gt; oldCap &amp;&amp; queue == array) newArray = new Object[newCap]; &#125; finally &#123; allocationSpinLock = 0; &#125; &#125; if (newArray == null) Thread.yield(); // 说明另一个线程正在分配，则退出 lock.lock(); if (newArray != null &amp;&amp; queue == array) &#123; queue = newArray; System.arraycopy(array, 0, newArray, 0, oldCap); &#125;&#125;private static &lt;T&gt; void siftUpComparable(int k, T x, Object[] array) &#123; Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;) x; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = array[parent]; if (key.compareTo((T) e) &gt;= 0) break; array[k] = e; k = parent; &#125; array[k] = key;&#125;private static &lt;T&gt; void siftUpUsingComparator(int k, T x, Object[] array, Comparator&lt;? super T&gt; cmp) &#123; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = array[parent]; if (cmp.compare(x, (T) e) &gt;= 0) break; array[k] = e; k = parent; &#125; array[k] = x;&#125; tryGrow扩容会先释放锁，然后用CAS控制只有一个线程可以扩容成功，扩容时若不释放锁，其他线程就不能入队和出队，大大降低了并发度，CAS失败的线程会调用Thread.yield()让出CPU，目的是为了让扩容线程扩容后优先调用lock.lock重新获取锁。 有可能yield的线程在扩容线程扩容完成前已经退出，并获取到了锁。若当前数组扩容还没完毕，当前线程会再次调用tryGrow方法。 出队操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); E result; try &#123; while ( (result = dequeue()) == null) notEmpty.await(); &#125; finally &#123; lock.unlock(); &#125; return result;&#125;public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); E result; try &#123; while ( (result = dequeue()) == null &amp;&amp; nanos &gt; 0) nanos = notEmpty.awaitNanos(nanos); &#125; finally &#123; lock.unlock(); &#125; return result;&#125;private E dequeue() &#123; int n = size - 1; if (n &lt; 0) return null; else &#123; Object[] array = queue; E result = (E) array[0]; // 因为是二叉最小根堆，即堆定即是要出队的元素 E x = (E) array[n]; array[n] = null; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) siftDownComparable(0, x, array, n); // 执行siftDown操作调整堆 else siftDownUsingComparator(0, x, array, n, cmp); size = n; return result; &#125;&#125;private static &lt;T&gt; void siftDownComparable(int k, T x, Object[] array, int n) &#123; if (n &gt; 0) &#123; Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;)x; int half = n &gt;&gt;&gt; 1; // loop while a non-leaf while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; // assume left child is least Object c = array[child]; int right = child + 1; if (right &lt; n &amp;&amp; ((Comparable&lt;? super T&gt;) c).compareTo((T) array[right]) &gt; 0) c = array[child = right]; if (key.compareTo((T) c) &lt;= 0) break; array[k] = c; k = child; &#125; array[k] = key; &#125;&#125;private static &lt;T&gt; void siftDownUsingComparator(int k, T x, Object[] array, int n, Comparator&lt;? super T&gt; cmp) &#123; if (n &gt; 0) &#123; int half = n &gt;&gt;&gt; 1; while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; Object c = array[child]; int right = child + 1; if (right &lt; n &amp;&amp; cmp.compare((T) c, (T) array[right]) &gt; 0) c = array[child = right]; if (cmp.compare(x, (T) c) &lt;= 0) break; array[k] = c; k = child; &#125; array[k] = x; &#125;&#125; DelayQueueDelayQueue即延迟队列，是一个按时间从小到大出队的PriorityQueue优先级队列，所谓的延迟时间，就是通过未来将要执行的时间减去当前时间，故放入DelayQueue中的元素，必须实现Delayed接口。 123public interface Delayed extends Comparable&lt;Delayed&gt; &#123; long getDelay(TimeUnit unit);&#125; 若getDelay返回值小于或等于0，则说明元素到期，需要从队列中拿出来执行，该接口首先继承了Comparable接口，故要实现该接口，必须实现Comparable接口。DelayQueue是基于一把锁加一个非空条件。 123456public class DelayQueue&lt;E extends Delayed&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt; &#123; private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;(); // 优先级队列 private Thread leader = null; private final transient ReentrantLock lock = new ReentrantLock(); // 一把锁 + 一个非空条件 private final Condition available = lock.newCondition();&#125; 出队操作不仅队列为空时阻塞，且堆顶元素的延迟时间没有到时也会阻塞，使用leader变量记录了等待堆顶元素的第一个线程，通过getDelay可知堆顶元素何时到期，不必无限期等待，可通过available.awaitNanos(delay)等待一个有期限的时间，只有还有其他线程也在等待堆顶元素时即leader != null，才需要无限期等待。 123456789101112131415161718192021222324252627282930313233public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; E first = q.peek(); // 取出二叉堆堆顶元素，也就是延迟最小的元素 if (first == null) available.await(); // 若队列为空则take线程阻塞 else &#123; long delay = first.getDelay(NANOSECONDS); // 计算延时时间 if (delay &lt;= 0) // 堆顶元素的延时时间小于或等于0，出队列，返回 return q.poll(); first = null; // 等待时不要保留引用 if (leader != null) // 若已经有其他线程在等待该元素，则无限期阻塞 available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; available.awaitNanos(delay); // 否则阻塞有限期时间 &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; q.peek() != null) available.signal(); // 自己是leader，已经获取了堆顶元素，唤醒其他线程 lock.unlock(); &#125;&#125; 入队操作不是每放入一个元素都需要通知等待线程，只有当延迟时间是最小的，在堆顶时，才有必要通知等待线程。 1234567891011121314151617181920212223public boolean add(E e) &#123; return offer(e);&#125;public boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); // 元素放入二叉堆 if (q.peek() == e) &#123; // 若放进去的元素刚好在堆顶，则说明放入的元素延迟时间最小，则需要通知等待线程 leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125;public void put(E e) &#123; offer(e);&#125;public boolean offer(E e, long timeout, TimeUnit unit) &#123; return offer(e);&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"线程池原理","date":"2021-09-07T16:00:00.000Z","path":"Blog/Java/并发/线程池原理/","text":"线程线程是调度CPU资源的最小单位，线程模型分为KLT模型与ULT模型，JVM使用的KLT模型，Java线程与OS线程保持1:1的映射关系，也就是说有一个java线程也会在操作系统里有一个对应的线程。 线程池线程池可以重用存在的线程，减少线程创建，消亡的开销，提高性能，提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 线程池框架中最基础的接口是Executor，其定义了用于执行Runnable的execute方法，在其子类ExecutorService中定义了线程池的具体行为： 1234567891011121314151617public interface Executor &#123; void execute(Runnable command);&#125;public interface ExecutorService extends Executor &#123; void shutdown(); // 在完成已提交的任务后封闭办事，不再接管新任务 List&lt;Runnable&gt; shutdownNow(); //停止所有正在履行的任务并封闭办事 boolean isShutdown(); // 测试是否该ExecutorService已被关闭 boolean isTerminated(); // 测试是否所有任务都履行完毕了 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); // 可用来提交Callable或Runnable任务，并返回代表此任务的Future对象 &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); // 可用来提交Callable或Runnable任务，并返回代表此任务的Future对象 Future&lt;?&gt; submit(Runnable task); // 可用来提交Callable或Runnable任务，并返回代表此任务的Future对象 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 线程池关闭线程池的运行状态和线程池中有效线程数都是他通过ctl一个字段来保存的，其高3位保存运行状态，低29位保存有效线程数。 1234567891011121314151617181920212223public class ThreadPoolExecutor extends AbstractExecutorService &#123; // 线程池的运行状态和线程池中有效线程的数量，高3位保存runState，低29位保存workerCount private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; // 29 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // 线程池容量 // 初始化状态，能够接收新任务，以及对已添加的任务进行处理 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; //高3位为111 // 不接收新任务，但能处理已添加的任务，调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; //高3位为000 // 不接收新任务，不处理已添加任务，且中断正在处理的任务，调用shutdownNow()时线程池由(RUNNING or SHUTDOWN) -&gt; STOP。 private static final int STOP = 1 &lt;&lt; COUNT_BITS; //高3位为001 // 当所有的任务已终止，线程池会变为TIDYING状态，会执行钩子函数terminated()，默认是空函数 // SHUTDOWN状态下，阻塞队列为空且线程池中执行的任务也为空时，则由SHUTDOWN -&gt; TIDYING，在STOP状态下，线程池中执行的任务为空时，则由STOP -&gt; TIDYING。 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; //高3位为010 // 线程池彻底终止，则为TERMINATED状态，TIDYING状态下，执行完terminated()之后，由TIDYING -&gt; TERMINATED private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; //高3位为011 // 获取运行状态 private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; // 取出低29位的值，表示当前活动的线程数 private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; // 获取运行状态和活动线程数的值 private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;&#125; 关闭一个线程池时，有的线程还在执行某个任务，有的调用者正在向线程池提交任务，且队列中可能还有未执行的任务，故关闭过程不可能瞬时，而是需要一个平滑的过渡。 RUNNING：线程池的初始化状态，能够接收新任务，能对已添加的任务进行处理； SHUTDOWN：调用线程池的shutdown接口时，线程池由RUNNING切换成SHUTDOWN状态，不接收新任务，但能处理已添加的任务； STOP：调用线程池shutdownNow接口，线程池由RUNNING或SHUTDOWN切换成STOP状态，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务； TIDYING：线程池在SHUTDOWN状态，阻塞队列为空并且线程池中执行的任务也为空，由SHUTDOWN切换为TIDYING状态；线程池在STOP状态，线程池中执行的任务为空，由STOP切换为TIDYING状态；当所有的任务已终止，ctl记录的任务数量为0，线程池切换为TIDYING状态。切换为TIDYING状态时，执行钩子函数terminated()，terminated()在ThreadPoolExecutor类中是空的，若想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()方法； TERMINATED：线程池彻底终止状态，线程池在TIDYING状态时，执行terminated()之后，就会由TIDYING切换为TERMINATED状态； 状态迁移只会从小到大-1，0，1，2，3迁移不会逆向迁移。除terminated之外，线程池还提供其他几个钩子函数，这些钩子函数实现都是空的，若要实现自己的线程池，可重写这几个函数。 123protected void beforeExecute(Thread t, Runnable r) &#123; &#125;protected void afterExecute(Runnable r, Throwable t) &#123; &#125;protected void terminated() &#123; &#125; 调用showdown或shutdownNow后，线程池并不会立即关闭，还需要循环调用awaitTermination来等待线程池真正终止。正确关闭线程池的步骤如下： 123456789executor.showdown(); // 或者executor.shutdownNow(); try &#123; boolean loop = true; do &#123; // 阻塞等待，直到线程池所有任务结束 loop = !executor.awaitTermination(2, TimeUnit.SECONDS); &#125; while (loop);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; awaitTermination内部是通过不断循环判断线程池是否到达最终状态TERMINATED，若是则返回，否则通过termination条件变量阻塞一段时间，后继续判断。 1234567891011121314151617181920private final Condition termination = mainLock.newCondition();public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (;;) &#123; if (runStateAtLeast(ctl.get(), TERMINATED)) // 判断状态是否是TERMINATED return true; // 若是TERMINATED状态直接返回true if (nanos &lt;= 0) return false; // 超时返回false nanos = termination.awaitNanos(nanos); // 条件等待 &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125;private static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s;&#125; 可从下面Worker的工作情况可知，Worker初始状态state为-1，只有调用unlock后state才变为0，一个Worker在执行任务前会加锁，意味着可以通过是否持有锁判断出线程是否处于空闲状态，tryLock调用成功说明线程处于空闲状态，向其发送中断信号。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 检测是否有关闭线程池的权限 advanceRunState(SHUTDOWN); // 把状态设置到SHUTDOWN interruptIdleWorkers(); // 只中断空闲线程 onShutdown(); // 钩子函数，空实现 &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125;private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // tryLock调用成功说明线程处于空闲状态，调用不成功说明线程当前持有锁，正在执行某个任务 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125;private void checkShutdownAccess() &#123; SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkPermission(shutdownPerm); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) security.checkAccess(w.thread); &#125; finally &#123; mainLock.unlock(); &#125; &#125;&#125;private void advanceRunState(int targetState) &#123; for (;;) &#123; int c = ctl.get(); if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) break; &#125;&#125; shutdownNow 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 检测是否有关闭线程池的权限 advanceRunState(STOP); // 把状态设置到STOP interruptWorkers(); // 只中断所有线程 tasks = drainQueue(); // 清空队列 &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125;private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) w.interruptIfStarted(); // 不管线程是否在执行中，一律发送中断信号 &#125; finally &#123; mainLock.unlock(); &#125;&#125;void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125;&#125;private List&lt;Runnable&gt; drainQueue() &#123; BlockingQueue&lt;Runnable&gt; q = workQueue; ArrayList&lt;Runnable&gt; taskList = new ArrayList&lt;Runnable&gt;(); q.drainTo(taskList); if (!q.isEmpty()) &#123; for (Runnable r : q.toArray(new Runnable[0])) &#123; if (q.remove(r)) taskList.add(r); &#125; &#125; return taskList;&#125; shutdown和shutdownNow都调用了tryTerminate方法，tryTerminate不会强制终止线程池，只是做一下检测，当worker为0时，workQueue为空时，先把状态切换到TIDYING，然后调用钩子函数terminated()，当执行完成时把状态改为TERMINATED，接着调用termination.signalAll()通知前面阻塞在awaitTermination的所有调用者线程。 123456789101112131415161718192021222324252627final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 若线程池为RUNNING、TIDYING、TERMINATED等状态，或线程池为SHUTDOWN状态且队列不为空，则直接退出 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; terminated(); &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; 核心配置参数12345678910111213141516171819public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 一般任务性质类型分为CPU密集型也叫计算密集型和IO密集型，CPU密集型的任务线程数一般设置为：线程数 = CPU核数 + 1；IO密集型任务线程数一般设置为：线程数 = ((线程等待时间 / 线程CPU时间) + 1) * CPU数目 核心数据结构通过阻塞队列workQueue存放线程池排队任务，通过mainLock独占锁对线程池内部各种变量进行互斥访问控制。 通过Worker封装线程，线程池中的每一个线程被封装成一个Worker对象，线程池维护的其实就是一组Worker对象，Worker中firstTask用来保存传入任务；thread是在调用构造方法时通过ThreadFactory来创建的线程，是用来处理任务的线程。通过getThreadFactory().newThread(this)来新建一个线程，newThread方法传入的参数是this，因为Worker本身实现了Runnable接口，也就是一个线程，所以一个Worker对象在启动时会调用Worker类的run方法。 Worker继承于AQS，用于判断线程是否空闲以及是否可被中断，从tryAcquire方法可看出Worker是不可重入的，这也是为什么不直接使用ReentrantLock的原因。之所以设置为不可重入，是因为不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁，否则会中断正在运行的线程。 构造方法中执行了setState(-1)把state变量设置为-1，是为了禁止在执行任务前对线程进行中断，AQS中默认的state是0，若刚创建一个Worker对象，还没有执行任务时，不应该被中断。所以在runWorker方法中会先调用Worker对象的unlock方法将state设置为0。 lock方法一旦获取了独占锁，表示当前线程正在执行任务中，则不应该中断线程；若该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断； 线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态； 1234567891011121314151617181920212223242526272829303132333435363738public class ThreadPoolExecutor extends AbstractExecutorService &#123; private final BlockingQueue&lt;Runnable&gt; workQueue; // 存放任务的阻塞队列 private final ReentrantLock mainLock = new ReentrantLock(); // 对线程池内部各种变量进行互斥访问控制 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // 线程集合 private final Condition termination = mainLock.newCondition(); private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; final Thread thread; // Worker封装的线程 Runnable firstTask; // Worker接收到的第一个任务，即保存传入的任务 volatile long completedTasks; // Worker执行完毕的任务个数 Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 以当前Worker创建一个thread &#125; public void run() &#123; runWorker(this); &#125; protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; // 不可重入 if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; &#125;&#125; 在Worker的run方法中调用runWorker方法while循环从队列中获取任务，执行原始任务的run方法而不是start方法，从而达到Worker线程复用的目的，如果任务执行异常会导致Worker线程退出，在finally中会先移除就的Worker再创建一个新的Worker线程。 线程池原理每次向线程池提交任务时，首先判断当前线程数是否大于或等于corePoolSize，若小于则新建线程执行，若大于则判断队列是否已满，若未满则放入队列，若已满，判断当前线程数是否大于或等于maximumPoolSize，若小于则新建线程执行，若大于则执行拒绝策略。 值得注意的是，当往阻塞队列中放任务时addWorker(null, false)并没有传入任务，因为任务已经被添加到workQueue中了，worker在执行时会直接从workQueue中获取任务。也是为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 当前活动线程数小于corePoolSize，则新建一个线程放入线程池中，并把任务添加到该线程中 if (workerCountOf(c) &lt; corePoolSize) &#123; // 第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断 if (addWorker(command, true)) return; // 若添加失败直接返回 // 若果添加失败，则重新获取ctl值 c = ctl.get(); &#125; // 若当前线程数大于或等于corePoolSize，且通过阻塞队列offer方法将任务放入队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 重新获取ctl值 int recheck = ctl.get(); // 再次判断线程池的运行状态，若不是运行状态，由于之前把command已添加到workQueue中，需移除该command，执行后通过拒绝策略对该任务进行处理，整个方法返回 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 调用具体配置的拒绝策略 // 获取线程池中有效线程数，若为0则执行addWorker方法，若workerCount大于0则直接返回，在workQueue中新增的command会在将来的某个时刻被执行 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 放入队列失败：若线程池已经不是RUNNING状态，或workerCount &gt;= corePoolSize且workQueue已满， else if (!addWorker(command, false)) reject(command); // 添加失败直接执行拒绝策略&#125;// firstTask新开一个线程，若core为true则corePoolSize为上界，否则maximumPoolSize为上界private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 获取运行状态 // 只要状态大于或等于SHUTDOWN，则说明线程池进入了关闭过程，此时不再接收新任务，则添加失败 // SHUTDOWN状态下firstTask不为空，则返回false，firstTask为空且workQueue为空，队列中已经无任务，无需再添加线程 if (rs &gt;= SHUTDOWN &amp;&amp; !(rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; !workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 当前活动的线程数 // 若工作线程数大于容量或大于设定的核心线程数或最大线程数，则添加失败 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 若将工作线程数加一成功，则直接退出内存和外层自旋，执行下面的逻辑 if (compareAndIncrementWorkerCount(c)) break retry; // 退出内层和外层循环 c = ctl.get(); // Re-read ctl // 若运行状态发生改变，需要重试外循环 if (runStateOf(c) != rs) continue retry; // 否则CAS由于workerCount变化而失败；重试内循环 &#125; &#125; // workerCount成功加一，则开始添加线程操作 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); // 根据firstTask来创建Worker对象 final Thread t = w.thread; // 每一个Worker对象都会创建一个线程 if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); // 若rs是RUNNING状态或rs是SHUTDOWN状态且firstTask为null，向线程池中添加线程 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 预先检查t是否可启动 throw new IllegalThreadStateException(); workers.add(w); // 把线程加入到线程集合 int s = workers.size(); if (s &gt; largestPoolSize) // largestPoolSize记录着线程池中出现过的最大线程数量 largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); // 若成功加入到线程集合则启动线程，这里启动是调用Worker的run方法 workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); // 加入失败或启动失败，将workerCount减一且将 &#125; return workerStarted;&#125;private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) // 若是启动失败造成的需要将worker移除 workers.remove(w); decrementWorkerCount(); // workerCount减一 tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125;private void decrementWorkerCount() &#123; do &#123;&#125; while (! compareAndDecrementWorkerCount(ctl.get()));&#125; addWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize。 rs == SHUTDOWN的情况下不会接受新提交的任务，故在firstTask不为空时会=返回false；若firstTask为空，且workQueue也为空，队列中已经没有任务了，不需要再添加线程了故返回false。 任务执行过程任务提交过程中会开启一个新的Worker线程，并把任务本身作为firstTask赋给该Worker，但对于一个Worker不仅执行一个任务，而是不断从队列中取出任务执行。 getTask中第二个if判断目的是控制线程池的有效线程数量。在执行execute方法时，若当前线程池的线程数量超过了corePoolSize且小于maximumPoolSize，且workQueue已满时，则可以增加工作线程，但这时若超时没有获取到任务，也就是timedOut为true的情况，说明workQueue已经为空了，说明当前线程池中不需要那么多线程来执行任务了，可以把多于corePoolSize数量的线程销毁掉，保持线程数量在corePoolSize即可。是runWorker方法执行完之后，也就是Worker中run方法执行完，由JVM自动回收会销毁空闲线程。 wc &gt; maximumPoolSize的情况是因为可能在此方法执行阶段同时执行了setMaximumPoolSize方法，timed &amp;&amp; timedOut如果为true，表示当前操作需要进行超时控制，且上次从阻塞队列中获取任务发生了超时。wc == 1时说明当前线程是线程池中唯一的一个线程。 getTask方法返回null时，在runWorker方法中会跳出while循环，该while循环就是线程复用的关键，然后会执行processWorkerExit方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public void run() &#123; runWorker(this);&#125;final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; // 获取第一个任务 w.firstTask = null; w.unlock(); // 初始时state变量为-1，不允许被中断，unlock方法将state设置为0，允许中断 boolean completedAbruptly = true; // 是否因为异常退出循环 try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // 执行任务前加锁，对应shutdown时的tryLock // 若池正在停止，确保线程被中断；若没有则要确保线程不被中断。需要在第二种情况下重新检查以在清除中断的同时处理 shutdownNow竞争 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); // 给自己发中断信号 try &#123; beforeExecute(wt, task); // 任务之前的钩子函数，目前实现为空 Throwable thrown = null; try &#123; task.run(); // 执行任务代码，线程复用的关键 &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); // 任务之后的钩子函数，目前实现为空 &#125; &#125; finally &#123; task = null; w.completedTasks++; // 成功完成任务，completedTasks累加 w.unlock(); // 释放锁 &#125; &#125; completedAbruptly = false; // 用于判断Worker是正常退出还是中断或异常退出 &#125; finally &#123; processWorkerExit(w, completedAbruptly); // Worker退出 &#125;&#125;private Runnable getTask() &#123; boolean timedOut = false; // timeOut表示上次从阻塞队列中取任务时是否超时 for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 非RUNNING状态，rs&gt;=STOP表示线程池是否正在stop， // 当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列中添加任务 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // timed变量用于判断是否需要进行超时控制，对于超过核心线程数的线程，需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) // 释放空闲线程，keepAliveTime的效用 return null; continue; &#125; try &#123; // 通过阻塞队列的poll方法进行超时控制，若在keepAliveTime时间内没有获取到任务，则返回null Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; // 若 r == null，说明已经超时，timedOut设置为true &#125; catch (InterruptedException retry) &#123; timedOut = false; // 若获取任务时当前线程发生了中断，则设置timedOut为false并返回循环重试 &#125; &#125;&#125;private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 若线程执行时没有出现异常，说明在getTask()方法中已经已经对workerCount进行了减1操作，这里就不必再减了 if (completedAbruptly) // 若为中断或异常退出，需要将workerCount减1 decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; //统计完成的任务数 workers.remove(w); // 从workers中移除，也就表示着从线程池中移除了一个工作线程 &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态进行判断是否结束线程池，和shutdown、shutdownNow一样，每个线程在结束时都会尝试调用该函数，看是否可以终止整个线程池 tryTerminate(); // 当线程池是RUNNING或SHUTDOWN状态时，如果worker是异常结束，那么会直接addWorker // 如果allowCoreThreadTimeOut=true，并且等待队列有任务，至少保留一个worker // 如果allowCoreThreadTimeOut=false，workerCount不少于corePoolSize int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125;private void decrementWorkerCount() &#123; do &#123;&#125; while (! compareAndDecrementWorkerCount(ctl.get()));&#125;private boolean compareAndDecrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect - 1);&#125; 拒绝策略123public interface RejectedExecutionHandler &#123; void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; AbortPolicy是线程池的默认拒绝策略，直接抛出异常 123456public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); &#125;&#125; CallerRunsPolicy使用调用者线程执行任务 12345678public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125; DiscardOldestPolicy丢弃队列尾部排队的线程，即排队最久的，不抛异常 123456789public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; DiscardPolicy丢弃当前任务，不抛异常 12345public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125;","tags":[{"name":"线程池","slug":"线程池","permalink":"https://yaoyinglong.github.io/tags/线程池/"},{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"同步工具类","date":"2021-09-06T16:00:00.000Z","path":"Blog/Java/并发/同步工具类/","text":"下面的方法基本都是会用到下面的两个方法123456789101112131415public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); // park阻塞 &#125; public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); // 唤醒后续节点 return true; &#125; return false; &#125;&#125; Semaphore通常将Semaphore称为信号量， 可控制同时访问特定资源的线程数，通过协调各个线程，以保证合理的使用资源。常用方法： 1234567891011121314151617public class Semaphore implements java.io.Serializable &#123; public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125; // permits表示许可线程数量， fair表示公平性 public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; // 获取一个令牌，在获取到令牌或被其他线程调用中断之前，线程一直处于阻塞状态 public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; // 释放一个令牌，唤醒一个获取令牌不成功的阻塞线程 public void release() &#123; sync.releaseShared(1); &#125;&#125; 当初始资源为1时，Semaphore退化为排他锁，Semaphore实现和锁时分类似，也是基于AQS，同样有公平与非公平之分，只有尝试获取锁的地方有公平与非公平之分，且唯一区别在于是否需要去判断队列中是否有元素排队，释放锁不区分公平与非公平的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Semaphore implements java.io.Serializable &#123; private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; Sync(int permits) &#123; setState(permits); // 可用资源的总数即state的初始值 &#125; final int getPermits() &#123; return getState(); &#125; final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; // 与公平锁的唯一区别在于，这里不需要去判断队列中是否有元素排队 int available = getState(); // 获取当前可用资源数量 int remaining = available - acquires; // remaining小于0直接返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) // remaining&gt;=0尝试更新资源数 return remaining; &#125; &#125; protected final boolean tryReleaseShared(int releases) &#123; // AQS模板方法 for (;;) &#123; int current = getState(); // 获取当前可用资源数量 int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); if (compareAndSetState(current, next)) // CAS加操作更新资源数 return true; &#125; &#125; final void reducePermits(int reductions) &#123; for (;;) &#123; int current = getState(); int next = current - reductions; if (next &gt; current) // underflow throw new Error(\"Permit count underflow\"); if (compareAndSetState(current, next)) return; &#125; &#125; final int drainPermits() &#123; for (;;) &#123; int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; &#125; &#125; &#125; static final class NonfairSync extends Sync &#123; NonfairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; // AQS模板方法 return nonfairTryAcquireShared(acquires); &#125; &#125; static final class FairSync extends Sync &#123; FairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; // AQS模板方法 for (;;) &#123; // 与非公平锁的唯一区别在于，这里需要去判断队列中是否有元素排队 if (hasQueuedPredecessors()) return -1; // 若队列中有元素排队直接返回-1 int available = getState(); // 获取当前可用资源数量 int remaining = available - acquires; // remaining小于0直接返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) // remaining&gt;=0 CAS减操作更新资源数 return remaining; &#125; &#125; &#125;&#125; 资源的总数即state的初始值，在acquire中对state进行CAS减操作，减到0之后线程阻塞，release中对state进行CAS加操作。 123456789Semaphore semaphore = new Semaphore(2);new Thread(() -&gt;&#123; try &#123; semaphore.acquire(); // 获取公共资源 Thread.sleep(5000); semaphore.release(); // 释放公共资源 &#125; catch (InterruptedException e) &#123; &#125;&#125;).start(); CountDownLatch12345678910111213141516long startTime = System.currentTimeMillis();CountDownLatch countDownLatch = new CountDownLatch(10);for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; try &#123; Integer sleep = new Random().nextInt(5000); System.out.println(\"index:\" + Thread.currentThread().getName() + \" sleep:\" + sleep); Thread.sleep(sleep); &#125; catch (Exception e) &#123; &#125; finally &#123; countDownLatch.countDown(); &#125; &#125;).start();&#125;countDownLatch.await();System.out.println(\"所有线程执行完毕:\" + (System.currentTimeMillis() - startTime)); CountDownLatch是一个同步工具类，用来协调多个线程之间的同步，能够使一个线程在等待另外一些线程完成各自工作之后，再继续执行。初始值为线程的数量，每完成一个线程后计数器减一，当计数器的值为0时，表示所有的线程都已经完成任务，然后在CountDownLatch上等待的线程就可以恢复执行接下来的任务。 CountDownLatch是一次性的，计算器的值只能在构造方法中初始化一次，当CountDownLatch使用完毕后，它不能再次被使用。CountDownLatch没有公平与非公平之分。 123456789101112131415161718192021222324252627282930313233343536373839public class CountDownLatch &#123; private static final class Sync extends AbstractQueuedSynchronizer &#123; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; // AQS模板方法 return (getState() == 0) ? 1 : -1; // 直接判断当前计数器是否为0，若不为0则阻塞 &#125; protected boolean tryReleaseShared(int releases) &#123; // AQS模板方法 for (;;) &#123; int c = getState(); if (c == 0) // 若计数器已经为0，直接返回false return false; int nextc = c-1; if (compareAndSetState(c, nextc)) // CAS减 return nextc == 0; // 判断计数器是否为0 &#125; &#125; &#125; private final Sync sync; public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count); &#125; public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; public void countDown() &#123; sync.releaseShared(1); &#125;&#125; CyclicBarrierCyclicBarrier栅栏屏障让一组线程到达一个屏障时被阻塞，也可叫同步点，直到最后一个线程到达屏障时，屏障才会打开，所有被屏障拦截的线程才会继续运行。 123456789101112131415CyclicBarrier cyclicBarrier = new CyclicBarrier(11, () -&gt; System.out.println(Thread.currentThread().getName() + \"：所有线程到达屏障，开始执行任务\"));for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; Integer sleep = new Random().nextInt(10000); System.out.println(\"index:\" + Thread.currentThread().getName() + \" sleep:\" + sleep); try &#123; Thread.sleep(sleep); cyclicBarrier.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start();&#125;cyclicBarrier.await();System.out.println(Thread.currentThread().getName() + \"：全部到达屏障.\"); CyclicBarrier是通过ReentrantLock和Condition组合实现的，构造方法中的Runnable参数表示最后一个线程到达要做的任务，线程调用await()表示自己已经到达栅栏，BrokenBarrierException表示栅栏已经被破坏，破坏原因可能是其中某个线程await()时被中断或者超时。一旦栅栏被破坏就不能再被重复使用了，所有等待的线程都将抛出异常。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class CyclicBarrier &#123; private final ReentrantLock lock = new ReentrantLock(); private final Condition trip = lock.newCondition(); private final int parties; private final Runnable barrierCommand; private Generation generation = new Generation(); private static class Generation &#123; boolean broken = false; // 栅栏是否已经被破坏 &#125; // 当所有节点已经到达栅栏时，重置栅栏 private void nextGeneration() &#123; trip.signalAll(); // 将阻塞在Condition等待队列中的元素移动到同步等待队列中 count = parties; // 重置count generation = new Generation(); &#125; private void breakBarrier() &#123; // 栅栏被破坏时调用 generation.broken = true; // 标识栅栏已被破坏 count = parties; // 栅栏被破坏后重置count trip.signalAll(); // 将阻塞在Condition等待队列中的元素移动到同步等待队列中 &#125; // parties表示屏障拦截的线程数量, Runnable表示最后一个线程到达要做的任务 public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; &#125; public CyclicBarrier(int parties) &#123; this(parties, null); &#125; public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125; &#125; public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; return dowait(true, unit.toNanos(timeout)); &#125; private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock(); // 获取锁 try &#123; final Generation g = generation; if (g.broken) // 若发生中断该属性设置为true，直接抛出异常 throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; breakBarrier(); // 若发生中断，打破栅栏 throw new InterruptedException(); &#125; int index = --count; if (index == 0) &#123; // 判断是否是最后一个到达的线程 boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) command.run(); // 若已经是最后一个线程了，执行设定任务 ranAction = true; nextGeneration(); // 重置栅栏 return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; for (;;) &#123; // 不是最后一个到达线程 try &#123; if (!timed) // 是否有超时 trip.await(); // 没有则放入条件队列中等待 else if (nanos &gt; 0L) // 超时时间nanos大于0，则等待设置nanos nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; Thread.currentThread().interrupt(); &#125; &#125; if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); // 唤醒从Condition等待队列中移动到同步队列中的元素 &#125; &#125;&#125; Exchanger当一个线程运行到exchange()方法时会阻塞，另一个线程运行到exchange()时，二者交换数据，然后执行后面的程序。 1234567891011121314final Exchanger&lt;Integer&gt; exchanger = new Exchanger&lt;Integer&gt;();for (int i = 0; i &lt; 10; i++) &#123; final Integer num = i; new Thread(() -&gt; &#123; System.out.println(\"线程：Thread_\" + Thread.currentThread().getName() + \"数据：\" + num); try &#123; Integer exchangeNum = exchanger.exchange(num); Thread.sleep(1000); System.out.println(\"线程：Thread_\" + Thread.currentThread().getName() + \"原先数据：\" + num + \" , 交换后的数据：\" + exchangeNum); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start();&#125; Phaser","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"},{"name":"Lock","slug":"Lock","permalink":"https://yaoyinglong.github.io/tags/Lock/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"ReentrantReadWriteLock原理","date":"2021-09-06T16:00:00.000Z","path":"Blog/Java/并发/ReentrantReadWriteLock原理/","text":"和互斥锁相比，ReentrantReadWriteLock读写锁是读线程之间不相互互斥，写线程与写线程和读线程间互斥，ReentrantReadWriteLock的父接口是ReadWriteLock。使用ReadWriteLock时是获得内部的读锁和写锁，然后分别调用lock/unlock。 1234public interface ReadWriteLock &#123; Lock readLock(); Lock writeLock();&#125; 表面上看readLock和writeLock是两把锁，实际上它们只是同一把锁的两个视图，线程分为两类，读线程和写线程，读线程间不互斥，读线程与写线程互斥，写线程间互斥。从源码看readLock和writeLock实际共用同一个sync对象。Sync对象同互斥锁一样分为公平锁与非公平锁两种策略，且继承自AQS。 1234567891011121314151617181920212223242526public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; private final ReentrantReadWriteLock.ReadLock readerLock; private final ReentrantReadWriteLock.WriteLock writerLock; final Sync sync; public ReentrantReadWriteLock() &#123; this(false); &#125; public ReentrantReadWriteLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); &#125; public static class ReadLock implements Lock, java.io.Serializable &#123; private final Sync sync; protected ReadLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; &#125; public static class WriteLock implements Lock, java.io.Serializable &#123; private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; &#125;&#125; 同互斥锁一样，读写锁也是用state变量来表示锁状态的，但含义完全不同，在Sync内部对state进行了重新定义，由于无法用一次CAS同事操作两个int变量，故state低16位用来记录写锁，若低16位的值等于5，表示一个写线程重入了5次；高16为用来记录读锁，若高16位的值等于5，表示5个线程都拿到了该锁或一个读线程重入了5次；state=0时表示没有线程持有锁；state&gt;0表示要么有线程持有读锁，要么有线程持有写锁： 12345678910abstract static class Sync extends AbstractQueuedSynchronizer &#123; static final int SHARED_SHIFT = 16; static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; // 持有读锁的线程重入次数，高16位记录读锁 static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125; // 持有写锁的线程重入次数，低16位记录写锁 static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125;&#125; 在AQS中有acquire/release和acquireShared/releaseShared两对模板方法，互斥锁和读写锁中的写锁都是基于acquire/release模板方法来实现的，读写锁中的读锁是基于acquireShared/releaseShared模板方法来实现的。 1234567891011121314151617181920212223242526public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125;&#125; 将读/写、公平与非公平进行排列组合，有四种组合方式，tryAcquireShared、tryAcquire都是在Sync中实现的，Sync中的这两个方法又是模板方法，在FairSync和NonfairSync中分别实现。 读锁的公平实现：Sync.tryAcquireShared + FairSync中两个覆写的子函数 读锁的非公平实现：Sync.tryAcquireShared + NonfairSync中两个覆写的子函数 写锁的公平实现：Sync.tryAcquire+ FairSync中两个覆写的子函数 写锁的非公平实现：Sync.tryAcquire+ NonfairSync中两个覆写的子函数 1234567891011121314151617181920212223242526272829303132static final class NonfairSync extends Sync &#123; final boolean writerShouldBlock() &#123; // 写线程抢锁时是否应该阻塞 return false; // 写线程在抢锁之前永远不被阻塞，是非公平 &#125; final boolean readerShouldBlock() &#123; // 读线程抢锁之前是否应该阻塞 return apparentlyFirstQueuedIsExclusive(); // 读线程在抢锁时，当队列中第一个元素是写线程时，要阻塞 &#125;&#125;static final class FairSync extends Sync &#123; final boolean writerShouldBlock() &#123; // 写线程抢锁时是否应该阻塞 return hasQueuedPredecessors(); // 写线程在抢锁之前，若队列中有其他线程排队，要阻塞，是公平的 &#125; final boolean readerShouldBlock() &#123; // 读线程抢锁之前是否应该阻塞 return hasQueuedPredecessors(); // 读线程在抢锁之前，若队列中有其他线程排队，要阻塞，是公平的 &#125;&#125;// 查询当队列中第一个元素是否是独占模式final boolean apparentlyFirstQueuedIsExclusive() &#123; Node h, s; return (h = head) != null &amp;&amp; (s = h.next) != null &amp;&amp; !s.isShared() &amp;&amp; // 第一元素为非共享模式 s.thread != null;&#125;// 查询当前队列中是否有元素排队public final boolean hasQueuedPredecessors() &#123; Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 对于公平锁，不论是读锁还是写锁，只要队列中有其他线程在排队，都不能直接去抢锁，要排在队列尾部； 对于非公平锁，读锁与写锁实现略有差异，state=0时写线程能抢锁，state&gt;0且持有写锁的线程是它自己能再次重入；因为读线程间不互斥，若当前是读线程持有锁，若其他读线程还非公平去一直抢锁，可能导致写线程永远拿不到锁，故对读线程的非公平做了一些约束。当队列第一个元素时写线程时，读线程也要阻塞一下不能直接的去抢锁。 WriteLock公平与非公平实现WriteLock写锁是排他锁，实现策略与互斥锁类似，重写了tryAcquire/tryRelease方法，若获取锁失败同互斥锁一样将该任务放入队列中排队处理。 123456789101112131415161718192021222324252627282930313233343536373839public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; public static class WriteLock implements Lock, java.io.Serializable &#123; public void lock() &#123; sync.acquire(1); &#125; &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125;&#125;public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; abstract static class Sync extends AbstractQueuedSynchronizer &#123; protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); // 写线程只能有一个，但写线程能多次重入 if (c != 0) &#123; // 说明写线程或读线程持有锁 // w == 0，说明锁被读线程持有直接，返回去队列中排队 // w != 0，且持有写锁的线程不是当前线程，返回去队列中排队 if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 超过了最大重入次数 throw new Error(\"Maximum lock count exceeded\"); // Reentrant acquire setState(c + acquires); return true; &#125; // c == 0 没有线程持有该锁，判断是否需要被阻塞，否则尝试获取锁，若获取锁失败返回false // writerShouldBlock()四种不同的实现策略：非公平直接返回false，公平判断队列中是否有元素排队 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); // 拿锁成功将独占锁设置为当前线程 return true; &#125; &#125;&#125; 若c != 0且w == 0，一定是读线程拿着锁； 若c != 0且w != 0，当前一定是写线程拿着锁，若current != getExclusiveOwnerThread()说明持有写锁的线程不是当前线程； 若c == 0，说明当前没有线程持有该锁，可以通过CAS抢锁，抢锁成功将持有锁的线程设置为自己 WriteLock写锁是排他锁，公平与非公平实现几乎一模一样，只是writerShouldBlock()分别被FairSync和NonfairSync实现。 1234567891011121314151617181920212223242526272829303132public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; public static class WriteLock implements Lock, java.io.Serializable &#123; public void unlock() &#123; sync.release(1); &#125; &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); // 释放锁成功，唤醒后续节点 return true; &#125; return false; &#125;&#125;public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; abstract static class Sync extends AbstractQueuedSynchronizer &#123; protected final boolean tryRelease(int releases) &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; // 低16位用来记录写锁，且写锁只能重入，故直接减 boolean free = exclusiveCount(nextc) == 0; // 是否将写锁完全释放锁成功 if (free) setExclusiveOwnerThread(null); setState(nextc); // 因为写线程是排他锁，故state操作不需要CAS return free; &#125; &#125;&#125; ReadLock公平与非公平实现ReadLock读锁是共享锁，重写了tryAcquireShared/tryReleaseShared方法，这里读锁唤醒队列中紧接着排队的所有读线程的关键代码在setHeadAndPropagate(node, r)方法中，该方法会调用doReleaseShared从而调用unparkSuccessor去唤醒后继节点，这里也是共享锁与独占锁唤醒后继线程的最大区别。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; public static class ReadLock implements Lock, java.io.Serializable &#123; public void lock() &#123; sync.acquireShared(1); &#125; &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); // 获取锁失败 &#125; private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); // 将节点以共享模型添加入队列尾部 boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 获取前置节点 if (p == head) &#123; // 若前置节点为head int r = tryAcquireShared(arg); // 再次尝试获取读锁 if (r &gt;= 0) &#123; // 若获取读锁成功 setHeadAndPropagate(node, r); // 该处是去唤醒后续排队的读线程 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; // 第一次将前置节点waitStatus设置为SIGNAL，第二次park阻塞等待 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) // 若后继节点是共享模式，则继续唤醒后继节点 doReleaseShared(); &#125; &#125;&#125;public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; abstract static class Sync extends AbstractQueuedSynchronizer &#123; protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); // 写锁被某线程持有，且该线程还不是自己，读锁肯定拿不到直接返回 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); // 非公平锁判断队列中第一个元素是否是写锁，公平锁判断队列中是否有元素排队 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; // CAS拿读锁高16位加1，读锁状态在高16位，故须把1左移16位再加一 if (r == 0) &#123; // r之前等于0，说明这是第一个拿到读锁的线程 firstReader = current; // 记录第一拿取读锁的线程 firstReaderHoldCount = 1; // firstReader的持有计数 &#125; else if (firstReader == current) &#123; // 不是第一个 firstReaderHoldCount++; // firstReader的持有计数加一 &#125; else &#123; // firstReader不为当前线程，说明已经有别人先占读锁了 HoldCounter rh = cachedHoldCounter; // 缓存最后一个获取读锁的线程; // rh中的线程不是当前线程 if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); // 初始化ThreadLocal将rh保存进去 rh.count++; &#125; return 1; // 说明成功获取了读锁 &#125; return fullTryAcquireShared(current); // 拿读锁失败，进入该函数不断自旋拿读锁 &#125; final int fullTryAcquireShared(Thread current) &#123; HoldCounter rh = null; for (;;) &#123; // 自旋抢读锁，直到写锁被人占了，且不是当前线程占的写锁 int c = getState(); // 判断写锁是否被占用 if (exclusiveCount(c) != 0) &#123; // 若线程拿到了写锁，且不是自己 if (getExclusiveOwnerThread() != current) return -1; // 非公平锁判断队列中第一个元素是否是写锁，公平锁判断队列中是否有元素排队 &#125; else if (readerShouldBlock()) &#123; // 当前线程就是第一个获取读锁的线程(重入) if (firstReader == current) &#123; &#125; else &#123; if (rh == null) &#123; rh = cachedHoldCounter; // 若当前线程未初始化过ThreadLocal中的值，get()会执行初始化 if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get(); // 若count==0，则是上一行代码初始化的，那么执行remove if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // CAS尝试获取锁 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; // 获取锁成功，且当前无读线程持有锁 firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; // 重入 firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125; &#125; &#125;&#125; 低16位不等于0，说明写线程持有锁，且getExclusiveOwnerThread() != current才返回-1，若getExclusiveOwnerThread() == current说明当前线程是一个写线程，即一个线程持有WriteLock写锁后可以再去调用ReadLock.lock。 这里的firstReader和cachedHoldCounter之类的变量，只是一些统计变量，在ReentrantReadWriteLock对外的一些查询函数中会用到，对整个读写互斥机制没有影响。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; public static class ReadLock implements Lock, java.io.Serializable &#123; public void unlock() &#123; sync.releaseShared(1); &#125; &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); // 若没有线程再持有读锁了 return true; &#125; return false; &#125; private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; // 若队列中还有元素排队 int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 且头节点waitStatus为-1 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) // 唤醒头节点前，将waitStatus设置为0 continue; // loop to recheck cases unparkSuccessor(h); // 唤醒头节点 &#125; // 若头节点状态已经是0了，则将头节点waitStatus修改为-3 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; // 退出循环 &#125; &#125;&#125;public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; abstract static class Sync extends AbstractQueuedSynchronizer &#123; protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); if (firstReader == current) &#123; // 第一个持有读锁的线程是否是当前线程 // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; // 说明是重入锁 释放一次 &#125; else &#123; HoldCounter rh = cachedHoldCounter; // 最后一个获取读锁的线程 if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; --rh.count; &#125; for (;;) &#123; // 自旋 int c = getState(); int nextc = c - SHARED_UNIT; // 读锁在高16，故需要左移16位，再减 if (compareAndSetState(c, nextc)) return nextc == 0; // 减1后判断，是否还有线程持有读锁 &#125; &#125; &#125;&#125; 因为读锁是共享锁，多个线程会同时持有读锁，所以对读锁的释放不能直接减一，需要通过一个for循环加CAS操作不断重试，这是tryReleaseShared与tryRelease根本差异所在。","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"},{"name":"Lock","slug":"Lock","permalink":"https://yaoyinglong.github.io/tags/Lock/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"Condition原理","date":"2021-09-06T16:00:00.000Z","path":"Blog/Java/并发/Condition原理/","text":"Condition本身也是一个接口，其功能与wait/notify类似。 123456789101112public interface Condition &#123; void await() throws InterruptedException; // 在接到信号或被中断之前一直处于等待状态 void awaitUninterruptibly(); // 在接到信号前一直处于等待状态，不可被中断 // 在接到信号、被中断或到达指定等待时间之前一直处于等待状态 long awaitNanos(long nanosTimeout) throws InterruptedException; // 在接到信号、被中断或到达指定等待时间之前一直处于等待状态 boolean await(long time, TimeUnit unit) throws InterruptedException; // 在接到信号、被中断或到达指定最后期限之前一直处于等待状态 boolean awaitUntil(Date deadline) throws InterruptedException; void signal(); // 唤醒一个等待线程。该线程从等待方法返回前必须获得与Condition相关的锁 void signalAll(); // 唤醒所有等待线程&#125; wait/notify必须与synchronized一起使用，同样Condition也必须和Lock一起使用，因此Lock接口中有一个与Condition相关的接口，所有Condition都是从Lock中构造出来的。Lock持有一个FIFO双向的同步阻塞队列，Condition持有一个FIFO单向条件等待队列。 12345678public interface Lock &#123; void lock(); // 不能被中断 void lockInterruptibly() throws InterruptedException; // 可以被中断 boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition(); // 所有Condition都是从Lock中构造出来的&#125; Condition使用很简洁，避免了wait/notify的生产者通知生产者、消费者通知消费者的问题；因为Condition也必须和Lock一起使用，故Condition的实现也是Lock的一部份。 1234567891011121314151617public class ReentrantLock implements Lock, java.io.Serializable &#123; public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125;public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; public static class ReadLock implements Lock, java.io.Serializable &#123; public Condition newCondition() &#123; throw new UnsupportedOperationException(); // 读锁不支持Condition &#125; &#125; public static class WriteLock implements Lock, java.io.Serializable &#123; public Condition newCondition() &#123; return sync.newCondition(); &#125; &#125;&#125; ReadLock读锁不支持Condition，WriteLock写锁和互斥锁都支持Condition，虽然他们钩子调用的是自己内部类Sync，但内部类Sync都继承自AQS，sync.newCondition()最终都调用了AQS中的newCondition： 123456789101112final ConditionObject newCondition() &#123; return new ConditionObject();&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public class ConditionObject implements Condition, java.io.Serializable &#123; // 条件等待队列的首节点，每个节点使用Node.nextWaiter保存下一个节点的引用，因此等待队列是一个单向队列 private transient Node firstWaiter; // 条件等待队列的尾节点 private transient Node lastWaiter; public ConditionObject() &#123; &#125; &#125;&#125; await实现每个Condition对象上面都阻塞了多个线程，ConditionObject内部维护了一个单向链表组成的FIFO队列，首先将当前线程封装成node节点，并将节点加入Condition等待队列的尾部，然后释放同步state状态即独占锁，释放锁的同时会将其在同步队列中移除，并非是将同步队列中的节点直接加入等待队列，唤醒同步队列中的后继节点，然后当前线程会进入park等待状态。 自旋等待直到其他线程调用signal()，将node节点在等待队列上的节点移动到了同步队列，或被中断。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121public class ConditionObject implements Condition, java.io.Serializable &#123; public final void await() throws InterruptedException &#123; if (Thread.interrupted()) // 正要执行await收到中断信号，抛出异常 throw new InterruptedException(); Node node = addConditionWaiter(); // 加入Condition等待队列 int savedState = fullyRelease(node); // 阻塞在Condition之前必须先释放锁，否则会死锁 int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 判断当前节点是否也在同步队列中，signal时会将节点移动到同步队列 LockSupport.park(this); // 若不在同步队列中，则还没有被其他线程signal，则park阻塞自己 // 判断标记两种中断，在被signal前中断还是被signal后中断。分别标记为THROW_IE，REINTERRUPT即-1和1 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; // 被中断唤醒也会退出自旋 &#125; // 阻塞当前节点，直到node获取到了锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) // 重新拿锁 interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 清理Condition队列中被关闭的节点 if (interruptMode != 0) reportInterruptAfterWait(interruptMode); // 根据中断状态来判断是抛出异常，还是执行中断 &#125; // 将节点添加Condition等待队列中 private Node addConditionWaiter() &#123; Node t = lastWaiter; // 若lastWaiter已经被cancelled直接清理出链表 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; // 执行清理操作后lastWaiter可能变化了，所以重新赋值 &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; // 检查中断，若在发出unpark信号之前被中断，则返回THROW_IE，否则返回REINTERRUPT，若未中断则返回0 private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; &#125; // 在取消等待后将节点转移到同步队列，若线程在发出信号之前被取消，则返回true final boolean transferAfterCancelledWait(Node node) &#123; if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; enq(node); // 若当前状态为CONDITION且更新为初始状态成功，则将其加入同步等待队列 return true; &#125; while (!isOnSyncQueue(node)) Thread.yield(); // 若不在同步队列让出等待 return false; &#125; private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; // 断掉中间废弃节点时使用 while (t != null) &#123; // 遍历整个链 Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; // 若当前节点waitStatus不为CONDITION t.nextWaiter = null; // 将当前节点的nextWaiter置空，即断掉 if (trail == null) // 若头节点都废弃了 firstWaiter = next; else // 将前一个正常节点的nextWaiter指向下一个节点 trail.nextWaiter = next; if (next == null) // next为null说明trail节点已经是最后的节点了 lastWaiter = trail; &#125; else trail = t; // 将trail往后移动 t = next; &#125; &#125; private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; final int fullyRelease(Node node) &#123; // 释放所持有全部锁，包括重入的 boolean failed = true; try &#123; int savedState = getState(); // 不管重入几次都把state释放为0 if (release(savedState)) &#123; // 释放独占锁，且唤醒同步阻塞队列中的排队元素 failed = false; return savedState; &#125; else &#123; // 释放锁失败抛出异常，后续将节点移除 throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) //若释放锁失败，将waitStatus置为CANCELLED，便于后续清理出Condition等待队列 node.waitStatus = Node.CANCELLED; &#125; &#125; public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; final boolean isOnSyncQueue(Node node) &#123; // 这里的同步队列是只Lock中的FIFO队列 // 若waitStatus为CONDITION或者其前置节点为null，表示没有在同步队列 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // 若后继节点不为空，则一定在同步队列中 return true; return findNodeFromTail(node); &#125; private boolean findNodeFromTail(Node node) &#123; // 从尾部向前搜索整个队列，查询该节点是否在同步队列中 Node t = tail; for (;;) &#123; if (t == node) return true; if (t == null) return false; t = t.prev; &#125; &#125;&#125; 线程调用await方法时，肯定已经拿到了锁，故在addConditionWaiter方法中，对双向链表的操作不需要执行CAS操作。 线程在执行wait操作前，必须先释放锁，也就是fullyRelease(node)，否则会发生死锁，这和wait/notify与synchronized的配合机制一样。 线程从wait中被唤醒后，必须用acquireQueued(node, savedState)重新获取锁。 checkInterruptWhileWaiting(node))在LockSupport.park(this)之后，是为了检测在park期间是否收到过中断信号。这里await方法是可以响应中断的，当发现自己是被中断唤醒的，会直接退出while循环，await方法也会返回。 isOnSyncQueue(node)用于判断该Node是否在AQS的同步队列中，初始时Node只在Condition队列中，而不在AQS队列中，执行signal操作时会放入AQS同步队列。 123456789101112public final void awaitUninterruptibly() &#123; Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if (Thread.interrupted()) // 从park中醒来，收到中断，不退出，继续执行while循环 interrupted = true; &#125; if (acquireQueued(node, savedState) || interrupted) selfInterrupt();&#125; signal实现signal方法会将等待队列中节点移到同步队列中。这里并不会直接唤醒等待队列中的节点，除非将等待队列中的节点移到同步队列中时，其在同步队列中的前置节点已经被取消，或CAS将前置节点waitStatus更新为SIGNAL时失败，才会执行唤醒当前节点操作。 123456789101112131415161718192021222324252627public final void signal() &#123; if (!isHeldExclusively()) // 只有持有锁的线程才有资格调用signal throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); // 唤醒Condition队列中第一个线程&#125;private void doSignal(Node first) &#123; do &#123; // 若first节点被取消，接着唤醒下一个节点 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 若已经是最后一个元素了 first.nextWaiter = null; // 唤醒当前节点后要被剔除队列，便于GC所以将nextWaiter置空 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; // 若更新waitStatus失败说明，节点已经被取消了 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 把Node放入互斥锁的同步队列中，再调用下面的unpark Node p = enq(node); int ws = p.waitStatus; // 若node前置节点已经被取消，或更新前置节点状态为可唤醒失败，则唤醒当前node if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); // 唤醒当前线程 return true;&#125; 同await一样，调用signal时必须先拿到锁，因为前面执行await时把锁释放了。从队列中取出firstWait唤醒，在通过unpark唤醒它之前，先调用enq(node)函数将该Node放入AQS锁对应的阻塞队列中，所以await中才while (!isOnSyncQueue(node))判断，若条件满足，说明await线程不是被中断，而是被unpark唤醒的。 1234567891011121314151617public final void signalAll() &#123; if (!isHeldExclusively()) // 只有持有锁的线程才有资格调用signal throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);&#125;private void doSignalAll(Node first) &#123; lastWaiter = firstWaiter = null; do &#123; Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; &#125; while (first != null);&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"},{"name":"Lock","slug":"Lock","permalink":"https://yaoyinglong.github.io/tags/Lock/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"AQS与ReentrantLock","date":"2021-09-04T16:00:00.000Z","path":"Blog/Java/并发/AQS与ReentrantLock/","text":"Java并发编程核心在于java.util.concurrent包，JUC中大多数同步器实现都是围绕着共同的基础行为，如等待队列、条件队列、独占获取、共享获取等，而该行为的抽象是基于AbstractQueuedSynchronizer简称AQS，AQS定义了一套多线程访问共享资源的同步器框架，是一个依赖状态state的同步器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; private static final long serialVersionUID = 3737899427754241961L; protected AbstractOwnableSynchronizer() &#123; &#125; // 独占模式同步下获取锁的线程 private transient Thread exclusiveOwnerThread; protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125;&#125;// AbstractQueuedSynchronizer主要属性public class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; // 不管是条件队列，还是同步等待队列都是基于Node类 static final class Node &#123; // 标记节点为共享模式 static final Node SHARED = new Node(); // 标记节点为独占模式 static final Node EXCLUSIVE = null; // 在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待 static final int CANCELLED = 1; // 后继节点线程处于等待状态，而当前的节点如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行。 static final int SIGNAL = -1; // 节点在等待队列中，节点的线程等待在Condition上，当其他线程对Condition调用了signal()方法后，该节点会从等待队列中转移到同步队列中，加入到同步状态的获取中 static final int CONDITION = -2; // 表示下一次共享式同步状态获取将会被无条件地传播下去 static final int PROPAGATE = -3; // 标记当前节点的信号量状态 (1,0,-1,-2,-3)5种状态，使用CAS更改状态，volatile保证线程可见性，高并发场景下，即被一个线程修改后，状态会立马让其他线程可见。 volatile int waitStatus; // 前驱节点，当前节点加入到同步队列中被设置 volatile Node prev; // 后继节点 volatile Node next; // 节点同步状态的线程 volatile Thread thread; // 等待队列中的后继节点，若当前节点是共享的，则该字段是一个SHARED常量，节点类型(独占和共享)和等待队列中的后继节点共用同一个字段。 Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 返回前驱节点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; // 空节点，用于标记共享模式 Node() &#123; // Used to establish initial head or SHARED marker &#125; // 用于同步等待队列 Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; // 用于条件队列 Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; // 指向同步等待队列的头节点 private transient volatile Node head; // 指向同步等待队列的尾节点 private transient volatile Node tail; // 源状态：state&gt;1：该线程重入了锁；state=1：有一个线程持有锁，exclusiveOwnerThread=该线程；state=0：没有线程持有锁 private volatile int state; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long stateOffset; private static final long headOffset; private static final long tailOffset; private static final long waitStatusOffset; private static final long nextOffset; static &#123; try &#123; stateOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"state\")); headOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"head\")); tailOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"tail\")); waitStatusOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"waitStatus\")); nextOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"next\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125;&#125; AbstractQueuedSynchronizer是通过state字段来标记锁状态，通过CAS操作该字段以保证线程安全，通过exclusiveOwnerThread记录当前持有锁的线程，通过Node队列维护所有阻塞线程，且该队列是安全的无锁阻塞队列，也是使用CAS来入队操作；通过Unsafe类提供阻塞或唤醒线程的一对操作原语park/unpark来对线程进行阻塞和唤醒操作，这里使用的是LockSupport工具类，其对park/unpark原语做了封装。 12345678910111213141516171819202122public final class Unsafe &#123; public native void unpark(Object var1); public native void park(boolean var1, long var2);&#125;public class LockSupport &#123; // 当前线程调用会被阻塞，会被中断永久唤醒 public static void park() &#123; UNSAFE.park(false, 0L); &#125; // 当前线程调用会被阻塞，会被中断唤醒一次 public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null); &#125; // 唤醒指定的线程 public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread); &#125;&#125; synchronized与AQSsynchronized：不可中断、不支持公平锁、JVM层面上实现、代码执行完成或者出现异常会自动释放锁、不能设置超时时间，可重入、无法判断锁状态 Lock：可中断、支持公平与非公平锁、通过CAS+park&amp;unpark+链表代码层面实现、不会自动释放锁、可设置超时时间、更加灵活、支持tryLock获取锁立即返回true或false、可判断锁状态、可重入 AQS具备特性阻塞等待队列，共享/独占，公平/非公平，可重入，允许中断；除Lock外Java.util.concurrent当中同步器实现，如Latch，Barrier，BlockingQueue等都是基于AQS框架实现。 一般通过定义内部类Sync继承AQS，将同步器所有调用都映射到Sync对应的方法，AQS内部维护volatile修饰的状态属性state，32位，表示资源的可用状态，State三种访问方式getState()、setState()、compareAndSetState()。 AQS定义Exclusive独占和Share共享两种资源共享方式，Exclusive独占只有一个线程能执行，如ReentrantLock；Share共享多个线程可同时执行，如Semaphore/CountDownLatch； 不同自定义同步器争用共享资源方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式，具体线程等待队列的维护AQS已在顶层实现。自定义同步器实现时主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源，只有用到condition才需要去实现它。 tryAcquire(int)：独占方式，尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式，尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式，尝试获取资源，负数为失败；0为成功，但无剩余可用资源；正数为成功，且有剩余资源。 tryReleaseShared(int)：共享方式，尝试释放资源，若释放后允许唤醒后续等待结点返回true，否则返回false。 AQS定义同步等待队列和条件等待队列两种队列，同步等待队列是FIFO先进先出线程等待队列，线程由原自旋机制改为阻塞机制 Condition条件等待队列是一个多线程间协调通信的工具类，使某个或某些线程一起等待某个条件Condition，仅当该条件具备时，这些等待线程才会被唤醒，从而重新争夺锁 ReentrantLock ReentrantLock实现了Lock接口： 12345678public interface Lock &#123; void lock(); // 不能被中断 void lockInterruptibly() throws InterruptedException; // 可以被中断 boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; ReentrantLock是基于AQS框架应用实现的，是JDK中线程并发访问的同步手段，其功能类似于synchronized是一种互斥锁，可保证线程安全。且具有比synchronized更多的特性，支持手动加锁与解锁及加锁的公平性。 123ReentrantLock lock = new ReentrantLock(false); // false为非公平锁，true为公平锁lock.lock() // 加锁lock.unlock() // 解锁 ReentrantLock本身没有逻辑代码，实现都在内部抽象类Sync中，该类继承AbstractQueuedSynchronized，对该抽象类的部分方法做了实现，Sync有两个子类FairSync公平锁与NonfairSync非公平锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; // 加锁的具体行为由子类实现 abstract void lock(); // 尝试获取非公平锁 acquires = 1，默认为非公平锁实现 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 不需要判断同步等待队列中是否有排队等待线程，判断state状态是否为0，为0可以加锁 if (c == 0) &#123; // 一上来就尝试抢锁修改state值，不考虑队列中有没有其他线程排队 if (compareAndSetState(0, acquires)) &#123; // unsafe操作，cas修改state状态 setExclusiveOwnerThread(current); // 独占状态锁持有者指向当前线程 return true; &#125; &#125; // state状态不为0，判断锁持有者是否是当前线程，若是当前线程持有则state+1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; // 已经拿到锁再次重入，直接累加state变量 if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; // 加锁失败 &#125; // 释放锁 protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; // 若重入锁被全部释放 free = true; setExclusiveOwnerThread(null); // 独占状态锁持有者置为null &#125; setState(c); return free; &#125; // 判断持有独占锁的线程是否是当前线程 protected final boolean isHeldExclusively() &#123; return getExclusiveOwnerThread() == Thread.currentThread(); &#125; // 返回条件对象 final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // 返回独占锁的线程 final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; return getState() != 0; &#125; private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; FairSync公平锁和NonfairSync非公平锁也间接继承了AbstractQueuedSynchronized，ReentrantLock默认无参构造函数为非公平锁，为了提高效率，减少线程切换，也通过有参构造函数指定使用公平锁还是非公平锁。 123456public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 公平锁加锁过程对于加锁过程公平锁与非公平锁不一样，这里的acquire(1)是AQS的模板方法。tryAcquire是一个虚函数，被FairSync公平锁和NonfairSync非公平锁分别实现，再次去尝试获取锁，若获取锁失败将其加入到同步等待队列中。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class ReentrantLock implements Lock, java.io.Serializable &#123; public void lock() &#123; sync.lock(); &#125;&#125;static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); // AQS的模板方法 &#125; // 尝试加锁，被AQS的acquire()方法调用 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 与非公平锁中的区别，需要先判断队列当中是否有等待的节点，没有则可以尝试CAS获取锁 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); // 独占线程指向当前线程 return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final void acquire(int arg) &#123; // tryAcquire回调子类的FairSync的tryAcquire方法 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; public final boolean hasQueuedPredecessors() &#123; // 是否有排队线程 Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125;&#125; 首先通过addWaiter方法为当前线程创建独占模式的节点，并加入到阻塞队列中 12345678910111213141516171819202122232425262728293031private Node addWaiter(Node mode) &#123; // 将当前线程构建成Node类型 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; // 若尾部节点不为空，则将当前节点插入队列尾部 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; // 尝试加到队列尾部，若不成功，则执行enq(node) pred.next = node; // 将之前的尾部节点的next执行当前的节点 return node; &#125; &#125; enq(node); return node;&#125;// 内部会进行队列的初始化，新建一个空Node，然后不断尝试自旋，直至成功把该Node加入队列尾部private Node enq(final Node node) &#123; for (;;) &#123; // 自旋 Node t = tail; if (t == null) &#123; // 初始化阻塞队列的头部为一个空节点 if (compareAndSetHead(new Node())) tail = head; // 并将尾部也指向该空节点 &#125; else &#123; // 第“二”次循环进入 node.prev = t; if (compareAndSetTail(t, node)) &#123; // 将尾部节点指向当前节点 t.next = node; // 将之前的尾部节点的next执行当前的节点 return t; &#125; &#125; &#125;&#125; 已经在队列当中的Thread节点，准备阻塞等待获取锁，acquireQueued函数不会中断响应，但会记录被阻塞期间有没有收到过中断信号。因为LockSupport.park(this)可能被中断唤醒，所以acquireQueued中才写了一个for自旋，唤醒后发现自己排在队列头部则尝试拿锁，若拿不到锁则再次被park阻塞。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 自旋 final Node p = node.predecessor(); // 获取当前节点的前置节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 被唤醒，且若前置节点为head，尝试获取锁 setHead(node); // 拿锁成功，出队列，将head节点设置为当前节点 p.next = null; // help GC failed = false; return interrupted; &#125; // 如果前驱节点不是Head，通过shouldParkAfterFailedAcquire判断是否应该阻塞 // 前驱节点信号量为-1，当前线程可以安全被parkAndCheckInterrupt用来阻塞线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; // 若前驱结点的状态是SIGNAL，意味着当前结点可以被安全地park if (ws &gt; 0) &#123; do &#123; // 前驱节点状态如果被取消状态，将被移除出队列 node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 当前驱节点waitStatus为0 or PROPAGATE状态时，将其设置为SIGNAL状态，然后当前结点才能被安全地park compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;// 阻塞当前节点，返回当前Thread的中断状态，LockSupport.park底层实现逻辑调用系统内核功能pthread_mutex_lock阻塞线程private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125;// 终结掉正在尝试去获取锁的节点private void cancelAcquire(Node node) &#123; if (node == null) return; node.thread = null; // 将当前节点的线程置空 // 剔除所有被cancel的前置节点 Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; Node predNext = pred.next; // 前置节点的next节点 node.waitStatus = Node.CANCELLED; // 将当前节点的信号量置为CANCELLED即1 // 若当前节点为尾节点，尝试将当前节点的前置节点置为尾结点，若成功将最新的尾节点的next置为空 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; // 若前置节点不为head节点且前置节点为SIGNAL状态，或前置节点可被置为SIGNAL状态 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; // 若当前节点的next节点不为空，且不为CANCELLED状态，则将前置节点的后继节点置为当前节点的后继节点 if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 非公平锁内部类Sync的默认实现是非公平锁，ReentrantLock的无参构造方法也是非公平锁。 1234567891011121314151617181920212223242526272829303132333435363738394041static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * 第一步：直接尝试加锁，与公平锁最大的区别在于，此处不会去判断同步等待队列中是否有排队等待加锁的节点， * 上来直接加锁（判断state是否为0,CAS修改state为1），并将独占锁持有者exclusiveOwnerThread属性指向当前线程，若当前有人占用锁，再尝试去加一次锁 */ final void lock() &#123; if (compareAndSetState(0, 1)) // 直接尝试加锁，不会先去判断同步等待队列中是否有排队等待加锁的节点 setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; // 父类AbstractQueuedSynchronizer.acquire()中调用本方法 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 尝试获取非公平锁 acquires = 1，默认为非公平锁实现 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 不需要判断同步等待队列中是否有排队等待线程，判断state状态是否为0，为0可以加锁 if (c == 0) &#123; // 一上来就尝试抢锁修改state值，不考虑队列中有没有其他线程排队 if (compareAndSetState(0, acquires)) &#123; // unsafe操作，cas修改state状态 setExclusiveOwnerThread(current); // 独占状态锁持有者指向当前线程 return true; &#125; &#125; // state状态不为0，判断锁持有者是否是当前线程，若是当前线程持有则state+1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; // 已经拿到锁再次重入，直接累加state变量 if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; // 加锁失败 &#125;&#125; 解锁过程解锁过程公平锁与非公平锁一样，都是调用超类AbstractQueuedSynchronizer中的release方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ReentrantLock implements Lock, java.io.Serializable &#123; public void unlock() &#123; sync.release(1); &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; // 释放独占模式持有的锁 public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 释放一次锁 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); // 唤醒后继结点 return true; &#125; return false; &#125; private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; // 获取wait状态 if (ws &lt; 0) // 将等待状态waitStatus设置为初始值0 compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; // 若后继结点为空，或状态为CANCEL（已失效） s = null; // 从后尾部往前遍历找到最前的一个处于正常阻塞状态的结点，进行唤醒 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread); &#125;&#125;public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); // 没有使用CAS，因为是排他锁，只有一个线程能执行该处，不存在竞争 return free; &#125; &#125;&#125; lockInterruptibly该方法相对于普通的获取锁的区别在于，可被中断收到中断信号不再阻塞直接抛出异常，acquireInterruptibly也是AQS中的模板方法，里面的tryAcquire方法被FairSync公平锁和NonfairSync非公平锁分别实现，上面已经讲过： 1234567891011121314151617181920212223242526272829303132333435public class ReentrantLock implements Lock, java.io.Serializable &#123; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125;&#125;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; // 与acquireQueued逻辑相似，唯一区别节点还不在队列当中需要先进行入队操作 private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; // 以独占模式放入队列尾部 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); // 收到中断信号不再阻塞，直接抛出异常 &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;&#125; tryLocktryLock()实现基于调用非公平锁的nonfairTryAcquire方法： 12345678910111213141516171819202122232425public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125;// 尝试获取非公平锁 acquires = 1，默认为非公平锁实现final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 不需要判断同步等待队列中是否有排队等待线程，判断state状态是否为0，为0可以加锁 if (c == 0) &#123; // 一上来就尝试抢锁修改state值，不考虑队列中有没有其他线程排队 if (compareAndSetState(0, acquires)) &#123; // unsafe操作，cas修改state状态 setExclusiveOwnerThread(current); // 独占状态锁持有者指向当前线程 return true; &#125; &#125; // state状态不为0，判断锁持有者是否是当前线程，若是当前线程持有则state+1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; // 已经拿到锁再次重入，直接累加state变量 if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; // 加锁失败&#125; 带参数的tryLock(long timeout, TimeUnit unit)，指定纳秒内获取不到锁就放弃锁的获取： 123456789101112131415161718192021222324252627282930313233public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125;private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; // 若剩余时间小于1000则直接自旋，否则通过parkNanos的方式阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); // 阻塞nanosTimeout时间后唤醒 if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) // 若获取锁失败则放弃锁的获取，将其从队列中移除 cancelAcquire(node); &#125;&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"Unsafe应用","date":"2021-09-03T16:00:00.000Z","path":"Blog/Java/并发/Unsafe应用/","text":"Unsafe位于sun.misc包下，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。 Unsafe类使Java拥有类似C语言指针一样操作内存空间的能力，增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大。 Unsafe类为单例实现，提供静态方法getUnsafe获取Unsafe实例，仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常。 1234567891011121314public final class Unsafe &#123; private static final Unsafe theUnsafe; private Unsafe() &#123; &#125; @CallerSensitive public static Unsafe getUnsafe() &#123; Class var0 = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(var0.getClassLoader())) &#123; throw new SecurityException(\"Unsafe\"); &#125; else &#123; return theUnsafe; &#125; &#125;&#125; 获取Unsafe实例通过Java命令行命令-Xbootclasspath/a把调用Unsafe相关方法的类所在jar包路径追加到默认的bootstrap路径中，使得调用Unsafe相关方法的类被引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例。 1java -Xbootclasspath/a:$&#123;path&#125; // 其中path为调用Unsafe相关方法的类所在jar包路径 通过反射获取单例对象theUnsafe： 12345678910public static Unsafe reflectGetUnsafe() &#123; try &#123; Field field = Unsafe.class.getDeclaredField(\"theUnsafe\"); field.setAccessible(true); return (Unsafe) field.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; Unsafe功能Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类。 内存操作主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法。在Java中创建的对象都处于堆内内存，堆内内存是由JVM所管控的进程内存，且遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。堆外内存存在于JVM管控之外的内存区域，对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。 使用堆外内存可对垃圾回收停顿的改善，由于堆外内存是直接受操作系统管理而不是JVM，故使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响。 提升程序I/O操作的性能，通常I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。 1234567891011121314151617// 分配内存, 相当于C++的malloc函数public native long allocateMemory(long bytes);// 扩充内存public native long reallocateMemory(long address, long bytes);// 释放内存public native void freeMemory(long address);// 在给定的内存块中设置值public native void setMemory(Object o, long offset, long bytes, byte value);// 内存拷贝public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes);// 获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt，getDouble，getLong，getChar等public native Object getObject(Object o, long offset);// 为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有: putInt,putDouble，putLong，putChar等public native void putObject(Object o, long offset, Object x);public native byte getByte(long address);// 为给定地址设置byte类型的值（当且仅当该内存地址为allocateMemory分配 时，此方法结果才是确定的）public native void putByte(long address, byte x); DirectByteBuffer是Java用于实现堆外内存的一个重要类，其对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现，通常用在通信过程中做缓冲池，如Netty、MINA等NIO框架中应用广泛。 123456789101112131415161718192021222324DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); // 分配内存 &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); // 内存初始化 if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; // 跟踪DirectByteBuffer对象的垃圾回收，当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放 cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; 12345678910111213Unsafe unsafe = UnsafeInstance.reflectGetUnsafe();long oneHundred = 123456789L;byte size = 8;// 调用allocateMemory分配内存long memoryAddress = unsafe.allocateMemory(size);System.out.println(\"memoryAddress: \" + memoryAddress);// 将oneHundred写入到内存中unsafe.putAddress(memoryAddress, oneHundred);// 内存中读取数据long readValue = unsafe.getAddress(memoryAddress);System.out.println(\"readValue: \" + readValue);// 释放内存unsafe.freeMemory(memoryAddress); CAS123456789101112/** * @param var1 o - 包含要修改field的对象 * @param var2 offset - 对象中某field的偏移量 * @param var4 expected - 期望值 * @param var5 update - 更新值 * @return - true | false */public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 通过Unsafe来给属性赋值，offset为user字段的内存偏移地址： 12345678910111213141516171819202122public class UnsafeTest &#123; private static final Unsafe unsafe; private static final long offset; private transient volatile User user; static &#123; unsafe = UnsafeInstance.reflectGetUnsafe(); try &#123; offset = unsafe.objectFieldOffset(UnsafeTest.class.getDeclaredField(\"head\")); &#125; catch (NoSuchFieldException e) &#123; throw new RuntimeException(); &#125; &#125; public static void main(String[] args) &#123; UnsafeTest unsafeTest = new UnsafeTest(); User user123 = new User(); user.setAddress(\"123\"); unsafe.compareAndSwapObject(unsafeTest, offset, null, user123); System.out.println(unsafeTest.head.getAddress()); &#125;&#125; 线程调度包括线程挂起、恢复、锁机制等方法，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现；unpark可终止一个挂起的线程，使其恢复正常。 Java锁和同步器框架的核心类AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的，而LockSupport的park、unpark方法实际是调用Unsafe的park、unpark方式来实现。 12345678910111213// 取消阻塞线程public native void unpark(Object thread);// 阻塞线程public native void park(boolean isAbsolute, long time);// 获得对象锁（可重入锁）@Deprecatedpublic native void monitorEnter(Object o);// 释放对象锁@Deprecatedpublic native void monitorExit(Object o);// 尝试获取对象锁@Deprecatedpublic native boolean tryMonitorEnter(Object o); 12345678static Object object = new Object();static Unsafe unsafe = UnsafeInstance.reflectGetUnsafe();public void method1()&#123; unsafe.monitorEnter(object);&#125;public void method2()&#123; unsafe.monitorExit(object);&#125; 1234567891011Unsafe unsafe = UnsafeInstance.reflectGetUnsafe();Thread t = new Thread(() -&gt; &#123; System.out.println(\"thread - is running----\"); //true则会实现ms定时,false则会实现ns定时。 unsafe.park(false,0L); //阻塞当前线程 System.out.println(\"thread is over-----\");&#125;);t.start();Thread.sleep(1000);System.out.println(\"唤醒Thread-t\");unsafe.unpark(t); 内存屏障Java8中引入，用于定义内存屏障，也称内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作，避免代码重排序。 123456// 禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前public native void loadFence();// 禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前public native void storeFence();// 禁止load、store操作重排序public native void fullFence(); AtomicAtomic包中类基本都是使用Unsafe实现的，Unsafe只提供了三种CAS方法compareAndSwapObject，compareAndSwapInt和compareAndSwapLong。 在Atomic包里一共有12个类，四种原子更新方式，分别是原子更新基本类型，原子更新数组，原子更新引用和原子更新字段。Atomic包里的类基本都是使用Unsafe实现的包装类。 基本类：AtomicInteger、AtomicLong、AtomicBoolean； 引用类型：AtomicReference、AtomicReference的ABA实例、AtomicStampedRerence、AtomicMarkableReference； 数组类型：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 属性原子修改器（Updater）：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"MVCC与BufferPool缓存机制","date":"2021-09-01T16:00:00.000Z","path":"Blog/DB/MVCC与BufferPool缓存机制/","text":"快照读即不加锁的简单SELECT都属于快照读，当前读即读取最新数据而不是历史数据，加锁的SELECT或对数据进行增删改都会进行当前读。 MVCC多版本并发控制机制MySQL在可重复读隔离级别下同样的SQL查询语句在一个事务里多次执行查询结果相同，就算其它事务对数据有修改也不会影响当前事务SQL语句的查询结果。 该隔离性是靠MVCC(Multi-Version Concurrency Control)机制来保证的，对同一行数据的读和写默认不通过加锁互斥来保证隔离性，避免频繁加锁互斥，而在串行化隔离级别为了保证较高的隔离性是通过将所有操作加锁互斥来实现的。MySQL在读已提交和可重复读隔离级别下都实现了MVCC机制。 undo日志版本链与read view机制详解undo日志版本链是指同一行数据被多个事务依次修改过后，在每个事务修改完后，MySQL会保留修改前的数据即undo回滚日志，且用两个隐藏字段trx_id和roll_pointer把这些undo日志串联起来形成一个历史记录版本链。 每开启一个日志都会从数据库中获得一个事务id即trx_id，且trx_id是自增的，可判断事务的时间顺序。roll_pointer为回滚指针，指向undo日志中的上一个版本。 在可重复读隔离级别，当事务开启，执行第一条查询SQL时会生成当前事务的一致性视图read-view，该视图在事务结束之前都不会变化，该视图是由执行查询时所有未提交事务id组成的数组，数组里最小的事务id为min_id，已创建的最大事务id为max_id，事务里的任何SQL查询结果需要从对应版本链里的最新数据开始逐条跟read-view做对比从而得到最终的快照结果。 对于读已提交隔离级别在每次执行查询SQL时都会重新生成read-view，其他逻辑跟可重复读一致。 版本链比对规则若row的trx_id落在绿色部分即trx_id&lt;min_id，表示该版本是已提交的事务生成的，则该数据是可见的； 若row的trx_id落在红色部分即trx_id&gt;max_id，表示该版本是由将来启动的事务生成的，则该数据是不可见的，若row的trx_id就是当前自己的事务是可见的； 若row的trx_id落在黄色部分即min_id &lt;=trx_id&lt;= max_id，则包括两种情况： 若row的trx_id在视图数组中，表示该版本是由还没提交的事务生成的，则该数据不可见，若row的trx_id是当前自己的事务则可见 若row的trx_id不在视图数组中，表示该版本是已经提交了的事务生成的，则该数据可见。 删除可认为是update的特殊情况，会将版本链上最新的数据复制一份，然后将trx_id修改成删除操作的trx_id，同时在该条记录的头信息record header里的deleted_flag标记位写上true，表示当前记录已经被删除，在查询时按照上面的规则查到对应的记录若delete_flag标记位为true，意味着记录已被删除，则不返回数据。 begin或start transaction命令并不是一个事务的起点，在执行到它们之后的第一个修改InnoDB表的语句，事务才真正启动，才会向MySQL申请事务id，MySQL内部是严格按照事务的启动顺序来分配事务id的。 MVCC机制的实现就是通过read-view机制与undo版本链比对机制，使得不同事务根据数据版本链对比规则读取同一条数据在版本链上的不同版本数据。 BufferPool缓存机制数据库的增删改查都是直接操作BufferPool，BufferPool一般设置为机器内存的60%左右，执行SQL执行流程如下： 加载缓存数据记录所在的整页数据到BufferPool 写入更新数据旧值到undo日志中，便于回滚恢复BufferPool中的缓存数据 更新BufferPool中缓存的数据 写redo日志，首先写到Redo Log Buffer中 准备提交事务，redo日志写入磁盘redo日志文件中 准备提交事务，binlog日志写入磁盘binlog日志文件中，用来恢复数据库磁盘中的数据 写入commit标记到redo日志文件中，事务提交完成。该标记为了保证事务提交后redo与binlog数据一致 以page页为单位将数据随机写入磁盘 若来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据性能可能相当差。因为磁盘随机读写的性能非常差，所以直接更新磁盘文件是不能让数据库抗住很高并发的。 MySQL这套机制看起来复杂，但它可以保证每个更新请求都是更新内存BufferPool，然后顺序写日志文件，同时还能保证各种异常情况下的数据一致性。若事务提交成功，BufferPool中的数据还没来得及写入磁盘，此时若系统宕机了，可以用redo日志中的数据恢复BufferPool中的缓存数据。 更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是非常高的，要远高于随机读写磁盘文件。正是通过这套机制，才能让MySQL数据库在较高配置的机器上每秒可以抗下几干的读写请求。 BufferPool默认为128M，MySQL的数据是以文件页16K为单位加载到BufferPool，故默认BufferPool可放8192个文件页，且BufferPool分冷热数据，一般热数据占八分之五，冷数据占八分之三，且通过升级版的LRU链表维护。若对于一个大表进行全表扫描时，可能很快就把缓存页数据占满了，故MySQL会判断超过1s再次被访问的数据才会放入热数据区域，否则使用冷数据区域。 且BufferPool通过空闲列表维护了空闲页free链表，当数据被查询到BufferPool中会判断空闲页，写到固定的位置，且若发生数据更新则会产生脏页，这些脏页也会被维护到一个Flush链表中。且通过基节点维护了链表信息。 redo log记录的是某一页的哪个地址开始的数据被修改，redo log有两个日志文件，会滚动写入即当一个文件写满了就会写另一个文件，且有一个检查点的概念，若覆盖写入时发现了脏数据即BufferPool中缓存页数据被修改过，则会先触发刷盘操作将FlushList中的文件页的数据批量刷到磁盘中，则redo log文件配置越小则刷盘越频繁性能就越受影响，但若redo log配置的很大可能导致启动缓慢，redo log可通过配置值从而配置其持久化到redo log文件的时机： 0：事务提交时，不立即对redo log进行持久化，交给后台线程异步去完成 1：默认值，事务提交时，立即把redo log进行持久化 2：事务提交时，立即将redo log写到操作系统的缓冲区，并不会直接将redo log进行持久化，若数据库挂了，但操作系统没有挂，则事务的持久性还可以保持 Change Buffer存储的是索引的更新信息，当执行SELECT时加载索引页时，会将索引页与Change Buffer中的缓存数据融合。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"操作系统底层","date":"2021-09-01T16:00:00.000Z","path":"Blog/Java/并发/操作系统底层/","text":"计算机模型 CPU缓存结构 CPU为了提升执行效率，减少CPU与内存的交互，一般在CPU上集成了多级缓存架构，常见的为三级缓存结构，存储器存储空间大小：内存&gt;L3&gt;L2&gt;L1&gt;寄存器，存储器速度快慢排序：寄存器&gt;L1&gt;L2&gt;L3&gt;内存： L1 Cache，分为数据缓存和指令缓存，逻辑核独占 L2 Cache，物理核独占，逻辑核共享 L3 Cache，所有物理核共享 缓存是由最小的存储区块缓存行cacheline组成，缓存行大小通常为64byte，L1缓存大小是512kb，则L1里有512 * 1024/64个缓存行。 在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。 时间局部性（Temporal Locality）：若一个信息项正在被访问，则近期很可能还会被再次访问，如循环、递归、方法的反复调用等。 空间局部性（Spatial Locality）：若一个存储器的位置被引用，则将来其附近位置也会被引用，如顺序执行的代码、连续创建的两个对象、数组等。 带有高速缓存的CPU执行计算的流程：程序以及数据被加载到主内存，指令和数据被加载到CPU的高速缓存，CPU执行指令，把结果写到高速缓存，高速缓存中的数据写回主内存； 12345678910111213141516171819202122232425262728293031323334353637383940public class TwoDimensionalArraySum &#123; private static final int RUNS = 100; private static final int DIMENSION_1 = 1024 * 1024; private static final int DIMENSION_2 = 6; private static long[][] longs; public static void main(String[] args) throws Exception &#123; longs = new long[DIMENSION_1][]; for (int i = 0; i &lt; DIMENSION_1; i++) &#123; longs[i] = new long[DIMENSION_2]; for (int j = 0; j &lt; DIMENSION_2; j++) &#123; longs[i][j] = 1L; &#125; &#125; System.out.println(\"Array初始化完毕....\"); long sum = 0L; long start = System.currentTimeMillis(); for (int r = 0; r &lt; RUNS; r++) &#123; for (int i = 0; i &lt; DIMENSION_1; i++) &#123;//DIMENSION_1=1024*1024 for (int j = 0; j &lt; DIMENSION_2; j++) &#123;//6 sum += longs[i][j]; &#125; &#125; &#125; System.out.println(\"spend time1:\" + (System.currentTimeMillis() - start)); System.out.println(\"sum1:\" + sum); sum = 0L; start = System.currentTimeMillis(); for (int r = 0; r &lt; RUNS; r++) &#123; for (int j = 0; j &lt; DIMENSION_2; j++) &#123;//6 for (int i = 0; i &lt; DIMENSION_1; i++) &#123;//1024*1024 sum += longs[i][j]; &#125; &#125; &#125; System.out.println(\"spend time2:\" + (System.currentTimeMillis() - start)); System.out.println(\"sum2:\" + sum); &#125;&#125; 12345Array初始化完毕....spend time1:1428sum1:629145600spend time2:4371sum2:629145600 CPU运行安全等级CPU有4个运行级别，从高到低分别为：ring0，ring1，ring2，ring3；Linux与Windows只用到ring0、ring3，操作系统内部程序指令通常运行在ring0级别，第三方程序运行在ring3级别，若第三方程序要调用操作系统内部函数功能，必须切换CPU运行状态即从ring3切换到ring0；因为CPU要切换运行状态，所以JVM创建线程，线程阻塞唤醒是重型操作。 JVM创建线程CPU的工作过程，CPU从ring3切换ring0创建线程，创建完毕，CPU从ring0切换回ring3，线程执行JVM程序，线程执行完毕，销毁还得切会ring0。 执行空间保护操作系统有用户空间与内核空间两个概念，目的也是为了做到程序运行安全隔离与稳定，用户程序运行在用户方式下，系统调用运行在内核方式下。在这两种方式下所用的堆栈不一样：用户方式下用的是一般的堆栈，即用户空间的堆栈，内核方式下用的是固定大小的堆栈内核空间的堆栈，一般为一个内存页的大小，即每个进程与线程其实有两个堆栈，分别运行于用户态与内核态。 CPU调度的基本单位线程，划分为内核线程模型(KLT)，用户线程模型(ULT) ，JVM使用的是内核线程模型。 内核线程模型(KLT)：系统内核管理线程(KLT)，内核保存线程的状态和上下文信息，线程阻塞不会引起进程阻塞，多线程在多处理器上并行运行。线程的创建、调度和管理由内核完成，效率比ULT要慢，比进程操作快。 用户线程模型(ULT)：用户程序实现，不依赖操作系统核心，应用提供创建、同步、调度和管理线程的函数来控制用户线程。不需要用户态/内核态切换，速度快，内核对ULT无感知，线程阻塞则进程阻塞。 虚拟机指令集架构虚拟机指令集架构主要分两种：栈指令集架构，寄存器指令集架构，Java是栈指令集架构，Python、Go是寄存器指令架构。 栈指令集架构 设计和实现更简单，适用于资源受限的系统; 避开了寄存器的分配难题：使用零地址指令方式分配; 指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈，指令集更小，编译器容易实现; 不需要硬件支持，可移植性更好，更好实现跨平台。 寄存器指令集架构 典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机。 指令集架构则完全依赖硬件，可移植性差。 性能优秀和执行更高效。 花费更少的指令去完成一项操作。 在大部分情况下，基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主。","tags":[{"name":"多线程","slug":"多线程","permalink":"https://yaoyinglong.github.io/tags/多线程/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"MySQL事务隔离级别与锁机制","date":"2021-08-31T16:00:00.000Z","path":"Blog/DB/MySQL事务隔离级别与锁机制/","text":"事务基本特征ACID事务是并发控制的单位，是用户定义的一个操作序列，由一组SQL语句组成的逻辑处理单元，这些操作要么都成功，要么都失败，是一个不可分割的工作单位。 Atomicity原子性：事务中的包含的操作被看做是一个逻辑单元，要么全部成功，要么全部失败 Isolation隔离性：多个用户可对同一个数据并发访问，而不破坏数据的正确性和完整性，并行事务的修改必须与其他并行事务的修改相互独立 Consistency一致性：合法的数据被写入到数据库，否则事务回滚到最初状态 Durability持久性：事务结束后，事务处理的结果必须能够得到固化 四种隔离级别数据库一般都会并发执行多个事务，多个事务可能会并发的对相同的一批数据进行增删改查操作，可能就会导致脏写、脏读、不可重复读、幻读等问题；为了解决多事务并发问题，数据库设计了事务隔离机制、锁机制、MVCC多版本并发控制隔离机制，用一整套机制来解决多事务并发问题。 Read Uncommitted读未提交级别最低，一个事务可读到另外一个事务未提交的数据，事务在读数据的时候并未对数据加锁，在修改数据的时候只对数据增加行级共享锁。 事务1读取某行记录时，事务2也能对这行记录进行读取、更新，因为事务1并未对数据增加任何锁； 当事务2对该记录进行更新时，事务1再次读取该记录，能读到事务2对该记录的修改版本，因为事务2只增加了共享读锁，事务1可以再增加共享读锁读取数据，即使该修改尚未被提交； 事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束，因为事务1对数据增加了共享读锁，事务2不能增加排他写锁进行数据的修改； 1set tx_isolation='Read-Uncommitted'; Read Committed读已提交在一个事务修改数据过程中，如果事务还没提交，其他事务不能读该数据，事务对当前被读取的数据加行级共享锁且当读到时才加锁，一旦读完该行，立即释放该行级共享锁；事务在更新某数据的瞬间，必须先对其加行级排他锁，直到事务结束才释放。 事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取，因为事务1对该行记录增加行级共享锁的情况下，事务2同样可以对该数据增加共享锁来读数据； 事务1读取某行的一瞬间，事务2不能修改该行数据，但只要事务1读取完改行数据，事务2就可以对该行数据进行修改。因为事务1在读取的一瞬间会对数据增加共享锁，任何其他事务都不能对该行数据增加排他锁。但事务1只要读完该行数据，就会释放行级共享锁，一旦锁释放，事务2就可以对数据增加排他锁并修改数据； 事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。因为事务1在更新数据时，会对该行数据增加排他锁，直到事务结束才会释放锁，所以在事务2没有提交之前，事务1都能不对数据增加共享锁进行数据的读取。所以可以解决脏读的现象，但不能解决不可重复读现象。1set tx_isolation='Read-Committed'; Repeatable Read可重复读事务在读取某数据的瞬间，必须先对其加行级共享锁，直到事务结束才释放；事务在更新某数据的瞬间，必须先对其加行级排他锁，直到事务结束才释放。 事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取，因为事务1对该行记录增加行级共享锁的情况下，事务2同样可以对该数据增加共享锁来读数据； 事务1在读取某行记录的整个过程中，事务2都不能修改该行数据，事务1在读取的整个过程会对数据增加共享锁，直到事务提交才会释放锁，所以整个过程中，任何其他事务都不能对该行数据增加排他锁。所以能解决不可重复读的读现象； 事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束，事务1在更新数据的时候，会对该行数据增加排他锁，直到事务结束才会释放锁，所以在事务2没有提交之前，事务1都能不对数据增加共享锁进行数据的读取。所以可以解决可重复读的现象，但不能解决幻读现象。若事务1对数据进行修改，事务2也对数据进行修改，此时事务2会被阻塞，直到事务1提交事务，事务1提交事务后，事务2会马上执行完成，但此时事务1只能查到自己更新的数据。事务2也只能查到自己更新的数据，不能查到事务1更新的数据即使事务1提交事务后。 1set tx_isolation='Repeatable-Read'; Serializable串行化可序列化的隔离级别中可以解决幻读，产生幻读的原因是事务在进行范围查询的时候没有增加范围锁所以导致幻读，范围锁range-locks：给SELECT 的查询中使用一个WHERE子句描述范围加锁。事务在读取数据时，必须先对其加表级共享锁 ，直到事务结束才释放；事务在更新数据时，必须先对其加表级排他锁 ，直到事务结束才释放。 事务1正在读取A表中的记录时，则事务2也能读取A表，但不能对A表做更新、新增、删除，直到事务1结束，因为事务1对表增加了表级共享锁，其他事务只能增加共享锁读取数据，不能进行其他任何操作； 事务1正在更新A表中的记录时，则事务2不能读取A表的任意记录，更不可能对A表做更新、新增、删除，直到事务1结束，事务1对表增加了表级排他锁，其他事务不能对表增加共享锁或排他锁，也就无法进行任何操作； 可序列化解决了脏读、不可重复读、幻读等读现象，但无法读取其它事务已修改但未提交的记录，在当前事务完成之前，其它事务不能修改目前事务已读取的记录，在当前事务完成之前，其它事务所插入的新记录，其索引键值不能在当前事务的任何语句所读取的索引键范围中。 1set tx_isolation='Serializable'; 脏读脏读又称无效数据的读出，在一个事务的处理过程中读到另一个未提的交事务中的数据。 不可重复读在对数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值与脏读的区别是：不可重复读是读取了前一事务提交的数据 虚读（幻读）事务在操作过程中两次查询，第二次查询的结果包含了第一次查询中未出现的数据或缺少第一次查询中出现的数据，一般解决幻读的方法是增加间隙锁，锁定检锁范围为只读，这样就避免了幻读。 四种事务隔离级别从隔离程度上越来越高，但同时在并发性上也就越来越低。之所以有这么几种隔离级别，就是为了方便开发人员在开发过程中根据业务需要选择最合适的隔离级别。 隔离级别 脏读 不可重复读 幻读 读未提交 可能 可能 可能 读已提交 不可能 可能 可能 可重复读 不可能 不可能 可能 可串行化 不可能 不可能 不可能 默认的事务隔离级别是可重复读，用Spring开发程序时，若不设置隔离级别默认用MySQL设置的隔离级别，若Spring设置了就用已经设置的隔离级别 ，查询和设置当前数据库事务隔离级别： 12show variables like 'tx_isolation';set tx_isolation='REPEATABLE-READ'; 锁分类从性能上分为乐观锁，用版本对比来实现和悲观锁，从对数据库操作的类型分，分为读锁和写锁，都属于悲观锁，读锁是共享锁，S锁(Shared）：针对同一份数据，多个读操作可同时进行而互相不影响，写锁是排它锁，X锁(eXclusive）：当前写操作没有完成前，它会阻断其他写锁和读锁，从对数据操作的粒度分，分为表锁、间隙锁和行锁。 表级锁每次操作锁住整张表。开销小，加锁快，不会出现死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低；一般用在整表数据迁移的场景。 表锁相关操作： 123456-- 手动增加表锁lock tables mylock write, employees read;-- 查看表上加过的锁show open tables;-- 删除表锁unlock tables; 行级锁每次操作锁住一行数据。开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度最高。 InnoDB支持事务和行级锁，MylSAM两者皆不支持。MyISAM在执行查询语句SELECT前，会自动给涉及的所有表加读锁，在执行update、insert、delete操作会自动给涉及的表加写锁。 InnoDB在非串行隔离级别下执行查询语句SELECT时，不会加锁，但update、insert、delete操作会加行锁。简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞 对MyISAM表的读操作，即加读锁，不会阻塞其他进程对同一表的读请求，但会阻赛对同一表的写请求，只有当，读锁释放后，才会执行其它进程的写操作。 对MylSAM表的写操作，即加写锁，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。 行锁分析通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况 1show status like 'innodb_row_lock%'; Innodb_row_lock_current_waits：当前正在等待锁的数量 Innodb_row_lock_time：从系统启动到现在锁定总时间长度 Innodb_row_lock_time_avg：每次等待平均时间 Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间 Innodb_row_lock_waits：系统启动后到现在总共等待的次数 当等待次数很高，且每次等待时长也不小时，就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划 间隙锁锁的就是两个值之间的空隙，间隙锁在某些情况下可解决幻读问题，间隙锁在可重复读隔离级别下才会生效。 1select * from account; 该数据的间隙有id为(2, 10)，(10, 20)，(20, 正无穷)这三个区间，全都是开区间；在Session1下执行： 1update account set name = 'eleven11' where id &gt; 8 and id &lt;18; 则其他Session没法在这个范围所包含的所有行记录，包括间隙行记录，以及行记录所在的间隙里插入或修改任何数据，即id在(3,20]区间都无法修改插入数据，这里的(3,20]叫做临键锁； 若上面例子中id &lt; 25，则相当于整个表都被锁住了，无法再更新或插入任何数据。 临键锁Next-Key Locks是行锁与间隙锁的组合。 无索引行锁会升级为表锁锁主要是加在索引上，如果对非索引字段更新，行锁可能会变表锁，InnoDB的行锁是针对索引加的锁，不是针对记录加的锁。且该索引不能失效，否则都会从行锁升级为表锁。 锁定某一行可用lock in share mode加共享锁，用for update加排它锁： 1234-- 加排它锁，其他session只能读这行数据，修改则会被阻塞，直到锁定行的session提交select * from employees where id = 1 for update;-- 加共享锁select * from employees where id = 1 lock in share mode; Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁更高，但在整体并发处理能力方面要远远优于MyISAM的表级锁。当系统并发量高时，InnoDB整体性能和MyISAM相比会有比较明显的优势。 但InnoDB的行级锁同样也有其脆弱的一面，当使用不当时，可能会让Innodb整体性能表现不仅不能比MyISAM高，甚至可能会更差。 查看INFORMATION_SCHEMA系统库锁相关数据表12345678910-- 查看事务select * from INFORMATION_SCHEMA.INNODB_TRX;-- 查看锁select * from INFORMATION_SCHEMA.INNODB_LOCKS;-- 查看锁等待select * from INFORMATION_SCHEMA.INNODB_LOCK_WAITS;-- 释放锁，trx_mysql_thread_id可以从INNODB_TRX表里查看到kill trx_mysql_thread_id;-- 查看锁等待详细信息show engine innodb status; 死锁1234567891011set tx_isolation='repeatable-read';-- Session_1执行select * from account where id = 1 for update;-- Session_2执行：select * from account where id = 2 for update;-- Session_1执行：select * from account where id = 2 for update;-- Session_2执行：select * from account where id = 1 for update;-- 查看近期死锁日志信息：show engine innodb status; 大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁。 优化尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁 合理设计索引，尽量缩小锁的范围 尽可能减少检索条件范围，避免间隙锁 尽量控制事务大小，减少锁定资源量和时间长度，涉及事务加锁的sql尽量放在事务最后执行 尽可能低级别事务隔离 示例数据123456789101112CREATE TABLE `account` ( `id` INT (11) NOT NULL AUTO_INCREMENT, `name` VARCHAR (20) DEFAULT NULL, `balance` VARCHAR (20) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE = InnoDb DEFAULT CHARSET = utf8;-- 插入数据INSERT INTO`account` (`id`, `name`, `balance`) VALUES ('1', 'zhangsan', 800);INSERT INTO`account` (`id`, `name`, `balance`) VALUES ('2', 'lisi', 3000);INSERT INTO`account` (`id`, `name`, `balance`) VALUES ('10', 'wanger', 2000);INSERT INTO`account` (`id`, `name`, `balance`) VALUES ('20', 'mazi', 1000);","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"索引优化三","date":"2021-08-31T16:00:00.000Z","path":"Blog/DB/索引优化三/","text":"分页查询优化业务系统分页功能可能会用如下sql实现，表示取出从10001行开始的10行记录，看似只查询10条，实际SQL是先读取10010条记录，然后抛弃前10000条记录，然后读到后面10条目标数据。因此要查询一张大表比较靠后的数据，执行效率是非常低的： 1explain select * from employees limit 10000,10; 根据自增且连续的主键排序的分页查询改写后的SQL走了索引，且扫描行数大大减少，执行效率更高，但很多场景并不实用，表中可能某些记录被删主键空缺，导致主键不连续结果不一致，这里没添加单独order by，表示通过主键排序，该优化只适合于主键自增且连续且结果按照主键排序： 1explain select * from employees where id &gt; 90000 limit 10; 根据非主键字段排序的分页查询并没有使用name字段的索引，扫描整个索引并查找到没索引的行的成本比扫描全表的成本更高，所以优化器放弃使用索引。 1explain select * from employees ORDER BY name limit 90000, 10; 优化关键是让排序时返回的字段尽可能少，可让排序和分页操作先查出主键，然后根据主键查到对应的记录 1explain select * from employees e inner join (select id from employees order by name limit 90000,5) ed on e.id = ed.id; Join关联查询优化1234567891011121314151617181920212223242526272829303132333435363738394041CREATE TABLE `t1`( `id` int(11) NOT NULL AUTO_INCREMENT, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_a` (`a`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;create table t2 like t1;-- 插入一些示例数据，往t1表插入1万行记录drop procedure if exists insert_t1;delimiter ;;create procedure insert_t1()begin declare i int; set i = 1; while(i &lt;= 10000) do insert into t1(a, b) values (i, i); set i = i + 1; end while;end;;delimiter ;call insert_t1();-- 往t2表插入100行记录drop procedure if exists insert_t2;delimiter ;;create procedure insert_t2()begin declare i int; set i = 1; while(i &lt;= 100) do insert into t2(a, b) values (i, i); set i = i + 1; end while;end;;delimiter ;call insert_t2(); MySQL的表关联常见有Nested-Loop Join嵌套循环连接算法和Block Nested-Loop Join基于块的嵌套循环连接算法两种算法 嵌套循环连接算法一次一行循环地从第一张表即驱动表中读取行，在这行数据中取到关联字段，根据关联字段在另一张表即被驱动表里取出满足条件的行，然后取出两张表的结果合集。 执行计划结果的id如果一样则按从上到下顺序执行sql，先执行的就是驱动表，从执行计划中可知，t2是驱动表，t1是被驱动表， 优化器一般会优先选择小表做驱动表，使用inner join时，排在前面的表并不一定是驱动表。 1EXPLAIN select * from t1 inner join t2 on t1.a= t2.a; 从t2表中读取一行数据，若t2表有查询过滤条件，会从过滤结果里取出一行数据，取出关联字段a，到t1表中查找；取出t1表中满足条件的行，跟t2中获取到的结果合并，作为结果返回给客户端；然后继续下一条数据。 整个过程会读取t2表的所有数据，即扫描t2表100行，然后遍历每行数据中字段a的值，根据t2表中a的值索引扫描 t1表中的对应行，1次扫描可认为读取t1表一行完整数据，由于t1表的a字段有索引，故扫描100次。因此整个过程扫描了200行。若被驱动表的关联字段没索引，使用NLJ嵌套循环连接算法性能会比较低； left join左表是驱动表，right join右表是驱动表，join优化器会选择数据量比较小的表作为驱动表。 一般join语句中，若执行计划Extra中未出现Using join buffer则表示使用的是NLJ嵌套循环连接算法 基于块的嵌套循环连接算法把驱动表的数据读入到join_buffer中，然后扫描被驱动表，把被驱动表每一行取出来跟join_buffer中的数据做对比。 Extra中的Using join buffer (Block Nested Loop)说明该关联查询使用的是基于块的嵌套循环连接算法。 1EXPLAIN select * from t1 inner join t2 on t1.b= t2.b; 首先将t2表的所有数据放入到join_buffer中，把t1表中每一行取出，跟join_buffer中的数据对比，返回满足join条件的数据。 整个过程对t1表和t2表都做了一次全表扫描，因此扫描的总行数为10000+100=10100。且join_buffer里的数据是无序的，故对t1表中的每一行，都要做100次判断，故内存中的判断次数是100 * 10000= 100万次。 join_buffer是由参数join_buffer_size设定的，默认为256k。若放不下所有数据，就是分段放。若t2表有1000行记录，join_buffer一次只能放800行，则先往join_buffer里放800行，然后从t1表里取数据跟join_buffer 中数据对比得到部分结果，然后清空join_buffer，再放入t2表剩余200行，再次从t1表里取数据跟join_buffer中数据对比，所以就多扫了一次t1表。 若使用嵌套循环连接算法，这里扫描行数为100万次，且是磁盘扫描，而基于块的嵌套循环连接算法是内存计算，即使扫描次数更多但性能更高。对于被驱动表的关联字段没索引的关联查询，一般都会使用BNL算法，若有索引一般选择NLJ算法，有索引的情况下NLJ算法比BNL算法性能更高； 关联SQL优化关联字段加索引，让MySQL做join操作时尽量选择嵌套循环连接算法，小表驱动大表，写多表连接SQL时若明确知道哪张表是小表可以用straight_join写法固定连接驱动方式，省去MySQL优化器自己判断时间 ； straight_join功能同join类似，能让左表来驱动右表，能改表优化器对于联表查询的执行顺序。 由于left join，right join已代表指定了表的执行顺序，故straight_join只适用于inner join； 1EXPLAIN select * from t2 straight_join t1 on t2.a = t1.a; 尽可能让优化器去判断，大部分情况下MySQL优化器是比人要聪明，使用straight_join一定要慎重，因为部分情况下人为指定的执行顺序并不一定比优化引擎靠谱； 在决定哪个表做驱动表时，是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的是小表作为驱动表。 in和exsits优化当t2表的数据集小于t1表的数据集时，in优于exists的写法 1explain select * from t1 where a in (select a from t2); 等价于： 123for(select a from t2)&#123; select * from t1 where t1.a = t2.a&#125; exists优于in的写法，将主查询t2的数据，放到子查询t1中做条件验证，根据验证结果true或false来决定主查询的数据是否保留 1explain select * from t2 where exists(select 1 from t1 where t1.a = t2.a); exists子查询只返回true或false，因此子查询中的select *也可以用select 1替换，官方说法是实际执行时会忽略select清单，因此没有区别；exists子查询的实际执行过程可能经过了优化而不是理解上的逐条对比；exists子查询往往也可以用join来代替，何种最优需要具体问题具体分析； count(*)查询优化只有根据某个字段count才不会统计字段为null值的数据行，下面4个语句的执行计划跑出来都一样，执行效率差不多，全都是使用的二级索引 1234EXPLAIN select count(1) from employees;EXPLAIN select count(id) from employees;EXPLAIN select count(name) from employees;EXPLAIN select count(*) from employees; 字段有索引时执行效率从大到小：count(*)≈count(1)&gt;count(字段)&gt;count(主键id)；因为字段有索引，count(字段)统计走二级索引，因为二级索引存储数据比主键索引少，所以count(字段)&gt;count(主键id) 字段无索引时执行效率从大到小：count(*)≈count(1)&gt;count(主键id)&gt;count(字段) ；因为字段没有索引count(字段)统计走不了索引，count(主键id)还可以走主键索引，所以count(主键id)&gt;count(字段) count(1)跟count(字段)执行过程类似，不过count(1)不需要取出字段统计，就用常量1做统计，count(字段)还需要取出字段，故理论上count(1)比count(字段)会快一点。 count(*) 是例外，MySQL并不会把全部字段取出来，而是专门做了优化，不取值按行累加，效率很高，故不需要用count(列名)或count(常量)来替代count(*)。 count(id)最终选择辅助索引而不是主键聚集索引，因为二级索引相对主键索引存储数据更少，检索性能应该更高，大概5.7版本才优化。 查询MySQL自己维护的总行数myisam存储引擎的表做不带where条件的count查询性能是很高的，因为myisam存储引擎的表的总行数会被mysql存储在磁盘上，查询不需要计算 1explain select count(*) from test_myisam; 对于InnoDB存储引擎的表，因为有MVCC机制MySQL不会存储表的总记录行数，查询count需要实时计算 show table status若只需要知道表总行数的估计值可以用如下SQL查询，性能很高 1show table status like 'employees'; 将总数维护到Redis插入或删除表数据行的时候同时维护redis里的表总行数key的计数值，用incr或decr命令，但是这种方式可能不准，很难保证表操作和redis操作的事务一致性 增加数据库计数表插入或删除表数据行的时候同时维护计数表，让它们在同一个事务里操作","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"MySQL内部组件结构","date":"2021-08-30T16:00:00.000Z","path":"Blog/DB/MySQL内部组件结构/","text":"MySQL大体来说可以分为Server层和存储引擎层两部分 Server层主要包括连接器、查询缓存、分析器、优化器、执行器等，涵盖大多数核心服务功能，以及所有的内置函数，如日期、时间、数学和加密函数等，所有跨存储引擎的功能都在这一层实现，如存储过程、触发器、视图等。 连接器MySQl有navicat、mysql front、jdbc、SQLyog等非常丰富的客户端，客户端要发起通信都必须先跟Server端建立通信连接，而建立连接的工作由连接器来完成。连接器负责跟客户端建立连接、获取权限、维持和管理连接。 1mysql ‐h host[数据库地址] ‐u root[用户] ‐p root[密码] ‐P 3306 连接器会到权限表里面查出拥有的权限，连接里面的权限判断逻辑，将依赖于此时读到的权限。一个用户成功建立连接后，即使管理员账号对该用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，新建的连接才会使用新的权限设置。用户的权限表在系统表空间的mysql的user表中。 12345678910-- 创建新用户CREATE USER 'test'@'%' IDENTIFIED BY 'test';-- 赋权限,%表示所有(host)grant all privileges on *.* to 'test'@'%';-- 刷新数据库flush privileges; -- (设置用户名密码)set password for 'test'@'localhost' = password('test');-- 查看当前用户的权限show grants for 'test'@'%'; 连接完成后，若没有后续动作，连接将处于空闲状态，可在show processlist命令中看到它。其中的Command列显示为Sleep表示空闲连接。1234-- 查询连接列表show processlist;-- 关闭具体的连接kill 3; 客户端如果长时间不发送command到Server端，连接器就会自动将它断开。该时间由参数wait_timeout控制，默认8小时。 1234-- 查看wait_timeoutshow global variables like 'wait_timeout';-- 设置全局服务器关闭非交互连接之前等待活动的秒数set global wait_timeout=28800; 长连接指连接成功后，若客户端持续有请求，则一直使用同一个连接。短连接则是每次执行完很少的几次查询就断开连接。大多数用的都是长连接，把连接放在Pool内进行管理，但长连接有些时候会导致MySQL占用内存涨得特别快，因为在执行过程中临时使用的内存是管理在连接对象里面的，这些资源会在连接断开的时候才释放。 若长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。可以定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后断开连接，要查询再重连。若用的是MySQL 5.7或更新版本，可在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。该过程不需要重连和重新做权限验证，但会将连接恢复到刚刚创建完时的状态。 Store层存储引擎层负责数据的存储和提取。插件式的架构模式，支持InnoDB、MyISAM、Memory等多个存储引擎。InnoDB从MySQL5.5.5版本开始成为默认存储引擎，是最常用的存储引擎，若在create table时不指定表的存储引擎类型，默认会设置存储引擎为InnoDB。 bin-log归档binlog是Server层实现的二进制日志，会记录cud操作。Binlog在MySQL的Server层实现是引擎共用的，是逻辑日志，记录的是一条语句的原始逻辑，不限大小，追加写入，不会覆盖以前的日志；若误删了数据库,可使用binlog进行归档，要使用binlog归档，首先得记录binlog，因此需要先开启MySQL的binlog功能。 binlog格式有3种statement，row，mixed； 从bin‐log恢复数据 123456# 恢复全部数据/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001|mysql -uroot -p eleven# 恢复指定位置数据/usr/local/mysql/bin/mysqlbinlog --no-defaults --start-position=\"408\" --stop-position=\"731\" /usr/local/mysql/data/binlog/mysql-bin.000001|mysql -uroot -p eleven# 恢复指定时间段数据/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001 --stop-date=\"2018-03-02 12:00:00\" --start-date=\"2019-03-02 11:55:00\"|mysql -uroot -p eleven","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"索引优化二","date":"2021-08-30T16:00:00.000Z","path":"Blog/DB/索引优化二/","text":"索引设计原则代码先行，索引后上建完表不要立马就建立索引，一般应等主体业务功能开发完毕，把涉及到该表相关sql都要拿出来分析之后再建立索引。 联合索引尽量覆盖条件可设计一个或两三个联合索引，尽量少建单值索引，让每一个联合索引都尽量去包含sql语句里的where、order by、group by的字段，还要确保这些联合索引的字段顺序尽量满足sql查询的最左前缀原则。 不要在小基数字段上建立索引索引基数是指这个字段在表里总共有多少个不同的值，若一张表总共100万行记录，其中性别字段其值不是男就是女，则该字段基数就是2。 若对这种小基数字段建立索引，还不如全表扫描，因为你的索引树里就包含男和女两种值，根本没法进行快速的二分查找，那用索引就没有太大的意义了。 一般建立索引，尽量使用那些基数比较大的字段，才能发挥出B+树快速二分查找的优势。 当然也存在特例，类似delete_status这类字段，用0和1分别表示未删除和已删除，一般仅仅只用到0的情况下也可以建立索引。 长字符串我们可以采用前缀索引尽量对字段类型较小的列设计索引，如tinyint类型的字段，字段类型较小的话，占用磁盘空间也会比较小，搜索时性能也会比较好。所谓的字段类型小一点的列，也不是绝对的，很多时候要针对varchar(255)这种字段建立索引，哪怕多占用一些磁盘空间也是有必要的。 对于这种varchar(255)的大字段可能会比较占用磁盘空间，可以稍微优化下，比如针对该字段的前20个字符建立索引，对这个字段里的每个值的前20个字符放在索引树里，类似于KEY，index(name(20),age,position)。 在where条件里搜索时，若根据name字段来搜索，此时就会先到索引树里根据name字段的前20个字符去搜索，定位到之后前20个字符的前缀匹配的部分数据之后，再回到聚簇索引提取出来完整的name字段值进行比对。 若要对字段name做排序order by和分组group by，此时name因为在索引树里仅仅包含了前20个字符，故该排序和分组没法用上索引。 where与order by冲突时优先where一般这种时候往往都是让where条件去使用索引来快速筛选出来一部分指定的数据，接着再进行排序。大多数情况基于索引进行where筛选往往可以最快速度筛选出需要的少部分数据，然后做排序的成本可能会小很多。 基于慢sql查询做优化可根据监控后台的一些慢sql，针对这些慢sql查询做特定的索引优化。 索引下推对于辅助的联合索引(name, age, position)，正常情况按照最左前缀原则，SELECT * FROM employees WHERE name like &#39;LiLei%&#39; AND age = 22 AND position =&#39;manager&#39;该情况只会走name字段索引，因为根据name字段过滤完，得到的索引行里age和position是无序的，无法很好的利用索引。 MySQL5.6之前的版本，该查询只能在联合索引里匹配到名字是’LiLei’开头的索引，然后拿这些索引对应的主键逐个回表，到主键索引上找出相应的记录，再比对age和position这两个字段的值是否符合。 MySQL5.6引入了索引下推优化，可在索引遍历过程中，对索引中包含的所有字段先做判断，过滤掉不符合条件的记录之后再回表，可有效减少回表次数。使用索引下推优化后，查询在联合索引里匹配到名字’LiLei’开头的索引后，同时还会在索引里过滤age和position这两个字段，拿着过滤完剩下的索引对应的主键id再回表查整行数据。 索引下推会减少回表次数，对于InnoDB引擎的表索引下推只能用于二级索引，InnoDB的主键索引是聚簇索引叶子节点上保存的是全行数据，故这时索引下推并不会起到减少查询全行数据的效果。 Using filesort文件排序原理详解filesort文件排序方式有单路排序和双路排序又叫回表排序模式 单路排序：一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；用trace工具可看到sort_mode信息里显示&lt;sort_key, additional_fields&gt;或者&lt;sort_key, packed_additional_fields&gt; 双路排序：首先根据相应条件取出相应的排序字段和可直接定位行数据的行ID，然后在sort buffer中进行排序，排序完后需要再次取回其它需要的字段；用trace工具可看到sort_mode信息里显示&lt;sort_key, rowid&gt; MySQL通过比较系统变量max_length_for_sort_data与需查询字段总大小来判断使用哪种排序模式，默认1024字节，若字段总长度小于max_length_for_sort_data 则使用单路排序模式；否则使用双路排序模式。 123set session optimizer_trace=\"enabled=on\",end_markers_in_json=on;explain select * from employees where name = 'zhangsan' order by position;select * from information_schema.OPTIMIZER_TRACE; 123456789101112131415161718192021222324252627&#123;//Sql执行阶段 \"select#\": 1, \"steps\": [ &#123; \"filesort_information\": [ &#123; \"direction\": \"asc\", \"table\": \"`employees`\", \"field\": \"position\" &#125; ] /* filesort_information */, \"filesort_priority_queue_optimization\": &#123; \"usable\": false, \"cause\": \"not applicable (no LIMIT)\" &#125; /* filesort_priority_queue_optimization */, \"filesort_execution\": [ ] /* filesort_execution */, \"filesort_summary\": &#123;//文件排序信息 \"rows\": 10000, //预计扫描行数 \"examined_rows\": 10000, //参与排序的行 \"number_of_tmp_files\": 3, //使用临时文件的个数，这个值若为0代表全部使用sort_buffer内存排序，否则使用磁盘文件排序 \"sort_buffer_size\": 262056, //排序缓存的大小，单位Byte \"sort_mode\": \"&lt;sort_key, packed_additional_fields&gt;\" //排序方式，这里用的单路排序 &#125; /* filesort_summary */ &#125; ] /* steps */&#125; /* join_execution */ 1234set max_length_for_sort_data = 10; --employees表所有字段长度总和肯定大于10字节explain select * from employees where name = 'zhangsan' order by position;select * from information_schema.OPTIMIZER_TRACE;set session optimizer_trace=\"enabled=off\"; --关闭trace 123456789101112131415161718192021222324252627&#123; \"select#\": 1, \"steps\": [ &#123; \"filesort_information\": [ &#123; \"direction\": \"asc\", \"table\": \"`employees`\", \"field\": \"position\" &#125; ] /* filesort_information */, \"filesort_priority_queue_optimization\": &#123; \"usable\": false, \"cause\": \"not applicable (no LIMIT)\" &#125; /* filesort_priority_queue_optimization */, \"filesort_execution\": [ ] /* filesort_execution */, \"filesort_summary\": &#123; \"rows\": 10000, \"examined_rows\": 10000, \"number_of_tmp_files\": 2, \"sort_buffer_size\": 262136, \"sort_mode\": \"&lt;sort_key, rowid&gt;\"// 排序方式， 这里用的双路排序 &#125; /* filesort_summary */ &#125; ] /* steps */&#125; /* join_execution */ 单路排序：从索引name找到第一个满足name = ‘zhangsan’ 条件的主键id，根据主键id取出整行，取出所有字段的值，存入sort_buffer中，直到将所以满足条件的数据找完，对sort_buffer中的数据按照字段position进行排序。 双路排序：从索引name找到第一个满足name = ‘zhuge’的主键id，根据主键id取出整行，把排序字段position和主键id放到sort buffer中，直到将所以满足条件的数据找完，对sort_buffer中的字段position和主键id按照字段 position进行排序，遍历排序好的id和字段position，按照id的值回到原表中取出所有字段的值返回给客户端 对比两个排序模式，单路排序会把所有需要查询的字段都放到sort buffer中，而双路排序只会把主键和需要排序的字段放到sort buffer中进行排序，然后再通过主键回到原表查询需要的字段。 若MySQL排序内存sort_buffer配置比较小且没有条件继续增加，可适当把max_length_for_sort_data配置小点，让优化器选择使用双路排序算法，可在sort_buffer中一次排序更多的行，只需要再根据主键回到原表取数据。 若MySQL排序内存有条件可配置比较大，可以适当增大max_length_for_sort_data的值，让优化器优先选择单路排序，把需要的字段放到sort_buffer中，这样排序后就会直接从内存里返回查询结果。 MySQL通过max_length_for_sort_data 参数来控制排序，在不同场景使用不同的排序模式，从而提升排序效率。若全部使用sort_buffer内存排序一般情况下效率会高于磁盘文件排序，但不能因为这个就随便增大sort_buffer默认1M，mysql很多参数设置都是做过优化的，不要轻易调整。 优化实例示例数据12345678910111213141516171819202122232425262728CREATE TABLE `employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT '' COMMENT '姓名', `age` int(11) NOT NULL DEFAULT '0' COMMENT '年龄', `position` varchar(20) NOT NULL DEFAULT '' COMMENT '职位', `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '入职时间', PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='员工记录表';INSERT INTO employees(name,age,position,hire_time) VALUES('LiLei',22,'manager',NOW());INSERT INTO employees(name,age,position,hire_time) VALUES('HanMeimei', 23,'dev',NOW());INSERT INTO employees(name,age,position,hire_time) VALUES('Lucy',23,'dev',NOW()); -- 插入一些示例数据drop procedure if exists insert_emp;delimiter ;;create procedure insert_emp()begin declare i int; set i=1; while(i&lt;=100000)do insert into employees(name,age,position) values(CONCAT('zhangsan',i),i,'dev'); set i=i+1; end while;end;;delimiter ;call insert_emp(); 联合索引第一个字段用范围查找第一个字段用范围查找，可能不会走索引，mysql内部计算第一个字段查询范围，若结果集很大，回表效率不高，或扫描的行很多，还不如就全表扫描，就不会走索引，很明显这里没有走索引，但是不同的数据是有可能走索引的，即使走索引也只是name字段能走索引。 1EXPLAIN SELECT * FROM employees WHERE name &gt; 'LiLei' AND age = 22 AND position ='manager'; 这里使用like就能走索引，且三个字段的索引都走了，但like也不一定必定走索引 1EXPLAIN SELECT * FROM employees WHERE name like 'LiLei%' AND age = 22 AND position ='manager'; 强制索引使用force index强制使用索引，虽然使用了强制走索引让联合索引第一个字段范围查找也走索引，扫描的行rows看上去也少了点，但是最终查找效率不一定比全表扫描高，因为回表效率不高 1EXPLAIN SELECT * FROM employees force index(idx_name_age_position) WHERE name &gt; 'LiLei' AND age = 22 AND position ='manager'; 关闭查询缓存，分别查询如下两个语句，很明强制索引比不走索引慢得多 123456set global query_cache_size=0;set global query_cache_type=0;-- 执行时间0.103sSELECT * FROM employees WHERE name &gt; 'LiLei';-- 执行时间0.623sSELECT * FROM employees force index(idx_name_age_position) WHERE name &gt; 'LiLei'; 覆盖索引优化1EXPLAIN SELECT name,age,position FROM employees WHERE name &gt; 'LiLei' AND age = 22 AND position ='manager'; in和orin和or在表数据量比较大的情况会走索引，在表记录不多的情况下会选择全表扫描 12EXPLAIN SELECT * FROM employees WHERE name in ('LiLei', 'HanMeimei', 'Lucy') AND age = 22 AND position = 'manager';EXPLAIN SELECT * FROM employees WHERE (name = 'LiLei' or name = 'HanMeimei') AND age = 22 AND position = 'manager'; 将employees表复制一张employees_copy的表，只保留两三条记录 12EXPLAIN SELECT * FROM employees_copy WHERE name in ('LiLei', 'HanMeimei', 'Lucy') AND age = 22 AND position = 'manager';EXPLAIN SELECT * FROM employees_copy WHERE (name = 'LiLei' or name = 'HanMeimei') AND age = 22 AND position = 'manager'; likelike KK%一般情况都会走索引，之所以走索引，是因为用到了索引下推优化 1EXPLAIN SELECT * FROM employees WHERE name like 'LiLei%' AND age = 22 AND position ='manager'; 但若扫表数据过多，也可能不走索引 1EXPLAIN SELECT * FROM employees WHERE name like 'zhangsan%' AND age = 22 AND position ='manager'; order by与group by优化最左前缀法则，中间字段不能断，因此查询用到了name索引，从key_len=74也能看出，age索引列用在排序过程中，因为Extra字段里没有using filesort 1explain select * from employees where name = 'Lilei' and position = 'dev' order by age; key_len=74查询使用了name索引，由于用了position进行排序，跳过了age，出现了Using filesort 1explain select * from employees where name = 'Lilei' order by position; 查找只用到索引name，age和position用于排序，无Using filesort 1explain select * from employees where name = 'Lilei' order by age, position; 出现Using filesort，因为索引的创建顺序为name,age,position，但是排序的时候age和position颠倒位置了 1explain select * from employees where name = 'Lilei' order by position,age; 未出现Using filesort，因为age为常量，在排序中被优化，所以索引未颠倒 1explain select * from employees where name = 'Lilei' and age = 18 order by position,age; 虽然排序的字段列与索引顺序一样，且order by默认升序，这里position desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。Mysql8以上版本有降序索引可以支持该种查询方式。 1explain select * from employees where name = 'zhangsan' order by age asc, position desc; 对于排序来说，多个相等条件也是范围查询 1explain select * from employees where name in ('zhangsan', 'LiLei') order by age, position; 1explain select * from employees where name &gt; 'a' order by name; 用覆盖索引优化 1explain select name, age, position from employees where name &gt; 'a' order by name; MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 order by满足两种情况会使用Using index：order by语句使用索引最左前列；使用where子句与order by子句条件列组合满足索引最左前列。 尽量在索引列上完成排序，遵循索引建立时的最左前缀法则。若order by的条件不在索引列上，就会产生Using filesort。能用覆盖索引尽量用覆盖索引； group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则，对于group by的优化若不需要排序的可加上order by null禁止排序 where高于having，能写在where中的限定条件就不要去having限定了 trace工具示例数据中name大于a的数据非常多，而大于zzz的数据几乎没有，由于用name索引需要遍历name字段联合索引树，然后还需要根据遍历出来的主键值去主键索引树里再去查出最终数据，成本比全表扫描还高； 1EXPLAIN select * from employees where name &gt; 'a'; 使用覆盖索引优化 1EXPLAIN select name,age,position from employees where name &gt; 'a' ; 1EXPLAIN select * from employees where name &gt; 'zzz' ; 最终是否选择走索引或一张表涉及多个索引，最终如何选择索引，可通过trace工具来具体分析，开启trace工具会影响MySQL性能，只能临时分析sql使用，用完之后立即关闭，如下是开启trace工具命令，然后调用具体的查询语句，在查询information_schema.OPTIMIZER_TRACE的trace字段。 123456-- 开启traceset session optimizer_trace = \"enabled=on\",end_markers_in_json = on;select * from employees where name &gt; 'a' order by position;select * from information_schema.OPTIMIZER_TRACE;-- 关闭traceset session optimizer_trace=\"enabled=off\"; 查询结果如下，可以很明显看到全表扫描的成本低于索引扫描，所以mysql最终选择全表扫描： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221&#123; \"steps\": [ &#123; \"join_preparation\": &#123; -- 第一阶段：SQL准备阶段，格式化sql \"select#\": 1, \"steps\": [ &#123; \"expanded_query\": \"/* select#1 */ select `employees`.`id` AS `id`,`employees`.`name` AS `name`,`employees`.`age` AS `age`,`employees`.`position` AS `position`,`employees`.`hire_time` AS `hire_time` from `employees` where (`employees`.`name` &gt; 'a') order by `employees`.`position`\" &#125; ] /* steps */ &#125; /* join_preparation */ &#125;, &#123; \"join_optimization\": &#123; --第二阶段：SQL优化阶段 \"select#\": 1, \"steps\": [ &#123; \"condition_processing\": &#123; --条件处理 \"condition\": \"WHERE\", \"original_condition\": \"(`employees`.`name` &gt; 'a')\", \"steps\": [ &#123; \"transformation\": \"equality_propagation\", \"resulting_condition\": \"(`employees`.`name` &gt; 'a')\" &#125;, &#123; \"transformation\": \"constant_propagation\", \"resulting_condition\": \"(`employees`.`name` &gt; 'a')\" &#125;, &#123; \"transformation\": \"trivial_condition_removal\", \"resulting_condition\": \"(`employees`.`name` &gt; 'a')\" &#125; ] /* steps */ &#125; /* condition_processing */ &#125;, &#123; \"substitute_generated_columns\": &#123; &#125; /* substitute_generated_columns */ &#125;, &#123; \"table_dependencies\": [ --表依赖详情 &#123; \"table\": \"`employees`\", \"row_may_be_null\": false, \"map_bit\": 0, \"depends_on_map_bits\": [ ] /* depends_on_map_bits */ &#125; ] /* table_dependencies */ &#125;, &#123; \"ref_optimizer_key_uses\": [ ] /* ref_optimizer_key_uses */ &#125;, &#123; \"rows_estimation\": [ --预估表的访问成本 &#123; \"table\": \"`employees`\", \"range_analysis\": &#123; \"table_scan\": &#123; --全表扫描情况 \"rows\": 97275, --扫描行数 \"cost\": 19810 --查询成本 &#125; /* table_scan */, \"potential_range_indexes\": [ --查询可能使用的索引 &#123; \"index\": \"PRIMARY\", --主键索引 \"usable\": false, \"cause\": \"not_applicable\" &#125;, &#123; \"index\": \"idx_name_age_position\", --辅助索引 \"usable\": true, \"key_parts\": [ \"name\", \"age\", \"position\", \"id\" ] /* key_parts */ &#125; ] /* potential_range_indexes */, \"setup_range_conditions\": [ ] /* setup_range_conditions */, \"group_index_range\": &#123; \"chosen\": false, \"cause\": \"not_group_by_or_distinct\" &#125; /* group_index_range */, \"analyzing_range_alternatives\": &#123; --分析各个索引使用成本 \"range_scan_alternatives\": [ &#123; \"index\": \"idx_name_age_position\", \"ranges\": [ \"a &lt; name\" --索引使用范围 ] /* ranges */, \"index_dives_for_eq_ranges\": true, \"rowid_ordered\": false, --使用该索引获取的记录是否按照主键排序 \"using_mrr\": false, \"index_only\": false, --是否使用覆盖索引 \"rows\": 48637, --索引扫描行数 \"cost\": 58365, --索引使用成本 \"chosen\": false, --是否选择该索引 \"cause\": \"cost\" &#125; ] /* range_scan_alternatives */, \"analyzing_roworder_intersect\": &#123; \"usable\": false, \"cause\": \"too_few_roworder_scans\" &#125; /* analyzing_roworder_intersect */ &#125; /* analyzing_range_alternatives */ &#125; /* range_analysis */ &#125; ] /* rows_estimation */ &#125;, &#123; \"considered_execution_plans\": [ &#123; \"plan_prefix\": [ ] /* plan_prefix */, \"table\": \"`employees`\", \"best_access_path\": &#123; --最优访问路径 \"considered_access_paths\": [ --最终选择的访问路径 &#123; \"rows_to_scan\": 97275, \"access_type\": \"scan\", --访问类型：为scan，全表扫描 \"resulting_rows\": 97275, \"cost\": 19808, \"chosen\": true, --确定选择 \"use_tmp_table\": true &#125; ] /* considered_access_paths */ &#125; /* best_access_path */, \"condition_filtering_pct\": 100, \"rows_for_plan\": 97275, \"cost_for_plan\": 19808, \"sort_cost\": 97275, \"new_cost_for_plan\": 117083, \"chosen\": true &#125; ] /* considered_execution_plans */ &#125;, &#123; \"attaching_conditions_to_tables\": &#123; \"original_condition\": \"(`employees`.`name` &gt; 'a')\", \"attached_conditions_computation\": [ ] /* attached_conditions_computation */, \"attached_conditions_summary\": [ &#123; \"table\": \"`employees`\", \"attached\": \"(`employees`.`name` &gt; 'a')\" &#125; ] /* attached_conditions_summary */ &#125; /* attaching_conditions_to_tables */ &#125;, &#123; \"clause_processing\": &#123; \"clause\": \"ORDER BY\", \"original_clause\": \"`employees`.`position`\", \"items\": [ &#123; \"item\": \"`employees`.`position`\" &#125; ] /* items */, \"resulting_clause_is_simple\": true, \"resulting_clause\": \"`employees`.`position`\" &#125; /* clause_processing */ &#125;, &#123; \"reconsidering_access_paths_for_index_ordering\": &#123; \"clause\": \"ORDER BY\", \"steps\": [ ] /* steps */, \"index_order_summary\": &#123; \"table\": \"`employees`\", \"index_provides_order\": false, \"order_direction\": \"undefined\", \"index\": \"unknown\", \"plan_changed\": false &#125; /* index_order_summary */ &#125; /* reconsidering_access_paths_for_index_ordering */ &#125;, &#123; \"refine_plan\": [ &#123; \"table\": \"`employees`\" &#125; ] /* refine_plan */ &#125; ] /* steps */ &#125; /* join_optimization */ &#125;, &#123; \"join_execution\": &#123; --第三阶段：SQL执行阶段 \"select#\": 1, \"steps\": [ &#123; \"filesort_information\": [ &#123; \"direction\": \"asc\", \"table\": \"`employees`\", \"field\": \"position\" &#125; ] /* filesort_information */, \"filesort_priority_queue_optimization\": &#123; \"usable\": false, \"cause\": \"not applicable (no LIMIT)\" &#125; /* filesort_priority_queue_optimization */, \"filesort_execution\": [ ] /* filesort_execution */, \"filesort_summary\": &#123; \"rows\": 100003, \"examined_rows\": 100003, \"number_of_tmp_files\": 31, \"sort_buffer_size\": 262056, \"sort_mode\": \"&lt;sort_key, packed_additional_fields&gt;\" &#125; /* filesort_summary */ &#125; ] /* steps */ &#125; /* join_execution */ &#125; ] /* steps */&#125;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"Explain工具","date":"2021-08-30T16:00:00.000Z","path":"Blog/DB/Explain工具/","text":"使用EXPLAIN关键字可以模拟优化器执行SQL语句，分析查询语句或是结构的性能瓶颈，在select语句之前增加explain关键字，MySQL会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是执行这条SQL，若from中包含子查询，仍会执行该子查询，将结果放入临时表中。1explain select * from actor; 在查询中的每个表会输出一行，如果有两个表通过join连接查询，那么会输出两行 示例数据使用示例数据时需特别关注表的主键、二级索引、联合索引等在各种SQL下产生的不同影响 12345678910111213141516171819202122232425262728293031323334353637383940-- 以id作为主键DROP TABLE IF EXISTS `actor`;CREATE TABLE `actor` ( `id` int(11) NOT NULL, `name` varchar(45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `actor` VALUES ('1', 'a', '2017-12-22 15:27:18');INSERT INTO `actor` VALUES ('2', 'b', '2017-12-22 15:27:18');INSERT INTO `actor` VALUES ('3', 'c', '2017-12-22 15:27:18');-- 以id为主键，name为二级索引DROP TABLE IF EXISTS `film`;CREATE TABLE `film` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;INSERT INTO `film` VALUES ('3', 'film0');INSERT INTO `film` VALUES ('1', 'film1');INSERT INTO `film` VALUES ('2', 'film2');-- 以id为主键，film_id和actor_id为联合索引DROP TABLE IF EXISTS `film_actor`;CREATE TABLE `film_actor` ( `id` int(11) NOT NULL, `film_id` int(11) NOT NULL, `actor_id` int(11) NOT NULL, `remark` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_film_actor_id` (`film_id`,`actor_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `film_actor` VALUES ('1', '1', '1', null);INSERT INTO `film_actor` VALUES ('2', '1', '2', null);INSERT INTO `film_actor` VALUES ('3', '2', '1', null); Explain两个变种explain extended会在explain的基础上额外提供一些查询优化的信息。紧随其后通过show warnings命令可得到优化后的查询语句，从而看出优化器优化了什么。额外还有filtered列，是一个百分比的值，rows * filtered/100可以估算出将要和explain中前一个表进行连接的行数，前一个表指explain中的id值比当前表id值小的表。 1explain extended select * from film where id = 1; 1show warnings; explain partitions相比explain多了个partitions字段，若查询是基于分区表的话，会显示查询将访问的分区。1explain partitions select * from film where id = 1; Explain列详情idid列的编号是select的序列号，有几个select就有几个id，并且id的顺序是按select出现的顺序增长的，id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。 select_type表示对应行是简单还是复杂的查询 simple：简单查询。查询不包含子查询和union primary：复杂查询中最外层的select subquery：包含在select中但不在from子句中的子查询 derived：包含在from子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表 union：在union中的第二个和随后的select 123set session optimizer_switch='derived_merge=off'; #关闭mysql5.7新特性对衍生表的合并优化explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der;set session optimizer_switch='derived_merge=on'; #还原默认配置 1explain select 1 union all select 1; type表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。依次从最优到最差分别为：system、const、eq_ref、ref、range、index、ALL，一般来说得保证查询达到range级别，最好达到ref。NULL：mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表 1explain select min(id) from film; const： mysql能对查询的某部分进行优化并将其转化成一个常量，可看show warnings的结果，用于primary key或unique key的所有列与常数比较时，表最多有一个匹配行，读取1次，速度比较快。 1explain extended select * from (select * from film where id = 1) tmp; system：system是const的特例，表里只有一条元组匹配时为systemeq_ref：primary key或unique key索引的所有部分被连接使用，最多只会返回一条符合条件的记录。这可能是在const之外最好的联接类型了，简单的select查询不会出现这种type。1explain select * from film_actor left join film on film_actor.film_id = film.id; ref：相比eq_ref不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。 简单 select 查询，name是普通索引（非唯一索引) 1explain select * from film where name = 'film1'; 关联表查询，idx_film_actor_id是film_id和actor_id的联合索引，这里使用film_actor的左边前缀film_id部分1explain select film_id from film left join film_actor on film.id = film_actor.film_id; range：范围扫描通常出现在in(), between,&gt; ,&lt;, &gt;=等操作中。使用一个索引来检索给定范围的行。1explain select * from actor where id &gt; 1; index：扫描全索引拿到结果，一般是扫描某个二级索引，这种扫描不会从索引树根节点开始快速查找，而是直接对二级索引的叶子节点遍历和扫描，速度还是比较慢的，这种查询一般为使用覆盖索引，二级索引一般比较小，所以这种通常比ALL快一些。1explain select * from film; ALL：即全表扫描，扫描聚簇索引的所有叶子节点，通常情况下这需要增加索引来进行优化了。 1explain select * from actor; possible_keys显示查询可能使用哪些索引来查找，explain时可能出现possible_keys有值，而key为NULL的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。若该列是NULL，则没有相关的索引，可通过检查where子句看是否可以创造一个适当的索引来提高查询性能，然后用explain查看效果。 key显示实际采用哪个索引来优化对该表的访问，若没有使用索引，则该列是NULL。若想强制使用或忽视possible_keys列中的索引，在查询中使用force index、ignore index key_len显示在索引里使用的字节数，通过该值可算出具体使用了索引中的哪些列，如film_actor的联合索引 idx_film_actor_id由film_id和actor_id两个int列组成，并且每个int是4字节。通过结果中的key_len=4可推断出查询使用了第一个列film_id列来执行索引查找。 1explain select * from film_actor where film_id = 2; key_len计算规则如下： 字符串：char(n)和varchar(n)，5.0.3以后版本中，n均代表字符数，而不是字节数，若是utf-8，一个数字或字母占1个字节，一个汉字占3个字节，char(n)：若存汉字长度就是3n字节，varchar(n)：若存汉字则长度是3n + 2字节，加的2字节用来存储字符串长度，因为varchar是变长字符串 数值类型：tinyint：1字节，smallint：2字节，int：4字节，bigint：8字节 时间类型：date：3字节，timestamp：4字节，datetime：8字节 若字段允许为 NULL，需要1字节记录是否为NULL 索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 ref显示在key列记录的索引中，表查找值所用到的列或常量，常见的有const常量，字段名，如film.id rows估计要读取并检测的行数，不是结果集里的行数。 ExtraUsing index：使用覆盖索引覆盖索引：mysql执行计划explain结果里的key有使用索引，若select后面查询的字段都可以从这个索引的树中获取，该情况一般可以说是用到了覆盖索引，extra里一般都有using index； 覆盖索引一般针对的是辅助索引，整个查询结果只通过辅助索引就能拿到结果，不需要通过辅助索引树找到主键，再通过主键去主键索引树里获取其它字段值 1explain select film_id from film_actor where film_id = 1; Using where：使用where语句来处理结果，且查询的列未被索引覆盖1explain select * from actor where name = 'a'; Using index condition：查询的列不完全被索引覆盖，where条件中是一个前导列的范围1explain select * from film_actor where film_id &gt; 1; Using temporary：需创建临时表来处理查询，该情况一般是要进行优化，首先考虑用索引来优化actor.name没有索引，此时创建了张临时表来distinct 1explain select distinct name from actor; film.name建立了idx_name索引，此时查询时extra是using index，没有用临时表 1explain select distinct name from film; Using filesort：用外部排序而非索引排序，数据较小时从内存排序，否则在磁盘完成排序该情况一般也要考虑用索引来优化，actor.name未创建索引，会浏览actor整个表，保存排序关键字name和对应的id，然后排序name并检索行记录 1explain select * from actor order by name; film.name建立了idx_name索引，此时查询时extra是using index 1explain select * from film order by name; Select tables optimized away：使用某些聚合函数，如max、min来访问存在索引的某个字段1explain select min(id) from film;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"索引优化一","date":"2021-08-29T16:00:00.000Z","path":"Blog/DB/索引优化一/","text":"示例数据12345678910111213CREATE TABLE `employees`( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT '' COMMENT '姓名', `age` int(11) NOT NULL DEFAULT '0' COMMENT '年龄', `position` varchar(20) NOT NULL DEFAULT '' COMMENT '职位', `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '入职时间', PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`, `age`, `position`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 4 DEFAULT CHARSET = utf8 COMMENT ='员工记录表';INSERT INTO employees(name, age, position, hire_time) VALUES ('LiLei', 22, 'manager', NOW());INSERT INTO employees(name, age, position, hire_time) VALUES ('HanMeimei', 23, 'dev', NOW());INSERT INTO employees(name, age, position, hire_time) VALUES ('Lucy', 23, 'dev', NOW()); 全值匹配通过key_len和ref可以明显的看出生效的索引个数 1EXPLAIN SELECT * FROM employees WHERE name= 'LiLei'; 1EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22; 12EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22 AND position ='manager';EXPLAIN SELECT * FROM employees WHERE name= 'LiLei%' AND age = 22 AND position ='manager'; 最左前缀法则若索引了多列，要遵守最左前缀法则，即查询从索引的最左前列开始并且不跳过索引中的列，但MySQL在执行时会做一些顺序优化，一下三条SQL语句都是使用到了索引，explain出来的结果一样 123EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND position ='manager' AND age = 22;EXPLAIN SELECT * FROM employees WHERE position ='manager' AND name= 'LiLei' AND age = 22;EXPLAIN SELECT * FROM employees WHERE position ='manager' AND age = 22 AND name= 'LiLei'; 一下两个SQL由于跳过了索引中的name列，导致索引失效 12EXPLAIN SELECT * FROM employees WHERE age = 30 AND position = 'dev';EXPLAIN SELECT * FROM employees WHERE position = 'manager'; 以下情况任然可以用到name列的索引 12EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND position ='manager';EXPLAIN SELECT * FROM employees WHERE position ='manager' AND name= 'LiLei'; 不在索引列上做任何计算、函数、自动or手动类型转换，会导致索引失效转向全表扫描对name列做left计算导致索引失效 1EXPLAIN SELECT * FROM employees WHERE left(name, 3) = 'LiLei'; 给hire_time增加一个普通索引，查询时进行日期类型转换，导致索引失效 12ALTER TABLE `employees` ADD INDEX `idx_hire_time` (`hire_time`) USING BTREE ;EXPLAIN select * from employees where date(hire_time) ='2018‐09‐30'; 转化为日期范围查询，有可能会走索引，具体是否会走索引，MySQL底层会做一些评估 12EXPLAIN select * from employees where hire_time &gt;='2018‐09‐30 00:00:00' and hire_time &lt;= '2018‐09‐30 23:59:59';ALTER TABLE `employees` DROP INDEX `idx_hire_time`; 存储引擎不能使用索引中范围条件右边的列以下两种情况一样仅联合索引的name列和age生效了 12EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age &gt; 22 AND position ='manager';EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age &gt; 22; 尽量使用覆盖索引减少select *语句，只访问索引的查询，即索引列包含查询列。下面的例子使用了覆盖索引： 1EXPLAIN SELECT name, age, position FROM employees WHERE name= 'LiLei' AND age = 23 AND position = 'manager'; 下面的情况是未使用覆盖索引的情况，先从联合索引中查出数据的主键索引，然后再回表到主键索引中查询数据 1EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 23 AND position ='manager'; 使用不等于在使用不等于!=，&lt;&gt;，not in，not exists时候无法使用索引会导致全表扫描；使用范围查询&lt;、 &gt; 、 &lt;=、&gt;=等，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引 1EXPLAIN SELECT * FROM employees WHERE name != 'LiLei'; is null，is not null一般情况下也无法使用索引1EXPLAIN SELECT * FROM employees WHERE name is null like以通配符开头索引失效会变成全表扫描操作1EXPLAIN SELECT * FROM employees WHERE name like '%Lei%'; like Lei%相当于=常量，Lei%和Lei%33%相当于范围 12EXPLAIN SELECT * FROM employees WHERE name like 'Lei%';EXPLAIN SELECT * FROM employees WHERE name like 'Lei%33%'; 解决like’%字符串%’索引不被使用的方法，使用覆盖索引，查询字段必须是建立覆盖索引字段，如果不能使用覆盖索引则可能需要借助搜索引擎 1EXPLAIN SELECT name, age, position FROM employees WHERE name like '%Lei%'; 字符串不加单引号索引失效1EXPLAIN SELECT * FROM employees WHERE name = 1000; 少用or或in用or或in查询时，mysql不一定使用索引，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引，详见范围查询优化 1EXPLAIN SELECT * FROM employees WHERE name = 'LiLei' or name = 'HanMeimei'; 范围查询优化给年龄添加单值索引，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引，可能由于单次数据量查询过大导致优化器最终选择不走索引，优化方法可将大的范围拆分成多个小范围 1234ALTER TABLE `employees` ADD INDEX `idx_age` (`age`) USING BTREE;explain select * from employees where age &gt;=1 and age &lt;=2000;explain select * from employees where age &gt;=1 and age &lt;=10;ALTER TABLE `employees` DROP INDEX `idx_age`;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"索引的原理与使用","date":"2021-08-29T16:00:00.000Z","path":"Blog/DB/索引的原理与使用/","text":"索引是帮助MySQL高效获取数据的排好序的数据结构。索引的数据结构：二叉树、红黑树、Hash表、B-Tree； MySQL的索引使用的是B+树而不是使用的B树，因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少，指针少的情况下要保存大量数据，只能增加树的高度，而在查找数据时一次页的查找代表一次IO，导致IO操作变多，查询性能变低； Hash对索引的key进行一次hash计算就可以定位出数据存储的位置，很多时候Hash索引要比B+ 树索引更高效，仅能满足=，IN，不支持范围查询，hash冲突问题 B-Tree叶子节点具有相同的深度，叶子节点的指针为空，所有索引元素不重复，节点中的数据索引从左到右依次递增排列 B+Tree非叶子节点不存储数据，只存储索引即冗余，可以放更多的索引，叶子节点包含所有索引字段，叶子节点用指针连接，方便范围查询，提高区间访问的性能。冗余索引的构建时，是提取叶子节点中索引最小的索引。 MySQL文件页大小为16K，假设一行数据大小为1K，一页就能存16条数据，也就是一个叶子节点能存16条数据；再看非叶子节点，假设主键ID为bigint类型，那么长度为8B，指针大小在Innodb源码中为6B，一共就是14B，一页里就可以存储16K/14=1170个(主键+指针)，一颗高度为2的B+树能存储的数据为：1170*16=18720条，一颗高度为3的B+树能存储的数据为：1170 * 1170 * 16 = 21902400（千万级条） 1SHOW GLOBAL STATUS like 'Innodb_page_size’; 聚集索引聚集索引即叶节点包含了完整的数据记录，每个InnoDB表有且仅有一个主键索引即聚集索引，二级索引等都是非聚集索引，需要回表，再去查询聚集索引从而找到具体的数据。 单从索引查询效率来说，聚集索引比非聚集索引要快。 非聚集索引联合索引 例：where age = 30 and position = &#39;dev&#39;该语句是不能用到索引的，因为虽然在某一个页里面age和position是排好序的，但跳过name在不同的页相比较age和position是乱序的。 MylSAM存储引擎MylSAM索引文件和数据文件是分离的，即索引是非聚集索引（非聚蔟索引） InnoDB存储引擎文件系统的最小单元是块，一个块的大小是4K，在文件系统中即使一个文件只有一个字节，但也不得不占4KB的磁盘空间。 InnoDB存储引擎的最小存储单元是Page页，页可用于存放数据也可用于存放键值+指针，指针大小在InnoDB源码中设置为6字节，在B+树中叶子节点存放数据，非叶子节点存放键值+指针，默认一个页的大小是16382即16K。InnoDB的所有数据文件后缀为ibd，其大小始终都是16K的整倍数。数据表中的数据都是存储在页中，若一行数据大小为1K，则一页可存放16行这样的数据。InnoDB索引文件和数据文件是一个文件，表数据文件本身就是按B+Tree组织的一个索引结构文件。 一个页中不可能所有空间都用于存放数据，它还会存放一些少量的其他字段比如page level，index number等等。 为什么建议InnoDB表必须建主键，并且推荐使用整型的自增主键？若InnoDB表没有设置主键，MySQL会从数据表中选择一列数据都不相等的列作为主键索引，若找不到这样的列，MySQL会创建一个隐藏列来作为主键索引。使用整型作为主键在做比较时效率高很多。之所以用自增主键，若插入数据的主键是无序的，插入时需要对数据索引做平衡之类的操作，插入效率变低。 为什么非主键索引结构叶子节点存储的是主键的索引值？一致性和节省存储空间 InnoDB二级索引结构","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"Tomcat启动过程","date":"2021-08-27T16:00:00.000Z","path":"Blog/中间件/Tomcat/Tomcat启动过程/","text":"Tomcat的启动是通过Bootstrap类的main方法来启动的，Bootstrap类只是入口，真正的初始化是通过Catalina类来完成的。启动的时候会将阻塞标志设置为true， 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static void main(String args[]) &#123; if (daemon == null) &#123; Bootstrap bootstrap = new Bootstrap(); try &#123; bootstrap.init(); // catalinaaemon &#125; catch (Throwable t) &#123; return; &#125; daemon = bootstrap; &#125; else &#123; Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); &#125; try &#123; String command = \"start\"; if (args.length &gt; 0) &#123; command = args[args.length - 1]; &#125; if (command.equals(\"startd\")) &#123; args[args.length - 1] = \"start\"; daemon.load(args); daemon.start(); &#125; else if (command.equals(\"stopd\")) &#123; args[args.length - 1] = \"stop\"; daemon.stop(); &#125; else if (command.equals(\"start\")) &#123; daemon.setAwait(true); // 设置阻塞标志 daemon.load(args); // 解析server.xml,初始化Catalina daemon.start(); if (null == daemon.getServer()) &#123; System.exit(1); &#125; &#125; else if (command.equals(\"stop\")) &#123; daemon.stopServer(args); &#125; else if (command.equals(\"configtest\")) &#123; daemon.load(args); if (null == daemon.getServer()) &#123; System.exit(1); &#125; System.exit(0); &#125; &#125; catch (Throwable t) &#123; System.exit(1); &#125;&#125; 启动前首先会调用bootstrap.init()方法进行类加载器的初始化，同时初始化一个Catalina实例，把Catalina的父类加载器设置为了sharedLoader类加载器，且默认catalinaLoader、sharedLoader默认其实就是commonLoader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public void init() throws Exception &#123; // catalina.home表示安装目录 // catalina.base表示工作目录 setCatalinaHome(); setCatalinaBase(); // 初始化commonLoader、catalinaLoader、sharedLoader // 其中catalinaLoader、sharedLoader默认其实就是commonLoader initClassLoaders(); // 设置线程的所使用的类加载器，默认情况下就是commonLoader Thread.currentThread().setContextClassLoader(catalinaLoader); // 如果开启了SecurityManager，那么则要提前加载一些类 SecurityClassLoad.securityClassLoad(catalinaLoader); // 加载Catalina类，并生成instance if (log.isDebugEnabled()) log.debug(\"Loading startup class\"); Class&lt;?&gt; startupClass = catalinaLoader.loadClass(\"org.apache.catalina.startup.Catalina\"); Object startupInstance = startupClass.newInstance(); // Set the shared extensions class loader // 设置Catalina实例的父级类加载器为sharedLoader(默认情况下就是commonLoader) if (log.isDebugEnabled()) log.debug(\"Setting startup class properties\"); String methodName = \"setParentClassLoader\"; Class&lt;?&gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(\"java.lang.ClassLoader\"); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); catalinaDaemon = startupInstance;&#125;private void initClassLoaders() &#123; try &#123; // CommonClassLoader是一个公共的类加载器,默认加载$&#123;catalina.base&#125;/lib,$&#123;catalina.base&#125;/lib/*.jar,$&#123;catalina.home&#125;/lib,$&#123;catalina.home&#125;/lib/*.jar下的class commonLoader = createClassLoader(\"common\", null); // 虽然这个地方parent是null，实际上是appclassloader // System.out.println(\"commonLoader的父类加载器====\"+commonLoader.getParent()); if( commonLoader == null ) &#123; // no config file, default to this loader - we might be in a 'single' env. commonLoader = this.getClass().getClassLoader(); &#125; // 下面这个两个类加载器默认情况下就是commonLoader catalinaLoader = createClassLoader(\"server\", commonLoader); sharedLoader = createClassLoader(\"shared\", commonLoader); &#125; catch (Throwable t) &#123; System.exit(1); &#125;&#125; 首先是通过Catalina的load方法进行资源的加载和初始化，首先是通过Digester解析器对server.xml配置文件进行解析，解析server.xml最主要的作用： 把server.xml中定义的节点都生成对应的Java对象，如在解析某个Host节点时对应生成一个StandardHost对象 把server.xml中定义的节点的层级关系解析出来，如StandardContext对象.addChild(StandardHost对象) 设置每个容器的pipeline的基础Valve 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public void load() &#123; if (loaded) &#123; return; &#125; loaded = true; long t1 = System.nanoTime(); // 如果catalinaHome和catalinaBase是相对路径，那么在这里会转化为绝对路径 initDirs(); initNaming(); // 初始化server.xml文件解析器 Digester digester = createStartDigester(); InputSource inputSource = null; InputStream inputStream = null; File file = null; try &#123; // 先从文件系统获取server.xml try &#123; file = configFile(); // 获取catalina.base目录下的conf/server.xml文件 inputStream = new FileInputStream(file); inputSource = new InputSource(file.toURI().toURL().toString()); &#125; catch (Exception e) &#123; &#125; // 如果文件系统没有，则从classloader中获取server.xml if (inputStream == null) &#123; try &#123; inputStream = getClass().getClassLoader().getResourceAsStream(getConfigFile()); inputSource = new InputSource(getClass().getClassLoader().getResource(getConfigFile()).toString()); &#125; catch (Exception e) &#123; &#125; &#125; // 如果没找到server.xml，那么则从classloader中找server-embed.xml if( inputStream==null ) &#123; try &#123; inputStream = getClass().getClassLoader() .getResourceAsStream(\"server-embed.xml\"); inputSource = new InputSource(getClass().getClassLoader() .getResource(\"server-embed.xml\").toString()); &#125; catch (Exception e) &#123; &#125; &#125; // 如果没找到server.xml或server-embed.xml，那么告警 // 如果文件存在，判断文件没有可读权限 if (inputStream == null || inputSource == null) &#123; return; &#125; try &#123; // 解析server.xml或server-embed.xml文件 inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &#125; &#125; // 解析完server.xml或server-embed.xml后，将catalina设置到StandardServer中 getServer().setCatalina(this); // 把System.out和System.err替换成SystemLogHandler对象 initStreams(); // 解析完配置文件，开始初始化Server，而从初始化Server开始，就包括了一系列的子组件的初始化 try &#123; getServer().init(); &#125; catch (LifecycleException e) &#123; &#125;&#125; 解析server.xml生成实例的流程及主要做的事如下所示： StandardServer server = new StandardServer(); catalina.setServer(server); server.addLifecycleListener(...); StandardService service = new StandardService(); server.addService(service); Connector connector = new Connector(); // 会根据配置初始化protocolHandler endpoint = new JIoEndpoint(); // 初始化Endpoint，JioEndpoint中会setMaxConnections(0); cHandler = new Http11ConnectionHandler(this); ((JIoEndpoint) endpoint).setHandler(cHandler); // endpoint对应的连接处理器 service.addConnector(connector); Engine engine = new StandardEngine(); // pipeline.setBasic(new StandardEngineValve()); service.setContainer(engine); Host host = new StandardHost(); // pipeline.setBasic(new StandardHostValve()); engine.addChild(host); Context context = new StandardContext(); // pipeline.setBasic(new StandardContextValve()); host.addChild(context); engine.setParentClassLoader(Catalina.class.getClassLoader()); // 实际调用的是ContainerBase.setParentClassLoader方法，设置属性parentClassLoader为shareClassLoader 然后调用LifecycleBase的init()，执行各个容器自身的状态改变而配置的事件监听器，以及各自实现的initInternal()初始化方法。Tomcat初始化主要做了以下事情： 将StandardServer实例注册到JMX 将StringCache实例注册到JMX 将StandardService实例注册到JMX container.init(); // 对StandardEngine进行初始化 初始化startStopExecutor线程池，用来启动子容器的 connector.init(); // 对Connector进行初始化 adapter = new CoyoteAdapter(this); protocolHandler.setAdapter(adapter); protocolHandler.init(); // 初始化协议处理器 endpoint.init(); // 初始化协议处理器对应的endpoint，默认在初始化的时候就会bind endpoint.bind() serverSocketFactory = new DefaultServerSocketFactory(this); serverSocket = serverSocketFactory.createSocket(getPort(), getBacklog(), getAddress()); mapperListener.init(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108// getServer().init()实际调用的是StandardServer的initInternal()public final class StandardServer extends LifecycleMBeanBase implements Server &#123; protected void initInternal() throws LifecycleException &#123; super.initInternal(); // 将StandardServer实例注册到jmx // 每个Server下都有一个全局的StringCache onameStringCache = register(new StringCache(), \"type=StringCache\"); // MBeanFactory是JMX中用来管理Server的一个对象，通过MBeanFactory可以创建、移除Connector、Host等待 MBeanFactory factory = new MBeanFactory(); factory.setContainer(this); onameMBeanFactory = register(factory, \"type=MBeanFactory\"); // Register the naming resources globalNamingResources.init(); // service初始化 for (int i = 0; i &lt; services.length; i++) &#123; services[i].init(); &#125; &#125;&#125;// services[i].init()实际调用的是StandardService的initInternal()public class StandardService extends LifecycleMBeanBase implements Service &#123; protected void initInternal() throws LifecycleException &#123; super.initInternal(); // 将StandardService注册到jmx中 // 将Service下的容器进行初始化，默认情况下是StandardEngine if (container != null) &#123; container.init(); // 注意：这里是Engine，这个流程只会初始化StandardEngine，并没有去初始话Engine下的Host，那么Host是在哪初始化的呢？ // 实际上，对于Host容器，并不需要进行初始化 &#125; // 初始化线程池，可以在Service下配置定义executor，默认实现类为org.apache.catalina.core.StandardThreadExecutor // 这个初始化只是走了一下生命周期的初始化流程，没有其他作用 for (Executor executor : findExecutors()) &#123; if (executor instanceof LifecycleMBeanBase) &#123; ((LifecycleMBeanBase) executor).setDomain(getDomain()); &#125; executor.init(); &#125; // 初始化连接器，为什么这里要同步，而上面的container和executor不同步？ synchronized (connectorsLock) &#123; for (Connector connector : connectors) &#123; try &#123; connector.init(); &#125; catch (Exception e) &#123;&#125; &#125; &#125; &#125;&#125;// container.init()实际调用的是StandardEngine的initInternal()public class StandardEngine extends ContainerBase implements Engine &#123; protected void initInternal() throws LifecycleException &#123; // Realm，域对象，用来存储用户、密码、权限等的数据对象，它的存储方式可以是内存、xml、数据库等待，主要作用是配合Tomcat实现资源认证。 getRealm(); super.initInternal(); // Engine是容器，所以这里会调用ContainerBase的initInternal方法。 &#125;&#125;public abstract class ContainerBase extends LifecycleMBeanBase implements Container &#123; protected void initInternal() throws LifecycleException &#123; BlockingQueue&lt;Runnable&gt; startStopQueue = new LinkedBlockingQueue&lt;Runnable&gt;(); // 开启、停止容器的线程池 startStopExecutor = new ThreadPoolExecutor(getStartStopThreadsInternal(),getStartStopThreadsInternal(), 10, TimeUnit.SECONDS,startStopQueue,new StartStopThreadFactory(getName() + \"-startStop-\")); startStopExecutor.allowCoreThreadTimeOut(true); super.initInternal(); // 将容器注册到jmx中 &#125;&#125;// connector.init()实际调用的是Connector的initInternal()public class Connector extends LifecycleMBeanBase &#123; protected void initInternal() throws LifecycleException &#123; super.initInternal(); adapter = new CoyoteAdapter(this); protocolHandler.setAdapter(adapter); if (null == parseBodyMethodsSet) &#123; setParseBodyMethods(getParseBodyMethods()); &#125; if (protocolHandler.isAprRequired() &amp;&amp;!AprLifecycleListener.isAprAvailable()) &#123; throw new LifecycleException(sm.getString(\"coyoteConnector.protocolHandlerNoApr\", getProtocolHandlerClassName())); &#125; try &#123; protocolHandler.init(); &#125; catch (Exception e) &#123;&#125; mapperListener.init(); &#125;&#125;// protocolHandler.init()实际调用的是AbstractProtocol的init()，然后在调用具体的endpoint.init()public abstract class AbstractProtocol&lt;S&gt; implements ProtocolHandler, MBeanRegistration &#123; public void init() throws Exception &#123; if (oname == null) &#123; oname = createObjectName(); if (oname != null) &#123; Registry.getRegistry(null, null).registerComponent(this, oname, null); &#125; &#125; if (this.domain != null) &#123; try &#123; tpOname = new ObjectName(domain + \":\" + \"type=ThreadPool,name=\" + getName()); Registry.getRegistry(null, null).registerComponent(endpoint, tpOname, null); &#125; catch (Exception e) &#123; getLog().error(sm.getString(\"abstractProtocolHandler.mbeanRegistrationFailed\", tpOname, getName()), e); &#125; rgOname=new ObjectName(domain + \":type=GlobalRequestProcessor,name=\" + getName()); Registry.getRegistry(null, null).registerComponent(getHandler().getGlobal(), rgOname, null ); &#125; String endpointName = getName(); endpoint.setName(endpointName.substring(1, endpointName.length()-1)); try &#123; endpoint.init(); &#125; catch (Exception ex) &#123; throw ex; &#125; &#125;&#125; 容器的启动启动容器主要是部署应用，部署应用分为两部分：部署server.xml中定义的Context，部署webapp文件夹下的Context。部署一个应用主要分为以下步骤： 生成Context对象，server.xml中定义的Context在解析server.xml时就已经生成了，webapp文件夹下的是在部署之前生成的 为每个应用生成一个WebappClassLoader 解析web.xml 设置Context对象中的属性，比如有哪些Wrapper 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public class Catalina &#123; public void start() &#123; if (getServer() == null) load(); if (getServer() == null) return; try &#123; getServer().start(); // &#125; catch (LifecycleException e) &#123; try &#123; getServer().destroy(); &#125; return; &#125; // Register shutdown hook if (useShutdownHook) &#123; if (shutdownHook == null) &#123; shutdownHook = new CatalinaShutdownHook(); &#125; Runtime.getRuntime().addShutdownHook(shutdownHook); LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) &#123; ((ClassLoaderLogManager) logManager).setUseShutdownHook(false); &#125; &#125; // 是否需要阻塞，await标记是在通过Bootstrap类启动时设置为true的 if (await) &#123; // true await(); // 使用ServerSocket来监听shutdown命令来阻塞 stop(); // 如果阻塞被解开，那么开始停止流程 &#125; &#125; public void await() &#123; getServer().await(); &#125;&#125;public final class StandardServer extends LifecycleMBeanBase implements Server &#123; public void await() &#123; if( port == -2 ) &#123; return; &#125; if( port==-1 ) &#123; try &#123; awaitThread = Thread.currentThread(); while(!stopAwait) &#123; try &#123; Thread.sleep( 10000 ); &#125; &#125; &#125; finally &#123; awaitThread = null; &#125; return; &#125; try &#123; awaitSocket = new ServerSocket(port, 1, InetAddress.getByName(address)); &#125; catch (IOException e) &#123; return; &#125; try &#123; awaitThread = Thread.currentThread(); while (!stopAwait) &#123; ServerSocket serverSocket = awaitSocket; if (serverSocket == null) &#123; break; &#125; Socket socket = null; StringBuilder command = new StringBuilder(); try &#123; InputStream stream; long acceptStartTime = System.currentTimeMillis(); try &#123; socket = serverSocket.accept(); socket.setSoTimeout(10 * 1000); // Ten seconds stream = socket.getInputStream(); &#125; catch (SocketTimeoutException ste) &#123; continue; &#125; catch (AccessControlException ace) &#123; continue; &#125; catch (IOException e) &#123; if (stopAwait) break; break; &#125; int expected = 1024; // Cut off to avoid DoS attack while (expected &lt; shutdown.length()) &#123; if (random == null) random = new Random(); expected += (random.nextInt() % 1024); &#125; while (expected &gt; 0) &#123; int ch = -1; try &#123; ch = stream.read(); &#125; catch (IOException e) &#123; ch = -1; &#125; if (ch &lt; 32 || ch == 127) &#123; break; &#125; command.append((char) ch); expected--; &#125; &#125; finally &#123; try &#123; if (socket != null) socket.close(); &#125; &#125; boolean match = command.toString().equals(shutdown); if (match) &#123; break; &#125; &#125; &#125; finally &#123; ServerSocket serverSocket = awaitSocket; awaitThread = null; awaitSocket = null; if (serverSocket != null) &#123; try &#123; serverSocket.close(); &#125; &#125; &#125; &#125;&#125; 容器的启动跟容器的初始化类似，是调用LifecycleBase的start()，执行各个容器自身的状态改变而配置的事件监听器，以及各自实现的startInternal初始化方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250// getServer().start()实际调用的是StandardServer的startInternal()public final class StandardServer extends LifecycleMBeanBase implements Server &#123; protected void startInternal()() throws LifecycleException &#123; fireLifecycleEvent(CONFIGURE_START_EVENT, null); setState(LifecycleState.STARTING); globalNamingResources.start(); synchronized (servicesLock) &#123; for (int i = 0; i &lt; services.length; i++) &#123; services[i].start(); &#125; &#125; &#125;&#125;// services[i].start()实际调用的是StandardServer的startInternal()public class StandardService extends LifecycleMBeanBase implements Service &#123; protected void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); if (container != null) &#123; synchronized (container) &#123; container.start(); &#125; &#125; synchronized (executors) &#123; for (Executor executor: executors) &#123; executor.start(); &#125; &#125; synchronized (connectorsLock) &#123; for (Connector connector: connectors) &#123; try &#123; if (connector.getState() != LifecycleState.FAILED) &#123; connector.start(); &#125; &#125; &#125; &#125; &#125;&#125;// container.start()实际调用的是StandardEngine的startInternal()public class StandardEngine extends ContainerBase implements Engine &#123; protected synchronized void startInternal() throws LifecycleException &#123; // 调用ContainerBase的startInternal，以异步的方式启动子容器 super.startInternal(); &#125;&#125;public abstract class ContainerBase extends LifecycleMBeanBase implements Container &#123; protected synchronized void startInternal() throws LifecycleException &#123; // 启动下级组件，如果有的话，容器的类加载器 Loader loader = getLoaderInternal(); if ((loader != null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); Manager manager = getManagerInternal(); if ((manager != null) &amp;&amp; (manager instanceof Lifecycle)) ((Lifecycle) manager).start(); Cluster cluster = getClusterInternal(); if ((cluster != null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm = getRealmInternal(); if ((realm != null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); DirContext resources = getResourcesInternal(); if ((resources != null) &amp;&amp; (resources instanceof Lifecycle)) ((Lifecycle) resources).start(); // 如果在server.xml中配置了&lt;Context/&gt;节点，那么对于Host节点就存在children，这个时候就会启动context, 并且是通过异步启动的 Container children[] = findChildren(); List&lt;Future&lt;Void&gt;&gt; results = new ArrayList&lt;Future&lt;Void&gt;&gt;(); for (int i = 0; i &lt; children.length; i++) &#123; results.add(startStopExecutor.submit(new StartChild(children[i]))); &#125; for (Future&lt;Void&gt; result : results) &#123; try &#123; result.get(); &#125; &#125; if (pipeline instanceof Lifecycle) &#123; ((Lifecycle) pipeline).start(); &#125; // 这个时候会触发START_EVENT事件，会进行deployApps setState(LifecycleState.STARTING); // Engine容器启动一个background线程 threadStart(); &#125;&#125;public class StandardHost extends ContainerBase implements Host &#123; protected synchronized void startInternal() throws LifecycleException &#123; String errorValve = getErrorReportValveClass(); if ((errorValve != null) &amp;&amp; (!errorValve.equals(\"\"))) &#123; try &#123; boolean found = false; Valve[] valves = getPipeline().getValves(); for (Valve valve : valves) &#123; if (errorValve.equals(valve.getClass().getName())) &#123; found = true; break; &#125; &#125; if(!found) &#123; Valve valve = (Valve) Class.forName(errorValve).getDeclaredConstructor().newInstance(); getPipeline().addValve(valve); &#125; &#125; &#125; super.startInternal(); &#125;&#125;public class StandardContext extends ContainerBase implements Context, NotificationEmitter &#123; protected synchronized void startInternal() throws LifecycleException &#123; setConfigured(false); if (namingResources != null) &#123; namingResources.start(); &#125; if (webappResources == null) &#123; // (1) Required by Loader try &#123; // 设置Context的资源，赋值webappResources属性，docBase地址 String docBase = getDocBase(); if (docBase == null) &#123; setResources(new EmptyDirContext()); &#125; else if (docBase.endsWith(\".war\") &amp;&amp; !(new File(getBasePath())).isDirectory()) &#123; setResources(new WARDirContext()); &#125; else &#123; setResources(new FileDirContext()); &#125; &#125; &#125; // 如果在Context节点下配置了Loader节点，那么就会在解析配置文件的时候就会初始化Loader,比如： // &lt;Context path=\"/ServletDemo\" docBase=\"C:\\Users\\IdeaProjects\\ServletDemo\\target\\ServletDemo\" addWebinfClassesResources=\"true\"&gt;&lt;Loader/&gt;&lt;/Context&gt; // 如果没有配，则生成一个WebappLoader if (getLoader() == null) &#123; // Webapp类加载器的父类加载器为Host的ParentClassLoader，最终就是Catalina类的类加载器，其实就是CommonClassLoader WebappLoader webappLoader = new WebappLoader(getParentClassLoader()); webappLoader.setDelegate(getDelegate()); setLoader(webappLoader); &#125; getCharsetMapper(); // 创建work目录，比如work\\Catalina\\localhost\\ServletDemo postWorkDirectory(); // Reading the \"catalina.useNaming\" environment variable String useNamingProperty = System.getProperty(\"catalina.useNaming\"); if ((useNamingProperty != null) &amp;&amp; (useNamingProperty.equals(\"false\"))) &#123; useNaming = false; &#125; if (ok &amp;&amp; isUseNaming()) &#123; if (getNamingContextListener() == null) &#123; NamingContextListener ncl = new NamingContextListener(); ncl.setName(getNamingContextName()); ncl.setExceptionOnFailedWrite(getJndiExceptionOnFailedWrite()); addLifecycleListener(ncl); setNamingContextListener(ncl); &#125; &#125; // 将当前线程的类加载器设置为WebClassLoader，记录一下当前线程的classloader ClassLoader oldCCL = bindThread(); try &#123; if (ok) &#123; Loader loader = getLoaderInternal(); // 获取Context的类加载器 if ((loader != null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); // 启动类加载器，包括初始话DirContext unbindThread(oldCCL); oldCCL = bindThread(); Cluster cluster = getClusterInternal(); if ((cluster != null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm = getRealmInternal(); if ((realm != null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); DirContext resources = getResourcesInternal(); if ((resources != null) &amp;&amp; (resources instanceof Lifecycle)) ((Lifecycle) resources).start(); // 这里会发布一个CONFIGURE_START_EVENT事件，虽然是事件，但其实并不是异步，ContextConfig会接收到此事件 fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null); // web.xml // Context下是Wrapper，这些Wrapper是什么时候添加进Context中的？就是上面的CONFIGURE_START_EVENT事件触发的 // 如果Wrapper不可用就启动，默认情况下是已经启动了的。 for (Container child : findChildren()) &#123; if (!child.getState().isAvailable()) &#123; child.start(); &#125; &#125; // 启动pipeline if (pipeline instanceof Lifecycle) &#123; ((Lifecycle) pipeline).start(); &#125; &#125; &#125; finally &#123; unbindThread(oldCCL); &#125; mapper.setContext(getPath(), welcomeFiles, getResources()); try &#123; if (ok) &#123; getServletContext().setAttribute(JarScanner.class.getName(), getJarScanner()); &#125; mergeParameters(); for (Map.Entry&lt;ServletContainerInitializer, Set&lt;Class&lt;?&gt;&gt;&gt; entry : initializers.entrySet()) &#123; try &#123; entry.getKey().onStartup(entry.getValue(), getServletContext()); &#125; catch (ServletException e) &#123; break; &#125; &#125; try &#123; Manager manager = getManagerInternal(); if ((manager != null) &amp;&amp; (manager instanceof Lifecycle)) &#123; ((Lifecycle) getManager()).start(); &#125; &#125; catch(Exception e) &#123; ok = false; &#125; super.threadStart(); &#125; if (getLoader() instanceof WebappLoader) &#123; ((WebappLoader) getLoader()).closeJARs(true); &#125; &#125;&#125;// connector.start()实际调用的是Connector的startInternal()：启动Endpoint开始接收请求，构造Mapper对象，用来处理请求时，快速解析出当前请求对应哪个Context哪个Wrapperpublic class Connector extends LifecycleMBeanBase &#123; protected void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); try &#123; protocolHandler.start(); &#125; mapperListener.start(); &#125;&#125;// protocolHandler.start()实际调用的是AbstractProtocol的start()public abstract class AbstractProtocol&lt;S&gt; implements ProtocolHandler, MBeanRegistration &#123; public void start() throws Exception &#123; try &#123; endpoint.start(); &#125; &#125;&#125;// mapperListener.start()实际调用的是MapperListener的startInternal()public class MapperListener extends LifecycleMBeanBase implements ContainerListener, LifecycleListener &#123; public void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); findDefaultHost(); Engine engine = (Engine) connector.getService().getContainer(); addListeners(engine); Container[] conHosts = engine.findChildren(); for (Container conHost : conHosts) &#123; Host host = (Host) conHost; if (!LifecycleState.NEW.equals(host.getState())) &#123; registerHost(host); // 将每个host注册到Mapper.hosts中 &#125; &#125; &#125;&#125; catalina.start() getServer().start() fireLifecycleEvent(CONFIGURE_START_EVENT, null) services[i].start() container.start(); // 启动StandardEngine results.add(startStopExecutor.submit(new StartChild(children[i]))); // 每个Childrean容器StandardHost用单独的线程启动 results.add(startStopExecutor.submit(new StartChild(children[i]))); // 每个Childrean容器StandardContext用单独的线程启动，以下为一个应用的启动过程 生成一个WebappLoader 启动WebappLoader 生成WebappClassLoader 将/WEB-INF/classes和/WEB-INF/lib目录作为loaderRepositories，后面应用如果加载类就从这两个目录加载 fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null); 解析web.xml文件 创建WebXml对象 解析web.xml文件内容设置WebXml对象属性 WebXML对象有以下几个主要属性 Map&lt;String,ServletDef&gt; servlets Map&lt;String,String&gt; servletMappings Map&lt;String,FilterDef&gt; filters Set&lt;FilterMap&gt; filterMaps 收集ServletContainerInitializers 将WebXML对象中的信息配置到Context对象中 context.addFilterDef(filter); context.addFilterMap(filterMap); context.addApplicationListener(listener); 遍历每个ServletDef，生成一个Wrapper，context.addChild(wrapper); 调用ServletContainerInitializers 上面会启动在server.xml中定义的Context，接下来会启动webapp文件夹下面的Context，是通过HostConfig触发的，调用HostConfig的start() deployApps(); deployDescriptors(configBase, configBase.list()); // 描述符部署 deployWARs(appBase, filteredAppPaths); // war包部署 deployDirectories(appBase, filteredAppPaths); // 文件夹部署 生成Context对象 context.setName(cn.getName()); context.setPath(cn.getPath()); host.addChild(context); // 这里会启动context，启动Context就会执行和上面类似的步骤 threadStart(); // 启动一个background线程 executor.start(); // 启动线程池, 如果用的默认连接池，这里不会启动 connector.start(); // 启动请求连接器 protocolHandler.start(); // 启动接收连接 endpoint.start(); // 启动Endpoint 如果没有配置Executor，就创建一个默认的Executor 初始化connectionLimitLatch 如果是NIO，则运行Poller线程 运行Acceptor线程 mapperListener.start(); 主要初始化Mapper对象，Mapper对象的结构层级如下 Mapper中有属性Host[] hosts Host中有属性ContextList contextList ContextList中有属性Context[] contexts Context中有属性ContextVersion[] versions ContextVersion中有如下属性 Wrapper[] exactWrappers，保存需要根据Servlet名字精确匹配的Wrapper Wrapper[] wildcardWrappers，保存需要根据Servlet名字匹配以(“/*”)结尾的Wrapper Wrapper[] extensionWrappers，保存需要根据Servlet名字匹配以(“*.”)开始的Wrapper Wrapper中有如下两个属性 name，Wrapper的名字 object，真实的Wrapper的对象 catalina.await(); // 使用ServerSocket来监听shutdown命令来阻塞 catalina.stop(); // 如果阻塞被解开，那么开始停止流程","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Tomcat","slug":"中间件/Tomcat","permalink":"https://yaoyinglong.github.io/categories/中间件/Tomcat/"}]},{"title":"Tomcat热部署热加载","date":"2021-08-27T16:00:00.000Z","path":"Blog/中间件/Tomcat/Tomcat热部署热加载/","text":"热部署和热加载是类似的，都是在不重启Tomcat的情况下，使得应用的最新代码生效，热部署表示重新部署应用，它的执行主体是Host表示主机；热加载表示重新加载class，它的执行主体是Context表示应用。 Tomcat中的后台线程热部署和热加载都需要监听相应的文件或文件夹是否发生了变化。它们都是由Tomcat的后台线程触发的。BackgroundProcessor就表示后台线程。每个容器都可以拥有一个BackgroundProcessor，但默认情况下只有Engine容器会在启动的时候启动一个BackgroundProcessor线程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public abstract class ContainerBase extends LifecycleMBeanBase implements Container &#123; protected synchronized void startInternal() throws LifecycleException &#123; // Engine容器启动一个background线程 threadStart(); &#125; protected void threadStart() &#123; if (thread != null) return; // System.out.println(this.getInfo() + \"的backgroundProcessorDelay等于=\" + backgroundProcessorDelay); // 默认情况下只有Engine的backgroundProcessorDelay大于0，为10， // 也就是说，虽然每个容器在启动的时候都会走到当前方法，但是只有Engine能继续往下面去执行 // 但是其他容器是可以配置backgroundProcessorDelay属性的，只要配置了大于0，那么这个容器也会单独开启一个backgroundProcessor线程 if (backgroundProcessorDelay &lt;= 0) return; threadDone = false; String threadName = \"ContainerBackgroundProcessor[\" + toString() + \"]\"; // ContainerBackgroundProcessor线程每隔一段时间会调用容器内的backgroundProcess方法，并且会调用子容器的backgroundProcess方法 thread = new Thread(new ContainerBackgroundProcessor(), threadName); thread.setDaemon(true); thread.start(); &#125; protected class ContainerBackgroundProcessor implements Runnable &#123; @Override public void run() &#123; Throwable t = null; String unexpectedDeathMessage = sm.getString(\"containerBase.backgroundProcess.unexpectedThreadDeath\", Thread.currentThread().getName()); try &#123; while (!threadDone) &#123; try &#123; Thread.sleep(backgroundProcessorDelay * 1000L); &#125; if (!threadDone) &#123; // 获取当前的容器 Container parent = (Container) getMappingObject(); ClassLoader cl = Thread.currentThread().getContextClassLoader(); if (parent.getLoader() != null) &#123; System.out.println(parent.getName() + \"有loader\"); cl = parent.getLoader().getClassLoader(); &#125; // 执行子容器的background processChildren(parent, cl); &#125; &#125; &#125; catch (RuntimeException e) &#123; t = e; throw e; &#125; catch (Error e) &#123; t = e; throw e; &#125; finally &#123; if (!threadDone) &#123; log.error(unexpectedDeathMessage, t); &#125; &#125; &#125; protected void processChildren(Container container, ClassLoader cl) &#123; try &#123; if (container.getLoader() != null) &#123; Thread.currentThread().setContextClassLoader(container.getLoader().getClassLoader()); &#125; container.backgroundProcess(); &#125; finally &#123; Thread.currentThread().setContextClassLoader(cl); &#125; Container[] children = container.findChildren(); for (int i = 0; i &lt; children.length; i++) &#123; if (children[i].getBackgroundProcessorDelay() &lt;= 0) &#123; // 调用子容器的backgroundProcess方法， delay小于0才调用，如果大于0，则该容器会有自己单独的background线程 processChildren(children[i], cl); &#125; &#125; &#125; &#125;&#125; 该线程会每隔一段时间（可以设置，单位为秒），去执行后台任务，先执行本容器定义的后台任务，然后再执行子容器的定义的后台任务，子容器的任务执行完成后会继续执行其子容器的任务，直到没有子容器为止。就算每个容器自己开启一个BackgroundProcessor，也只不过是多了一个执行相同任务的线程而已，执行任务的效率有所提升。 对于后台任务，所有容器会有一些统一的任务需要执行，在这个过程中的第2步中会触发热加载，第6步中会触发热部署： 集群服务器心跳 如果一个容器拥有自己的类加载器，那么查看是否需要进行热加载 检查Session是否过期 执行每个容器对于的Realm对应的后台任务 执行每个容器中pipeline中的每个valve的后台任务 发布PERIODIC_EVENT事件 热加载我们可以在Context上配置reloadable属性为true，这样就表示该应用开启了热加载功能，默认是false。热加载触发的条件是：WEB-INF/classes目录下的文件发生了变化，WEB-INF/lib目录下的jar包添加、删除、修改都会触发热加载。 热加载大致流程为： 设置当前Context不能接受以及处理请求标志为true 停止当前Context 启动当前Context 设置当前Context不能接受以及处理请求标志为false 创建每个应用都单独自定义的WebappClassLoader，解析web.xml文件，这一步会做很多事情，但是主要的目的是寻找定义的Servlet并把它添加到Context中去，而对于寻找Servlet需要进行两个方面的寻找，一是从web.xml中寻找定义的Servlet，二是从寻找class文件中添加了@WebServlet注解的类。此时不会去加载定义的Servlet类，Servlet类的加载是在后面步骤发生的，Tomcat是直接先把class文件当做一个普通文件，然后看这个文件对应的地方是否存在一个WebServlet注解，若存在则认为这个class文件是一个Servlet，把该class的全名封装到Servlet对象中去，然后将Servlet对象添加到Context对象中。在解析web.xml时也是类似了，对于我们定义的Servlet，最后都会生成一个Servlet对象，然后记录一个这个Servlet对象对应的class的全名，最后把Servlet对象添加到Context中去。 我们在使用Servlet的时候还会用其他的一些注解比如@ServletSecurity、@RunAs等等，对于这些注解是有特定功能的，Tomcat为了识别这个注解，此时就要去真正加载我们的Servlet类了。当然要不要识别这些注解是可以配置的，如果不识别，那么这一步就不会发生了，则Servlet类的加载就会在有请求过来时才会进行类的加载。 加载类过程 调用WebappClassLoaderBase的loadClass方法进行类的加载，该方法传递一个类的全限定名。 要加载一个类，先得找到这个类在哪里，对应的是哪个classs文件，所以Tomcat中有一个缓存对象，该对象保存了一个类的全限定名对应的资源路径。当然在第一次加载这个类时，这个缓存是空的，所以这个时候就要去寻找这个类对应的class文件地址，找到之后再缓存。接下来就来分析是怎么找到这个class文件地址的。 其实查找很容易，现在WEB-INF/classes/目录下是否存在这个类，如果不存在就看WEB-INF/lib/目录下的JAR包中是否存在这个类，最终如果找到就将进行缓存，保存一个类的全限定名对应的class文件地址或jar包地址。 当知道这个类在哪了之后，就可以defineClass了，最终得到一个class对象，并且也会将这个class对象设置到我们的缓存中，所以上文说的缓存中，其实是这么一个映射关系，一个类的全限定名对应这个类的文件地址以及这个类的class对象。 所以当下次再有情况需要加载class时，就可以直接取缓存中的对应的class对象了。 对于第2步停止当前Context，其实所做的事情比较单一，就是清空和销毁，而其中跟类加载相关就是清空上文中的缓存对象。我们的热加载就是先清空所有东西，然后重新启动我们应用，但是因为这个的触发条件基本上是class类发生了变化，所以热加载的过程中关于应用其他的一些属性是没有发生变化的，比如你现在想在Context中添加一个Vavle是不会触发热加载的，而若要达到该效果就要用到热部署。 虽然我们在热加载的过程发现它是先停止再启动，做法看似粗暴，但是这样是性价比比较高的，并且这种方式至少比重启Tomcat效率要高很多。且热加载不能用于war包。 对于一个class文件所表示的类，同一个类加载器的不同实例，都可以加载这个类，并且得到的class对象是不同的，若现在有一个A类，一个自定义的WebappClassloader类，一开始先用一个WebappClassloader实例加载A类，那么在jvm中就会存在一个A类的class对象，然后进行热加载，先停止，再启动，在停止的时候会杀掉当前应用的所有线程（除开真正执行代码的线程），再启动时又会生成一个WebappClassloader实例来加载A类，如果热加载之前的那个A类的class对象还没有被回收的话，那么此时jvm中其实会存在两个A类的class对象，这是不冲突，因为class对象的唯一标志是类加载器实例对象+类的全限定名。 热部署BackgroundProcessor线程第六步会发出一个PERIODIC_EVENT事件，而HostConfig监听了此事件，当接收到此事件后就会执行热部署的检查与操作。 对于一个文件夹部署的应用，通常会检查以下资源是否发生变动： webapps/应用名.war webapps/应用名 /webapps/应用名/META-INF/context.xml /conf/Catalina/localhost/应用名.xml /conf/context.xml 对于一个War部署的应用，会检查以下资源是否发生变动： /webapps/应用名.war /conf/Catalina/localhost/应用名.xml /conf/context.xml 对于一个描述符部署的应用，会检查以下资源是否发生变动： /conf/Catalina/localhost/应用名.xml 指定的DocBase目录 /conf/context.xml 一旦这些文件或目录发生了变化，就会触发热部署，当然热部署也是有开关的，在Host上默认是开启的。这里需要注意的是，对于一个目录是否发生了变化，Tomcat只判断了这个目录的修改时间是否发生了变化，和热加载不冲突，因为热加载监听的是WEB-INF/classes和WEB-INF/lib目录，而热部署监听的是应用名那一层的目录。 在讲热部署的过程之前，我们要先讲一下应用部署的优先级，对于一个应用，我们可以在四个地方进行定义： server.xml中的context节点 /conf/Catalina/localhost/应用名.xml /webapps/应用名.war /webapps/应用名 优先级就是上面所列的顺序，同一个应用名，若在这个四个地方都配置了，则优先级低的将不起作用，因为Tomcat在部署一个应用的时候，会先查一下这个应用名是否已经被部署过了。 热部署的过程如果发生改变的是文件夹，如/webapps/应用名，则不会做什么事情，只会更新一下记录的修改时间，因为这个/webapps/应用名目录下的文件，要么是jsp文件，要么是其他文件，而Tomcat只会管jsp文件，而对于jsp文件如果发生了修改，jsp自带的机制会处理修改的。 若发生改变的是/conf/Catalina/localhost/应用名.xml文件，则就先undeploy，然后再deploy，和热加载其实类似。undeploy就是将当前应用从host中移除，包括了当前应用的停止和销毁，还会从已部署列表中移除当前应用，然后调用deployApps()就可以重新部署应用了。","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Tomcat","slug":"中间件/Tomcat","permalink":"https://yaoyinglong.github.io/categories/中间件/Tomcat/"}]},{"title":"Tomcat整体架构","date":"2021-08-27T16:00:00.000Z","path":"Blog/中间件/Tomcat/Tomcat整体架构/","text":"Tomcat是一个Servlet容器，在Tomcat中容器分为Wrapper、Context、Host、Engine。从Tomcat的server.xml中也可以看出他们的层级关系，Engine管理Host，Host管理Context，Context管理Wrapper，Wrapper管理Servlet，一个Tomcat一个Engine，一个Host表示一个虚拟主机，一个Engine下可以有多个，一个Context就是一个应用一个项目，Wrapper表示一个Servelet的包装，在定义Servelet时若没实现SingleThreadModel接口，则Tomcat中只会产生一个Servelet实例对象，若实现了该接口，则每个请求线程都会产生一个Servelet实例对象： 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;Server port=\"8005\" shutdown=\"SHUTDOWN\"&gt; &lt;Listener className=\"org.apache.catalina.startup.VersionLoggerListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\" /&gt; &lt;Listener className=\"org.apache.catalina.core.JasperListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\" /&gt; &lt;Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=\"UserDatabase\" auth=\"Container\" type=\"org.apache.catalina.UserDatabase\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" pathname=\"conf/tomcat-users.xml\" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=\"Catalina\"&gt; &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" maxKeepAliveRequests=\"2\"/&gt; &lt;Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;Engine name=\"Catalina\" defaultHost=\"localhost\"&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/&gt; &lt;/Realm&gt; &lt;Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"&gt; &lt;Context path=\"/HelloEleven\" relaodable=\"false\"docBase=\"E:\\SourceCode\\ElevenServlet\\target\\ElevenServlet\"/&gt; &lt;Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; PipelinePipeline是在每个容器中都会用到，而Pipeline中有一些列的Valve，这些Valve是真正处理相关逻辑的，在处理每个请求时，Tomcat就会调用具体配置的Valve，如上面的server.xml中的&lt;Valve&gt;标签。每个容易有默认的Valve，如Wrapper中： 123456public StandardWrapper() &#123; super(); swValve = new StandardWrapperValve(); pipeline.setBasic(swValve); broadcaster = new NotificationBroadcasterSupport(); // 广播&#125; 自定义Valve： 1234567891011public class TestValve extends RequestFilterValve &#123; @Override public void invoke(Request request, Response response) throws IOException, ServletException &#123; System.out.println(\"test value\"); getNext().invoke(request, response); &#125; @Override protected Log getLog() &#123; return null; &#125;&#125; 使用时在server.xml中直接配置，每个容器都可以配置自己的Valve，也可以配置多个： 1&lt;Valve className=\"com.eleven.TestValve\"/&gt; Tomcat生命周期Tomcat架构是一种树状的层级管理结构，组件会有自己的父子节点，每个节点都是组件，每个组件都有生命周期，为了管理方便，子节点的生命周期都是交由父节点来管理的。 每个组件生命周期的管理主要由Lifecycle接口和LifecycleState枚举来表示，即每个组件都实现了Lifecycle类，Lifecycle接口定义了组件所有执行的动作。 123456789101112131415161718192021222324252627282930313233343536public interface Lifecycle &#123; public static final String BEFORE_INIT_EVENT = \"before_init\"; public static final String AFTER_INIT_EVENT = \"after_init\"; public static final String START_EVENT = \"start\"; public static final String BEFORE_START_EVENT = \"before_start\"; public static final String AFTER_START_EVENT = \"after_start\"; public static final String STOP_EVENT = \"stop\"; public static final String BEFORE_STOP_EVENT = \"before_stop\"; public static final String AFTER_STOP_EVENT = \"after_stop\"; public static final String AFTER_DESTROY_EVENT = \"after_destroy\"; public static final String BEFORE_DESTROY_EVENT = \"before_destroy\"; public static final String PERIODIC_EVENT = \"periodic\"; public static final String CONFIGURE_START_EVENT = \"configure_start\"; public static final String CONFIGURE_STOP_EVENT = \"configure_stop\"; public void addLifecycleListener(LifecycleListener listener); public LifecycleListener[] findLifecycleListeners(); public void removeLifecycleListener(LifecycleListener listener); public void init() throws LifecycleException; public void start() throws LifecycleException; public void stop() throws LifecycleException; public void destroy() throws LifecycleException; public LifecycleState getState(); public String getStateName(); public interface SingleUse &#123; &#125;&#125; 所有组件的所有生命周期状态由LifecycleState枚举类来管理，第一个参数表示当前状态下组件是否可用，第二个参数表示当变为当前状态时出发相应事件。 12345678910111213141516171819202122232425262728293031public enum LifecycleState &#123; NEW(false, null), INITIALIZING(false, Lifecycle.BEFORE_INIT_EVENT), INITIALIZED(false, Lifecycle.AFTER_INIT_EVENT), STARTING_PREP(false, Lifecycle.BEFORE_START_EVENT), STARTING(true, Lifecycle.START_EVENT), STARTED(true, Lifecycle.AFTER_START_EVENT), STOPPING_PREP(true, Lifecycle.BEFORE_STOP_EVENT), STOPPING(false, Lifecycle.STOP_EVENT), STOPPED(false, Lifecycle.AFTER_STOP_EVENT), DESTROYING(false, Lifecycle.BEFORE_DESTROY_EVENT), DESTROYED(false, Lifecycle.AFTER_DESTROY_EVENT), FAILED(false, null), @Deprecated MUST_STOP(true, null), @Deprecated MUST_DESTROY(false, null); private final boolean available; private final String lifecycleEvent; private LifecycleState(boolean available, String lifecycleEvent) &#123; this.available = available; this.lifecycleEvent = lifecycleEvent; &#125; public boolean isAvailable() &#123; return available; &#125; public String getLifecycleEvent() &#123; return lifecycleEvent; &#125;&#125; Tomcat生命周期的流转： 所有状态都能转变为FAILED 一个组件在STARTING_PREP、STARTING、STARTED状态调用start()方法不会产生影响 一个组件在NEW状态调用start()方法时，会先调用init()方法 一个组件在STOPPING_PREP、STOPPING、STOPPED状态调用stop方法不会产生影响 一个组件在NEW状态调用stop()方法是，会将状态直接改为STOPPED。当组件自己启动失败去停止时，需要将子组件也进行停止，尽管某些子组件还没有启动。 其他状态相互转换都会抛异常 合法的状态转换发生时都会触发相应的LifecycleEvent事件，非合法的转换不会触发事件。 Tomcat事件监听Tomcat中每个组件的状态会发送变化，变化的时候会抛出一些事件，Tomcat支持定义事件监听器来监听并消费这些事件。实现事件监听功能的类为LifecycleBase。每个组件都会继承该类。该类通过List&lt;LifecycleListener&gt; lifecycleListeners属性来保存事件监听器，即每个组件拥有一个事件监听器列表。 所有组件的初始化、开始、停止、销毁都是通过LifecycleBase中的方法来完成，具体的组件的具体的初始化、开始、停止、销毁逻辑都是通过实现相关的*Internal抽象方法来完成的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170public abstract class LifecycleBase implements Lifecycle &#123; protected void fireLifecycleEvent(String type, Object data) &#123; lifecycle.fireLifecycleEvent(type, data); &#125; public void fireLifecycleEvent(String type, Object data) &#123; LifecycleEvent event = new LifecycleEvent(lifecycle, type, data); LifecycleListener interested[] = listeners; // ContextCOnfig for (int i = 0; i &lt; interested.length; i++) interested[i].lifecycleEvent(event); &#125; @Override public final synchronized void init() throws LifecycleException &#123; if (!state.equals(LifecycleState.NEW)) &#123; invalidTransition(Lifecycle.BEFORE_INIT_EVENT); &#125; try &#123; setStateInternal(LifecycleState.INITIALIZING, null, false); initInternal(); setStateInternal(LifecycleState.INITIALIZED, null, false); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException( sm.getString(\"lifecycleBase.initFail\",toString()), t); &#125; &#125; protected abstract void initInternal() throws LifecycleException; @Override public final synchronized void start() throws LifecycleException &#123; if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) &#123; if (log.isDebugEnabled()) &#123; Exception e = new LifecycleException(); log.debug(sm.getString(\"lifecycleBase.alreadyStarted\", toString()), e); &#125; else if (log.isInfoEnabled()) &#123; log.info(sm.getString(\"lifecycleBase.alreadyStarted\", toString())); &#125; return; &#125; if (state.equals(LifecycleState.NEW)) &#123; init(); &#125; else if (state.equals(LifecycleState.FAILED)) &#123; stop(); &#125; else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) &#123; invalidTransition(Lifecycle.BEFORE_START_EVENT); &#125; try &#123; setStateInternal(LifecycleState.STARTING_PREP, null, false); startInternal(); if (state.equals(LifecycleState.FAILED)) &#123; stop(); &#125; else if (!state.equals(LifecycleState.STARTING)) &#123; invalidTransition(Lifecycle.AFTER_START_EVENT); &#125; else &#123; setStateInternal(LifecycleState.STARTED, null, false); &#125; &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException(sm.getString(\"lifecycleBase.startFail\", toString()), t); &#125; &#125; protected abstract void startInternal() throws LifecycleException; @Override public final synchronized void stop() throws LifecycleException &#123; if (LifecycleState.STOPPING_PREP.equals(state) || LifecycleState.STOPPING.equals(state) || LifecycleState.STOPPED.equals(state)) &#123; if (log.isDebugEnabled()) &#123; Exception e = new LifecycleException(); log.debug(sm.getString(\"lifecycleBase.alreadyStopped\", toString()), e); &#125; else if (log.isInfoEnabled()) &#123; log.info(sm.getString(\"lifecycleBase.alreadyStopped\", toString())); &#125; return; &#125; if (state.equals(LifecycleState.NEW)) &#123; state = LifecycleState.STOPPED; return; &#125; if (!state.equals(LifecycleState.STARTED) &amp;&amp; !state.equals(LifecycleState.FAILED)) &#123; invalidTransition(Lifecycle.BEFORE_STOP_EVENT); &#125; try &#123; if (state.equals(LifecycleState.FAILED)) &#123; fireLifecycleEvent(BEFORE_STOP_EVENT, null); &#125; else &#123; setStateInternal(LifecycleState.STOPPING_PREP, null, false); &#125; stopInternal(); if (!state.equals(LifecycleState.STOPPING) &amp;&amp; !state.equals(LifecycleState.FAILED)) &#123; invalidTransition(Lifecycle.AFTER_STOP_EVENT); &#125; setStateInternal(LifecycleState.STOPPED, null, false); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException(sm.getString(\"lifecycleBase.stopFail\",toString()), t); &#125; finally &#123; if (this instanceof Lifecycle.SingleUse) &#123; setStateInternal(LifecycleState.STOPPED, null, false); destroy(); &#125; &#125; &#125; protected abstract void stopInternal() throws LifecycleException; @Override public final synchronized void destroy() throws LifecycleException &#123; if (LifecycleState.FAILED.equals(state)) &#123; try &#123; stop(); &#125; catch (LifecycleException e) &#123; log.error(sm.getString(\"lifecycleBase.destroyStopFail\", toString()), e); &#125; &#125; if (LifecycleState.DESTROYING.equals(state) || LifecycleState.DESTROYED.equals(state)) &#123; if (log.isDebugEnabled()) &#123; Exception e = new LifecycleException(); log.debug(sm.getString(\"lifecycleBase.alreadyDestroyed\", toString()), e); &#125; else if (log.isInfoEnabled() &amp;&amp; !(this instanceof Lifecycle.SingleUse)) &#123; log.info(sm.getString(\"lifecycleBase.alreadyDestroyed\", toString())); &#125; return; &#125; if (!state.equals(LifecycleState.STOPPED) &amp;&amp; !state.equals(LifecycleState.FAILED) &amp;&amp; !state.equals(LifecycleState.NEW) &amp;&amp; !state.equals(LifecycleState.INITIALIZED)) &#123; invalidTransition(Lifecycle.BEFORE_DESTROY_EVENT); &#125; try &#123; setStateInternal(LifecycleState.DESTROYING, null, false); destroyInternal(); setStateInternal(LifecycleState.DESTROYED, null, false); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException(sm.getString(\"lifecycleBase.destroyFail\",toString()), t); &#125; &#125; protected abstract void destroyInternal() throws LifecycleException; private synchronized void setStateInternal(LifecycleState state, Object data, boolean check) throws LifecycleException &#123; if (check) &#123; if (state == null) &#123; invalidTransition(\"null\"); return; &#125; if (!(state == LifecycleState.FAILED || (this.state == LifecycleState.STARTING_PREP &amp;&amp; state == LifecycleState.STARTING) || (this.state == LifecycleState.STOPPING_PREP &amp;&amp; state == LifecycleState.STOPPING) || (this.state == LifecycleState.FAILED &amp;&amp; state == LifecycleState.STOPPING))) &#123; invalidTransition(state.name()); &#125; &#125; this.state = state; String lifecycleEvent = state.getLifecycleEvent(); if (lifecycleEvent != null) &#123; fireLifecycleEvent(lifecycleEvent, data); &#125; &#125;&#125; 所有组件的状态的变更都是通过setStateInternal方法来完成的，从而调用fireLifecycleEvent方法来执行相关的监听器来完成相关的逻辑。 自定义监听器只需要实现LifecycleListener接口即可，定义好事件监听器后，每个组件就可以调用父类LifecycleBase中的addLifecycleListener()方法添加事件监听器到该组件的监听器列表中。虽然说是事件监听，但实际上并不是异步触发，而是主动调用事件监听器，从fireLifecycleEvent方法也可以很明显的看出。 123public interface LifecycleListener &#123; public void lifecycleEvent(LifecycleEvent event);&#125; Tomcat自定义类加载器Tomcat 拥有不同的自定义类加载器，以实现对各种资源库的控制。一般来说Tomcat 主要用类加载器解决以下 4 个问题。 同一个Tomcat中，各个Web应用之间各自使用的Java类库要互相隔离。 同一个Tomcat中，各个Web应用之间可以提供共享的Java类库。 为了使Tomcat不受Web应用的影响，应该使服务器的类库与应用程序的类库互相独立。 Tomcat支持热部署。 在 Tomcat中，最重要的一个类加载器是Common类加载器，它的父类加载器是应用程序类加载器，负责加载$CATALINA_ BASE/lib、$CATALINA_HOME/lib两个目录下所有的.class文件与.jar文件。 Tomcat中一般会有多个WebApp类加载器WebAppClassLoader，每个类加载器负责加载一个Web程序。它的父类加载器是Common类加载器。 由于每个 Web 应用都有自己的 WebApp 类加载器，很好地使多个 Web 应用程序之间互相隔离且能通过创建新的WebApp类加载器达到热部署。这种类加载器结构能有效使Tomcat不受Web应用程序影响，而Common类加载器的存在使多个Web应用程序能够互相共享类库。","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Tomcat","slug":"中间件/Tomcat","permalink":"https://yaoyinglong.github.io/categories/中间件/Tomcat/"}]},{"title":"BIO和NIO底层原理对比","date":"2021-08-24T16:00:00.000Z","path":"Blog/中间件/Tomcat/BIO和NIO底层原理对比/","text":"在Tomcat7中，默认为BIO，可以通过如下配置改为NIO 1&lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; BIOBIO的模型比较简单，是通过JioEndpoint实例中的Acceptor线程负责循环阻塞接收socket连接，每接收到一个socket连接就包装成SocketProcessor扔进线程池Executor中，SocketProcessor是一个Runnable，SocketProcessor负责从socket中阻塞读取数据，并且向socket中阻塞写入数据。 Acceptor线程的数量默认为1个，可以通过acceptorThreadCount参数进行配置，线程池Executor是可以配置的，比如： 123&lt;Executor name=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\" maxThreads=\"150\" minSpareThreads=\"4\"/&gt;&lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" connectionTimeout=\"20000\" redirectPort=\"8443\" executor=\"tomcatThreadPool\"/&gt; 每个Connector可以对应一个线程池，默认情况下Tomcat中每个Connector都会创建一个自己的线程池，并且该线程池的默认值为：最小线程数量为10，最大线程数量为200，若两个Connector配置的executor是一样的话，则表示这两个Connector共用一个线程池。 使用BIO来处理请求时，当请求数量比较大时，可以提高Acceptor线程数量，提高接收请求的速率，当请求比较耗时时，可以提高线程池Executor的最大线程数量。 增加线程的目的都是为了提高Tomcat的性能，但一台机器的线程数量并不是越多越好，需要利用压测来最终确定一个更加符合当前业务场景的线程数量。 BIO的处理请求和响应的流程。 NIONIO最大的特性就是非阻塞，非阻塞接收socket连接，非阻塞从socket中读取数据，非阻塞从将数据写到socket中。但在Tomcat7中，只有在从socket中读取请求行，请求头数据时是非阻塞的，在读取请求体是阻塞的，响应数据时也是阻塞的。因为Tomcat7对应Servlet3.0，Servlet3.0规范中没有考虑NIO，如在具体Servlet中读取请求体的代码： 123456ServletInputStream inputStream = req.getInputStream();byte[] bytes = new byte[1024];int n;while ((n = inputStream.read(bytes)) &gt; 0) &#123; System.out.println(new String(bytes, 0, n));&#125; inputStream.read()方法的含义就是阻塞读取数据，当读取请求体时，如果操作系统中还没有准备好，那么read方法就得阻塞。 而NIO则不一样，NIO中是一旦操作系统中的数据准备好了，那么则会通知Java程序可以读取数据了，这里的通知很重要，这决定了Java代码到底如何实现，若在Servlet中想利用NIO去读取数据，则在Servlet中肯定就要去监听是否有通知过来，比如在Servlet3.1中则增加了NIO相关的定义，这里有Listener，用来监听数据可读的通知，这才是真正的利用了NIO： 123456789101112131415ServletInputStream inputStream = req.getInputStream();inputStream.setReadListener(new ReadListener() &#123; // 有数据可用时触发 @Override public void onDataAvailable() throws IOException &#123; &#125; // 数据全部读完了 @Override public void onAllDataRead() throws IOException &#123; &#125; // 出现异常了 @Override public void onError(Throwable throwable) &#123; &#125;&#125;); 利用Acceptor来阻塞获取socket连接，NIO中叫socketChannel，接收到socketChannel后，需要将socketChannel绑定到一个Selector中并注册读事件，基于NIO还需要一个线程来轮询Selector中是否存在就绪事件，若存在则将就绪事件查出来，并处理该事件，在Tomcat中支持多个线程同时查询是否存在就绪事件，该线程对象为Poller，每个Poller中都包含一个Selector，这样每个Poller线程就负责轮询自己的Selector上就绪的事件，然后处理事件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class NioEndpoint extends AbstractEndpoint&lt;NioChannel&gt; &#123; protected class Acceptor extends AbstractEndpoint.Acceptor &#123; @Override public void run() &#123; int errorDelay = 0; while (running) &#123; while (paused &amp;&amp; running) &#123; state = AcceptorState.PAUSED; try &#123; Thread.sleep(50); &#125; &#125; if (!running) &#123; break; &#125; state = AcceptorState.RUNNING; try &#123; countUpOrAwaitConnection(); SocketChannel socket = null; try &#123; socket = serverSock.accept(); &#125; catch (IOException ioe) &#123; countDownConnection(); errorDelay = handleExceptionWithDelay(errorDelay); throw ioe; &#125; errorDelay = 0; if (running &amp;&amp; !paused) &#123; if (!setSocketOptions(socket)) &#123; countDownConnection(); closeSocket(socket); &#125; &#125; else &#123; countDownConnection(); closeSocket(socket); &#125; &#125; &#125; state = AcceptorState.ENDED; &#125; &#125; protected boolean setSocketOptions(SocketChannel socket) &#123; try &#123; // 从该channel上读取数据不阻塞 socket.configureBlocking(false); Socket sock = socket.socket(); socketProperties.setProperties(sock); // 每接收到一个socket连接就获取一个NioChannel来封装这个socket，NioChannel是可重用的对象 NioChannel channel = nioChannels.poll(); // nioChannels是一个缓存队列，拿出对头的NioChannel if (channel == null) &#123; // SSL setup if (sslContext != null) &#123; SSLEngine engine = createSSLEngine(); int appbufsize = engine.getSession().getApplicationBufferSize(); NioBufferHandler bufhandler = new NioBufferHandler(Math.max(appbufsize, socketProperties.getAppReadBufSize()),Math.max(appbufsize, socketProperties.getAppWriteBufSize()), socketProperties.getDirectBuffer()); channel = new SecureNioChannel(socket, engine, bufhandler, selectorPool); &#125; else &#123; // normal tcp setup NioBufferHandler bufhandler = new NioBufferHandler(socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); channel = new NioChannel(socket, bufhandler); &#125; &#125; else &#123; channel.setIOChannel(socket); if (channel instanceof SecureNioChannel) &#123; SSLEngine engine = createSSLEngine(); ((SecureNioChannel) channel).reset(engine); &#125; else &#123; channel.reset(); &#125; &#125; // 每接收到一个新socket连接，就会生成一个 getPoller0().register(channel); &#125; catch (Throwable t) &#123; return false; &#125; return true; &#125; public void register(final NioChannel socket) &#123; socket.setPoller(this); // 获取一个KeyAttachment对象，将当前socket的相关信息设置进去 KeyAttachment key = keyCache.poll(); final KeyAttachment ka = key != null ? key : new KeyAttachment(socket); ka.reset(this, socket, getSocketProperties().getSoTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); // 获取一个PollerEvent对象，本事件为一个注册事件，对读事件感兴趣（这里暂时还没有真正的向select去注册事件） PollerEvent r = eventCache.poll(); ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into. if (r == null) r = new PollerEvent(socket, ka, OP_REGISTER); else r.reset(socket, ka, OP_REGISTER); // 把PollerEvent添加到事件列表中去 addEvent(r); &#125; public void addEvent(Runnable event) &#123; events.offer(event); if (wakeupCounter.incrementAndGet() == 0) selector.wakeup(); &#125;&#125; 当Acceptro接收到一个socketChannel后，就会将socketChannel注册到某一个Poller上，确定Polloer的逻辑非常简单，假设现在有3个Poller，编号为1,2,3，那么Tomcat接收到的第一个socketChannel注册到1号Poller上，第二个socketChannel注册到2号Poller上，第三个socketChannel注册到3号Poller上，第四个socketChannel注册到1号Poller上，依次循环。 1234public Poller getPoller0() &#123; int idx = Math.abs(pollerRotater.incrementAndGet()) % pollers.length; return pollers[idx];&#125; 代码中的nioChannels，keyCache，eventCache等都是缓存队列，为了避免重复大量的New对象，以及下面的processorCache。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201public class Poller implements Runnable &#123; public void run() &#123; while (true) &#123; try &#123; while (paused &amp;&amp; (!close)) &#123; try &#123; Thread.sleep(100); &#125; &#125; boolean hasEvents = false; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; break; &#125; else &#123; // 执行PollerEvent事件，向Selector注册读写事件 hasEvents = events(); // 真正的向selector注册 &#125; try &#123; if (!close) &#123; if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; // 上面的events()会去注册事件，而这里是去查询是否有事件就绪，不阻塞 keyCount = selector.selectNow(); &#125; else &#123; // 阻塞，超时会继续执行下面的代码，不会报错 keyCount = selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; break; &#125; &#125; if (keyCount == 0) hasEvents = (hasEvents | events()); // 如果存在就绪事件，那么则遍历并处理事件 Iterator&lt;SelectionKey&gt; iterator = eyCount &gt; 0 ? selector.selectedKeys().iterator() : null; // 循环处理当前就绪的事件 while (iterator != null &amp;&amp; iterator.hasNext()) &#123; SelectionKey sk = iterator.next(); KeyAttachment attachment = (KeyAttachment) sk.attachment(); if (attachment == null) &#123; iterator.remove(); &#125; else &#123; attachment.access(); iterator.remove(); processKey(sk, attachment);// 处理事件 &#125; &#125;//while timeout(keyCount, hasEvents); if (oomParachute &gt; 0 &amp;&amp; oomParachuteData == null) checkParachute(); &#125; catch (OutOfMemoryError oom) &#123; try &#123; oomParachuteData = null; releaseCaches(); log.error(\"\", oom); &#125; &#125; &#125;//while stopLatch.countDown(); &#125; public boolean events() &#123; boolean result = false; Runnable r = null; // poll会把元素从队列中删除掉 for (int i = 0, size = events.size(); i &lt; size &amp;&amp; (r = events.poll()) != null; i++) &#123; result = true; try &#123; // 如果是PollerEvent，会将读事件注册到当前poller中的selector对象上 r.run(); if (r instanceof PollerEvent) &#123; ((PollerEvent) r).reset(); eventCache.offer((PollerEvent) r); &#125; &#125; &#125; return result; &#125; protected boolean processKey(SelectionKey sk, KeyAttachment attachment) &#123; boolean result = true; try &#123; if (close) &#123; cancelledKey(sk, SocketStatus.STOP, attachment.comet); &#125; else if (sk.isValid() &amp;&amp; attachment != null) &#123; attachment.access();//make sure we don't time out valid sockets sk.attach(attachment);//cant remember why this is here // 当前就绪事件对应的channel NioChannel channel = attachment.getChannel(); // 读就绪或写就绪 if (sk.isReadable() || sk.isWritable()) &#123; if (attachment.getSendfileData() != null) &#123; processSendfile(sk, attachment, false); &#125; else &#123; if (isWorkerAvailable()) &#123; unreg(sk, attachment, sk.readyOps()); // boolean closeSocket = false; // Read goes before write if (sk.isReadable()) &#123; // 从channel中读取数据 if (!processSocket(channel, SocketStatus.OPEN_READ, true)) &#123; closeSocket = true; &#125; &#125; // 读完数据之后可能就要写数据 if (!closeSocket &amp;&amp; sk.isWritable()) &#123; // 将数据写入到channel中 if (!processSocket(channel, SocketStatus.OPEN_WRITE, true)) &#123; closeSocket = true; &#125; &#125; if (closeSocket) &#123; cancelledKey(sk, SocketStatus.DISCONNECT, false); &#125; &#125; else &#123; result = false; &#125; &#125; &#125; &#125; &#125; return result; &#125;&#125;public class NioEndpoint extends AbstractEndpoint&lt;NioChannel&gt; &#123; public boolean processSocket(NioChannel socket, SocketStatus status, boolean dispatch) &#123; // 该方法是用来从socket中读数据或写数据的，dispatch表示是不是要把这个任务派发给线程池，也就是要不要异步 try &#123; KeyAttachment attachment = (KeyAttachment) socket.getAttachment(); if (attachment == null) &#123; return false; &#125; attachment.setCometNotify(false); //will get reset upon next reg // 获取一个SocketProcessor对象 SocketProcessor sc = processorCache.poll(); if (sc == null) sc = new SocketProcessor(socket, status); else sc.reset(socket, status); // 派发给线程池 if (dispatch &amp;&amp; getExecutor() != null) getExecutor().execute(sc); else sc.run(); &#125; catch (RejectedExecutionException rx) &#123; return false; &#125; catch (Throwable t) &#123; return false; &#125; return true; &#125;&#125;// events()中r.run()方法实际上是调用的PollerEvent的run方法，真正将读事件注册到当前poller中的selector对象上public static class PollerEvent implements Runnable &#123; // PollerEvent表示需要注册的事件, protected NioChannel socket; protected int interestOps; protected KeyAttachment key; @Override public void run() &#123; if (interestOps == OP_REGISTER) &#123; // 真正将读事件注册到当前poller中的selector对象上 try &#123; socket.getIOChannel().register(socket.getPoller().getSelector(), SelectionKey.OP_READ, key); &#125; &#125; else &#123; final SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); try &#123; // 如果当前这个channel没有任何注册事件了，表示这个这个socket连接已经关掉了 if (key == null) &#123; socket.getPoller().getEndpoint().countDownConnection(); &#125; else &#123; final KeyAttachment att = (KeyAttachment) key.attachment(); if (att != null) &#123; if (att.isComet() &amp;&amp; (interestOps &amp; OP_CALLBACK) == OP_CALLBACK) &#123; att.setCometNotify(true); &#125; else &#123; att.setCometNotify(false); &#125; interestOps = (interestOps &amp; (~OP_CALLBACK));//remove the callback flag att.access();//to prevent timeout // 将新注册的事件添加到注册事件列表中 int ops = key.interestOps() | interestOps; att.interestOps(ops); key.interestOps(ops); &#125; else &#123; socket.getPoller().cancelledKey(key, SocketStatus.ERROR, false); &#125; &#125; &#125; catch (CancelledKeyException ckx) &#123; try &#123; socket.getPoller().cancelledKey(key, SocketStatus.DISCONNECT, true); &#125; &#125; &#125;//end if &#125;//run&#125; 在某一个Poller中，除开有selector外，还有一个ConcurrentLinkedQueue队列events，events表示待执行事件，比如Tomcat要socketChannel注册到selector上，但是Tomcat并没有直接这么做，而是先自己生成一个PollerEvent，然后把PollerEvent加入到队列events中，然后这个队列中的事件会在Poller线程的循环过程中真正执行 Poller线程中需要循环查询selector中是否存在就绪事件，而Tomcat在真正查询之前会先看一下events队列中是否存在待执行事件，如果存在就会先执行，这些事件表示需要向selector上注册事件，比如注册socketChannel的读事件和写事件，所以在真正执行events队列中的事件时就会真正的向selector上注册事件。所以只有先执行events队列中的PollerEvent，Poller线程才能有机会从selector中查询到就绪事件，每个Poller线程一旦查询到就绪事件，就会去处理这些事件，事件无非就是读事件和写事件 处理的第一步就是获取当前就绪事件对应的socketChannel，因为我们要向socketChannel中读数据或写数据 处理的第二步就是把socketChannel和当前要做的事情（读或写）封装为SocketProcessor对象 处理的第三步就是把SocketProcessor扔进线程池进行处理 在SocketProcessor线程运行时，就会从socketChannel读取数据（假设当前处理的是读事件），并且是非阻塞读，既然是非阻塞读，大概的一个流程就是，某一个Poller中的selector查询到了一个读就绪事件，然后交给一个SocketProcessor线程进行处理，SocketProcessor线程读取数据之后，如果发现请求行和请求头的数据都已经读完了，并解析完了，那么该SocketProcessor线程就会继续把解析后的请求交给Servlet进行处理，Servlet中可能会读取请求体，可能会响应数据，而不管是读请求体还是响应数据都是阻塞的，直到Servlet中的逻辑都执行完后，SocketProcessor线程才会运行结束。假如SocketProcessor读到了数据之后，发现请求行或请求头的数据还没有读完，那么本次读事件处理完毕，需要Poller线程再次查询到就绪读事件才能继续读数据，以及解析数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980protected class SocketProcessor implements Runnable &#123; protected NioChannel socket = null; protected SocketStatus status = null; @Override public void run() &#123; // 获取当前channel上就绪的事件 SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); KeyAttachment ka = null; if (key != null) &#123; ka = (KeyAttachment) key.attachment(); &#125; if (ka != null &amp;&amp; ka.isUpgraded() &amp;&amp; SocketStatus.OPEN_WRITE == status) &#123; synchronized (ka.getWriteThreadLock()) &#123; doRun(key, ka); &#125; &#125; else &#123; // 在nio中，每产生一个就绪的io事件，就会通过一个线程来处理该事件，需要进行同步 // 多个线程只能并发处理不同socket,不能处理同一个socket synchronized (socket) &#123; doRun(key, ka); // 真正处理事件的逻辑 &#125; &#125; &#125; private void doRun(SelectionKey key, KeyAttachment ka) &#123; try &#123; int handshake = -1; try &#123; if (key != null) &#123; if (socket.isHandshakeComplete() || status == SocketStatus.STOP) &#123; handshake = 0; &#125; else &#123; handshake = socket.handshake(key.isReadable(), key.isWritable()); status = SocketStatus.OPEN_READ; &#125; &#125; &#125; catch (IOException x) &#123; handshake = -1; &#125; catch (CancelledKeyException ckx) &#123; handshake = -1; &#125; if (handshake == 0) &#123; SocketState state = SocketState.OPEN; if (status == null) &#123; state = handler.process(ka, SocketStatus.OPEN_READ); &#125; else &#123; state = handler.process(ka, status); &#125; if (state == SocketState.CLOSED) &#123; close(ka, socket, key, SocketStatus.ERROR); &#125; &#125; else if (handshake == -1) &#123; close(ka, socket, key, SocketStatus.DISCONNECT); &#125; else &#123; ka.getPoller().add(socket, handshake); &#125; &#125; catch (CancelledKeyException cx) &#123; socket.getPoller().cancelledKey(key, null, false); &#125; catch (OutOfMemoryError oom) &#123; try &#123; oomParachuteData = null; if (socket != null) &#123; socket.getPoller().cancelledKey(key, SocketStatus.ERROR, false); &#125; releaseCaches(); &#125; &#125; catch (Throwable t) &#123; if (socket != null) &#123; socket.getPoller().cancelledKey(key, SocketStatus.ERROR, false); &#125; &#125; finally &#123; socket = null; status = null; //return to cache if (running &amp;&amp; !paused) &#123; processorCache.offer(this); &#125; &#125; &#125;&#125; 这里调用的handler.process和BIO是同一个方法包括processor.process(wrapper)也是一样，不同的点在于后续解析字节流的逻辑，connections是将未处理完的socket缓存起来，以便下一次事件继续读取数据： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176protected abstract static class AbstractConnectionHandler&lt;S,P extends Processor&lt;S&gt;&gt; implements AbstractEndpoint.Handler &#123; public SocketState process(SocketWrapper&lt;S&gt; wrapper, SocketStatus status) &#123; S socket = wrapper.getSocket(); Processor&lt;S&gt; processor = connections.get(socket); // 设置为非异步，就是同步 wrapper.setAsync(false); try &#123; if (processor == null) &#123; // 从被回收的processor中获取processor processor = recycledProcessors.poll(); &#125; if (processor == null) &#123; processor = createProcessor(); // HTTP11NIOProce &#125; initSsl(wrapper, processor); SocketState state = SocketState.CLOSED; do &#123; if (status == SocketStatus.DISCONNECT &amp;&amp; !processor.isComet()) &#123; // Do nothing here, just wait for it to get recycled // Don't do this for Comet we need to generate an end // event (see BZ 54022) &#125; else if (processor.isAsync() || state == SocketState.ASYNC_END) &#123; // 要么Tomcat线程还没结束，业务线程就已经调用过complete方法了，然后利用while走到这个分支 // 要么Tomcat线程结束后，在超时时间内业务线程调用complete方法，然后构造一个新的SocketProcessor对象扔到线程池里走到这个分支 // 要么Tomcat线程结束后，超过超时时间了，由AsyncTimeout线程来构造一个SocketProcessor对象扔到线程池里走到这个分支 // 不管怎么样，在整个调用异步servlet的流程中，此分支只经历一次，用来将output缓冲区中的内容发送出去 state = processor.asyncDispatch(status); if (state == SocketState.OPEN) &#123; getProtocol().endpoint.removeWaitingRequest(wrapper); state = processor.process(wrapper); &#125; &#125; else if (processor.isComet()) &#123; state = processor.event(status); &#125; else &#123; // 大多数情况下走这个分支 state = processor.process(wrapper); &#125; if (state != SocketState.CLOSED &amp;&amp; processor.isAsync()) &#123; // 代码执行到这里，就去判断一下之前有没有调用过complete方法 // 如果调用，那么当前的AsyncState就会从COMPLETE_PENDING--&gt;调用doComplete方法改为COMPLETING，SocketState为ASYNC_END // 如果没有调用，那么当前的AsyncState就会从STARTING--&gt;STARTED，SocketState为LONG // // 状态转换，有三种情况 // 1. COMPLETE_PENDING---&gt;COMPLETING，COMPLETE_PENDING是在调用complete方法时候由STARTING改变过来的 // 2. STARTING----&gt;STARTED，STARTED的下一个状态需要有complete方法来改变，会改成COMPLETING // 3. COMPLETING----&gt;DISPATCHED state = processor.asyncPostProcess(); &#125; // 如果在访问异步servlet时，代码执行到这里，已经调用过complete方法了，那么状态就是SocketState.ASYNC_END &#125; while (state == SocketState.ASYNC_END || state == SocketState.UPGRADING || state == SocketState.UPGRADING_TOMCAT); return state; &#125; return SocketState.CLOSED; &#125;&#125;public abstract class AbstractHttp11Processor&lt;S&gt; extends AbstractProcessor&lt;S&gt; &#123; public SocketState process(SocketWrapper&lt;S&gt; socketWrapper) throws IOException &#123; RequestInfo rp = request.getRequestProcessor(); rp.setStage(org.apache.coyote.Constants.STAGE_PARSE); // 设置请求状态为解析状态 // Setting up the I/O setSocketWrapper(socketWrapper); getInputBuffer().init(socketWrapper, endpoint); // 将socket的InputStream与InternalInputBuffer进行绑定 getOutputBuffer().init(socketWrapper, endpoint); // 将socket的OutputStream与InternalOutputBuffer进行绑定 keepAlive = true; comet = false; openSocket = false; sendfileInProgress = false; readComplete = true; // NioEndpoint返回true, Bio返回false if (endpoint.getUsePolling()) &#123; keptAlive = false; &#125; else &#123; keptAlive = socketWrapper.isKeptAlive(); &#125; // 如果当前活跃的线程数占线程池最大线程数的比例大于75%，那么则关闭KeepAlive，不再支持长连接 if (disableKeepAlive()) &#123; socketWrapper.setKeepAliveLeft(0); &#125; // keepAlive默认为true,它的值会从请求中读取 while (!getErrorState().isError() &amp;&amp; keepAlive &amp;&amp; !comet &amp;&amp; !isAsync() &amp;&amp; upgradeInbound == null &amp;&amp; httpUpgradeHandler == null &amp;&amp; !endpoint.isPaused()) &#123; // keepAlive如果为true,接下来需要从socket中不停的获取http请求 try &#123; // 第一次从socket中读取数据，并设置socket的读取数据的超时时间 // 对于BIO，一个socket连接建立好后，不一定马上就被Tomcat处理了，其中需要线程池的调度，所以这段等待的时间要算在socket读取数据的时间内 // 而对于NIO而言，没有阻塞 setRequestLineReadTimeout(); // 解析请求行 if (!getInputBuffer().parseRequestLine(keptAlive)) &#123; // 下面这个方法在NIO时有用，比如在解析请求行时，如果没有从操作系统读到数据，则上面的方法会返回false // 而下面这个方法会返回true，从而退出while，表示此处read事件处理结束，到下一次read事件发生了，就会从小进入到while中 if (handleIncompleteRequestLineRead()) &#123; break; &#125; &#125; if (endpoint.isPaused()) &#123; // 503 - Service unavailable // 如果Endpoint被暂停了，则返回503 response.setStatus(503); setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; else &#123; keptAlive = true; // Set this every time in case limit has been changed via JMX // 每次处理一个请求就重新获取一下请求头和cookies的最大限制 request.getMimeHeaders().setLimit(endpoint.getMaxHeaderCount()); request.getCookies().setLimit(getMaxCookieCount()); // Currently only NIO will ever return false here // 解析请求头 if (!getInputBuffer().parseHeaders()) &#123; // We've read part of the request, don't recycle it // instead associate it with the socket openSocket = true; readComplete = false; break; &#125; if (!disableUploadTimeout) &#123; setSocketTimeout(connectionUploadTimeout); &#125; &#125; &#125; if (!getErrorState().isError()) &#123; // Setting up filters, and parse some request headers rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE); // 设置请求状态为预处理状态 try &#123; prepareRequest(); // 预处理, 主要从请求中处理处keepAlive属性，以及进行一些验证，以及根据请求分析得到ActiveInputFilter &#125; &#125; if (maxKeepAliveRequests == 1) &#123; // 如果最大的活跃http请求数量仅仅只能为1的话，那么设置keepAlive为false，则不会继续从socket中获取Http请求了 keepAlive = false; &#125; else if (maxKeepAliveRequests &gt; 0 &amp;&amp; socketWrapper.decrementKeepAlive() &lt;= 0) &#123; // 如果已经达到了keepAlive的最大限制，也设置为false，则不会继续从socket中获取Http请求了 keepAlive = false; &#125; // Process the request in the adapter if (!getErrorState().isError()) &#123; try &#123; rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE); // 设置请求的状态为服务状态，表示正在处理请求 adapter.service(request, response); // 交给容器处理请求 if(keepAlive &amp;&amp; !getErrorState().isError() &amp;&amp; (response.getErrorException() != null || (!isAsync() &amp;&amp; statusDropsConnection(response.getStatus())))) &#123; setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; setCometTimeouts(socketWrapper); &#125; &#125; // Finish the handling of the request rp.setStage(org.apache.coyote.Constants.STAGE_ENDINPUT); // 设置请求的状态为处理请求结束 if (!isAsync() &amp;&amp; !comet) &#123; // 当前http请求已经处理完了，做一些收尾工作 endRequest(); &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDOUTPUT); // 请求状态为输出结束 if (getErrorState().isError()) &#123; response.setStatus(500); &#125; request.updateCounters(); if (!isAsync() &amp;&amp; !comet || getErrorState().isError()) &#123; if (getErrorState().isIoAllowed()) &#123; // 准备处理下一个请求 getInputBuffer().nextRequest(); getOutputBuffer().nextRequest(); &#125; &#125; rp.setStage(org.apache.coyote.Constants.STAGE_KEEPALIVE); // 如果处理完当前这个Http请求之后，发现socket里没有下一个请求了,那么就退出当前循环 // 如果是keepalive，就不会关闭socket, 如果是close就会关闭socket // 对于keepalive的情况，因为是一个线程处理一个socket,当退出这个while后，当前线程就会介绍， // 当时对于socket来说，它仍然要继续介绍连接，所以又会新开一个线程继续来处理这个socket if (breakKeepAliveLoop(socketWrapper)) &#123; break; &#125; &#125; &#125;&#125; 当Servlet中通过inputstream.read()来读取请求体数据时，最终执行的是InternalNioInputBuffer.SocketInputBuffer.doRead()方法，该方法中会调用fill(true,true)，第一个参数是timeout，第二个参数是block，block等于true，表示阻塞，fill方法会从操作系统读取数据填充到Tomcat的buf中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556protected boolean fill(boolean timeout, boolean block) throws IOException, EOFException &#123; // 读请求体数据的时候需要阻塞读 boolean read = false; if (parsingHeader) &#123; if (lastValid &gt; headerBufferSize) &#123; throw new IllegalArgumentException(sm.getString(\"iib.requestheadertoolarge.error\")); &#125; // Do a simple read with a short timeout read = readSocket(timeout,block)&gt;0; &#125; else &#123; lastValid = pos = end; // Do a simple read with a short timeout read = readSocket(timeout, block)&gt;0; &#125; return read;&#125;private int readSocket(boolean timeout, boolean block) throws IOException &#123; // 读请求体数据的时候需要阻塞读 int nRead = 0; socket.getBufHandler().getReadBuffer().clear(); if ( block ) &#123; Selector selector = null; try &#123; selector = pool.get(); &#125; try &#123; NioEndpoint.KeyAttachment att = (NioEndpoint.KeyAttachment) socket.getAttachment(); if (att == null) &#123; throw new IOException(\"Key must be cancelled.\"); &#125; // socket. selector nRead = pool.read(socket.getBufHandler().getReadBuffer(), socket, selector, att.getTimeout()); &#125; catch ( EOFException eof ) &#123; nRead = -1; &#125; finally &#123; if ( selector != null ) pool.put(selector); &#125; &#125; else &#123; // 非阻塞读，没有读到不会阻塞，立即返回0，如果在处理这次NIo事件中没有读到数据，那么此事件其实就是处理结束了，等待下一次事件 nRead = socket.read(socket.getBufHandler().getReadBuffer()); &#125; if (nRead &gt; 0) &#123; socket.getBufHandler().getReadBuffer().flip(); socket.getBufHandler().getReadBuffer().limit(nRead); expand(nRead + pos); // 把readBuffer中的数据转移到buf中 socket.getBufHandler().getReadBuffer().get(buf, pos, nRead); lastValid = pos + nRead; return nRead; &#125; else if (nRead == -1) &#123; //return false; throw new EOFException(sm.getString(\"iib.eof.error\")); &#125; else &#123; return 0; &#125;&#125; 在接下来的阻塞读取数据流程中，主要利用的还是Selector，为什么阻塞的时候还要利用Selector呢，因为socketChannel一开始是非阻塞的，我们现在如果想把它改成阻塞的，在NIO里是有一个限制的，如果一个socketChannel被设置成了非阻塞的，然后注册了事件，然后又想把socketChannel设置成阻塞的，这时会抛异常。所以在Tomcat中是使用的另外的方式来达到阻塞效果的。 在需要读取请求体数据时，不能直接利用之前的主Selector了，主Selector就是用来注册新socketChannel的，需要一个辅助Selector，在读取请求体数据时，新生成一个辅助Selector，这个辅助Selector用来监听当前请求的读事件，当有数据就绪时，辅助Selector就会查询到此次就绪事件，这时主Selector是监听不到的，因为在这之前主Selector已经取消了对当前socketChannel的事件。 这是辅助Selector的主要作用，inputstream.read()，向辅助Selector注册读事件，加锁（目的是达到阻塞），与辅助Selector对应的有另外一个辅助Poller，辅助Poller负责轮询辅助Selector上发生的就绪事件，一旦轮询到就绪事件就会解锁，从而解阻塞，从socketChannel中读数据，返回，本次read结束。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146public class NioSelectorPool &#123; protected static final boolean SHARED = Boolean.parseBoolean(System.getProperty(\"org.apache.tomcat.util.net.NioSelectorShared\", \"true\")); protected NioBlockingSelector blockingSelector; protected volatile Selector SHARED_SELECTOR; protected ConcurrentLinkedQueue&lt;Selector&gt; selectors = new ConcurrentLinkedQueue&lt;Selector&gt;(); protected Selector getSharedSelector() throws IOException &#123; if (SHARED &amp;&amp; SHARED_SELECTOR == null) &#123; synchronized ( NioSelectorPool.class ) &#123; if ( SHARED_SELECTOR == null ) &#123; synchronized (Selector.class) &#123; SHARED_SELECTOR = Selector.open(); &#125; &#125; &#125; &#125; return SHARED_SELECTOR; &#125; public Selector get() throws IOException&#123; if ( SHARED ) &#123; return getSharedSelector(); &#125; if ( (!enabled) || active.incrementAndGet() &gt;= maxSelectors ) &#123; if ( enabled ) active.decrementAndGet(); return null; &#125; Selector s = null; try &#123; s = selectors.size()&gt;0?selectors.poll():null; if (s == null) &#123; synchronized (Selector.class) &#123; s = Selector.open(); &#125; &#125; else spare.decrementAndGet(); &#125; catch (NoSuchElementException x ) &#123; try &#123; synchronized (Selector.class) &#123; s = Selector.open(); &#125; &#125; &#125; finally &#123; if ( s == null ) active.decrementAndGet();//we were unable to find a selector &#125; return s; &#125; public void open() throws IOException &#123; enabled = true; getSharedSelector(); if (SHARED) &#123; blockingSelector = new NioBlockingSelector(); blockingSelector.open(getSharedSelector()); &#125; &#125; public int write(ByteBuffer buf, NioChannel socket, Selector selector, long writeTimeout) throws IOException &#123; return write(buf,socket,selector,writeTimeout,true); &#125; public int write(ByteBuffer buf, NioChannel socket, Selector selector, long writeTimeout, boolean block) throws IOException &#123; if ( SHARED &amp;&amp; block ) &#123; return blockingSelector.write(buf,socket,writeTimeout); &#125; SelectionKey key = null; int written = 0; boolean timedout = false; int keycount = 1; //assume we can write 假设现在就可以写 long time = System.currentTimeMillis(); //start the timeout timer try &#123; // 没有超时并且buf中有数据 while ( (!timedout) &amp;&amp; buf.hasRemaining() ) &#123; int cnt = 0; if ( keycount &gt; 0 ) &#123; //only write if we were registered for a write // 写数据，返回的数字是多少，表示写了多少，可能返回0，表示没有写入数据 cnt = socket.write(buf); //write the data if (cnt == -1) throw new EOFException(); written += cnt; if (cnt &gt; 0) &#123; // 如果有数据写到socket中了，就继续while，看buf中还有没剩余数据 time = System.currentTimeMillis(); //reset our timeout timer continue; //we successfully wrote, try again without a selector &#125; // 如果没有写入数据并且是阻塞的，则不会break if (cnt==0 &amp;&amp; (!block)) break; //don't block &#125; if ( selector != null ) &#123; //register OP_WRITE to the selector // 向selector注册一个写事件 if (key==null) key = socket.getIOChannel().register(selector, SelectionKey.OP_WRITE); else key.interestOps(SelectionKey.OP_WRITE); // 查询是否有写事件发生 keycount = selector.select(writeTimeout); &#125; // 看是否超时 if (writeTimeout &gt; 0 &amp;&amp; (selector == null || keycount == 0) ) timedout = (System.currentTimeMillis()-time)&gt;=writeTimeout; &#125;//while if ( timedout ) throw new SocketTimeoutException(); &#125; finally &#123; if (key != null) &#123; key.cancel(); if (selector != null) selector.selectNow();//removes the key from this selector &#125; &#125; return written; &#125; public int read(ByteBuffer buf, NioChannel socket, Selector selector, long readTimeout) throws IOException &#123; return read(buf,socket,selector,readTimeout,true); &#125; public int read(ByteBuffer buf, NioChannel socket, Selector selector, long readTimeout, boolean block) throws IOException &#123; if ( SHARED &amp;&amp; block ) &#123; return blockingSelector.read(buf,socket,readTimeout); &#125; SelectionKey key = null; int read = 0; boolean timedout = false; int keycount = 1; //assume we can write long time = System.currentTimeMillis(); //start the timeout timer try &#123; while ( (!timedout) ) &#123; int cnt = 0; if ( keycount &gt; 0 ) &#123; //only read if we were registered for a read cnt = socket.read(buf); if (cnt == -1) throw new EOFException(); read += cnt; if (cnt &gt; 0) continue; //read some more if (cnt==0 &amp;&amp; (read&gt;0 || (!block) ) ) break; //we are done reading &#125; if ( selector != null ) &#123;//perform a blocking read //register OP_WRITE to the selector if (key==null) key = socket.getIOChannel().register(selector, SelectionKey.OP_READ); else key.interestOps(SelectionKey.OP_READ); keycount = selector.select(readTimeout); &#125; if (readTimeout &gt; 0 &amp;&amp; (selector == null || keycount == 0) ) timedout = (System.currentTimeMillis()-time)&gt;=readTimeout; &#125;//while if ( timedout ) throw new SocketTimeoutException(); &#125; finally &#123; if (key != null) &#123; key.cancel(); if (selector != null) selector.selectNow();//removes the key from this selector &#125; &#125; return read; &#125;&#125; 默认情况下，辅助Selector是NioBlockingSelector对象，每次read都使用同一个NioBlockingSelector对象，在NioBlockingSelector对象中存在一个辅助Poller即BlockPoller线程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183public class NioBlockingSelector &#123; protected BlockPoller poller; protected Selector sharedSelector; public void open(Selector selector) &#123; sharedSelector = selector; poller = new BlockPoller(); poller.selector = sharedSelector; poller.setDaemon(true); poller.setName(\"NioBlockingSelector.BlockPoller-\"+(++threadCounter)); poller.start(); &#125; public int read(ByteBuffer buf, NioChannel socket, long readTimeout) throws IOException &#123; SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); if ( key == null ) throw new IOException(\"Key no longer registered\"); KeyReference reference = keyReferenceQueue.poll(); if (reference == null) &#123; reference = new KeyReference(); &#125; KeyAttachment att = (KeyAttachment) key.attachment(); int read = 0; boolean timedout = false; int keycount = 1; //assume we can read long time = System.currentTimeMillis(); //start the timeout timer try &#123; while(!timedout) &#123; if (keycount &gt; 0) &#123; //only read if we were registered for a read // 先尝试着读一下，如果没有读到数据，则返回0 read = socket.read(buf); if (read == -1) throw new EOFException(); if (read &gt; 0) break; &#125; try &#123; // 开启latch if ( att.getReadLatch()==null || att.getReadLatch().getCount()==0) att.startReadLatch(1); // 将注册读事件，通过events队列和线程实现，poller为BlockPoller poller.add(att,SelectionKey.OP_READ, reference); if (readTimeout &lt; 0) &#123; att.awaitReadLatch(Long.MAX_VALUE, TimeUnit.MILLISECONDS); &#125; else &#123; // 注册完事件后就会阻塞，直到BlockPoller发现了读事件，才会解阻塞 att.awaitReadLatch(readTimeout, TimeUnit.MILLISECONDS); &#125; &#125;catch (InterruptedException ignore) &#123; Thread.interrupted(); &#125; // 不是正常被poller解阻塞的 if ( att.getReadLatch()!=null &amp;&amp; att.getReadLatch().getCount()&gt; 0) &#123; //we got interrupted, but we haven't received notification from the poller. keycount = 0; &#125;else &#123; // 解阻塞之后就得到了1个读事件，就可以读取数据了 //latch countdown has happened keycount = 1; att.resetReadLatch(); &#125; if (readTimeout &gt;= 0 &amp;&amp; (keycount == 0)) timedout = (System.currentTimeMillis() - time) &gt;= readTimeout; &#125; //while if (timedout) throw new SocketTimeoutException(); &#125; finally &#123; poller.remove(att,SelectionKey.OP_READ); if (timedout &amp;&amp; reference.key!=null) &#123; poller.cancelKey(reference.key); &#125; reference.key = null; keyReferenceQueue.add(reference); &#125; return read; &#125; protected static class BlockPoller extends Thread &#123; protected volatile boolean run = true; protected Selector selector = null; protected ConcurrentLinkedQueue&lt;Runnable&gt; events = new ConcurrentLinkedQueue&lt;Runnable&gt;(); public void add(final KeyAttachment key, final int ops, final KeyReference ref) &#123; Runnable r = new Runnable() &#123; @Override public void run() &#123; if ( key == null ) return; NioChannel nch = key.getChannel(); if ( nch == null ) return; SocketChannel ch = nch.getIOChannel(); if ( ch == null ) return; SelectionKey sk = ch.keyFor(selector); try &#123; // 将事件注册到BlockPoller的selector上，sharedSelector if (sk == null) &#123; sk = ch.register(selector, ops, key); ref.key = sk; &#125; else if (!sk.isValid()) &#123; cancel(sk,key,ops); &#125; else &#123; sk.interestOps(sk.interestOps() | ops); &#125; &#125;catch (CancelledKeyException cx) &#123; cancel(sk,key,ops); &#125;catch (ClosedChannelException cx) &#123; cancel(sk,key,ops); &#125; &#125; &#125;; // 添加进事件队列 events.offer(r); // 添加事件成功后，立即唤醒select.select()方法 wakeup(); &#125; public boolean events() &#123; Runnable r = null; int size = events.size(); for (int i = 0; i &lt; size &amp;&amp; (r = events.poll()) != null; i++) &#123; r.run(); &#125; return (size &gt; 0); &#125; @Override public void run() &#123; while (run) &#123; try &#123; events(); // 执行PollerEvent实现，就是Runnable int keyCount = 0; try &#123; // 这个wakeupCounter只有0，-1，1三中情况 int i = wakeupCounter.get(); // i==1表示添加了PollerEvent，并且上面执行了events方法，所以应该可以直接selectNow查询到事件 if (i&gt;0) keyCount = selector.selectNow(); else &#123; // 此处i只可能为0，然后改成-1，表示没有添加过PollerEvent，然后阻塞获取 // 在阻塞获取就绪事件的过程中，很有可能添加了PollerEvent进入到了events中，并且会被唤醒，调用selector.wakeup() wakeupCounter.set(-1); keyCount = selector.select(1000); &#125; // 不管有没有查询到就绪事件，都会改为0 wakeupCounter.set(0); if (!run) break; &#125;catch ( NullPointerException x ) &#123; continue; &#125; catch ( CancelledKeyException x ) &#123; continue; &#125; catch (Throwable x) &#123; ExceptionUtils.handleThrowable(x); log.error(\"\",x); continue; &#125; Iterator&lt;SelectionKey&gt; iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator() : null; while (run &amp;&amp; iterator != null &amp;&amp; iterator.hasNext()) &#123; SelectionKey sk = iterator.next(); KeyAttachment attachment = (KeyAttachment)sk.attachment(); try &#123; attachment.access(); iterator.remove(); sk.interestOps(sk.interestOps() &amp; (~sk.readyOps())); if ( sk.isReadable() ) &#123; countDown(attachment.getReadLatch()); &#125; if (sk.isWritable()) &#123; countDown(attachment.getWriteLatch()); &#125; &#125;catch (CancelledKeyException ckx) &#123; sk.cancel(); countDown(attachment.getReadLatch()); countDown(attachment.getWriteLatch()); &#125; &#125;//while &#125;catch ( Throwable t ) &#123; log.error(\"\",t); &#125; &#125; events.clear(); if (selector.isOpen()) &#123; try &#123; selector.selectNow(); &#125;catch( Exception ignore ) &#123; if (log.isDebugEnabled())log.debug(\"\",ignore); &#125; &#125; &#125; &#125;&#125; 对于响应也是类似的思路，也是先注册写事件，阻塞，都有写就绪事件时就解阻塞，开始写入数据。","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Tomcat","slug":"中间件/Tomcat","permalink":"https://yaoyinglong.github.io/categories/中间件/Tomcat/"}]},{"title":"Tomcat处理响应过程","date":"2021-08-23T16:00:00.000Z","path":"Blog/中间件/Tomcat/Tomcat处理响应过程/","text":"和读取数据原理类似，getOutputStream方法调用的是Tomcat底层Response的getOutputStream方法，最终是通过CoyoteOutputStream方法的write方法去写数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; OutputStream outputStream = resp.getOutputStream(); outputStream.write(\"test\".getBytes()); outputStream.flush(); outputStream.write(\"test2222\".getBytes());&#125;public ServletOutputStream getOutputStream() throws IOException &#123; if (usingWriter) &#123; throw new IllegalStateException (sm.getString(\"coyoteResponse.getOutputStream.ise\")); &#125; usingOutputStream = true; if (outputStream == null) &#123; // outputBuffer就是输出缓冲区 outputStream = new CoyoteOutputStream(outputBuffer); &#125; return outputStream;&#125;public class CoyoteOutputStream extends ServletOutputStream &#123; protected OutputBuffer ob; @Override public void write(byte[] b) throws IOException &#123; write(b, 0, b.length); &#125; @Override public void write(byte[] b, int off, int len) throws IOException &#123; ob.write(b, off, len); &#125;&#125;public class OutputBuffer extends Writer implements ByteChunk.ByteOutputChannel, CharChunk.CharOutputChannel &#123; private final ByteChunk bb; private byte[] buff; public void write(byte b[], int off, int len) throws IOException &#123; if (suspended) &#123; return; &#125; writeBytes(b, off, len); &#125; private void writeBytes(byte b[], int off, int len) throws IOException &#123; if (closed) &#123; return; &#125; // 将数据先写入ByteChunk的缓冲区中, 如果缓冲区满了，可能会把数据发送出去 bb.append(b, off, len); bytesWritten += len; // 如果此前已经调用过flush方法 if (doFlush) &#123; // 那么每次write都把缓冲中的数据发送出去 bb.flushBuffer(); &#125; &#125; public void append(byte src[], int off, int len) throws IOException &#123; // will grow, up to limit // 向缓冲区中添加数据，需要开辟缓存区空间，缓存区初始大小为256，最大大小可以设置，默认为8192 // 意思是现在要想缓冲区存放数据，首先得去开辟空间，但是空间是有一个最大限制的，所以要存放的数据可能小于限制，也可能大于限制 makeSpace(len); int limit = getLimitInternal(); // 缓冲区大小的最大限制 // 如果要添加到缓冲区中的数据大小正好等于最大限制，并且缓冲区是空的，那么则直接把数据发送给out，不要存在缓冲区中了 if (optimizedWrite &amp;&amp; len == limit &amp;&amp; end == start &amp;&amp; out != null) &#123; out.realWriteBytes(src, off, len); return; &#125; // 如果要发送的数据长度小于缓冲区中剩余空间，则把数据填充到剩余空间 if (len &lt;= limit - end) &#123; System.arraycopy(src, off, buff, end, len); end += len; return; &#125; // 如果要发送的数据长度大于缓冲区中剩余空间， // Need more space than we can afford, need to flush buffer. // The buffer is already at (or bigger than) limit. // We chunk the data into slices fitting in the buffer limit, although // if the data is written directly if it doesn't fit. // 缓冲区中还能容纳avail个字节的数据 int avail = limit - end; // 先将一部分数据复制到buff，填满缓冲区 System.arraycopy(src, off, buff, end, avail); end += avail; // 将缓冲区的数据发送出去 flushBuffer(); // 还剩下一部分数据没有放到缓冲区中的 int remain = len - avail; // 如果剩下的数据 超过 缓冲区剩余大小,那么就把数据直接发送出去 while (remain &gt; (limit - end)) &#123; out.realWriteBytes(src, (off + len) - remain, limit - end); remain = remain - (limit - end); &#125; // 知道最后剩下的数据能放入缓冲区，那么就放入到缓冲区 System.arraycopy(src, (off + len) - remain, buff, end, remain); end += remain; &#125; public void realWriteBytes(byte buf[], int off, int cnt) throws IOException &#123; if (closed) &#123; return; &#125; if (coyoteResponse == null) &#123; return; &#125; if (cnt &gt; 0) &#123; outputChunk.setBytes(buf, off, cnt); try &#123; coyoteResponse.doWrite(outputChunk); &#125; catch (IOException e) &#123; throw new ClientAbortException(e); &#125; &#125; &#125;&#125; 最终调用的底层的coyote包下面Response中的doWrite方法来写数据： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public final class Response &#123; public void doWrite(ByteChunk chunk) throws IOException &#123; // 把chunk中的数据写入InternalOutputBuffer outputBuffer.doWrite(chunk, this); contentWritten+=chunk.getLength(); &#125;&#125;public abstract class AbstractOutputBuffer&lt;S&gt; implements OutputBuffer&#123; public int doWrite(ByteChunk chunk, Response res) throws IOException &#123; // 没有发送响应头，则先发送响应头 if (!committed) &#123; // Send the connector a request for commit. The connector should // then validate the headers, send them (using sendHeaders) and // set the filters accordingly. response.action(ActionCode.COMMIT, null); &#125; // chunk, content- // 通过outputStreamOutputBuffer发送数据，可能会再次先发到缓冲区，也可能直接发送socket // 在发送响应头的时候，会设置ActiveFilter，如果没有则直接发给outputStreamOutputBuffer，如果有先经过ActiveFilter if (lastActiveFilter == -1) return outputStreamOutputBuffer.doWrite(chunk, res); else return activeFilters[lastActiveFilter].doWrite(chunk, res); &#125;&#125;protected class OutputStreamOutputBuffer implements OutputBuffer &#123; public int doWrite(ByteChunk chunk, Response res) throws IOException &#123; try &#123; int length = chunk.getLength(); // 如果再次发送到缓冲区中，则该缓冲区慢了之后就会发送，或者当前请求要结束时发送 if (useSocketBuffer) &#123; socketBuffer.append(chunk.getBuffer(), chunk.getStart(), length); &#125; else &#123; outputStream.write(chunk.getBuffer(), chunk.getStart(), length); &#125; byteCount += chunk.getLength(); return chunk.getLength(); &#125; catch (IOException ioe) &#123; response.action(ActionCode.CLOSE_NOW, ioe); throw ioe; &#125; &#125;&#125; 与读数据有点区别在于，outputStream.write方法并不是直接将数据写到操作系统中的sendBuf，而是在中间有两层缓冲区outputBuffer和socketBuffer，首先数据会进入到outputBuffer，当outputBuffer满了后会进入到socketBuffer，是否进入socketBuffer是有有点的条件的，当socketBuffer满了后会将数据写入到操作系统的sendBuf发送给客户端，当显示的调用flush方法或者close方法也会将数据写入sendBuf发送给客户端。当然如果程序执行完了后，若数据未发送出去，会进行相关的处理将数据写入sendBuf发送给客户端。 当显示调用flush方法是会生成响应头将数据发送出去，再次发送时就不会在发送响应头了，数据以chunk的方式发送数据，而不是以content-length的方式发送数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public class CoyoteOutputStream extends ServletOutputStream &#123; protected OutputBuffer ob; public void flush() throws IOException &#123; ob.flush(); &#125;&#125;public class OutputBuffer extends Writer implements ByteChunk.ByteOutputChannel, CharChunk.CharOutputChannel &#123; public void flush() throws IOException &#123; doFlush(true); &#125; protected void doFlush(boolean realFlush) throws IOException &#123; if (suspended) &#123; return; &#125; try &#123; doFlush = true; if (initial) &#123; // 先发送请求头，再发送请求体 coyoteResponse.sendHeaders(); initial = false; &#125; if (cb.getLength() &gt; 0) &#123; cb.flushBuffer(); &#125; if (bb.getLength() &gt; 0) &#123; // 这里只是把上层缓冲区中的数据发送到底层缓冲区中，所以数据到底会不会发送给socket并不确定 bb.flushBuffer(); &#125; &#125; finally &#123; doFlush = false; &#125; if (realFlush) &#123; // 如果是真正flush，把底层缓冲区中的数据发送给socket coyoteResponse.action(ActionCode.CLIENT_FLUSH, null); if (coyoteResponse.isExceptionPresent()) &#123; throw new ClientAbortException(coyoteResponse.getErrorException()); &#125; &#125; &#125;&#125;public final class Response &#123; public void sendHeaders() &#123; action(ActionCode.COMMIT, this); setCommitted(true); &#125; public void action(ActionCode actionCode, Object param) &#123; if (hook != null) &#123; if (param == null) &#123; hook.action(actionCode, this); &#125; else &#123; hook.action(actionCode, param); &#125; &#125; &#125;&#125;public abstract class AbstractHttp11Processor&lt;S&gt; extends AbstractProcessor&lt;S&gt; &#123; public final void action(ActionCode actionCode, Object param) &#123; switch (actionCode) &#123; case CLOSE: &#123; // End the processing of the current request try &#123; getOutputBuffer().endRequest(); &#125; catch (IOException e) &#123; setErrorState(ErrorState.CLOSE_NOW, e); &#125; break; &#125; case COMMIT: &#123; // Commit current response if (response.isCommitted()) &#123; return; &#125; // Validate and write response headers try &#123; prepareResponse(); // 把响应头的数据写入到InternalOutputBuffer中 getOutputBuffer().commit(); // 将InternalOutputBuffer中的数据发送给socket &#125; catch (IOException e) &#123; setErrorState(ErrorState.CLOSE_NOW, e); &#125; break; &#125; case CLIENT_FLUSH: &#123; try &#123; // 将InternalOutputBuffer中的数据发送给socket getOutputBuffer().flush(); &#125; catch (IOException e) &#123; setErrorState(ErrorState.CLOSE_NOW, e); response.setErrorException(e); &#125; break; &#125; &#125;&#125;public class InternalOutputBuffer extends AbstractOutputBuffer&lt;Socket&gt; implements ByteChunk.ByteOutputChannel &#123; protected void commit() throws IOException &#123; committed = true; response.setCommitted(true); if (pos &gt; 0) &#123; // Sending the response header buffer，如果用了socketbuffer则写写到socketbuffer中，如果没有则直接通过socketoutputstream返回 if (useSocketBuffer) &#123; socketBuffer.append(buf, 0, pos); &#125; else &#123; outputStream.write(buf, 0, pos); &#125; &#125; &#125; public void flush() throws IOException &#123; super.flush(); // Flush the current buffer // 上面的流程目的是把数据发送给socket，但是如果使用了socketBuffer，那么就只会把数据发送给socketbuffer，所以这里要调用socketbuffer最终发送数据 if (useSocketBuffer) &#123; socketBuffer.flushBuffer(); &#125; &#125;&#125;","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Tomcat","slug":"中间件/Tomcat","permalink":"https://yaoyinglong.github.io/categories/中间件/Tomcat/"}]},{"title":"Tomcat处理请求过程","date":"2021-08-22T16:00:00.000Z","path":"Blog/中间件/Tomcat/Tomcat处理请求过程/","text":"数据在操作系统层面是通过TCP协议来传输通过Socket来实现，Tomcat是实现的HTTP等应用层的协议，通过Socket去获取解析数据，解析出请求行、请求头、请求体，从而生成具体的HttpServletRequest对象； Tomcat接收到请求后，首先会判断该请求域名，找到对应的Host，再根据请求信息找到要访问的应用即Context，Context拿到请求后，会根据请求信息找到对应的Servelet； Tomcat中有一个Connector组件，其专门用来接收Socket连接，在Connector内部有个组件叫ProtocolHandler，其有好几种实现Http11Protocol、Http11NioProtocol、Http11AprProtocol，在Connector中通过配置的协议去处理相关的请求： 1234567891011121314151617181920212223public class Connector extends LifecycleMBeanBase &#123; public void setProtocol(String protocol) &#123; if (AprLifecycleListener.isAprAvailable()) &#123; if (\"HTTP/1.1\".equals(protocol)) &#123; setProtocolHandlerClassName(\"org.apache.coyote.http11.Http11AprProtocol\"); &#125; else if (\"AJP/1.3\".equals(protocol)) &#123; setProtocolHandlerClassName(\"org.apache.coyote.ajp.AjpAprProtocol\"); &#125; else if (protocol != null) &#123; setProtocolHandlerClassName(protocol); &#125; else &#123; setProtocolHandlerClassName(\"org.apache.coyote.http11.Http11AprProtocol\"); &#125; &#125; else &#123; if (\"HTTP/1.1\".equals(protocol)) &#123; setProtocolHandlerClassName(\"org.apache.coyote.http11.Http11Protocol\"); // BIO &#125; else if (\"AJP/1.3\".equals(protocol)) &#123; setProtocolHandlerClassName(\"org.apache.coyote.ajp.AjpProtocol\"); &#125; else if (protocol != null) &#123; setProtocolHandlerClassName(protocol); // org.apache.coyote.http11NIOProxot &#125; &#125; &#125;&#125; 以Http11Protocol为例，在Http11Protocol中有个JIoEndpoint组件，实例化该实例时回去创建JIoEndpoint： 12345678public Http11Protocol() &#123; endpoint = new JIoEndpoint(); cHandler = new Http11ConnectionHandler(this); ((JIoEndpoint) endpoint).setHandler(cHandler); setSoLinger(Constants.DEFAULT_CONNECTION_LINGER); setSoTimeout(Constants.DEFAULT_CONNECTION_TIMEOUT); setTcpNoDelay(Constants.DEFAULT_TCP_NO_DELAY);&#125; 最终请求在JIoEndpoint通过Acceptor侦听传入TCP/IP连接并将它们移交给适当处理器的后台线程处理，非关键代码被移除： 123456789101112131415161718192021222324252627282930313233343536protected class Acceptor extends AbstractEndpoint.Acceptor &#123; @Override public void run() &#123; int errorDelay = 0; while (running) &#123; try &#123; //达到了最大连接数限制则等待 countUpOrAwaitConnection(); Socket socket = null; // bio，nio try &#123; // 此处是阻塞的，那么running属性就算已经被改成false，那么怎么进入到下一次循环呢？ socket = serverSocketFactory.acceptSocket(serverSocket);// System.out.println(\"接收到了一个socket连接\"); &#125; catch (IOException ioe) &#123; countDownConnection(); errorDelay = handleExceptionWithDelay(errorDelay); throw ioe; &#125; errorDelay = 0; // 如果Endpoint正在运行并且没有被暂停，那么就处理该socket if (running &amp;&amp; !paused &amp;&amp; setSocketOptions(socket)) &#123; // socket被正常的交给了线程池，processSocket就会返回true // 如果没有被交给线程池或者中途Endpoint被停止了，则返回false，返回false则关闭该socket if (!processSocket(socket)) &#123; countDownConnection(); closeSocket(socket); &#125; &#125; else &#123; countDownConnection(); closeSocket(socket); &#125; &#125; &#125; state = AcceptorState.ENDED; &#125;&#125; 通过processSocket将一个HTTP请求放到线程中处理： 12345678910111213protected boolean processSocket(Socket socket) &#123; try &#123; SocketWrapper&lt;Socket&gt; wrapper = new SocketWrapper&lt;Socket&gt;(socket); wrapper.setKeepAliveLeft(getMaxKeepAliveRequests()); wrapper.setSecure(isSSLEnabled()); if (!running) &#123; return false; &#125; // bio， 一个socket连接对应一个线程 getExecutor().execute(new SocketProcessor(wrapper)); &#125; return true;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected class SocketProcessor implements Runnable &#123; protected SocketWrapper&lt;Socket&gt; socket = null; protected SocketStatus status = null; public SocketProcessor(SocketWrapper&lt;Socket&gt; socket) &#123; if (socket==null) throw new NullPointerException(); this.socket = socket; &#125; @Override public void run() &#123; boolean launch = false; synchronized (socket) &#123; try &#123; SocketState state = SocketState.OPEN; try &#123; serverSocketFactory.handshake(socket.getSocket()); &#125; // 当前socket没有关闭则处理socket if ((state != SocketState.CLOSED)) &#123; // SocketState是Tomcat定义的一个状态,这个状态需要处理一下socket才能确定，因为跟客户端，跟具体的请求信息有关系 if (status == null) &#123; state = handler.process(socket, SocketStatus.OPEN_READ); &#125; else &#123; // status表示应该读数据还是应该写数据，state表示处理完socket后socket的状态 state = handler.process(socket,status); &#125; &#125; // 如果Socket的状态是被关闭，那么就减掉连接数并关闭socket，那么Socket的状态是在什么时候被关闭的？ if (state == SocketState.CLOSED) &#123; countDownConnection(); try &#123; socket.getSocket().close(); &#125; &#125; else if (state == SocketState.OPEN || state == SocketState.UPGRADING || state == SocketState.UPGRADING_TOMCAT || state == SocketState.UPGRADED)&#123; socket.setKeptAlive(true); socket.access(); launch = true; &#125; else if (state == SocketState.LONG) &#123; // socket不会关闭，但是当前线程会执行结束 socket.access(); waitingRequests.add(socket); &#125; &#125; &#125; socket = null; &#125;&#125; 最终调用处理请求的核心代码，该方法也是Tomcat实现长链接的核心逻辑地方： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public SocketState process(SocketWrapper&lt;S&gt; socketWrapper) throws IOException &#123; RequestInfo rp = request.getRequestProcessor(); rp.setStage(org.apache.coyote.Constants.STAGE_PARSE); // 设置请求状态为解析状态 setSocketWrapper(socketWrapper); getInputBuffer().init(socketWrapper, endpoint); // 将socket的InputStream与InternalInputBuffer进行绑定 getOutputBuffer().init(socketWrapper, endpoint); // 将socket的OutputStream与InternalOutputBuffer进行绑定 keepAlive = true; comet = false; openSocket = false; sendfileInProgress = false; readComplete = true; // NioEndpoint返回true, Bio返回false if (endpoint.getUsePolling()) &#123; keptAlive = false; &#125; else &#123; keptAlive = socketWrapper.isKeptAlive(); &#125; // 如果当前活跃的线程数占线程池最大线程数的比例大于75%，那么则关闭KeepAlive，不再支持长连接 if (disableKeepAlive()) &#123; socketWrapper.setKeepAliveLeft(0); &#125; // keepAlive默认为true,它的值会从请求中读取 while (!getErrorState().isError() &amp;&amp; keepAlive &amp;&amp; !comet &amp;&amp; !isAsync() &amp;&amp; upgradeInbound == null &amp;&amp; httpUpgradeHandler == null &amp;&amp; !endpoint.isPaused()) &#123; // keepAlive如果为true,接下来需要从socket中不停的获取http请求 try &#123; // 第一次从socket中读取数据，并设置socket的读取数据的超时时间 // 对于BIO，一个socket连接建立好后，不一定马上就被Tomcat处理了，其中需要线程池的调度，所以这段等待的时间要算在socket读取数据的时间内，而对于NIO而言，没有阻塞 setRequestLineReadTimeout(); // 解析请求行 if (!getInputBuffer().parseRequestLine(keptAlive)) &#123; // 下面这个方法在NIO时有用，比如在解析请求行时，如果没有从操作系统读到数据，则上面的方法会返回false // 而下面这个方法会返回true，从而退出while，表示此处read事件处理结束，到下一次read事件发生了，就会从小进入到while中 if (handleIncompleteRequestLineRead()) &#123; break; &#125; &#125; if (endpoint.isPaused()) &#123; // 如果Endpoint被暂停了，则返回503 response.setStatus(503); setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; else &#123; keptAlive = true; // 每次处理一个请求就重新获取一下请求头和cookies的最大限制 request.getMimeHeaders().setLimit(endpoint.getMaxHeaderCount()); request.getCookies().setLimit(getMaxCookieCount()); // 解析请求头 if (!getInputBuffer().parseHeaders()) &#123; openSocket = true; readComplete = false; break; &#125; if (!disableUploadTimeout) &#123; setSocketTimeout(connectionUploadTimeout); &#125; &#125; &#125; if (!getErrorState().isError()) &#123; rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE); // 设置请求状态为预处理状态 try &#123; prepareRequest(); // 预处理, 主要从请求中处理处keepAlive属性，以及进行一些验证，以及根据请求分析得到ActiveInputFilter &#125; &#125; if (maxKeepAliveRequests == 1) &#123; // 如果最大的活跃http请求数量仅仅只能为1的话，那么设置keepAlive为false，则不会继续从socket中获取Http请求了 keepAlive = false; &#125; else if (maxKeepAliveRequests &gt; 0 &amp;&amp; socketWrapper.decrementKeepAlive() &lt;= 0) &#123; // 如果已经达到了keepAlive的最大限制，也设置为false，则不会继续从socket中获取Http请求了 keepAlive = false; &#125; if (!getErrorState().isError()) &#123; try &#123; rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE); // 设置请求的状态为服务状态，表示正在处理请求 adapter.service(request, response); // 交给容器处理请求 if(keepAlive &amp;&amp; !getErrorState().isError() &amp;&amp; ( response.getErrorException() != null || (!isAsync() &amp;&amp; statusDropsConnection(response.getStatus())))) &#123; setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; setCometTimeouts(socketWrapper); &#125; &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDINPUT); // 设置请求的状态为处理请求结束 if (!isAsync() &amp;&amp; !comet) &#123; if (getErrorState().isError()) &#123; getInputBuffer().setSwallowInput(false); &#125; else &#123; checkExpectationAndResponseStatus(); &#125; endRequest(); // 当前http请求已经处理完了，做一些收尾工作 &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDOUTPUT); // 请求状态为输出结束 if (getErrorState().isError()) &#123; response.setStatus(500); &#125; request.updateCounters(); if (!isAsync() &amp;&amp; !comet || getErrorState().isError()) &#123; if (getErrorState().isIoAllowed()) &#123; // 准备处理下一个请求 getInputBuffer().nextRequest(); getOutputBuffer().nextRequest(); &#125; &#125; rp.setStage(org.apache.coyote.Constants.STAGE_KEEPALIVE); // 如果处理完当前这个Http请求之后，发现socket里没有下一个请求了,那么就退出当前循环 // 如果是keepalive，就不会关闭socket, 如果是close就会关闭socket // 对于keepalive的情况，因为是一个线程处理一个socket,当退出这个while后，当前线程就会介绍， // 当时对于socket来说，它仍然要继续介绍连接，所以又会新开一个线程继续来处理这个socket if (breakKeepAliveLoop(socketWrapper)) &#123; break; &#125; &#125; // 至此，循环结束 rp.setStage(org.apache.coyote.Constants.STAGE_ENDED); // 主要流程就是将socket的状态设置为CLOSED if (getErrorState().isError() || endpoint.isPaused()) &#123; return SocketState.CLOSED; &#125; else if (isAsync() || comet) &#123;// 异步servlet return SocketState.LONG; &#125; else &#123; if (sendfileInProgress) &#123; return SocketState.SENDFILE; &#125; else &#123; if (openSocket) &#123; // openSocket为true，表示不要关闭socket // readComplete表示本次读数据是否完成，比如nio中可能就没有读完数据，还需要从socket中读数据 if (readComplete) &#123; return SocketState.OPEN; &#125; else &#123; // nio可能会走到这里 return SocketState.LONG; &#125; &#125; else &#123; return SocketState.CLOSED; &#125; &#125; &#125;&#125; 解析字节流不同的IO模型表示从Socket上获取字节流的方式不同，获取字节流后，Tomcat需要按照HTTP协议格式来解析字节流，浏览器或HttpClient发送数据时，需要按照HTTP协议来构造字符串数据，然后将字符串转换成字节发送出去。 Tomcat解析字节流的逻辑，遍历每个字节遇到空格时，之前遍历的字节数据即请求方法，继续遍历当遇到空格时，之前遍历的字节数据即URL，继续遍历当遇到回车、换行符时，之前遍历的字节数据即协议版本，且请求行遍历结束。 继续遍历当遇到一个回车符合换行符时，所遍历的数据即请求头，当遍历到两个回车符合换行符时，表示请求头遍历完毕，剩下的数据就是请求体。 1234567891011121314151617181920212223242526272829303132333435protected void setRequestLineReadTimeout() throws IOException &#123; // 最近一次访问的时间 if (inputBuffer.lastValid == 0 &amp;&amp; socketWrapper.getLastAccess() &gt; -1) &#123; int firstReadTimeout; // 如果长连接没有超时时间，那么从socket中读数据也没有超时时间 if (keepAliveTimeout == -1) &#123; firstReadTimeout = 0; &#125; else &#123; // 一个socket在被处理之前会调用一下access方法，所以queueTime表示的是socket创建好了到真正被处理这段过程的排队时间 long queueTime = System.currentTimeMillis() - socketWrapper.getLastAccess(); // 如果排队时间大于keepAliveTimeout，表示该socket已经超时了不需要被处理了，设置一个最小的超时时间，当从这个socket上读取数据时会立刻超时 if (queueTime &gt;= keepAliveTimeout) &#123; firstReadTimeout = 1; &#125; else &#123; // 如果排队时间还没有超过keepAliveTimeout，那么第一次从socket中读取数据的超时时间就是所剩下的时间了 firstReadTimeout = keepAliveTimeout - (int) queueTime; &#125; &#125; // 设置socket的超时时间，然后开始读数据，该时间就是每次读取数据的超时时间 socketWrapper.getSocket().setSoTimeout(firstReadTimeout); // 会从inputStream中获取数据,会阻塞，如果在firstReadTimeout的时间内没有读到数据则抛Eof异常 , 数据会被读到buf中 if (!inputBuffer.fill()) &#123; // eof是End Of File的意思 throw new EOFException(sm.getString(\"iib.eof.error\")); &#125; // 当第一次读取数据完成后，设置socket的超时时间为原本的超时时间 if (endpoint.getSoTimeout()&gt; 0) &#123; setSocketTimeout(endpoint.getSoTimeout()); &#125; else &#123; setSocketTimeout(0); &#125; // 这里的场景有点像工作，我现在要做一个任务，规定是5天内要完成，但是其中由于客观原因有1天不能工作，所以那一天不算在5天之内，而客观原因解决之后，以后每次做任务就仍然按5天来限制 // 任务的就是read，5天就是timeout，客观原因就是tomcat的调度 &#125;&#125; 以下方法是Tomcat从操作系统RecvBuf中读取数据的关键代码，这里的pos和lastValid非常关键： 12345678910111213141516171819202122232425262728293031323334protected boolean fill() throws IOException &#123; return fill(true);&#125;@Overrideprotected boolean fill(boolean block) throws IOException &#123; int nRead = 0; if (parsingHeader) &#123; // 如果还在解析请求头，lastValid表示当前解析数据的下标位置，如果该位置等于buf的长度了，表示请求头的数据超过buf了。 if (lastValid == buf.length) &#123; throw new IllegalArgumentException(sm.getString(\"iib.requestheadertoolarge.error\")); &#125; // 从inputStream中读取数据，len表示要读取的数据长度，pos表示把从inputStream读到的数据放在buf的pos位置 // nRead表示真实读取到的数据 nRead = inputStream.read(buf, pos, buf.length - lastValid); if (nRead &gt; 0) &#123; lastValid = pos + nRead; // 移动lastValid &#125; &#125; else &#123; // 当读取请求体的数据时 // buf.length - end表示还能存放多少请求体数据，如果小于4500，那么就新生成一个byte数组，这个新的数组专门用来盛放请求体 if (buf.length - end &lt; 4500) &#123; buf = new byte[buf.length]; end = 0; &#125; pos = end; lastValid = pos; nRead = inputStream.read(buf, pos, buf.length - lastValid); if (nRead &gt; 0) &#123; lastValid = pos + nRead; &#125; &#125; return (nRead &gt; 0);&#125; 若使用长连接，就会存在多个HTTP请求共用一个Socket连接，Tomcat在获取并解析Socket连接中的字节流时，如何判断一个HTTP请求结束： 设置Content-Length：在发送请求时直接设置请求体长度，Tomcat在解析请求时就知道在哪里结束了 设置Transfer-Encoding为chunk：分块传输，发送请求按如下格式传输请求体：[chunk size][\\r\\n][chunk data][\\r\\n][chunk size][\\r\\n][chunk data][\\r\\n][chunk size = 0][\\r\\n][\\r\\n]，最后的chunk size = 0和两个回车换行符表示接收到最后一块，表示请求体结束 请求体解析原理普通的Servlet获取用户请求体中的内容： 12345678public class ElevenServlet extends HttpServlet &#123; protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; ServletInputStream inputStream = req.getInputStream(); byte[] bytes = new byte[20]; inputStream.read(bytes); System.out.println(new String(bytes)); &#125;&#125; 在Tomcat中HttpServletRequest的getInputStream方法的是调用的Tomcat底层自己的Request的门面模式RequestFacade RequestFacade是调用的Tomcat自身connector包下的Request： 12345678910111213141516171819202122232425262728293031public class RequestFacade implements HttpServletRequest &#123; protected Request request = null; @Override public ServletInputStream getInputStream() throws IOException &#123; if (request == null) &#123; throw new IllegalStateException(sm.getString(\"requestFacade.nullRequest\")); &#125; return request.getInputStream(); &#125;&#125;public class Request implements HttpServletRequest &#123; @Override public ServletInputStream getInputStream() throws IOException &#123; if (usingReader) &#123; throw new IllegalStateException(sm.getString(\"coyoteRequest.getInputStream.ise\")); &#125; usingInputStream = true; if (inputStream == null) &#123; inputStream = new CoyoteInputStream(inputBuffer); &#125; return inputStream; &#125;&#125;public class CoyoteInputStream extends ServletInputStream &#123; protected InputBuffer ib; protected CoyoteInputStream(InputBuffer ib) &#123; this.ib = ib; &#125;&#125; 所以用户程序中的req.getInputStream().read(bytes)方法最终调用的是InputBuffer的read方法： 12345678private final ByteChunk bb;public int read(byte[] b, int off, int len) throws IOException &#123; if (closed) &#123; throw new IOException(sm.getString(\"inputBuffer.streamClosed\")); &#125; // 从bb中截取一部分数据到b中 return bb.substract(b, off, len);&#125; 调用ByteChunk中的substract方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public int substract(byte dest[], int off, int len) throws IOException &#123; // 这里会对当前ByteChunk初始化 if (checkEof()) &#123; return -1; &#125; int n = len; // 如果需要的数据超过buff中标记的数据长度 if (len &gt; getLength()) &#123; n = getLength(); &#125; // 将buff数组中从start位置开始的数据，复制到dest中，长度为n，desc数组中就有值了 System.arraycopy(buff, start, dest, off, n); start += n; return n;&#125;private boolean checkEof() throws IOException &#123; if ((end - start) == 0) &#123; // 如果bytechunk没有标记数据了，则开始比较 if (in == null) &#123; return true; &#125; // 从in中读取buff长度大小的数据，读到buff中，真实读到的数据为n int n = in.realReadBytes(buff, 0, buff.length); if (n &lt; 0) &#123; return true; &#125; &#125; return false;&#125;public int realReadBytes(byte cbuf[], int off, int len) throws IOException &#123; if (closed) &#123; return -1; &#125; if (coyoteRequest == null) &#123; return -1; &#125; if(state == INITIAL_STATE) &#123; state = BYTE_STATE; &#125; // 上层缓冲区中没有数据，则从底层取（这里的底层是InputStreamInputBuffer中的buff） int result = coyoteRequest.doRead(bb); return result;&#125; 最终是调用的Tomcat中coyote包下的Request中的doRead方法来将数据读取到用传入的字节数组中： 123456789101112131415161718192021222324public final class Request &#123; private InputBuffer inputBuffer = null; public int doRead(ByteChunk chunk) throws IOException &#123; // 从InputStreamInputBuffer中读取数据，其实是标记，这里首先进入AbstractInputBuffer中的doRead方法 int n = inputBuffer.doRead(chunk, this); if (n &gt; 0) &#123; bytesRead+=n; &#125; return n; &#125;&#125;public int doRead(ByteChunk chunk, Request req) throws IOException &#123; // 如果没有ActiveFilter，则直接从inputStreamInputBuffer中读取 // 如果有ActiveFilter，则调用对应的ActiveFilter读取 // 要么是IdentityInputFilter: 每次读多少不确定，看能从操作系统拿到多少 // 要么是ChunkedInputFilter: 客户端分块发送的，ChunkedInputFilter一次读一块数据 // 要么是VoidInputFilter：直接读不到数据，不管到底有没有请求体 if (lastActiveFilter == -1) return inputStreamInputBuffer.doRead(chunk, req); else return activeFilters[lastActiveFilter].doRead(chunk,req);&#125; 以IdentityInputFilter为例，若当前用户的read(bytes)方法没有将数据读完，下次调用read(bytes)方法时接着继续读取剩余数据，若当前数据读超了，返回给用户的数据还是当前请求的请求体，但是remaining变成了负数，或者用户根本就不来读取数据或者有剩余数据未读取完，若不处理则会影响下一次请求的数据读取： 1234567891011121314151617181920212223242526272829public int doRead(ByteChunk chunk, Request req) throws IOException &#123; // 当servlet中读取请求体时，会进入到这个方法，该方法返回 int result = -1; // contentLength表示请求体的长度，当读取请求体时，只会返回这么长的数据 // remaining初始值为contentLength if (contentLength &gt;= 0) &#123; // 100 // 可能会多次读取请求体，所以记录一下请求体还剩下多少 if (remaining &gt; 0) &#123; // 10 // 这里的buffer是InputSteamInputBuffer，会从操作系统的RecvBuf中读取数据，nRead表示读到了多少了数据 int nRead = buffer.doRead(chunk, req); // 20 // 如果读到的数据超过了剩余部分，那么将chunk的标记缩小，缩小为剩余部分的最后一个位置，多余数据不属于请求体了 if (nRead &gt; remaining) &#123; chunk.setBytes(chunk.getBytes(), chunk.getStart(), (int) remaining); result = (int) remaining; &#125; else &#123; // 如果真实读到的数据小于剩下的 result = nRead; &#125; if (nRead &gt; 0) &#123;// 记录一下还需要读多少数据 // 10 - 20==10 remaining = remaining - nRead; // 如果剩余数据比真实读到的数据小，remaining将为负数 &#125; &#125; else &#123; // 如果没有剩余数据了，返回-1 chunk.recycle(); result = -1; &#125; &#125; return result;&#125; 针对上面的情况，在用户请求处理完后，会调用AbstractHttp11Processor的endRequest进行修正： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public void endRequest() &#123; // Finish the handling of the request if (getErrorState().isIoAllowed()) &#123; try &#123; // 把InputBuffer的pos位置移动到第二个请求开始的位置 getInputBuffer().endRequest(); &#125; catch (IOException e) &#123; setErrorState(ErrorState.CLOSE_NOW, e); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); response.setStatus(500); setErrorState(ErrorState.CLOSE_NOW, t); getLog().error(sm.getString(\"http11processor.request.finish\"), t); &#125; &#125; if (getErrorState().isIoAllowed()) &#123; try &#123; getOutputBuffer().endRequest(); &#125; catch (IOException e) &#123; setErrorState(ErrorState.CLOSE_NOW, e); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); setErrorState(ErrorState.CLOSE_NOW, t); getLog().error(sm.getString(\"http11processor.response.finish\"), t); &#125; &#125;&#125;public void endRequest() throws IOException &#123; if (swallowInput &amp;&amp; (lastActiveFilter != -1)) &#123; int extraBytes = (int) activeFilters[lastActiveFilter].end(); // 多度的数据 pos = pos - extraBytes; // 把pos向前移动 &#125;&#125;public long end() throws IOException &#123; // 本次http请求已经处理完了，做收尾工作，主要处理看请求体是否有剩余数据没有读完，判断剩余数据是否超过了限制 final boolean maxSwallowSizeExceeded = (maxSwallowSize &gt; -1 &amp;&amp; remaining &gt; maxSwallowSize); long swallowed = 0; // 还有剩余数据 while (remaining &gt; 0) &#123; // 从操作系统读取数据 int nread = buffer.doRead(endChunk, null); if (nread &gt; 0 ) &#123; // 如果读到了数据 swallowed += nread; // 更新剩余数据 remaining = remaining - nread; // 如果在遍历剩余数据时，读到的数据超过了maxSwallowSize，则会抛异常，后续逻辑就会把socket关掉 if (maxSwallowSizeExceeded &amp;&amp; swallowed &gt; maxSwallowSize) &#123; // 我们不会提早失败，因此客户端可以去读取响应在连接关闭之前 throw new IOException(sm.getString(\"inputFilter.maxSwallow\")); &#125; &#125; else &#123; // errors are handled higher up. // 如果本来认为还有剩余数据，但是真正去读的时候没有数据了，nread等于-1，索引剩余数据为0 remaining = 0; &#125; &#125; // 读到的真实数据超过了剩余数据，则remaining为负数 return -remaining;&#125;","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Tomcat","slug":"中间件/Tomcat","permalink":"https://yaoyinglong.github.io/categories/中间件/Tomcat/"}]},{"title":"常量池","date":"2021-08-20T16:00:00.000Z","path":"Blog/Java/VM/常量池/","text":"Class常量池与运行时常量池Class常量池可以理解为Class文件中的资源仓库，Class文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池Constant pool，用于存放编译期生成的各种字面量和符号引用。一个class文件的16进制大体结构如下： 对应的含义如下： 一般不会去人工解析这种16进制的字节码文件，一般可以通过javap命令或一些字节码工具生成更可读的JVM字节码指令文件，如下所示，Constant pool即是class常量池信息，常量池中主要存放字面量和符号引用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364Classfile /E:/SourceCode/JVM-Learn/target/classes/com/eleven/icode/jvm/unit/Math.class Last modified 2021-8-21; size 999 bytes MD5 checksum 333e6820383da465bfe69370b8b00ae4 Compiled from \"Math.java\"public class com.eleven.icode.jvm.unit.Math minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #11.#39 // java/lang/Object.\"&lt;init&gt;\":()V #2 = Class #40 // com/eleven/icode/jvm/unit/Math #3 = Methodref #2.#39 // com/eleven/icode/jvm/unit/Math.\"&lt;init&gt;\":()V #4 = Methodref #2.#41 // com/eleven/icode/jvm/unit/Math.compute:()I #5 = Fieldref #42.#43 // java/lang/System.out:Ljava/io/PrintStream; #6 = String #44 // test #7 = Methodref #45.#46 // java/io/PrintStream.println:(Ljava/lang/String;)V #8 = Class #47 // com/eleven/icode/jvm/entity/User #9 = Methodref #8.#39 // com/eleven/icode/jvm/entity/User.\"&lt;init&gt;\":()V #10 = Fieldref #2.#48 // com/eleven/icode/jvm/unit/Math.user:Lcom/eleven/icode/jvm/entity/User; #11 = Class #49 // java/lang/Object #12 = Utf8 initData #13 = Utf8 I #14 = Utf8 ConstantValue #15 = Integer 666 #16 = Utf8 user #17 = Utf8 Lcom/eleven/icode/jvm/entity/User; #18 = Utf8 &lt;init&gt; #19 = Utf8 ()V #20 = Utf8 Code #21 = Utf8 LineNumberTable #22 = Utf8 LocalVariableTable #23 = Utf8 this #24 = Utf8 Lcom/eleven/icode/jvm/unit/Math; #25 = Utf8 compute #26 = Utf8 ()I #27 = Utf8 a #28 = Utf8 b #29 = Utf8 c #30 = Utf8 main #31 = Utf8 ([Ljava/lang/String;)V #32 = Utf8 args #33 = Utf8 [Ljava/lang/String; #34 = Utf8 math #35 = Utf8 MethodParameters #36 = Utf8 &lt;clinit&gt; #37 = Utf8 SourceFile #38 = Utf8 Math.java #39 = NameAndType #18:#19 // \"&lt;init&gt;\":()V #40 = Utf8 com/eleven/icode/jvm/unit/Math #41 = NameAndType #25:#26 // compute:()I #42 = Class #50 // java/lang/System #43 = NameAndType #51:#52 // out:Ljava/io/PrintStream; #44 = Utf8 test #45 = Class #53 // java/io/PrintStream #46 = NameAndType #54:#55 // println:(Ljava/lang/String;)V #47 = Utf8 com/eleven/icode/jvm/entity/User #48 = NameAndType #16:#17 // user:Lcom/eleven/icode/jvm/entity/User; #49 = Utf8 java/lang/Object #50 = Utf8 java/lang/System #51 = Utf8 out #52 = Utf8 Ljava/io/PrintStream; #53 = Utf8 java/io/PrintStream #54 = Utf8 println #55 = Utf8 (Ljava/lang/String;)V 字面量字面量就是指由字母、数字等构成的字符串或者数值常量，字面量只可以右值出现，所谓右值是指等号右边的值，如int a=1这里的a为左值，1为右值即字面量。 符号引用符号引用是编译原理中的概念，是相对于直接引用来说的。主要包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符三类常量；如int a=1中a就是字段名称，就是一种符号引用，还有Math类常量池里#24对应的Lcom/eleven/icode/jvm/unit/Math;就是类的全限定名，main和compute是方法名称，()是一种UTF8格式的描述符，这些都是符号引用； 运行时常量池这些常量池现在是静态信息，只有到运行时被加载到内存后，这些符号才有对应的内存地址信息，这些常量池一旦被装入内存就变成运行时常量池，对应的符号引用在程序加载或运行时会被转变为被加载到内存区域的代码的直接引用，也就是我们说的动态链接，如compute()这个符号引用在运行时会被转变为compute()方法具体代码在内存中的地址，主要通过对象头里的类型指针去转换直接引用。 字符串常量池字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能，JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化为字符串开辟一个字符串常量池，类似于缓存区，创建字符串常量时，首先查询字符串常量池是否存在该字符串，存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中。 直接赋值字符串如String param = &quot;eleven&quot;; 代码中，param指向常量池中的引用，这种方式创建的字符串对象，只会在常量池中，因为&quot;eleven&quot;这个字面量，创建对象param时，JVM会先去常量池中通过equals(key)方法，判断是否有相同的对象若有，则直接返回该对象在常量池中的引用；若没有则会在常量池中创建一个新对象，再返回引用。 new String() 方式如String name = new String(&quot;eleven&quot;);代码中，name指向内存中的对象引用，这种方式会保证字符串常量池和堆中都有这个对象，没有就创建，最后返回堆内存中的对象引用。因为有&quot;eleven&quot;这个字面量，故会先检查字符串常量池中是否存在字符串&quot;eleven&quot;，若不存在，先在字符串常量池里创建一个字符串对象；再去内存中创建一个字符串对象&quot;eleven&quot;；存在的话，就直接去堆内存中创建一个字符串对象&quot;eleven&quot;；最后将内存中的引用返回。 intern方法123String s1 = new String(\"zhuge\");String s2 = s1.intern();System.out.println(s1 == s2); //false String中的intern方法是一个native方法，当调用intern方法时，用equals(oject)方法确定字符串常量池是否已经包含一个等于此String对象的字符串，若有则返回池中的字符串，否则将intern返回的引用指向当前字符串s1，jdk1.6需要将s1复制到字符串常量池里。 字符串常量池位置Jdk1.6及之前：有永久代，运行时常量池在永久代，运行时常量池包含字符串常量池Jdk1.7：有永久代，但已经逐步去永久代，字符串常量池从永久代里的运行时常量池分离到堆里Jdk1.8及之后： 无永久代，运行时常量池在元空间，字符串常量池里依然在堆里 12345678910111213/** * jdk6：-Xms6M -Xmx6M -XX:PermSize=6M -XX:MaxPermSize=6M * jdk8：-Xms6M -Xmx6M -XX:MetaspaceSize=6M -XX:MaxMetaspaceSize=6M */public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 100000000; i++) &#123; String str = String.valueOf(i).intern(); list.add(str); &#125; &#125;&#125; 运行结果： 1234jdk7及以上:Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap spacejdk6:Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space 字符串常量池设计原理字符串常量池底层是hotspot的C++实现的，底层类似一个HashTable，保存的本质上是字符串对象的引用。如下代码创建了多少个对象： 123String s1 = new String(\"he\") + new String(\"llo\");String s2 = s1.intern();System.out.println(s1 == s2); 在JDK 1.6下输出是false，创建了 6 个对象，在JDK 1.7及以上的版本输出是true，创建了 5 个对象，这里没有考虑GC，但这些对象确实存在或存在过。产生这种变化的原因主要是，字符串常量池从永久代中脱离移入堆区的原因，intern()方法也相应发生了变化： 在JDK 1.6中，调用intern()首先会在字符串池中寻找 equal() 相等的字符串，若字符串存在则返回该字符串在字符串常量池中的引用；若字符串不存在，虚拟机会重新在永久代上创建一个实例，将StringTable的一个表项指向这个新创建的实例。 JDK 1.7及以上版本中，由于字符串常量池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象。字符串存在时和JDK 1.6一样，字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例。 实例分析123456String s0 = \"eleven\";String s1 = new String(\"eleven\");String s2 = \"ele\" + new String(\"ven\");System.out.println( s0==s1 ); // falseSystem.out.println( s0==s2 ); // falseSystem.out.println( s1==s2 ); // false 用new String()创建的字符串不是常量，不能在编译期就确定，故new String()创建的字符串不放入常量池中，它们有自己的地址空间。s0还是常量池中”eleven”的引用，s1因为无法在编译期确定，所以是运行时创建的新对象”eleven”的引用，s2因为有后半部分new String(”ven”)故也无法在编译期确定，故也是一个新创建对象”eleven”的引用; 123456789101112131415161718192021222324String a = \"a1\";String b = \"a\" + 1;System.out.println(a == b); // trueString a = \"atrue\";String b = \"a\" + \"true\";System.out.println(a == b); // trueString a = \"a3.4\";String b = \"a\" + 3.4;System.out.println(a == b); // trueString a = \"ab\";String bb = \"b\";String b = \"a\" + bb;System.out.println(a == b); // falseString a = \"ab\";final String bb = getBB();String b = \"a\" + bb;System.out.println(a == b); // falseprivate static String getBB() &#123; return \"b\";&#125; JVM对于字符串常量的+号连接，将在程序编译期，JVM就将常量字符串的+连接优化为连接后的值，拿&quot;a&quot; +1来说，经编译器优化后在class中就已经是a1。 JVM对于字符串引用，由于在字符串的+连接中，有字符串引用存在，而引用的值在程序编译期是无法确定的，即&quot;a&quot; + bb无法被编译器优化，只有在程序运行期来动态分配并将连接后的新地址赋给b。 JVM对于字符串引用bb，它的值在编译期无法确定，只有在程序运行期调用方法后，将方法的返回值和”a”来动态连接并分配地址为b。 String是不可变的12345String s = \"a\" + \"b\" + \"c\";String a = \"a\";String b = \"b\";String c = \"c\";String s1 = a + b + c; 由上面的例子可知s就等价于String s = &quot;abc&quot;，s1就不一样了，通过观察其JVM指令码发现s1的”+”操作会变成如下操作： 1String s1 = (new StringBuilder()).append(a).append(b).append(c).toString() 字符串常量池中会存在计算机和技术，堆内存中存储的是str引用的对象计算机技术，由于StringBuilder的toString方法返回的是一个new String()对象，该对象才是真正返回的对象引用，没有出现计算机技术字面量，在常量池中不会生成计算机技术对象，故str.intern()返回的也是对象在堆中的引用。 12String str = new StringBuilder(\"计算机\").append(\"技术\").toString();System.out.println(str == str.intern()); // true 下面的例子和上面的类似，但唯一区别在于java是关键字，在JVM初始化相关类里肯定早就放入字符串常量池中，故str.intern()返回的是常量池中对象。 12String str = new StringBuilder(\"ja\").append(\"va\").toString();System.out.println(str == str.intern()); // false 下面的例子和上面的类似，但唯一区别在于这里的test是字面量，故会在常量池中创建该对象，故str.intern()返回的是常量池中对象。 12String str = new String(\"test\");System.out.println(str == str.intern()); // false 八种基本类型的包装类和对象池java中基本类型的包装类的大部分在堆上都实现了对象池技术，这些类是Byte,Short,Integer,Long,Character,Boolean,另外两种浮点数类型的包装类则没有实现。另外Byte,Short,Integer,Long,Character这5种整型的包装类也只是在对应值大于等于-128小于等于127时才可使用对象池，也即对象不负责创建和管理大于127的这些类的对象。因为一般这种比较小的数用到的概率相对较大 12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) &#123; //5种整形的包装类Byte,Short,Integer,Long,Character的对象， //在值小于127时可以使用对象池 Integer i1 = 127; //这种调用底层实际是执行的Integer.valueOf(127)，里面用到了IntegerCache对象池 Integer i2 = 127; System.out.println(i1 == i2);//输出true //值大于127时，不会从对象池中取对象 Integer i3 = 128; Integer i4 = 128; System.out.println(i3 == i4);//输出false //用new关键词新生成对象不会使用对象池 Integer i5 = new Integer(127); Integer i6 = new Integer(127); System.out.println(i5 == i6);//输出false //Boolean类也实现了对象池技术 Boolean bool1 = true; Boolean bool2 = true; System.out.println(bool1 == bool2);//输出true //浮点类型的包装类没有实现对象池技术 Double d1 = 1.0; Double d2 = 1.0; System.out.println(d1 == d2);//输出false &#125;&#125; 如一下源码所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private static class LongCache &#123; private LongCache()&#123;&#125; static final Long cache[] = new Long[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Long(i - 128); &#125;&#125;public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125;private static class ByteCache &#123; private ByteCache()&#123;&#125; static final Byte cache[] = new Byte[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Byte((byte)(i - 128)); &#125;&#125;private static class ShortCache &#123; private ShortCache()&#123;&#125; static final Short cache[] = new Short[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Short((short)(i - 128)); &#125;&#125;private static class CharacterCache &#123; private CharacterCache()&#123;&#125; static final Character cache[] = new Character[127 + 1]; static &#123; for (int i = 0; i &lt; cache.length; i++) cache[i] = new Character((char)i); &#125;&#125;","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"JVM调优工具","date":"2021-08-20T16:00:00.000Z","path":"Blog/Java/JVM调优工具/","text":"JVM参数汇总查看命令java -XX:+PrintFlagsInitial：打印出所有参数选项的默认值java -XX:+PrintFlagsFinal：打印出所有参数选项在运行程序时生效的值 jpsjps的作用是显示当前系统的java进程情况及进程id 123jps25712 Jps25900 Launcher 123456# 输出传递给main方法的参数jps -m# 输出应用程序main class的完整package名或者应用程序的jar文件完整路径名jps -l# 输出传递给JVM的参数jps -v jmap用来查看内存信息，实例个数以及占用内存大小 12# 查看内存占用排名前20的对象jmap -histo PID | head -20 存活实例统计：jmap -histo 23960 &gt; ./log.txt num：序号 instances：实例数量 bytes：占用空间大小 class name：类名称 堆内存统计：jmap -heap 2650012345678910111213141516171819202122232425262728293031323334353637383940414243444546Attaching to process ID 26500, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11using thread-local object allocation.Parallel GC with 6 thread(s)Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 4273995776 (4076.0MB) NewSize = 89128960 (85.0MB) MaxNewSize = 1424490496 (1358.5MB) OldSize = 179306496 (171.0MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 96993280 (92.5MB) used = 14883328 (14.19384765625MB) free = 82109952 (78.30615234375MB) 15.34470016891892% usedFrom Space: capacity = 11010048 (10.5MB) used = 10977376 (10.468841552734375MB) free = 32672 (0.031158447265625MB) 99.70325288318452% usedTo Space: capacity = 11010048 (10.5MB) used = 0 (0.0MB) free = 11010048 (10.5MB) 0.0% usedPS Old Generation capacity = 111149056 (106.0MB) used = 13376792 (12.757102966308594MB) free = 97772264 (93.2428970336914MB) 12.035002798404333% used15634 interned Strings occupying 2076984 bytes. 堆内存dump：jmap -dump:format=b,file=test.hprof 2650012Dumping heap to C:\\Users\\90627\\Desktop\\test.hprof ...Heap dump file created 也可以通过-XX:+HeapDumpOnOutOfMemoryError 和-XX:HeapDumpPath=./test 参数设置内存溢出自动导出dump文件，内存很大的时候，可能会导不出来，可以将导出的dump文件导入到jvisualvm 进行查看。 1234567891011121314/** * -Xms10M -Xmx10M -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=D:\\jvm.dump */public class OOMTest &#123; public static void main(String[] args) &#123; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); int i = 0; int j = 0; while (true) &#123; list.add(new User(i++, UUID.randomUUID().toString())); new User(j--, UUID.randomUUID().toString()); &#125; &#125;&#125; jstack用jstack加进程id查找死锁。如下是死锁示例代码： 12345678910111213141516171819202122232425262728293031323334public class DeadLockTest &#123; private static Object lock1 = new Object(); private static Object lock2 = new Object(); public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (lock1) &#123; System.out.println(Thread.currentThread().getName() + \" begin\"); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (lock2) &#123; System.out.println(Thread.currentThread().getName() + \" end\"); &#125; &#125; &#125;, \"thread1\").start(); new Thread(() -&gt; &#123; synchronized (lock2) &#123; System.out.println(Thread.currentThread().getName() + \" begin\"); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (lock1) &#123; System.out.println(Thread.currentThread().getName() + \" end\"); &#125; &#125; &#125;, \"thread2\").start(); &#125;&#125; 执行后具体日志如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445jstack 137282021-08-19 21:39:46Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.171-b11 mixed mode):\"thread2\" #12 prio=5 os_prio=0 tid=0x000000001f35d000 nid=0x665c waiting for monitor entry [0x000000001fb9f000] java.lang.Thread.State: BLOCKED (on object monitor) at com.eleven.icode.jvm.DeadLockTest.lambda$main$1(DeadLockTest.java:34) - waiting to lock &lt;0x000000076b3a5530&gt; (a java.lang.Object) - locked &lt;0x000000076b3a5540&gt; (a java.lang.Object) at com.eleven.icode.jvm.DeadLockTest$$Lambda$2/2121055098.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)\"thread1\" #11 prio=5 os_prio=0 tid=0x000000001f33f800 nid=0x2cf0 waiting for monitor entry [0x000000001fa9f000] java.lang.Thread.State: BLOCKED (on object monitor) at com.eleven.icode.jvm.DeadLockTest.lambda$main$0(DeadLockTest.java:20) - waiting to lock &lt;0x000000076b3a5540&gt; (a java.lang.Object) - locked &lt;0x000000076b3a5530&gt; (a java.lang.Object) at com.eleven.icode.jvm.DeadLockTest$$Lambda$1/1225358173.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)Found one Java-level deadlock:=============================\"thread2\": waiting to lock monitor 0x000000001cb8ec78 (object 0x000000076b3a5530, a java.lang.Object), which is held by \"thread1\"\"thread1\": waiting to lock monitor 0x000000001cb91508 (object 0x000000076b3a5540, a java.lang.Object), which is held by \"thread2\"Java stack information for the threads listed above:===================================================\"thread2\": at com.eleven.icode.jvm.DeadLockTest.lambda$main$1(DeadLockTest.java:34) - waiting to lock &lt;0x000000076b3a5530&gt; (a java.lang.Object) - locked &lt;0x000000076b3a5540&gt; (a java.lang.Object) at com.eleven.icode.jvm.DeadLockTest$$Lambda$2/2121055098.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)\"thread1\": at com.eleven.icode.jvm.DeadLockTest.lambda$main$0(DeadLockTest.java:20) - waiting to lock &lt;0x000000076b3a5540&gt; (a java.lang.Object) - locked &lt;0x000000076b3a5530&gt; (a java.lang.Object) at com.eleven.icode.jvm.DeadLockTest$$Lambda$1/1225358173.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 还可以用jvisualvm自动检测死锁： 启动JAR的JMX端口配置1java -Dcom.sun.management.jmxremote.port=8888 -Djava.rmi.server.hostname=192.168.0.103 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar ElevenJvmApplication.jar Tomcat的JMX配置在catalina.sh文件里最后一个JAVA_OPTS赋值语句下一行增加如下配置行： 1JAVA_OPTS=\"$JAVA_OPTS -Dcom.sun.management.jmxremote.port=8888 -Djava.rmi.server.hostname=192.168.50.60 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false\" jstack找出占用CPU最高的线程堆栈信息123456789101112131415161718public class CpuHighTest &#123; public static final int initData = 666; public static User user = new User(); public int compute() &#123; int a = 1; int b = 2; int c = (a + b) * 10; return c; &#125; public static void main(String[] args) &#123; CpuHighTest test = new CpuHighTest(); while (true) &#123; test.compute(); &#125; &#125;&#125; 首先使用命令top -p &lt;pid&gt; ，显示进程的CPU使用情况 按大写的H，获取每个线程的内存情况 找到内存和cpu占用最高的线程tid，将线程id的十进制转为十六进制得到0x4cd0，执行jstack 19663|grep -A 10 4cd0，得到线程堆栈信息中4cd0这个线程所在行的后面10行，从堆栈中可以发现导致cpu飙高的调用方法，从而查看对应的堆栈信息找出可能存在问题的代码。 jinfo通过jinfo -flags PID查看正在运行的Java应用程序的扩展参数： 123456Attaching to process ID 15184, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11Non-default VM flags: -XX:CICompilerCount=3 -XX:InitialHeapSize=268435456 -XX:+ManagementServer -XX:MaxHeapSize=4273995776 -XX:MaxNewSize=1424490496 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=89128960 -XX:OldSize=179306496 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGCCommand line: -Dcom.sun.management.jmxremote.port=8888 -Djava.rmi.server.hostname=192.168.0.103 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false 通过jinfo -sysprops PID查看java系统参数: 123456789101112131415161718192021222324252627Attaching to process ID 15184, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11com.sun.management.jmxremote.authenticate = falsejava.runtime.name = Java(TM) SE Runtime Environmentjava.vm.version = 25.171-b11sun.boot.library.path = C:\\Program Files\\Java\\jdk1.8.0_171\\jre\\binjava.protocol.handler.pkgs = org.springframework.boot.loaderjava.vendor.url = http://java.oracle.com/java.vm.vendor = Oracle Corporationpath.separator = ;java.rmi.server.randomIDs = truefile.encoding.pkg = sun.iojava.vm.name = Java HotSpot(TM) 64-Bit Server VMsun.os.patch.level =sun.java.launcher = SUN_STANDARDuser.script =user.country = CNuser.dir = D:\\tmpjava.vm.specification.name = Java Virtual Machine Specificationcom.sun.management.jmxremote.port = 8888PID = 15184java.runtime.version = 1.8.0_171-b11java.awt.graphicsenv = sun.awt.Win32GraphicsEnvironmentos.arch = amd64java.endorsed.dirs = C:\\Program Files\\Java\\jdk1.8.0_171\\jre\\lib\\endorsed jstatjstat [-命令选项] [vmid] [间隔时间(毫秒)] [查询次数] 查看堆内存各部分的使用量，以及加载类的数量 12# 1s执行一次，总共执行100次，用于查看垃圾收集YGC FGC的次数变化jstat -gcutil PID 1000 100 jstat -gc 15184 12 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 9728.0 12288.0 0.0 0.0 134656.0 32979.9 186880.0 15970.6 35496.0 33974.9 4656.0 4355.1 6 0.027 2 0.079 0.105 S0C：Survivor0区大小，单位KBS1C：Survivor1区的大小S0U：Survivor0区的使用大小S1U：Survivor1区的使用大小EC：Eden区的大小EU：Eden区的使用大小OC：老年代大小OU：老年代使用大小MC：方法区大小(元空间)MU：方法区使用大小CCSC：压缩类空间大小CCSU：压缩类空间使用大小YGC：年轻代垃圾回收次数YGCT：年轻代垃圾回收消耗时间，单位sFGC：老年代垃圾回收次数FGCT：老年代垃圾回收消耗时间，单位sGCT：垃圾回收消耗总时间，单位s 堆内存统计jstat -gccapacity 15184 12NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC87040.0 1391104.0 201216.0 9728.0 12288.0 134656.0 175104.0 2782720.0 186880.0 186880.0 0.0 1081344.0 35496.0 0.0 1048576.0 4656.0 6 2 NGCMN：新生代最小容量NGCMX：新生代最大容量NGC：当前新生代容量S0C：Survivor0区大小S1C：Survivor1区的大小EC：Eden区的大小OGCMN：老年代最小容量OGCMX：老年代最大容量OGC：当前老年代大小OC：当前老年代大小MCMN：最小元数据容量MCMX：最大元数据容量MC：当前元数据空间大小CCSMN：最小压缩类空间大小CCSMX：最大压缩类空间大小CCSC：当前压缩类空间大小YGC：年轻代GC次数FGC：老年代GC次数 新生带垃圾回收统计jstat -gcnew 15184 12 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT9728.0 12288.0 0.0 0.0 7 15 12288.0 134656.0 33428.7 6 0.027 S0C：Survivor0区的大小S1C：Survivor1区的大小S0U：Survivor0区的使用大小S1U：Survivor1区的使用大小TT：对象在新生代存活的次数MTT：对象在新生代存活的最大次数DSS：期望的幸存区大小EC：伊甸园区的大小EU：伊甸园区的使用大小YGC：年轻代垃圾回收次数YGCT：年轻代垃圾回收消耗时间 新生代内存统计jstat -gcnewcapacity 15184 12 NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC87040.0 1391104.0 201216.0 463360.0 9728.0 463360.0 12288.0 1390080.0 134656.0 6 2 NGCMN：新生代最小容量NGCMX：新生代最大容量NGC：当前新生代容量S0CMX：最大Survivor0区大小S0C：当前Survivor0区大小S1CMX：最大Survivor1区大小S1C：当前Survivor1区大小ECMX：最大伊甸园区大小EC：当前伊甸园区大小YGC：年轻代垃圾回收次数FGC：老年代回收次数 老年代垃圾回收统计jstat -gcold 15184 12 MC MU CCSC CCSU OC OU YGC FGC FGCT GCT35496.0 33974.9 4656.0 4355.1 186880.0 15970.6 6 2 0.079 0.105 MC：方法区大小MU：方法区使用大小CCSC:压缩类空间大小CCSU:压缩类空间使用大小OC：老年代大小OU：老年代使用大小YGC：年轻代垃圾回收次数FGC：老年代垃圾回收次数FGCT：老年代垃圾回收消耗时间GCT：垃圾回收消耗总时间 老年代内存统计jstat -gcoldcapacity 15184 12 OGCMN OGCMX OGC OC YGC FGC FGCT GCT175104.0 2782720.0 186880.0 186880.0 6 2 0.079 0.105 OGCMN：老年代最小容量OGCMX：老年代最大容量OGC：当前老年代大小OC：老年代大小YGC：年轻代垃圾回收次数FGC：老年代垃圾回收次数FGCT：老年代垃圾回收消耗时间GCT：垃圾回收消耗总时间 元数据空间统计jstat -gcmetacapacity 15184 12MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC FGCT GCT0.0 1081344.0 35496.0 0.0 1048576.0 4656.0 6 2 0.079 0.105 MCMN:最小元数据容量MCMX：最大元数据容量MC：当前元数据空间大小CCSMN：最小压缩类空间大小CCSMX：最大压缩类空间大小CCSC：当前压缩类空间大小YGC：年轻代垃圾回收次数FGC：老年代垃圾回收次数FGCT：老年代垃圾回收消耗时间GCT：垃圾回收消耗总时间 ArthasArthas是 Alibaba 在 2018 年 9 月开源的 Java 诊断工具。支持 JDK6+， 采用命令行交互模式，可以方便的定位和诊断线上程序运行问题，用java -jar运行即可，可以识别机器上所有Java进程。 这里专门准备了一个Arthas测试程序： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class Arthas &#123; private static HashSet hashSet = new HashSet(); public static void main(String[] args) &#123; // 模拟CPU过高 cpuHigh(); // 模拟线程死锁 deadThread(); // 不断向hashSet集合增加数据 addHashSetThread(); &#125; private static void addHashSetThread() &#123; new Thread(() -&gt; &#123; try &#123; int count = 0; while (true) &#123; hashSet.add(\"count\" + count); Thread.sleep(1000); count++; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; private static void deadThread() &#123; Object lock1 = new Object(); Object lock2 = new Object(); new Thread(() -&gt; &#123; synchronized (lock1) &#123; System.out.println(Thread.currentThread().getName() + \" begin\"); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (lock2) &#123; System.out.println(Thread.currentThread().getName() + \" end\"); &#125; &#125; &#125;, \"thread1\").start(); new Thread(() -&gt; &#123; synchronized (lock2) &#123; System.out.println(Thread.currentThread().getName() + \" begin\"); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (lock1) &#123; System.out.println(Thread.currentThread().getName() + \" end\"); &#125; &#125; &#125;, \"thread2\").start(); &#125; private static void cpuHigh() &#123; new Thread(() -&gt; &#123; while (true) &#123; &#125; &#125;).start(); &#125;&#125; 首先通过java -jar arthas-boot.jar启动arthas然后选择我们的对应的进程： 12wget https://arthas.gitee.io/arthas-boot.jarjava -jar arthas-boot.jar dashboarddashboard可以查看整个进程的运行情况，线程、内存、GC、运行环境信息： thread可以查看线程详情： thread加上线程ID，可以查看线程堆栈： thread -b可以查看线程死锁： 123456# 最繁忙的3个线程，即占用cpu最多的前3个，输出栈信息thread -n 3# 列出1000ms内最忙的3个线程栈thread -n 3 -i 1000 # 查看指定状态的线程thread --state WAITING jad加类的全名可以反编译，这样可以方便我们查看线上代码是否是正确的版本： ognl命令可以查看线上系统变量的值，甚至可以修改变量的值：","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"}]},{"title":"JVM调优思路","date":"2021-08-18T16:00:00.000Z","path":"Blog/Java/JVM调优思路/","text":"用jstat -gc PID命令可以计算出一些关键数据，有了这些数据就可以采用一些优化思路，先给系统设置一些初始性的JVM参数，比如堆内存大小，年轻代大小，Eden和Survivor比例，老年代大小，大对象的阈值，大龄对象进入老年代的阈值等。 优化思路其实简单来说就是尽量让每次Young GC后存活的对象小于Survivor区域的50%，都留存在年轻代里，尽量别让对象进入老年代。尽量减少Full GC的频率，避免频繁Full GC对JVM性能的影响。 JVM参数汇总查看命令java -XX:+PrintFlagsInitial：打印出所有参数选项的默认值java -XX:+PrintFlagsFinal：打印出所有参数选项在运行程序时生效的值 对象进入老年代的触发条件 Eden区没有足够空间进行分配，进行一次Minor GC，若survivor空间不足以放下剩余存活对象，则把新生代的对象提前转移到老年代中去，若老年代空间不足，则触发Full GC 设置了大对象进入老年代的阈值，若对象超过设置大小会直接进入老年代，-XX:PretenureSizeThreshold单位字节，只在Serial和ParNew两个收集器下有效 对象动态年龄判断，一批对象的总大小大于这块Survivor区域内存大小的50%，可以通过-XX:TargetSurvivorRatio参数指定，则此时大于等于这批对象年龄最大值的对象，直接进入老年代。对象动态年龄判断机制一般是在minor gc之后触发。 老年代空间分配担保机制，年轻代每次minor gc之前JVM都会计算老年代剩余可用空间，若可用空间小于年轻代里现有的所有对象大小之和，包括垃圾对象，就会检查-XX:-HandlePromotionFailure参数是否设置，jdk1.8默认设置，若已设置则检查老年代可用内存大小，判断是否大于之前每一次minor gc后进入老年代的对象的平均大小。若小于或参数未设置，则触发一次Full gc，若回收完还是没有足够空间存放新的对象则发生OOM，若minor gc之后剩余存活的需要挪动到老年代的对象大小还是大于老年代可用空间，也会触发full gc，full gc完之后如果还是没有空间放minor gc之后的存活对象，则也会发生OOM。 年轻代对象增长的速率通过命令jstat -gc pid 1000 10 每隔1000毫秒执行1次命令，共执行10次，通过观察EU即eden区的使用来估算每秒Eden大概新增多少对象，若系统负载不高，可把频率换成1分钟，甚至10分钟来观察整体情况。一般系统可能有高峰期和日常期，故需要在不同的时间分别估算不同情况下对象增长速率。 Young GC触发频率和每次耗时知道年轻代对象增长速率就能根据Eden区的大小推算出Young GC大概多久触发一次，Young GC平均耗时可以通过YGCT/YGC公式算出来，根据结果大概就能知道系统大概多久会因为Young GC的执行而卡顿多久。 每次Young GC有多少对象存活及进入老年代已经大概知道Young GC的频率，假设是每5分钟一次，则可以执行命令jstat -gc pid 300000 10观察每次结果eden，survivor和老年代使用的变化情况，在每次gc后eden区使用一般会大幅减少，survivor和老年代都有可能增长，这些增长的对象就是每次Young GC后存活的对象，同时还可以看出每次Young GC后进入老年代大概多少对象，从而可以推算出老年代对象增长速率。 Full GC的触发频率和每次耗时知道了老年代对象的增长速率就可以推算出Full GC的触发频率，Full GC每次耗时可以用公式FGCT/FGC计算得出。 Full GC比Minor GC还多的情况 元空间不够导致的多余full gc 显示调用System.gc()造成多余的full gc，这种一般线上尽量通过-­XX:+DisableExplicitGC参数禁用，若加上该J参数，则代码中调用System.gc()没有任何效果 老年代空间分配担保机制 频繁Full GC频繁Full GC但是系统又没有有OOm的可能，根据上面的几种情况可能是触发了对象动态年龄判断机制或者是新生代的对象提前转移到老年代中或者有大量大对象的分配，导致老年代很快被占满从而频繁触发Full GC。 首先考虑的是把年轻代适当调大点，通过jstat -gc pid 300000 10命令查看频繁Full GC的情况是否有所好转，以及查看一下各各区域内存变化情况，从而进一步分析，若有大量对象频繁的被挪动到老年代，这种情况可以借助jmap命令大概看下是什么对象，从而排查具体的代码，若好转则再适当调整年轻代大小即可，若调大了反而情况恶化了，导致full gc的次数比minor gc的次数还多了 首先可以通过jstat -gcmetacapacity 15184 5000 10命令监测元空间内存变化情况，确定是否是元空间不够导致。 开启-­XX:+DisableExplicitGC参数禁用看是否还出现频繁GC 检查是否如下图所示触发了老年代空间分派担保机制： 同时分析下占用cpu较高的线程，一般有大量对象不断产生，对应的方法代码肯定会被频繁调用，占用的cpu必然较高可以用jstack或jvisualvm来定位cpu使用较高的代码。 内存泄露一般电商架构可能会使用多级缓存架构，就是redis加上JVM级缓存，不断往JVM级缓存里面放缓存数据，可能漏考虑了容量问题，结果导致缓存越来越大，一直占用着老年代的很多空间，时间长了就会导致full gc非常频繁，这就是一种内存泄漏，对于一些老旧数据没有及时清理导致一直占用着宝贵的内存资源，时间长了除了导致full gc，还有可能导致OOM。 这种情况完全可以考虑采用一些成熟的JVM级缓存框架来解决，比如ehcache等自带一些LRU数据淘汰算法的框架来作为JVM级的缓存。 实际项目调优对于系统调优可使用Skywalking链路追踪工具，查看请求处理在哪些地方比较慢，从而找到需要优化的点；对于网关Gateway底层是使用的Netty故对CPU性能要求较高，若CPU性能不够可能导致由于网关的原因将系统的TPS拖下一大节，一般网关损耗在10%以内才是正常的；Gateway可调节Netty线程池的大小，可通过-Dreactor.netty.ioWorkerCount=16JVM参数设置工作线程数，默认为逻辑核心数，一般调大意义不是很大。 对于MySQL数据库也是比较吃CPU资源的，可通过Skywalking或通过Prometheus&amp;Grafana中监控的MySQL指标确定是否存在慢查询或MySQL中开启慢查询查找慢查询SQL，对具体的SQL通过explain来分析是否走索引等情况具体进行优化。 123456789101112131415161718192021-- 查看是否开启慢查询show variables like &apos;%slow_query_log%&apos;;-- 开启慢查询set global slow_query_log = 1;-- 查看慢查询阈值show variables like &apos;%long_query_time%&apos;;-- 设置慢查询阈值，默认为1，单位s，设置完成需要重启session才生效set global long_query_time = 0.5;-- 查看慢查询是写文件还是写数据表，默认写文件show variables like &apos;%log_output%&apos;;-- 设置慢查询写数据表set global log_output = &apos;TABLE&apos;;-- 默认OFF关闭，表是是否记录没有使用索引的查询set global log_queries_not_using_indexes = ON;-- 模拟慢查询select sleep(12);-- 查询慢查询数据表select * from mysql.slow_log;# 修改mysql重启后会恢复之前值，要彻底修改需要修改mysql的配置文件并重启set global max_connections=500; # 默认151 需要特别说明的是对于一些离散度小的字段一般不建议建立索引，但若某个字段离散度小但是我们一般只使用其中一个两个值，且可以过滤掉百分之八九十的数据时，也可以建立索引，如delete_status字段，若0表示未删除，1表示删除，若存在大量删除数据，且删除数据基本不用的情况可给delete_status建立索引。 通过Arthas的thread命令查看应用是否有很多占用CPU高且处于等待状态的线程，排查线程等待的原因，是否是应用中配置的数据库连接池连接数不够导致的等。 12345678# Arthas中执行thread -n 3 # 最繁忙的3个线程（占用cpu最多的前3个），输出栈信息thread -b # 输出阻塞的线程栈信息，若响应慢，阻塞状态的线程比较多，需要重点关注# JVM自带调优工具jstat -gcutil PID 1000 1000 # 用jstat看下gc情况jmap -histo PID | head -20 # 若FGC比较频繁可通过jmap查看下对象占用内存的情况jinfo -flags PID # 当前堆内存情况 若内存不大，如4核8G的机器，可用默认的Parallel垃圾收集器，若对停顿时间有一定要求，JDK8版本可使用ParNew+CMS垃圾收集器组合，如下面配置，若是大内存的服务且对单机并发要求非常高，则一般可用G1垃圾收集器. 1-Xms3072M -Xmx3072M -Xmn1536M -Xss1M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:SurvivorRatio=6 -XX:MaxTenuringThreshold=5 -XX:PretenureSizeThreshold=1M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFaction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 大多数时候系统瓶颈往往出现在数据库上，所以优化方案是尽可能的让各种操作被缓存以及其它各种中间件拦截，让尽量少请求的到达MySQL数据库。 在MySQL中尽量不要搞太多表关联的SQL查询，因为不好优化索引，所以建议对于一些多表的操作能用Java做的尽量用Java做，哪怕java实现可能费时间更多点，但是java应用扩容是很方便的，数据库扩容是比较麻烦。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"}]},{"title":"JVM内存参数设置","date":"2021-08-14T16:00:00.000Z","path":"Blog/Java/JVM内存参数设置/","text":"JVM整体结构及内存模型 JVM内存参数设置 Spring Boot程序的JVM参数设置格式(Tomcat启动直接加在bin目录下catalina.sh文件里)： 1java ‐Xms2048M ‐Xmx2048M ‐Xmn1024M ‐Xss512K ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M ‐jar test‐server.jar -XX:MaxMetaspaceSize： 设置元空间最大值，默认是-1，即不限制，或者说只受限于本地内存大小。-XX:MetaspaceSize： 指定元空间触发Full gc初始阈值(元空间无固定初始大小)，以字节为单位，默认是21M，达到该值就会触发full gc进行类型卸载，同时收集器会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，在不超过设置的-XX:MaxMetaspaceSize的值的情况下，适当提高该值。这个跟早期jdk版本的-XX:PermSize参数意思不一样，-XX:PermSize代表永久代的初始容量。‐Xms：初始堆内存-Xmx：最大堆内存-XX:+HeapDumpOnOutofMemoryError：内存异常打印dump-Xmn：新生代内存-Xss：每个栈内存大小，默认为1M-XX:SurvivorRatio=8：新生代内存分配比例(8:1:1) 注：由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生了大小调整，基于这种情况，一般建议在JVM参数中将MetaspaceSize和MaxMetaspaceSize设置成一样的值，并设置得比初始值要大，对于8G物理内存的机器来说，一般我会将这两个值都设置为256M。 StackOverflowError示例12345678910111213141516171819202122/** * JVM设置 * -Xss128k * -Xss默认1M */public class StackOverflowTest &#123; static int count = 0; static void redo() &#123; count++; redo(); &#125; public static void main(String[] args) &#123; try &#123; redo(); &#125; catch (Throwable e) &#123; e.printStackTrace(); System.out.println(count); &#125; &#125;&#125; 运行结果： 123456java.lang.StackOverflowError at com.eleven.icode.jvm.StackOverflowTest.redo(StackOverflowTest.java:15) at com.eleven.icode.jvm.StackOverflowTest.redo(StackOverflowTest.java:15) at com.eleven.icode.jvm.StackOverflowTest.redo(StackOverflowTest.java:15) ……19790 当-Xss设置越小count值越小，说明一个线程栈里能分配的栈帧就越少，但是对JVM整体来说能开启的线程数会更多。 尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"}]},{"title":"字节码指令手册","date":"2021-08-14T16:00:00.000Z","path":"Blog/Java/VM/字节码指令手册/","text":"栈和局部变量操作将常量压入栈的指令aconst_null 将null对象引用压入栈iconst_m1 将int类型常量-1压入栈iconst_0 将int类型常量0压入栈iconst_1 将int类型常量1压入操作数栈iconst_2 将int类型常量2压入栈iconst_3 将int类型常量3压入栈iconst_4 将int类型常量4压入栈iconst_5 将int类型常量5压入栈lconst_0 将long类型常量0压入栈lconst_1 将long类型常量1压入栈fconst_0 将float类型常量0压入栈fconst_1 将float类型常量1压入栈dconst_0 将double类型常量0压入栈dconst_1 将double类型常量1压入栈bipush 将一个8位带符号整数压入栈sipush 将16位带符号整数压入栈ldc 把常量池中的项压入栈ldc_w 把常量池中的项压入栈（使用宽索引）ldc2_w 把常量池中long类型或者double类型的项压入栈（使用宽索引） 从栈中的局部变量中装载值的指令iload 从局部变量中装载int类型值lload 从局部变量中装载long类型值fload 从局部变量中装载float类型值dload 从局部变量中装载double类型值aload 从局部变量中装载引用类型值（refernce）iload_0 从局部变量0中装载int类型值iload_1 从局部变量1中装载int类型值iload_2 从局部变量2中装载int类型值iload_3 从局部变量3中装载int类型值lload_0 从局部变量0中装载long类型值lload_1 从局部变量1中装载long类型值lload_2 从局部变量2中装载long类型值lload_3 从局部变量3中装载long类型值fload_0 从局部变量0中装载float类型值fload_1 从局部变量1中装载float类型值fload_2 从局部变量2中装载float类型值fload_3 从局部变量3中装载float类型值dload_0 从局部变量0中装载double类型值dload_1 从局部变量1中装载double类型值dload_2 从局部变量2中装载double类型值dload_3 从局部变量3中装载double类型值aload_0 从局部变量0中装载引用类型值aload_1 从局部变量1中装载引用类型值aload_2 从局部变量2中装载引用类型值aload_3 从局部变量3中装载引用类型值iaload 从数组中装载int类型值laload 从数组中装载long类型值faload 从数组中装载float类型值daload 从数组中装载double类型值aaload 从数组中装载引用类型值baload 从数组中装载byte类型或boolean类型值caload 从数组中装载char类型值saload 从数组中装载short类型值 将栈中的值存入局部变量的指令istore 将int类型值存入局部变量lstore 将long类型值存入局部变量fstore 将float类型值存入局部变量dstore 将double类型值存入局部变量astore 将将引用类型或returnAddress类型值存入局部变量istore_0 将int类型值存入局部变量0istore_1 将int类型值存入局部变量1istore_2 将int类型值存入局部变量2istore_3 将int类型值存入局部变量3lstore_0 将long类型值存入局部变量0lstore_1 将long类型值存入局部变量1lstore_2 将long类型值存入局部变量2lstore_3 将long类型值存入局部变量3fstore_0 将float类型值存入局部变量0fstore_1 将float类型值存入局部变量1fstore_2 将float类型值存入局部变量2fstore_3 将float类型值存入局部变量3dstore_0 将double类型值存入局部变量0dstore_1 将double类型值存入局部变量1dstore_2 将double类型值存入局部变量2dstore_3 将double类型值存入局部变量3astore_0 将引用类型或returnAddress类型值存入局部变量0astore_1 将引用类型或returnAddress类型值存入局部变量1astore_2 将引用类型或returnAddress类型值存入局部变量2astore_3 将引用类型或returnAddress类型值存入局部变量3iastore 将int类型值存入数组中lastore 将long类型值存入数组中fastore 将float类型值存入数组中dastore 将double类型值存入数组中aastore 将引用类型值存入数组中bastore 将byte类型或者boolean类型值存入数组中castore 将char类型值存入数组中sastore 将short类型值存入数组中 wide指令wide 使用附加字节扩展局部变量索引通用(无类型）栈操作nop 不做任何操作pop 弹出栈顶端一个字长的内容pop2 弹出栈顶端两个字长的内容dup 复制栈顶部一个字长内容dup_x1 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的两个字长的内容压入栈dup_x2 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈dup2 复制栈顶部两个字长内容dup2_x1 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈dup2_x2 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的四个字长的内容压入栈swap 交换栈顶部两个字长内容 类型转换i2l 把int类型的数据转化为long类型i2f 把int类型的数据转化为float类型i2d 把int类型的数据转化为double类型l2i 把long类型的数据转化为int类型l2f 把long类型的数据转化为float类型l2d 把long类型的数据转化为double类型f2i 把float类型的数据转化为int类型f2l 把float类型的数据转化为long类型f2d 把float类型的数据转化为double类型d2i 把double类型的数据转化为int类型d2l 把double类型的数据转化为long类型d2f 把double类型的数据转化为float类型i2b 把int类型的数据转化为byte类型i2c 把int类型的数据转化为char类型i2s 把int类型的数据转化为short类型 整数运算iadd 执行int类型的加法ladd 执行long类型的加法isub 执行int类型的减法lsub 执行long类型的减法imul 执行int类型的乘法lmul 执行long类型的乘法idiv 执行int类型的除法ldiv 执行long类型的除法irem 计算int类型除法的余数lrem 计算long类型除法的余数ineg 对一个int类型值进行取反操作lneg 对一个long类型值进行取反操作iinc 把一个常量值加到一个int类型的局部变量上 逻辑运算移位操作ishl 执行int类型的向左移位操作lshl 执行long类型的向左移位操作ishr 执行int类型的向右移位操作lshr 执行long类型的向右移位操作iushr 执行int类型的向右逻辑移位操作lushr 执行long类型的向右逻辑移位操作 按位布尔运算iand 对int类型值进行“逻辑与”操作land 对long类型值进行“逻辑与”操作ior 对int类型值进行“逻辑或”操作lor 对long类型值进行“逻辑或”操作ixor 对int类型值进行“逻辑异或”操作lxor 对long类型值进行“逻辑异或”操作 浮点运算fadd 执行float类型的加法dadd 执行double类型的加法fsub 执行float类型的减法dsub 执行double类型的减法fmul 执行float类型的乘法dmul 执行double类型的乘法fdiv 执行float类型的除法ddiv 执行double类型的除法frem 计算float类型除法的余数drem 计算double类型除法的余数fneg 将一个float类型的数值取反dneg 将一个double类型的数值取反 对象和数组对象操作指令new 创建一个新对象checkcast 确定对象为所给定的类型getfield 从对象中获取字段putfield 设置对象中字段的值getstatic 从类中获取静态字段putstatic 设置类中静态字段的值instanceof 判断对象是否为给定的类型 数组操作指令newarray 分配数据成员类型为基本上数据类型的新数组anewarray 分配数据成员类型为引用类型的新数组arraylength 获取数组长度multianewarray 分配新的多维数组 控制流条件分支指令ifeq 如果等于0，则跳转ifne 如果不等于0，则跳转iflt 如果小于0，则跳转ifge 如果大于等于0，则跳转ifgt 如果大于0，则跳转ifle 如果小于等于0，则跳转if_icmpcq 如果两个int值相等，则跳转if_icmpne 如果两个int类型值不相等，则跳转if_icmplt 如果一个int类型值小于另外一个int类型值，则跳转if_icmpge 如果一个int类型值大于或者等于另外一个int类型值，则跳转if_icmpgt 如果一个int类型值大于另外一个int类型值，则跳转if_icmple 如果一个int类型值小于或者等于另外一个int类型值，则跳转ifnull 如果等于null，则跳转ifnonnull 如果不等于null，则跳转if_acmpeq 如果两个对象引用相等，则跳转if_acmpnc 如果两个对象引用不相等，则跳转 比较指令lcmp 比较long类型值fcmpl 比较float类型值（当遇到NaN时，返回-1）fcmpg 比较float类型值（当遇到NaN时，返回1）dcmpl 比较double类型值（当遇到NaN时，返回-1）dcmpg 比较double类型值（当遇到NaN时，返回1） 无条件转移指令goto 无条件跳转goto_w 无条件跳转（宽索引） 表跳转指令tableswitch 通过索引访问跳转表，并跳转lookupswitch 通过键值匹配访问跳转表，并执行跳转操作 异常athrow 抛出异常或错误finally 子句jsr 跳转到子例程jsr_w 跳转到子例程（宽索引）rct 从子例程返回 方法调用与返回方法调用指令invokcvirtual 运行时按照对象的类来调用实例方法invokespecial 根据编译时类型来调用实例方法invokestatic 调用类（静态）方法invokcinterface 调用接口方法 方法返回指令ireturn 从方法中返回int类型的数据lreturn 从方法中返回long类型的数据freturn 从方法中返回float类型的数据dreturn 从方法中返回double类型的数据areturn 从方法中返回引用类型的数据return 从方法中返回，返回值为void 线程同步montiorenter 进入并获取对象监视器monitorexit 释放并退出对象监视器 JVM指令助记符变量到操作数栈：iload,iload_,lload,lload_,fload,fload_,dload,dload_,aload,aload_操作数栈到变量：istore,istore_,lstore,lstore_,fstore,fstore_,dstore,dstor_,astore,astore_常数到操作数栈：bipush,sipush,ldc,ldc_w,ldc2_w,aconst_null,iconst_ml,iconst_,lconst_,fconst_,dconst_加：iadd,ladd,fadd,dadd减：isub,lsub,fsub,dsub乘：imul,lmul,fmul,dmul除：idiv,ldiv,fdiv,ddiv余数：irem,lrem,frem,drem取负：ineg,lneg,fneg,dneg移位：ishl,lshr,iushr,lshl,lshr,lushr按位或：ior,lor按位与：iand,land按位异或：ixor,lxor类型转换：i2l,i2f,i2d,l2f,l2d,f2d(放宽数值转换) i2b,i2c,i2s,l2i,f2i,f2l,d2i,d2l,d2f(缩窄数值转换)创建类实便：new创建新数组：newarray,anewarray,multianwarray访问类的域和类实例域：getfield,putfield,getstatic,putstatic把数据装载到操作数栈：baload,caload,saload,iaload,laload,faload,daload,aaload从操作数栈存存储到数组：bastore,castore,sastore,iastore,lastore,fastore,dastore,aastore获取数组长度：arraylength检相类实例或数组属性：instanceof,checkcast操作数栈管理：pop,pop2,dup,dup2,dup_xl,dup2_xl,dup_x2,dup2_x2,swap有条件转移：ifeq,iflt,ifle,ifne,ifgt,ifge,ifnull,ifnonnull,if_icmpeq,if_icmpene,if_icmplt,if_icmpgt,if_icmple,if_icmpge,if_acmpeq,if_acmpne,lcmp,fcmpl,fcmpg,dcmpl,dcmpg复合条件转移：tableswitch,lookupswitch无条件转移：goto,goto_w,jsr,jsr_w,ret调度对象的实便方法：invokevirtual调用由接口实现的方法：invokeinterface调用需要特殊处理的实例方法：invokespecial调用命名类中的静态方法：invokestatic方法返回：ireturn,lreturn,freturn,dreturn,areturn,return异常：athrowfinally关键字的实现使用：jsr,jsr_w,ret","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"状态模式","date":"2021-08-11T16:00:00.000Z","path":"Blog/设计模式/行为型模式/状态模式/","text":"状态模式适用于当某个对象在它的状态发生改变时，其行为也随着发生比较大的变化，在行为受状态约束的情况下可以使用状态模式，而且使用时对象的状态最好不要超过5个 。 定义当一个对象内在状态改变时允许其改变行为，这个对象看起来像改变了其类 实现优点 结构清晰，避免了过多的switch…case或者if…else语句的使用，避免了程序的复杂性,提高系统的可维护性 很好地体现了开闭原则和单一职责原则，每个状态都是一个子类 封装性非常好，状态变换放置到类内部实现，外部调用不用知道类内部如何实现状态和行为的变换 缺点 子类太多导致类膨胀 应用 行为随状态改变而改变的场景 条件、分支判断语句的替代者 扩展","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"状态模式","slug":"状态模式","permalink":"https://yaoyinglong.github.io/tags/状态模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"访问者模式","date":"2021-08-10T16:00:00.000Z","path":"Blog/设计模式/行为型模式/访问者模式/","text":"访问者模式是一种集中规整模式，特别适用于大规模重构的项目，通过访问者模式可以很容易把一些功能进行梳理。还可以与其他模式混编建立一套自己的过滤器或者拦截器。 访问者模式是对迭代器模式的扩充，可以遍历不同的对象，然后执行不同的操作，也就是针对访问的对象不同， 执行不同的操作。 访问者模式还可以充当拦截器Interceptor角色 。 访问者模式能把处理方法从数据结构中分离出来，并可以根据需要增加新的处理方法，且不用修改原来的程序代码与数据结构，这提高了程序的扩展性和灵活性。 定义封装一些作用于某种数据结构中的各元素的操作，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作。 将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离，是行为类模式中最复杂的一种模式。 实现 抽象访问者Visitor：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作visit() ，该操作中的参数类型标识了被访问的具体元素。 1234public interface Visitor &#123; void visit(ConcreteElementA element); void visit(ConcreteElementB element);&#125; 具体访问者角色ConcreteVisitor：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时的具体功能。1234567891011121314151617181920212223public class ConcreteVisitorA implements Visitor &#123; @Override public void visit(ConcreteElementA element) &#123; System.out.println(\"具体访问者A访问--&gt;\" + element.operationA()); &#125; @Override public void visit(ConcreteElementB element) &#123; System.out.println(\"具体访问者A访问--&gt;\" + element.operationB()); &#125;&#125;public class ConcreteVisitorB implements Visitor &#123; @Override public void visit(ConcreteElementA element) &#123; System.out.println(\"具体访问者B访问--&gt;\" + element.operationA()); &#125; @Override public void visit(ConcreteElementB element) &#123; System.out.println(\"具体访问者B访问--&gt;\" + element.operationB()); &#125;&#125; 抽象元素角色Element：声明一个包含接受操作accept()的接口，被接受的访问者对象作为accept()方法的参数。123public interface Element &#123; void accept(Visitor visitor);&#125; 具体元素角色ConcreteElement：实现抽象元素角色提供的 accept() 操作，其方法体通常都是visitor.visit(this)，另外具体元素中可能还包含本身业务逻辑的相关操作。 123456789101112131415161718192021public class ConcreteElementA implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; public String operationA() &#123; return \"具体元素A的操作。\"; &#125;&#125;public class ConcreteElementB implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; public String operationB() &#123; return \"具体元素B的操作。\"; &#125;&#125; 对象结构角色ObjectStructure：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。12345678910111213141516171819202122232425262728public class ObjectStructure &#123; private List&lt;Element&gt; list = new ArrayList&lt;Element&gt;(); public void accept(Visitor visitor) &#123; for (Element element : list) &#123; element.accept(visitor); &#125; &#125; public void add(Element element) &#123; list.add(element); &#125; public void remove(Element element) &#123; list.remove(element); &#125; public static void main(String[] args) &#123; ObjectStructure os = new ObjectStructure(); os.add(new ConcreteElementA()); os.add(new ConcreteElementB()); Visitor visitor = new ConcreteVisitorA(); os.accept(visitor); System.out.println(\"------------------------\"); visitor = new ConcreteVisitorB(); os.accept(visitor); &#125;&#125; 优点 扩展性好：能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。 复用性好：可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度。 灵活性好：访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构。 符合单一职责原则：访问者模式把相关行为封装在一起构成一个访问者，使每个访问者功能都比较单一。 缺点 增加新的元素类很困难：每增加一个新的元素类，都要在每个具体访问者类中增加相应的具体操作，违背开闭原则。 破坏封装：具体元素对访问者公布细节，这破坏了对象的封装性。 违反了依赖倒置原则：访问者模式依赖了具体类，而没有依赖抽象类。 应用 需要对一个对象结构中的对象进行很多不同并且不相关的操作，而你想避免让这些操作污染这些对象的类 数据元素相对稳定而访问方式多种多样的数据结构 对象结构相对稳定，但其操作算法经常变化的程序。 对象结构中的对象需要提供多种不同且不相关的操作，而且要避免让这些操作的变化影响对象的结构。 对象结构包含很多类型的对象，希望对这些对象实施一些依赖于其具体类型的操作。 扩展 统计功能：数据统计和报表的批处理通过访问者模式来处理会比较简单 多个访问者：用于展示的访问者和用于汇总的访问者","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"访问者模式","slug":"访问者模式","permalink":"https://yaoyinglong.github.io/tags/访问者模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"外观模式","date":"2021-08-03T16:00:00.000Z","path":"Blog/设计模式/结构型模式/外观模式/","text":"外观模式也叫门面模式，注重统一的对象，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。 该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。 除了这个接口不允许有任何访问子系统的行为发生，是外界访问子系统内部的唯一通道，是一种比较常用的封装模式。 一般情况下，一个子系统只要一个门面，但若门面已经庞大到不能忍受的程度，可拆分成多个门面；需要子系统可以提供不同访问路径的情况，也可提供多个门面。 门面不参与子系统的业务逻辑，否则会产生倒依赖问题，子系统必须依赖门面才能被访问，违反了单一职责原则，同时也破坏了系统的封装性。 定义要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行，外观模式提供一个高层次的接口，使得子系统更易于使用。 实现 外观角色Facade：为多个子系统对外提供一个共同的接口。 1234567891011public class Facade &#123; private SubSystem01 obj1 = new SubSystem01(); private SubSystem02 obj2 = new SubSystem02(); private SubSystem03 obj3 = new SubSystem03(); public void method() &#123; obj1.method1(); obj2.method2(); obj3.method3(); &#125;&#125; 子系统角色SubSystem：实现系统的部分功能，客户可以通过外观角色访问它。 1234567891011121314151617public class SubSystem01 &#123; public void method1() &#123; System.out.println(\"子系统01的method1()被调用\"); &#125;&#125;public class SubSystem02 &#123; public void method2() &#123; System.out.println(\"子系统02的method2()被调用\"); &#125;&#125;public class SubSystem03 &#123; public void method3() &#123; System.out.println(\"子系统03的method3()被调用\"); &#125;&#125; 客户角色Client：通过一个外观角色访问各个子系统的功能。 1234public static void main(String[] args) &#123; Facade facade = new Facade(); facade.method();&#125; 优点 减少了系统的相互依赖，所有的依赖都是对门面对象的依赖，与子系统无关，降低了子系统与客户端之间的耦合度 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。 提高了灵活性，不管子系统内部如何变化，只要不影响到门面对象，可随意修改 提高了安全性，不在门面上开通的方法不能访问 缺点 不符合开闭原则，增加新的子系统可能需要修改外观类或客户端的源代码 应用场景 为一个复杂的模块或子系统提供一个供外界访问的接口 子系统相对独立，外界对子系统的访问只要黑箱操作即可，如利息计算问题 预防低水平人员带来的风险扩散 对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系 当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。 使用外观模式整合已有的API","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"外观模式","slug":"外观模式","permalink":"https://yaoyinglong.github.io/tags/外观模式/"},{"name":"门面模式","slug":"门面模式","permalink":"https://yaoyinglong.github.io/tags/门面模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/结构型模式/"}]},{"title":"备忘录模式","date":"2021-08-03T16:00:00.000Z","path":"Blog/设计模式/行为型模式/备忘录模式/","text":"备忘录模式又叫快照模式，就是一个对象的备份模式，提供了一种程序数据的备份方法。当后悔时能撤销当前操作，使数据恢复到它原先的状态。 备忘录创建出来就要在“最近”的代码中使用，要主动管理它的生命周期，建立就要使用，不使用就要立刻删除其引用。不要在频繁建立备份的场景中使用备忘录模式。 定义在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态。 实现 发起人角色Originator：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。 123456789101112131415public class Originator &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public Memento createMemento() &#123; return new Memento(state); &#125; public void restoreMemento(Memento m) &#123; this.setState(m.getState()); &#125;&#125; 备忘录角色Memento：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。 123456789101112131415public class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125;&#125; 管理者角色Caretaker：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。 123456789public class Caretaker &#123; private Memento memento; public void setMemento(Memento m) &#123; memento = m; &#125; public Memento getMemento() &#123; return memento; &#125;&#125; 客户端代码： 12345678910111213public class MementoPattern &#123; public static void main(String[] args) &#123; Originator or = new Originator(); Caretaker cr = new Caretaker(); or.setState(\"S0\"); System.out.println(\"初始状态:\" + or.getState()); cr.setMemento(or.createMemento()); //保存状态 or.setState(\"S1\"); System.out.println(\"新的状态:\" + or.getState()); or.restoreMemento(cr.getMemento()); //恢复状态 System.out.println(\"恢复状态:\" + or.getState()); &#125;&#125; 优点 提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态 实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息 发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，符合单一职责原则 缺点 资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源 应用 需要保存和恢复数据的相关状态场景，游戏中的存档功能 提供一个可回滚rollback的操作，如Word、记事本、Photoshop，Eclipse 等软件在编辑时按 Ctrl+Z 组合键，还有数据库中事务操作 需要监控的副本场景中 扩展clone方式的备忘录发起人角色Originator 1234567891011121314151617181920212223class OriginatorPrototype implements Cloneable &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public OriginatorPrototype createMemento() &#123; return this.clone(); &#125; public void restoreMemento(OriginatorPrototype opt) &#123; this.setState(opt.getState()); &#125; public OriginatorPrototype clone() &#123; try &#123; return (OriginatorPrototype) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 管理者角色Caretaker123456789class PrototypeCaretaker &#123; private OriginatorPrototype opt; public void setMemento(OriginatorPrototype opt) &#123; this.opt = opt; &#125; public OriginatorPrototype getMemento() &#123; return opt; &#125;&#125; 客户端代码： 12345678910111213public class Client &#123; public static void main(String[] args) &#123; OriginatorPrototype or = new OriginatorPrototype(); PrototypeCaretaker cr = new PrototypeCaretaker(); or.setState(\"S0\"); System.out.println(\"初始状态:\" + or.getState()); cr.setMemento(or.createMemento()); //保存状态 or.setState(\"S1\"); System.out.println(\"新的状态:\" + or.getState()); or.restoreMemento(cr.getMemento()); //恢复状态 System.out.println(\"恢复状态:\" + or.getState()); &#125;&#125; 多状态的备忘录模式可以通过对备忘录角色Memento角色进行扩展，将存储状态的字段用Map来存储多个状态，从而实现多状态备忘录模式。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"备忘录模式","slug":"备忘录模式","permalink":"https://yaoyinglong.github.io/tags/备忘录模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"观察者模式","date":"2021-06-30T16:00:00.000Z","path":"Blog/设计模式/行为型模式/观察者模式/","text":"实现观察者模式时要注意具体目标对象和具体观察者对象之间不能直接调用，否则将使两者之间紧密耦合起来，这违反了面向对象的设计原则。 定义定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新。 实现 Subject被观察者，定义被观察者的实现职责，必须能够动态的增加、取消观察者，一般是抽象类或者实现类，仅仅完成作为被观察者必须实现的职责：管理观察者并通知观察者。 123456789101112131415161718public abstract class Subject &#123; //定义一个观察者数组 private Vector&lt;Observer&gt; obsVector = new Vector&lt;Observer&gt;(); //增加一个观察者 public void addObserver(Observer o)&#123; this.obsVector.add(o); &#125; //删除一个观察者 public void delObserver(Observer o)&#123; this.obsVector.remove(o); &#125; //通知所有观察者 public void notifyObservers()&#123; for(Observer o:this.obsVector)&#123; o.update(); &#125; &#125;&#125; Observer观察者，观察者接收到消息后，对消息进行处理。 123public interface Observer &#123; void update();&#125; ConcreteSubject具体的被观察者，定义被观察者自己的业务逻辑，同时定义对哪些事件进行通知。 1234567public class ConcreteSubject extends Subject &#123; //具体的业务 public void doSomething()&#123; System.out.println(\"do something\"); super.notifyObservers(); &#125;&#125; ConcreteObserver具体的观察者，每个观察者接收到消息后的处理逻辑是不一样的。 123456public class ConcreteObserver implements Observer &#123; @Override public void update() &#123; System.out.println(\"接收到信息， 并进行处理！ \"); &#125;&#125; 客户端使用 12345678910public static void main(String[] args) &#123; //创建一个被观察者 ConcreteSubject subject = new ConcreteSubject(); //定义一个观察者 Observer obs= new ConcreteObserver(); //观察者观察被观察者 subject.addObserver(obs); //观察者开始活动了 subject.doSomething();&#125; 优点 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则。 目标与观察者之间建立了一套触发机制。形成了一个触发链。 观察者模式可以完美地实现这里的链条形式。 缺点 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。 观察者对象很多时，开发和调试就会比较复杂，通知的发布会花费很多时间，影响程序的效率，且一个观察者卡壳，会影响整体的执行效率；在这种情况下，一般考虑采用异步的方式。 应用在软件系统中，当系统一方行为依赖另一方行为的变动时，可使用观察者模式松耦合联动双方，使得一方的变动可以通知到感兴趣的另一方对象，从而让另一方对象对此做出响应。 对象间存在一对多关系，一个对象的状态发生改变会影响其他对象。 当一个抽象模型有两个方面，其中一个方面依赖于另一方面时，可将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。 实现类似广播机制的功能，不需要知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播。 多层级嵌套使用，形成一种链式触发机制，使得事件具备跨域（跨越两种观察者类型）通知。 注意广播链的问题，一个观察者可以有双重身份，既是观察者，也是被观察者，链一旦建立，逻辑就比较复杂，可维护性非常差，根据经验建议，在一个观察者模式中最多出现一个对象既是观察者也是被观察者，也就是说消息最多转发一次（传递两次），这还是比较好控制的。 它和责任链模式的最大区别就是观察者广播链在传播的过程中消息是随时更改的，它是由相邻的两个节点协商的消息结构；而责任链模式在消息传递过程中基本上保持消息不可变，如果要改变，也只是在原有的消息上进行修正。 异步处理问题，被观察者发生动作，观察者要做出回应，如果观察者比较多，而且处理时间比较长，就用异步处理，异步处理就要考虑线程安全和队列的问题。 扩展Java提供了java.util.Observable类和java.util.Observer接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。 Observable类是抽象目标类，它有一个 Vector 向量，用于保存所有要通知的观察者对象； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Observable &#123; // 内部标志位，注明目标对象发生了变化,为true时，notifyObservers()才会通知观察者 private boolean changed = false; private Vector&lt;Observer&gt; obs; public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; public void notifyObservers() &#123; notifyObservers(null); &#125; public void notifyObservers(Object arg) &#123; Object[] arrLocal; synchronized (this) &#123; if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; Observer接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用void update(Observable o,Object arg)方法，进行相应的工作。 123public interface Observer &#123; void update(Observable o, Object arg);&#125; 利用Observable类和Observer接口实现观察者模式实例 1234567891011121314151617181920212223242526public class ConcreteSubject extends Observable &#123; public void doSomething()&#123; System.out.println(\"do something\"); // 设置内部标志位，注明数据发生变化 super.setChanged(); super.notifyObservers(\"msg\"); &#125;&#125;public class ConcreteObserver implements Observer &#123; @Override public void update(Observable o, Object arg) &#123; System.out.println(\"接收到信息：\" + arg); &#125;&#125;public static void main(String[] args) &#123; //创建一个被观察者 ConcreteSubject subject = new ConcreteSubject(); //定义一个观察者 Observer obs= new ConcreteObserver(); //观察者观察被观察者 subject.addObserver(obs); //观察者开始活动了 subject.doSomething();&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"观察者模式","slug":"观察者模式","permalink":"https://yaoyinglong.github.io/tags/观察者模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"组合模式","date":"2021-06-29T16:00:00.000Z","path":"Blog/设计模式/结构型模式/组合模式/","text":"组合模式也叫合成模式，有时又叫部分整体模式，主要是用来描述部分与整体的关系； 只要是树形结构， 就要考虑使用组合模式， 只要是要体现局部和整体的关系的时候， 而且这种关系还可能比较深， 考虑使用组合模式。 定义将对象组合成树形结构以表示部分—整体的层次结构，使得用户对单个对象和组合对象的使用具有一致性。 实现组合模式一般用来描述整体与部分的关系，它将对象组织到树形结构中，顶层的节点被称为根节点，根节点下面可以包含树枝节点和叶子节点，树枝节点下面又可以包含树枝节点和叶子节点。 组合模式分为透明式的组合模式和安全式的组合模式。 透明式的组合模式中，抽象构件声明了所有子类中的全部方法，所以客户端无须区别树叶对象和树枝对象，对客户端来说是透明的。 缺点是树叶构件本来没有 add()、remove()、getChild() 方法，却要实现它们，空实现或抛异常，会带来一些安全性问题。 Component抽象构件角色，其主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。 123456789public interface Component &#123; void add(Component c); void remove(Component c); Component getChild(int i); void operation();&#125; Leaf树叶构件角色，是组合中的叶节点对象，它没有子节点，用于继承或实现抽象构件。 12345678910111213141516public class Leaf implements Component &#123; private String name; public Leaf(String name) &#123; this.name = name; &#125; public void add(Component c) &#123; &#125; public void remove(Component c) &#123; &#125; public Component getChild(int i) &#123; return null; &#125; public void operation() &#123; System.out.println(\"树叶\" + name + \"：被访问！\"); &#125;&#125; Composite树枝构件角色 / 中间构件，是组合中的分支节点对象，它有子节点，用于继承和实现抽象构件。它的主要作用是存储和管理子部件，通常包含 add()、remove()、getChild() 等方法。 123456789101112131415161718192021public class Composite implements Component &#123; private ArrayList&lt;Component&gt; children = new ArrayList&lt;&gt;(); public void add(Component c) &#123; children.add(c); &#125; public void remove(Component c) &#123; children.remove(c); &#125; public Component getChild(int i) &#123; return children.get(i); &#125; public void operation() &#123; for (Object obj : children) &#123; ((Component) obj).operation(); &#125; &#125;&#125; 客户端使用： 123456789101112public static void main(String[] args) &#123; Component c0 = new Composite(); Component c1 = new Composite(); Component leaf1 = new Leaf(\"1\"); Component leaf2 = new Leaf(\"2\"); Component leaf3 = new Leaf(\"3\"); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation();&#125; 安全式的组合模式中，将管理子构件的方法移到树枝构件中，抽象构件和树叶构件没有对子对象的管理方法，这样就避免了上一种方式的安全性问题，但由于叶子和分支有不同的接口，客户端在调用时要知道树叶对象和树枝对象的存在，所以失去了透明性。 安全式的组合模式与透明式组合模式的实现代码类似，只要对其做简单修改就可以了： 12345678910111213141516public interface Component &#123; void operation();&#125;public static void main(String[] args) &#123; Composite c0 = new Composite(); Composite c1 = new Composite(); Component leaf1 = new Leaf(\"1\"); Component leaf2 = new Leaf(\"2\"); Component leaf3 = new Leaf(\"3\"); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation();&#125; 优点 简化客户端代码，使客户端代码可一致地处理单个对象和组合对象，无须关心处理的是单个对象，还是组合对象 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足开闭原则 缺点 设计较复杂，客户端需要花更多时间理清类之间的层次关系 不容易限制容器中的构件 容易用继承的方法来增加构件的新功能 应用在需要表示一个对象整体与部分的层次结构的场合；要求对用户隐藏组合对象与单个对象的不同，用户可以用统一的接口使用组合结构中的所有对象的场合；","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"组合模式","slug":"组合模式","permalink":"https://yaoyinglong.github.io/tags/组合模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/结构型模式/"}]},{"title":"Java问题排查工具及命令","date":"2021-06-28T16:00:00.000Z","path":"Blog/杂记/Linux/Java问题排查工具及命令/","text":"btracebtrace是生产环境&amp;预发的排查问题大杀器； 查看当前谁调用了ArrayList的add方法，同时只打印当前ArrayList的size大于500的线程调用栈； 12345678910@OnMethod(clazz = \"java.util.ArrayList\", method=\"add\", location = @Location(value = Kind.CALL, clazz = \"/.*/\", method = \"/.*/\"))public static void m(@ProbeClassName String probeClass, @ProbeMethodName String probeMethod, @TargetInstance Object instance, @TargetMethodOrField String method) &#123; if(getInt(field(\"java.util.ArrayList\", \"size\"), instance) &gt; 479)&#123; println(\"check who ArrayList.add method:\" + probeClass + \"#\" + probeMethod + \", method:\" + method + \", size:\" + getInt(field(\"java.util.ArrayList\", \"size\"), instance)); jstack(); println(); println(\"===========================\"); println(); &#125;&#125; 监控当前服务方法被调用时返回的值以及请求的参数； 1234@OnMethod(clazz = \"com.taobao.sellerhome.transfer.biz.impl.C2CApplyerServiceImpl\", method=\"nav\", location = @Location(value = Kind.RETURN))public static void mt(long userId, int current, int relation, String check, String redirectUrl, @Return AnyType result) &#123; println(\"parameter# userId:\" + userId + \", current:\" + current + \", relation:\" + relation + \", check:\" + check + \", redirectUrl:\" + redirectUrl + \", result:\" + result);&#125; 注意：正则表达式匹配trace类时范围一定要控制，否则极有可能出现跑满CPU导致应用卡死的情况；由于是字节码注入的原理，想要应用恢复到正常情况，需要重启应用； Greyssc -df xxx: 输出当前类的详情,包括源码位置和classloader结构 trace class method: 打印出当前方法调用的耗时情况，细分到每个方法。对排查方法性能时很有帮助。 javOSizejavOSize通过修改了字节码，改变了类的内容，即时生效。所以可以做到快速的在某个地方打个日志看看输出，缺点是对代码的侵入性太大； ArthasArthas 是Alibaba开源的Java诊断工具，可以帮助解决： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 怎么快速定位应用的热点，生成火焰图？ 怎样直接从JVM内查找某个类的实例？ 排查问题常用命令12345678910111213141516// jps -mlvV// jstack 2815// jstack -m 2815// jinfo -flags 2815// jmap -heap 2815// jmap -dump:live,format=b,file=/tmp/heap2.bin 2815// jmap -histo 2815 | head -10// jstat -gcutil 2815 1000 CPU占用过高问题排查 用top命令查看系统资源占用信息 用ps -mp pid -o THREAD,tid,time命令查看这个程序的线程信息,tid代码线程ID，time代表这个线程的已运行时间 通过printf “%x\\n” number命令将tid进行进制转换 通过jstack -pid | grep 2hex查询","tags":[{"name":"Linux","slug":"Linux","permalink":"https://yaoyinglong.github.io/tags/Linux/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"迭代器模式","date":"2021-06-28T16:00:00.000Z","path":"Blog/设计模式/行为型模式/迭代器模式/","text":"从JDK1.2开始增加java.util.Iterator接口， 并逐步把Iterator应用到各个Collection聚集类中，Collection、List、Set、Map 等都包含了迭代器 。正因为把迭代器模式已经融入到基本API中了，再去写迭代器， 就有点多余，所以迭代器模式没落了，基本上没人会单独写一个迭代器。 迭代器模式提供了遍历容器的方便性，容器只要管理增减元素就可以了，需要遍历时交由迭代器进行。 定义提供一种方法访问一个容器对象中各个元素，而又不暴露该对象的内部细节。 实现迭代器模式是通过将聚合对象的遍历行为分离出来，抽象成迭代器类来实现的，其目的是在不暴露聚合对象的内部结构的情况下，让外部代码透明地访问聚合的内部数据。 Iterator抽象迭代器，定义访问和遍历聚合元素的接口，通常包含hasNext()、first()、next()等方法 。 12345interface Iterator &#123; Object first(); Object next(); boolean hasNext();&#125; ConcreteIterator具体迭代器，实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。 1234567891011121314151617181920212223242526public class ConcreteIterator implements Iterator &#123; private List&lt;Object&gt; list = null; private int index = -1; public ConcreteIterator(List&lt;Object&gt; list) &#123; this.list = list; &#125; public boolean hasNext() &#123; if (index &lt; list.size() - 1) &#123; return true; &#125; else &#123; return false; &#125; &#125; public Object first() &#123; index = 0; Object obj = list.get(index); return obj; &#125; public Object next() &#123; Object obj = null; if (this.hasNext()) &#123; obj = list.get(++index); &#125; return obj; &#125;&#125; Aggregate抽象容器，定义存储、添加、删除聚合对象以及创建迭代器对象的接口。 12345public interface Aggregate &#123; public void add(Object obj); public void remove(Object obj); public Iterator getIterator();&#125; ConcreteAggregate具体容器 ，实现抽象聚合类，返回一个具体迭代器的实例。 123456789101112public class ConcreteAggregate implements Aggregate &#123; private List&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); public void add(Object obj) &#123; list.add(obj); &#125; public void remove(Object obj) &#123; list.remove(obj); &#125; public Iterator getIterator() &#123; return (new ConcreteIterator(list)); &#125;&#125; 客户端调用 12345678910111213public static void main(String[] args) &#123; Aggregate ag = new ConcreteAggregate(); ag.add(\"中山大学\"); ag.add(\"华南理工\"); ag.add(\"韶关学院\"); Iterator it = ag.getIterator(); while (it.hasNext()) &#123; Object ob = it.next(); System.out.print(ob.toString() + \"\\t\"); &#125; Object ob = it.first(); System.out.println(\"\\nFirst：\" + ob.toString());&#125; 优点 访问一个聚合对象的内容而无须暴露它的内部表示 遍历任务交由迭代器完成，这简化了聚合类 它支持以不同方式遍历一个聚合，甚至可以自定义迭代器的子类以支持新的遍历 增加新的聚合类和迭代器类都很方便，无须修改原有代码 封装性良好，为遍历不同的聚合结构提供一个统一的接口 缺点 增加了类的个数，这在一定程度上增加了系统的复杂性 应用当需要为聚合对象提供多种遍历方式时；当需要为遍历不同的聚合结构提供一个统一的接口时。当访问一个聚合对象的内容而无须暴露其内部细节的表示时。 迭代器模式常常与组合模式结合起来使用，在对组合模式中的容器构件进行访问时，经常将迭代器潜藏在组合模式的容器构成类中。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"迭代器模式","slug":"迭代器模式","permalink":"https://yaoyinglong.github.io/tags/迭代器模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"适配器模式","date":"2021-06-27T16:00:00.000Z","path":"Blog/设计模式/结构型模式/适配器模式/","text":"适配器模式是一个补偿模式，通常用来解决接口不相容的问题 ，又叫变压器模式，也叫包装模式。 适配器模式最好在详细设计阶段不要考虑它，它不是为了解决还处在开发阶段的问题，而是解决正在服役的项目问题，该模式使用的主要场景是扩展应用。 定义将一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配儿无法再一起工作的两个类能够在一起工作。 实现适配器模式分为类结构型模式和对象结构型模式两种，前者类之间的耦合度比后者高，且要求了解现有组件库中的相关组件的内部结构。 Target目标接口，当前系统业务所期待的接口，它可以是抽象类或接口。 123public interface Target &#123; void request();&#125; Adaptee适配者类，它是被访问和适配的现存组件库中的组件接口。 12345public class Adaptee &#123; public void specificRequest() &#123; System.out.println(\"适配者中的业务代码被调用！\"); &#125;&#125; Adapter适配器类，它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。 通过继承进行的适配， 叫做类适配器 。 1234567891011public class ClassAdapter extends Adaptee implements Target &#123; @Override public void request() &#123; super.specificRequest(); &#125;&#125;public static void main(String[] args) &#123; Target target = new ClassAdapter(); target.request();&#125; 通过关联关系进行的适配，叫做对象适配器。可釆用将现有组件库中已经实现的组件引入适配器类中，该类同时实现当前系统的业务接口。 1234567891011121314151617public class ObjectAdapter implements Target &#123; private Adaptee adaptee; public ObjectAdapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void request() &#123; adaptee.specificRequest(); &#125;&#125;public static void main(String[] args) &#123; Adaptee adaptee = new Adaptee(); Target target = new ObjectAdapter(adaptee); target.request();&#125; 对象适配器和类适配器的区别是：类适配器是类间继承，对象适配器是对象的组合关系，对象适配器是通过类间的关联关系进行耦合的，因此在设计时就可以做到比较灵活；而类适配器就只能通过覆写源角色的方法进行扩展。 优点 可以让两个没有任何关系的类在一起运行 增加了类的透明性，客户端通过适配器可以透明地调用目标接口 提高了类的复用度，复用了现存的类，不需要修改原有代码而重用现有的适配者类 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题 灵活性非常好 缺点 适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性 增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱 应用场景在Spring AOP源码中适配器模式应用非常广泛，Advice就是来增强被代理类的功能，Advice 的类型主要有 BeforeAdvice、AfterReturningAdvice、ThrowsAdvice。 1234567891011public interface Advice &#123;&#125;public interface AfterAdvice extends Advice &#123;&#125;public interface BeforeAdvice extends Advice &#123;&#125;public interface ThrowsAdvice extends AfterAdvice &#123;&#125; 每种Advice都有对应的拦截器，即MethodBeforeAdviceInterceptor、AfterReturningAdviceInterceptor、ThrowsAdviceInterceptor，不同类型的Interceptor，通过适配器统一对外提供接口，最终调用不同的 advice来实现被代理类的增强。 12345678910111213141516171819202122232425262728293031323334353637383940public interface Interceptor extends Advice &#123;&#125;public interface MethodInterceptor extends Interceptor &#123; @Nullable Object invoke(@Nonnull MethodInvocation invocation) throws Throwable;&#125;public class AfterReturningAdviceInterceptor implements MethodInterceptor, AfterAdvice, Serializable &#123; private final AfterReturningAdvice advice; public AfterReturningAdviceInterceptor(AfterReturningAdvice advice) &#123; Assert.notNull(advice, \"Advice must not be null\"); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; Object retVal = mi.proceed(); this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal; &#125;&#125;public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; private final MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, \"Advice must not be null\"); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; Spring AOP的AdvisorAdapter类有 4 个实现类，即 SimpleBeforeAdviceAdapter、MethodBeforeAdviceAdapter、AfterReturningAdviceAdapter、ThrowsAdviceAdapter； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public interface AdvisorAdapter &#123; boolean supportsAdvice(Advice advice); MethodInterceptor getInterceptor(Advisor advisor);&#125;class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof AfterReturningAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice(); return new AfterReturningAdviceInterceptor(advice); &#125;&#125;public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; private final MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, \"Advice must not be null\"); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125;class SimpleBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof SimpleBeforeAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; SimpleBeforeAdvice advice = (SimpleBeforeAdvice) advisor.getAdvice(); return new SimpleBeforeAdviceInterceptor(advice) ; &#125;&#125;class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof ThrowsAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; return new ThrowsAdviceInterceptor(advisor.getAdvice()); &#125;&#125; 适配器模式在Spring MVC中的经典使用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface HandlerAdapter &#123; boolean supports(Object handler); @Nullable ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; long getLastModified(HttpServletRequest request, Object handler);&#125;public class SimpleServletHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return (handler instanceof Servlet); &#125; @Override @Nullable public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((Servlet) handler).service(request, response); return null; &#125; @Override public long getLastModified(HttpServletRequest request, Object handler) &#123; return -1; &#125;&#125;public class HttpRequestHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return (handler instanceof HttpRequestHandler); &#125; @Override @Nullable public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((HttpRequestHandler) handler).handleRequest(request, response); return null; &#125; @Override public long getLastModified(HttpServletRequest request, Object handler) &#123; if (handler instanceof LastModified) &#123; return ((LastModified) handler).getLastModified(request); &#125; return -1L; &#125;&#125; MVC中体现在它的核心方法doDispatch方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 在doDispatch()方法中调用了getHandlerAdapter()方法，在getHandlerAdapter()方法中循环调用supports()方法来判断是否兼容，循环迭代集合中的Adapter在初始化时早已被赋值。 1234567891011protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter adapter : this.handlerAdapters) &#123; if (adapter.supports(handler)) &#123; return adapter; &#125; &#125; &#125; throw new ServletException(\"No adapter for handler [\" + handler + \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\");&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"适配器模式","slug":"适配器模式","permalink":"https://yaoyinglong.github.io/tags/适配器模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/结构型模式/"}]},{"title":"策略模式","date":"2021-06-23T16:00:00.000Z","path":"Blog/设计模式/行为型模式/策略模式/","text":"当实现某一个功能存在多种算法或者策略，可以根据环境或者条件的不同选择不同的算法或者策略来完成该功能。 如果使用多重条件转移语句实现即硬编码，不但使条件语句变得很复杂，而且增加、删除或更换算法要修改原代码，不易维护，违背开闭原则。采用策略模式就能很好解决该问题。 定义定义一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。 实现策略模式是准备一组算法，并将这组算法封装到一系列的策略类里面，作为一个抽象策略类的子类。策略模式的重心不是如何实现算法，而是如何组织这些算法，从而让程序结构更加灵活，具有更好的维护性和扩展性。 Strategy抽象策略类定义一个公共接口，各种不同算法以不同方式实现该接口，环境角色使用该接口调用不同的算法 123public interface Strategy &#123; void strategy();&#125; ConcreteStrategy具体策略类，实现了抽象策略定义的接口，提供具体的算法实现 12345678910111213public class ConcreteStrategyA implements Strategy &#123; @Override public void strategy() &#123; System.out.println(\"具体策略A的策略方法被访问！\"); &#125;&#125;public class ConcreteStrategyB implements Strategy &#123; @Override public void strategy() &#123; System.out.println(\"具体策略B的策略方法被访问！\"); &#125;&#125; Context环境类，持有一个策略类的引用，最终给客户端调用 1234567891011public class Context &#123; private Strategy strategy; public void setStrategy(Strategy strategy) &#123; this.strategy = strategy; &#125; public void strategy() &#123; this.strategy.strategy(); &#125;&#125; 客户端使用 123456789public static void main(String[] args) &#123; Context c = new Context(); Strategy strategyA = new ConcreteStrategyA(); c.setStrategy(strategyA); c.strategy(); Strategy strategyB = new ConcreteStrategyB(); c.setStrategy(strategyB); c.strategy();&#125; 如果一个策略家族的具体策略数量超过4个，则需要考虑使用混合模式，解决策略类膨胀和对外暴露的问题。 优点 多重条件语句不易维护，而使用策略模式可以避免使用多重条件语句 策略模式提供了一系列的可供重用的算法族，恰当使用继承可以把算法族的公共代码转移到父类里面，从而避免重复的代码 自由切换，策略模式可以提供相同行为的不同实现，客户可以根据不同时间或空间要求选择不同的 策略模式提供了对开闭原则的完美支持，可以在不修改原代码的情况下，灵活增加新算法 策略模式把算法的使用放到环境类中，而算法的实现移到具体策略类中，实现了二者的分离 缺点 会造成很多的策略类，增加维护难度 所有策略类都需要对外暴露，上层模块必须知道有哪些策略，才能决定使用哪个策略，与迪米特法则相违背 应用 多个类只有在算法或行为上稍有不同的场景 算法需要自由切换的场景 需要屏蔽算法规则的场景 扩展策略枚举，把原有定义在抽象策略中的方法移植到枚举中，每个枚举成员就成为一个具体策略 。略枚举是一个非常优秀和方便的模式，但是它受枚举类型的限制，每个枚举项都是public、final、static的，扩展性受到了一定的约束，因此在系统开发中，策略枚举一般担当不经常发生变化的角色。 1234567891011121314151617181920212223242526public enum StrategyEnum &#123; ADD(\"+\")&#123; public int exec(int a,int b)&#123; return a + b; &#125; &#125;, SUB(\"-\")&#123; public int exec(int a,int b)&#123; return a - b; &#125; &#125;; String value; private StrategyEnum(String _value)&#123; this.value = _value; &#125; public String getValue()&#123; return this.value; &#125; public abstract int exec(int a,int b);&#125;public static void main(String[] args) &#123; int a = Integer.parseInt(args[0]); int b = Integer.parseInt(args[2]); System.out.println(\"运行结果为： \" + StrategyEnum.ADD.exec(a, b));&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"策略模式","slug":"策略模式","permalink":"https://yaoyinglong.github.io/tags/策略模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"装饰模式","date":"2021-06-22T16:00:00.000Z","path":"Blog/设计模式/结构型模式/装饰模式/","text":"动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式相比生成子类更为灵活。是对继承的有力补充。 扩展一个类的功能会使用继承方式来实现。但继承具有静态特征，耦合度高，并且随着扩展功能的增多，子类会很膨胀。装饰器模式的目标是使用组合关系来创建一个装饰对象来包裹真实对象，并在保持真实对象的类结构不变的前提下，为其提供额外的功能。 实现抽象构件角色：定义一个抽象接口以规范准备接收附加责任的对象。 123public interface Component &#123; void operation();&#125; 具体构件角色：实现抽象构件，通过装饰角色为其添加一些职责。 123456public class ConcreteComponent implements Component &#123; @Override public void operation() &#123; System.out.println(\"ConcreteComponent operation\"); &#125;&#125; 抽象装饰角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。 123456789101112public abstract class Decorator implements Component &#123; private Component component; public Decorator(Component component) &#123; this.component = component; &#125; @Override public void operation() &#123; this.component.operation(); &#125;&#125; 具体装饰角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。 123456789101112public class ConcreteDecorator extends Decorator &#123; public ConcreteDecorator(Component component) &#123; super(component); &#125; public void operation() &#123; super.operation(); addedFunction(); &#125; public void addedFunction() &#123; System.out.println(\"为具体构件角色增加额外的功能addedFunction()\"); &#125;&#125; 场景类 123456public static void main(String[] args) &#123; Component p = new ConcreteComponent(); p.operation(); Component d = new ConcreteDecorator(p); d.operation();&#125; 若只有一个具体构件而没有抽象构件时，可以让抽象装饰继承具体构件。若只有一个具体装饰时，可以将抽象装饰和具体装饰合并。 优点 装饰类和被装饰类可以独立发展， 而不会相互耦合； 装饰模式是继承关系的一个替代方案； 装饰模式可以动态地扩展一个实现类的功能； 缺点装饰器模式会增加许多子类，过度使用会增加程序得复杂性，尽量减少装饰类的数量， 以便降低系统的复杂度。 应用场景 需要扩展一个类的功能， 或给一个类增加附加功能，而又不能采用生成子类的方法进行扩充时； 需要动态地给一个对象增加功能， 这些功能可以再动态地撤销； 当需要通过对现有的一组基本功能进行排列组合而产生非常多的功能时，采用继承关系很难实现； Java I/O 标准库的设计，InputStream的子类FilterInputStream，OutputStream的子类FilterOutputStream，Reader的子类BufferedReader以及FilterReader，还有Writer的子类BufferedWriter、FilterWriter以及 PrintWriter等，它们都是抽象装饰类。 12BufferedReader in = new BufferedReader(new FileReader(\"filename.txt\"));String s = in.readLine();","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"装饰模式","slug":"装饰模式","permalink":"https://yaoyinglong.github.io/tags/装饰模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/结构型模式/"}]},{"title":"责任链模式","date":"2021-06-22T16:00:00.000Z","path":"Blog/设计模式/行为型模式/责任链模式/","text":"定义：使多个对象都有机会处理请求，从而避免了请求的发送者和接受者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有对象处理它为止。 责任链模式的关键是在链上，链是由多个处理者ConcreteHandler组成，由一条链去处理相似的请求在链中决定谁来处理这个请求，并返回相应结果。 实现抽象处理者角色，定义一个处理请求的接口，包含抽象处理方法和一个后继连接，融合了模板方法模式。 123456789101112131415161718192021public abstract class AbstractChainHandler&lt;T&gt; &#123; private AbstractChainHandler next; protected abstract &lt;T&gt; T doHandler(Object... obj); protected abstract &lt;T&gt; boolean isAccordWith(T t); public &lt;T&gt; T handler(Object... obj) &#123; T result = doHandler(obj); if (!isAccordWith(result) &amp;&amp; next != null) &#123; return (T) next.handler(obj); &#125; else &#123; return result; &#125; &#125; public void setNext(AbstractChainHandler next) &#123; this.next = next; &#125;&#125; 具体处理者角色，实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。 12345678910111213141516171819202122232425public class ConcreteChainHandler1&lt;T&gt; extends AbstractChainHandler&lt;T&gt; &#123; protected &lt;T&gt; T doHandler(Object... obj) &#123; // 具体业务逻辑 return null; &#125; @Override protected &lt;T1&gt; boolean isAccordWith(T1 t1) &#123; // 根据具体业务逻辑判断返回true还是false return false; &#125;&#125;public class ConcreteChainHandler2&lt;T&gt; extends AbstractChainHandler&lt;T&gt; &#123; protected &lt;T&gt; T doHandler(Object... obj) &#123; // 具体业务逻辑 return null; &#125; @Override protected &lt;T1&gt; boolean isAccordWith(T1 t1) &#123; // 根据具体业务逻辑判断返回true还是false return false; &#125;&#125; 客户类角色，创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。 123456public static void main(String[] args) &#123; AbstractChainHandler h1 = new ConcreteChainHandler1(); AbstractChainHandler h2 = new ConcreteChainHandler2(); h1.setNext(h2); h1.handler(new Object[]&#123;&#125;);&#125; 责任链模式的本质是解耦请求与处理，让请求在处理链中能进行传递与被处理；独到之处是将其节点处理者组合成了链式结构，并允许节点自身决定是否进行请求处理或转发，相当于让请求流动起来。 优点只需要将请求发送到责任链上即可，无须关心请求的处理细节和请求的传递过程，请求会自动进行传递。所以责任链将请求的发送者和请求的处理者解耦了。 降低了对象之间的耦合度，对象无须知道到底是哪一个对象处理其请求以及链的结构，发送者和接收者也无须拥有对方的明确信息 增强了系统的可扩展性，可以根据需要增加新的请求处理类 增强了给对象指派职责的灵活性，当工作流程发生变化，可以动态地改变链内的成员或者调动它们的次序，也可动态地新增或者删除责任 简化了对象之间的连接，每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句。 责任分担，每个类只需要处理自己该处理的工作 缺点 不能保证每个请求一定被处理，没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理 对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响 职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用 应用场景过滤器链的实现，Spring中的拦截器链 多个对象可以处理一个请求，但具体由哪个对象处理该请求在运行时自动确定。 可动态指定一组对象处理请求，或添加新的处理者 需要在不明确指定请求处理者的情况下，向多个处理者中的一个提交请求","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"责任链模式","slug":"责任链模式","permalink":"https://yaoyinglong.github.io/tags/责任链模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"Java实用工具库","date":"2021-06-21T16:00:00.000Z","path":"Blog/Java/基础/Java实用工具库/","text":"commons-lang312345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.12.0&lt;/version&gt; &lt;/dependency 首字母转成大写1StringUtils.capitalize(\"test\"); 重复拼接字符串1StringUtils.repeat(\"ab\", 2) 格式化日期Date类型转String类型 1String date = DateFormatUtils.format(new Date(), \"yyyy-MM-dd HH:mm:ss\"); String类型转Date类型 1Date date = DateUtils.parseDate(\"2021-05-01 01:01:01\", \"yyyy-MM-dd HH:mm:ss\"); 一个小时候的日期 1Date date = DateUtils.addHours(new Date(), 1); 包装临时对象当一个方法需要返回两个及以上字段时，一般会封装成一个临时对象返回，但Pair和Triple可以完美解决 返回两个字段 12ImmutablePair&lt;Integer, String&gt; pair = ImmutablePair.of(1, \"test\");System.out.println(pair.getLeft() + \",\" + pair.getRight()); 返回三个字段 12ImmutableTriple&lt;Integer, String, Date&gt; triple = ImmutableTriple.of(1, \"test\", new Date());System.out.println(triple.getLeft() + \",\" + triple.getMiddle() + \",\" + triple.getRight()); commons-collections412345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-collections4&lt;/artifactId&gt; &lt;version&gt;4.4&lt;/version&gt; &lt;/dependency&gt; 两个集合取交集 1Collection&lt;String&gt; collection = CollectionUtils.retainAll(listA, listB); 两个集合取并集 1Collection&lt;String&gt; collection = CollectionUtils.union(listA, listB); 两个集合取差集 1Collection&lt;String&gt; collection = CollectionUtils.subtract(listA, listB); common-beanutils12345&lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt; &lt;/dependency&gt; 设置对象属性 12345678910@Datapublic class User &#123; private Integer id; private String name;&#125; User user = new User(); BeanUtils.setProperty(user, \"id\", 1); BeanUtils.setProperty(user, \"name\", \"test\"); System.out.println(BeanUtils.getProperty(user, \"name\")); 对象和map互转 1234Map&lt;String, String&gt; map = BeanUtils.describe(user);User newUser = new User();BeanUtils.populate(newUser, map); commons-io 文件流处理12345&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt;&lt;/dependency&gt; 读取文件 12File file = new File(\"demo1.txt\"); List&lt;String&gt; lines = FileUtils.readLines(file, Charset.defaultCharset()); 写入文件 1FileUtils.writeLines(new File(\"demo2.txt\"), lines); 复制文件 1FileUtils.copyFile(srcFile, destFile); Guava工具类库12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;30.1.1-jre&lt;/version&gt; &lt;/dependency&gt; 反转List 1List&lt;Integer&gt; reverse = Lists.reverse(list); list集合元素太多，可以分成若干个集合，每个集合10个元素 1List&lt;List&lt;Integer&gt;&gt; partition = Lists.partition(list, 10); Multimap一个key可以映射多个value的HashMap 12345678Multimap&lt;String, Integer&gt; map = ArrayListMultimap.create(); map.put(\"key\", 1); map.put(\"key\", 2); Collection&lt;Integer&gt; values = map.get(\"key\"); // 输出 &#123;\"key\":[1,2]&#125;System.out.println(map); // 还能返回你以前使用的臃肿的MapMap&lt;String, Collection&lt;Integer&gt;&gt; collectionMap = map.asMap(); BiMap一种连value也不能重复的HashMap 123456789BiMap&lt;String, String&gt; biMap = HashBiMap.create(); // 如果value重复，put方法会抛异常，除非用forcePut方法 biMap.put(\"key\",\"value\"); // 输出 &#123;\"key\":\"value\"&#125; System.out.println(biMap); // 既然value不能重复，何不实现个翻转key/value的方法，已经有了 BiMap&lt;String, String&gt; inverse = biMap.inverse();// 输出 &#123;\"value\":\"key\"&#125; System.out.println(inverse); Table一种有两个key的HashMap 1234567891011121314// 一批用户，同时按年龄和性别分组 Table&lt;Integer, String, String&gt; table = HashBasedTable.create(); table.put(18, \"男\", \"NameA\"); table.put(18, \"女\", \"NameB\"); // 输出NameASystem.out.println(table.get(18, \"男\")); // 这其实是一个二维的Map，可以查看行数据 Map&lt;String, String&gt; row = table.row(18);// 输出 &#123;\"男\":\"NameA\",\"女\":\"NameB\"&#125;System.out.println(row); // 查看列数据Map&lt;Integer, String&gt; column = table.column(\"男\");// 输出 &#123;18:\"NameA\"&#125;System.out.println(column); Multiset一种用来计数的Set 12345678910111213141516Multiset&lt;String&gt; multiset = HashMultiset.create(); multiset.add(\"apple\");multiset.add(\"apple\");multiset.add(\"orange\");// 输出 2System.out.println(multiset.count(\"apple\")); // 查看去重的元素 Set&lt;String&gt; set = multiset.elementSet(); System.out.println(set); // 输出 [\"orange\",\"apple\"] // 还能查看没有去重的元素 Iterator&lt;String&gt; iterator = multiset.iterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; // 还能手动设置某个元素出现的次数 multiset.setCount(\"apple\", 5);","tags":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/tags/Java/"},{"name":"工具","slug":"工具","permalink":"https://yaoyinglong.github.io/tags/工具/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"命令模式","date":"2021-06-20T16:00:00.000Z","path":"Blog/设计模式/行为型模式/命令模式/","text":"命令模式是一个高内聚的模式 ，将一个请求封装成一个对象， 从而让你使用不同的请求把客户端参数化， 对请求排队或者记录请求日志， 可以提供命令的撤销和恢复功能 。 命令模式有三个角色： Receiver接收者角色：执行命令功能的相关操作，具体命令对象业务的真正实现者。 Command命令角色：需要执行的所有命令在该角色中声明，拥有执行命令的抽象方法execute()。 Invoker调用者角色：是请求发送者，通常拥有很多命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者。 实现通用的Receiver类： 123456789public abstract class Receiver &#123; public abstract void find(); public abstract void add(); public abstract void delete(); public abstract void update();&#125; 接收者可以是多个，具体的Receiver类： 1234567891011121314151617181920212223242526272829303132333435public class ConcreteReceiver1 extends Receiver&#123; @Override public void find() &#123; &#125; @Override public void add() &#123; &#125; @Override public void delete() &#123; &#125; @Override public void update() &#123; &#125;&#125;public class ConcreteReceiver2 extends Receiver&#123; @Override public void find() &#123; &#125; @Override public void add() &#123; &#125; @Override public void delete() &#123; &#125; @Override public void update() &#123; &#125;&#125; 命令角色是命令模式的核心，抽象的Command类： 123public abstract class Command &#123; public abstract void execute();&#125; 具体的Command类，可以在实际应用中扩展该命令类，在每个命令类中，通过构造函数定义该命令是针对哪个接收者发出的，定义一个命令接收的主题，这样调用者就仅需要实现命令的传递即可： 123456789101112131415161718192021222324252627282930313233public class ConcreteCommand1 extends Command &#123; private Receiver receiver; public ConcreteCommand1(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125;public class ConcreteCommand2 extends Command &#123; private Receiver receiver; public ConcreteCommand2(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 调用者Invoker类，不管什么命令都要接收、执行： 1234567891011public class Invoker &#123; private Command command; public void setCommand(Command command) &#123; this.command = command; &#125; public void action() &#123; this.command.execute(); &#125;&#125; 场景类： 12345678910111213public class Client &#123; public static void main(String[] args) &#123; //首先声明调用者Invoker Invoker invoker = new Invoker(); //定义接收者 Receiver receiver = new ConcreteReceiver1(); //定义一个发送给接收者的命令 Command command = new ConcreteCommand1(receiver); //把命令交给调用者去执行 invoker.setCommand(command); invoker.action(); &#125;&#125; 命令模式的Receiver在实际应用中可以被封装掉，从而减少高层模块Client类对低层模块Receiver角色类的依赖关系，提高系统整体的稳定性。 1234567891011121314151617181920212223242526public abstract class Command &#123; //定义一个子类的全局共享变量 protected final Receiver receiver; //实现类必须定义一个接收者 public Command(Receiver _receiver)&#123; this.receiver = _receiver; &#125; public abstract void execute();&#125;public class ConcreteCommand1 extends Command &#123; public ConcreteCommand1() &#123; super(new ConcreteReceiver1()); &#125; public ConcreteCommand1(Receiver receiver) &#123; super(receiver); &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 优点类间解耦：调用者角色和接收者角色之间没有任何依赖关系，调用者实现功能时只需要调用Command抽象类的execute方法即可，不需要了解到底是哪个接收者执行。 可扩展性：Command子类可以非常容易地扩展，而调用者Invoker和高层模块Client不产生严重代码耦合。 和其他模式结合会更优秀：命令模式和结合责任链模式，实现命令族解析任务；结合模板方法模式，可减少Command子类的膨胀问题。 缺点Command子类会出现膨胀问题。 应用命令模式在Spring框架JdbcTemplate源码的应用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private &lt;T&gt; T execute(StatementCallback&lt;T&gt; action, boolean closeResources) throws DataAccessException &#123; Assert.notNull(action, \"Callback object must not be null\"); Connection con = DataSourceUtils.getConnection(obtainDataSource()); Statement stmt = null; try &#123; stmt = con.createStatement(); applyStatementSettings(stmt); T result = action.doInStatement(stmt); handleWarnings(stmt); return result; &#125; catch (SQLException ex) &#123; String sql = getSql(action); JdbcUtils.closeStatement(stmt); stmt = null; DataSourceUtils.releaseConnection(con, getDataSource()); con = null; throw translateException(\"StatementCallback\", sql, ex); &#125; finally &#123; if (closeResources) &#123; JdbcUtils.closeStatement(stmt); DataSourceUtils.releaseConnection(con, getDataSource()); &#125; &#125;&#125;public &lt;T&gt; T query(final String sql, final ResultSetExtractor&lt;T&gt; rse) throws DataAccessException &#123; Assert.notNull(sql, \"SQL must not be null\"); Assert.notNull(rse, \"ResultSetExtractor must not be null\"); if (logger.isDebugEnabled()) &#123; logger.debug(\"Executing SQL query [\" + sql + \"]\"); &#125; class QueryStatementCallback implements StatementCallback&lt;T&gt;, SqlProvider &#123; @Override @Nullable public T doInStatement(Statement stmt) throws SQLException &#123; ResultSet rs = null; try &#123; rs = stmt.executeQuery(sql); return rse.extractData(rs); &#125; finally &#123; JdbcUtils.closeResultSet(rs); &#125; &#125; @Override public String getSql() &#123; return sql; &#125; &#125; return execute(new QueryStatementCallback(), true);&#125; StatementCallback接口，类似Command命令接口，QueryStatementCallback匿名内部类，实现了命令接口，同时也充当命令接收者；命令调用者是 JdbcTemplate，不同的实现StatementCallback接口的对象，对应不同的doInStatement实现逻辑； 扩展实现在没有执行或执行后撤回，有两种方法可以解决，一是结合备忘录模式还原最后状态，该方法适合接收者为状态的变更情况，而不适合事件处理；二是通过增加一个新的命令，实现事件的回滚。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"命令模式","slug":"命令模式","permalink":"https://yaoyinglong.github.io/tags/命令模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"MySQL基础","date":"2021-06-17T16:00:00.000Z","path":"Blog/DB/MySQL基础/","text":"数据类型选择选择正确的数据类型，对于性能至关重要，在数据类型设置方面，尽量用更小的数据类型，因为它们通常有更好的性能，花费更少的硬件资源，且尽量把字段定义为NOT NULL，避免使用NULL。一般应该遵循下面两步： 确定合适的大类型：数字、字符串、时间、二进制； 确定具体的类型：有无符号、取值范围、变长定长等。 数值类型若整形数据没有负数，如ID号，建议指定为UNSIGNED无符号类型，容量可以扩大一倍；建议使用TINYINT代替ENUM、BITENUM、SET；避免使用整数的显示宽度，不要用INT(10)类似的方法指定字段显示宽度，直接用INT。 DECIMAL最适合保存准确度要求高，且用于计算的数据，如价格。但在使用DECIMAL类型时，注意长度设置。建议使用整形类型来运算和存储实数，方法是实数乘以相应的倍数后再操作。整数通常是最佳的数据类型，因为它速度快，且能使用AUTO_INCREMENT。 INT显示宽度：在使用ZEROFILL时有用，让查询结果前填充0，如TINYINT(5) ，若结果是5，则输出就是00005，实际存储的值还是5，且存储的数据不会超过255，只是输出数据时在前面填充了0。 类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 字节 -2^7 ~ 2^7-1 (0, 255) 小整数值 SMALLINT 2 字节 -2^15 ~ 2^15-1 (0, 65535) 大整数值 MEDIUMINT 3 字节 -2^23 ~ 2^23-1 (0, 16777215) 大整数值 INT或 INTEGER 4 字节 -2^31 ~ 2^31-1 0~2^63-1 大整数值 BIGINT 8 字节 -2^63 ~ 2^63-1 0~2^127-1 极大整数值 FLOAT 4 字节 单精度浮点数值 DOUBLE 8 字节 双精度浮点数值 DECIMAL DECIMAL(M,D) 若M&gt;D为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 日期和时间MySQL能存储的最小时间粒度为秒。建议用DATE数据类型来保存日期，默认日期格式yyyy-MM-dd。用内建类型DATE、TIME、DATETIME来存储时间，而不是使用字符串。 当数据格式为TIMESTAMP和DATETIME时，可用CURRENT_TIMESTAMP作为默认值，MySQL会自动返回记录插入的确切时间，TIMESTAMP是UTC时间戳，与时区相关。 DATETIME的存储格式是一个yyyy-MM-dd HH:mm:ss的整数，与时区无关，存什么读出来就是什么。除非有特殊需求，一般的公司建议使用TIMESTAMP，它比DATETIME更节约空间，但大公司一般用DATETIME，因为不用考虑TIMESTAMP将来的时间上限问题。不推荐把Unix的时间戳保存为整数值。 类型 大小 (字节) 范围 格式 用途 DATE 3 1000-01-01到9999-12-31 YYYY-MM-DD 日期值 TIME 3 -838:59:59到838:59:59 HH:mm:ss 时间值或持续时间 YEAR 1 1901到2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00到9999-12-31 23:59:59 YYYY-MM-DD HH:mm:ss 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:00到2038-01-19 03:14:07 YYYYMMDDhhmmss 混合日期、时间，时间戳 字符串 字符串长度相差较大用VARCHAR；字符串短且所有值都接近一个长度用CHAR。CHAR和VARCHAR适用于包括人名、邮政编码、电话号码和不超过255个字符长度的任意字母数字组合。需要用来计算的数字不要用VARCHAR类型保存，可能会导致一些与计算相关的问题，可能影响到计算的准确性和完整性。 尽量少用BLOB和TEXT，若实在要用可考虑将BLOB和TEXT字段单独存一张表用id关联。BLOB系列存储二进制字符串，与字符集无关。TEXT系列存储非二进制字符串，与字符集相关。BLOB和TEXT都不能有默认值。 类型 大小 用途 CHAR 0-255字节 定长字符串，char(n)当插入字符串实际长度不足n时，插入空格进行补充保存。检索时尾部的空格会被去掉。 VARCHAR 0-65535字节 变长字符串，varchar(n)中n代表最大列长度，插入字符串实际长度不足n时不会补充空格 TINYBLOB 0-255字节 不超过255个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65535字节 二进制形式的长文本数据 TEXT 0-65535字节 长文本数据 MEDIUMBLOB 0-16777215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16777215字节 中等长度文本数据 LONGBLOB 0-4294967295字节 二进制形式的极大文本数据 LONGTEXT 0-4294967295字节 极大文本数据","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"分库分表","date":"2021-06-16T16:00:00.000Z","path":"Blog/DB/分库分表/","text":"中大型项目中，一旦遇到数据量比较大，都知道对数据进行拆分，有垂直拆分和水平拆分两种。 垂直拆分：从业务角度拆分多个库。 水平拆分：同一个业务数据量大，进行水平拆分。Redis集群就是典型的水平分片 常用分片策略 取余\\取模 ： 优点均匀存放数据，缺点扩容非常麻烦 按范围分片 ： 比较好扩容， 数据分布不够均匀 按时间分片 ： 比较容易将热点数据区分出来。 按枚举值分片 ： 例如按地区分片 按目标字段前缀指定进行分区：自定义业务规则分片 水平分片从理论上突破了单机数据量处理的瓶颈，且扩展相对自由，是分库分表的标准解决方案。一般在系统设计阶段就应该根据业务耦合松紧来确定垂直分库、分表方案，在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案。若数据量极大，且持续增长，再考虑水平分库、分表方案。 分库分表缺点虽然数据分片解决了性能、可用性以及单点备份恢复等问题，但是分布式的架构在获得收益的同时，也引入了非常多新的问题。 事务一致性问题：原本单机数据库有很好的事务机制能保证数据一致性，但是分库分表后，由于数据分布在不同库甚至不同服务器，不可避免会产生分布式事务问题 跨节点关联查询问题：没有分库时可很容易进行跨表关联查询，但是在分库后表被分散在不同数据库，无法关联查询。需要将关联查询拆分成多次查询，然后将获得结果拼装 跨节点分页、排序函数：跨节点多库进行查询时limit分页、order by排序等问题，就变得比较复杂。需要先在不同分片节点中将数据排序返回，然后将不同分片返回的结果集进行汇总再排序。这时非常容易出现内存崩溃的问题 主键避重问题：由于表中数据同时存在不同数据库中，无法再使用自增主键，某个分区数据库生成的ID无法保证全局唯一，因此需要单独设计全局主键，以避免跨库主键重复问题 公共表处理：参数表、数据字典表等都是数据量较小，变动少，且属于高频联合查询的依赖表。这一类表一般需要在每个数据库中都保存一份，且所有对公共表的操作都要分发到所有的分库去执行 运维工作量：面对散乱的分库分表之后的数据，应用开发工程师和数据库管理员对数据库的操作都变得非常繁重 分库分表时机单表记录达到500W这个级别，或单表容量达到2GB，建议进行分库分表。而考虑到分库分表需要对数据进行再平衡，所以若要使用分库分表，就要在系统设计之初就详细考虑好分库分表的方案，这里要分两种情况。 一般对用户数据这类后期增长比较缓慢的数据，一般可按照三年左右的业务量来预估使用人数，按照标准预设好分库分表的方案。 对于业务数据这一类增长快速且稳定的数据，一般则需要按照预估量的两倍左右预设分库分表方案，且由于分库分表后期扩容是非常麻烦的，所以在进行分库分表时，尽量根据情况多分一些表 在设计分库分表方案时，尽量兼顾业务场景和数据分布。在支持业务场景的前提下，尽量保证数据能够分得更均匀。 一旦用到了分库分表，就会表现为对数据查询业务的灵活性有一定的影响，进行排序、分页、聚合等操作，很容易扛不住。尽量在分库分表的同时，再补充设计一个降级方案，如将数据转存一份到ES，ES可实现更灵活的大数据聚合查询。 常见分库分表组件由于分库分表之后，数据被分散在不同的数据库、服务器。因此对数据的操作就无法通过常规方式完成，且还带来了一系列的问题。 ShardingSphereSharding-JDBC是当当网研发的开源分布式数据库中间件，他是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。 他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。 MyCatMyCat基于阿里开源的Cobar产品研发，Cobar的稳定性、可靠性、优秀的架构和性能以及众多成熟的使用案例使得MyCat一开始就拥有一个很好的起点。MyCat虽然是从阿里技术体系中出来的，但跟阿里其实没什么关系。 DBLEDBLE该网站包含几个重要产品。其中分布式中间件可以认为是MyCAT的一个增强版，专注于MySQL的集群化管理。另外还有数据传输组件和分布式事务框架组件可供选择。 分库分表方案hash取模和range范围方案是分库分表方案中常用的方案；分库分表方案最主要就是路由算法，把路由的key按照指定的算法进行路由存放。 hash取模方案hash的方案就是对指定的路由key对分表总数进行取模，可以参考HashMap源码。 优点：是可以将数据均匀放到各个分表中，不会出现热点问题。 缺点：是数据迁移和扩容会比较困难。因为若之前分表是4，现在分表变成了8，由于取模基数变化导致之前的数据可能会找不到。要解决这样的问题，就需要将之前的数据重新按照新的取模基数做hash方案把数据进行迁移，放到新规划的分表中。但是对某些不允许停机做数据迁移的业务就会非常痛苦。 range范围方案range方案比较简单，就是把一定范围内的订单，存放到一个表中；如id=12放到0表中，id=1300万的放到1表中。设计这个方案时就是前期把表的范围设计好。通过id进行路由存放。 优点：有利于将来的扩容，不需要做数据迁移。 缺点：有热点问题。 扩展hash是可以解决数据均匀的问题，range可以解决数据迁移问题，可以将两种方案结合，在一定的范围内数据均匀，每次扩容肯定会先设计好这次扩容的范围大小，只要保证这次的范围内的数据均匀就行了。 可以先定义一个group组的概念，首先通过范围range定位是哪个group组，然后根据hash方案定位是哪个DB，再根据range方案定位哪个Table。 例如对10进行取模，如果值为【0，1，2，3】就路由到DB_0，【4，5，6】路由到DB_1，【7，8，9】路由到DB_2。1000万以内的id都均匀的分配到DB_0，DB_1，DB_2三个数据库中的Table_0表中。 扩容的时候只需要再设计一个group02组就行了。 设计是比较简单的，就3张表，把group，DB，table之间建立好关联关系就行了。 在开发的时候把三张关联数据保存到缓存中。","tags":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/tags/DB/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"Spring初始化扩展","date":"2021-06-16T16:00:00.000Z","path":"Blog/Spring/Spring初始化扩展/","text":"经常需要在容器启动时做一些钩子动作，比如注册消息消费者，监听配置等。 容器刷新完成扩展点监听容器刷新完成扩展点ApplicationListener&lt;ContextRefreshedEvent&gt;容器刷新成功意味着所有的Bean已初始化完成，当容器刷新之后Spring将会调用容器内所有实现了ApplicationListener&lt;ContextRefreshedEvent&gt;的Bean的onApplicationEvent方法，应用程序可以以此达到监听容器初始化完成事件的目的。 1234567@Log4j2public class ApplicationListenerExample implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; log.info(\"ApplicationListenerExample Startup\"); &#125;&#125; 上面的写法，就会造成onApplicationEvent方法被执行两次。因为在Spring MVC项目中，系统会存在两个容器，一个是root ApplicationContext，一个是作为root ApplicationContext的子容器的WebApplicationContext。 123456789@Log4j2public class ApplicationListenerExample implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; if (event.getApplicationContext().getParent() == null) &#123; log.info(\"ApplicationListenerExample Startup\"); &#125; &#125;&#125; 自定义事件可以借助Spring以最小成本实现一个观察者模式，首先定义一个事件，然后注册一个监听器，最后发布事件： 1234567891011121314151617181920212223242526public class NotifyEvent extends ApplicationEvent &#123; public NotifyEvent(Object source) &#123; super(source); &#125;&#125;@Log4j2public class NotifyListener implements ApplicationListener&lt;NotifyEvent&gt; &#123; @Override public void onApplicationEvent(NotifyEvent event) &#123; log.info(\"NotifyListener Startup\"); &#125;&#125;@RunWith(SpringRunner.class)@SpringBootTestpublic class ListenerTest &#123; @Autowired private WebApplicationContext webApplicationContext; @Test public void testListener() &#123; NotifyEvent event = new NotifyEvent(\"object\"); webApplicationContext.publishEvent(event); &#125;&#125; SpringBoot的CommandLineRunner接口当容器上下文初始化完成之后，SpringBoot也会调用所有实现了CommandLineRunner接口的run方法。 12345678@Log4j2@Componentpublic class CommandLineStartupRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; log.info(\"CommandLineStartupRunner Startup\"); &#125;&#125; 多个实现了CommandLineRunner的Bean的执行顺序可以根据Bean上的@Order注解调整。其run方法可以接受从控制台输入的参数，跟ApplicationListener&lt;ContextRefreshedEvent&gt;这种扩展相比更加灵活。 1java -jar CommandLineStartupRunner.jar abc abcd SpringBoot的ApplicationRunner接口SpringBoot的CommandLineRunner接口扩展类似，只不过接受参数是一个ApplicationArguments类，对控制台输入的参数提供了更好的封装，以--开头的被视为带选项的参数，否则是普通的参数。 12345678@Log4j2@Componentpublic class ApplicationStartupRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; log.info(\"ApplicationStartupRunner Startup: &#123;&#125;\", args.getOptionNames()); &#125;&#125; 控制台输入参数示例： 1java -jar ApplicationStartupRunner.jar abc abcd --autho=mark verbose Bean初始化完成扩展点@PostConstruct注解@PostConstruct注解一般放在Bean的方法上，被@PostConstruct修饰的方法会在Bean初始化后马上调用： 1234567891011@Log4j2@Componentpublic class PostConstructExample &#123; @Autowired private Environment environment; @PostConstruct public void init() &#123; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125; InitializingBean接口InitializingBean的用法基本上与@PostConstruct一致，只不过相应的Bean需要实现afterPropertiesSet方法。 1234567891011@Log4j2@Componentpublic class InitializingBeanExample implements InitializingBean &#123; @Autowired private Environment environment; @Override public void afterPropertiesSet() throws Exception &#123; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125; @Bean注解的初始化方法通过@Bean注入Bean的时候可以指定初始化方法： 123456789101112131415@Log4j2@Componentpublic class InitMethodExampleBean &#123; @Autowired private Environment environment; public void init() &#123; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125;@Bean(initMethod=\"init\")public InitMethodExampleBean initMethodExampleBean() &#123; return new InitMethodExampleBean();&#125; 通过构造函数注入Spring也支持通过构造函数注入，我们可以把搞事情的代码写在构造函数中，同样能达到目的 1234567891011@Log4j2@Componentpublic class ConstructorExampleBean &#123; private final Environment environment; @Autowired public ConstructorExampleBean(Environment environment) &#123; this.environment = environment; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125; Bean初始化完成扩展点执行顺序是：构造函数注入，@PostConstruct注解，InitializingBean接口，@Bean注解的初始化方法。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"中介者模式","date":"2021-04-18T16:00:00.000Z","path":"Blog/设计模式/行为型模式/中介者模式/","text":"常常会出现好多对象之间存在复杂的交互关系，这种交互关系常常是网状结构，它要求每个对象都必须知道它需要交互的对象。若把这种网状结构改为星形结构的话，将大大降低它们之间的耦合性，这时只要找一个中介者就可以了。 定义一个中介对象来封装一系列对象之间的交互，中介者使各对象不需要显示地相互作用 ，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。 实现中介者模式由抽象中介者、具体中介者、抽象同事、具体同事几个主要角色。 抽象中介者：定义统一的接口， 用于各同事角色之间的通信 12345678910@Datapublic abstract class Mediator &#123; //定义同事类 protected ConcreteColleague1 c1; protected ConcreteColleague2 c2; //中介者模式的业务逻辑 public abstract void doSomething1(); public abstract void doSomething2();&#125; 具体中介者：通过协调各同事角色实现协作行为， 因此它必须依赖于各个同事角色 12345678910111213public class ConcreteMediator extends Mediator &#123; @Override public void doSomething1() &#123; super.c1.selfMethod1(); super.c2.selfMethod2(); &#125; @Override public void doSomething2() &#123; super.c1.selfMethod1(); super.c2.selfMethod2(); &#125;&#125; 抽象同事类：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能 1234567public abstract class Colleague &#123; protected Mediator mediator; public Colleague(Mediator mediator) &#123; this.mediator = mediator; &#125;&#125; 具体同事类：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互，每个同事角色都知道中介者角色， 且与其他同事角色通信时， 一定要通过中介者角色协作 12345678910111213141516171819202122232425262728293031public class ConcreteColleague1 extends Colleague &#123; public ConcreteColleague1(Mediator mediator) &#123; super(mediator); &#125; public void selfMethod1() &#123; //处理自己的业务逻辑 &#125; public void depMethod1() &#123; //处理自己的业务逻辑 //自己不能处理的业务逻辑， 委托给中介者处理 super.mediator.doSomething1(); &#125;&#125;public class ConcreteColleague2 extends Colleague &#123; public ConcreteColleague2(Mediator mediator) &#123; super(mediator); &#125; public void selfMethod2() &#123; //处理自己的业务逻辑 &#125; public void depMethod2() &#123; //处理自己的业务逻辑 //自己不能处理的业务逻辑， 委托给中介者处理 super.mediator.doSomething2(); &#125;&#125; 优点类之间各司其职，符合迪米特法则 降低了对象之间的耦合性，使得对象易于独立地被复用 将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展 缺点中介者模式将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护 应用在MVC框架中，控制器（C）就是模型（M）和视图（V）的中介者。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"中介者模式","slug":"中介者模式","permalink":"https://yaoyinglong.github.io/tags/中介者模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"原型模式","date":"2021-04-07T16:00:00.000Z","path":"Blog/设计模式/创建型模式/原型模式/","text":"用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。用这种方式创建对象非常高效，无须知道对象创建的细节。 在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现， 通过clone的方法创建一个对象，然后由工厂方法提供给调用者。 原型模式简单程度仅次于单例模式和迭代器模式，Java中的Object类提供了浅克隆的clone()方法，具体原型类只要实现Cloneable接口就可实现对象的浅克隆。Cloneable 接口只是一个标记作用， 在JVM中具有这个标记的对象才有可能被拷贝。 原型模式的克隆分为浅克隆和深克隆 浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。 12345678910111213public class Thing implements Cloneable &#123; private ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); @Override public Thing clone() &#123; Thing thing = null; try &#123; thing = (Thing) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return thing; &#125;&#125; 深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。 1234567891011121314public class Thing implements Cloneable &#123; private ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); @Override public Thing clone() &#123; Thing thing = null; try &#123; thing = (Thing) super.clone(); thing.arrayList = (ArrayList&lt;String&gt;)this.arrayList.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return thing; &#125;&#125; 对象的clone与对象内的final关键字是有冲突的 ，要使用clone方法， 类的成员变量上不要增加final关键字。 优点Java自带的原型模式基于内存二进制流的复制，在性能上比直接new一个对象更加优良，特别是要在一个循环体内产生大量的对象时 可以使用深克隆方式保存对象的状态，使用原型模式将对象复制一份，并将其状态保存起来，简化了创建对象的过程，以便在需要的时候使用。 逃避构造函数的约束，直接在内存中拷贝， 构造函数是不会执行的 缺点需要为每一个类都配置一个clone方法 clone 方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违背了开闭原则 当实现深克隆时，需要编写较为复杂的代码，而且当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。 应用场景对象之间相同或相似，即只是个别的几个属性不同的时候 创建对象成本较大，例如初始化时间长，占用CPU太多，或者占用网络资源太多等，需要优化资源 创建一个对象需要繁琐的数据准备或访问权限等，需要提高性能或者提高安全性 系统中大量使用该类对象，且各个调用者都需要给它的属性重新赋值 一个对象需要提供给其他对象访问， 而且各个调用者可能都需要修改其值时， 可以考虑使用原型模式拷贝多个对象供调用者使用 JDK源码中 ArrayList的应用： 1234567891011public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"原型模式","slug":"原型模式","permalink":"https://yaoyinglong.github.io/tags/原型模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/创建型模式/"}]},{"title":"分布式系统常见问题","date":"2021-01-22T16:00:00.000Z","path":"Blog/Cloud/分布式系统常见问题/","text":"对于分布式高并发系统需要考虑的问题：容量规划、架构设计、数据库设计、缓存设计、框架选型、数据迁移方案、性能压测、监控报警、领域模型、回滚方案、高并发、分库分表。 分布式IDUUID优点：生成简单、本地生成无网络成本； 缺点：无序的字符串，不具备趋势自增特性、没有具体的业务含义、长度过长16字节128位，36位长度的字符串，存储以及查询对MySQL的性能消耗较大，作为数据库主键UUID的无序性会导致数据位置频繁变动，严重影响性能 数据库自增ID需要一个单独的MySQL实例用来生成ID，要一个ID时，向表中插入一条记录返回主键ID，但该方式在访问量激增时MySQL本身就是系统的瓶颈，用它来实现分布式服务风险比较大。 优点：实现简单，ID单调自增，数值类型查询速度快 缺点：DB单点存在宕机风险，无法扛住高并发场景 数据库多主模式主从模式或多主模式集群，设置起始值和自增步长 优点：解决DB单点问题 缺点：不利于后续扩容，且实际上单个数据库自身压力还是大，依旧无法满足高并发场景 号段模式一次获取一批号段，可以基于MySQL也可以局域Redis或Zookeeper等 RedisRDB模式：若连续自增但redis没及时持久化，但Redis挂掉了，重启Redis后会出现ID重复的情况 AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长 雪花算法SnowFlake雪花算法能保证不同进程主键不重复相同进程主键有序，二进制形式包含4部分，从高位到低位分表为：1bit符号位、41bit时间戳位、10bit工作进程位，12bit序列号位。毫秒数在高位自增序列在低位，整个ID趋势递增；不依赖第三方组件稳定性高，生成ID性能也非常高；可根据自身业务特性分配bit位，非常灵活；但强依赖机器时钟，若机器上时钟回拨会导致发号重复。 1bit符号位：预留的符号位恒为零 41bit时间戳位：41位时间戳可容纳毫秒数为2的41次幂，一年所使用的毫秒数为365 * 24 * 60 * 60 * 1000 Math.pow(2, 41) / (365 * 24 * 60 * 60 * 1000L) = 69.73年不重复 10bit工作进程位：该标志Java进程内唯一，若分布式应用部署应保证每个工作进程的id不同，默认为0，可通过属性设置 12bit序列号位：该序列用来在同一个毫秒内生成不同的ID，若在该毫秒内生成数量超过4096即2的12次幂，则生成器会等待到下个毫秒继续生成。 滴滴出品TinyIDTinyid是基于号段模式原理实现的 百度uid-generatoruid-generator是基于Snowflake算法实现，与原始的snowflake算法不同在于，uid-generator支持自定义时间戳、工作机器ID和序列号等各部分的位数，而且uid-generator中采用用户自定义workId的生成策略。 uid-generator需要与数据库配合使用，需要新增一个WORKER_NODE表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增ID就是该机器的workId数据由host，port组成。 美团LeafLeaf同时支持号段模式和snowflake算法模式，可以切换使用；Leaf的snowflake模式依赖于ZooKeeper，不同于原始snowflake算法也主要是在workId的生成上，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。 不存在数据过滤使用布隆过滤器 接口幂等性解决方案需要判断哪些操作是需要回滚的，以及这次成功下次不需要再处理了，数据积累问题怎么解决 全局唯一ID 去重表：可以在redis中做去重表 状态机：将状态从0改成1 分布式Session解决方案Session Sticky对IP进行hash分发到固定的机器上，但是会存在单点故障问题， Session Relication即Session复制，可解决单点复制，但耗内存、耗宽带 Session Center将Session存入Redis应用与Redis通信 数据库优化 换数据库：MySQL -&gt; Redis；读多写少使用Redis做缓存，ES搜索（全量更新、增量更新） 分库分表，读写分离； JDBC应用层：shardingsphere、tddl；性能更高、不支持夸语言 Proxy代理层：mycat、mysql-proxy；性能相对较差、支持夸语言、业务侵入性低 图片处理可以存OSS等 后端优化一般商品详情页都是读多写少，通过多级缓存 缓存应用场景 访问量大、QPS高、更新频率不是很高的业务 数据一致性要求不高 缓存一致性问题提高请求的吞吐量 减少磁盘IO 减少网络IO 若商品详情页数据过大，Redis会存在网络瓶颈，需要对数据进行压缩后再缓存到Redis，提升通讯性能。 最终一致性 设置超时时间 实时一致性 canal binlog日志实时同步 二级缓存L1缓存失效时间短，L2缓存失效时间长。请求优先从L1缓存获取数据，如果未命中则加锁，保证只有一个线程去数据库中读取数据然后再更新到L1和L2中。然后其他线程依然在L2缓存获取数据。 多级缓存设计对于高并发系统来说，网络IO和磁盘IO对系统的影响比较大，引入Redis缓存的目的是提高网站的性能，本质是不走磁盘走内存减少磁盘IO来提高性能，但是增加了网络的操作，若是本地缓存的既可以减少磁盘IO也可以减少网络IO。引入Guava缓存， 1234567891011121314151617public class LocalCache &#123; private Cache&lt;String, ProductParam&gt; localCache = null; @PostConstruct private void init() &#123; localCache = CacheBuilder.newBuilder() .initialCapacity(10) //设置本地缓存容器的初始容量 .maximumSize(500) //设置本地缓存的最大容量 .expireAfterWrite(60, TimeUnit.SECONDS) //设置写缓存后多少秒过期 .build(); &#125; public void setLocalCache(String key, PmsProductParam object) &#123; localCache.put(key, object); &#125; public PmsProductParam get(String key) &#123; return localCache.getIfPresent(key); &#125;&#125; 前端页面静态化处理可通过FreeMarker模板引擎，基于模板和数据源生成前端静态页面，适用于小流量商品详情页缓存架构，缺点是每个商品都需要生成一个静态页面，且若有多个机房每个产品得生成多个静态页面或生成一个静态页面同步多个机房。且若插入、修改、数据调整导致模板变化所有产品得重新生成。 架构问题：数据新增分增量更新或全量更新，不同应用部署在不同服务器甚至不同的机房或国家，存在数据同步问题 通过网络方式同步：其中一台服务器静态化，把文件同步到其他应用服务器上，如scp命令 定时任务：在每个应用使用一个定时任务，分别执行数据库需要静态话的数据，解决了同步问题，但产生了数据重复执行问题 消息中间件：通过消息中间件，订阅Topic生成当前服务器静态化的页面 后天数据有变更如何及时更新同步到其他服务端，页面静态化后，搜索打开一个商品详细页，怎么确定需要访问的静态页面，或若模板修改等问题 前端缓存小流量架构可通过FreeMarker模板引擎，基于模板和数据源生成前端静态页面，适用于小流量商品详情页缓存架构，缺点是每个商品都需要生成一个静态页面，且若有多个机房每个产品得生成多个静态页面或生成一个静态页面同步多个机房。且若插入、修改、数据调整导致模板变化所有产品得重新生成。 架构问题：数据新增分增量更新或全量更新，不同应用部署在不同服务器甚至不同的机房或国家，存在数据同步问题 通过网络方式同步：其中一台服务器静态化，把文件同步到其他应用服务器上，如scp命令 定时任务：在每个应用使用一个定时任务，分别执行数据库需要静态话的数据，解决了同步问题，但产生了数据重复执行问题 消息中间件：通过消息中间件，订阅Topic生成当前服务器静态化的页面 数据有变更如何及时更新同步到其他服务端，页面静态化后，搜索打开一个商品详细页，怎么确定需要访问的静态页面，或若模板修改等问题 大型网站架构可使用OpenResty来搭建能够处理超高并发、扩展性极高的动态Web应用、Web服务和动态网关。OpenResty是基于Nginx和Lua脚本的高性能Web平台，内部集成了大量精良的Lua库、第三方模块以及大多数的依赖项。通过汇聚各种设计精良的Nginx模块，从而将Nginx有效的变成一个强大的通用Web应用平台。 高并发整体架构高并发架构v1使用静态化技术，按照商品维度生成静态化HTML 通过MQ得到变更通知 通过Java Worker调用多个依赖系统生成详情页HTML 通过rsync同步到其他机器 通过Nginx直接输出静态页 接入层负责负载均衡 随着商品数量的增加这种架构的存储容量到达了瓶颈，且按照商品维度生成整个页面会存在如分类维度变更就要全部刷一遍该分类下所有信息的问题 若只有分类、模板变更，所有相关的商品都需要重新静态化 随着商品数量的增加，rsync会成为瓶颈 无法迅速响应一些页面需求变更，大部分都是通过JavaScript动态改页面元素。 方案改进： 容量问题通过按照商品尾号做路由分散到多台机器，按照自营商品单独一台，第三方商品分散到11台 按维度生成HTML片段（框架、商品介绍、规格参数、面包屑、相关分类、店铺信息），而不是一个大HTML 通过Nginx SSI合并片段输出 接入层负责负载均衡 多机房部署也无法通过rsync同步，而是使用部署多套相同架构来实现 该方案主要缺点，随着业务的发展，无法满足迅速变化、还有一些变态的需求 碎片文件太多，导致无法rsync 机械盘做SSI合并时，高并发时性能差 模板如果要变更，数亿商品需要数天才能刷完 到达容量瓶颈时，会删除一部分静态化商品，然后通过动态渲染输出，动态渲染系统在高峰时会导致依赖系统压力大，抗不住 还是无法迅速响应一些业务需求 高并发架构v2存在需要解决的问题： 能迅速响瞬变的需求，和各种变态需求 支持各种垂直化页面改版 页面模块化 AB测试 高性能、水平扩容 多机房多活、异地多活 目前架构的目标不仅仅是为商品详情页提供数据，只要是Key-Value获取的而非关系的都可以提供服务，叫做动态服务系统 数据变更还是通过MQ通知 数据异构Worker得到通知，然后按照一些维度进行数据存储，存储到数据异构JIMDB集群即Redis+持久化引擎，存储的数据都是未加工的原子化数据，如商品基本信息、商品扩展属性、商品其他一些相关信息、商品规格参数、分类、商家信息等 数据异构Worker存储成功后，会发送一个MQ给数据同步Worker，数据同步Worker也可叫做数据聚合Worker，按照相应的维度聚合数据存储到相应的JIMDB集群；三个维度：基本信息（基本信息+扩展属性等的一个聚合）、商品介绍（PC版、移动版）、其他信息（分类、商家等维度，数据量小，直接Redis存储） 前端展示分为两个：商品详情页和商品介绍，使用Nginx+Lua技术获取数据并渲染模板输出","tags":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/tags/Cloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://yaoyinglong.github.io/categories/Cloud/"}]},{"title":"代理模式","date":"2020-11-04T16:00:00.000Z","path":"Blog/设计模式/结构型模式/代理模式/","text":"由于某些原因需要给某对象提供一个代理以控制对该对象的访问。访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。 代理模式是一个使用率非常高的模式，为其他对象提供一种代理以控制这个对象的访问。代理模式也叫做委托模式，它是一项基本设计技巧。许多其他的模式，如状态模式、策略模式、访问者模式本质上是在更特殊的场合采用了委托模式，而且在日常的应用中，代理模式可以提供非常好的访问控制。 代理模式的结构比较简单，主要是通过定义一个继承抽象主题的代理来包含真实主题，从而实现对真实主题的访问； 抽象主题类Subject通过接口或抽象类声明真实主题和代理对象实现的业务方法： 123public interface Subject &#123; void request();&#125; 真实主题类RealSubject实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象，为具体主题角色，也叫被委托角色或被代理角色，是业务逻辑的具体执行者： 123456public class RealSubject implements Subject &#123; @Override public void request() &#123; // 业务逻辑处理 &#125;&#125; 代理类Proxy提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能，也叫委托类或代理类： 1234567891011121314public class Proxy implements Subject &#123; private Subject subject; public Proxy(Subject subject) &#123; this.subject = subject; &#125; @Override public void request() &#123; this.before(); this.subject.request(); this.after(); &#125; private void before() &#123;&#125; private void after() &#123;&#125;&#125; 一般代理会被理解为代码增强，实际上就是在原代码逻辑前后增加一些代码逻辑，而使调用者无感知；一个代理类可以代理多个被委托者或被代理者， 因此一个代理类具体代理哪个真实主题角色， 是由场景类决定。 代理模式优点职责清晰，真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务；高扩展性；智能化。 根据代理的创建时期，代理模式分为静态代理和动态代理，还可以通过反射的方式实现动态代理 优点在客户端与目标对象之间起到一个中介作用和保护目标对象的作用 可以扩展目标对象的功能 能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性 缺点会造成系统设计中类的数量增加 在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢 增加了系统的复杂度 应用场景当无法或不想直接引用某个对象或访问某个对象存在困难时，可以通过代理对象来间接访问。使用代理模式主要有两个目的：保护目标对象，增强目标对象。 远程代理，通常是为了隐藏目标对象存在于不同地址空间的事实，方便客户端访问。 虚拟代理，通常用于要创建的目标对象开销很大时。 安全代理，通常用于控制不同种类客户对真实对象的访问权限。 智能指引，主要用于调用目标对象时，代理附加一些额外的处理功能。 延迟加载，指为了提高系统的性能，延迟对目标的加载。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"代理模式","slug":"代理模式","permalink":"https://yaoyinglong.github.io/tags/代理模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/结构型模式/"}]},{"title":"建造者模式","date":"2020-11-03T16:00:00.000Z","path":"Blog/设计模式/创建型模式/建造者模式/","text":"建造者模式也叫生成器模式，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。当一个类的构造函数参数个数超过4个，而且这些参数有些是可选的参数，考虑使用构造者模式。 车辆模型抽象类： 1234567891011121314151617181920212223public abstract class CarModel &#123; private List&lt;String&gt; sequence = new ArrayList&lt;&gt;(); protected abstract void start(); protected abstract void stop(); protected abstract void alarm(); protected abstract void engineBoom(); public final void setSequence(List&lt;String&gt; sequence) &#123; this.sequence = sequence; &#125; public final void run() &#123; for (String actionName : sequence) &#123; if (\"start\".equals(actionName)) &#123; this.start(); &#125; else if (\"stop\".equals(actionName)) &#123; this.stop(); &#125; else if (\"alarm\".equals(actionName)) &#123; this.alarm(); &#125; else if (\"engineBoom\".equals(actionName)) &#123; this.engineBoom(); &#125; &#125; &#125;&#125; 车辆模型的具体代码： 12345678910111213141516171819202122232425262728293031323334353637public class BenzModel extends CarModel &#123; @Override protected void start() &#123; System.out.println(\"Benz开动\"); &#125; @Override protected void stop() &#123; System.out.println(\"Benz停车\"); &#125; @Override protected void alarm() &#123; System.out.println(\"Benz鸣笛\"); &#125; @Override protected void engineBoom() &#123; System.out.println(\"Benz发动引擎\"); &#125;&#125;public class BMWModel extends CarModel &#123; @Override protected void start() &#123; System.out.println(\"BMW开动\"); &#125; @Override protected void stop() &#123; System.out.println(\"BMW停车\"); &#125; @Override protected void alarm() &#123; System.out.println(\"BMW鸣笛\"); &#125; @Override protected void engineBoom() &#123; System.out.println(\"BMW发动引擎\"); &#125;&#125; 抽象汽车的组装者： 1234public abstract class CarBuilder &#123; public abstract void setSequence(List&lt;String&gt; seqence); public abstract CarModel getCarModel();&#125; 具体的车的组装者： 1234567891011121314151617181920212223public class BenzBuilder extends CarBuilder &#123; private BenzModel benz = new BenzModel(); @Override public void setSequence(List&lt;String&gt; sequence) &#123; this.benz.setSequence(sequence); &#125; @Override public CarModel getCarModel() &#123; return this.benz; &#125;&#125;public class BMWBuilder extends CarBuilder &#123; private BMWModel bmw = new BMWModel(); @Override public void setSequence(List&lt;String&gt; sequence) &#123; this.bmw.setSequence(sequence); &#125; @Override public CarModel getCarModel() &#123; return this.bmw; &#125;&#125; 场景类的调用： 123456789101112List&lt;String&gt; sequence = new ArrayList&lt;&gt;();sequence.add(\"engineBoom\");sequence.add(\"start\");sequence.add(\"stop\");BenzBuilder benzBuilder = new BenzBuilder();benzBuilder.setSequence(sequence);BenzModel benz = (BenzModel)benzBuilder.getCarModel();benz.run();BMWBuilder bmwBuilder = new BMWBuilder();bmwBuilder.setSequence(sequence);BMWModel bmw = (BMWModel)bmwBuilder.getCarModel();bmw.run(); CarModel及其之类都是产品类，CarBuilder是抽象的建造者，用于规范产品的组建，其子类是具体的建造者，实现抽象类定义的所有，并返回一个组建好的对象。 建造者模式有良好的封装性，使用建造者模式可以使客户端不必知道产品内部组成的细节，建造者是独立的容易扩展，因此也便于控制细节风险，对建造过程逐步细化，而不对其他的模式产生任何影响。 使用场景 相同的方法，不同的执行顺序，产生不同的事件结果时。 多个部件或零件，都可以装配到一个对象中，但是产生的运行结果又不相同时。 产品类非常复杂，或者产品类中的调用顺序不同产生了不同的效能。 在对象创建过程中会使用到系统中的一些其他对象，这些对象在产品对象的创建过程中不易得到时，也可以采用建造者模式封装该对象的创建过程，该种场景只能是一个补偿方法。 与工厂模式的区别建造者模式最主要的功能是基本方法的调用顺序安排，也就是这些基本方法已经实现了，通俗地说就是零件的装配，顺序不同产生的对象也不同；而工厂方法则重点是创建，创建零件是它的主要职责，组装顺序则不是它关心的。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"建造者模式","slug":"建造者模式","permalink":"https://yaoyinglong.github.io/tags/建造者模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/创建型模式/"}]},{"title":"工厂模式","date":"2020-11-02T16:00:00.000Z","path":"Blog/设计模式/创建型模式/工厂模式/","text":"工厂方法模式工厂方法模式使用的频率非常高 ，用于创建对象的接口， 让子类决定实例化哪一个类。 工厂方法使一个类的实例化延迟到其子类 。用于封装和管理对象的创建，是一种创建模式。是典型的解耦框架，在需要灵活的、可扩展的框架时可以采用，可以用在异构项目中，可以使用在测试驱动的开发框架下。 抽象产品类，抽象人种类： 12345public interface Human &#123; void getColor(); void talk();&#125; 具体的产品类可以有多个， 都继承于抽象产品类，具体的人种类： 1234567891011121314151617181920212223242526272829303132333435public class BlackHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(\"黑色人种\"); &#125; @Override public void talk() &#123; System.out.println(\"我是黑色人种\"); &#125;&#125;public class WhiteHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(\"白色人种\"); &#125; @Override public void talk() &#123; System.out.println(\"我是白色人种\"); &#125;&#125;public class YellowHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(\"黄色人种\"); &#125; @Override public void talk() &#123; System.out.println(\"我是黄色人种\"); &#125;&#125; 抽象工厂类负责定义产品对象的产生： 123public abstract class AbstractHumanFactory &#123; public abstract &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz);&#125; 具体如何产生一个产品的对象， 是由具体的工厂类实现的，具体的工厂类： 1234567891011public class HumanFactory extends AbstractHumanFactory &#123; @Override public &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz) &#123; try &#123; return (T) Class.forName(clazz.getName()).newInstance(); &#125; catch (Exception e) &#123; System.out.println(\"人种生成错误\"); &#125; return null; &#125;&#125; 场景类的调用: 12345678910AbstractHumanFactory YinYangLu = new HumanFactory();Human whiteHuman = YinYangLu.createHuman(WhiteHuman.class);whiteHuman.getColor();whiteHuman.talk();Human blackHuman = YinYangLu.createHuman(BlackHuman.class);blackHuman.getColor();blackHuman.talk();Human yellowHuman = YinYangLu.createHuman(YellowHuman.class);yellowHuman.getColor();yellowHuman.talk(); 优点 良好的封装性， 代码结构清晰 良好的扩展性，增加产品类， 只要适当地修改具体的工厂类或扩展一个工厂类 屏蔽产品类，产品类的实现如何变化， 调用者都不需要关心，上层模块不发生变化 典型的解耦框架，高层模块值需要知道产品的抽象类，符合迪米特法则、依赖倒置原则、里氏替换原则 使用场景 需要生成对象的地方都可以使用， 但是需要慎重考虑是否要增加一个工厂类进行管理， 增加代码的复杂度 需要灵活的、 可扩展的框架时 异构项目中，如通过WebService与一个非Java的项目交互 可以使用在测试驱动开发的框架下 扩展工厂方法模式有很多扩展，且与其他模式结合使用威力更大，可将其缩小为简单工厂模式，可升级为多个工厂类，可替代单例模式，可延迟初始化。 缩小为简单工厂模式该模式是工厂方法模式的弱化，简单工厂模式又叫静态工厂模式，仅简单的对不同类对象的创建进行了简单的封装。缺点是工厂类的扩展比较困难， 不符合开闭原则。 简单工厂模式相对于工厂方法模式，去掉了AbstractHumanFactory抽象类， 同时把createHuman方法设置为静态类型， 简化了类的创建过程。 12345678910public class HumanFactory &#123; public static &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz) &#123; try &#123; return (T) Class.forName(clazz.getName()).newInstance(); &#125; catch (Exception e) &#123; System.out.println(\"人种生成错误\"); &#125; return null; &#125;&#125; 场景类的调用: 123456789Human whiteHuman = HumanFactory.createHuman(WhiteHuman.class);whiteHuman.getColor();whiteHuman.talk();Human blackHuman = HumanFactory.createHuman(BlackHuman.class);blackHuman.getColor();blackHuman.talk();Human yellowHuman = HumanFactory.createHuman(YellowHuman.class);yellowHuman.getColor();yellowHuman.talk(); 升级为多个工厂类在相对比较复杂的项目中，经常遇到初始化一个对象很耗费精力的情况，所有产品类都放到一个工厂方法中进行初始化会使代码结构不清晰。为每个产品定义一个创造者， 然后由调用者自己去选择与哪个工厂方法关联。 多工厂模式的工厂抽象类，抽象方法中已经不再需要传递相关参数了， 因为每一个具体的工厂都已经非常明确自己的职责。但也给可扩展性和可维护性带来了一定的影响。 多工厂模式的抽象工厂类： 123public abstract class AbstractHumanFactory &#123; public abstract Human createHuman();&#125; 黑色人种的创建工厂实现： 12345public class BlackHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 黄色人种的创建工厂实现：12345public class YellowHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 白色人种的创建工厂实现：12345public class WhiteHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 场景类的调用: 123456789Human whiteHuman = (new WhiteHumanFactory()).createHuman();whiteHuman.getColor();whiteHuman.talk();Human blackHuman = (new BlackHumanFactory()).createHuman();blackHuman.getColor();blackHuman.talk();Human yellowHuman = (new YellowHumanFactory()).createHuman();yellowHuman.getColor();yellowHuman.talk(); 在复杂的应用中一般采用多工厂的方法， 然后再增加一个协调类， 避免调用者与各个子工厂交流， 协调类的作用是封装子工厂类， 对高层模块提供统一的访问接口。 替代单例模式通过获得类构造器， 然后设置访问权限， 生成一个对象， 然后提供外部访问， 保证内存中的对象唯一。 通过工厂方法模式创建了一个单例对象， 该框架可以继续扩展， 在一个项目中可以产生一个单例构造器， 所有需要产生单例的类都遵循一定的规则 ， 然后通过扩展该框架。 12345678910111213141516171819202122232425public class Singleton &#123; private Singleton() &#123;&#125; public void doSomething() &#123;&#125;&#125;public class SingletonFactory &#123; private static Singleton singleton; static&#123; try &#123; Class cl= Class.forName(Singleton.class.getName()); // 获得无参构造 Constructor constructor = cl.getDeclaredConstructor(); // 设置无参构造是可访问的 constructor.setAccessible(true); // 产生一个实例对象 singleton = (Singleton)constructor.newInstance(); &#125; catch (Exception e) &#123; // 异常处理 &#125; &#125; public static Singleton getSingleton()&#123; return singleton; &#125;&#125; 延迟初始化一个对象被消费完后，并不立即释放，工厂类保持其初始状态，等待再次被调用。 12345678910111213141516171819public class ProductFactory &#123; private static final Map&lt;String, Human&gt; humanMap = new HashMap&lt;&gt;(); public static synchronized Human createHuman(String type) throws Exception &#123; Human human; if (humanMap.containsKey(type)) &#123; human = humanMap.get(type); &#125; else &#123; if (type.equals(\"BlackHuman\")) &#123; human = new BlackHuman(); &#125; else if (type.equals(\"WhiteHuman\")) &#123; human = new WhiteHuman(); &#125; else &#123; human = new YellowHuman(); &#125; humanMap.put(type, human); &#125; return human; &#125;&#125; 延迟加载框架是可扩展的， 例如限制某一个产品类的最大实例化数量， 可以通过判断Map中已有的对象数量来实现，还可以用在对象初始化比较复杂的情况下， 例如硬件访问， 涉及多方面的交互， 则可以通过延迟加载降低对象的产生和销毁带来的复杂性。 抽象工厂模式抽象工厂模式是一种比较常用的模式，为创建一组相关或相互依赖的对象提供一个接口， 且无须指定它们的具体类。 当一个对象族有相同的约束时可以使用抽象工厂模式。 优点封装性，产品的具体实现细节高层模块不需要关心；产品族内的约束为非公开状态。缺点产品族扩展非常困难，严重违反开闭原则。 抽象工厂模式是工厂方法模式的升级版， 在有多个业务品种、 业务分类时， 通过抽象工厂模式产生需要的对象是一种非常好的解决方式。 人种接口： 12345public interface Human &#123; void getColor(); void talk(); void getSex();&#125; 人种有三个抽象类， 负责人种的抽象属性定义： 1234567891011121314151617181920212223242526272829303132333435public abstract class AbstractBlackHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(\"黑色人种\"); &#125; @Override public void talk() &#123; System.out.println(\"我是黑色人种\"); &#125;&#125;public abstract class AbstractWhiteHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(\"白色人种\"); &#125; @Override public void talk() &#123; System.out.println(\"我是白色人种\"); &#125;&#125;public abstract class AbstractYellowHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(\"黄色人种\"); &#125; @Override public void talk() &#123; System.out.println(\"我是黄色人种\"); &#125;&#125; 每个抽象类都有两个实现类， 分别实现公共的最细节、 最具体的事物： 123456789101112public class FemaleYellowHuman extends AbstractYellowHuman &#123; @Override public void getSex() &#123; System.out.println(\"黄种女人\"); &#125;&#125;public class MaleYellowHuman extends AbstractYellowHuman &#123; @Override public void getSex() &#123; System.out.println(\"黄种男人\"); &#125;&#125; 制造人类的抽象工厂类： 12345public interface HumanFactory &#123; Human createYellowHuman(); Human createWhiteHuman(); Human createBlackHuman();&#125; 制造男人和女人的具体工厂类： 123456789101112131415161718192021222324252627282930313233public class FemaleFactory implements HumanFactory &#123; @Override public Human createYellowHuman() &#123; return new FemaleYellowHuman(); &#125; @Override public Human createWhiteHuman() &#123; return new FemaleWhiteHuman(); &#125; @Override public Human createBlackHuman() &#123; return new FemaleBlackHuman(); &#125;&#125;public class MaleFactory implements HumanFactory &#123; @Override public Human createYellowHuman() &#123; return new MaleYellowHuman(); &#125; @Override public Human createWhiteHuman() &#123; return new MaleWhiteHuman(); &#125; @Override public Human createBlackHuman() &#123; return new MaleBlackHuman(); &#125;&#125; 场景类的调用: 12345678910HumanFactory maleHumanFactory = new MaleFactory();HumanFactory femaleHumanFactory = new FemaleFactory();Human maleYellowHuman = maleHumanFactory.createYellowHuman();Human femaleYellowHuman = femaleHumanFactory.createYellowHuman();femaleYellowHuman.getColor();femaleYellowHuman.talk();femaleYellowHuman.getSex();maleYellowHuman.getColor();maleYellowHuman.talk();maleYellowHuman.getSex();","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"工厂模式","slug":"工厂模式","permalink":"https://yaoyinglong.github.io/tags/工厂模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/创建型模式/"}]},{"title":"模板方法模式","date":"2020-11-02T16:00:00.000Z","path":"Blog/设计模式/行为型模式/模板方法模式/","text":"模板方法模式非常简单应用非常广泛的模式，定义一个操作中的算法框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 AbstractClass叫做抽象模板，其方法分为基本方法和模板方法两类。基本方法也叫做基本操作，由子类实现的方法，且在模板方法中被调用。模板方法可以有一个或几个，用于实现对基本方法的调度，完成固定的逻辑。为了防止恶意操作，一般模板方法都使用final关键之修饰，防止被覆盖。 抽象模板类： 1234567891011public abstract class AbstractPerson &#123; public final void prepareGotoSchool()&#123; derssUp(); eatBreakfast(); tackThings(); &#125; protected abstract void derssUp(); protected abstract void eatBreakfast(); protected abstract void tackThings();&#125; 具体的模板类： 1234567891011121314151617181920212223242526272829public class Student extends AbstractPerson&#123; @Override protected void derssUp() &#123; System.out.println(\"穿衣服\"); &#125; @Override protected void eatBreakfast() &#123; System.out.println(\"吃妈妈做的早餐\"); &#125; @Override protected void tackThings() &#123; System.out.println(\"背书包，带上家庭作业和红领巾\"); &#125;&#125;public class Teacher extends AbstractPerson&#123; @Override protected void derssUp() &#123; System.out.println(\"穿工作服\"); &#125; @Override protected void eatBreakfast() &#123; System.out.println(\"做早饭，照顾孩子吃早饭\"); &#125; @Override protected void tackThings() &#123; System.out.println(\"带上昨天晚上准备的考卷\"); &#125;&#125; 场景类的调用: 1234Student student = new Student();student.prepareGotoSchool();Teacher teacher = new Teacher();teacher.prepareGotoSchool(); 抽象模板中的基本方法尽量设计为protected类型，符合迪米特法则，不需要暴露的属性或方法尽量不要设置为protected类型。实现类若非必要，尽量不要扩大父类中的访问权限。 模板方法模式可封装不变部分，扩展可变部分；可提取公共部分代码，便于维护；行为由父类控制，子类实现。但一般的设计习惯，抽象类负责声明最抽象、最一般的事物属性和方法，实现类完成具体的事物属性和方法。但是模板方法模式却颠倒了，抽象类定义了部分抽象方法，由子类实现，子类执行的结果影响了父类的结果，也就是子类对父类产生了影响，在复杂的项目中，会带来代码阅读的难度。 使用场景 多个子类有公有的方法，且逻辑基本相同时 重要、复杂的算发，可以把核心算法设计为模板方法，周边的相关细节功能由各个子类实现 重构时，模板方法模式时一个经常使用的模式，把相同的代码抽取到父类中，然后通过钩子函数约束其行为 在Spring源码中refresh()就是典型的模板方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public interface ConfigurableApplicationContext extends ApplicationContext, ifecycle, Closeable &#123; void refresh() throws BeansException, IllegalStateException;&#125;public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; @Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; StartupStep contextRefresh = this.applicationStartup.start(\"spring.context.refresh\"); // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(\"spring.context.beans.post-process\"); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); contextRefresh.end(); &#125; &#125; &#125;&#125; JDK中HashMap、Map、AQS中都有用到模板方法设计模式。 12345678910111213// AQS中用到的模板方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// JDK8 Map中的模板方法default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key)) ? v : defaultValue;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"模板方法模式","slug":"模板方法模式","permalink":"https://yaoyinglong.github.io/tags/模板方法模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/行为型模式/"}]},{"title":"锁优化","date":"2020-10-29T16:00:00.000Z","path":"Blog/Java/并发/锁优化/","text":"高效并发是从JDK1.5到JDK1.6的一个重要改进，HotSpot虚拟机为了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率在该版本上花费了大量精力去实现各种锁优化技术，如适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等。 自旋锁与自适应自旋互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这会给操作系统的并发性能带来很大的压力。在许多应用上，共享数据的锁定状态只会持续很短一段时间，为了这段时间去挂起和恢复线程并不值得。 两个或以上的线程同时并行执行，可以让后面请求锁的那个线程不放弃处理器执行时间，而是执行一个忙循环，也就是所谓的自旋，看看持有锁的线程是否会很快就释放锁，这项技术就是所谓的自旋锁。 自旋锁在JDK1.4.2中引入但默认关闭，使用-XX:UseSpinning参数开启，JDK1.6默认开启自旋锁。自旋等待不能代替阻塞，自旋等待本身虽然避免了线程切换的开销，但还是要占用处理器时间，若锁被占用的时间很短，自旋等待的效果会非常好，若锁被占用的时间很长，自旋等待的线程只会白白消耗处理器资源，反而带来性能上的浪费。 自旋等待的时间是有一定的限度，若自旋超过了限定的次数仍然没有成功获得锁，就使用传统的方式挂起线程。自旋次数默认为10次，可使用参数-XX:PreBlockSpin来更改。 JDK1.6引入了自适应的自旋锁，自适应意味着自旋的时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。若在同一个锁对象上，上一次是通过自旋等待获得的锁，且持有锁的线程正在运行中，则虚拟机将认为这次自旋锁也很有可能再次成功，进而它将运行自旋等待持续相对更长的时间。且若对于某个锁，通过自旋的方式很少成功获得过锁，则在以后要获取该锁时将可能省略自旋过程，以避免浪费处理器资源。 锁消除锁的消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但被检测到不可能存在共享数据竞争的锁进行消除。锁消除主要判定依据来源于逃逸分析的数据支持，若判断在一段代码中，堆上所有数据都不会逃逸出去从而被其他线程访问到，即可以将其当做栈上数据对待，认为其是私有的，即可进行锁消除。 123456private void method1() &#123; Object object1 = new Object(); synchronized (object1) &#123; System.out.println(); &#125;&#125; Java中有许多同步措施并不是程序员自己加入的，且同步代码在Java中是普遍存在的。例如最简单的String字符串的相加，由于String是不可变的类，在JDK1.5后将转化为StringBuilder对象的连续append操作，而每个append方法中都有一个同步块。 逃逸分析若一个对象被发现只能从一个线程被访问到，则该对象的操作可以不考虑同步，将堆分配转化为栈分配。若一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配。分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，则对象的部分或全部可以不存储在内存，而是存储在CPU寄存器中。 锁粗化原则上总是推荐将同步块的作用范围限制得尽可能小，即只在共享数据的实际作用域中才进行同步，是为了使得需要同步得操作数量尽可能小，当存在竞争时，等待锁的线程也能尽可能快的拿到锁。 但若一系列连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中，即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。 如连续的StringBuilder的append方法，若虚拟机检查到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步得范围粗化到整个操作序列的外部。连续的StringBuilder的append操作会扩展到第一个append操作之前直到最后一个append操作之后，这样加一次锁即可。 轻量级锁传统的锁机制成为重量级锁，轻量级是相对于使用操作系统互斥量来实现的传统锁而言的，是JDK1.6加入的新型锁机制。轻量级锁并不是用来代替重量级锁的，其本意是在没有多线程竞争的前提下，减少重量级锁使操作系统互斥量产生的性能消耗。 对象头中用于存储对象自身的运行时数据信息是实现轻量级锁和偏向锁的关键，官方称为Mark Word。对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的信息，它会根据对象的状态复用自己的存储空间。 在32位HotSpot虚拟机中， 对象未被锁定的状态下，Mark Word的32比特空间里的25比特将用于存储对象哈希码， 4比特用于存储对象分代年龄， 2比特用于存储锁标志位， 1比特固定为0表示未进入偏向模式。 对象除了未被锁定的正常状态外， 还有轻量级锁定、 重量级锁定、 GC标记、 可偏向等几种不同状态 。 代码即将进入同步块时， 若锁标志位为01状态即同步对象没有被锁定 ， 虚拟机首先将在当前线程的栈帧中建立一个名为Lock Record锁记录 的空间， 用于存储锁对象目前的Mark Word的拷贝，官方将该拷贝称为Displaced Mark Word 。 虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。 若更新成功， 即代表该线程拥有了该对象的锁， 且对象Mark Word的锁标志位将转变为00， 表示此对象处于轻量级锁定状态。此时线程堆栈与对象头的状态如下： 若更新失败， 意味着至少存在一条线程与当前线程竞争获取该对象的锁。 虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧， 若是则说明当前线程已经拥有了该对象的锁， 则直接进入同步块， 否则说明该锁对象已经被其他线程抢占。 若出现两条以上的线程争用同一个锁， 则轻量级锁不再有效， 必须要膨胀为重量级锁， 锁标志的状态值变为10， 此时Mark Word中存储的就是指向重量级锁（互斥量） 的指针， 等待锁的线程也必须进入阻塞状态。 轻量级锁解锁过程也同样是通过CAS操作来进行， 若对象的Mark Word仍然指向线程的锁记录， 则用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来。 若能成功替换， 则整个同步过程顺利完成； 若替换失败， 则说明有其他线程尝试过获取该锁， 就要在释放锁的同时， 唤醒被挂起的线程。 轻量级锁能提升程序同步性能的依据：对于绝大部分的锁， 在整个同步周期内都不存在竞争，这一经验法则。若没有竞争， 轻量级锁便通过CAS操作成功避免了使用互斥量的开销； 但如果确实存在锁竞争， 除了互斥量的本身开销外， 还额外发生了CAS操作的开销。 因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢 。 偏向锁偏向锁是JDK1.6引入的一项锁优化措施， 其目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。 若说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量， 偏向锁就是在无竞争的情况下把整个同步都消除掉。 偏向锁的意思是锁会偏向于第一个获得它的线程， 若在接下来的执行过程中， 该锁一直没有被其他的线程获取， 则持有偏向锁的线程将永远不需要再进行同步。 若虚拟机启用了偏向锁， 则当锁对象第一次被线程获取时， 虚拟机将把对象头中的标志位设置为01、 把偏向模式设置为1， 表示进入偏向模式。 同时使用CAS操作把获取到该锁的线程的ID记录在对象的Mark Word中。 若CAS操作成功， 持有偏向锁的线程以后每次进入该锁相关的同步块时， 虚拟机都可以不再进行任何同步操作 。偏向锁启用参数-XX：+UseBiasedLocking。 一旦出现另外一个线程去尝试获取该锁， 偏向模式立即结束。 根据锁对象目前是否处于被锁定的状态决定是否撤销偏向 ， 撤销后标志位恢复到未锁定或轻量级锁定的状态， 后续的同步操作按照轻量级锁执行。 当对象进入偏向状态时， Mark Word大部分的空间（23个比特） 都用于存储持有锁的线程ID了， 这部分空间占用了原有存储对象哈希码的位置 。 Java中对象如果计算过哈希码， 就应该一直保持该值不变 ，否则很多依赖对象哈希码的API都可能存在出错风险。 而作为绝大多数对象哈希码来源的Object::hashCode()方法， 返回的是对象的一致性哈希码， 该值是能强制保证不变的， 它通过在对象头中存储计算结果来保证第一次计算之后， 再次调用该方法取到的哈希码值永远不会再发生改变。 因此当一个对象已经计算过一致性哈希码后， 则再也无法进入偏向锁状态了； 而当一个对象当前正处于偏向锁状态， 又收到需要计算其一致性哈希码请求时， 其偏向状态会被立即撤销， 且锁会膨胀为重量级锁。 在重量级锁的实现中， 对象头指向了重量级锁的位置， 代表重量级锁的ObjectMonitor类里有字段可以记录非加锁状态下的Mark Word， 其中自然可以存储原来的哈希码。 偏向锁可以提高带有同步但无竞争的程序性能， 但同样是一个带有效益权衡性质的优化，也就是说它并非总是对程序运行有利。 若程序中大多数锁都总是被多个不同的线程访问， 偏向模式则是多余的。 锁的膨胀升级过程偏向锁的启动是在启动几秒之后才激活，因为jvm启动的过程中会有大量的同步块，且这些同步块都有竞争，若一启动就启动偏向锁，会出现很多没有必要的锁撤销。 12345678910111213141516171819202122232425262728public static void main(String[] args) throws InterruptedException &#123; Object a = new Object(); Thread thread1 = new Thread(() -&gt; &#123; synchronized (a) &#123; System.out.println(\"thread1 locking\"); System.out.println(ClassLayout.parseInstance(a).toPrintable()); try &#123; //让线程晚点儿死亡，造成锁的竞争 Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; synchronized (a) &#123; System.out.println(\"thread2 locking\"); System.out.println(ClassLayout.parseInstance(a).toPrintable()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); thread1.start(); thread2.start();&#125; 从结果很明显看到对象的锁升级成了重量级锁： 123456789101112131415161718java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 3a 02 43 25 (00111010 00000010 01000011 00100101) (625148474) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totalthread2 lockingjava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 3a 02 43 25 (00111010 00000010 01000011 00100101) (625148474) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total","tags":[{"name":"多线程","slug":"多线程","permalink":"https://yaoyinglong.github.io/tags/多线程/"},{"name":"Thread","slug":"Thread","permalink":"https://yaoyinglong.github.io/tags/Thread/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"序列化","date":"2020-10-26T16:00:00.000Z","path":"Blog/Java/基础/序列化/","text":"","tags":[{"name":"序列化","slug":"序列化","permalink":"https://yaoyinglong.github.io/tags/序列化/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"注解实现及应用","date":"2020-10-25T16:00:00.000Z","path":"Blog/Java/基础/注解实现及应用/","text":"注解一种标记式高耦合的配置方式，Java注解是从JDK1.5引入的。注解用于为Java代码提供元数据。作为元数据注解不直接影响代码执行。注解的本质就是一个Annotation接口。 123456789public interface Annotation &#123; boolean equals(Object obj); int hashCode(); String toString(); Class&lt;? extends Annotation&gt; annotationType();&#125; 注解本身就是Annotation接口的子接口，注解中其实可以有属性和方法，但接口中属性和方法都是static fianl的，对于注解没有意义，而定义接口的方法就相当于注解的属性，也就是为什么说注解只有成员变量，其实其就是接口的方法，也就是为什么成员变量会有括号。 注解属性类型可以有一下几种类型： 基本数据类型 String 枚举类型 注解类型 Class类型 以上类型的一维数组类型 元注解作用于注解的注解，JDK提供的元注解有@Retention、@Target、@Documented、@Inherited以及JDK8新增的@Repeatable五种。 @Retention表示注解存在阶段是保留在源码（编译期），字节码（类加载）或者运行期（JVM中运行），在@Retention注解中使用枚举RetentionPolicy来表示注解的生命周期。 @Retention(RetentionPolicy.SOURCE)，注解仅存在于源码中，在class字节码文件中不包含。 @Retention(RetentionPolicy.CLASS)， 默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得。 @Retention(RetentionPolicy.RUNTIME)， 注解会在class字节码文件中存在，在运行时可以通过反射获取。 若自定义注解，自定义注解如果只存着源码中或者字节码文件中就无法发挥作用，而在运行期间能获取到注解才能实现我们目的，所以自定义注解中肯定是使用 @Retention(RetentionPolicy.RUNTIME)。 12345678910@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Retention &#123; /** * Returns the retention policy. * @return the retention policy */ RetentionPolicy value();&#125; @Target表示注解的作用目标，作用范围可以是类、方法、方法参数等，通过枚举类ElementType表达作用类型。 @Target(ElementType.TYPE) 作用接口、类、枚举、注解 @Target(ElementType.FIELD) 作用属性字段、枚举的常量 @Target(ElementType.METHOD) 作用方法 @Target(ElementType.PARAMETER) 作用方法参数 @Target(ElementType.CONSTRUCTOR) 作用构造函数 @Target(ElementType.LOCAL_VARIABLE)作用局部变量 @Target(ElementType.ANNOTATION_TYPE)作用于注解（@Retention注解中就使用该属性） @Target(ElementType.PACKAGE) 作用于包 @Target(ElementType.TYPE_PARAMETER) 作用于类型泛型，即泛型方法、泛型类、泛型接口 （JDK8加入） @Target(ElementType.TYPE_USE) 类型使用，可以用于标注任意类型除了 class （JDK8加入） 12345678910@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Retention &#123; /** * Returns the retention policy. * @return the retention policy */ RetentionPolicy value();&#125; @Documented其作用是能够将注解中的元素包含到 Javadoc 中去。 @Inherited被@Inherited注解了的注解修饰了一个父类，若其子类没有被其他注解修饰，则其子类也继承了父类的注解。 @Repeatable被该元注解修饰的注解可以同时作用一个对象多次，但是每次作用注解又可以代表不同的含义。 1234567891011121314151617181920212223@Documented@Retention(value = RetentionPolicy.RUNTIME)@Target(value = ElementType.METHOD)public @interface Prople &#123; Game[] value();&#125;@Documented@Repeatable(Prople.class)@Target(value = ElementType.METHOD)@Retention(value = RetentionPolicy.RUNTIME)public @interface Game &#123; String value() default \"\";&#125;public class PlayGame &#123; @Game(value = \"LOL\") @Game(value = \"PUBG\") @Game(value = \"NFS\") @Game(value = \"Dirt4\") public void play() &#123; &#125;&#125; 注解属性注解的属性与类中定义的变量有异曲同工之处，注解中的变量都是成员变量，并且注解中是没有方法的，只有成员变量，变量名就是使用注解括号中对应的参数名，变量返回值就是使用注解括号中对应参数类型。 @Repeatable注解中的变量则类型则是对应Annotation（接口）的泛型Class。 1234567891011@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Repeatable &#123; /** * Indicates the &lt;em&gt;containing annotation type&lt;/em&gt; for the * repeatable annotation type. * @return the containing annotation type */ Class&lt;? extends Annotation&gt; value();&#125; JDK内置注解JDK预定义了@Override、@Deprecated、@SuppressWarnings三种注解。 12345678910111213141516@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override &#123;&#125;@Documented@Retention(RetentionPolicy.RUNTIME)@Target(value=&#123;CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE&#125;)public @interface Deprecated &#123;&#125;@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings &#123; String[] value();&#125; 应用若注解有多个属性，给属性赋值时使用逗号隔开分别赋值。 1234567891011121314@Documented@Inherited@Retention(value = RetentionPolicy.RUNTIME)@Target(value = ElementType.TYPE)public @interface InvokeListener &#123; String name() default \"baseService\"; int weight() default 25;&#125;@InvokeListener(name = \"taskService\", weight = 50)public class TaskServiceImpl implements TaskService &#123; @FieldListener(value = \"baseTask\") private String taskName;&#125; 在自定义注解后在使用时通常需要获取注解的属性，需要通过反射的方式获取。获取类注解属性： 1234567Class&lt;TaskServiceImpl&gt; taskServiceClass = TaskServiceImpl.class;boolean annotationPresent = taskServiceClass.isAnnotationPresent(InvokeListener.class);if (annotationPresent) &#123; InvokeListener annotation = taskServiceClass.getAnnotation(InvokeListener.class); System.out.println(annotation.name()); System.out.println(annotation.weight());&#125; 获取方法注解属性： 12345678Method play = PlayGame.class.getDeclaredMethod(\"play\");if (play != null) &#123; People annotation = play.getAnnotation(People.class); Game[] value = annotation.value(); for (Game game : value) &#123; System.out.println(game.value()); &#125;&#125; 获取属性注解属性： 1234567Class&lt;TaskServiceImpl&gt; taskServiceClass = TaskServiceImpl.class;Field field = taskServiceClass.getDeclaredField(\"taskName\");boolean annotationPresent = field.isAnnotationPresent(FieldListener.class);if (annotationPresent) &#123; FieldListener annotation = field.getAnnotation(FieldListener.class); System.out.println(annotation.value());&#125; 在Spring中使用自定义注解 123456789101112131415161718192021222324public class ListenerConfig implements ApplicationContextAware &#123; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; Map&lt;String, Object&gt; beanMap = applicationContext.getBeansWithAnnotation(InvokeListener.class); for (Object bean : beanMap.values()) &#123; Field[] fields = bean.getClass().getDeclaredFields(); for (Field field : fields) &#123; FieldListener fieldListener = field.getAnnotation(FieldListener.class); if (fieldListener != null) &#123; System.out.println(fieldListener.value()); &#125; &#125; Method[] methods = bean.getClass().getMethods(); for (Method method : methods) &#123; MethodListener methodListener = method.getAnnotation(MethodListener.class); if (methodListener != null) &#123; System.out.println(methodListener.value()); &#125; &#125; &#125; &#125; &#125;","tags":[{"name":"注解","slug":"注解","permalink":"https://yaoyinglong.github.io/tags/注解/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"Java与线程","date":"2020-10-20T16:00:00.000Z","path":"Blog/Java/并发/Java与线程/","text":"线程的实现线程是CPU调度的基本单位，是比进程更轻量级的调度执行单位，线程可以把进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O），又可以独立调度。 主流操作系统都提供了线程实现，Java提供了在不同硬件和操作系统平台下对线程操作的统一处理，每个已经执行start()且还未结束的Thread类的实例代表一个线程。且Thread类所有关键方法都被声明为Native。在Java中Native方法意味着该方法没有使用或无法使用平台无关的手段实现，也可能为了执行效率而使用Native方法，通常最高效的手段是平台相关的手段。 实现线程主要有3种方式：使用内核线程实现、使用用户线程实现、使用用户线程加轻量级进程混合实现 使用内核实现KTL内核线程是直接由操作系统内核直接支持的线程，由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可视为内核的一个分身。 程序一般不会使用内核线程，而是去使用内核线程的一种高级接口轻量级进程LWP。轻量级进程就是通常意义上所说的线程，每个轻量级进程都由一个内核线程支持，这种关系称为一对一线程模型。 每个轻量级进程都成为一个独立的调度单元，但轻量级进程具有局限性，由于是基于内核线程实现的，故各种线程操作都需要进行系统调用。而系统调用的代价相对较高，需要在用户态和内核态中来回切换。每个轻量级进程都需要一个内核线程支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的。 使用用户线程实现广义上讲一个线程只要不是内核线程，就可以认为是用户线程，因此轻量级进程也属于用户线程，但轻量级进程始终是建立在内核之上的，许多操作系统都要进行系统调用，效率会受限。 狭义上讲用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核帮助。若程序实现得当，这种线程不需要切换到内核态，因此操作可以非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间的1：N的关系称为一对多的线程模型。 用户线程优势在于不需要系统内核支援，劣势在于没有系统内核支援，所有线程操作都需要使用用户程序自己处理。由于操作系统只把处理器资源分配到进程，诸如阻塞处理、多处理器系统将线程映射到其他处理器上这类为题解决起来异常困难，甚至不可能完成。现在使用用户线程的程序越来越少了，Java曾经使用过用户线程但最终放弃了。 使用用户线程加轻量级进程混合实现还可以将内核线程与用户线程一起使用，在这种混合实现下，既存在用户线程，也存在轻量级进程。 用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，且支持大规模的用户线程并发。操作系统提供的轻量级进程作为用户线程和内核线程之间的桥梁，通过轻量级进程使用内核提供的线程调度功能及处理器映射，且用户线程的系统调用要通过轻量级进程来完成，大大降低了整个进程被完全阻塞的风险。这种混合模式中，用户线程与轻量级进程的数量比是不固定的。 Java线程的实现JDK1.2之前是基于用户线程实现的，JDK1.2中线程模型替换为基于操作系统原生线程模型来实现。Sun JDK的Windows版与Linux版都是使用一对一的线程模型实现的，一条Java线程就映射到一条轻量级进程中。 由于Solaris平台中操作系统的线程特性可同时支持一对一和多对多的线程模型。因此Solaris版的JDK中对应提供了两个平台专有的虚拟机参数-XX:+UseLWPSynchronization和-XX:UseBoundThreads来明确指定虚拟机使用哪种线程模型。 Java线程调度线程调度是指操作系统为线程分配处理器使用权的过程，主要有协同式线程调度和抢占式线程调度两种调度方式。Java使用的是抢占式线程调度。 使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完后，要主动通知系统切换到另一个线程上。优点是实现简单，切换操作对线程自己是可知的，没有线程同步问题。缺点是线程执行时间不可控。 使用抢占式调度的多线程系统，线程将由系统来分配执行时间，线程的切换不由线程本身来决定，Thread.yield()可以让出执行时间，但线程没办法主动获取执行时间。优点线程执行时间可控，不会产生由一个线程导致整个进程阻塞。 虽然Java线程调度是由系统自动来完成，但可通过设置线程优先级来给系统建议给某些线程多分配或少分配一点执行时间。Java中一共设置了10个级别的线程优先级，两个线程同时处于Ready状态时，优先级越高的线程越容易被系统选择执行。 但线程优先级并不靠谱，因为Java线程是映射到系统原生线程上来实现的，最终线程调度还是取决于操作系统，虽然很多系统都提供线程优先级的概念，但并不一定能与Java线程优先级一一对应，且优先级可能被系统自动改变。 状态转换Java定义了五种线程状态，在任意时间点，一个线程只能有且只有其中一种状态。 新建（New）：创建后未启动的线程处于该状态 运行（Runable）：包括了操作系统线程状态中的Running和Ready，处于次状态的线程有可能正在执行，也可能在等待CPU为他分配执行时间。 无限期等待（Waiting）：该状态下线程不会被CPU分配执行时间，它们要等待被其他线程显式地唤醒。产生： 没有设置Timeout参数的Object.wait()方法 没有设置Timeout参数的Thread.join()方法 LockSupport.park()方法 限期等待（Timed Waiting）：不会被CPU分配执行时间，无需等待被其他线程显式唤醒，在一定时间之后会由系统自动唤醒。产生： Thread.sleep()方法 设置了Timeout参数的Object.wait()方法 设置了Timeout参数的Thread.join()方法 LockSupport.parkNanos()方法 LockSupport.parkUntil()方法 阻塞（Blocked）：等待获取到一个排他锁，该事件将在另一个线程放弃这个锁时发生； 结束（Terminated）：线程已结束执行。","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"Synchronized总结","date":"2020-10-20T16:00:00.000Z","path":"Blog/Java/并发/Synchronized总结/","text":"所有的并发模式在解决线程安全问题时，采用的方案都是序列化访问临界资源。即同一时刻只能有一个线程访问临界资源，也称作同步互斥访问。 Java提供synchronized和Lock两种方式来实现同步互斥访问。 synchronized内置锁是一种对象锁，锁的是对象而非引用，作用粒度是对象，可用来实现对临界资源的同步互斥访问，是可重入的，是Java中解决并发问题的一种最常用最简单的方法，它可以确保线程互斥的访问同步代码，保证方法或者代码块在运行时，同一时刻只有一个方法可以进入到临界区，同时它还可以保证共享变量的内存可见性。 原理虚拟机支持方法级的同步和方法内部一段指令序列的同步，两种同步都使用管程Monitor来支持的。 方法级的同步是隐式的，无须通过字节码指令来控制，它实现在方法调用和返回操作之中。虚拟机可以从方法常量池的方法结构中的ACC_SYNCHRONIZED访问标志得知方法是否声明为同步方法。当方法调用时，调用的指令将会检查方法的ACC_SYNCHRONIZED访问标志是否被设置，若被设置，执行线程就要求先成功持有管程Monitor，然后才能执行方法，最后当方法执行完成，无论是否正常完成释放管程Monitor，方法执行期间，执行线程持有了管程Monitor，其他任何线程都无法再获得同一个管程Monitor。若同步方法执行期间抛出异常，且方法内部无法处理异常，同步方法所持有的管程Monitor将在异常抛到同步方法外时自动释放。 Monitor监视器锁的实现依赖底层操作系统的Mutex lock互斥锁实现，是一个重量级锁性能较低。Java1.5之后版本做了重大的优化，如锁粗化、锁消除、轻量级锁、偏向锁、适应性自旋等技术来减少锁操作的开销。 12345678910111213public synchronized void method() &#123; System.out.println(\"Synchronized\");&#125;// 编译后的具体信息public synchronized void method(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String Synchronized 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return 同步一段指令集序列通常是通过synchronized语句块来完成，虚拟机的指令集使用monitorenter和monitorexit两条指令来支持synchronized关键字的语义，正确实现synchronized关键字需要Javac编译器和Java虚拟机共同协作支持，编译器必须保证方法通过任何方式完成，方法中调用过的每条monitorenter指令都必须执行其对应的monitorexit指令，无论该方法是否正常结束。 为了保证方法异常完成时monitorenter和monitorexit指令能正确配对执行，编译器会自动产生一个异常处理器，且声明可处理的所有异常，来执行monitorexit指令。 monitorenter和monitorexit这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。若synchronized明确指定了对象参数，那就是这个对象的reference，若没有明确指定，就根据synchronized修饰的是实例方法还是类方法，则取对应的对象实例或Class对象来作为锁对象。 monitorexit指令出现了两次，第1次为同步正常退出释放锁；第2次为发生异常退出释放锁；wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException异常。 虚拟机规范要求，执行monitorenter指令时，首先尝试获取对象的锁，若对象没有被锁定或当前线程已经拥有这个对象的锁，将锁的计数器加一，执行monitorexit指令时将锁计数器减一，当计数器为零时锁被释放。若获取对象锁失败，当前线程阻塞等待，直到对象锁被另一个线程释放。 12345678910111213141516171819202122232425262728public void method() &#123; synchronized (this) &#123; System.out.println(\"Synchronized\"); &#125;&#125;// 编译后的具体信息public void method(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String Synchronized 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit 20: aload_2 21: athrow 22: return synchronized同步块对同一线程是可重入的，不会将自己死锁，但不可中断。同步块在已进入的线程执行完成之前，会阻塞后面其他线程的进入。Java线程是映射到操作系统原生线程上的，阻塞或唤醒线程都需要操作系统帮忙，需要从用户状态转换到核心态中，因此转态转换需要耗费很多处理器时间。 12345678910private final static Object object = new Object();public static void reentrantlock()&#123; String tname = Thread.currentThread().getName(); synchronized (object) &#123; System.out.println(String.format(\"&#123;&#125;:) hold &#123;&#125;-&gt;monitor lock\",tname,object)); synchronized (object)&#123; System.out.println(String.format(\"&#123;&#125;:) re-hold &#123;&#125;-&gt;monitor lock\",tname,object)); &#125; &#125;&#125; 对象头MarkWord锁标识位为10，其中指针指向的是Monitor对象的起始地址，Monitor是由ObjectMonitor实现的，其位于HotSpot虚拟机源码ObjectMonitor.hpp文件。 wait与notifywait和notify都是Object的成员函数，因为synchronized关键字可以加在任何对象的成员函数上，任何对象都可以成为锁，所以wait和notify只能放在Object里面。 wait内部会先释放锁，然后进入阻塞状态，当被另一个线程notify后，重新拿锁，在执行后续逻辑。 对于生产者消费者模型来说，由于wait和notify所作用对象和synchronized作用的对象是同一个，只能是一个对象，无法区分队列空或队列满两个条件。 使用场景Java中使用synchronized可使用在代码块和方法中，synchronized用的位置不同锁得对象就不同。 分类 被锁对象 实例 实例方法 类得实例对象 public synchronized void sync1() {} 静态方法 类对象 public static synchronized void sync2() {} 实例对象 类得实例对象 synchronized (this) {} class对象 类对象 synchronized (SynchronizedDemo.class) {} 任意实例对象Object 实例对象Object String lock = &quot;&quot;; synchronized (lock) {} 当一个线程访问某对象的synchronized方法或者synchronized代码块时，其他线程对该对象的该synchronized方法或者synchronized代码块的访问将被阻塞；其他线程仍可以访问该对象的非同步代码块；其他线程对该对象的其他的synchronized方法或者synchronized代码块的访问将被阻塞。 123456789public static void main(String[] args) &#123; SynchronizedDemo instance = new SynchronizedDemo(); Thread thread1 = new Thread(instance, \"thread1\"); Thread thread2 = new Thread(instance, \"thread2\"); thread1.start(); thread2.start(); while (thread1.isAlive() || thread2.isAlive()) &#123; &#125;&#125; 同步代码块锁的对象是括号里面的this对象 1234567891011121314public class SynchronizedDemo implements Runnable &#123; @Override public void run() &#123; synchronized (this) &#123; System.out.println(\"I am \" + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" 运行结束\"); &#125; &#125;&#125; 最终打印结果如下，可以很明显的看出run方法里的代码是顺序执行。 1234I am thread1thread1 运行结束I am thread2thread2 运行结束 如下写法运行结果一样，除了使用this对象作为锁，也可以定义一个专门的锁对象。 123456789101112131415public class SynchronizedDemo implements Runnable &#123; private Object lock = new Object(); @Override public void run() &#123; synchronized (lock) &#123; System.out.println(\"I am \" + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" 运行结束\"); &#125; &#125;&#125; 可以定义多个锁对象 12345678910111213141516171819202122232425public class SynchronizedDemo implements Runnable &#123; private Object lock1 = new Object(); private Object lock2 = new Object(); @Override public void run() &#123; synchronized (lock1) &#123; System.out.println(\"I am lock1 \" + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" lock1部分运行结束\"); &#125; synchronized (lock2) &#123; System.out.println(\"I am lock2 \" + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" lock2部分运行结束\"); &#125; &#125;&#125; 最终打印结果如下，可以看出run方法里的代码是时被执行的。当thread1释放掉lock1的锁时，thread2即可获得lock1的锁，所以thread2的lock1中的同步代码块可以与thread1的lock2中的同步代码块并行执行。 12345678I am lock1 thread1thread1 lock1部分运行结束I am lock2 thread1I am lock1 thread2thread1 lock2部分运行结束thread2 lock1部分运行结束I am lock2 thread2thread2 lock2部分运行结束 方法锁锁对象是当前实例对象 123456789101112131415public class SynchronizedDemo3 implements Runnable &#123; @Override public void run() &#123; this.method(); &#125; public synchronized void method() &#123; System.out.println(\"方法锁：\" + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"运行结束\"); &#125;&#125; 最终打印结果如下 1234方法锁：thread1thread1运行结束方法锁：thread2thread2运行结束 类锁锁对象是当前类对象，Java类可能有多个对象，但只有一个Class对象，而类锁的锁对象就是该类的Class对象，类锁有两种形式：将synchronized加在static方法上和synchronized(*.class)代码块。synchronized加在static方法上： 1234567891011121314151617181920212223242526public class SynchronizedClassStatic4 implements Runnable &#123; @Override public void run() &#123; method(); &#125; public static synchronized void method() &#123; System.out.println(\"静态方法锁：\" + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"运行结束\"); &#125; public static void main(String[] args) &#123; SynchronizedClassStatic4 instance1 = new SynchronizedClassStatic4(); SynchronizedClassStatic4 instance2 = new SynchronizedClassStatic4(); Thread thread1 = new Thread(instance1, \"thread1\"); Thread thread2 = new Thread(instance2, \"thread2\"); thread1.start(); thread2.start(); while (thread1.isAlive() || thread2.isAlive()) &#123; &#125; System.out.println(\"finished\"); &#125;&#125; 最终打印结果如下 1234静态方法锁：thread2thread2运行结束静态方法锁：thread1thread1运行结束 synchronized(*.class)代码块： 12345678910111213141516171819202122232425public class SynchronizedClassClass5 implements Runnable &#123; @Override public void run() &#123; synchronized (SynchronizedClassClass5.class) &#123; System.out.println(\"类锁同步代码块形式：\" + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"运行结束\"); &#125; &#125; public static void main(String[] args) &#123; SynchronizedClassClass5 instance1 = new SynchronizedClassClass5(); SynchronizedClassClass5 instance2 = new SynchronizedClassClass5(); Thread thread1 = new Thread(instance1, \"thread1\"); Thread thread2 = new Thread(instance2, \"thread2\"); thread1.start(); thread2.start(); while (thread1.isAlive() || thread2.isAlive()) &#123; &#125; System.out.println(\"finished\"); &#125;&#125; 最终打印结果如下 1234类锁同步代码块形式：thread1thread1运行结束类锁同步代码块形式：thread2thread2运行结束 多线程访问synchronized同步方法常见的7种情况： 两个线程同时访问一个对象的同步方法：阻塞 两个线程访问的是两个对象的同步方法：非阻塞 两个线程访问的是synchronized的静态方法：阻塞 同时访问同步方法和非同步方法：非阻塞 访问同一对象的不同的普通同步方法：阻塞 同时访问静态synchronized和非静态synchronized方法：非阻塞 方法抛出异常后，会释放锁 可重入同一个方法可重入 1234567891011121314151617public synchronized void method(int a) &#123; System.out.println(\"a = \" + a); if (a == 0) &#123; method(a + 1); &#125;&#125;private final static Object object = new Object();public static void reentrantLock() &#123; String tname = Thread.currentThread().getName(); synchronized (object) &#123; System.out.println(String.format(\"&#123;&#125;:) hold &#123;&#125;-&gt;monitor lock\", tname, object)); synchronized (object) &#123; System.out.println(String.format(\"&#123;&#125;:) re-hold &#123;&#125;-&gt;monitor lock\", tname, object)); &#125; &#125;&#125; 不同的方法可重入 12345678public synchronized void methodA() &#123; System.out.println(\"methodA\"); methodB();&#125;public synchronized void methodB() &#123; System.out.println(\"methodB\");&#125; 不同的类可重入 123456789101112public class SynchronizedDemo &#123; public synchronized void methodB() &#123; System.out.println(\"methodB\"); &#125;&#125;class TestClass extends SynchronizedDemo &#123; public synchronized void methodB() &#123; System.out.println(\"subclass methodB\"); super.methodB(); &#125;&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"},{"name":"Synchronized","slug":"Synchronized","permalink":"https://yaoyinglong.github.io/tags/Synchronized/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"Redis总结","date":"2020-10-18T16:00:00.000Z","path":"Blog/Interview/Redis总结/","text":"redis的速度非常的快，单机的redis就可以支撑每秒10几万的并发，相对于mysql来说，性能是mysql的几十倍。速度快的原因主要有几点： 完全基于内存操作 C语言实现，优化过的数据结构，基于几种基础的数据结构，redis做了大量的优化，性能极高 使用单线程，无上下文的切换成本 基于非阻塞的IO多路复用机制 虽然6.0后改用多线程，但并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能，执行命令还是使用单线程。 基本数据类型字符串：redis没有直接使用C语言传统的字符串表示，而是自己实现的叫做简单动态字符串SDS的抽象类型。C语言的字符串不记录自身的长度信息，而SDS则保存了长度信息，这样将获取字符串长度的时间由O(N)降低到了O(1)，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。 链表linkedlist：是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，表头节点的前置和后置节点都指向NULL。 字典hashtable：用于保存键值对的抽象数据结构，redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的而是渐进式的。 跳跃表skiplist：有序集合的底层实现之一，redis中实现有序集合键和集群节点的内部结构中都是使用跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。 整数集合intset：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。 压缩列表ziplist：压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 基于基础的数据结构，redis封装了自己的对象系统，包含字符串对象string、列表对象list、哈希对象hash、集合对象set、有序集合对象zset，每种对象都用到了至少一种基础的数据结构。 redis通过encoding属性设置对象的编码形式来提升灵活性和效率，基于不同的场景redis会自动做出优化。不同对象的编码如下： 字符串对象string：int整数、embstr编码的简单动态字符串、raw简单动态字符串 列表对象list：ziplist、linkedlist 哈希对象hash：ziplist、hashtable 集合对象set：intset、hashtable 有序集合对象zset：ziplist、skiplist 过期策略惰性删除当查询key的时候才对key进行检测，如果已经达到过期时间，则删除。显然，他有一个缺点就是如果这些过期的key没有被访问，那么他就一直无法被删除，而且一直占用内存。 定期删除每隔一段时间对数据库做一次检查，删除里面的过期key。由于不可能对所有key去做轮询来删除，所以redis会每次随机取一些key去做检查和删除。 定期+惰性都没有删除过期的key每次定期随机查询key的时候没有删掉，这些key也没有做查询的话，就会导致这些key一直保存无法被删除，这时候就会走到redis的内存淘汰机制。 volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰 volatile-ttl：从已设置过期时间的key中，移出将要过期的key volatile-random：从已设置过期时间的key中，随机选择key淘汰 allkeys-lru：从key中选择最近最少使用的进行淘汰 allkeys-random：从key中随机选择key进行淘汰 noeviction：当内存达到阈值的时候，新写入操作报错 持久化方式RDBRDB持久化可手动执行也可根据配置定期执行，它的作用是将某个时间点上的数据库状态保存到RDB文件中，RDB文件是一个压缩的二进制文件，通过它可以还原某个时刻数据库的状态。由于RDB文件是保存在硬盘上的，所以即使redis崩溃或者退出，只要RDB文件存在，就可以用它来恢复还原数据库的状态。 可以通过SAVE或者BGSAVE来生成RDB文件。SAVE命令会阻塞redis进程，直到RDB文件生成完毕，在进程阻塞期间，redis不能处理任何命令请求，显然不合适。 BGSAVE则是会fork出一个子进程，然后由子进程去负责生成RDB文件，父进程还可以继续处理命令请求，不会阻塞进程。 AOFAOF是通过保存redis服务器所执行的写命令来记录数据库状态的，AOF通过追加、写入、同步三个步骤来实现持久化机制。 当AOF持久化处于激活状态，服务器执行完写命令之后，写命令将会被追加append到aof_buf缓冲区的末尾； 在服务器每结束一个事件循环之前，将调用flushAppendOnlyFile函数决定是否要将aof_buf的内容保存到AOF文件中，可以通过配置appendfsync来决定。 always：aof_buf内容写入并同步到AOF文件 everysec：将aof_buf中内容写入到AOF文件，如果上次同步AOF文件时间距离现在超过1秒，则再次对AOF文件进行同步 no：将aof_buf内容写入AOF文件，但是并不对AOF文件进行同步，同步时间由操作系统决定 默认选项是everysec，因为always来说虽然最安全（只会丢失一次事件循环的写命令），但是性能较差，而everysec模式只不过会可能丢失1秒钟的数据，而no模式的效率和everysec相仿，但是会丢失上次同步AOF文件之后的所有写命令数据。 热KEY突然有几十万的请求访问redis上的某个特定key，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机引发雪崩。解决方案： 提前把热key打散到不同的服务器，降低压力 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询 缓存击穿缓存击穿的概念就是单个key并发访问过高，过期时导致所有请求直接打到db上。解决方案： 加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了 将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。 缓存穿透查询不存在缓存中的数据，每次请求都会打到DB。可以通过加一层布隆过滤器。布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的K个点，同时把他们置为1。这样当用户再次来查询A，而A在布隆过滤器值为0，直接返回，就不会产生击穿请求打到DB了。 缓存雪崩当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上，这样可能导致整个系统的崩溃。解决方案： 针对不同key设置不同的过期时间，避免同时过期 限流，如果redis宕机，可以限流，避免同时刻大量请求打崩DB 二级缓存，同热key的方案。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://yaoyinglong.github.io/tags/Redis/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"CAS原理及使用场景","date":"2020-10-14T16:00:00.000Z","path":"Blog/Java/并发/CAS原理及使用场景/","text":"","tags":[{"name":"CAS","slug":"CAS","permalink":"https://yaoyinglong.github.io/tags/CAS/"},{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"单例模式","date":"2020-10-08T16:00:00.000Z","path":"Blog/设计模式/创建型模式/单例模式/","text":"单例模式的核心代码就是将构造方法私有化，只有一个实例，自己负责创建自己的对象即自行实例化，提供一种访问其唯一对象的方式，可直接访问，不需要实例化该类的对象。 优点： 内存中只有一个实例，减少了内存开支，特别是一个对象需要频繁创建和销毁时。 只生成一个实例，减少了系统性能开销，当一个对象的产生需要比较多的资源时，如读取配置、产生其他依赖对象时，则可通过在应用启动时直接产生一个单例对象，永久驻留内存的方式解决。 可以避免对资源的多重占用，例如写文件动作，避免了对同一个资源文件同事写操作。 可以在系统设置全局访问点，优化和共享资源访问。如设计一个单例类，负责所有数据表的映射处理。 缺点： 单例模式一般没有接口，扩展困难。单例模式要求自行实例化，且提供单一实例，接口和抽象类是不能被实例化的。 对测试不利，单例模式未开发完，是不能进行测试的，没有接口也不能使用mock方式来进行测试。 与单一职责原则冲突。 懒汉式实例在使用时才去创建，用的时候才去检查有没有实例。有线程安全和线程不安全两种写法，区别就是synchronized关键字。下面这种写法存在线程安全问题，在并发获取实例时，可能会存在创建多个实例的情况。 123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton() &#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 饿汉式在类加载时实例被创建。实现简单且没有线程安全的问题，可能在还不需要此实例的时候就已经把实例创建出来了，浪费内存空间，没起到lazy loading的效果。 123456789public class HungrySingleton &#123; private static HungrySingleton instance = new HungrySingleton(); private HungrySingleton() &#123;&#125; private static HungrySingleton getInstance() &#123; return instance; &#125;&#125; 双检锁双重校验锁，综合了懒汉式和饿汉式两者的优缺点。特点在synchronized关键字内外都加了一层 if 条件判断，既保证了线程安全，又比直接上锁提高了执行效率，还节省了内存空间。这里还用到了volatile关键字来修饰instance，其最关键的作用是防止指令重排。 12345678910111213141516public class Singleton &#123; private static volatile Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类静态内部类的方式效果类似双检锁，但实现更简单且线程安全。同时静态内部类不会在Singleton类加载时就加载，而是在调用getInstance()方法时才进行加载，达到了懒加载的效果。但这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。 1234567891011public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 枚举枚举的方式是比较少见的一种实现方式，却更简洁清晰。还自动支持序列化机制，绝对防止多次实例化。单元素的枚举类型已经成为实现Singleton的最佳方法。 123456789101112131415161718public class Singleton &#123; private enum SingletonEnum &#123; INSTANCE; private Singleton singleton; private SingletonEnum() &#123; singleton = new Singleton(); &#125; public Singleton getInstance() &#123; return singleton; &#125; &#125; public static Singleton getInstance() &#123; return SingletonEnum.INSTANCE.getInstance(); &#125;&#125; 使用场景在系统中要求一个类有且仅有一个对象，若出现多个对象会出现副作用，可以采用单例模式。 要求生成唯一序列号的环境 在整个项目中需要一个共享访问点或共享数据 创建一个对象需要消耗的资源过多，如访问IO和数据库等资源 需要定义大量的静态常量和静态方法的环境 Spring中典型应用1234567891011121314151617181920212223242526/** Cache of singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/** Cache of singleton factories: bean name to ObjectFactory. */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/** Cache of early singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"},{"name":"单例模式","slug":"单例模式","permalink":"https://yaoyinglong.github.io/tags/单例模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/创建型模式/"}]},{"title":"Volatile原理","date":"2020-10-05T16:00:00.000Z","path":"Blog/Java/并发/Volatile原理/","text":"在说Volatile原理前先熟悉一下相关的基本概念原子性、可见性、有序性 Volatile原理关键字Volatile是Java虚拟机提供的最轻量级的同步机制，当一个变量被定义为volatile后，其将具备两种特性：保证此变量对所有线程的可见性，禁止指令重排序。通常适用于一个线程写多个线程读的场景。 在某些情况下volatile的同步机制的性能确实优于锁，但虚拟机对锁进行了许多消除和优化。很难量化认为volatile比synchronized快多少；即便如此大多数场景下volatile总开销仍然要比锁低。 volatile自己与自己比较，volatile 的读性能消耗与普通变量几乎相同，但写操作稍慢，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。 在volatile与锁之间选择的唯一依据仅仅是volatile语义能否满足使用场景的需求。 Volatile保证当前CPU缓存、其他CPU缓存、主内存、工作内存间的数据一致及读写逻辑代码的有序执行。 可见性volatile变量在各个线程的工作内存中不存在一致性问题，在各个线程的工作内存中，volatile变量也可以存在不一致的情况，但由于每次使用之前都要刷新，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题。若这里initFlag不加volatile关键字，线程B将感知不到initFlag值的变化： 1234567891011121314151617181920212223242526272829303132333435public class VolatileVisibilitySample &#123; private volatile boolean initFlag = false; public void save() &#123; this.initFlag = true; String threadname = Thread.currentThread().getName(); System.out.println(\"线程：\" + threadname + \":修改共享变量initFlag\"); &#125; public void load() &#123; String threadname = Thread.currentThread().getName(); while (!initFlag) &#123; //线程在此处空跑，等待initFlag状态改变 &#125; System.out.println(\"线程：\" + threadname + \"当前线程嗅探到initFlag的状态的改变\"); &#125; public static void main(String[] args) &#123; VolatileVisibilitySample sample = new VolatileVisibilitySample(); Thread threadA = new Thread(() -&gt; &#123; sample.save(); &#125;, \"threadA\"); Thread threadB = new Thread(() -&gt; &#123; sample.load(); &#125;, \"threadB\"); threadB.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; threadA.start(); &#125;&#125; 但Java中的运算并非原子操作，导致volatile变量的运算在并发下一样是不安全的。 123456789101112131415161718192021222324252627private static final int THREAD_COUNT = 20;public static volatile int race = 0;public static void increase() &#123; race++;&#125;public static void main(String[] args) &#123; Thread[] threads = new Thread[THREAD_COUNT]; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; threads[i] = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i1 = 0; i1 &lt; 10000; i1++) &#123; increase(); &#125; System.out.println(Thread.currentThread().getId() + \" completed\"); &#125; &#125;); threads[i].start(); &#125; while (Thread.activeCount() &gt; 2) &#123; Thread.yield(); &#125; System.out.println(race);&#125; 若正确并发最后结果应为200000，但实际运行结果基本上为160000多一点。问题出在race++，increase()方法的字节码可以看到，race++是由4条字节码指令完成的。 1234567public static void increase(); Code: 0: getstatic #2 // Field race:I 3: iconst_1 4: iadd 5: putstatic #2 // Field race:I 8: return 题外话，这里使用的是Thread.activeCount() &gt; 2而不是Thread.activeCount() &gt; 1是因为我使用的是IDEA，IDEA是用得反射，所以还有一个monitor监控线程。但是在Java和Eclipse中是1。 123java.lang.ThreadGroup[name=main,maxpri=10] Thread[main,5,main] Thread[Monitor Ctrl-Break,5,main] 使用字节码来分析并发问题，仍不严谨，因为即使编译出来只有一条字节码指令，也并不意味执行这条指令就是一个原子操作。一条字节码指令在解释执行时，解释器将要运行许多行代码才能实现它的语意，若是编译执行，一条字节码指令也可能转化成若干本地机器码指令，可以通过使用-XX:+PrintAssembly参数输出反汇编来分析会更加严谨。 访问volatile变量时不会执行加锁操作，volatile变量是一种比sychronized关键字更轻量级的同步机制。对非volatile变量进行读写时，每个线程先从内存拷贝变量到CPU缓存中。若计算机有多个CPU，每个线程可能在不同的CPU上被处理，每个线程可以拷贝到不同的CPU cache中。声明volatile变量时，JVM保证每次读变量都从主内存中读取，跳过CPU cache这一步。 volatile 保证变量对所有线程的可见性，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。可见性只能保证每次读取的是最新的值，但volatile没办法保证对变量操作的原子性。 指令重排序若定义initialized变量没有使用volatile修饰，可能会由于指令重排序优化，导致A线程中最后一句initialized = true被提前执行。从而导致B线程中使用的配置信息可能出错。 12345678910111213141516171819Map configOptions;char[] configText;volatile boolean initialized = false;// 线程A中执行public void init(String fileName) &#123; configOptions = new HashMap(); configText = readConfigFile(fileName); processConfigOptions(configText, configOptions); initialized = true;&#125;// 线程B中执行public void use() throws InterruptedException &#123; while (!initialized) &#123; Thread.sleep(1); &#125; doSomethingWithConfig();&#125; 这里若不发生指令重排序，不可能出现x=0且y=0的情况，但下面的代码执行会产生该情况，证明了指令重排序： 1234567891011121314151617181920212223242526272829303132333435private static int x = 0, y = 0, a = 0, b = 0;public static void main(String[] args) throws InterruptedException &#123; int i = 0; for (; ; ) &#123; i++; x = 0; y = 0; a = 0; b = 0; Thread t1 = new Thread(() -&gt; &#123; shortWait(10000); a = 1; x = b; &#125;); Thread t2 = new Thread(() -&gt; &#123; b = 1; y = a; &#125;); t1.start(); t2.start(); t1.join(); t2.join(); String result = \"第\" + i + \"次 (\" + x + \",\" + y + \"）\"; if (x == 0 &amp;&amp; y == 0) &#123; System.out.println(result); break; &#125; else &#123; log.info(result); &#125; &#125;&#125;public static void shortWait(long interval) &#123; long start = System.nanoTime(); long end; do &#123; end = System.nanoTime(); &#125; while (start + interval &gt;= end);&#125; volatile 禁止指令重排序，volatile修饰的变量，赋值后多执行了一个lock addl $0x0, (%esp)操作，该操作相当于一个内存屏障，指令重排序时不能把后面的指令重排序到内存屏障之前的位置，只有一个CPU访问内存时，不需要内存屏障。lock的作用是使得本CPU的Cache写入内存，该写入操作也会引起别的CPU或别的内核无效化其Cache。所以通过该操作可让volatile变量的修改对其他CPU立即可见。 从硬件架构上讲，指令重排序是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给个相应电路单元处理。但并不是说指令任意重排，CPU需要能正确处理指令依赖情况以保障程序能得出正确额的执行结果。lock addl $0x0, (%esp)指令把修改同步到内存，意味着所有之前的操作都已经执行完成，这样便形成了指令重排序无法越过内存屏障的效果。 volatile内存语义的实现重排序分为编译器重排序和处理器重排序，为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型。JMM针对编译器制定的volatile重排序规则表； 第一个操作 第二个操作：普通读写 第二个操作：volatile读 第二个操作：volatile写 普通读写 可以重排 可以重排 不可以重排 volatile读 不可以重排 不可以重排 不可以重排 volatile写 可以重排 不可以重排 不可以重排 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。该规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。该规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读或写时，不能重排序。 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略： 在每个volatile写操作的前面插入一个StoreStore屏障 在每个volatile写操作的后面插入一个StoreLoad屏障 在每个volatile读操作的后面插入一个LoadLoad屏障 在每个volatile读操作的后面插入一个LoadStore屏障 12345678910int a;volatile int v1 = 1;volatile int v2 = 2;void readAndWrite () &#123; int i = v1; // 第一个volatile读 int j = v2; // 第二个volatile读 a = i + j; // 普通写 v1 = i + 1; // 第一个volatile写 v2 = j * 2; // 第二个 volatile写&#125; volatile变量内存交互操作volatile变量内存交互操作，T表示一个线程，V、W表示两个volatile变量，在进行read、load、use、assign、store、write操作时满足如下规则： 该规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的值，用于保证能看见其他线程对变量V所做的修改后的值。只有当线程T对变量V执行的前一个操作是load时，线程T才能对变量V执行use操作；且仅当线程T对变量V执行的最后一个操作时use时，线程T才能对变量V执行load操作。线程T对变量V的use操作可以认为是和线程T对变量V的load、read操作相关联，必须连续译器出现。 该规则要求在工作内存中，每次修改V后都必须立即同步回主内存中，用于保证其他线程可以看到自己对变量V所作的修改。仅当线程T对变量V执行的前一个操作时assign时，先吃T才能对变量V执行store操作；且仅当线程T对变量V的执行的最后一个操作是store时，线程T才能对变量V执行assign操作。线程T对变量V的assign操作可以认为是和线程T对变量V的store、write操作相关联，必须连续译器出现。 该规则要求volatile修饰的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相同。若动作A是线程T对变量V实施的use或assign操作，动作F是和动作A相关联的load或store操作，动作P是和动作F相应的对变量V的read或write操作；若动作B是线程T对变量W实施的use或assign操作，动作Q是和动作G相关联的load或store操作，动作Q是和动作G相应的对变量W的read或write操作；若A优于B则P优于Q。 C和C++在C和C++中的volatile作用：优化无效代码、禁止指令重排序、直接完成简单运算、读写都走内存不走寄存器。volatile是通过lock指令触发了读写屏障，通过MESI缓存一致性协议从而实现了当前CPU、其他CPU和主存之间的一致性。 内存屏障内存屏障又称内存栅栏，是一个CPU指令作用有两个，一是保证特定操作执行顺序，二是保证某些变量内存可见性，利用该特性实现volatile内存可见性。由于编译器和处理器都能执行指令重排优化。若在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。volatile变量正是通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化。 编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。 JVM中的四种内存屏障：storeload、storestore、loadload、loadstore 编译器屏障在解决编译乱序问题时，需要使用barrier()编译屏障，在code中使用barrier()可以阻止编译器对该code的编译优化，可以防止编译屏障之前的code和编译屏障之后的code出现编译乱序。 1#definebarrier() _asm_ _volatile_(\"\": : :\"memory\") CPU屏障是为了解决缓存一致性问题，分为锁总线（ifence、sfence、mfence）和锁缓存（lock） 锁总线的方式效率极低基本不怎么用，32位机32根总线、64位机64根总线，ifence是一种Load Barrier读屏障、sfence是一种Store Barrier写屏障、mfence是一种全能型的屏障，具备ifence和sfence的能力。 Lock不是一种内存屏障，但是它能完成类似内存屏障的功能，Lock会对CPU总线和高速缓存加锁，锁缓存其实首先是通过MESI缓存一致性协议来完成的。 使用场景符合以下两条运算场景： 运算结果不依赖变量的当前值，或能够确保只有单一线程修改变量的值。 变量不需要与其他的状态变量共同参与不变约束 当shutdown()方法被调用时，能保证所以线程中执行的doWork()方法都立即停止下来。 1234567891011volatile boolean shutdownRequested;public void shutdown() &#123; shutdownRequested = true;&#125;public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; 双锁检查单例模式 双锁检查单例模式中volatile的作用是防止高并发情况下指令重排序造成的线程安全问题 123456789101112private static volatile Singleton singleton;private Singleton()&#123;&#125;public static Singleton getSingleton()&#123; if(singleton == null)&#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton;&#125; 这里若不加volatile在多线程环境下就可能出现线程安全问题。原因在于某一个线程执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化，因为这里对象的初始化是分为三步，第二步和第三步可能被重排序。 123memory = allocate(); // 1.分配对象内存空间instance(memory); // 2.初始化对象instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance！=null","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"},{"name":"Volatile","slug":"Volatile","permalink":"https://yaoyinglong.github.io/tags/Volatile/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"Java内存模型","date":"2020-09-26T16:00:00.000Z","path":"Blog/Java/并发/Java内存模型/","text":"硬件效率与一致性计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存中将数据同步回内存之中。 基于高速缓存的存储交互很好的解决了处理器与内存的速度矛盾，但也引入了一个新的问题：缓存一致性。在多处理器系统中，每个处理器都有自己的高速缓存，又共享同一主内存，多个处理器的运算任务都涉及同一块主内存区域时，可能导致各自的缓存数据不一致。 为了解决缓存数据一致性问题，需要各个处理器访问缓存时都遵循一些协议，如：MSI、MESI、MOSI、Synapse、Firefly、Dragon Protocol等。 除了增加高速缓存外，为了使处理器内部的运算单元尽可能被充分利用，处理器可能会对输入的代码进行乱序执行优化，即指令重排序，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但不保证程序中各个语句计算的先后顺序与输入的代码中的顺序一致。 Java虚拟机的即时编译器中也有类似的指令重排序优化。 MESI协议MESI协议是通过锁缓存行，一个缓存行大小为64byte，当超过该值MESI协议将失效，这时会升级成锁总线，每个Cache line有4个状态，可用2个bit表示，MESI四个字母表示这四种状态： 状态 描述 监听任务 M 修改 (Modified) 缓存行有效，数据被修改和内存中的数据不一致，数据只存在于本Cache中。 缓存行须监听所有试图读该缓存行相对主存的操作，该操作必须在缓存将该缓存行写回主存前，并将状态置为S之前被延迟执行。 E 独享、互斥(Exclusive) 缓存行有效，数据和内存中的数据一致，数据只存在于本Cache中。 缓存行须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S状态。 S 共享 (Shared) 缓存行有效，数据和内存中的数据一致，数据存在于很多Cache中。 缓存行须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效。 I 无效 (Invalid) 缓存行无效 无 对于M和E状态是精确的，在和该缓存行的真正状态是一致的，而S状态可能是非一致的。若缓存将处于S状态的缓存行作废，而另一个缓存实际上可能已经独享了该缓存行，但该缓存却不会将该缓存行升迁为E状态，因为其它缓存不会广播作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此没有办法确定自己是否已经独享了该缓存行。 缓存行伪共享目前主流的CPU Cache的Cache Line大小都是64Bytes。多线程情况下若修改共享同一个缓存行的变量，就会无意中影响彼此的性能。如2个long 型变量 a 、b，若t1访问a，t2访问b，而a与b刚好在同一个cache line中，此时t1先修改a，将导致b被刷新。 为了解决伪共享，Java8新增了sun.misc.Contended注解，该注解的类会自动补齐缓存行，此注解默认是无效的，需在jvm启动时设置-XX:-RestrictContended参数。 Store Bufferes为了避免这种CPU运算能力浪费，处理器把它想要写入主存的值写到Store Bufferes缓存，然后继续去处理其他事情，当所有失效确认都接收到时，数据才会最终被提交。 Java内存模型主内存与工作内存Java虚拟机中试图定义一种Java内存模型JMM来屏蔽各种硬件和操作系统的内存访问差异。C/C++语言是直接使用物理硬件和操作系统的内存模型，由于不同平台上内存模型的差异，可能导致不同平台上并发访问出错。 Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。这里说的变量包括：实例字段、静态字段、构成数组对象的元素，不包括：局部变量、方法参数。因为局部变量和方法参数是线程私有的。 Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。 Java内存模型规定了所有的变量都存储在主内存（虚拟机内存中的一部分）中，每条线程有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量。不同的线程间也无法直接访问对方的工作内存中的变量，线程间变量值得传递均需要通过主内存来完成。 注：拷贝副本，事实上并不会完全复制一份对象拷贝出来，该对象的引用、对象中某个在线程访问到的字段是有可能存在拷贝的，但不会有虚拟机实现成把整个对象拷贝一次。 注：若局部变量是一个reference类型，它引用的对象在堆中可被各个线程共享，但reference本身在Java栈的局部变量表中，是线程私有的。 内存间交互操作Java内存模型中定义了以下8种操作来完成主内存与工作内存之间的具体交互协议，虚拟机实现时必须保证每一种操作都是原子的、不可再分的。 操作 作用域 完成的工作 lock（锁定） 主内存变量 把一个变量标识为一条线程独占状态 unlock（解锁） 主内存变量 把一个处于锁定状态的变量释放出来，释放后才可被其他线程锁定 read（读取） 主内存变量 把一个变量的值从主内存传输到线程的工作内存中 load（载入） 工作内存变量 把read操作从主内存中得到的变量值放入工作内存的变量副本中 use（使用） 工作内存变量 把工作内存中变量值传递给执行引擎 assign（赋值） 工作内存变量 把从执行引擎接收到的值赋给工作内存的变量 store（存储） 工作内存变量 把工作内存中一个变量的值传递到主内存中 write（写入） 主内存变量 把store操作从工作内存中得到的变量值放入主内存的变量中 若把一个变量从主内存复制到工作内存，需要顺序执行read和load操作。若要将变量从工作内存同步回主内存，需顺序执行store和write操作。Java内存模型只要求上述两个操作必须顺序执行，而没有保证是连续执行。 Java内存模型规定了在执行上述8种操作时必须满足以下规则： 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或从工作内存发起回写但主内存不接受的情况出现。 不允许线程丢弃它最近的assign操作，即变量在工作内存中改变了之后必须把它同步回主内存。 不允许线程无原因地（未发生任何assign操作）把数据从线程工作内存同步回主内存。 一个新变量只能在主内存中诞生，不允许工作内存中直接使用一个未被初始化（load或assign）的变量。即对一个变量实施use、store操作之前，必须先执行过了assign和load操作。 一个变量同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 若对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量钱，需要重新执行load或assign操作初始化变量的值。 若变量事先没有被lock操作锁定，不允许对它执行unlock操作，也不允许unlock一个被其他线程锁定的变量。 对变量执行unlock操作之前，必须先把此变量同步回主内存中。 happens-before原则从JDK 5开始Java使用新的JSR-133内存模型，提供了happens-before原则来辅助保证程序执行的原子性、可见性以及有序性问题，它是判断数据是否存在竞争、线程是否安全的依据，happens-before原则内容如下： 程序顺序原则：即在一个线程内必须保证语义串行性，也就是说按照代码顺序执行。 锁规则：解锁unlock操作必发生在后续同一个锁加锁lock前，若同一个锁解锁后，再加锁，则加锁动作必须在解锁动作之后。 volatile规则：volatile变量的写，先发生于读，这保证了volatile变量的可见性，volatile变量在每次被线程访问时，都强迫从主内存中读该变量的值，而当该变量发生变化时，又会强迫将最新的值刷新到主内存，任何时刻，不同的线程总是能够看到该变量的最新值。 线程启动规则：线程的start()方法先于它的每一个动作，即若线程A在执行线程B的start方法之前修改了共享变量的值，则当线程B执行start方法时，线程A对共享变量的修改对线程B可见 传递性：A先于B ，B先于C则A必然先于C 线程终止规则：线程的所有操作先于线程的终结，Thread.join()方法作用是等待当前执行的线程终止。若在线程B终止之前，修改了共享变量，线程A从线程B的join方法成功返回后，线程B对共享变量的修改将对线程A可见。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可通过Thread.interrupted()方法检测线程是否中断。 对象终结规则：对象的构造函数执行结束先于finalize()方法。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"},{"name":"线程","slug":"线程","permalink":"https://yaoyinglong.github.io/tags/线程/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"动态代理","date":"2020-09-09T16:00:00.000Z","path":"Blog/Java/基础/动态代理/","text":"代理的基础类 12345678910public interface Subject &#123; void doSomething(String param);&#125;public class RealSubject implements Subject &#123; @Override public void doSomething(String param) &#123; System.out.println(\"RealSubject do something \" + param); &#125;&#125; 静态代理1234567891011121314public class SubjectProxy implements Subject &#123; private Subject subject; public SubjectProxy(Subject subject) &#123; this.subject = subject; &#125; @Override public void doSomething(String param) &#123; System.out.println(\"Do something before\"); subject.doSomething(param); System.out.println(\"Do something after\"); &#125;&#125; JDK动态代理JDK动态代理是jre提供的类库，可直接使用不依赖第三方，但JDK的动态代理只能代理接口。首先创建一个代理类EnhaceInvocationHandler实现java.lang.reflect.InvocationHandler接口，重写invoke方法。在method.invoke方法调用前后添加我们需要增强的代码逻辑。 123456789101112131415161718192021222324252627282930313233public class EnhaceInvocationHandler implements InvocationHandler &#123; private Object target; public EnhaceInvocationHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (args != null) &#123; for (Object obj : args) &#123; System.out.println(\"args==\" + obj.toString()); &#125; &#125; else &#123; System.out.println(\"args==null\"); &#125; try &#123; System.out.println(\"Do something before\"); Object result = method.invoke(target, args); System.out.println(\"Do something after\"); return result; &#125; catch (Exception e) &#123; e.getCause().printStackTrace(); throw e; &#125; &#125; public Object creatProxyObj() &#123; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125;&#125; 代理配置 123456789Subject realSubject = new RealSubject();Subject subject = (Subject) Proxy.newProxyInstance(Subject.class.getClassLoader(), new Class[]&#123;Subject.class&#125;, new EnhaceInvocationHandler(realSubject));subject.doSomething(\"AAAA\");EnhaceInvocationHandler handler = new EnhaceInvocationHandler(realSubject);Subject subject = (Subject) handler.creatProxyObj();subject.doSomething(\"AAAA\"); CGLib代理代理的目的是构造一个和被代理的对象同样行为的对象，一个对象的行为是在类中定义的，对象只是类的实例，故构造代理不一定非得通过持有、包装对象这一种方式。CGLib是通过继承父类所有的公有方法，然后重写这些方法，在重写时对这些方法增强。首先也是创建一个代理类CGLibProxy实现net.sf.cglib.proxy.MethodInterceptor接口重写intercept方法。 1234567891011121314151617public class CGLibProxy implements MethodInterceptor &#123; @Override public Object intercept(Object obj, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"Do something before\"); Object object = methodProxy.invokeSuper(obj, objects); System.out.println(\"Do something after\"); return object; &#125; public Object creatProxyObj(Class&lt;?&gt; clazz) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(clazz); enhancer.setCallback(this); return enhancer.create(); &#125;&#125; 在配置代理的地方与JDK动态代理略有区别。并不要求委托类必须实现接口，底层采用asm字节码生成框架生成代理类的字节码，Enhancer是CGLib的字节码增强器，可以方便的对类进行扩展，内部调用GeneratorStrategy.generate方法生成代理类的字节码，CGLib动态代理不仅仅可以代理接口，还可以代理非接口类。 12345678910Subject realSubject = new RealSubject();Enhancer enhancer = new Enhancer();enhancer.setSuperclass(realSubject.getClass());enhancer.setCallback(new CGLibProxy());Subject subject = (Subject) enhancer.create();subject.doSomething(\"AAAA\");CGLibProxy proxy = new CGLibProxy();Subject subject = (Subject) proxy.creatProxyObj(realSubject.getClass());subject.doSomething(\"AAAA\"); CGLib动态代理中生成的字节码更加复杂，生成的代理类是委托类的子类，且不能处理被final关键字修饰的方法；JDK采用反射机制调用委托类的方法，CGLib采用类似索引的方式直接调用委托类方法；","tags":[{"name":"动态代理","slug":"动态代理","permalink":"https://yaoyinglong.github.io/tags/动态代理/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"反射基础","date":"2020-09-07T16:00:00.000Z","path":"Blog/Java/基础/反射基础/","text":"反射主要指程序可以访问、检测和修改他本身状态和行为的一种能力，程序在运行时能获取自身的信息；对于任意一个类，都能够获取到这个类的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法和属性，包括私有的方法和属性，这种动态获取的信息以及动态调用对象的方法的功能就称为Java语言的反射机制。 反射的优点：能使代码更灵活，更加容易实现面向对象，能够使我们很方便的创建灵活的代码，这些代码可以在运行时再装配，无需组件之间进行源代码的链接，体现了多态的应用，降低类之间的耦合性，可以动态的创建对象和编译； 反射的缺点：打破了Java的封装性，导致了Java对像的不安全，使软件的性能降低，复杂度增加，维护成本变高。 反射相关的主要API: java.lang.Class：代表一个类 java.lang.reflect.Method：代表类的方法 java.lang.reflect.Field：代表类的成员变量 java.lang.reflect.Constructor：代表类的构造方法 用于测试的基础类 123456789101112131415161718192021222324public class ReflectIssue &#123; public String publicParam = \"this is a reflect public parameter\"; private String privateParam = \"this is a reflect private parameter\"; public ReflectIssue() &#123; &#125; public ReflectIssue(String publicParam, String privateParam) &#123; this.publicParam = publicParam; this.privateParam = privateParam; &#125; private void reflectPrivate(String str) &#123; System.out.println(\"private : \" + str); &#125; public void reflectPublic(String str) &#123; System.out.println(\"public : \" + str); &#125; public void moreParam(String paramA, String paramB) &#123; System.out.println(\"paramA : \" + paramA + \", paramB：\" + paramB); &#125;&#125; Reflection方式获取类的Class对象有以下四种方式，实际应用中最常用的是通过Class.forName和classLoader的方式来获取Class对象。 123456789ReflectIssue reflectIssue = new ReflectIssue();Class clazz = reflectIssue.getClass();Class clazz = ReflectIssue.class;Class clazz = Class.forName(\"com.example.ReflectIssue\");ClassLoader classLoader = this.getClass().getClassLoader();Class clazz = classLoader.loadClass(\"com.example.ReflectIssue\"); getField不能获取私有属性，要获取私有属性使用getDeclaredField方法，该方法也可以用于获取public属性。如果要访问私有属性必须通过setAccessible将访问权限打开。如果在当前类中进行反射调用自己可以不用通过setAccessible打开权限。 1234567891011Class clazz = Class.forName(\"com.example.ReflectIssue\");ReflectIssue reflectIssue = (ReflectIssue) clazz.newInstance();Field publicParam = clazz.getField(\"publicParam\");System.out.println(publicParam.getName());System.out.println(publicParam.get(reflectIssue));Field privateParam = clazz.getDeclaredField(\"privateParam\");privateParam.setAccessible(true);System.out.println(privateParam.getName());System.out.println(privateParam.get(reflectIssue));privateParam.set(reflectIssue, \"new private param value\"); 同样针对于方法的获取，私有方法获取必须使用getDeclaredMethod方法，该方法也可以用于获取public方法，关于参数的列表可以直接传入一个数组，也可以按照顺序传入多个参数。私有方法的调用需要通过setAccessible方法打开权限。 1234567891011Method method = clazz.getMethod(\"reflectPublic\", String.class);method.invoke(clazz.newInstance(), \"this is a public function\");Method method = clazz.getMethod(\"reflectPublic\", new Class[]&#123;String.class&#125;);method.invoke(clazz.newInstance(), new Object[]&#123;\"this is a public function\"&#125;);Method reflectPrivate = clazz.getDeclaredMethod(\"reflectPrivate\", String.class);reflectPrivate.setAccessible(true);reflectPrivate.invoke(clazz.newInstance(), \"this is a private function\");((ReflectIssue) clazz.newInstance()).reflectPrivate(\"this is a private function\"); 在实际使用中可能需要用到多参数构造方法进行对象的实例化，多参数构造方法实例化类，使用getConstructor和getDeclaredConstructor都可以。getDeclaredConstructor可以获取私有构造方法。和私有属性私有方法访问一样私有构造方法访问需要通过Constructor的setAccessible打开访问权限。 1234567Class clazz = Class.forName(\"com.example.ReflectIssue\");Constructor constructor = clazz.getDeclaredConstructor(String.class, String.class);ReflectIssue reflectIssue2 = (ReflectIssue) constructor.newInstance(\"paramA\", \"paramB\");Constructor constructor = clazz.getDeclaredConstructor(String.class);constructor.setAccessible(true);ReflectIssue reflectIssue2 = (ReflectIssue) constructor.newInstance(\"paramA\"); MethodHandle方式也可以使用虚拟机提供的MethodHandle通过模拟字节码层次的调用来实现反射，需要主意得是，默认所有得方法得第一个参数一定是一个void参数。 1234567891011121314151617Class clazz = Class.forName(\"com.example.ReflectIssue\");MethodType methodType = MethodType.methodType(void.class, String.class);MethodHandle methodHandle = MethodHandles.lookup().findVirtual(clazz, \"reflectPublic\", methodType).bindTo(clazz.newInstance());methodHandle.invokeExact(\"a\");MethodType methodType = MethodType.methodType(void.class, String.class, String.class);MethodHandle methodHandle = MethodHandles.lookup().findVirtual(clazz, \"moreParam\", methodType).bindTo(clazz.newInstance());methodHandle.invokeExact(\"a\", \"b\");MethodHandles.Lookup lookup = MethodHandles.lookup();Method pm = clazz.getDeclaredMethod(\"reflectPrivate\", String.class);pm.setAccessible(true);MethodHandle methodHandle = lookup.unreflect(pm);methodHandle.invoke(clazz.newInstance(), \"a\");methodHandle.invokeExact((ReflectIssue) clazz.newInstance(), \"a\"); MethodHandle服务于所有java虚拟机上的语言，Reflection仅仅服务于java语言，Reflection在模拟Java代码层次的调用，而MethodHandle在模拟字节码层次的方法调用。Reflection是重量级，而MethodHandle是轻量级。MethodHandle可以进行内联优化，Reflection完全没有。但JDK8环境下MethodHandles.lookup方法是调用者敏感的。不同调用者访问权限不同，其结果也不同。","tags":[{"name":"反射","slug":"反射","permalink":"https://yaoyinglong.github.io/tags/反射/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"HashMap源码分析JDK8","date":"2020-09-06T16:00:00.000Z","path":"Blog/Java/基础/HashMap源码分析JDK8/","text":"数据存储结构JDK7中数据结构的存储由数组+链表的方式，因为数组是一组连续的内存空间，易查询，不易增删，而链表是不连续的内存空间，通过节点相互连接，易删除，不易查询。 JDK8中为了解决hash碰撞过于频繁和链表过长查询效率过低，采用数组+链表+红黑树的存储方式，当链表长度超过阈值8且数组长度超过64时，将链表转换为红黑树。极大的提高了查询效率。 在JDK8中默认容量，最大容量以及装载因子等默认值未发生变化。但是多了一些树相关的属性。 12345678910111213static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64;transient Node&lt;K,V&gt;[] table;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;transient int size;transient int modCount;int threshold;final float loadFactor; JDK8中hash方法有略微的简化了，可能是因为引用了红黑树，没有必要再对hashCode过于离散化。 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 构造方法略微变化，最大的变化是将获取table的容量的方法tableSizeFor进行了优化，功能还是一样获取大于等于cap的最接近的2的幂的数作为数组的容量，且移位方式由带符号右移变成了无符号右移，在构造方法中就计算好threshold。 123456789101112131415161718192021222324public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125;// 获取大于等于cap的最接近的2的幂的数作为数组的容量static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 添加方法在JDK8中table的扩容是在添加元素后再进行的。当table为空时通过resize()方法对table进行初始化，以及++size &gt; threshold时通过resize()方法对table的扩容。 如果新插入的元素的key不存在与链表中，则将新元素插入到对应链表的尾部，相对于JDK7的头插法，采用高低位拆分转移方式，避免了链表环的产生 ，解决了并发情况下的死循环问题。当插入新元素后链表的长度大于等于8且数组长度超过64时，会通过treeifyBin方法将链表转换成红黑树。 如果新插入的元素的key存在于链表中，退出for (int binCount = 0; ; ++binCount)循环，将旧值替换为新的值。其中13、14行干的是同样的事。 如果table中存的已经是红黑树了，就直接进行红黑树的插入操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 若table没有被初始化，进行初始化 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 若插入的元素的hash对应的数组的槽为空 tab[i] = newNode(hash, key, value, null); // 直接新建一个节点放到该槽上 else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 相同的Key else if (p instanceof TreeNode) // 红黑树，走单独的逻辑 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 若已经是链表末尾了 p.next = newNode(hash, key, value, null); // 新建节点放入链表尾部 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // 若链表的长度大于等于8了 treeifyBin(tab, hash); // 转换为红黑树 break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // 相同的Key，则退出循环，去替换旧值 p = e; // 下移指针 &#125; &#125; if (e != null) &#123; // 若key重复，这替换旧值 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); // 空实现 return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); // 扩容 afterNodeInsertion(evict); // 空实现 return null;&#125;final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); // 若数组长度小于64，则进行扩容，而不是转红黑树 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; // 将Node转换成TreeNode TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); // 将简单树转换成共黑树 &#125;&#125; threshold的值在构造方法中被赋值为table的capacity，但是在resize()方法中被重新设置为capacity * loadFactor。这里对table的扩容以及threshold调整都是通过向左移位来完成的。 43行的if判断，主要是为了将老的table中的一个链表按照高位和低位拆分成两个链表。这个跟JDK是类是的，只不过JDK7是使用的头插法，这里是使用的尾插法，实现方式不一样。高位链表的数据下标按照JDK7的实现方式就为hiHead.hash &amp; (newCap - 1)其实就等于这里的j + oldCap。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172final Node&lt;K,V&gt;[] resize() &#123; // 初始化table或扩容table Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; // 未被初始化为0，否则为数组长度 int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 若已经是最大容量了，则无需在扩容了 threshold = Integer.MAX_VALUE; return oldTab; &#125; // 若旧容量的两倍小于最大容量，且旧容量大于等于默认容量时，将新的threshold扩展为原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // 初始化时走的逻辑，使用有参构造函数 newCap = oldThr; else &#123; // 初始化时走的逻辑，使用无参构造函数 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 新数组初始化 table = newTab; if (oldTab != null) &#123; // 若旧表不为空，说明是扩容，否则直接返回newTab for (int j = 0; j &lt; oldCap; ++j) &#123; // 遍历旧数组 Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; // 跳过为空的槽 oldTab[j] = null; // 释放旧表中的值 if (e.next == null) // 若链表中只有一个元素，直接将整个链表搬到新的数组中 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 若是红黑树，走单独的逻辑 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 采用高低位的方式将旧链表中的数据拆分成两个高低位链表 Node&lt;K,V&gt; loHead = null, loTail = null; // 低位 Node&lt;K,V&gt; hiHead = null, hiTail = null; // 高位 Node&lt;K,V&gt; next; do &#123; next = e.next; // 通过判断最高位是否为0，来确定其在新数组中的高低位 if ((e.hash &amp; oldCap) == 0) &#123; // 若为0则说明是低位 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; resize()方法中当table存储的元素是红黑树时，将通过split方法按照hash值得高低位将一颗树拆分成两棵树。如果拆分后树得节点个数小于等于UNTREEIFY_THRESHOLD = 6时，将树转换回链表。否正将loHead和hiHead转换成红黑树。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // 采用高低的方式将一棵树拆分成两棵树 TreeNode&lt;K,V&gt; loHead = null, loTail = null; // 低位 TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; // 高位 int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; // 通过判断最高位是否为0，来确定其在新数组中的高低位 if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) // 若个数小于6，则将红黑树转回链表 tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); // 将普通的树转换成红黑树 &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) // 若个数小于6，则将红黑树转回链表 tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); // 将普通的树转换成红黑树 &#125; &#125;&#125;final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); // 将红黑树转换成链表 if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;","tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://yaoyinglong.github.io/tags/HashMap/"},{"name":"JDK8","slug":"JDK8","permalink":"https://yaoyinglong.github.io/tags/JDK8/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"HashMap源码分析JDK7","date":"2020-09-06T16:00:00.000Z","path":"Blog/Java/基础/HashMap源码分析JDK7/","text":"哈希算法 直接定址法：直接以关键字k或者k加上某个常数（k+c）作为哈希地址。 数字分析法：提取关键字中取值比较均匀的数字作为哈希地址。 除留余数法：用关键字k除以某个不大于哈希表长度m的数p，将所得余数作为哈希表地址。 分段叠加法：按照哈希表地址位数将关键字分成位数相等的几部分，其中最后一部分可以比较短。然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。 平方取中法：如果关键字各个部分分布都不均匀的话，可以先求出它的平方值，然后按照需求取中间的几位作为哈希地址。 伪随机数法：采用一个伪随机数当作哈希函数 解决碰撞算法衡量一个哈希函数的好坏的重要指标就是发生碰撞的概率以及发生碰撞的解决方案。任何哈希函数基本都无法彻底避免碰撞，常见的解决碰撞的方法有以下几种： 开放定址法：开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 链地址法：将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。 再哈希法：当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止。 建立公共溢出区：将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中。 数据存储结构HashMap是由数组和链表来实现的对数据的存储，采用Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体，以此来解决Hash冲突的问题。 123456789101112static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; // 头插法的体现 value = v; next = n; key = k; hash = h; &#125;&#125; hashSeed问题对key的hashCode进行了二次hash，即hash扰动，以获得更好的散列值。这里做二次hash的目的是避免自定义对象的hashCode方法，算出来的hashCode离散性比较差，从而导致某些链表特别长，而有些特别短，从而导致性能差。 123456789final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 上面用到的hashSeed值在HashMap初始化时默认为0，根据源码来看hashSeed可能会在初始化table时通过inflateTable中调用的initHashSeedAsNeeded方法被重新设置。currentAltHashing显然为false，useAltHashing通过下面分析可知其值为也为false，故initHashSeedAsNeeded始终返回false，而hashSeed值始终得不到重新设置，所以其始终为0。 123456789final boolean initHashSeedAsNeeded(int capacity) &#123; // 初始化hashSeed boolean currentAltHashing = hashSeed != 0; // false boolean useAltHashing = sun.misc.VM.isBooted() &amp;&amp; (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD); // false boolean switching = currentAltHashing ^ useAltHashing; // false if (switching) &#123; // false hashSeed = useAltHashing ? sun.misc.Hashing.randomHashSeed(this) : 0; &#125; return switching;&#125; sun.misc.VM.isBooted()的源码如下，但是实际通过调用发现其返回值为true。 1234private static volatile boolean booted = false;public static boolean isBooted() &#123; return booted;&#125; 而关于Holder.ALTERNATIVE_HASHING_THRESHOLD，如下所示该值取决于altThreshold的值，实际调试发现该值其实为null，故Holder.ALTERNATIVE_HASHING_THRESHOLD为Integer.MAX_VALUE。 12345678910111213141516171819private static class Holder &#123; static final int ALTERNATIVE_HASHING_THRESHOLD; static &#123; String altThreshold = java.security.AccessController.doPrivileged(new sun.security.action.GetPropertyAction(\"jdk.map.althashing.threshold\")); // null int threshold; try &#123; threshold = (null != altThreshold) ? Integer.parseInt(altThreshold) : ALTERNATIVE_HASHING_THRESHOLD_DEFAULT; if (threshold == -1) &#123; threshold = Integer.MAX_VALUE; &#125; if (threshold &lt; 0) &#123; throw new IllegalArgumentException(\"value must be positive integer.\"); &#125; &#125; catch(IllegalArgumentException failed) &#123; throw new Error(\"Illegal value for 'jdk.map.althashing.threshold'\", failed); &#125; ALTERNATIVE_HASHING_THRESHOLD = threshold; &#125;&#125; 构造方法HashMap的前三个构造方法仅仅是给负载系数loadFactor和数组容量阈值threshold赋值，并不会对数组table进行填充初始化等。HashMap的填充是在真正使用时才会通过inflateTable方法进行填充。如HashMap(Map&lt;? extends K, ? extends V&gt; m)、put(K key, V value)、putAll(Map&lt;? extends K, ? extends V&gt; m)等方法。 123456789101112131415161718192021222324252627282930313233static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 默认初始容量16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 最大容量static final float DEFAULT_LOAD_FACTOR = 0.75f; // 加载因子static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; // 用于存储链表数据transient int size; // 存储KV的数量, 所有链表元素总和int threshold; // threshold=capacity*loadFactor，size大于threshold时会执行resize操作final float loadFactor; // 装载因子，用来衡量HashMap满的程度transient int modCount; // 记录当前集合被修改的次数: 添加，删除，为了实现快速失败的机制public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m);&#125; 表的初始化inflateTable方法是为了初始化数组table，当通过构造方法创建HashMap时设置了initialCapacity，但是实际上创建数组时，使用的并不是我们设置initialCapacity来创建的数组的长度，而是通过roundUpToPowerOf2方法对数组容量进行了优化，不管怎么设置initialCapacity大小，数组容量始终是2的幂，且是大于等于threshold的最近的2的幂。也为后续通过indexFor方法为hash值取模起到帮助。 highestOneBit方法是为了获取二进制数据的最高位，低位全部置0，在调用highestOneBit方法之所以传入的是(number - 1) &lt;&lt; 1而不是直接传入number &lt;&lt; 1，因为若number本身就是2的幂，就会造成将数组容量扩大一倍，若number = 16期望返回的是16，若传入number &lt;&lt; 1将放回32. 12345678910111213141516171819private void inflateTable(int toSize) &#123; int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity);&#125;// 获取大于等于number的最接近的2的幂的数作为数组的容量private static int roundUpToPowerOf2(int number) &#123; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;&#125;// 获取数据二进制的最高位，低位全部置0public static int highestOneBit(int i) &#123; i |= (i &gt;&gt; 1); i |= (i &gt;&gt; 2); i |= (i &gt;&gt; 4); i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1);&#125; 添加方法当存在相同的key且hash相同时，是替换已有的值，并将旧值返回，而不知直接插入到链表中。之所以即要判断散列值也要判断key，是因为不同的输入可能会散列成相同的输出。根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。同一散列函数计算出的散列值相同的现象叫做碰撞。 12345678910111213141516171819202122public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; // 若数组还未初始化，则进行先进行初始化 inflateTable(threshold); &#125; if (key == null) // 若key为空，将其插入到table[0]中 return putForNullKey(value); int hash = hash(key); // 计算hash值 int i = indexFor(hash, table.length); // 通过hash值和数组长度取模得到数组下标 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 若链表存在，在遍历链表，若存在key相等的则替换value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); // 若数组下标对应的链表为空或key不存在，则新建链表或用头插法插入数据 return null;&#125; 仅当 b = 2^n 时位运算才可以转换成取模运算，a % b = a &amp; (b - 1) 。故HashMap才将初始长度设置为 16，且扩容只能是以 2 的倍数扩容。由上面可知数组容量始终是2的幂，故可通过h &amp; (length-1)对hash值取余，从而获取对应的table数组的下标。使用位运算代替取模运算，除了性能之外，还有一个好处就是可以很好的解决负数的问题。 123static int indexFor(int h, int length) &#123; // 取模运算得到数组下标 return h &amp; (length-1);&#125; 通过put方法中key为空的情况调用的putForNullKey()方法可知，HashMap中key为空的数据始终是存储到数组table下标为0的链表中。故table[0]的链表长度适中是1. 12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; // 赋新值 e.recordAccess(this); // 空实现 return oldValue; // 返回旧值 &#125; &#125; modCount++; addEntry(0, null, value, 0); // key为空的元素只能有一个 return null;&#125; table数组的长度并不是初始化后就固定不变了，将链表变得非常长后效率将变得低下，故当元素个数大于等于threshold = capacity * loadFactor时且该数组下标对应的链表不为空，就对数组进行扩容。且是按两倍进行扩容。并将数据从旧的table中拷贝到新的table中。在createEntry仅仅只有两行代码，实现了数据在链表中的头插法插入。 12345678910111213141516171819202122232425void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; // 重新计算一次hash bucketIndex = indexFor(hash, table.length); // 获取新的数组下标 &#125; createEntry(hash, key, value, bucketIndex); // 使用头插法插入数据&#125;void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; // 若数组长度已经是最大容量了，不需要再扩容了 threshold = Integer.MAX_VALUE; // 则将threshold设置为最大值 return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); // 头插法 size++;&#125; 由于newCapacity容量变化了，故indexFor返回的数据下标将可能变化或变成另一个固定的值，故旧的table中同一个链表的数据拷贝到新的table中可能会拆分成两个链表，且将旧表中的数据使用的头插法进行拷贝到新的table中的链表中，链表中的数据将被反序。而不是直接将数组的前N个元素对拷贝到新的数组中。 12345678910111213141516void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; // 实际传入的false，不需要重新计算hash e.hash = null == e.key ? 0 : hash(e.key); &#125; // 重新计算数组下标，新下标要么不变，要么等于原来的下标加上旧的数组长度 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; // 头插法 newTable[i] = e; e = next; &#125; &#125;&#125; 在1.8之前，新插入的元素都是放在了链表的头部位置，但是这种操作在高并发的环境下容易导致死锁，所以1.8之后，新插入的元素都放在了链表的尾部。 获取方法首先计算hash值通过indexFor()方法得到该key在table中的存储位置，遍历链表，在获取数据时不仅判断了hash值是否相等，还判断了key是否相等，故有时候重写hashCode和equals方法尤为重要。 12345678910111213141516171819202122232425262728public V get(Object key) &#123; if (key == null) return getForNullKey(); // key为空的逻辑 Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125;private V getForNullKey() &#123; if (size == 0) &#123; return null; &#125; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) return e.value; &#125; return null;&#125;","tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://yaoyinglong.github.io/tags/HashMap/"},{"name":"JDK7","slug":"JDK7","permalink":"https://yaoyinglong.github.io/tags/JDK7/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"基础面试题","date":"2020-09-04T16:00:00.000Z","path":"Blog/Interview/基础面试题/","text":"基础 == 与 equals区别 hashCode和equals HashMap原理 如何解决hash冲突 扩展策略 Lambda表达式 final有哪些用法：类、方法、变量、提高运行效率、常量在编译时放入常量池 反射 动态代理InvocationHandler 并发 实现方式：Thread、Runnable、Callable（配合FutureTask）、线程池 线程池的使用：ThreadPoolTaskExecutor 最大线程数、核心线程数 拒绝策略：CallerRunsPolicy、AbortPolicy、DiscardPolicy、DiscardOldestPolicy sleep与wait区别 start与run区别 Callable ThreadLocal synchronized的锁对象是哪些： 普通方法是当前实例对象 同步方法快是括号中配置内容，可以是类Class对象，可以是实例对象 静态方法是当前类Class对象 只要不是同一个锁，就可以并行执行，同一个锁，只能串行执行 volatile作用：只能修饰变量，保证可见性，禁止指令重排序，但是不保证原子性。 volatile和synchronized的区别是什么 volatile只能使用在变量上；而synchronized可以在类，变量，方法和代码块上。 volatile至保证可见性；synchronized保证原子性与可见性。 volatile禁用指令重排序；synchronized不会。 volatile不会造成阻塞；synchronized会。 CAS是什么：通过对指定内存地址的实际值与期望值进行比较，如果相同，则替换成新值，否则不替换。 多线程请求最终合并结果Future Spring中的@Async(value = “cusPool”)注解的使用自定义该注解的线程池 Spring中的夸线程池数据共享 Mybatis 当实体类中的属性名和表中的字段名不一样 sql语句中定义字段名的别名 通过resultMap来映射字段名和实体类属性名的 #{}与${}的区别 #{}是预编译处理，${}是字符串替换。 #{}可以有效的防止SQL注入，提高系统安全性 like语句怎么写：concat、”%”${value}”%”、在Java代码中添加sql通配符 动态SQL常用标签：trim | where | set | foreach | if | choose | when | otherwise | bind Hystrix使用 基于编程式 基于注解 断路器 服务限流-降级 Spring 常用注解：@ConfigurationProperties、@Value默认值、@Qualifier作用、@PathVariable IOC的原理 注入方式：构造器注入、setter方法注入、注解注入 Bean的生命周期： 实例化Bean：通过获取BeanDefinition实例化Bean 通过BeanWrapper提供的设置属性的接口完成依赖注入 处理Aware接口 BeanPostProcessor接口：postProcessBeforeInitialization InitializingBean 与 init-method：配置了 init-method 属性，则会自动调用其配置的初始化方法 BeanPostProcessor接口：postProcessAfterInitialization Bean不再使用时：DisposableBean 配置了destroy-method属性，会自动调用其配置的销毁方法 Bean的几种作用域：singleton、prototype、request、session、global-session BeanFactory和ApplicationContext有什么区别 ApplicationContext是BeanFactory子类、提供了更完整的框架功能 BeanFactory采用延迟加载调用getBean时才实例化bean、ApplicationContext容器初始化时创建所有Bean，Bean多启动变慢、前者以编程的方式创建、后者以声明的方式 都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册 SpringAOP的动态代理方式：JDK动态代理、CGLib动态代理 切面、连接点、通知、切入点 使用过哪些Aware接口：ApplicationContextAware 配置参数的注入 用过哪些Aware 接口 三级缓存、循环依赖 基于Java的配置@Configuration 、@Bean BeanFactory和FactoryBean有什么区别 BeanFactory是IoC容器或对象工厂，FactoryBean是个Bean，这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean @Autowired是通过什么来查找依赖的 Feign 超时时间设置：Feign 的负载均衡底层用的就是 Ribbon:ribbon.ConnectTimeout；ribbon.ReadTimeout 如何启用和禁用对hystrix的使用：feign.hystrix.enabled redis 数据类型：String、hash、list、set、sorted set 使用Reids做过哪些业务场景 redis实现分布式锁 数据库 事务四大特性：原子性、隔离性、一致性、持久性 隔离级别： 脏读：事务B读取事务A还没有提交的数据 不可重复读：一行被检索两次，并且该行中的值在不同的读取之间不同时 幻读：当在事务处理过程中执行两个相同的查询，并且第二个查询返回的行集合与第一个查询不同时 索引： B+索引：数据有序,范围查询 Hash索引：等值查询效率高，不能排序,不能进行范围查询 聚集索引：数据按索引顺序存储，中子结点存储真实的物理数据 非聚集索引：存储指向真正数据行的指针 优缺点：提高查询速度、更新数据时效率低、数据频繁查询建立索引，频繁更改数据不建议使用索引 SQL优化 limit优化：先利用ID定位，再分页 or条件优化，多个or条件可以用union all对结果进行合并 如果对三个字段建立联合索引，如果第二个字段没有使用索引，第三个字段也使用不到索引了 like查询尽量在字段后面使用模糊查询 LIKE ‘zhang%’ 索引失效：like查询以%开头、对索引列进行计算、需要类型转换、where中索引列有运算、where中索引列使用了函数、复合索引未用左列字段、有or必全有索引、is null不会用，is not null 会用 算法 树的遍历 排序算法 快排 并发 做过的项目，使用到那些技术 JVM 内存 程序计数器 Java虚拟机栈 局部变量表 操作数栈 动态链接 方法出口 本地方法栈 堆 年轻代：Eden、Survivor1、Survivor1 老年代 方法区（永久代来实现） 常量、静态变量、已加载的类信息、编译后的代码、运行时常量池 直接内存 垃圾回收 几种回收算法：老年代：标记清除、标记整理；新生代：复制算法 对象是否存活：引用计数、可达性分析算法 JVisualVM等工具的使用 Maven phase绑定到生命周期 如何解决依赖冲突 测试用例 MockIto：Spy、Mock、InjectMocks PowerMock等测试工具 单元测试、集成测试 IDEA","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"位运算","date":"2020-09-02T16:00:00.000Z","path":"Blog/Java/基础/位运算/","text":"字节、字、位、比特1位 = 1比特， 1字节 = 8位，1字=2字节， 1Byte=8bit 1B = 8bit， 1KB = 1024B 位：计算机最小存储单位，简记为b，也成为比特bit，计算机中用0和1来表示数据，一个0或1就代表1位。 比特（bit）：也是二进制数字中的位，信息量的最小单位。 字节（Byte）：计算存储容量的计量单位，一个字节等于八位。习惯上用B表示。 字：计算机进行数据处理时，一次存取、加工和传送的数据长度称为字（word），一个字通常由一个或多个（一般是字节的整数位）字节构成。如286微机的字由2个字节组成；486微机的字由4个字节组成。 位移运算Java中有三个位移运算： &lt;&lt;：左移：正数高位丢弃，低位补0，负数符号位保持不变 &gt;&gt;：右移：正数低位丢弃，高位补0；负数高位补1 &gt;&gt;&gt;：无符号右移：低位丢弃，高位补0，符号位也会跟着一起移动 123456System.out.println(2 &lt;&lt; 1); // 4System.out.println(2 &gt;&gt; 1); // 1System.out.println(2 &gt;&gt;&gt; 1); // 1System.out.println(-2 &lt;&lt; 1); // -4System.out.println(-2 &gt;&gt; 1); // -1System.out.println(-2 &gt;&gt;&gt; 1); // 2147483647 原码、反码、补码原码，利用二进制中的第一位来表示符号位，0表示正数，1表示负数。 反码，正数的反码和原码一样，负数的反码就是在原码的基础上符号位保持不变，其他位取反。 补码，补码是为了解决反码的问题，正数的补码和原码、反码一样，负数的补码就是反码+1。 十进制 原码 反码 补码 2 0000 0010 0000 0010 0000 0010 -2 1000 0010 1111 1101 1111 1110 计算机在进行运算时是不会去管符号位的，计算时用到的时补码，让符号位也参与运算，最后将运算得到的结果再转换成源码即可。 负数位移运算-2用原码表示为10000000 00000000 00000000 00000010 -2用反码表示为11111111 11111111 11111111 11111101 -2用补码表示为11111111 11111111 11111111 11111110 -2 &lt;&lt; 1，表示-2的补码左移一位后为11111111 11111111 11111111 11111100，该补码对应的反码为 12311111111 11111111 11111111 11111100- 1= 11111111 11111111 11111111 11111011 该反码对应的原码为：符号位不变，其他位取反，为10000000 00000000 00000000 00000100，表示-4。所以-2 &lt;&lt; 1 = -4。 -2 &gt;&gt; 1，表示-2的补码右移一位后（高位补1）为11111111 11111111 11111111 11111111，该补码对应的反码为 12311111111 11111111 11111111 11111111- 1= 11111111 11111111 11111111 11111110 该反码对应的原码为：符号位不变，其他位取反，为10000000 00000000 00000000 00000001，表示-1。所以-2 &gt;&gt; 1 = -1。 无符号右移在对补码进行移动时，符号位是固定不动的，而无符号右移是指在进行移动时，符号位也会跟着一起移动。比如-2 &gt;&gt;&gt; 1。 -2用原码表示为10000000 00000000 00000000 00000010 -2用反码表示为11111111 11111111 11111111 11111101 -2用补码表示为11111111 11111111 11111111 11111110 -2的补码右移1位为：01111111 11111111 11111111 11111111 右移后的补码对应的反码、原码为：01111111 11111111 11111111 11111111 ，因为现在的符号位为0表示正数，正数的原、反、补码都相同，所以-2 &gt;&gt;&gt; 1 = 2147483647 ~（取反运算）12345： 00000000 00000000 00000000 00000101~5： 11111111 11111111 11111111 11111010 // 补码形式 11111111 11111111 11111111 11111001 // 反码 10000000 00000000 00000000 00000110 // 原码 基本应用交换内容12345void swap(int a, int b) &#123; a ^= b; b ^= a; a ^= b;&#125; 判断奇偶1(a &amp; 1) == 0 求平均数123int average(int x, int y) &#123; return (x &amp; y) + ((x ^ y) &gt;&gt; 1);&#125; 获取大于等于i的最接近的2的幂123456789101112131415161718192021// 获取数据二进制的最高位，低位全部置0public static int highestOneBit(int i) &#123; i |= (i &gt;&gt; 1); i |= (i &gt;&gt; 2); i |= (i &gt;&gt; 4); i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1);&#125;highestOneBit((number - 1) &lt;&lt; 1) static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;","tags":[{"name":"位运算","slug":"位运算","permalink":"https://yaoyinglong.github.io/tags/位运算/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"ThreadLocal原理","date":"2020-09-01T16:00:00.000Z","path":"Blog/Java/并发/ThreadLocal原理/","text":"ThreadLocal是一个线程内部的存储类，可以在指定线程内存储数据，数据存储以后，只有指定线程可以得到存储数据。提供了线程内存储变量的能力，这些变量不同之处在于每一个线程读取的变量是对应的互相独立的。 单看ThreadLocal类的源码其实很简单，对外提供的方法也很少。复杂的点在于内部静态类ThreadLocalMap。每个线程持有一个ThreadLocalMap对象，每一个新的线程Thread都会实例化一个ThreadLocalMap并赋值给成员变量threadLocals。 原理HASH_INCREMENT魔数的选取与斐波那契散列有关，用0x61c88647作为魔数累加为每个ThreadLocal分配各自的ID也就是threadLocalHashCode再与2的幂取模，得到的结果分布很均匀。ThreadLocalMap使用的是线性探测法，均匀分布的好处在于很快就能探测到下一个临近的可用slot，从而保证效率。 1234567private final int threadLocalHashCode = nextHashCode();private static AtomicInteger nextHashCode = new AtomicInteger();private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; initialValue和withInitial两个方法是使用的时候用于重写赋初始值。withInitial通过lambda表达式的方式来重写initialValue方法。 12345678910111213141516171819protected T initialValue() &#123; return null;&#125;public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) &#123; return new SuppliedThreadLocal&lt;&gt;(supplier);&#125;static final class SuppliedThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; private final Supplier&lt;? extends T&gt; supplier; SuppliedThreadLocal(Supplier&lt;? extends T&gt; supplier) &#123; this.supplier = Objects.requireNonNull(supplier); &#125; @Override protected T initialValue() &#123; return supplier.get(); &#125;&#125; 通过ThreadLocal的get源码可以看到，数据是存储在ThreadLocalMap中，而具体的ThreadLocalMap实例并不是ThreadLocal保持，而是保持在每个Thread持有的成员变量threadLocals中。不同的Thread持有不同的ThreadLocalMap实例，因此它们是不存在线程竞争。每次线程死亡，所有map中引用到的对象都会随着这个Thread的死亡而被垃圾收集器一起收集。 12345678910111213141516171819202122232425262728public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; set方法跟上面的setInitialValue差不多。如果当前线程的ThreadLocalMap为空就创建一个新的ThreadLocalMap并赋值给当前线程的成员变量threadLocals，否则set当前值。 123456789101112public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; ThreadLocalMapThreadLocalMap是ThreadLocal的静态内部类为每个Thread都维护了一个数组table，ThreadLocal确定了一个数组下标，而这个下标就是value存储的对应位置。 实例化ThreadLocalMap时创建了一个初始长度为16的Entry数组，且数组长度始终为2的幂。与HashMap类似通过hashCode与length位运算确定数组下标。结合此处的构造方法可以理解成每个线程Thread都持有一个Entry型的数组table，而一切的读取过程都是通过操作这个数组table完成的。 1234private static final int INITIAL_CAPACITY = 16;private Entry[] table;private int size = 0;private int threshold; 为了解决内存回收，这里的Entry继承了WeakReference弱引用。ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，系统gc的时候，该ThreadLocal势必会被回收。 Entry的key是对ThreadLocal的弱引用，当抛弃掉ThreadLocal对象时，垃圾收集器会忽略这个key的引用而清理掉ThreadLocal对象， 防止了内存泄漏。 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; i是通过对threadLocalHashCode的取模得到数组的下标，将构建的Entry放到table数组中。并设置threshold。ThreadLocalMap有两个方法用于得到上一个/下一个索引，从nextIndex和prevIndex两个方法的实现上来看，Entry数组在程序逻辑上是作为一个环形存在的，这也是由于ThreadLocalMap是使用线性探测法来解决散列冲突。 线性探测法：往哈希表中插入数据时，通过哈希函数计算该值的哈希地址，若发现该位置已有数据，则找紧跟着的下一个位置，若无数据则插入，若有数据则继续探测下一个位置。 12345678910111213141516171819ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);&#125;private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125;private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125;private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1);&#125; getEntry方法在ThreadLocal中的get方法中被调用，首先从ThreadLocal的直接索引位置获取Entry e，若e不为null并且key相同则返回e，若e为null直接返回null，若e不为null且key不一致则向下一个位置查询，如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry，否则若key值为null，则擦除该位置的Entry，返回null，否则继续向下一个位置查询，直到e为null还没有找到对应的Entry则返回null。 1234567891011121314151617181920212223242526private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;// 由于使用的是线性探索，往后还可能找到目标Entryprivate Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; 当Entry的key为空时通过expungeStaleEntry方法擦除该位置的Entry。防止该Entry的value被一直强引用从而导致内存泄露。ThreadLocal引用示意图如下，实线表示强引用，虚线表示弱引用 从图中可看到，虽然Entry的key是ThreadLocal的弱引用，key在其他地方没有强引用时即会被回收，但是Entry的value会一直被引用，不能得到释放。当然若线程执行结束threadLocal和threadRef会断掉，因此threadLocal、threadLocalMap、entry都会被回收，但实际中为了线程复用我们会使用线程池，threadRef可能永远不会断掉，可能导致value永远无法回收。所以这里是直接将table的Entry和Entry的value的引用置空。 for循环是往后环形查找，直到遇到table[i] == null时结束，k == null表示再次遇到脏Entry同样将其清理掉。k != null且h != i表示处理rehash的情况，将起挪到hash表下标为h开始的第一个为空的位置。 注：脏Entry仅仅是key为null，而不是通过table[i]获取的Entry为空。这也是为什么遇到tab[i] == null就退出搜索了。 12345678910111213141516171819202122232425262728293031323334353637383940414243private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; tab[staleSlot].value = null; tab[staleSlot] = null; size--; Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; /* * 对于还没有被回收的情况，需要做一次rehash。 * 如果对应的ThreadLocal的ID对len取模出来的索引h不为当前位置i， * 则从h向后线性探测到第一个空的slot，把当前的entry给挪过去。 */ int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; /* * ThreadLocalMap因为使用了弱引用，所以其实每个slot的状态有三种也即 * 有效（value未回收），无效（value已回收），空（entry==null）。 * 正是因为ThreadLocalMap的entry有三种状态，所以不能完全套高德纳原书的R算法。 * * 因为expungeStaleEntry函数在扫描过程中还会对无效slot清理将之转为空slot， * 如果直接套用R算法，可能会出现具有相同哈希值的entry之间断开（中间有空entry）。 */ while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; 若当前table[i] != null说明hash冲突就需要向后环形查找，若查找过程中遇到脏entry就通过replaceStaleEntry进行处理；若当前table[i] == null说明新的entry可以直接插入，但是插入后会调用cleanSomeSlots方法检测并清除脏entry。 123456789101112131415161718192021222324252627private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; // 替换失效的entry if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; replaceStaleEntry并不仅仅局限于处理当前已知的脏Entry，首先通过for循环向前找到第一个脏Entry，这里的第一个是指向前查找遇到的最靠近table[i] == null的Entry，它认为在出现脏Entry的相邻位置也有很大概率出现脏Entry，为了一次处理到位，就需要向前环形搜索，找到前面的脏Entry。 根据向前搜索中是否有脏Entry以及在for循环向后环形查找中是否找到可覆盖的Entry，，最后使用cleanSomeSlots方法从slotToExpunge为起点开始进行清理脏Entry，可分四种情况： 前向有脏Entry，向后环形查找找到可覆盖的Entry 前向有脏Entry，向后环形查找未找到可覆盖的Entry 前向无脏Entry，向后环形查找找到可覆盖的Entry 前向无脏Entry，向后环形查找未找到可覆盖的Entry 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 向前扫描，查找最前的一个无效slot int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 向后遍历table for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; /* * 如果在整个扫描过程中（包括函数一开始的向前扫描与i之前的向后扫描） * 找到了之前的无效slot则以那个位置作为清理的起点，否则以当前的i作为清理起点 */ if (slotToExpunge == staleSlot) slotToExpunge = i; // 从slotToExpunge开始做一次连续段的清理，再做一次启发式清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // 如果当前的slot已经无效，并且向前扫描过程中没有无效slot，则更新slotToExpunge为当前位置 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // 如果key在table中不存在，则在原地放一个即可 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 在探测过程中如果发现任何无效slot，则做一次清理（连续段清理+启发式清理） if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 参数n主要用于扫描次数控制，若没有遇到脏Entry，整个扫描过程持续log2(n)次，若遇到脏Entry将n重置为当前hash表的长度，再扫描log2(n)次，注意这里的nextIndex获取的数组下标是一个环。遇到脏Entry时通过expungeStaleEntry清理脏Entry。 若当前n等于hash表的size即n=10，i=1,在第一趟搜索过程中通过nextIndex，i指向索引为2的位置，此时table[2]为null，则第一趟未发现脏Entry，进行第二趟搜索。 第二趟搜索先通过nextIndex方法，table[3] != null找到脏Entry，先将n置为哈希表的长度len，然后继续调用expungeStaleEntry方法，将当前索引为3的脏Entry给清除掉，令value为null且table[3]为null，但该方法会继续往后环形搜索，往后发现索引4、5的位置的Entry同样为脏Entry，索引6的Entry不是脏Entry保持不变，直至i=7时此处table[7]为null，返回索引7。 继续向后环形搜索，直到在整个搜索范围里都未发现脏Entry，cleanSomeSlot方法执行结束退出。 123456789101112131415161718// 启发式地清理slotprivate boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; // 扩大扫描控制因子 n = len; removed = true; // 清理一个连续段 i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed;&#125; 当调用set方法时发现需要扩容时，会调用rehash方法对table进行扩容。扩容前回先清理掉hash表中所有的脏Entry，然后在进行扩容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private void rehash() &#123; // 做一次全量清理 expungeStaleEntries(); /* * 因为做了一次清理，所以size很可能会变小。 * ThreadLocalMap这里的实现是调低阈值来判断是否需要扩容， * threshold默认为len*2/3，所以这里的threshold - threshold / 4相当于len/2 */ if (size &gt;= threshold - threshold / 4) resize();&#125;private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; // 线性探测来存放Entry int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125;private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125;&#125; 调用threadLocal.remove方法时候，实际上会调用threadLocalMap的remove方法，当遇到了key为null的脏entry的时候，也会调用expungeStaleEntry清理掉脏entry。 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 在threadLocal的生命周期里，针对threadLocal存在的内存泄漏的问题，都会通过expungeStaleEntry，cleanSomeSlots,replaceStaleEntry这三个方法清理掉key为null的脏entry。 InheritableThreadLocal12345678910111213public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; protected T childValue(T parentValue) &#123; return parentValue; &#125; ThreadLocalMap getMap(Thread t) &#123; return t.inheritableThreadLocals; &#125; void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); &#125;&#125; InheritableThreadLocal提供了一种父子线程之间的数据共享机制，在线程初始化init时，会调用ThreadLocal的createInheritedMap从父线程的inheritableThreadLocals中把有效的entry都拷过来。InheritableThreadLocal只是在子线程创建时会去拷一份父线程的inheritableThreadLocals。若父线程是在子线程创建后再set某个InheritableThreadLocal对象的值，对子线程是不可见的。 123456789101112131415161718192021222324252627static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap);&#125;private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if (e != null) &#123; @SuppressWarnings(\"unchecked\") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125;&#125; 应用在使用ThreadLocal时很可能出现数据错乱，这是由于通过线程池时，线程池对线程进行了复用，从而导致ThreadLocal中的数据串了。用完及时清理数据。在Web环境中可以自定义HandlerInterceptorAdapter，在preHandler中去设置ThreadLocal，在afterCompletion时区remove。 重写initialValue方法重写initialValue赋初值方法。 12345678static ThreadLocal&lt;Long&gt; threadLocal = new ThreadLocal&lt;Long&gt;() &#123; @Override protected Long initialValue() &#123; return Thread.currentThread().getId(); &#125;&#125;;static ThreadLocal&lt;Long&gt; threadLocal = ThreadLocal.withInitial(() -&gt; Thread.currentThread().getId()); MDCMDC主要是用于将某个或某些所有日志中都需要打印的字符串设置于MDC中，这样就不需要每次打印日志时专门写出来，这里也是通过ThreadLocal来实现的。 123456789101112static MDCAdapter mdcAdapter;mdcAdapter.put(key, val);mdcAdapter.get(key);public class Log4jMDCAdapter implements MDCAdapter &#123; public Log4jMDCAdapter() &#123; &#125; public void put(String key, String val) &#123; ThreadContext.put(key, val); &#125;&#125; 在DefaultThreadContextMap可以看到localMap其实就是一个ThreadLocal 1234567891011121314151617181920212223242526272829303132333435public final class ThreadContext &#123; private static ThreadContextMap contextMap; public static void put(String key, String value) &#123; contextMap.put(key, value); &#125;&#125; public class DefaultThreadContextMap implements ThreadContextMap &#123; public static final String INHERITABLE_MAP = \"isThreadContextMapInheritable\"; private final boolean useMap; private final ThreadLocal&lt;Map&lt;String, String&gt;&gt; localMap; public DefaultThreadContextMap(boolean useMap) &#123; this.useMap = useMap; this.localMap = createThreadLocalMap(useMap); &#125; static ThreadLocal&lt;Map&lt;String, String&gt;&gt; createThreadLocalMap(final boolean isMapEnabled) &#123; PropertiesUtil managerProps = PropertiesUtil.getProperties(); boolean inheritable = managerProps.getBooleanProperty(\"isThreadContextMapInheritable\"); return (ThreadLocal)(inheritable ? new InheritableThreadLocal&lt;Map&lt;String, String&gt;&gt;() &#123; protected Map&lt;String, String&gt; childValue(Map&lt;String, String&gt; parentValue) &#123; return parentValue != null &amp;&amp; isMapEnabled ? Collections.unmodifiableMap(new HashMap(parentValue)) : null; &#125; &#125; : new ThreadLocal()); &#125; public void put(String key, String value) &#123; if (this.useMap) &#123; Map&lt;String, String&gt; map = (Map)this.localMap.get(); Map&lt;String, String&gt; map = map == null ? new HashMap() : new HashMap(map); map.put(key, value); this.localMap.set(Collections.unmodifiableMap(map)); &#125; &#125;&#125; 数据库连接、 Session 管理12345678910111213private static final ThreadLocal threadSession = new ThreadLocal();public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; 使用ThreadLocal代替锁123456789101112131415161718192021222324252627static HashSet&lt;Val&lt;Integer&gt;&gt; set = new HashSet&lt;&gt;();synchronized static void addSet(Val&lt;Integer&gt; val) &#123; set.add(val);&#125;static ThreadLocal&lt;Val&lt;Integer&gt;&gt; c = new ThreadLocal&lt;Val&lt;Integer&gt;&gt;()&#123; @Override protected Val&lt;Integer&gt; initialValue() &#123; Val&lt;Integer&gt; v = new Val&lt;Integer&gt;(); v.set(0); addSet(v); return v; &#125;&#125;;// 统计结果set.stream().map(Val::get).reduce((a, sum) -&gt; a + sum).get() public class Val&lt;T&gt; &#123; T val; public T get() &#123; return val; &#125; public void set(T val) &#123; this.val = val; &#125;&#125; 自实现123456789101112131415161718192021222324252627282930313233public class MyThreadLocal&lt;T&gt; &#123; static AtomicInteger atomic = new AtomicInteger(); private int threadLocalHash = atomic.addAndGet(0x61c88647); static HashMap&lt;Thread, HashMap&lt;Integer, Object&gt;&gt; threadLocalHashMap = new HashMap&lt;&gt;(); synchronized static HashMap&lt;Integer, Object&gt; getMap() &#123; Thread thread = Thread.currentThread(); if (!threadLocalHashMap.containsKey(thread)) &#123; threadLocalHashMap.put(thread, new HashMap&lt;&gt;()); &#125; return threadLocalHashMap.get(thread); &#125; protected T initialValue() &#123; return null; &#125; public T get() &#123; HashMap&lt;Integer, Object&gt; map = getMap (); if (!map.containsKey(this.threadLocalHash)) &#123; map.put(this.threadLocalHash, initialValue()); &#125; return (T) map.get(this.threadLocalHash); &#125; public void set(T value) &#123; HashMap&lt;Integer, Object&gt; map = getMap (); map.put(this.threadLocalHash, value); &#125;&#125; 与Synchronized的区别相同：都是为了解决多线程中相同变量的访问冲突问题， 不同：Synchronized同步机制是通过以时间换空间的方式控制线程访问共享对象的顺序，而threadLocal是以空间换时间为每一个线程分配一个该对象各用各的互不影响。","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"https://yaoyinglong.github.io/tags/ThreadLocal/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"JVM整体概览","date":"2020-08-24T16:00:00.000Z","path":"Blog/Java/JVM整体概览/","text":"","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"}]},{"title":"设计模式概览","date":"2020-08-24T16:00:00.000Z","path":"Blog/设计模式/设计模式概览/","text":"设计模式分类23种设计模式大体上可以分为三类： 创建型模式（5个）：对象实例化的模式，用于解耦对象的实例化过程； 结构型模式（7个）：把类或对象结合在一起形成一个更大的结构； 行为型模式（11个）：类和对象如何交互，及划分职责和算法； 各种模式的关键点创建型模式单例模式：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例。 简单工厂：一个工厂类根据传入的参量决定创建出那一种产品类的实例。 工厂方法：定义一个用于创建产品的接口，由子类决定生产什么产品。 抽象工厂：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。 建造者模式：封装一个复杂对象的构建过程，并可以按步骤构造。 原型模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。 结构型模式适配器模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。 组合模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。 装饰模式：动态的给对象增加一些职责，即增加其额外的功能。 代理模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。 亨元模式：运用共享技术来有效地支持大量细粒度对象的复用。 外观模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。 桥接模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 行为型模式模板模式：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 解释器模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。 策略模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。 状态模式：允许一个对象在其内部状态发生改变时改变其行为能力。 观察者模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。 备忘录模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。 中介者模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。 命令模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。 访问者模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。 责任链模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。 迭代器模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 23种设计模式间的关系","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"}]},{"title":"Spring知识点","date":"2020-08-23T16:00:00.000Z","path":"Blog/Spring/Spring知识点/","text":"","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"IoC容器","date":"2020-08-15T16:00:00.000Z","path":"Blog/Spring/IoC容器/","text":"IoC容器概述依赖反转的概念：依赖对象的获得被反转了，基于该结论为控制反转创造了一个更好听的名字：依赖注入。依赖控制反转的实现方式有很多种，Spring中IoC容器是实现该模式的载体，它可以在对象生成或初始化时直接将数据注入到对象中，也可以通过将对象引用注入到对象数据域中的方式来注入对方法调用的依赖。这种依赖注入是可以递归的，对象被逐层注入。 应用控制反转后，当对象被创建时，由一个调用系统内的所有对象的外界实体将其所依赖的对象的引用传递给它，控制反转是关于一个对象如何获取它所依赖的对象的引用，反转指的是责任的反转。 通过使用IoC容器，对象的依赖关系的管理被反转了或者说是把资源的获取方式反转了，对象之间的相互依赖关系由IoC容器进行管理，并由IoC容器完成对象的注入。注入的主要实现方式有：接口注入、setter注入、构造器注入。Spring中setter注入和构造器注入是主要的注入方式，使用Spring时setter注入是常见的注入方式。且Spring还提供了对特定依赖的检查。 Spring IoC提供了一个基本的JavaBean容器，通过IoC容器管理依赖关系，并通过依赖注入和AOP切面增强了为JavaBean这样的POJO对象赋予事务管理、生命周期管理等基本功能。 IoC容器的设计与实现Spring IoC容器的设计中，实现了BeanFactory接口的简单容器系列，该系列容器只实现了容器的最基本的功能；和容器的高级形态ApplicationContext应用上下文，两个主要的容器系列。BeanFactory是IoC容器具体实现的基本功能规范的设计表现。 对于使用者来说，可将BeanFactory和ApplicationContext看成容器的具体表现形式。通常所说的IoC容器实际上代表的是一系列功能各异的容器产品。Spring中有各种各样的IoC容器的实现。 在Spring提供的基本的IoC容器的接口定义和实现的基础上，Spring通过定义BeanDefinition来管理基本的Spring的应用中的各种对象以及它们之间的相互依赖关系。BeanDefinition抽象了对Bean的定义，是让容器起作用的主要数据类型。对于IoC容器来说，BeanDefinition就是对依赖反转模式中管理的对象依赖关系的数据抽象，也是容器实现依赖反转功能的核心数据结构，依赖反转功能都是围绕对BeanDefinition的处理来完成的。 BeanFactory接口定义了基本的IoC容器规范，从接口BeanFactory到HierarchicalBeanFactory再到ConfigurableBeanFactory是一条主要的BeanFactory设计路径。HierarchicalBeanFactory接口增加了getParentBeanFactory()的接口功能，使BeanFactory具备了双亲IoC容器的管理功能。ConfigurableBeanFactory接口主要定义了一些对BeanFactory的配置功能。可设置双亲IoC容器，配置Bean后置处理器等。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"IoC","slug":"IoC","permalink":"https://yaoyinglong.github.io/tags/IoC/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"Spring整体架构","date":"2020-08-11T16:00:00.000Z","path":"Blog/Spring/Spring整体架构/","text":"Spring子项目Spring Framework（core）包含一系列Ioc容器的设计，提供了依赖反转的实现，集成了AOP，还包含了MVC、JDBC、事务处理模块的实现。 Spring Web Flow定义了一种特定的语言来描述工作流，同时高级的工作流控制引擎可以管理会话状态，支持AJAX来构建丰富的客户端体验，并提供JSF支持。其实际上是构建在Spring MVC的基础上的，相对于Spring Framework（core）独立发展的。 Spring BlazeDS Integration提供Spring于Adobe Flex技术集成的模块。 Spring Security基于Spring的认证和安全工具。 Spring Security OAuth为OAuth在Spring上集成提供支持，OAuth是一个第三方模块，提供一个开放协议的实现，通过改协议，前端桌面应用可以对Web应用进行简单而标准的安全调用。 Spring Dynamic Modules可以让Spring运行在OSGi平台上。 Spring Batch提供构建批处理应用和自动化操作的框架。 Spring Integration为企业数据集成提供了各种适配器，通过这些适配器来转换各种消息格式，并帮助Spring应用完成与企业应用系统的集成。 Spring AMQP为Spring应用更好地使用基于AMQP（高级消息队列协议）的消息服务而开发。 Spring Data为Spring应用提供使用费关系型数据的能力。 Spring设计目标​ 为开发者提供的是一个一站式的轻量级应用开发框架。其抽象了许多应用开发中遇到的共性问题。支持POJO和使用JavaBean的开发方式，使应用面向接口开发，充分支持OO（面向对象）的设计方法，使开发的入门、测试、应用部署都得到简化。 ​ 通过使用Spring的IoC容器，可以对应用开发中复杂的对象耦合关系实现一个文本化、外部化的工作，即通过一个或几个XML文件，可以方便地对应用的耦合关系进行浏览、修改和维护，很大程度上简化应用开发。通过Ioc容器实现的依赖反转，把依赖关系的管理从Java对象中解放出来，交给IoC容器来完成，从而完成了对象之间的解耦，将原来的对象—对象的关系，转化为对象—IoC容器—对象的关系。 ​ Spring即作为用户和机器之间的平台，同时也为用户使用底层的机器资源提供了应用开发环境。Spring关系的是一些企业应用资源的使用，如数据持久化、数据集成、事务管理、消息中间件、Web2.0应用、分布式计算等对高效可靠处理企业数据方法的技术抽象。 ​ Spring一方面通过IoC容器来管理POJO对象，以及它们相互之间的耦合关系，使企业的信息、数据、资源可以用简单得Java语言来抽象和描述；另一方面可通过AOP以动态和非侵入式的方式来增强服务的功能。 ​ IoC容器和AOP模块是平台实现的核心，代表了最为基础的底层抽象，同时也是Spring其他模块实现的基础。 Spring整体架构Spring IoC​ 包含了最基本的IoC容器BeanFactory接口的实现，也提供了一系列这个接口的实现。如：XmlBeanFactory、SimpleJndiBeanFactory、StaticListableBeanFactory等，为了让应用更方便得使用IoC容器，还在IoC容器的外围提供如Resource访问资源的抽象和定位等支持。Spring还设计了IoC容器的高级形态ApplicationContext应用上下文提供用户使用。 Spring AOP​ Spring核心模块，围绕AOP增强功能，Spring集成了AspectJ作为AOP的一个特定实现，还在JVM动态代理/CGLIB的基础上实现了一个AOP框架。 Spring MVC​ 以DispatcherServlet为核心的模块，实现了MVC模式，包括怎样与Web容器环境集成、Web请求的拦截、分发、处理、和ModelAndView数据的返回，以及如何集成各种UI视图展现和数据表现。 Spring JDBC/ORM​ Spring JDBC包提供了JdbcTemplate作为模板类，封装了基本的数据库操作方法，如数据查询、更新等。 ​ Spring还提供许多对ORM工具的封装。如Hibernate、iBatis等。可以把对这些工具的使用和Spring声明式事务处理结合起来。同时Spring还提供许多模板对象，如HibernateTemplate来实现对Hibernate的驱动。 Spring事务处理​ Spring事务处理是一个通过Spring AOP实现的自身功能增强的典型模块。通过AOP增强实现了声明式事务处理的功能，使应用只需要在IoC容器中对事务属性进行配置即可完成，同时这些事务处理的基本过程和具体的事务处理器实现是无关的，应用可以选择不同的具体的事务处理机制，使用了声明式事务处理，这些具体的事务处理机制会被纳入Spring事务处理的统一框架中完成，并完成与具体业务代码的解耦。 Spring远端调用​ 通过Spring的封装，为应用屏蔽了各种通信和调用细节的实现，通过这一层的封装，使应用可以通过选择各种不同的远端调用来实现。如HTTP调用器、第三方二进制同学实现Hessian/Burlap、RMI调用。 Spring应用场景​ 在Spring这个一站式应用平台或框架中，其中各个模块除了依赖IoC容器和AOP之外，相互之间没有很强的耦合性；Spring最重目标是简化应用开发的编程模型。其所提供的服务可贯穿应用道整个软件中，从最上层Web UI道底层数据操作，道其他企业信息数据集成，再到各种J2EE服务的使用。 ​ 可把Spring作为一个整体使用，也可以把Spring各个模块拿出来单独使用，因其本身是非常模块化的。Spring的价值： 非侵入性框架，其目标是使应用程序代码对框架的依赖最小化。 提供了一个一致的编程模型，使应用直接使用POJO开发，从而可以与运行环境隔离开。 推动应用的设计风格向面向对象及面向接口编程转变，提高代码的重用性和可测性。 改进了体系结构的选择，Spring可以帮助我们选择不同的技术实现。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"时间&空间复杂","date":"2020-07-31T16:00:00.000Z","path":"Blog/算法/时间&空间复杂/","text":"时间复杂度常见的时间复杂度：O(1)：常数复杂度，O(log n)：对数复杂度，O(n)：线性时间复杂度，O(n^2)：平方，O(n^3)：立方，O(2^n)：指数，O(n!)：阶乘。 O(log n)12for (int i = 0; i &lt; n; i++) &#123;&#125; O(n^2)1234for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; &#125;&#125; O(log n)12for (int i = 0; i &lt; n; i *= 2) &#123;&#125; O(k^n)123456private int Fibonacci(int n) throws Exception &#123; if(n &lt; 2)&#123; return n; &#125; return Fibonacci(n-1) + Fibonacci(n -2);&#125; O(n!)1234for (int i = 0; i &lt; n; i++) &#123; for (int j = i + 1; j &lt; n; j++) &#123; &#125;&#125; 空间复杂度","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"二叉搜索树","date":"2020-07-27T16:00:00.000Z","path":"Blog/算法/二叉搜索树/","text":"左子树上所有节点的值均小于根节点的值，而右子树上所有结点的值均大于根节点的值。故二叉搜索树中序遍历是单调递增的。 插入的序列越接近有序，生成的二叉搜索树就越像一个链表，为了避免二叉搜索树变成链表，故引入了平衡二叉树，即让树的结构看起来尽量均匀，左右子树的节点数尽量一样多。 生成平衡二叉树时，先按照生成二叉搜索树的方法构造二叉树，再根据插入的导致二叉树不平衡的节点位置进行调整，有LL左旋、RR右旋、LR先左旋后右旋、RL先右旋后左旋四种调整方式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146public class BinaryNode &#123; int data; BinaryNode left; BinaryNode right; BinaryNode parent; public BinaryNode(int data) &#123; this.data = data; this.left = null; this.right = null; this.parent = null; &#125;&#125;public class BinarySearchTree &#123; /** * 查找数据 */ public BinaryNode find(BinaryNode root, int key) &#123; BinaryNode current = root; while (current != null) &#123; if (key &lt; current.data) &#123; current = current.left; &#125; else if (key &gt; current.data) &#123; current = current.right; &#125; else &#123; return current; &#125; &#125; return null; &#125; /** * 插入数据 */ public void insert(BinaryNode root, int data) &#123; if (root.data &lt; data) &#123; if (root.right != null) &#123; insert(root.right, data); &#125; else &#123; BinaryNode newNode = new BinaryNode(data); newNode.parent = root; root.right = newNode; &#125; &#125; else &#123; if (root.left != null) &#123; insert(root.left, data); &#125; else &#123; BinaryNode newNode = new BinaryNode(data); newNode.parent = root; root.left = newNode; &#125; &#125; &#125; /** * 查找node的后继节点，若右子树为null，则返回当前节点作为后继节点 */ public BinaryNode finSuccessor(BinaryNode node) &#123; if (node.right == null) &#123; // 表示没有右边 那就没有后继 return node; &#125; BinaryNode cur = node.right; BinaryNode pre = node.right; // 开一个额外的空间用来返回后继节点，因为要找到为空的时候，那么其实返回的是上一个节点 while (cur != null) &#123; pre = cur; cur = cur.left; // 注意后继节点是要往左边找，因为右边的肯定比左边的大，要找的是第一个比根节点小的，所以只能往左边 &#125; return pre; // 因为cur会变成null，实际是要cur的上一个点，所以就是pre来代替 &#125; /** * 删除节点值为data的节点 */ public BinaryNode remove(BinaryNode root, int data) &#123; BinaryNode delNode = find(root, data); if (delNode == null) &#123; System.out.println(\"要删除的值不在树中\"); return root; &#125; // 1.删除的点没有左右子树 if (delNode.left == null &amp;&amp; delNode.right == null) &#123; if (delNode == root) &#123; // 若删除的就是根节点，且根节点左右节点都为null root = null; &#125; else if (delNode.parent.data &lt; delNode.data) &#123; delNode.parent.right = null; // 删除节点是右节点 &#125; else &#123; delNode.parent.left = null; // 删除节点是左节点 &#125; &#125; else if (delNode.left != null &amp;&amp; delNode.right != null) &#123; // 2.删除的节点有两颗子节点 BinaryNode successor = finSuccessor(delNode); // 从右子树上找的后继节点，若右子树为null，则返回当前delNode节点，但明显不可能 // 后继节点和删除节点进行交换，首先后继节点的左节点是肯定为空的，将删除节点的左子树放到后继节点的左子树上 successor.left = delNode.left; // 后继的左边变为删除的左边，由于后继节点从右子树上找的，故这里的successor.left一开始肯定为null successor.left.parent = successor; // 删除点的左边parent指向后继节点 // 再来看后继节点的右边 if (successor.right != null &amp;&amp; successor.parent != delNode) &#123; // 后继节点有右边，这其实就是下面情况3的第一种 successor.right.parent = successor.parent; successor.parent.left = successor.right; successor.right = delNode.right; successor.right.parent = successor; &#125; else if (successor.right == null) &#123; // 若后继节点没有右边，那其实就是情况1，没有左右子树 if (successor.parent != delNode) &#123; // 若后继节点的parent不等于删除的点 那么就需要把删除的右子树赋值给后继节点 successor.parent.left = null; // 注意原来的后继节点上的引用要删掉，否则会死循环 successor.right = delNode.right; successor.right.parent = successor; &#125; &#125; // 替换做完接下来就要删除节点了 if (delNode == root) &#123; successor.parent = null; return successor; &#125; successor.parent = delNode.parent; if (delNode.data &gt; delNode.parent.data) &#123; // 删除的点在右边，关联右子树 delNode.parent.right = successor; &#125; else &#123; delNode.parent.left = successor; &#125; &#125; else &#123; // 3.删除点有一个节点 if (delNode.right != null) &#123; // 有右节点 if (delNode == root) &#123; return delNode.right; &#125; delNode.right.parent = delNode.parent; // 把右节点的parent指向删除点的parent // 关联父节点的左右子树 if (delNode.data &lt; delNode.parent.data) &#123; delNode.parent.left = delNode.right; // 删除的点在左边 &#125; else &#123; delNode.parent.right = delNode.right; // 删除的点在右边 &#125; &#125; else &#123; // 有左节点 if (delNode == root) &#123; return delNode.left; &#125; delNode.left.parent = delNode.parent; if (delNode.data &lt; delNode.parent.data) &#123; delNode.parent.left = delNode.left; // 删除的点在左边 &#125; else &#123; delNode.parent.right = delNode.left; // 删除的点在右边 &#125; &#125; &#125; return root; &#125;&#125; 验证二叉搜索树1234567891011121314151617181920212223242526272829303132333435public Integer min;public boolean isValidBST(TreeNode root) &#123; if (root == null) &#123; return true; &#125; boolean left = isValidBST(root.left); if (!left || min != null &amp;&amp; root.val &lt;= min) &#123; return false; &#125; min = root.val; return isValidBST(root.right);&#125;public boolean isValidBSTDfs(TreeNode root) &#123; if (root == null) &#123; return true; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode node = root; Integer min = null; while (node != null || !stack.isEmpty()) &#123; while (node != null) &#123; stack.add(node); node = node.left; &#125; node = stack.pop(); if (min != null &amp;&amp; node.val &lt;= min) &#123; return false; &#125; min = node.val; node = node.right; &#125; return true;&#125; 二叉搜索树插入1234567891011public TreeNode insertIntoBST(TreeNode root, int val) &#123; if (root == null) &#123; return new TreeNode(val); &#125; if (val &gt; root.val) &#123; root.right = insertIntoBST(root.right, val); &#125; else &#123; root.left = insertIntoBST(root.left, val); &#125; return root;&#125; 删除节点 若key &gt; root.val，说明要删除的节点在右子树，root.right = deleteNode(root.right, key)。 若key &lt; root.val，说明要删除的节点在左子树，root.left = deleteNode(root.left, key)。 若key == root.val，则该节点就是我们要删除的节点，则： 若该节点是叶子节点，直接删除：root = null。 若该节点不是叶子节点且有右节点，则用其后继节点值替代root.val = successor.val，然后删除后继节点。 若该节点不是叶子节点且只有左节点，则用它的前驱节点值替代root.val = predecessor.val，然后删除前驱节点。 123456789101112131415161718192021public TreeNode deleteNode(TreeNode root, int key) &#123; if (root == null) &#123; return null; &#125; if (key &gt; root.val) &#123; root.right = deleteNode(root.right, key); &#125; else if (key &lt; root.val) &#123; root.left = deleteNode(root.left, key); &#125; else &#123; if (root.left == null &amp;&amp; root.right == null) &#123; root = null; &#125; else if (root.right != null) &#123; root.val = successor(root); root.right = deleteNode(root.right, root.val); &#125; else &#123; root.val = predecessor(root); root.left = deleteNode(root.left, root.val); &#125; &#125; return root;&#125; 后继节点，中序遍历序列的下一个节点。即比当前节点大的最小节点，先取当前节点的右节点，然后一直取该节点的左节点，直到左节点为空，则最后指向的节点为后继节点。 1234567public int successor(TreeNode root) &#123; root = root.right; while (root.left != null) &#123; root = root.left; &#125; return root.val;&#125; 前驱节点，中序遍历序列的前一个节点。即比当前节点小的最大节点，先取当前节点的左节点，然后取该节点的右节点，直到右节点为空，则最后指向的节点为前驱节点。 1234567public int predecessor(TreeNode root) &#123; root = root.left; while (root.right != null) &#123; root = root.right; &#125; return root.val;&#125; 将树转换成链表cursor只是做一个引用传递，不断的将节点的right节点更新，然后将当前游标置为新节点。 123456789101112131415161718TreeNode cursor;public TreeNode increasingBST(TreeNode root) &#123; TreeNode ans = new TreeNode(0); cursor = ans; inorder(root); return ans.right;&#125;public void inorder(TreeNode node) &#123; if (node == null) &#123; return; &#125; inorder(node.left); node.left = null; cursor.right = node; cursor = node; inorder(node.right);&#125; 二叉搜索树降序遍历12345678public void convertBST(TreeNode root) &#123; if (root == null) &#123; return; &#125; convertBST(root.right); System.out.println(root); convertBST(root.left);&#125; 最近公共祖先1234567891011121314151617181920212223242526272829303132public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if (root.val &lt; p.val &amp;&amp; root.val &lt; q.val) &#123; return lowestCommonAncestor(root.right, p, q); &#125; if (root.val &gt; p.val &amp;&amp; root.val &gt; q.val) &#123; return lowestCommonAncestor(root.left, p, q); &#125; return root;&#125;public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; // 保证 p.val &lt; q.val if (p.val &gt; q.val) &#123; TreeNode tmp = p; p = q; q = tmp; &#125; while (root != null) &#123; // p,q 都在 root 的右子树中 if (root.val &lt; p.val) &#123; // 遍历至右子节点 root = root.right; // p,q 都在 root 的左子树中 &#125; else if (root.val &gt; q.val) &#123; // 遍历至左子节点 root = root.left; &#125; else &#123; break; &#125; &#125; return root;&#125; 修剪二叉搜索树1234567891011121314public TreeNode trimBST(TreeNode root, int L, int R) &#123; if (root == null) &#123; return null; &#125; if (root.val &gt; R) &#123; return trimBST(root.left, L, R); &#125; if (root.val &lt; L) &#123; return trimBST(root.right, L, R); &#125; root.left = trimBST(root.left, L, R); root.right = trimBST(root.right, L, R); return root;&#125; 前序结果构建树12345678910111213141516171819202122public int index = 0;public TreeNode bstFromPreorder(int[] preorder) &#123; if (preorder == null || preorder.length == 0) &#123; return null; &#125; return generateTree(preorder, Integer.MIN_VALUE, Integer.MAX_VALUE);&#125;public TreeNode generateTree(int[] preorder, int lower, int upper) &#123; if (index == preorder.length) &#123; return null; &#125; int rootVal = preorder[index]; if (rootVal &gt; upper || rootVal &lt; lower) &#123; return null; &#125; index++; TreeNode root = new TreeNode(rootVal); root.left = generateTree(preorder, lower, rootVal); root.right = generateTree(preorder, rootVal, upper); return root;&#125; 后序结果构建树12345678910111213141516171819202122public int index = 0;public TreeNode bstFromPostorder(int[] postorder) &#123; if (postorder == null || postorder.length == 0) &#123; return null; &#125; return generateTree(postorder, Integer.MIN_VALUE, Integer.MAX_VALUE);&#125;public TreeNode generateTree(int[] postorder, int lower, int upper) &#123; if (index == postorder.length) &#123; return null; &#125; int rootVal = postorder[index]; if (rootVal &gt; upper || rootVal &lt; lower) &#123; return null; &#125; index++; TreeNode root = new TreeNode(rootVal); root.right = generateTree(postorder, rootVal, upper); root.left = generateTree(postorder, lower, rootVal); return root;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"},{"name":"树","slug":"树","permalink":"https://yaoyinglong.github.io/tags/树/"},{"name":"AVL","slug":"AVL","permalink":"https://yaoyinglong.github.io/tags/AVL/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"平衡二叉树","date":"2020-07-27T16:00:00.000Z","path":"Blog/算法/平衡二叉树/","text":"平衡二叉树是一种特殊的二叉排序树，每个节点左子树和右子树高度差至多等于1。 将二叉树上节点左子树深度减去右子树深度的值称为平衡因子BF，平衡二叉树上所有节点的平衡因子只可能是1，-1，0。 距离插入节点最近且平衡因子绝对值大于1的节点为根的子树，称为最小不平衡子树。 构建平衡二叉树时，每插入一个节点时，先检查是否因插入而破坏树的平衡性，若是则找出最小不平衡树，在保持二叉排序树特性的前提下，调整最小不平衡子树中各个节点之间的链接关系，进行相应的旋转，使之成为新的平衡子树。 右旋：最小不平衡子树的BF和它的子树BF符号相同且最小不平衡子树的BF大于0 左旋：最小不平衡子树的BF和它的子树BF符号相同且最小不平衡子树的BF小于零 左右旋：最小不平衡子树的BF与它的子树的BF符号相反时且最小不平衡子树的BF大于0时，需要对节点先进行一次向左旋使得符号相同后，在向右旋转一次完成平衡操作。 右左旋：最小不平衡子树的BF与它的子树的BF符号相反时且最小不平衡子树的BF小于0时，需要对节点先进行一次向右旋转使得符号相同时，在向左旋转一次完成平衡操作。 左旋LL 123456public TreeNode leftLeftRotation(TreeNode root) &#123; TreeNode left = root.left; root.left = left.right; left.right = root; return left;&#125; 右旋RR 123456public TreeNode rightRightRotation(TreeNode root) &#123; TreeNode right = root.right; root.right = right.left; right.left = root; return right;&#125; 左右旋LR 1234public TreeNode leftRightRotation(TreeNode root) &#123; root.left = rightRightRotation(root.left); return leftLeftRotation(root);&#125; 右左旋RL 1234public TreeNode rightLeftRotation(TreeNode root) &#123; root.right = leftLeftRotation(root.right); return rightRightRotation(root);&#125; 插入节点123456789101112131415161718192021222324252627282930public TreeNode insertAvl(TreeNode root, int val) &#123; if (root == null) &#123; return new TreeNode(val); &#125; if (val == root.val) &#123; throw new RuntimeException(\"不允许添加相同的节点\"); &#125; if (val &lt; root.val) &#123; root.left = insertAvl(root.left, val); // 插入节点后，若AVL树失去平衡，则进行相应的调节 if (maxDepth(root.left) - maxDepth(root.right) == 2) &#123; if (val &lt; root.left.val) &#123; return leftLeftRotation(root); &#125; else &#123; return leftRightRotation(root); &#125; &#125; &#125; else &#123; root.right = insertAvl(root.right, val); // 插入节点后，若AVL树失去平衡，则进行相应的调节 if (maxDepth(root.right) - maxDepth(root.left) == 2) &#123; if (val &gt; root.right.val) &#123; return rightRightRotation(root); &#125; else &#123; return rightLeftRotation(root); &#125; &#125; &#125; return root;&#125; 删除节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public TreeNode remove(TreeNode root, int val) &#123; if (root == null) &#123; return null; &#125; if (val &lt; root.val) &#123; root.left = remove(root.left, val); if (maxDepth(root.right) - maxDepth(root.left) == 2) &#123; if (maxDepth(root.right.left) &gt; maxDepth(root.right.right)) &#123; return rightLeftRotation(root); &#125; else &#123; return rightRightRotation(root); &#125; &#125; &#125; else if (val &gt; root.val) &#123; root.right = remove(root.right, val); if (maxDepth(root.left) - maxDepth(root.right) == 2) &#123; if (maxDepth(root.left.right) &gt; maxDepth(root.left.left)) &#123; return leftRightRotation(root); &#125; else &#123; return leftLeftRotation(root); &#125; &#125; &#125; else &#123; if (root.left != null &amp;&amp; root.right != null) &#123; if (maxDepth(root.left) &gt; maxDepth(root.right)) &#123; int maxVal = findMax(root.left); root.val = maxVal; root.left = remove(root.left, maxVal); &#125; else &#123; int minVal = findMin(root.right); root.val = minVal; root.right = remove(root.right, minVal); &#125; &#125; else &#123; return root.left != null ? root.left : root.right; &#125; &#125; return root;&#125;public int findMax(TreeNode root) &#123; if (root.left == null || root.right == null) &#123; return root.val; &#125; return findMax(root.right);&#125;public int findMin(TreeNode root) &#123; if (root.right == null || root.left == null) &#123; return root.val; &#125; return findMin(root.left);&#125; 有序数组转换成AVL123456789101112131415161718192021222324252627282930313233343536373839public TreeNode sortedArrayToBST(int[] nums) &#123; return toBstTraversalLeft(nums, 0, nums.length - 1);&#125;// 总是选择中间位置左边的数字作为根节点public TreeNode toBstTraversalLeft(int[] nums, int left, int right) &#123; if (left &gt; right) &#123; return null; &#125; int mid = (left + right) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = toBstTraversalLeft(nums, left, mid - 1); root.right = toBstTraversalLeft(nums, mid + 1, right); return root;&#125;// 总是选择中间位置右边的数字作为根节点public TreeNode toBstTraversalRight(int[] nums, int left, int right) &#123; if (left &gt; right) &#123; return null; &#125; int mid = (left + right + 1) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = toBstTraversalRight(nums, left, mid - 1); root.right = toBstTraversalRight(nums, mid + 1, right); return root;&#125;// 选择任意一个中间位置数字作为根节点public TreeNode toBstTraversalRandom(int[] nums, int left, int right) &#123; if (left &gt; right) &#123; return null; &#125; int mid = (left + right + new Random().nextInt(2)) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = toBstTraversalRandom(nums, left, mid - 1); root.right = toBstTraversalRandom(nums, mid + 1, right); return root;&#125; 平衡二叉树判定对二叉树做后序遍历，从底至顶返回子树深度，若判定某子树不是平衡树则 直接向上返回： 123456789101112131415161718public boolean isBalanced(TreeNode treeNode) &#123; return recur(treeNode) != -1;&#125;public int recur(TreeNode treeNode) &#123; if (treeNode == null) &#123; return 0; &#125; int leftDepth = recur(treeNode.leftNode); if (leftDepth == -1) &#123; return -1; &#125; int rightDepth = recur(treeNode.rightNode); if (rightDepth == -1) &#123; return -1; &#125; return Math.abs(leftDepth - rightDepth) &lt; 2 ? Math.max(leftDepth, rightDepth) + 1 : -1;&#125; B树B树属于多叉树又名平衡多路查找树，数据库索引技术里大量使用者B树和B+树的数据结构。 红黑树红黑树是一种含有红黑结点并能自平衡的二叉查找树。主要用于存储有序数据，查找时间复杂度为O(logn)，插入近似O(nlogn)，删除近似O(logn)。一棵含有n个节点的红黑树的高度至多为2log(n+1) 每个节点要么是黑色，要么是红色 根节点是黑色 每个空叶子节点是黑色 每个红色结点的两个子结点一定都是黑色 任意一结点到每个叶子结点的路径都包含数量相同的黑结点 插入时旋转和颜色变换规则：当前结点的父节点是红色，且它的祖父结点的另一个子结点即叔叔结点也是红色，则把父节点和叔叔节点设为黑色，把祖父节点设为红色，把指针定义到祖父结点设为当前要操作。 当前父结点是红色，叔叔节点是黑色时，且当前结点是右子树，则左旋。左旋是以父结点作为左旋，指针变换到父亲结点；当前父结点是红色，叔叔节点是黑色时，且当前结点是左子树，则右旋，右旋是把父结点变为黑色，把祖父结点变为红色，祖父结点旋转。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162public class RedBlackTree &#123; private final int Red = 0; // 红色 private final int Black = 1; // 黑色 private class Node &#123; int key = -1; // 数据 int color = Black; // 颜色 Node left = nil; // nil表示的是叶子结点 Node right = nil; // 右节点 Node parent = nil; // 父节点 Node(int key) &#123; this.key = key; &#125; @Override public String toString() &#123; return \"Node [key=\" + key + \", color=\" + color + \", left=\" + left.key + \", right=\" + right.key + \", p=\" + parent.key + \"]\" + \"\\r\\n\"; &#125; &#125; private final Node nil = new Node(-1); private Node root = nil; public void printTree(Node node) &#123; if (node == nil) &#123; return; &#125; printTree(node.left); System.out.print(node.toString()); printTree(node.right); &#125; /** * 向红黑树插入节点 */ private void insert(Node node) &#123; Node temp = root; if (root == nil) &#123; // 若为根节点 root = node; node.color = Black; // 将根节点设置为黑色 node.parent = nil; // 根节点父节点为null &#125; else &#123; // 不是根节点 node.color = Red; // 将节点颜色设置为红色 while (true) &#123; // 完成节点插入 if (node.key &lt; temp.key) &#123; // 插入节点位于左边 if (temp.left == nil) &#123; temp.left = node; node.parent = temp; break; &#125; else &#123; temp = temp.left; &#125; &#125; else &#123; // 插入节点位于右边 if (temp.right == nil) &#123; temp.right = node; node.parent = temp; break; &#125; else &#123; temp = temp.right; &#125; &#125; &#125; fixTree(node); // 平衡红黑树 &#125; &#125; private void fixTree(Node node) &#123; while (node.parent.color == Red) &#123; // 若父节点为红色 Node uncleNode = nil; // 当前节点的叔叔节点 if (node.parent == node.parent.parent.left) &#123; // 若插入节点的父节点为祖父节点的左节点 uncleNode = node.parent.parent.right; if (uncleNode != nil &amp;&amp; uncleNode.color == Red) &#123; // 若叔叔节点存在且也为红色 node.parent.color = Black; // 将父节点置为黑色 uncleNode.color = Black; // 将叔叔节点置为黑色 node.parent.parent.color = Red; // 将祖父节点置为红色 node = node.parent.parent; // 将当前节点置为祖父节点 continue; // 重新进入循环 &#125; if (node == node.parent.right) &#123; // 若当前节点是父节点的右节点 node = node.parent; // 将当前节点指向父节点 rotateLeft(node); // 将当前节点左旋 &#125; node.parent.color = Black; // 将当前节点父节点设置为黑色 node.parent.parent.color = Red; // 将当前节点祖父节点设置为红色 rotateRight(node.parent.parent); // 将祖父节点右旋 &#125; else &#123; uncleNode = node.parent.parent.left; if (uncleNode != nil &amp;&amp; uncleNode.color == Red) &#123; node.parent.color = Black; uncleNode.color = Black; node.parent.parent.color = Red; node = node.parent.parent; continue; &#125; if (node == node.parent.left) &#123; node = node.parent; rotateRight(node); &#125; node.parent.color = Black; node.parent.parent.color = Red; rotateLeft(node.parent.parent); &#125; &#125; root.color = Black; &#125; void rotateLeft(Node node) &#123; if (node.parent != nil) &#123; // 若当前节点父节点不为null if (node == node.parent.left) &#123; // 若当前节点是父节点的左节点 node.parent.left = node.right; // 将当前节点父节点的左节点设置为当前节点的右节点 &#125; else &#123; // 若当前节点是父节点的右节点 node.parent.right = node.right; // 将当前节点父节点的右节点设置为当前节点的右节点 &#125; node.right.parent = node.parent; // 将当前节点的右节点的父节点设置为当前节点父节点 node.parent = node.right; // 将当前节点的父节点设置为当前节点的右节点 if (node.right.left != nil) &#123; // 当前节点原来的右节点的左节点不为null node.right.left.parent = node; // 将当前节点的原来的右节点的左节点的父节点设置为当前节点 &#125; node.right = node.right.left; // 将当前节点的右节点设置为，原来右节点的左节点 node.parent.left = node; // 将当前节点设置为其原来的右节点的左节点 &#125; else &#123; // 若当前节点父节点为null Node right = root.right; root.right = right.left; right.left.parent = root; root.parent = right; right.left = root; right.parent = nil; root = right; &#125; &#125; void rotateRight(Node node) &#123; if (node.parent != nil) &#123; if (node == node.parent.left) &#123; node.parent.left = node.left; &#125; else &#123; node.parent.right = node.left; &#125; node.left.parent = node.parent; node.parent = node.left; if (node.left.right != nil) &#123; node.left.right.parent = node; &#125; node.left = node.left.right; node.parent.right = node; &#125; else &#123; Node left = root.left; root.left = root.left.right; left.right.parent = root; root.parent = left; left.right = root; left.parent = nil; root = left; &#125; &#125; public void creatTree() &#123; int[] data = new int[]&#123;23, 32, 15, 221, 3&#125;; Node node; System.out.println(Arrays.toString(data)); for (int i = 0; i &lt; data.length; i++) &#123; node = new Node(data[i]); insert(node); &#125; printTree(root); &#125; public static void main(String[] args) &#123; RedBlackTree bst = new RedBlackTree(); bst.creatTree(); &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"},{"name":"树","slug":"树","permalink":"https://yaoyinglong.github.io/tags/树/"},{"name":"AVL","slug":"AVL","permalink":"https://yaoyinglong.github.io/tags/AVL/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"面试准备大纲","date":"2020-07-25T16:00:00.000Z","path":"Blog/Interview/大纲/","text":"Spring AOP IOC 源码 SpringBoot SpringCloud 数据库 常见面试笔试内容 算法 树（前序遍历、中序遍历、后序遍历、层序遍历） 二叉搜索树 平衡二叉树（AVL树） 红黑树 图（广度优先遍历BFS、深度优先遍历DFS） leetcode题（前期每周5道，中期每周10道，后期每周15道） 常见排序总结 复杂度分析：了解常见时间复杂度，建立复杂度和数据规模之间的概念，理解均摊复杂度分析 数组 双索引技术 对撞指针—浮动窗口 查找表 map set unordered_map unordered_set 链表 虚拟头结点 双指针 栈 非递归算法 深入系统栈，模拟系统递归调用 队列 广度优先遍历 回溯 回溯算法 排序问题-组合问题 Floodfill 动态规划 记忆化搜索 重叠子问题和问题的无后效性 背包问题 LIS，LCS问题分析 贪心算法：避过陷阱 设计模式 6大基本原则（一周） 23种设计模式（一周5个） 设计模式对比 Java基础 JVM 源码 多线程 消息队列 RabbitMQ 常见面试笔试内容 Reids 常见面试笔试内容 Linux 常用命令 Go 常见面试笔试内容 Maven 常见面试笔试内容 单元测试","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"SOLID基本原则","date":"2020-07-25T16:00:00.000Z","path":"Blog/设计模式/SOLID基本原则/","text":"6大设计基本原则：单一职责原则、里氏替换原则、依赖倒置原则、接口隔离原则、迪米特法则、开闭原则 单一职责原则SRP​ 单一职责原则提出了一个编写程序的标准，用职责或变化原因来衡量接口或类设计得是否优良，但职责和变化原因都是不可度量得，因项目和环境而异。单一职责适用于接口、类、方法。 定义：应该有且仅有一个原因引起类的变更。 优点：类复杂性降低，实现职责清晰明确；可读性高；可维护性高；变更引起的风险低； 里氏替换原则LSP定义：每一个类型为S的对象s，都有类型为T的对象t，使得以T定义的所有程序P在所有的对象s都代替成t时，程序P的行为无变化，则类型S是类型T的子类；所有引用基类的地方必须能透明的使用其子类的对象。 子类必须完全实现父类的方法：若子类不能完全实现父类方法，或某些方法在子类种已发生畸变，建议断开父子继承关系。 子类可以有自己的个性：子类出现的地方父类未必能出现 覆盖或实现父类方法时输入参数可以被放大 覆写或实现父类的方法时输出结果可以被缩小 在类中调用其他类时务必使用父类或接口，否则即是违背LSP原则。 依赖倒置原则DIP​ 采用依赖倒置原则可以减少类间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性。可以通过依赖倒置原则涉及的接口或抽象类对实现类进行约束，可减少需求变化引起的工作量剧增的情况，可让维护人员轻松地扩展和维护，是实现开闭原则的重要途径。TDD测试驱动开发模式就是依赖倒置原则的最高级应用。 定义：高层模块不应该依赖底层模块两者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象； 表现：模块间依赖通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生；接口和抽象类不依赖于实现类；实现类依赖接口或抽象类； 依赖的三种写法： 构造函数传递依赖对象，也叫构造函数注入 Setter方法传递依赖对象，也叫Setter依赖注入 接口声明依赖对象，也叫接口注入 依赖倒置原则的本质就是通过抽象（接口或抽象类）使各个类或模块的实现彼此独立，不互相影响，实现模块间的松耦合。 每个类尽量都有接口或抽象类，或抽象类和接口两者都具备 变量的表面类型尽量是接口或抽象类 任何类都不应该从具体类派生 尽量不要覆写基类的方法 结合里氏替换原则使用 接口隔离原则ISP定义：客户端不应该依赖它不需要的接口；类间的依赖关系应该建立在最小的接口上。建立单一的接口，不要建立臃肿庞大的接口； 接口尽量小 接口要高内聚：提高接口、类、模块的处理能力，减少对外的交互 定制服务，单独为一个个体提供优良的服务 接口设计要有限度 根据接口隔离原则拆分接口时，首先必须满足单一职责原则。接口和类尽量使用原子接口或原子类来组装。 一个接口只服务玉一个子模块或业务 通过业务逻辑压缩接口中的public方法 已经被污染的接口，尽量去修改，若变更风险较大，则采用适配器模式进行转化处理 了解环境，拒绝盲从 迪米特法则LD也称最少知识原则：一个对象应该对其他对象有最少的了解，对需要耦合或调用的类知道越少越好。 只和朋友交流：类与类间的关系是建立在类之间而不是方法间，一个方法尽量不引入一个类中不存在的对象 朋友间也是有距离的：尽量不对外公布太多public方法和非静态得public变量，尽量内敛 是自己的就是自己的：若一个方法放在本类中，即不增加类间关系，也对本类不产生负面影响，那就放置在本类中。 谨慎使用Serializable 两个对象之间的耦合就成为朋友关系，朋友关系类型很多如组合、聚合、依赖等。 注：朋友类的定义，出现在成员变量、方法输入输出参数中的类称为成员朋友类，出现在方法体内部的类不属于朋友类。 迪米尔法则要求类羞涩一点，尽量不对外公布太多public方法和非静态得public变量，尽量内敛，多使用private、package-private、protected等访问权限。类公开的public属性或方法越多，修改时涉及得面也就越大，变更引起得风险扩散也就越大。迪米特法则核心观念是类间解耦、弱耦合。 缺点：会产生大量中转或跳转类，导致系统的复杂性提高，同时也为维护带来了难度。使用时请反复权衡，既做到让结构清晰，又做到高内聚底耦合。 开闭原则OCP一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。应该通过扩展来实现变化，而不是通过修改已有代码来实现变化。 开闭原则对扩展开放，对修改关闭，并不意味着不做任何修改，底层模块的变更，必然要有更高层模块进行耦合。 可把变化大致分为三类： 逻辑变化：可以通过修改原有类中的方法来完成，前提是所有依赖或者关联类都按照相同的逻辑处理。 子模块变化：底层模块变化必然引起高层模块变化，因此通过扩展完成变化时，高层模块修改是必然的。 可见视图变化 开闭原则是最基础的一个原则，前五个原则都是开闭原则的具体形态，前五个原则就是指导设计的工具和方法，而开闭原则才是精神领袖。 开闭原则对测试的影响在比较重要的方法，测试方法都会很多，可能测试逻辑都很复杂，若要通过修改修改一个方法或多个方法来完成变化，基本上测试用例都得重新写。所以需要通过扩展来实现业务逻辑而不是修改。 开闭原则可以提高复用性在面向对象设计中，所有的逻辑都是从原子逻辑组合而来，而不是在一个类中独立实现一个业务逻辑。颗粒度越小，被复用的可能性就越大。避免相同的逻辑分撒在多个角落，缩小颗粒度，直到一个逻辑不可再拆分为止。 开闭原则可以提高可维护性面向对象开发的要求开闭原则应用抽象约束通过接口或抽象类可以约束一组可能变化的行为，并且能够实现对扩展开放： 通过接口或抽象类约束扩展，对扩展边界限定，不允许出现在接口或抽象类中不存在的public方法 参数类型、引用对象尽量使用接口或抽象类，而不是实现类 抽象层尽量保持稳定 元数据（metadata）控制模块行为尽量使用元数据来控制程序行为，减少重复开发，如login方法中提供的先检查IP地址是否在允许访问的列表中，然后在确定是否需要到数据库中验证密码，表达的极致其实就是控制反转，如Spring的IoC容器。 注：元数据是用来描述环境和数据的数据，通俗的说就是配置参数。 制定项目章程对于项目来说约定优于配置。 封装变化对变化的封装：将相同的变化封装到一个接口或抽象类中，将不同的变化封装到不同的接口或抽象类中，不应该有两个不同的变化出现在同一个接口或抽象类中。 封装变化，也就是受保护的变化，找出预计有变化或不稳定的点。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"}]},{"title":"Maven常见问题总结","date":"2020-07-05T16:00:00.000Z","path":"Blog/Maven/Maven常见问题总结/","text":"IDEA中POM变更IDEA中由于POM中未配置maven-compiler-plugin插件可能导致每次POM发生变更时，Language level变成5，从而导致编译时不成功。 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; Maven编译后文件损坏在一般Maven项目中的build标签下通常会有如下配置： 123456789101112131415161718192021&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;application-test.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; 以上的配置本身是没有问题的，但在某些需要需要将一些文件存放在项目中直接提供下载时，以上配置就回有问题，如果是将文件放到resources目录下，由于filtering设置为true，开启了过滤，会用指定的参数替换directory下的文件中的参数(eg. ${name})。从而导致文件可能会损坏。 若配置文件需要传参数将filtering设置为false显然是不行的。使用exclude排除想下载的文件打包时都不会将文件打到jar包中，显然也是不行的。然后尝试做了如下调整，但并没有生效： 1234567891011121314151617181920&lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;application-test.yml&lt;/exclude&gt; &lt;exclude&gt;src/main/resources/download&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt;&lt;/resource&gt;&lt;resource&gt; &lt;directory&gt;src/main/resources/download&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt;&lt;/resource&gt; 最终只能将下载的文件单独放到其他目录，然后做如下配置： 12345678910111213141516171819202122232425262728&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;application-test.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;download&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; HBase依赖冲突远程连接maven依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt;&lt;/dependency&gt; 连接代码： 123456789101112131415161718@Beanpublic Connection hbaseConnection() throws IOException &#123; org.apache.hadoop.conf.Configuration conf = HBaseConfiguration.create(); conf.set(\"hbase.zookeeper.quorum\", \"127.0.0.1\"); conf.set(\"hbase.zookeeper.property.clientPort\", \"2181\"); conf.set(\"zookeeper.znode.parent\", \"/hbase-unsecure\"); Connection connection = ConnectionFactory.createConnection(conf); return connection;&#125;public String query(String tableName, String familyName, String columnName, String qualifier) throws Exception &#123; TableName name = TableName.valueOf(tableName); Table table = hbaseConnection.getTable(name); Get get = new Get(qualifier.getBytes()); get.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(columnName)); Result rs = table.get(get); return Bytes.toString(rs.value());&#125; hive依赖包冲突在项目中同时存在hive和hbase时，hive中引用的guava与hbase中引用的guava版本冲突，从而导致执行hbase查询时报错。 1org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.&lt;init&gt;()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator Stopwatch在google的guava包下，hbase1.1.2只在guava12-16下能正常运行。guava17开始，出现以上异常。尝试着将guava版本降低，后启动项目后报如下错误： 123An attempt was made to call the method com.google.common.base.Splitter.splitToList(Ljava/lang/CharSequence;)Ljava/lang/List; but it does not exist. Its class, com.google.common.base.Splitter, is available from the following locations: jar:file:/mvnRespo/org/apache/hive/hive-exec/1.2.1/hive-exec-1.2.1.jar!/com/google/common/base/Splitter.class jar:file:/mvnRespo/com/google/guava/guava/16.0/guava-16.0.jar!/com/google/common/base/Splitter.class 由此可见hive必须依赖高版本的guava才行，然后就尝试着将hbase的依赖版本升级到1.3.0，问题得到了解决。 tablestore依赖包冲突12345678910111213141516171819202122232425262728@Value(value = \"$&#123;aliyun.endpoint:http&#125;\")private String endPoint;@Value(value = \"$&#123;aliyun.accessKeyId:test&#125;\")private String accessKeyId;@Value(value = \"$&#123;aliyun.accessSecret:test&#125;\")private String accessSecret;@Value(value = \"$&#123;aliyun.instanceName:test&#125;\")private String instanceName;private SyncClient syncClient;@PostConstructpublic void init() &#123; syncClient = new SyncClient(endPoint, accessKeyId, accessSecret, instanceName);&#125;public String query(String key, String value, String tableName, String columnName) &#123; PrimaryKeyBuilder primaryKeyBuilder = PrimaryKeyBuilder.createPrimaryKeyBuilder(); primaryKeyBuilder.addPrimaryKeyColumn(key, PrimaryKeyValue.fromString(value)); PrimaryKey primaryKey = primaryKeyBuilder.build(); GetRowRequest request = new GetRowRequest(); SingleRowQueryCriteria singleRowQueryCriteria = new SingleRowQueryCriteria(tableName, primaryKey); singleRowQueryCriteria.setMaxVersions(1); request.setRowQueryCriteria(singleRowQueryCriteria); GetRowResponse response = syncClient.getRow(request); Row row = response.getRow(); return row.getLatestColumn(columnName).getValue().asString();&#125; 在项目中同时存在tablestore和hbase时，tablestore中引用的protobuf版本2.4.1与hbase中引用的protobuf版本2.5.0版本冲突，从而导致执行hbase查询时报错。 1Caused by: java.lang.VerifyError: class org.apache.hadoop.hbase.protofuf.generated.ClientProtos$Result overrides final method getUnknownFields.()Lcom/google/protobuf/UnknownFieldSet; 首先想到的是引入高版本的protobuf。但是引入高版本的protobuf后查询阿里的彩虹表tablestore时会报另外的错误。 1java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses. 尝试着将hbase的版本升高到2.2.0，然后发现问题解决了，然后继续查看了一下protobuf依赖冲突版本，发现多了一个hbase-shaded-protobuf,原来在该版本中使用了hbase-shaded , 用来更改hbase中的一些报名，解决protobuf的冲突问题。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Go基础","date":"2020-07-02T16:00:00.000Z","path":"Blog/杂记/Go/Go基础/","text":"Go语言是静态类型语言，所有的内存在 Go 中都是经过初始化的，当一个变量被声明之后，系统自动赋予它该类型的零值：int 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil 等。 只有两个相同类型的值才可以进行比较，如果值的类型是接口（interface），那么它们也必须都实现了相同的接口。&amp;&amp;的优先级比||高（&amp;&amp; 对应逻辑乘法，|| 对应逻辑加法，乘法比加法优先级要高）。 变量、函数、常量名称如果首字母大写，则表示它可被其它的包访问；如果首字母小写，则表示它只能在本包中使用。 nil 不是关键字或保留字且不能比较。 数据类型Go语言的基本类型有： bool string int、int8、int16、int32、int64 uint、uint8、uint16、uint32、uint64、uintptr（只有在底层编程时才需要） byte （uint8 的别名） rune （int32 的别名 代表一个 Unicode 码点） float32、float64 complex64、complex128 尽管在某些特定的运行环境下 int、uint 和 uintptr 的大小可能相等，但是它们依然是不同的类型，在需要把 int 类型当做 int32 类型使用的时候必须显示的对类型进行转换。 1234567891011121314const num1 int = 1var num1, num2, num3 = 1, 2, 3var num1, num2, num3 = 1, \"2\", 3.5var ( num1 int num2 string num3 float64)var ( num1 = 1 num2 = \"2\" num3 = 3.5) Go是一门静态类型语言，每个变量都有一个在编译时就确定的静态类型。虽然a和b的的基本类型相同，但静态类型不同，无类型转换的情况下无法相互赋值。虽然在运行时中，接口变量存储的值也许会变，但接口变量的类型是不会变的。 1234type MyInt intvar a intvar b MyInt 容器Go语言常用容器有数组，切片，Map，List。map和切片是不可以用==直接被比较的。 数组的长度必须是常量表达式，若数组长度的位置出现...省略号，则表示数组的长度是根据初始化值的个数来计算。数组的长度是数组类型的一个组成部分，若两个数组类型相同（包括数组的长度，数组中元素的类型），可直接通过较运算符==和!=来判断两个数组是否相等，不能比较两个类型不同的数组，且不能相互赋值，否则程序将无法完成编译。 1234var numArr = [3]int&#123;2, 3, 4,&#125;strArr := [3]int&#123;\"2\", \"3\", \"4\"&#125;array := [5]int&#123;1:10, 3:30&#125; 切片（slice）是对数组的一个连续片段的引用，所以切片是一个引用类型，终止索引标识的项不包括在切片内。切片的内部结构包含地址、大小和容量，切片一般用于快速地操作一块数据集合。切片在扩容时，容量的扩展规律是按容量的 2 倍数进行扩充。在切片开头添加元素一般都会导致内存的重新分配，而且会导致已有元素全部被复制 1 次。make函数创建切片时若只指定长度，则切片的长度和容量相等，不允许创建长度大于容量的切片。 123456789101112131415161718192021222324252627var numbers = [4]int&#123;1, 2&#125;var arr = [...]int&#123;1, 2, 3, 4, 5,&#125;slice := arr[:]slice := arr[1:3]slice := arr[1:]slice := arr[:3]var slice []intslice = append(slice, 1)var slice = make([]int, 2, 5)slice = append(slice, 1, 2, 3, 4)slice = append(slice, []int&#123;5, 6, 7&#125;...)slice = append([]int&#123;-3, -2, -1&#125;, slice...)slice := []int&#123;1, 2, 3, 4&#125;slice = append(slice[:2], append([]int&#123;6, 7&#125;, slice[2:]...)...)sliceA := []int&#123;1, 2, 3, 4, 5&#125;sliceB := []int&#123;6, 7, 8&#125;copyCount := copy(sliceA, sliceB)sliceB := []int&#123;1, 2, 3, 4, 5&#125;sliceA := []int&#123;6, 7, 8&#125;copyCount := copy(sliceA, sliceB)// 创建容量和长度都是100的切片slice := []int&#123;99:0&#125; 计算切片的长度和容量，若底层数组容量k的切片slice[i:j]，长度为j-i，容量为k-i。也可以通过第三个索引来控制新切片的容量。若底层数组容量k的切片slice[i:j:s]，长度为j-i，容量为s-i，s&lt;=K。 map 是引用类型，可动态增长，未初始化的 map 的值是 nil，使用函数 len() 可以获取 map 中 pair 的数目。map不能使用cap()函数。定义map时可现实指定容量，当 map 增长到容量上限的时候，如果再增加新的 key-value，map 的大小会自动加 1。map可以存函数。map是无序的。切片、函数以及包含切片的结构类型由于具有引用语意不能作为map的键。 1234567891011121314151617181920212223242526var mapLit = map[int]string&#123;&#125;var mapLit map[int]stringvar mapLit = make(map[int]string, 16)mapLit := map[int]string&#123;1: \"a\", 2: \"b\"&#125;mapLit[3] = \"c\"for key, value := range mapLit &#123; fmt.Println(\"key value:\", key, value)&#125;delete(mapLit, 1)mapLit := map[string]int&#123; \"hello\": 100, \"world\": 200,&#125;if value, isExist := mapLit[\"hello\"]；isExist： fmt.Println(\"value:\", value)skill := map[string]func()&#123; \"fire\": func() &#123; fmt.Println(\"chicken fire\") &#125;,&#125;f, ok := skill[\"fire\"] 列表是一种非连续的存储容器，由多个节点组成，节点通过一些变量记录彼此之间的关系。 123456789lit := list.New()lit.PushBack(\"AA\")lit.PushFront(\"BB\")element := lit.PushFront(\"CC\")lit.InsertBefore(\"DD\", element)for i := lit.Front(); i != nil; i = i.Next() &#123; fmt.Println(\"lit value:\", i.Value)&#125;lit.Remove(element) Go语言线程安全的sync.Map，Range返回为false时将不再往下遍历。 12345678var syncMap sync.MapsyncMap.Store(1, \"a\")syncMap.Store(2, \"b\")value, ok := syncMap.Load(2)syncMap.Range(func(key, value interface&#123;&#125;) bool &#123; fmt.Println(\"key, value\", key, value) return true&#125;) 流程控制Go 语言常用流程控制有 if 和 for，而 switch 和 goto 主要是为了简化代码、降低重复代码而生的结构，属于扩展类的流程控制。 if-else分支结构，可结合goto使用。 123456789if index := 12; index &gt; 10 &#123;&#125; else &#123;&#125;if index := 10; index == 10 &#123; goto onExit&#125;onExit:fmt.Println(\"exit\") go中只有for循环结构，不支持 while 和 do-while 结构；for range 可以遍历数组、切片、字符串、map 及通道（channel）；其中用到的range 返回的是每个元素的副本，而不是直接返回对该元素的引用。字符串的遍历是一个个rune 字符。 1234567891011121314151617181920212223242526272829JLoop:for j := 0; j &lt; 5; j++ &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 5 &#123; break JLoop &#125; &#125;&#125;var index intfor index &lt; 10 &#123; index++&#125;str := \"12456789\"for pos, char := range str &#123; fmt.Println(\"pos, char:\", pos, char)&#125;channel := make(chan int)go func() &#123; channel &lt;- 1 channel &lt;- 2 channel &lt;- 3 close(channel)&#125;()for value := range channel &#123; fmt.Println(\"channel value:\", value)&#125; switch表达式不需要为常量，甚至不需要为整数，case 按照从上到下的顺序进行求值，直到找到匹配的项，若switch 没有表达式，则对 true 进行匹配。fallthrough会紧接着执行下一个 case。 12345678910111213141516str := \"kk\"switch str &#123;case \"hello\", \"kk\": fmt.Println(1) fallthroughcase \"world\": fmt.Println(2)default: fmt.Println(1)&#125;r := 11switch &#123;case r &gt; 10 &amp;&amp; r &lt; 20: fmt.Println(r)&#125; 函数Go 语言支持普通函数、匿名函数和闭包。函数间传递变量总是以值得方式传递，数组传递会完整复制并传递给函数，最好只传入指向数组的指针。函数间传递切片和map，只会复制切片和map本身，不会涉及底层数据。 123456789101112131415161718192021222324252627282930313233343536373839404142func funcA() (a, b int) &#123; a = 1 b = 2 return&#125;a, b := funcA()func funcB() (int, int) &#123; return 3, 4&#125;a, b := funcB()f := funcBa, b := f()func funcC() (a, b string, c int) &#123; return \"a1\", \"b2\", 5&#125;a, b, c := funcC()func funcD(arr []int, f func(int)) &#123; for _, value := range arr &#123; f(value) &#125;&#125;funcD([]int&#123;1, 2, 3, 4&#125;, func(data int) &#123; fmt.Println(\"this value:\", data)&#125;)// 函数变量var f func() (int, int)f = funcAa, b := f()// 匿名函数func(data int) &#123; fmt.Println(\"inner func:\", data)&#125;(100)f := func(data int) &#123; fmt.Println(\"inner func:\", data)&#125;f(500) 闭包是引用了自由变量的函数，被引用的自由变量和函数一同存在，即使已经离开了自由变量的环境也不会被释放或者删除。被捕获到闭包中的变量让闭包本身拥有了记忆效应。 12345678910func accumulate(value int) func() int &#123; return func() int &#123; value++ return value &#125;&#125;accumulator := accumulate(1)fmt.Println(accumulator()) // 2fmt.Println(accumulator()) // 3 可变参数和任意类型的可以变参数，用 interface{} 传递任意类型数据，可变参数变量是一个包含所有参数的切片，如果要将这个含有可变参数的变量传递给下一个可变参数函数，可以在传递时给可变参数变量后面添加...，这样就可以将切片中的元素进行传递，而不是传递可变参数变量本身。 1234567891011121314151617181920212223242526func notFixedParam(args ...int) &#123;&#125;func notFixedParamV2(format string, args ...interface&#123;&#125;) &#123; for _, arg := range args &#123; switch arg.(type) &#123; case int: case string: case int64: default: &#125; &#125;&#125;notFixedParam(1, 2)notFixedParamV2(\"kk\", 1, 234, \"hello\", 3.14)func rawPrint(rawList ...interface&#123;&#125;) &#123; for _, raw := range rawList &#123; fmt.Println(raw) &#125;&#125;func print(slist ...interface&#123;&#125;) &#123; rawPrint(slist...)&#125; defer 语句会将其后面跟随的语句进行延迟处理，在 defer 归属的函数即将返回时，将延迟处理的语句按 defer 的逆序进行执行。类似java的finally语句块。可与宕机panic 一起使用，宕机前会优先执行defer。提供recover 用于宕机恢复，且仅在延迟函数 defer 中有效。正常的执行过程中，调用 recover 会返回 nil 并且没有其他任何效果，调用 recover 可以捕获到 panic 的输入值，并且恢复正常的执行。recover 的宕机恢复机制就对应其他语言中的 try/catch 机制。 12defer fmt.Println(\"宕机后要做的事情\")panic(\"宕机\") 结构体结构体的定义只是一种内存布局的描述，只有当结构体实例化时，才会真正地分配内存。使用new或&amp;构造的类型实例的类型是类型的指针。Go语言的类型或结构体没有构造函数的功能. 使用.来访问结构体的成员变量，访问结构体指针的成员变量时可以继续使用.，Go使用了语法糖（Syntactic sugar）技术，将 ins.Name 形式转换为 (*ins).Name；对结构体进行&amp;取地址操作时，视为对该类型进行一次 new 的实例化操作； 1234567891011121314151617181920212223242526272829303132333435type Color struct &#123; R, G, B byte&#125;color := new(Color)(*color).R = 12color.G = 16color := &amp;Color&#123;&#125;(*color).R = 12color.G = 16type Command struct &#123; Name string Var *int Comment string&#125;version := 1// 使用键值对填充结构体cmd := &amp;Command&#123; Name: \"version\", Var: &amp;version, Comment: \"show version\",&#125;fmt.Println(\"cmd, Name, Var, Comment:\", *cmd, cmd.Name, *cmd.Var, cmd.Comment)// 使用多个值的列表初始化结构体cmd := Command&#123; \"version\", &amp;version, \"show version\",&#125;fmt.Println(\"cmd, Name, Var, Comment:\", cmd, cmd.Name, *cmd.Var, cmd.Comment) 匿名结构体没有类型名称，无须通过 type 关键字定义就可以直接使用。 12345678910111213141516171819202122232425ins := struct &#123; Name string Var *int Comment string&#125;&#123; \"version\", &amp;version, \"show version\",&#125;func printMsg (msg *struct&#123; id int data string&#125;)&#123; fmt.Println(\"msg\", msg)&#125;msg := &amp;struct &#123; id int data string&#125;&#123; 1024, \"hello\",&#125;printMsg(msg) 结构体可以包含一个或多个匿名（或内嵌）字段，没有显式的名字，只有字段的类型，此时类型也就是字段的名。在一个结构体中对于每一种数据类型只能有一个匿名字段。结构体可以包含内嵌结构体，内嵌结构体甚至可以来自其他包。 结构体实例访问任意一级的嵌入结构体成员时都只用给出字段名，而无须像传统结构体字段一样，通过一层层的结构体字段访问到最终的字段。内嵌结构体字段仍然可以使用详细的字段进行一层层访问，内嵌结构体的字段名就是它的类型名。 1234567891011121314151617181920212223type innerS struct &#123; in1 int in2 int&#125;type outerS struct &#123; b int c float32 in1 int int innerS&#125;outer := new(outerS)outer.b = 6outer.c = 7.5outer.int = 60outer.in1 = 20outer.innerS.in1 = 5outer.in2 = 10fmt.Println(\"outer1 :\", *outer)outer2 := outerS&#123;6, 7.5, 20, 60, innerS&#123;5, 10&#125;&#125;fmt.Println(\"outer2 :\", outer2) 结构体标签是对结构体字段的额外信息标签，由一个或多个键值对组成；键与值使用冒号分隔，值用双引号括起来；键值对之间使用一个空格分隔。标签内容是静态的，无须实例化结构体，可以通过反射从结构体中获取标签内容。 123456789type Ins struct &#123; in1 int `key1:\"value1\" key2:\"value2\"` in2 int `key1:\"value1\" key2:\"value2\"`&#125;typeOfIns := reflect.TypeOf(Ins&#123;&#125;)if catType, ok := typeOfIns.FieldByName(\"in2\"); ok &#123; fmt.Println(catType.Tag.Get(\"key1\"))&#125; 方法能给用户定义的类型添加新的行为，实际上也是函数，仅仅是在申明时，在关键字func和方法名间增加了一个参数，该参数称为接收者（值接收者、指针接收者），有接收者为方法，无接收者为函数。值接收者调用时会使用这个值的副本来执行，如下所示changeEmailV2方法是无效的。 123456789101112type cusUser struct &#123; name string email string&#125;func (u *cusUser) changeEmailV1(email string) &#123; u.email = email&#125;func (u cusUser) changeEmailV2(email string) &#123; u.email = email&#125; 若要创建一个新值，该类型的方法使用值接收者，若要修改当前值，使用指针接收者。 接口Go无类和继承的概念，Go语言的接口在命名时，一般会在单词后面添加 er；当方法名首字母大写时，且该接口类型名首字母也大写时，该方法可被接口所在的包之外的代码访问。 接口被实现必须满足，接口的方法与实现接口的类型方法格式一致，接口中所有方法均被现实。类型和接口之间有一对多和多对一的关系。一个类型可以同时实现多个接口，一个接口的方法，不一定需要由一个类型完全实现。 一个接口可以包含一个或多个其他的接口，这相当于直接将这些内嵌接口的方法列举在外层接口中一样。只要接口的所有方法被实现，则这个接口中的所有嵌套接口的方法均可以被调用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type DataWriter interface &#123; WriteData(data interface&#123;&#125;) error CanWriter() bool&#125;type Closer interface &#123; WriterClose() error&#125;type FileWriter struct &#123;&#125;type NetWriter struct &#123; FileWriter&#125;func(d *FileWriter) WriteData(data interface&#123;&#125;) error &#123; fmt.Println(\"WriteData:\", data) return nil&#125;func(d *FileWriter) WriterClose() error &#123; fmt.Println(\"FileWriter Close\") return nil&#125;func(d *NetWriter) CanWriter() bool &#123; fmt.Println(\"CanWrite\") return false&#125;fileWriter := new(FileWriter)fileWriter.WriterClose()fileWriter.WriteData(\"FileWriter\")netWriter := new(NetWriter)netWriter.WriterClose()netWriter.WriteData(\"NetWriter\")netWriter.CanWriter()f := new(NetWriter)var writer DataWriterwriter = fwriter.WriteData(\"NetWriter2\")writer.CanWriter()var writer DataWriter = new(NetWriter)writer = fwriter.WriteData(\"NetWriter3\")writer.CanWriter()var writeCloser DataWriteCloser = new(NetWriter)writeCloser.WriterClose()writeCloser.WriteData(\"writeCloser\")writeCloser.CanWriter() 将接口转换为其他接口，若不写ok接收是否为实现该类型，若rw没有完全实现接口，将触发宕机。 123var writeCloser DataWriteCloser = new(NetWriter)rw, ok := writeCloser.(Closer)fmt.Println(ok, \";\", rw.WriterClose()) 将接口转换为其他类型时，接口内保存的实例对应的类型指针，必须是要转换的对应的类型指针。 123var writeCloser DataWriteCloser = new(NetWriter)rw, ok := writeCloser.(*NetWriter)fmt.Println(ok, \";\", rw.WriterClose(), rw.WriteData(\"*NetWriter\"), rw.CanWriter()) 接口在底层的实现有type 和 data两个部分。显式地将 nil 赋值给接口时，接口的 type 和 data 都将为 nil，此时接口与 nil 值判断是相等的。将带有类型的 nil 赋值给接口时，只有 data 为 nil，而type 不为 nil，此时接口与 nil 判断将不相等。 12345678910111213141516type insImpl struct &#123;&#125;func (ins *insImpl) String() string &#123; return \"hi\"&#125;func GetStringer() fmt.Stringer&#123; var ins *insImpl = nil return ins&#125;// falsefmt.Println(GetStringer() == nil)// truevar ins *insImpl = nilfmt.Println(ins == nil) 包Go的源码复用建立在包package的基础上，入口 main() 函数所在的包（package）叫 main。包与文件夹一一对应，一般包的名称就是其源文件所在目录的名称，所有与包相关的操作，必须依赖于工作目录GOPATH。包可以定义在很深的目录中，包名的定义是不包括目录路径的，但是包在引用时一般使用全路径引用。 包的习惯用法： 包名一般小写，使用简短且有意义的名称。 包名一般和所在目录同名，也可不同，包名中不能包含-等特殊符号。 包一般使用域名作为目录名称，能保证包名的唯一性。 包名为 main 的包为应用程序的入口包，编译不包含 main 包的源码文件时不会得到可执行文件。 一个文件夹下的所有源码文件只能属于同一个包，同样属于同一个包的源码文件不能放在多个文件夹下。 包的引用路径分为全路径导入和相对路径导入。可以自定义别名引用包；也可用.省略引用格式，相当于把 包直接合并到当前程序中，在使用 包内的方法是可以不用加前缀直接引用；若只执行包初始化的 init 函数，不使用包内部的数据可使用匿名引用格式； 12345678910// 全路径导入：源码位于GOPATH/src/lab/test目录下import \"lab/test\"// 相对路径导入：源码位GOPATH/src/lab/a目录下import \"../a\"// 自定义别名引用包import F \"fmt\"// 省略引用格式import . \"fmt\"// 匿名引用格式import _ \"fmt\" 一个包可有多个 init 函数，包加载时会执行全部 init 函数，但不能保证执行顺序；包不能出现环形引用；包允许重复引用；包初始化程序从 main 函数引用的包开始，逐级查找包的引用，直到找到没有引用其他包的包，最终生成一个包引用的有向无环图；编译器会将有向无环图转换为一棵树，然后从树的叶子节点开始逐层向上对包进行初始化；单个包的初始化先初始化常量，然后是全局变量，最后执行包的 init 函数。 并发Go 的并发通过 goroutine特性完成。goroutine 类似于线程，但是可根据需要创建多个 goroutine 并发工作。goroutine 是由 Go 运行时调度完成，而线程是由操作系统调度完成。 Go 提供 channel在多个 goroutine 间进行通信，channel是类型相关的语言级别得goroutine间的进程内的通信方式。必须使用 make 创建 channel；可以通过通道共享内置类型、命名类型、结构类型和引用类型的值或者指针。 123456789101112ch := make(chan int)go func() &#123; ch &lt;- 1 &#125;()ch := make(chan interface&#123;&#125;)go func() &#123; ch &lt;- \"hi\" &#125;()type Equip struct &#123; a int b int&#125;ch := make(chan *Equip)go func() &#123; ch &lt;- &amp;Equip&#123;a: 1, b: 2&#125; &#125;() 通道使用&lt;-操作符发送和接收数据；把数据往通道中发送时，若接收方一直未接收，发送操作将持续阻塞；通道的收发操作在不同的两个 goroutine 间进行；接收将持续阻塞直到发送方发送数据；每次接收一个元素；被关闭的通道不会被置为 nil。对已经关闭的通道进行发送，将会触发宕机。从已关闭的通道接收数据或者正在接收数据时，将会接收到通道类型的零值，然后停止阻塞并返回。 1234567891011121314// 阻塞接收数据data := &lt;-ch// 非阻塞接收数据，可能造成高CPU占用，很少使用，若ok未false表示通道ch已关闭data, ok := &lt;-ch// 接收任意数据，忽略接收数据&lt;- ch// 声明一个只能发送的通道类型var chSendOnly = make(chan&lt;- int)// 声明一个只能接收的通道类型var chRecvOnly = make(&lt;-chan int)// 关闭通道close(chSendOnly)// 带缓冲的通道，缓冲通道被填满时，发送数据时发生阻塞，带缓冲通道为空时，接收数据时发生阻塞ch := make(chan int, 3) 协程有独立的栈空间，共享堆空间，调度由用户自己控制，本质上类似于用户级线程，这些用户级线程的调度也是自己实现的。一个线程上可以跑多个协程，协程是轻量级的线程。 使用 go 关键字创建 goroutine 时，被调用函数的返回值会被忽略。若要在 goroutine 中返回数据，通过通道把数据从 goroutine 中作为返回值传出。 123go func(param1, param2 int) &#123; fmt.Println(\"param3, param4:\", param1, param2)&#125;(3, 4) Go未为channel专门设置超时处理机制，但可通过select来设置超时。select用法与switch很类似，但select中只要其中一个case已经完成，程序就会继续往下执行，而不会考虑其他case情况，且每个case语句里必须是一个IO操作，select是按顺序从头至尾评估。若无语句可执行，则执行default语句，否则被阻塞。 12345678910ch := make(chan int)quit := make(chan bool)select &#123;case num := &lt;-ch: fmt.Println(\"num:\", num)case &lt;-time.After(3 * time.Second): fmt.Println(\"timeout\") quit &lt;- true&#125; Go的sync包中提供互斥锁sync.Mutex和读写互斥锁sync.RWMutex。同时提供了等待组sync.WaitGroup进行多个任务的同步，每个 sync.WaitGroup 值在内部维护着一个计数，保证在并发环境中完成指定数量的任务，若WaitGroup的值大于0，Wait方法就会被阻塞。同时提供原子访问atomic。 12345678910111213141516171819202122var rw sync.Mutexrw.Lock()defer rw.Unlock()var rw sync.RWMutexrw.RLock()defer rw.RUnlock()rw.Lock()defer rw.Unlock()var wg sync.WaitGroupwg.Add(1)go func()&#123; defer wg.Done() &#125;()wg.Wait()atomic.AddInt32(&amp;counter, 1)// 安全的写整型值atomic.StoreInt64(&amp;counter, 1)// 安全的读整型值atomic.LoadInt64(&amp;counter) 死锁发生条件： 互斥条件 请求和保持条件 不剥夺条件 环路等待 解决办法： 并发范文多个表，约定访问顺序 同一事物中，尽可能一次锁定获取所需资源 容易死锁业务场景，尝试升级锁颗粒度 采用分布式事务锁或乐观锁 反射reflect 包定义了两个重要的类型 Type 和 Value 任意接口值在反射中都可以理解为由 reflect.Type 和 reflect.Value 两部分组成；提供了reflect.TypeOf 和reflect.ValueOf 两个函数来获取任意对象的 Value 和 Type。 反射中分类型Type和种类Kind，当需要区分一个大品种的类型时用Kind，Kind方法描述的是基础类型；如需统一判断类型中的指针时。而Type是指系统原生数据类型，以及使用type关键字定义的类型。通过 reflect.Elem() 方法获取该指针指向的元素类型。Elem方法能够对指针进行解引用，然后将结果存储到反射 Value 类型对象 中。 反射可以将接口类型变量转换为反射类型对象，反射可以将反射类型对象转换为接口类型变量，若要修改反射类型对象其值必须是可写的。可通过 CanSet 方法检查reflect.Value类型变量的可写性。对于不具有可写性的 Value 类型变量，调用 Set 方法会报错。 1234567891011121314151617181920212223242526272829303132333435type T struct &#123; A int B string&#125;t := &amp;T&#123;&#125;typeOfT := reflect.TypeOf(t)// Name: ,Kind:ptrfmt.Println(\"name:\", typeOfT.Name(), \"kind:\", typeOfT.Kind())// 通过 reflect.Elem() 方法获取这个指针指向的元素类型typeOfT = typeOfT.Elem()// Name: T,Kind: structfmt.Println(\"name:\", typeOfT.Name(), \"kind:\", typeOfT.Kind())typeOfT.Field(0).SetInt(99)typeOfT.Field(1).SetString(\"Sunset Strip\")t := T&#123;23, \"skidoo\"&#125;typeOfA := reflect.TypeOf(t)// Name: T,Kind: structfmt.Println(\"name:\", typeOfA.Name(), \"kind:\", typeOfA.Kind())type MyInt intvar x MyInt = 7tof := reflect.TypeOf(x)// Name: MyInt,Kind: intfmt.Println(\"name:\", tof.Name(), \"kind:\", tof.Kind())vof := reflect.ValueOf(x)// 不能是intref := vof.Interface().(MyInt)fmt.Println(\"can set:\", vof.CanSet()) // falsevof2 := reflect.ValueOf(&amp;x)fmt.Println(\"can set:\", vof2.CanSet()) // falsevof3 := vof2.Elem()fmt.Println(\"can set:\", vof3.CanSet()) // truevof3.SetInt(25)fmt.Println(\"ref:\", vof3) // 25 Map、Slice、Chan 属于引用类型，使用起来类似于指针，但是在种类常量定义中仍然属于独立的种类Kind，不属于 Ptr。所有通过reflect.ValueOf(x) 返回的reflect.Value都不可以取地址，通过指针间接地获取的reflect.Value都可以取地址，即使开始的是一个不可取地址的Value。当reflect.Value不可寻址时，使用 Addr() 方法也无法取到值的地址。 已知reflect.Type时，可动态地创建这个类型的实例，实例的类型为指针。 12345var a inttypeOfA := reflect.TypeOf(a)aIns := reflect.New(typeOfA)// name: *int, kind: ptrfmt.Println(\"name:\", aIns.Type(), \"kind:\", aIns.Kind()) 使用反射调用函数时，需将参数使用反射值对象的切片[]reflect.Value构造后传入Call()方法中，调用完成时，函数的返回值通过[]reflect.Value返回。 123456funcVal := reflect.ValueOf(func(a, b int) int &#123; return a + b&#125;)paramList := []reflect.Value&#123;reflect.ValueOf(10), reflect.ValueOf(24)&#125;retList := funcVal.Call(paramList)fmt.Println(\"result:\", retList[0].Int()) Test 测试用例文件不会参与正常源码的编译，不会被包含到可执行文件中； 测试用例的文件名必须以_test.go结尾； 需要使用 import 导入 testing 包； 测试函数的名称要以Test或Benchmark开头，后面可以跟任意字母组成的字符串，但第一个字母必须大写，例如 TestAbc()，一个测试用例文件中可以包含多个测试函数； 单元测试则以(t *testing.T)作为参数，性能测试以(t *testing.B)做为参数； 测试用例文件使用go test命令来执行，源码中不需要 main() 函数作为入口，所有以_test.go结尾的源码文件内以Test开头的函数都会自动执行。 SetFinalizerGo语言自带垃圾回收机制，GC 是自动进行的，可以使用 runtime.GC() 函数手动 GC。 finalizer（终止器）是通过 runtime.SetFinalizer 来设置与对象关联的一个函数，若某对象定义了 finalizer，当它被 GC 时候，该finalizer 将被调用。 1func SetFinalizer(x, f interface&#123;&#125;) 参数x 必须是一个指向通过 new 申请的对象的指针，或者通过对复合字面值取址得到的指针，参数 f 必须是一个函数。SetFinalizer 函数将 x 的终止器设置为 f，当垃圾收集器发现 x 不能再直接或间接访问时，则清理 x 并调用 f(x)，终止器会在 x 不能直接或间接访问后的任意时间被调用执行，不保证终止器会在程序退出前执行，因此一般终止器只用于在长期运行的程序中释放关联到某对象的非内存资源。*x 的大小为 0 字节，也不保证终止器会执行。也可以使用SetFinalizer(x, nil)来清理绑定到 x 上的终止器。 1234567891011121314151617type Road intfunc findRoad(r *Road) &#123; log.Println(\"road:\", *r)&#125;func entry() &#123; var rd = Road(999) r := &amp;rd runtime.SetFinalizer(r, findRoad)&#125;entry()for i := 0; i &lt; 10; i++ &#123; time.Sleep(time.Second) runtime.GC()&#125;","tags":[{"name":"Go","slug":"Go","permalink":"https://yaoyinglong.github.io/tags/Go/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"Go","slug":"杂记/Go","permalink":"https://yaoyinglong.github.io/categories/杂记/Go/"}]},{"title":"图基础","date":"2020-06-21T16:00:00.000Z","path":"Blog/算法/图基础/","text":"​ 图可分为有向图和无向图，一般用G=(V,E)来表示图，V表示顶点，E表示通过图的边，常用邻接矩阵或者邻接表来描述一副图。图的遍历算法，根据访问节点的顺序，可分为广度优先搜索（BFS：Breadth First Search）和深度优先搜索（DFS：Depth First Search），图的存储常用邻接矩阵和邻接表。 ​ 邻接矩阵是指用矩阵来表示图。它是采用矩阵来描述图中顶点之间的关系（及弧或边的权），通常采用两个数组来实现邻接矩阵：一个一维数组用来保存顶点信息，一个二维数组来用保存边的信息，邻接矩阵的缺点就是比较耗费空间。 ​ 邻接表是图的一种链式存储表示方法。它是改进后的邻接矩阵，它的缺点是不方便判断两个顶点之间是否有边，但是相对邻接矩阵来说更省空间。 ​ 一条边上的两个顶点叫做邻接点，有向图有入边（以该点为终点的边）和出边（以该点为起点的边）的概念。无向图中，某个顶点的度是邻接到该顶到的边的数目。有向图有入度和出度之分。 简单路径：一条路径上顶点不重复出现 简单回路：第一个顶点和最后一个顶点相同，其它各顶点都不重复的回路则是简单回路 连通图：对无向图而言，任意两顶点之间存在一条无向路径，则称该无向图为连通图。 对有向图而言，若图中任意两个顶点之间存在一条有向路径，则称该有向图为强连通图。 连通分量：非连通图中的各个连通子图称为该图的连通分量。 广度优先搜索（BFS）​ 广度优先搜索在进一步遍历图中顶点之前，先访问当前顶点的所有邻接结点。 首先选择一个顶点作为起始结点 将起始结点放入队列中 从队列首部选出一个顶点，并找出所有与之邻接的结点，将找到的邻接结点放入队列尾部 按照同样的方法处理队列中的下一个结点 深度优先搜索（DFS）​ 深度优先搜索在搜索过程中访问某个顶点后，需要递归地访问此顶点的所有未访问过的相邻顶点，和树的遍历比较类似，若初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。DFS在环监测和拓扑排序中都有不错的应用。 并查集并查集是一种树型的数据结构，用于处理一些不相交集合的合并及查询问题。常常在使用中以森林来表示。在一些有N个元素的集合应用问题中，通常是在开始时让每个元素构成一个单元素的集合，然后按一定顺序将属于同一组的元素所在的集合合并，其间要反复查找一个元素在哪个集合中。 合并操作是把两个不相交的集合合并为一个集合，查询操作是查询两个元素是否在同一个集合中。最简单的并查集效率比较低，可以使用路径压缩的方法，使每个元素到根节点的路径尽可能短，最好只需要一步。 123456789101112131415161718192021class DSU &#123; int[] parent; public DSU(int N) &#123; parent = new int[N]; for (int n = 0; n &lt; N; ++n) &#123; parent[n] = n; &#125; &#125; public int find(int x) &#123; return parent[x] == x ? x : find(parent[x]); &#125; public int findCompress(int x) &#123; return parent[x] == x ? x : (parent[x] = find(parent[x])); &#125; public void union(int x, int y) &#123; parent[find(x)] = find(y); &#125;&#125; 可能会认为并查集始终都是一个只有两层的树，由于压缩路径值在查询时进行，也只压缩一条路径，应该把简单的树往复杂的树上合并，用一个数组rank[]记录每个根节点对应的树的深度，把所有元素的rank秩设为1。按秩合并会带来额外的空间复杂度。 12345678910111213141516171819202122232425262728class DSU &#123; int[] parent; int[] rank; public void init(int N) &#123; parent = new int[N]; for (int n = 0; n &lt; N; ++n) &#123; parent[n] = n; rank[n] = 1; &#125; &#125; public int findCompress(int x) &#123; return parent[x] == x ? x : (parent[x] = find(parent[x])); &#125; public void merge(int i, int j) &#123; int x = find(i), y = find(j); if (rank[x] &lt;= rank[y]) &#123; parent[x] = y; &#125; else &#123; parent[y] = x; &#125; if (rank[x] == rank[y] &amp;&amp; x != y) &#123; rank[y]++; &#125; &#125;&#125; 克隆图使用哈希表存储所有已被访问和克隆的节点。哈希表中的 key 是原始图中的节点，value 是克隆图中的对应节点。若某个节点已经被访问过，则返回其克隆图中的对应节点。若当前访问的节点不在哈希表中，则创建其克隆节点并存储在哈希表中。递归调用每个节点的邻接点。 1234567891011121314151617181920212223242526272829303132333435363738class Node &#123; public int val; public List&lt;Node&gt; neighbors; public Node() &#123; val = 0; neighbors = new ArrayList&lt;Node&gt;(); &#125; public Node(int _val) &#123; val = _val; neighbors = new ArrayList&lt;Node&gt;(); &#125; public Node(int _val, ArrayList&lt;Node&gt; _neighbors) &#123; val = _val; neighbors = _neighbors; &#125;&#125;private Map&lt;Node, Node&gt; nodeMap = new HashMap&lt;&gt;();public Node cloneGraph(Node node) &#123; if (node == null) &#123; return null; &#125; if (nodeMap.containsKey(node)) &#123; return nodeMap.get(node); &#125; Node cloneNode = new Node(node.val, new ArrayList&lt;&gt;()); nodeMap.put(node, cloneNode); for (Node neighbor : node.neighbors) &#123; cloneNode.neighbors.add(cloneGraph(neighbor)); &#125; return cloneNode;&#125;","tags":[{"name":"图，算法","slug":"图，算法","permalink":"https://yaoyinglong.github.io/tags/图，算法/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"树基础","date":"2020-06-21T16:00:00.000Z","path":"Blog/算法/树基础/","text":"特点 每个节点有零个或多个子节点； 没有父节点的节点称为根节点； 每个非根节点有且仅有一个父节点； 除了根节点以外，每个子节点都可分为多个不相交的子树； 术语 节点的度：一个节点含有的子树的个数称为该节点的度，二叉树的度为2； 树的度：一棵树中，最大的节点的度称为树的度； 叶节点或终端节点：度为零的节点； 父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点； 子节点：一个节点含有的子树的根节点称为该节点的子节点； 兄弟节点：具有相同父节点的节点互称为兄弟节点； 节点的层次：从根开始定义起，根为第1层，根的子节点为第2层，以此类推； 树的高度或深度：树中节点的最大层次； 堂兄弟节点：父节点在同一层的节点互为堂兄弟； 节点的祖先：从根到该节点所经分支上的所有节点； 子孙：以某节点为根的子树中任一节点都称为该节点的子孙。 森林：由m（m&gt;=0）棵互不相交的树的集合称为森林； 分类 无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树； 有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树； 二叉树：每个节点最多含有两个子树的树称为二叉树； 完全二叉树：对于一颗二叉树，假设其深度为d(d&gt;1)。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，其中满二叉树的定义是所有叶节点都在最底层的完全二叉树; 平衡二叉树（AVL树，红黑树是该树的一种）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树，SGI/STL的set/map底层都是用红黑树实现的； 排序二叉树（二叉查找树（英语：Binary Search Tree），也称二叉搜索树、有序二叉树）； 霍夫曼树（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树； B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树。 二叉树的遍历​ 二叉树的遍历分为广度优先遍历和深度优先遍历，广度优先遍历又叫层序遍历，从上往下每一层从左到右依次访问节点；深度优先遍历可细分为先序遍历、中序遍历、后续遍历； 12345public class TreeNode &#123; int value; TreeNode leftNode; TreeNode rightNode;&#125; 前序遍历对任一子树，先访问根，然后遍历其左子树，最后遍历其右子树。前序遍历的形式总是：[ 根节点, [左子树的前序遍历结果], [右子树的前序遍历结果] ] 1234567891011121314151617181920212223public void preorder(TreeNode treeNode) &#123; if (treeNode == null) &#123; return; &#125; System.out.println(treeNode); preorder(treeNode.leftNode); preorder(treeNode.rightNode);&#125;public void preOrderDfs(TreeNode root) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()) &#123; TreeNode tree = stack.pop(); System.out.println(tree); if (tree.rightNode != null) &#123; stack.push(tree.rightNode); &#125; if (tree.leftNode != null) &#123; stack.push(tree.leftNode); &#125; &#125;&#125; 中序遍历对任一子树，先遍历其左子树，然后访问根，最后遍历其右子树。中序遍历的形式总是：[ [左子树的中序遍历结果], 根节点, [右子树的中序遍历结果] ] 123456789101112131415161718192021public void inorder(TreeNode treeNode) &#123; if (treeNode == null) &#123; return; &#125; inorder(treeNode.leftNode); System.out.println(treeNode); inorder(treeNode.rightNode);&#125;public void inOrderDfs(TreeNode root) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while (root != null || !stack.isEmpty()) &#123; while (root != null) &#123; stack.push(root); root = root.left; &#125; root = stack.pop(); System.out.print(root.val); root = root.right; &#125;&#125; 后序遍历对任一子树，先遍历其左子树，然后遍历其右子树，最后访问根。 123456789101112131415161718192021222324252627282930public void backorder(TreeNode treeNode) &#123; if (treeNode == null) &#123; return; &#125; backorder(treeNode.leftNode); backorder(treeNode.rightNode); System.out.println(treeNode);&#125;public void backOrderDfs(TreeNode root) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while (root != null || !stack.isEmpty()) &#123; while (root != null) &#123; stack.push(root); root = root.left; &#125; root = stack.pop(); TreeNode right = null; while (root.right == null || root.right == right) &#123; System.out.print(root.val); right = root; if (stack.isEmpty()) &#123; return; &#125; root = stack.pop(); &#125; stack.push(root); root = root.right; &#125;&#125; 层序遍历|广度优先遍历12345678910111213141516171819public List&lt;Integer&gt; bfs(TreeNode root) &#123; List&lt;Integer&gt; lists = new ArrayList&lt;Integer&gt;(); if (root == null) &#123; return lists; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode tree = queue.poll(); if (tree.leftNode != null) &#123; queue.offer(tree.leftNode); &#125; if (tree.rightNode != null) &#123; queue.offer(tree.rightNode); &#125; lists.add(tree.value); &#125; return lists;&#125; 二叉树的深度计算二叉树的深度可以通过后序遍历和层序遍历计算二叉树的深度。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public int maxDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; return Math.max(maxDepth(root.leftNode), maxDepth(root.rightNode)) + 1;&#125;public int maxDepthBfs(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); int maxDepth = 0; queue.add(root); while (!queue.isEmpty()) &#123; maxDepth++; int len = queue.size(); for (int i = 0; i &lt; len; i++) &#123; TreeNode treeNode = queue.poll(); if (treeNode.leftNode != null) &#123; queue.add(treeNode.leftNode); &#125; if (treeNode.rightNode != null) &#123; queue.add(treeNode.rightNode); &#125; &#125; &#125; return maxDepth;&#125;public int minDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int left = minDepth(root.left); int right = minDepth(root.right); if (left == 0) &#123; return right + 1; &#125; if (right == 0) &#123; return left + 1; &#125; return Math.min(left, right) + 1;&#125;public int minDepthBfs(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int minDepth = 0; while (!queue.isEmpty()) &#123; int len = queue.size(); for (int i = 0; i &lt; len; i++) &#123; TreeNode node = queue.poll(); if (node.left == null &amp;&amp; node.right == null) &#123; return minDepth + 1; &#125; if (node.left != null) &#123; queue.offer(node.left); &#125; if (node.right != null) &#123; queue.offer(node.right); &#125; &#125; minDepth++; &#125; return minDepth;&#125; 二叉树的直径123456789101112131415int diameter = 0;public int diameter(TreeNode root) &#123; depth(root); return diameter;&#125;public int depth(TreeNode treeNode) &#123; if (treeNode == null) &#123; return 0; &#125; int left = depth(treeNode.leftNode); int right = depth(treeNode.rightNode); diameter = Math.max(left + right, diameter); return Math.max(left, right) + 1;&#125; 镜像二叉树转换123456789101112131415161718192021222324252627282930public TreeNode mirrorTree(TreeNode root) &#123; if (root == null) &#123; return null; &#125; TreeNode tmp = root.left; root.left = mirrorTree(root.right); root.right = mirrorTree(tmp); return root;&#125;public TreeNode mirrorTree(TreeNode root) &#123; if (root == null) &#123; return null; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode treeNode = queue.poll(); if (treeNode.right != null) &#123; queue.offer(treeNode.right); &#125; if (treeNode.left != null) &#123; queue.offer(treeNode.left); &#125; TreeNode tmp = treeNode.left; treeNode.left = treeNode.right; treeNode.right = tmp; &#125; return root;&#125; 对称二叉树判断12345678910111213public boolean isSymmetric(TreeNode root) &#123; return check(root, root);&#125;public boolean check(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null) &#123; return true; &#125; if (p == null || q == null || p.val != q.val) &#123; return false; &#125; return check(p.left, q.right) &amp;&amp; check(p.right, q.left);&#125; 合并二叉树123456789101112public TreeNode mergeTrees(TreeNode t1, TreeNode t2) &#123; if (t1 == null) &#123; return t2; &#125; if (t2 == null) &#123; return t1; &#125; t1.val += t2.val; t1.left = mergeTrees(t1.left, t2.left); t1.right = mergeTrees(t1.right, t2.right); return t1;&#125; 最长相同直径12345678910111213141516171819202122public int longest = 0;public int longestUnivaluePath(TreeNode root) &#123; traversal(root); return longest;&#125;public int traversal(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int left = traversal(root.left); int right = traversal(root.right); int arrowLeft = 0, arrowRight = 0; if (root.left != null &amp;&amp; root.left.val == root.val) &#123; arrowLeft += left + 1; &#125; if (root.right != null &amp;&amp; root.right.val == root.val) &#123; arrowRight += right + 1; &#125; longest = Math.max(longest, arrowLeft + arrowRight); return Math.max(arrowLeft, arrowRight);&#125; 最近公共祖先根据 left 和 right ，可展开为四种情况； 当left和right同时为空 ：说明root的左 / 右子树中都不包含 p,q，返回 null； 当left和right同时不为空 ：说明 p, q分列在root的 异侧 ，因此 root为最近公共祖先，返回 root； 当left为空 ，right 不为空 ：p,q都不在 root的左子树中，直接返回 right。具体可分为两种情况： p,q其中一个在root的 右子树中，此时right指向p； p,q两节点都在 root的 右子树中，此时的 right指向最近公共祖先节点 ； 当 left不为空 ， right为空 同理； 1234567891011121314public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if(root == null || root == p || root == q) &#123; return root; &#125; TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); if(left == null) &#123; return right; &#125; if(right == null) &#123; return left; &#125; return root;&#125; 通过前序中序创建树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public TreeNode buildTree(int[] preorder, int[] inorder) &#123; if (preorder == null || inorder == null || preorder.length == 0 || preorder.length != inorder.length) &#123; return null; &#125; Map&lt;Integer, Integer&gt; indexMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; inorder.length; i++) &#123; indexMap.put(inorder[i], i); &#125; return buildTrav(preorder, 0, preorder.length - 1, 0, indexMap);&#125;public TreeNode buildTrav(int[] preorder, int preLeft, int preRight, int inLeft, Map&lt;Integer, Integer&gt; indexMap) &#123; if (preLeft &gt; preRight) &#123; return null; &#125; TreeNode root = new TreeNode(preorder[preLeft]); if (preLeft == preRight) &#123; return root; &#125; int rootIndex = indexMap.get(preorder[preLeft]); int leftNodes = rootIndex - inLeft; root.left = buildTrav(preorder, preLeft + 1, leftNodes + preLeft, inLeft, indexMap); root.right = buildTrav(preorder, preLeft + leftNodes + 1, preRight, rootIndex + 1, indexMap); return root;&#125;public TreeNode buildTree(int[] preorder, int[] inorder) &#123; if (preorder == null || inorder == null || preorder.length == 0 || preorder.length != inorder.length) &#123; return null; &#125; TreeNode root = new TreeNode(preorder[0]); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); int inorderIndex = 0; for (int i = 1; i &lt; preorder.length; i++) &#123; int preorderVal = preorder[i]; TreeNode node = stack.peek(); if (node.val != inorder[inorderIndex]) &#123; node.left = new TreeNode(preorderVal); stack.push(node.left); &#125; else &#123; while (!stack.isEmpty() &amp;&amp; stack.peek().val == inorder[inorderIndex]) &#123; node = stack.pop(); inorderIndex++; &#125; node.right = new TreeNode(preorderVal); stack.push(node.right); &#125; &#125; return root;&#125; 通过中序后序创建树123456789101112131415161718192021222324public int postIndex;public TreeNode buildTree(int[] inorder, int[] postorder) &#123; if (inorder == null || postorder == null || inorder.length == 0 || inorder.length != postorder.length) &#123; return null; &#125; postIndex = inorder.length - 1; Map&lt;Integer, Integer&gt; indexMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; inorder.length; i++) &#123; indexMap.put(inorder[i], i); &#125; return buildTreeTrav(postorder, 0, postIndex, indexMap);&#125;public TreeNode buildTreeTrav(int[] postorder, int inLeft, int inRight, Map&lt;Integer, Integer&gt; indexMap) &#123; if (inLeft &gt; inRight) &#123; return null; &#125; TreeNode root = new TreeNode(postorder[postIndex]); postIndex--; int rootIndex = indexMap.get(root.val); root.right = buildTreeTrav(postorder, rootIndex + 1, inRight, indexMap); root.left = buildTreeTrav(postorder, inLeft, rootIndex - 1, indexMap); return root;&#125; 通过前序后序创建树12345678910111213141516171819202122public TreeNode constructFromPrePost(int[] pre, int[] post) &#123; return constructFromPrePostTrav(pre, post, 0, 0, pre.length);&#125;public TreeNode constructFromPrePostTrav(int[] pre, int[] post, int preLeft, int preRight, int N) &#123; if (N == 0) &#123; return null; &#125; TreeNode root = new TreeNode(pre[preLeft]); if (N == 1) &#123; return root; &#125; int L = 1; for (; L &lt; N; ++L) &#123; if (post[preRight + L - 1] == pre[preLeft + 1]) &#123; break; &#125; &#125; root.left = constructFromPrePostTrav(pre, post, preLeft + 1, preRight, L); root.right = constructFromPrePostTrav(pre, post, preLeft + L + 1, preRight + L, N-L-1); return root;&#125; 完全二叉树123456789101112131415161718192021222324public boolean isCompleteTree(TreeNode root) &#123; if (root == null) &#123; return true; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int k = 0; while (!queue.isEmpty()) &#123; int len = queue.size(); for (int i = 0; i &lt; len; i++) &#123; TreeNode node = queue.poll(); if (node == null) &#123; k = 1; continue; &#125; if (k == 1 &amp;&amp; node != null) &#123; return false; &#125; queue.offer(node.left); queue.offer(node.right); &#125; &#125; return true;&#125; 哈夫曼树哈夫曼树的核心思想其实就是贪心算法，即利用局部最优推出全局最优，把频率出现多的用短码表示，频率出现少的就用长码表示。且任何一个字符编码都不是其他任务编码的前缀，在解压缩时，每次会读取尽可能长的可解压的二进制串，故在解压缩时也不会产生歧义。 哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近，给定N个权值作为N个叶子结点，构造一棵二叉树，若该树带权路径长度最小，称这样的二叉树为最优二叉树，也称为Huffman Tree哈夫曼树。若想要得到二进制编码，可将二叉分左节点的边设置为0，右节点的边设置为1。 每次取数值最小的两个节点，将之组成为一颗子树，可规定权值小的为左节点，权值大的为右节点 移除原来的两个点 然后将组成的子树放入原来的序列中 重复执行上面的步骤直到只剩最后一个点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class HfmNode implements Comparable&lt;HfmNode&gt;&#123; // 优先队列,小的我把你优先级调高 String chars; //节点里面的字符 int fre; //表示是频率 HfmNode left; HfmNode right; HfmNode parent; //用来找上层的 @Override public int compareTo(HfmNode o) &#123; return this.fre - o.fre; &#125;&#125;public class HuffmenTree &#123; HfmNode root; List&lt;HfmNode&gt; leafs; // 叶子节点 Map&lt;Character, Integer&gt; weights; // 叶子节点的权重, a,b,c,d,e public HuffmenTree(Map&lt;Character, Integer&gt; weights) &#123; this.weights = weights; leafs = new ArrayList&lt;HfmNode&gt;(); &#125; // 叶子节点进行编码 public Map&lt;Character, String&gt; code() &#123; Map&lt;Character, String&gt; map = new HashMap&lt;&gt;(); for (HfmNode node : leafs) &#123; String code = \"\"; Character c = new Character(node.chars.charAt(0)); // 叶子节点肯定只有一个字符 HfmNode current = node; // 只有一个点 do &#123; if (current.parent != null &amp;&amp; current == current.parent.left) &#123; // 说明当前点是左边 code = \"0\" + code; &#125; else &#123; code = \"1\" + code; &#125; current = current.parent; &#125; while (current.parent != null); // parent == null就表示到了根节点 map.put(c, code); System.out.println(c + \":\" + code); &#125; return map; &#125; public void creatTree() &#123; Character keys[] = weights.keySet().toArray(new Character[0]); // 拿出所有的点 PriorityQueue&lt;HfmNode&gt; priorityQueue = new PriorityQueue&lt;HfmNode&gt;(); // jdk底层的优先队列 for (Character c : keys) &#123; HfmNode hfmNode = new HfmNode(); hfmNode.chars = c.toString(); hfmNode.fre = weights.get(c); // 权重 priorityQueue.add(hfmNode); // 首先把优先队列初始化进去 leafs.add(hfmNode); &#125; int len = priorityQueue.size(); for (int i = 1; i &lt;= len - 1; i++) &#123; // 每次找最小的两个点合并 HfmNode n1 = priorityQueue.poll(); HfmNode n2 = priorityQueue.poll(); // 每次取优先队列的前面两个 就一定是两个最小的 HfmNode newNode = new HfmNode(); newNode.chars = n1.chars + n2.chars; // 把值赋值一下，也可以不复制 newNode.fre = n1.fre + n2.fre; // 把权重相加 // 维护出树的结构 newNode.left = n1; newNode.right = n2; n1.parent = newNode; n2.parent = newNode; priorityQueue.add(newNode); &#125; root = priorityQueue.poll(); // 最后这个点就是根节点 &#125; public static void main(String[] args) &#123; Map&lt;Character, Integer&gt; weights = new HashMap&lt;Character, Integer&gt;(); weights.put('a', 3); weights.put('b', 24); weights.put('c', 6); weights.put('d', 1); weights.put('e', 34); weights.put('f', 4); weights.put('g', 12); HuffmenTree huffmenTree = new HuffmenTree(weights); huffmenTree.creatTree(); Map&lt;Character, String&gt; codeMap = huffmenTree.code(); String str = \"aceg\"; System.out.println(\"编码后的：\"); char[] tests = str.toCharArray(); for (char test : tests) &#123; System.out.print(codeMap.get(test)); &#125; &#125;&#125; 堆树12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class HeapTree &#123; private int size; private Integer[] data; public HeapTree(Integer[] arr) &#123; size = arr.length; data = new Integer[size]; for (int i = 0; i &lt; arr.length; i++) &#123; if (arr[i] == null) &#123; throw new IllegalArgumentException(); &#125; data[i] = arr[i]; &#125; int len = data.length; // len / 2 - 1表示的是从完全二叉数中最后一个元素的父节点开始堆化 for (int i = (len &gt;&gt; 1) - 1; i &gt;= 0; i--) &#123; // o(nlgn) maxHeapDown(i, len); // 将树中最大的元素排到堆顶 &#125; &#125; public void add(Integer element) &#123; if (size + 1 &gt;= data.length) &#123; grow(); &#125; int index = size++; if (index != 0) &#123; while (index &gt; 0) &#123; int parent = index - 1 &gt;&gt; 1; Integer e = data[parent]; if (e &gt;= element) &#123; break; &#125; data[index] = e; index = parent; &#125; data[index] = element; &#125; &#125; public void deleteByIndex(int index) &#123; if (index &gt; size) &#123; throw new IllegalArgumentException(); &#125; int last = --size; data[index] = data[last]; data[last] = null; if (index &lt; last) &#123; maxHeapDown(index, size); &#125; &#125; private void grow() &#123; int oldCapacity = data.length; int newCapacity = oldCapacity &lt;&lt; 1; data = Arrays.copyOf(data, newCapacity); &#125; /** * 将完全二叉树中最大的元素放到堆顶，end表示最多建到的点 */ public void maxHeapDown(int start, int end) &#123; int parent = start; int left = (parent &lt;&lt; 1) + 1; // 找到当前节点的左子节点位置 while (left &lt; end) &#123; int max = left; // max表示左右节点大的那一个在数组中的位置 if (left + 1 &lt; end &amp;&amp; data[left] &lt; data[left + 1]) &#123; // 比较左右节点和父节点的大小 max = left + 1; // 若右节点比左节点大，则将父节点和右节点交换 &#125; // 若左节点比右节点大，则将父节点和左节点交换 if (data[parent] &gt; data[max]) &#123; // 若父节点大于子节点中最大的那一个，则退出 return; &#125; else &#123; // 若父节点小于子节点中最大的那一个，则交换 int tmp = data[parent]; data[parent] = data[max]; data[max] = tmp; parent = max; // 还原指针，交换数据后，max指向的是被交换下来的父节点，还需要往下遍历，故需要将parent指向需要遍历的数据 left = (parent &lt;&lt; 1) + 1; // 找到之前左右节点大的节点的左子节点在数组中的索引位置 &#125; &#125; &#125; public void minHeapDown(Integer[] arr, int start, int end) &#123; int parent = start; int left = (start &lt;&lt; 1) + 1; // 找到当前节点的左子节点位置 while (left &lt; end) &#123; int min = left; // min表示左右节点小的那一个在数组中的位置 if (left + 1 &lt; end &amp;&amp; arr[left] &gt; arr[left + 1]) &#123; min = left + 1; &#125; if (arr[min] &gt; arr[parent]) &#123; // 比较左右节点中小的那一个和父节点的大小 break; // 若小的那个节点都比父节点大，说明不需要再遍历了 &#125; int tmp = arr[min]; arr[min] = arr[parent]; arr[parent] = tmp; parent = min; // 还原指针，交换数据后，min指向的是被交换下来的父节点，还需要往下遍历，故需要将parent指向需要遍历的数据 left = (parent &lt;&lt; 1) + 1; // 找到之前左右节点小的节点的左子节点在数组中的索引位置 &#125; &#125;&#125; 堆树可以解决Top K问题 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class TopK &#123; private final int topK = 10; private final int[] data = new int[topK]; public void topK() &#123; Random r = new Random(); long time = System.currentTimeMillis(); int size = 0; boolean init = false; for (int i = 0; i &lt; 100000000; i++) &#123; int num = r.nextInt(1000000000); if (size &lt; topK) &#123; data[size] = num; size++; &#125; else &#123; if (!init) &#123; // 初始化堆，这里我们只需要初始化一次就可以了 for (int j = topK / 2 - 1; j &gt;= 0; j--) &#123; minHeap(0, topK); &#125; init = true; &#125; if (num &gt; data[0]) &#123; // 小顶堆那么堆顶是最小的，如果当前的数比堆顶大，则替换堆顶，然后做一次堆化 data[0] = num; minHeap(0, topK); &#125; &#125; &#125; System.out.println(\"耗时：\" + (System.currentTimeMillis() - time) + \"ms\"); System.out.println(Arrays.toString(data)); &#125; public void minHeap(int start, int end) &#123; // 构建一个小顶堆 从上往下构建 int parent = start; int left = (start &lt;&lt; 1) + 1; // 找到当前节点的左子节点位置 while (left &lt; end) &#123; int min = left; // min表示左右节点小的那一个在数组中的位置 if (left + 1 &lt; end &amp;&amp; data[left] &gt; data[left + 1]) &#123; min = left + 1; &#125; if (data[min] &gt; data[parent]) &#123; // 比较左右节点中小的那一个和父节点的大小 break; // 若小的那个节点都比父节点大，说明不需要再遍历了 &#125; int tmp = data[min]; data[min] = data[parent]; data[parent] = tmp; parent = min; // 还原指针，交换数据后，min指向的是被交换下来的父节点，还需要往下遍历，故需要将parent指向需要遍历的数据 left = (parent &lt;&lt; 1) + 1; // 找到之前左右节点小的节点的左子节点在数组中的索引位置 &#125; &#125; public static void main(String[] args) &#123; TopK topK = new TopK(); topK.topK(); &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"},{"name":"树","slug":"树","permalink":"https://yaoyinglong.github.io/tags/树/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"Spring常面问题","date":"2020-06-18T16:00:00.000Z","path":"Blog/Interview/Spring常面问题/","text":"什么是BeanFactory？它与ApplicationContext的区别？BeanFactory可以理解为含有bean集合的工厂类， 包含了种bean的定义，以便在接收到客户端请求时将对应的bean实例化。还能在实例化对象时生成协作类之间的关系。此举将bean自身与bean客户端的配置中解放出来，还包含了bean生命周期的控制，调用客户端的初始化方法（initialization methods）和销毁方法（destruction methods）。从表面上看， application context 如同 bean factory 一样具有 bean 定义、 bean 关联关系的设置，根据请求分发 bean 的功能。但 applicationcontext 在此基础上还提供了其他的功能。 1、Spring Boot、Spring MVC、Spring之间的区别？（Spring Boot本质是什么？） 2、Spring Boot Starter是什么？ 3、如何自定义Spring Boot Starter？（如何扩展Spring Boot） 4、Spring Boot的自动装配原理是什么？（源码分析哦） 5、Spring Boot的启动流程是什么？ 6、有没有看过Spring Boot源码？你觉得最神奇的地方是什么？ 7、Spring为什么用“三级缓存”去解决循环依赖？ 8、Spring中Bean的生命周期有哪些步骤？ 9、什么是BeanDefinition？它为什么非常重要？ 10、什么是Bean的后置处理器？ 11、什么是Bean工厂的后置处理器？ 13、什么是FactoryBean？它与BeanFactory的区别？ 14、@Import、@Component、@Bean的区别是什么？ 15、什么是ImportBeanDefinitionRegistrar？它的作用是什么？ 16、springboot零配置的原理 17、springboot如何做到内嵌tomcat 18、springboot启动流程原理 19、常见面试考点SPI规范讲解","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"数据库常面问题","date":"2020-06-18T16:00:00.000Z","path":"Blog/Interview/数据库常面问题/","text":"B+树的定义 InnoDB中的“页” InnoDB中主键索引生成过程 InnoDB中联合索引生成过程 索引实战与优化","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Excel文件数据抽取","date":"2020-06-18T16:00:00.000Z","path":"Blog/杂记/Python/Excel文件数据抽取/","text":"本文仅仅是对Excel中的数据进行了简单的读取抽出并统一输出到指定的地方，在读取老版本xls文件的时候可能会出现编码的问题导致文件读取失败：1UnicodeDecodeError: 'utf-16-le' codec can't decode byte 0x40 in position 104: truncated data 可以通过对报错的源码unpack_unicode代码进行try-except并将其赋值为空。 1234try: strg = unpack_unicode(data, 0, lenlen=2) except: strg = \"\" 以下代码仅仅是遍历指定目录下的所有文件，之所以多写一重判断循环文件，是为了将第一层的文件夹名称生成一个新的sheet，第一级文件夹下的所有文件的数据都统计到当前文件夹名称所对应的sheet中，且对实际情况进行了简单的数据过滤和处理，在此仅仅是存储一个简单的模板，后续有其他的需求可在该模板上持续修改优化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# -*- coding: UTF-8 -*-import osimport openpyxlimport pandas as pdimport xlrddef find_value(basePath): fileDirs = os.listdir(basePath) dataAllValue = pd.DataFrame() for fileDir in fileDirs: childFile = os.path.join('%s%s%s' % (basePath, \"\\\\\", fileDir)) if os.path.isfile(childFile): if fileDir.endswith(\"xls\") or fileDir.endswith(\"xlsx\") or fileDir.endswith(\"XLS\") or fileDir.endswith(\"XLSX\"): colunm_count, sheetDataFrameValue = read_excel(childFile) if sheetDataFrameValue.empty: continue if colunm_count == 1: continue dataAllValue = dataAllValue.append(sheetDataFrameValue) if os.path.isdir(childFile): childDataFrameValue = find_value(childFile) dataAllValue = dataAllValue.append(childDataFrameValue) return dataAllValuedef read_excel(childFile): try: FileObj = xlrd.open_workbook(childFile) # 打开处理的excel文件 sheetNames = FileObj.sheet_names() except: print(\"有问题的文件：\", childFile) return 1, pd.DataFrame() i = 0 for sheetName in sheetNames: sheet = FileObj.sheets()[i] # 获取第一个工作表 i += 1 row_count = sheet.nrows # 行数 colunm_count = 0 sheetDataFrameValue = pd.DataFrame() for element in range(2, row_count): row_values = [cell_value_clear(cell_value) for cell_value in sheet.row_values(element)] for keyValue in keyValues: if keyValue.lower() in row_values: findCon = sheet.row_values(element) not_empty = [i for i in findCon if i != ''] if len(not_empty) &lt; 3: continue columnDf = pd.DataFrame(findCon) columnDf.rename(columns=&#123;0: colunm_count&#125;, inplace=True) if sheetDataFrameValue.empty: sheetDataFrameValue = columnDf.join(sheetDataFrameValue) else: sheetDataFrameValue = sheetDataFrameValue.join(columnDf) colunm_count += 1 return colunm_count, sheetDataFrameValuedef cell_value_clear(cell_value): if cell_value is None: return '' return str(cell_value).replace(\" \", \"\").lower()def write_excel_xlsx(dataFrameValue1, sheetName, excelName): newExcel = pd.DataFrame(dataFrameValue1) writer = pd.ExcelWriter(excelName, engine='openpyxl') is_file_exists = os.path.exists(excelName) # 判断文件是否存在 if is_file_exists is True: book = openpyxl.load_workbook(writer.path) writer.book = book newExcel.to_excel(excel_writer=writer, sheet_name=sheetName, encoding=\"utf-8\", index=False) writer.save() writer.close() else: newExcel.to_excel(excel_writer=writer, sheet_name=sheetName, encoding=\"utf-8\", index=False) writer.save() writer.close()def run(basePath): pathDirs = os.listdir(basePath) for path in pathDirs: provinceDataPath = os.path.join('%s%s%s' % (basePath, \"\\\\\", path)) print(provinceDataPath) if os.path.isdir(provinceDataPath): dataAllValue = find_value(provinceDataPath) print(dataAllValue) if dataAllValue.empty: continue write_excel_xlsx(dataAllValue, path, excelName)if __name__ == '__main__': # 文件路径 basePath = r\"F:\\data\" keyValues = [\"指标1\", \"指标2\", \"指标3\", \"指标4\"] excelName = 'F:\\抽取数据\\数据统计总览.xlsx' # 文件保存的路径 run(basePath)","tags":[{"name":"Python","slug":"Python","permalink":"https://yaoyinglong.github.io/tags/Python/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"Python","slug":"杂记/Python","permalink":"https://yaoyinglong.github.io/categories/杂记/Python/"}]},{"title":"排序算法","date":"2020-05-24T16:00:00.000Z","path":"Blog/算法/排序算法/","text":"十种常见的排序算法可分为比较类排序和非比较类排序。比较类排序通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此也称为非线性时间比较类排序；非比较类排序不通过比较来决定元素间的相对次序，可以突破基于比较排序的时间下界，也称为线性时间非比较类排序。 算法类比 排序算法 时间复杂度（平均） 时间复杂度（最坏） 时间复杂度（最好） 空间复杂度 稳定性 冒泡排序 O(n^2) O(n^2) O(n) O(1) 稳定 选择排序 O(n^2) O(n^2) O(n^2) O(1) 不稳定 快速排序 O(nlog2^n) O(n^2) O(nlog2^n) O(nlog2^n) 不稳定 插入排序 O(n^2) O(n^2) O(n) O(1) 稳定 希尔排序 O(n^1.3) O(n^2) O(n) O(1) 不稳定 堆排序 O(nlog2^n) O(nlog2^n) O(nlog2^n) O(1) 不稳定 归并排序 O(nlog2^n) O(nlog2^n) O(nlog2^n) O(n) 稳定 计数排序 O(n + k) O(n + k) O(n + k) O(n + k) 稳定 桶排序 O(n + k) O(n^2) O(n) O(n + k) 稳定 基数排序 O(n * k) O(n * k) O(n * k) O(n + k) 稳定 冒泡排序比较两个相邻的元素，将值大或者小的的元素交换到一边。 1234567891011121314public void bubblerSort(Integer[] arr) &#123; boolean flag = true; for (int i = 0; i &lt; arr.length &amp;&amp; flag; i++) &#123; flag = false; for (int j = arr.length - 1; j &gt; i; j--) &#123; if (arr[j - 1] &gt; arr[j]) &#123; int temp = arr[j]; arr[j] = arr[j - 1]; arr[j - 1] = temp; flag = true; &#125; &#125; &#125;&#125; 选择排序在待排序的一组数据中，选出最小（最大）的一个数与第一个位置的数交换，然后在剩下的数中，再找最小（最大）的数与第二个位置的数交换位置，依次类推，直到第N-1个元素与第N个元素交换位置，选择排序结束。 12345678910111213141516public void selectSort(Integer[] arr) &#123; int index; for (int i = 0; i &lt; arr.length; i++) &#123; index = i; for (int k = i + 1; k &lt; arr.length; k++) &#123; if (arr[index] &gt; arr[k]) &#123; index = k; &#125; &#125; if (i != index) &#123; int temp = arr[i]; arr[i] = arr[index]; arr[index] = temp; &#125; &#125;&#125; 快速排序随机找出一个数，可以随机取，也可以取固定位置，一般是取第一个或最后一个称为基准，比基准小的交换到左边，比基准大的交换到右边，交换完左边都是比基准小的，右边都是比较基准大的，这样就将一个数组分成了两个子数组，然后再按照同样的方法把子数组再分成更小的子数组，直到不能分解为止。 123456789101112131415161718public void quickSort(Integer[] arr, int left, int right) &#123; if (left &lt; right) &#123; int dl = left, dr = right, pivot = arr[left]; while (dl &lt; dr) &#123; while (dl &lt; dr &amp;&amp; arr[dr] &gt; pivot) dr--; if (dl &lt; dr) arr[dl++] = arr[dr]; while (dl &lt; dr &amp;&amp; arr[dl] &lt; pivot) dl++; if (dl &lt; dr) arr[dr--] = arr[dl]; &#125; arr[dl] = pivot; quickSort(arr, left, dl - 1); quickSort(arr, dl + 1, right); &#125;&#125; 插入排序把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。 1234567891011121314151617public void insertSort(Integer[] arr) &#123; int j, k; for (int i = 1; i &lt; arr.length; i++) &#123; for (j = i - 1; j &gt;= 0; j--) &#123; if (arr[i] &gt; arr[j]) &#123; break; &#125; &#125; if (j != i - 1) &#123; int temp = arr[i]; for (k = i - 1; k &gt; j; k--) &#123; arr[k + 1] = arr[k]; &#125; arr[k + 1] = temp; &#125; &#125;&#125; 希尔排序希尔排序(Shell Sort)是插入排序的一种，它是针对直接插入排序算法的改进。该方法又称缩小增量排序。实质上是一种分组插入方法。 对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap=1时，整个数列就是有序的。 123456789101112131415161718public void shellSort(Integer[] arr) &#123; int i, j, gap; for (gap = arr.length / 2; gap &gt; 0; gap /= 2) &#123; for (i = 0; i &lt; gap; i++) &#123; for (j = i + gap; j &lt; arr.length; j += gap) &#123; if (arr[j] &lt; arr[j - gap]) &#123; int temp = arr[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; arr[k] &gt; temp) &#123; arr[k + gap] = arr[k]; k -= gap; &#125; arr[k + gap] = temp; &#125; &#125; &#125; &#125;&#125; 堆排序堆排序是利用完全二叉树的特性，堆树又分为大顶堆和小顶堆。数组是完全二叉树最佳存储结构，因为完全二叉树有特殊的属性，可直接利用数组下标表示左右节点，数组下标为K的元素对应的完全二叉树中左右子节点在数组中的位置分别为2*K + 1、2*K+2。 不论大顶堆还是小顶堆，都是从完全二叉数中最后一个元素的父节点开始堆化，将最大或最小的元素排到堆顶，然后遍历整棵树，每一次将堆顶的元素，和未排序的最后一个元素交换，再进行一次堆化，这样就将数据排好序了。 堆化的过程，即将元素从堆顶元素与左右子节点比较，若为大顶堆，则若左右节点中大的节点比父节点还大，则将父节点与其交换，然后再继续往下遍历。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class HeapSort &#123; public void heapSortAsc(Integer[] arr) &#123; int len = arr.length; // len / 2 - 1表示的是从完全二叉数中最后一个元素的父节点开始堆化 for (int start = len / 2 - 1; start &gt;= 0; start--) &#123; maxHeapDown(arr, start, len); // 将树中最大的元素排到堆顶 &#125; // 上面的循环只是将最大的元素排到了堆顶，但是整棵树即数组中的元素不是有序的 // 每一次将对顶的元素即最大的元素，和未排序的最后一个元素交换，再进行一次堆化，这样就将数据从小到大排序了 for (int index = len - 1; index &gt; 0; index--) &#123; int temp = arr[0]; arr[0] = arr[index]; arr[index] = temp; maxHeapDown(arr, 0, index); // len~i已经排好序了 &#125; &#125; /** * 将完全二叉树中最大的元素放到堆顶，end表示最多建到的点 */ public void maxHeapDown(Integer[] arr, int start, int end) &#123; int parent = start; int left = parent * 2 + 1; // 找到当前节点的左子节点位置 while (left &lt; end) &#123; int max = left; // max表示左右节点大的那一个在数组中的位置 if (left + 1 &lt; end &amp;&amp; arr[left] &lt; arr[left + 1]) &#123; // 比较左右节点和父节点的大小 max = left + 1; // 若右节点比左节点大，则将父节点和右节点交换 &#125; // 若左节点比右节点大，则将父节点和左节点交换 if (arr[parent] &gt; arr[max]) &#123; // 若父节点大于子节点中最大的那一个，则退出 return; &#125; else &#123; // 若父节点小于子节点中最大的那一个，则交换 int tmp = arr[parent]; arr[parent] = arr[max]; arr[max] = tmp; parent = max; // 还原指针，交换数据后，max指向的是被交换下来的父节点，还需要往下遍历，故需要将parent指向需要遍历的数据 left = parent * 2 + 1; // 找到之前左右节点大的节点的左子节点在数组中的索引位置 &#125; &#125; &#125; public void heapSortDesc(Integer[] arr) &#123; int len = arr.length; for (int start = len / 2 - 1; start &gt;= 0; start--) &#123; minHeapDown(arr, start, len); &#125; for (int index = len - 1; index &gt; 0; index--) &#123; int tmp = arr[0]; arr[0] = arr[index]; arr[index] = tmp; minHeapDown(arr, 0, index); &#125; &#125; /** * 将完全二叉树中最小的元素放到堆顶，end表示最多建到的点 */ public void minHeapDown(Integer[] arr, int start, int end) &#123; int parent = start; int left = 2 * start + 1; // 找到当前节点的左子节点位置 while (left &lt; end) &#123; int min = left; // min表示左右节点小的那一个在数组中的位置 if (left + 1 &lt; end &amp;&amp; arr[left] &gt; arr[left + 1]) &#123; min = left + 1; &#125; if (arr[min] &gt; arr[parent]) &#123; // 比较左右节点中小的那一个和父节点的大小 break; // 若小的那个节点都比父节点大，说明不需要再遍历了 &#125; int tmp = arr[min]; arr[min] = arr[parent]; arr[parent] = tmp; parent = min; // 还原指针，交换数据后，min指向的是被交换下来的父节点，还需要往下遍历，故需要将parent指向需要遍历的数据 left = 2 * parent + 1; // 找到之前左右节点小的节点的左子节点在数组中的索引位置 &#125; &#125; @Test public void InsertSortTest() &#123; &#123; Integer[] arr = new Integer[]&#123;8, 6, 4, 9, 74, 25, 1, 3, 5, 28, 35, 0, 22, 2, 7, 10, 26, 29&#125;; heapSortAsc(arr); System.err.println(\" after:\" + Arrays.asList(arr)); &#125; &#123; Integer[] arr = new Integer[]&#123;8, 6, 4, 9, 74, 25, 1, 3, 5, 28, 35, 0, 22, 2, 7, 10, 26, 29&#125;; heapSortDesc(arr); System.err.println(\" after:\" + Arrays.asList(arr)); &#125; &#125;&#125; 归并排序将两个的有序数列合并成一个有序数列，归并排序包括从上往下和从下往上两种方式。 从下往上：将待排序的数列分成若干个长度为1的子数列，然后将这些数列两两合并；得到若干个长度为2的有序数列，再将这些数列两两合并；得到若干个长度为4的有序数列，再将它们两两合并；直接合并成一个数列为止。 从上往下：它与从下往上在排序上是反方向的，它基本包括3步： 分解：将当前区间一分为二，即求分裂点 mid = (low + high)/2 求解：递归对两个子区间a[low...mid]和a[mid+1...high]归并排序。递归终结条件是子区间长度为1 合并：将已排序的两个子区间a[low...mid]和 a[mid+1...high]归并为一个有序的区间a[low...high] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void mergeSortUp2Down(Integer[] arr, int start, int end) &#123; if (arr == null || start &gt;= end) &#123; return; &#125; int mid = (start + end) / 2; mergeSortUp2Down(arr, start, mid); mergeSortUp2Down(arr, mid + 1, end); merge(arr, start, mid, end);&#125;public void mergeSortDown2Up(Integer[] arr, int len) &#123; if (arr == null || len &lt; 0) &#123; return; &#125; for (int n = 1; n &lt; len; n *= 2) &#123; mergeGroups(arr, len, n); &#125;&#125;void mergeGroups(Integer[] arr, int len, int gap) &#123; int i; for (i = 0; i + 2 * gap - 1 &lt; len; i += 2 * gap) &#123; merge(arr, i, i + gap - 1, i + 2 * gap - 1); &#125; if (i + gap - 1 &lt; len - 1) &#123; merge(arr, i, i + gap - 1, len - 1); &#125;&#125;public void merge(Integer[] arr, int start, int mid, int end) &#123; int[] temp = new int[end - start + 1]; int i = start; int j = mid + 1; int k = 0; while (i &lt;= mid &amp;&amp; j &lt;= end) &#123; if (arr[i] &lt;= arr[j]) &#123; temp[k++] = arr[i++]; &#125; else &#123; temp[k++] = arr[j++]; &#125; &#125; while (i &lt;= mid) &#123; temp[k++] = arr[i++]; &#125; while (j &lt;= end) &#123; temp[k++] = arr[j++]; &#125; for (i = 0; i &lt; k; i++) &#123; arr[start + i] = temp[i]; &#125;&#125; 桶排序将数组分到有限数量的桶子里。数组arr数据范围为[0, max)，创建容量为max的桶数组buckets，遍历数组arr将其值作为数组下标，再遍历桶数组得到有序数组。 1234567891011public void bucketSort(Integer[] arr, int n, int max) &#123; int[] buckets = new int[max]; for (int index = 0; index &lt; n; index++) &#123; buckets[arr[index]]++; &#125; for (int bucketIndex = 0, arrIndex = 0; bucketIndex &lt; max; bucketIndex++) &#123; while (buckets[bucketIndex]-- &gt; 0) &#123; arr[arrIndex++] = bucketIndex; &#125; &#125;&#125; 基数排序基数排序是桶排序的扩展，将整数按位数切割成不同的数字，然后按每个位数分别比较。将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 12345678910111213141516171819202122232425262728293031323334353637public void radixSort(Integer[] arr) &#123; int max = getMax(arr); for (int exp = 1; max / exp &gt; 0; exp *= 10) &#123; countSort(arr, exp); &#125;&#125;public void countSort(Integer[] arr, int exp) &#123; int[] output = new int[arr.length]; int[] buckets = new int[10]; for (int index = 0; index &lt; arr.length; index++) &#123; buckets[arr[index] / exp % 10]++; &#125; for (int index = 1; index &lt; 10; index++) &#123; buckets[index] += buckets[index - 1]; &#125; for (int index = arr.length - 1; index &gt;= 0; index--) &#123; output[buckets[arr[index] / exp % 10] - 1] = arr[index]; buckets[arr[index] / exp % 10]--; &#125; for (int index = 0; index &lt; arr.length; index++) &#123; arr[index] = output[index]; &#125;&#125;public int getMax(Integer[] arr) &#123; int max = arr[0]; for (int i = 1; i &lt; arr.length; i++) &#123; if (arr[i] &gt; max) &#123; max = arr[i]; &#125; &#125; return max;&#125;","tags":[{"name":"算法，排序","slug":"算法，排序","permalink":"https://yaoyinglong.github.io/tags/算法，排序/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"MySQL事务","date":"2020-02-04T16:00:00.000Z","path":"Blog/DB/MySQL事务/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"https://yaoyinglong.github.io/tags/事务/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Java中调用Groovy脚本","date":"2019-12-24T16:00:00.000Z","path":"Blog/Java/工具/Java中调用Groovy脚本/","text":"Groovy是构建在JVM上的一个轻量级动态语言，其是Java实现的，与Java语法类是，能很好的与Java代码结合，及扩展现有代码。 Java在语音动态性方面只能通过反射，且参数传递格式很严格不是很灵活，而Groovy是构建在JVM上的一个轻量级动态语言，其是Java实现的，与Java语法类是，能很好的与Java代码结合，及动态扩展现有代码。 Java中可以通过GroovyScriptEngine、GroovyClassLoader、GroovyShell、ScriptEngineManager等方式调用Groovy，以及在实际项目中的运用。Maven依赖： 123456&lt;dependency&gt; &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt; &lt;artifactId&gt;groovy-all&lt;/artifactId&gt; &lt;version&gt;$&#123;groovy.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt;&lt;/dependency&gt; GroovyScriptEngine从指定的位置（文件系统，URL，数据库等）加载Groovy脚本，并且随着脚本变化而重新加载。在相互关联的多个脚本情况下使用GroovyScriptEngine更好些。 1234567GroovyScriptEngine engine = new GroovyScriptEngine(\"src/test/resources/groovy/\");Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);Binding binding = new Binding(param);Object result = engine.run(\"Mixed.groovy\", binding); GroovyClassLoaderGroovyClassLoader是一个定制的类装载器，负责解释加载Java类中用到的Groovy类。 123456789GroovyClassLoader loader = new GroovyClassLoader();Class aClass = loader.parseClass(new File(\"src/test/resources/groovy/Mixed.groovy\"));try &#123; GroovyObject instance = (GroovyObject) aClass.newInstance(); Object result = instance.invokeMethod(\"Mixed\", new Object[]&#123;\"KKKKKKKKKKKKKK\", 45&#125;); System.out.println(result);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; GroovyShellGroovyShell允许在Java类甚至Groovy类中求任意Groovy表达式的值。可用Binding对象输入参数给表达式，并最终通过GroovyShell返回Groovy表达式的计算结果。多用于推求独立的脚本或表达式。 即使使用GroovyShell也有多种实现方式，使用invokeMethod方法调用： 12345678GroovyShell loader = new GroovyShell();Script script = loader.parse(new File(\"src/test/resources/groovy/Mixed.groovy\"));try &#123; Object result = script.invokeMethod(\"Mixed\", new Object[]&#123;\"KKKKKKKKKKKKKK\", 45&#125;); System.out.println(result);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; 通过GroovyShell得evaluate方式直接调用脚本： 12345678910111213Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);param.put(\"bb\", 55L);param.put(\"cc\", 9.9999);Binding binding = new Binding(param);GroovyShell loader = new GroovyShell(binding);try &#123; Object result = loader.evaluate(\"return id + (aa + bb + cc)\"); System.out.println(result);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; 通过InvokerHelper类来调用： 123456789101112Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);param.put(\"bb\", 55L);param.put(\"cc\", 9.9999);Binding binding = new Binding(param);GroovyShell shell = new GroovyShell();Script script = shell.parse(new File(\"src/test/resources/groovy/Mixed.groovy\"));Object result = InvokerHelper.createScript(script.getClass(), binding).run();System.out.println(result); 还可以通过GroovyShell来直接parse脚本内容： 123456789101112131415Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);param.put(\"bb\", 55L);param.put(\"cc\", 9.9999);Binding binding = new Binding(param);GroovyShell shell = new GroovyShell();Script script = shell.parse(\"def Mixed(String id, int aa, Long bb, double cc) &#123;\\n\" + \" return id + (aa + bb + cc)\\n\" + \"&#125;\\n\" + \"Mixed(id, aa, bb, cc)\");Object result = InvokerHelper.createScript(script.getClass(), binding).run();System.out.println(result); ScriptEngineManager1234567891011ScriptEngineManager manager = new ScriptEngineManager();ScriptEngine engine = manager.getEngineByName(\"groovy\");Bindings binding = engine.createBindings();binding.put(\"id\", \"KKKKKKKKKKKKKK\");binding.put(\"aa\", 45);binding.put(\"bb\", 55L);binding.put(\"cc\", 9.9999);Object result = engine.eval(\"return id + (aa + bb + cc)\", binding);System.out.println(result); 集成常见问题使用GroovyShell的parse方法导致perm区爆满的问题若应用中内嵌Groovy引擎，会动态执行传入的表达式并返回执行结果，而Groovy每执行一次脚本，都会生成一个脚本对应的class对象，并new一个InnerLoader去加载这个对象，而InnerLoader和脚本对象都无法在gc的时候被回收运行一段时间后将perm占满，一直触发fullgc。 对于同一个Groovy脚本，Groovy执行引擎都会不同的命名，且命名与时间戳有关。当传入text时，class对象的命名规则为：&quot;script&quot; + System.currentTimeMillis() + Math.abs(text.hashCode()) + &quot;.groovy&quot;。这就导致就算Groovy脚本未发生任何变化，每次执行parse方法都会新生成一个脚本对应的class对象，且由GroovyClassLoader进行加载，不断增大perm区。 JVM中的Class只有满足以下三个条件，才能被GC回收，也就是该Class被卸载： 该类所有的实例都已经被GC，也就是JVM中不存在该Class的任何实例； 加载该类的ClassLoader已经被GC； 该类的java.lang.Class对象没有在任何地方被引用，如不能在任何地方通过反射访问该类的方法。 在GroovyClassLoader代码中有一个class对象的缓存，每次编译脚本时都会在Map中缓存这个对象，即：setClassCacheEntry(clazz)。每次groovy编译脚本后，都会缓存该脚本的Class对象，下次编译该脚本时，会优先从缓存中读取，这样节省掉编译的时间。这个缓存的Map由GroovyClassLoader持有，key是脚本的类名，这就导致每个脚本对应的class对象都存在引用，无法被GC清理掉。","tags":[{"name":"Groovy","slug":"Groovy","permalink":"https://yaoyinglong.github.io/tags/Groovy/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://yaoyinglong.github.io/categories/Java/工具/"}]},{"title":"国债逆回购","date":"2019-12-09T16:00:00.000Z","path":"Blog/杂记/理财/国债逆回购/","text":"购买技巧 每到年中，年底，长的节假日前，国债逆回购利息都会比较高 国债逆回购收益最高一般出现在节假日前的第二天，一般是周四，此时逆回购收益是最高的 每年1月初的市场资金面通常会比较宽松","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"基金基本知识总结","date":"2019-12-05T16:00:00.000Z","path":"Blog/杂记/理财/基金基本知识总结/","text":"指数基金 上证 50：主要投资大型企业， 50 是代表它所投资企业的数量 沪深 300：主要投资中大型企业，是国内影响力最大、最重要的指数基金，沪深300是从上海和深圳两个交易所中挑选最大的300家大型企业 中证 500：主要投资中小型企业 创业版：主要投资小型企业，专门投资小型企业门槛更低的上市市场，一些当前规模不够大，盈利不够好，达不到主板上市的要求创业板 红利指数：主要投资高分红企业，现金分红：股票的股息，指业绩比较好的公司， 会每年从公司的净利润当中抽出一部分，以现金分红的方式回馈给股东通过持有几十只现金分红比较高的股票，来获取更高的收益.","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Maven Assembly标签全解","date":"2019-10-27T16:00:00.000Z","path":"Blog/Maven/Maven Assembly标签全解/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796&lt;assembly xmlns=\"http://maven.apache.org/ASSEMBLY/2.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd\"&gt; &lt;!-- 设置此程序集的标识。这是来自此项目的特定文件组合的符号名称。此外，除了用于通过将生成的归档的值附加到组合包以明确命名组合包之外，该ID在部署时用作工件的分类器。 --&gt; &lt;!--string--&gt; &lt;id/&gt; &lt;!-- (许多） 指定程序集的格式。通过目标参数而不是在这里指定格式通常会更好。例如，允许不同的配置文件生成不同类型的档案。 可以提供多种格式，装配体插件将生成每种所需格式的档案。部署项目时，所有指定的文件格式也将被部署。 通过在&lt;format&gt;子元素中提供以下值之一来指定格式： “zip” - 创建一个ZIP文件格式 “tar” - 创建一个TAR格式 “tar.gz”或“tgz” - 创建一个gzip'd TAR格式 “tar.bz2”或“tbz2” - 创建一个bzip'd TAR格式 “tar.snappy” - 创建一个灵活的TAR格式 “tar.xz”或“txz” - 创建一个xz'd TAR格式 “jar” - 创建一个JAR格式 “dir” - 创建分解的目录格式 “战争” - 创建一个WAR格式 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;formats/&gt; &lt;!-- 在最终归档中包含一个基本目录。例如，如果您正在创建一个名为“your-app”的程序集，则将includeBaseDirectory设置为true将创建一个包含此基本目录的归档文件。 如果此选项设置为false，则创建的存档将其内容解压缩到当前目录。 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeBaseDirectory/&gt; &lt;!-- 设置生成的程序集归档的基本目录。如果没有设置，并且includeBaseDirectory == true，则将使用$ &#123;project.build.finalName&#125;。（从2.2-beta-1开始） --&gt; &lt;!--string--&gt; &lt;baseDirectory/&gt; &lt;!-- 在最终档案中包含一个网站目录。项目的站点目录位置由Assembly Plugin的siteDirectory参数确定。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;includeSiteDirectory/&gt; &lt;!-- （许多） 从常规归档流中过滤各种容器描述符的组件集合，因此可以将它们聚合然后添加。 --&gt; &lt;!--List&lt;ContainerDescriptorHandlerConfig&gt;--&gt; &lt;containerDescriptorHandlers&gt; &lt;!-- 配置文件头部的过滤器，以启用各种类型的描述符片段（如components.xml，web.xml等）的聚合。 --&gt; &lt;containerDescriptorHandler&gt; &lt;!-- 处理程序的plexus角色提示，用于从容器中查找。 --&gt; &lt;!--string--&gt; &lt;handlerName/&gt; &lt;!-- 处理程序的配置选项。 --&gt; &lt;!--DOM--&gt; &lt;configuration/&gt; &lt;/containerDescriptorHandler&gt; &lt;/containerDescriptorHandlers&gt; &lt;!-- （许多） 指定在程序集中包含哪些模块文件。moduleSet是通过提供一个或多个&lt;moduleSet&gt;子元素来指定的。 --&gt; &lt;!--List&lt;ModuleSet&gt;--&gt; &lt;moduleSets&gt; &lt;!-- moduleSet表示一个或多个在项目的pom.xml中存在的&lt;module&gt;项目。这使您可以包含属于项目&lt;modules&gt;的源代码或二进制文件。 注意：从命令行使用&lt;moduleSets&gt;时，需要先通过“mvn package assembly：assembly”来传递包阶段。这个bug计划由Maven 2.1解决。 --&gt; &lt;moduleSet&gt; &lt;!-- 如果设置为true，则该插件将包含当前反应堆中的所有项目，以便在此ModuleSet中进行处理。这些将被 纳入/排除(includes/excludes) 规则。（从2.2开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useAllReactorProjects/&gt; &lt;!-- 如果设置为false，则该插件将从该ModuleSet中排除子模块的处理。否则，它将处理所有子模块，每个子模块都要遵守包含/排除规则。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeSubModules/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组包含的项目坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的项目工件坐标。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 当存在这个时，插件将在生成的程序集中包含这个集合中包含的模块的源文件。 包含用于在程序集中包含项目模块的源文件的配置选项。 --&gt; &lt;!--ModuleSources--&gt; &lt;sources&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当&lt;include&gt;子元素存在时，它们定义一组要包含的文件和目录。如果不存在，则&lt;includes&gt;表示所有有效值。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的文件和目录。如果不存在，则&lt;excludes&gt;不表示排除。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- （许多） 指定包含在程序集中的每个包含模块的哪些文件组。fileSet通过提供一个或多个&lt;fileSet&gt;子元素来指定。（从2.2-beta-1开始） --&gt; &lt;!--List&lt;FileSet&gt;--&gt; &lt;fileSets&gt; &lt;!-- fileSet允许将文件组包含到程序集中。 --&gt; &lt;fileSet&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当&lt;include&gt;子元素存在时，它们定义一组要包含的文件和目录。如果不存在，则&lt;includes&gt;表示所有有效值。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的文件和目录。如果不存在，则&lt;excludes&gt;不表示排除。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644. --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 设置模块目录的绝对或相对位置。例如，“src / main / bin”会选择定义这个依赖关系的项目的这个子目录。 --&gt; &lt;!--string--&gt; &lt;directory/&gt; &lt;!-- 设置此文件集中文件的行结束符。有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行尾（即“\\ n”） “lf” - 使用一个换行符结束符（即“\\ n”） “dos” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “windows” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “crlf” - 使用回车，换行符结尾（即“\\ r \\ n”） --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 是否在复制文件时过滤符号，使用构建配置中的属性。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;!-- 指定模块的finalName是否应该添加到应用于它的任何fileSets的outputDirectory值。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeModuleDirectory/&gt; &lt;!-- 指定是否应从应用于该模块的文件集中排除当前模块下方的子模块目录。如果仅仅意味着复制与此ModuleSet匹配的确切模块列表的源，忽略（或单独处理）当前目录下目录中存在的模块，这可能会很有用。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;excludeSubModuleDirectories/&gt; &lt;!-- 设置此程序集中包含的所有模块基本目录的映射模式。注意：只有在includeModuleDirectory == true的情况下才会使用此字段。 缺省值是在 2.2-beta-1中是$ &#123;artifactId&#125;，以及后续版本中是$ &#123;module.artifactId&#125;。（从2.2-beta-1开始） 默认值是：$ &#123;module.artifactId&#125;。 --&gt; &lt;!--string--&gt; &lt;outputDirectoryMapping/&gt; &lt;/sources&gt; &lt;!-- 如果存在，插件将在生成的程序集中包含来自该组的所包含模块的二进制文件。 包含用于将项目模块的二进制文件包含在程序集中的配置选项。 --&gt; &lt;!--ModuleBinaries--&gt; &lt;binaries&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组要包含的工件坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组依赖项工件坐标以排除。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 指定时，attachmentClassifier将使汇编器查看附加到模块的工件，而不是主工程工件。如果能够找到与指定分类符匹配的附件，则会使用它; 否则，会抛出异常。（从2.2-beta-1开始） --&gt; &lt;!--string--&gt; &lt;attachmentClassifier/&gt; &lt;!-- 如果设置为true，插件将包含这里包含的项目模块的直接和传递依赖关系。否则，它将只包含模块包。 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeDependencies/&gt; &lt;!--List&lt;DependencySet&gt;--&gt; &lt;dependencySets&gt; &lt;!-- 依赖关系集允许在程序集中包含和排除项目依赖关系。 --&gt; &lt;dependencySet&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组要包含的工件坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组依赖项工件坐标以排除。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 如果指定为true，那么在程序集创建过程中任何用于过滤实际构件的包含/排除模式都将导致构建失败，并显示错误。这是为了强调过时的包含或排除，或者表示程序集描述符配置不正确。（从2.2开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useStrictFiltering/&gt; &lt;!-- 为此程序集中包含的所有依赖项设置映射模式。（从2.2-beta-2开始； 2.2-beta-1使用$ &#123;artifactId&#125; - $ &#123;version&#125; $ &#123;dashClassifier？&#125;。$ &#123;extension&#125;作为默认值）。 默认值是：$ &#123;artifact.artifactId&#125; - $ &#123;artifact.version&#125; $ &#123;dashClassifier？&#125;。$ &#123;artifact.extension&#125;。 --&gt; &lt;!--string--&gt; &lt;outputFileNameMapping/&gt; &lt;!-- 如果设置为true，则此属性将所有依赖项解包到指定的输出目录中。设置为false时，依赖关系将被包含为档案（jar）。只能解压jar，zip，tar.gz和tar.bz压缩文件。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;unpack/&gt; &lt;!-- 允许指定包含和排除以及过滤选项，以指定从相关性工件解压缩的项目。（从2.2-beta-1开始） --&gt; &lt;unpackOptions&gt; &lt;!-- （许多） 文件和/或目录模式的集合，用于匹配将在解压缩时从归档文件中包含的项目。每个项目被指定为&lt;include&gt; some / path &lt;/ include&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 用于匹配项目的文件和/或目录模式的集合，在解压缩时将其从归档文件中排除。每个项目被指定为&lt;exclude&gt; some / path &lt;/ exclude&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 是否使用构建配置中的属性过滤从档案中解压缩的文件中的符号。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;!-- 设置文件的行尾。（从2.2开始）有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行结尾 “lf” - 使用单个换行符结束符 “dos” - 使用DOS风格的行尾 “ crlf ” - 使用Carraige返回，换行符结束 --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 允许指定解压档案时使用的编码，支持指定编码的unarchiver。如果未指定，将使用归档程序默认值。Archiver默认值通常代表理智（modern）的values。 --&gt; &lt;!--string--&gt; &lt;encoding/&gt; &lt;/unpackOptions&gt; &lt;!-- 为此dependencySet设置依赖项范围。 默认值是：runtime。 --&gt; &lt;!--string--&gt; &lt;scope/&gt; &lt;!-- 确定当前项目构建过程中产生的工件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useProjectArtifact/&gt; &lt;!-- 确定当前项目构建过程中产生的附件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useProjectAttachments/&gt; &lt;!-- 确定是否将传递依赖项包含在当前依赖项集的处理中。如果为true，那么include / excludes / useTransitiveFiltering将应用于传递依赖项构件以及主项目依赖项构件。 如果为false，则useTransitiveFiltering无意义，并且包含/排除仅影响项目的直接依赖关系。 默认情况下，这个值是真的。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveDependencies/&gt; &lt;!-- 确定此依赖项集中的包含/排除模式是否将应用于给定工件的传递路径。 如果为真，并且当前工件是由包含或排除模式匹配的另一个工件引入的传递依赖性，则当前工件具有与其相同的包含/排除逻辑。 默认情况下，此值为false，以保持与2.1版的向后兼容性。这意味着包含/排除仅仅直接应用于当前的工件，而不应用于传入的工件。（从2.2-beta-1） 默认值为：false。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveFiltering/&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;!-- 如果设置为true，则此属性将所有模块包解包到指定的输出目录中。当设置为false时，模块包将作为归档（jar）包含在内。 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;unpack/&gt; &lt;!-- 允许指定包含和排除以及过滤选项，以指定从相关性工件解压缩的项目。（从2.2-beta-1开始） --&gt; &lt;unpackOptions&gt; &lt;!-- （许多） 文件和/或目录模式的集合，用于匹配将在解压缩时从归档文件中包含的项目。每个项目被指定为&lt;include&gt; some / path &lt;/ include&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 用于匹配项目的文件和/或目录模式的集合，在解压缩时将其从归档文件中排除。每个项目被指定为&lt;exclude&gt; some / path &lt;/ exclude&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 是否使用构建配置中的属性过滤从档案中解压缩的文件中的符号。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;!-- 设置文件的行尾。（从2.2开始）有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行结尾 “lf” - 使用单个换行符结束符 “dos” - 使用DOS风格的行尾 “ crlf ” - 使用Carraige返回，换行符结束 --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 允许指定解压档案时使用的编码，支持指定编码的unarchiver。如果未指定，将使用归档程序默认值。Archiver默认值通常代表理智（modern）的values。 --&gt; &lt;!--string--&gt; &lt;encoding/&gt; &lt;/unpackOptions&gt; &lt;!-- 设置此程序集中包含的所有非UNPACKED依赖关系的映射模式。（由于2.2-beta-2; 2.2-beta-1使用$ &#123;artifactId&#125; - $ &#123;version&#125; $ &#123;dashClassifier？&#125;。$ &#123;extension&#125;作为默认值）注意：如果dependencySet指定unpack == true，则outputFileNameMapping将不要使用; 在这些情况下，使用outputDirectory。有关可用于outputFileNameMapping参数的条目的更多详细信息，请参阅插件FAQ。 默认值是：$ &#123;module.artifactId&#125; - $ &#123;module.version&#125; $ &#123;dashClassifier？&#125;。$ &#123;module.extension&#125;。 --&gt; &lt;!--string--&gt; &lt;outputFileNameMapping/&gt; &lt;/binaries&gt; &lt;/moduleSet&gt; &lt;/moduleSets&gt; &lt;!-- （许多） 指定在程序集中包含哪些文件组。fileSet通过提供一个或多个&lt;fileSet&gt;子元素来指定。 --&gt; &lt;!--List&lt;FileSet&gt;--&gt; &lt;fileSets&gt; &lt;!-- fileSet允许将文件组包含到程序集中。 --&gt; &lt;fileSet&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当&lt;include&gt;子元素存在时，它们定义一组要包含的文件和目录。如果不存在，则&lt;includes&gt;表示所有有效值。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的文件和目录。如果不存在，则&lt;excludes&gt;不表示排除。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644. --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 设置模块目录的绝对或相对位置。例如，“src / main / bin”会选择定义这个依赖关系的项目的这个子目录。 --&gt; &lt;!--string--&gt; &lt;directory/&gt; &lt;!-- 设置此文件集中文件的行结束符。有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行尾（即“\\ n”） “lf” - 使用一个换行符结束符（即“\\ n”） “dos” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “windows” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “crlf” - 使用回车，换行符结尾（即“\\ r \\ n”） --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 是否在复制文件时过滤符号，使用构建配置中的属性。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;!-- （许多） 指定在程序集中包含哪些单个文件。通过提供一个或多个&lt;file&gt;子元素来指定文件。 --&gt; &lt;!--List&lt;FileItem&gt;--&gt; &lt;files&gt; &lt;!-- 一个文件允许单个文件包含选项来更改不受fileSets支持的目标文件名。 --&gt; &lt;file&gt; &lt;!-- 设置要包含在程序集中的文件的模块目录的绝对路径或相对路径。 --&gt; &lt;!--string--&gt; &lt;source/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- 在outputDirectory中设置目标文件名。默认是与源文件相同的名称。 --&gt; &lt;!--string--&gt; &lt;destName/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个八卦价值。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 设置此文件中文件的行结束符。有效值是： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行尾（即“\\ n”） “lf” - 使用一个换行符结束符（即“\\ n”） “dos” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “windows” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “crlf” - 使用回车，换行符结尾（即“\\ r \\ n”） --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 设置是否确定文件是否被过滤。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;/file&gt; &lt;/files&gt; &lt;!--List&lt;DependencySet&gt;--&gt; &lt;dependencySets&gt; &lt;!-- 依赖关系集允许在程序集中包含和排除项目依赖关系。 --&gt; &lt;dependencySet&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组要包含的工件坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组依赖项工件坐标以排除。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 如果指定为true，那么在程序集创建过程中任何用于过滤实际构件的包含/排除模式都将导致构建失败，并显示错误。这是为了强调过时的包含或排除，或者表示程序集描述符配置不正确。（从2.2开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useStrictFiltering/&gt; &lt;!-- 为此程序集中包含的所有依赖项设置映射模式。（从2.2-beta-2开始； 2.2-beta-1使用$ &#123;artifactId&#125; - $ &#123;version&#125; $ &#123;dashClassifier？&#125;。$ &#123;extension&#125;作为默认值）。 默认值是：$ &#123;artifact.artifactId&#125; - $ &#123;artifact.version&#125; $ &#123;dashClassifier？&#125;。$ &#123;artifact.extension&#125;。 --&gt; &lt;!--string--&gt; &lt;outputFileNameMapping/&gt; &lt;!-- 如果设置为true，则此属性将所有依赖项解包到指定的输出目录中。设置为false时，依赖关系将被包含为档案（jar）。只能解压jar，zip，tar.gz和tar.bz压缩文件。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;unpack/&gt; &lt;!-- 允许指定包含和排除以及过滤选项，以指定从相关性工件解压缩的项目。（从2.2-beta-1开始） --&gt; &lt;unpackOptions&gt; &lt;!-- （许多） 文件和/或目录模式的集合，用于匹配将在解压缩时从归档文件中包含的项目。每个项目被指定为&lt;include&gt; some / path &lt;/ include&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 用于匹配项目的文件和/或目录模式的集合，在解压缩时将其从归档文件中排除。每个项目被指定为&lt;exclude&gt; some / path &lt;/ exclude&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 是否使用构建配置中的属性过滤从档案中解压缩的文件中的符号。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;!-- 设置文件的行尾。（从2.2开始）有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行结尾 “lf” - 使用单个换行符结束符 “dos” - 使用DOS风格的行尾 “crlf ” - 使用Carraige返回，换行符结束 --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 允许指定解压档案时使用的编码，支持指定编码的unarchiver。如果未指定，将使用归档程序默认值。Archiver默认值通常代表理智（modern）的values。 --&gt; &lt;!--string--&gt; &lt;encoding/&gt; &lt;/unpackOptions&gt; &lt;!-- 为此dependencySet设置依赖项范围。 默认值是：runtime。 --&gt; &lt;!--string--&gt; &lt;scope/&gt; &lt;!-- 确定当前项目构建过程中产生的工件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useProjectArtifact/&gt; &lt;!-- 确定当前项目构建过程中产生的附件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useProjectAttachments/&gt; &lt;!-- 确定是否将传递依赖项包含在当前依赖项集的处理中。如果为true，那么include / excludes / useTransitiveFiltering将应用于传递依赖项构件以及主项目依赖项构件。 如果为false，则useTransitiveFiltering无意义，并且包含/排除仅影响项目的直接依赖关系。 默认情况下，这个值是真的。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveDependencies/&gt; &lt;!-- 确定此依赖项集中的包含/排除模式是否将应用于给定工件的传递路径。 如果为真，并且当前工件是由包含或排除模式匹配的另一个工件引入的传递依赖性，则当前工件具有与其相同的包含/排除逻辑。 默认情况下，此值为false，以保持与2.1版的向后兼容性。这意味着包含/排除仅仅直接应用于当前的工件，而不应用于传入的工件。（从2.2-beta-1） 默认值为：false。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveFiltering/&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;!-- 定义要包含在程序集中的Maven仓库。可用于存储库中的工件是项目的依赖工件。创建的存储库包含所需的元数据条目，并且还包含sha1和md5校验和。这对创建将被部署到内部存储库的档案很有用。 注意：目前，只有来自中央存储库的工件才被允许。 --&gt; &lt;!--List&lt;Repository&gt;--&gt; &lt;repositories&gt; &lt;repository&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组包含的项目坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的项目工件坐标。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 如果设置为true，则此属性将触发创建存储库元数据，这将允许存储库用作功能性远程存储库。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;includeMetadata/&gt; &lt;!-- （许多） 指定要将一组工件与指定的版本对齐。groupVersionAlignment通过提供一个或多个&lt;groupVersionAlignment&gt;子元素来指定。 允许一组工件与指定的版本对齐。 --&gt; &lt;!--List&lt;GroupVersionAlignment&gt;--&gt; &lt;groupVersionAlignments&gt; &lt;groupVersionAlignment&gt; &lt;!-- 要为其对齐版本的工件的groupId。 --&gt; &lt;!--string--&gt; &lt;id/&gt; &lt;!-- 您想要将该组对齐的版本。 --&gt; &lt;!--string--&gt; &lt;version/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义要排除的构件的artifactIds。如果不存在，则&lt;excludes&gt;不表示排除。排除是通过提供一个或多个&lt;exclude&gt;子元素来指定的。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;/groupVersionAlignment&gt; &lt;/groupVersionAlignments&gt; &lt;!-- 指定此存储库中包含的工件的范围。（从2.2-beta-1开始） 默认值是：runtime。 --&gt; &lt;!--string--&gt; &lt;scope/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- （许多） 指定要包含在程序集中的共享组件xml文件位置。指定的位置必须相对于描述符的基本位置。 如果描述符是通过类路径中的&lt;descriptorRef /&gt;元素找到的，那么它指定的任何组件也将在类路径中找到。 如果通过路径名通过&lt;descriptor /&gt;元素找到，则此处的值将被解释为相对于项目basedir的路径。 当找到多个componentDescriptors时，它们的内容被合并。检查 描述符组件 了解更多信息。 componentDescriptor通过提供一个或多个&lt;componentDescriptor&gt;子元素来指定。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;componentDescriptors/&gt;&lt;/assembly&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"},{"name":"Assembly","slug":"Assembly","permalink":"https://yaoyinglong.github.io/tags/Assembly/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven个性化打包","date":"2019-10-27T16:00:00.000Z","path":"Blog/Maven/Maven个性化打包/","text":"在某些场景下，比如有N个产品，经常需要从这N个产品中抽取M个产品打包运行。而且每个产品都会持续迭代。若是将每个产品都写成一个项目会出现大量得重复代码，而且打包时需要打成多个包，会对客户造成困扰。为了解决这种场景可以使用maven-assembly-plugin插件自定义打包结构及定制依赖项将需要得class打进包中即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;com.icloud.CusMainApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-jar&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/common_jar.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&lt;/outputDirectory&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;make-tar&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/common_tar.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; make-jar是通过描述文件将项目打成JAR包，make-tar是为了将JAR包、配置文件、sh脚本等打成tar包。 common_jar.xml脚本示例： 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;assembly xmlns=\"http://maven.apache.org/ASSEMBLY/1.1.2\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/ASSEMBLY/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd\"&gt; &lt;id&gt;TestAssembly&lt;/id&gt; &lt;formats&gt; &lt;format&gt;jar&lt;/format&gt; &lt;/formats&gt; &lt;!-- 改为false不会出现两层相同的目录 --&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;fileSets&gt; &lt;!-- Main --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;\\..\\target\\classes&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;com\\icloud\\CusMainApplication.class&lt;/include&gt; &lt;/includes&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;!-- resources --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;\\..\\target\\classes&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;rs\\test_rs.csv&lt;/include&gt; &lt;/includes&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;unpack&gt;true&lt;/unpack&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt;&lt;/assembly&gt; common_tar.xml脚本示例： 1234567891011121314151617181920212223242526272829303132333435363738&lt;assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd\"&gt; &lt;id&gt;bundle&lt;/id&gt; &lt;formats&gt; &lt;format&gt;tar.gz&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources/&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;application.yml&lt;/include&gt; &lt;include&gt;application-prod.yml&lt;/include&gt; &lt;include&gt;log4j2-prod.xml&lt;/include&gt; &lt;/includes&gt; &lt;outputDirectory&gt;/config&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;!-- scripts --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources/&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;run.sh&lt;/include&gt; &lt;/includes&gt; &lt;fileMode&gt;0755&lt;/fileMode&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;!-- executable jar --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.build.directory&#125;/&lt;/directory&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;$&#123;assembly.finalName&#125;.jar&lt;/include&gt; &lt;/includes&gt; &lt;fileMode&gt;0755&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 若在SpringBoot项目中遇到使用Log4j2的情况，以上配置能完成打包，但是在运行的时候会出现由于日志配置文件解析不了导致项目启动失败。这时需要用到另一个插件maven-shade-plugin对架包种得Log4j2进行处理。 12345678910111213141516171819202122232425262728293031323334ERROR StatusLogger Unrecognized format specifier [d]ERROR StatusLogger Unrecognized conversion specifier [d] starting at position 16 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [thread]ERROR StatusLogger Unrecognized conversion specifier [thread] starting at position 25 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [level]ERROR StatusLogger Unrecognized conversion specifier [level] starting at position 35 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [logger]ERROR StatusLogger Unrecognized conversion specifier [logger] starting at position 47 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [msg]ERROR StatusLogger Unrecognized conversion specifier [msg] starting at position 54 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [n]ERROR StatusLogger Unrecognized conversion specifier [n] starting at position 56 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [d]ERROR StatusLogger Unrecognized conversion specifier [d] starting at position 16 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [thread]ERROR StatusLogger Unrecognized conversion specifier [thread] starting at position 25 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [level]ERROR StatusLogger Unrecognized conversion specifier [level] starting at position 35 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [logger]ERROR StatusLogger Unrecognized conversion specifier [logger] starting at position 47 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [msg]ERROR StatusLogger Unrecognized conversion specifier [msg] starting at position 54 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [n]ERROR StatusLogger Unrecognized conversion specifier [n] starting at position 56 in conversion pattern. . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot ::%d [%thread] %-5level %logger - %msg%n%d [%thread] %-5level %logger - %msg%n org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [com.icloud.CusMainApplication]; nested exception is java.lang.IllegalArgumentException: No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct. maven-shade-plugin插件配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.springframework.boot.maven.PropertiesMergingResourceTransformer\"&gt; &lt;resource&gt;META-INF/spring.factories&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\"/&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"&gt; &lt;mainClass&gt;com.icloud.CusMainApplication&lt;/mainClass&gt; &lt;/transformer&gt; &lt;transformer implementation=\"com.github.edwgiz.mavenShadePlugin.log4j2CacheTransformer.PluginsCacheFileTransformer\" /&gt; &lt;/transformers&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.edwgiz&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin.log4j2-cachefile-transformer&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"},{"name":"assembly","slug":"assembly","permalink":"https://yaoyinglong.github.io/tags/assembly/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven加密JAR包","date":"2019-10-27T16:00:00.000Z","path":"Blog/Maven/Maven加密JAR包/","text":"在某些情况下可能会需要将JAR包提供给第三方使用，但又不想泄露源码，可以对架包进行加密处理。可以使用xjar-maven-plugin插件对生成得JAR进行加密，Maven配置如下： 1234567891011121314151617181920212223&lt;plugin&gt; &lt;groupId&gt;com.github.core-lib&lt;/groupId&gt; &lt;artifactId&gt;xjar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;v2.0.6&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;configuration&gt; &lt;password&gt;7nBHK8bKB6&lt;/password&gt; &lt;includes&gt; &lt;include&gt;com/icloud/**&lt;/include&gt; &lt;/includes&gt; &lt;sourceDir&gt;$&#123;outputDirectory&#125;&lt;/sourceDir&gt; &lt;sourceJar&gt;$&#123;finalName&#125;.jar&lt;/sourceJar&gt; &lt;targetDir&gt;$&#123;assembly.outputDirectory&#125;&lt;/targetDir&gt; &lt;targetJar&gt;$&#123;finalName&#125;-encrypted.jar&lt;/targetJar&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 在执行JAR包时，需要在启动命令中加入--xjar.password=7nBHK8bKB6命令进行解密，否则JAR包将不能正常启动。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"},{"name":"加密","slug":"加密","permalink":"https://yaoyinglong.github.io/tags/加密/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"国密SM2","date":"2019-10-27T16:00:00.000Z","path":"Blog/Java/工具/国密SM2/","text":"SM2为非对称加密，基于ECC 椭圆曲线密码机制。该算法已公开。由于该算法基于ECC，故其签名速度与秘钥生成速度都快于RSA。ECC 256位（SM2采用的就是ECC 256位的一种）安全强度比RSA 2048位高，但运算速度快于RSA。 Maven配置： 1234&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt;&lt;/dependency&gt; 特别关注对于SM2加解密，需要注意三点，首先需要注意加密处理的密文顺序，关于密钥的使用，以及加解密的HEX转码问题。 加密处理的密文顺序 注意约定C1、C2、C3的拼装顺序（参照下面加密相关的代码内容，示例顺序为：C1+C2+C3） 密钥的使用 有的生成的公钥是带04前缀，有的是不带的。在使用时最对实际情况进行04的截取或补充（示例是带04的） 有的生成的私钥前缀带有00，有的是不带00的，在使用时最对实际情况进行00的截取或补充（示例是不带00的） HEX转码问题 SM2加解密过程中会多次进行HEX的编码何解码，调试时需要注意 在进行HEX编码时，注意中文的编码格式 相关代码Cipher代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class Cipher &#123; private int ct; private ECPoint p2; private SM3Digest sm3keybase; private SM3Digest sm3c3; private byte[] key; private byte keyOff; public Cipher() &#123; this.ct = 1; this.key = new byte[32]; this.keyOff = 0; &#125; private void Reset() &#123; this.sm3keybase = new SM3Digest(); this.sm3c3 = new SM3Digest(); byte[] publicKeyX = HexUtil.byteConvert32Bytes(p2.getX().toBigInteger()); this.sm3keybase.update(publicKeyX, 0, publicKeyX.length); this.sm3c3.update(publicKeyX, 0, publicKeyX.length); byte[] publicKeyY = HexUtil.byteConvert32Bytes(p2.getY().toBigInteger()); this.sm3keybase.update(publicKeyY, 0, publicKeyY.length); this.ct = 1; NextKey(); &#125; private void NextKey() &#123; SM3Digest sm3keycur = new SM3Digest(this.sm3keybase); sm3keycur.update((byte) (ct &gt;&gt; 24 &amp; 0xff)); sm3keycur.update((byte) (ct &gt;&gt; 16 &amp; 0xff)); sm3keycur.update((byte) (ct &gt;&gt; 8 &amp; 0xff)); sm3keycur.update((byte) (ct &amp; 0xff)); sm3keycur.doFinal(key, 0); this.keyOff = 0; this.ct++; &#125; public ECPoint Init_enc(SM2 sm2, ECPoint userKey) &#123; AsymmetricCipherKeyPair key = sm2.ecc_key_pair_generator.generateKeyPair(); ECPrivateKeyParameters ecpriv = (ECPrivateKeyParameters) key.getPrivate(); ECPublicKeyParameters ecpub = (ECPublicKeyParameters) key.getPublic(); BigInteger k = ecpriv.getD(); ECPoint c1 = ecpub.getQ(); this.p2 = userKey.multiply(k); Reset(); return c1; &#125; public void Encrypt(byte[] data) &#123; this.sm3c3.update(data, 0, data.length); for (int i = 0; i &lt; data.length; i++) &#123; if (keyOff == key.length) &#123; NextKey(); &#125; data[i] ^= key[keyOff++]; &#125; &#125; public void Init_dec(BigInteger userD, ECPoint c1) &#123; this.p2 = c1.multiply(userD); Reset(); &#125; public void Decrypt(byte[] data) &#123; for (int i = 0; i &lt; data.length; i++) &#123; if (keyOff == key.length) &#123; NextKey(); &#125; data[i] ^= key[keyOff++]; &#125; this.sm3c3.update(data, 0, data.length); &#125; public void Dofinal(byte[] c3) &#123; byte[] publicKeyY = HexUtil.byteConvert32Bytes(p2.getY().toBigInteger()); this.sm3c3.update(publicKeyY, 0, publicKeyY.length); this.sm3c3.doFinal(c3, 0); Reset(); &#125;&#125; SM2代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SM2 &#123; public static String[] ECC_PARAM = &#123; \"FFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00000000FFFFFFFFFFFFFFFF\", \"FFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00000000FFFFFFFFFFFFFFFC\", \"28E9FA9E9D9F5E344D5A9E4BCF6509A7F39789F515AB8F92DDBCBD414D940E93\", \"FFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFF7203DF6B21C6052B53BBF40939D54123\", \"32C4AE2C1F1981195F9904466A39C9948FE30BBFF2660BE1715A4589334C74C7\", \"BC3736A2F4F6779C59BDCEE36B692153D0A9877CC62A474002DF32E52139F0A0\" &#125;; public final BigInteger ecc_p; public final BigInteger ecc_a; public final BigInteger ecc_b; public final BigInteger ecc_n; public final BigInteger ecc_gx; public final BigInteger ecc_gy; public final ECCurve ecc_curve; public final ECPoint ecc_point_g; public final ECDomainParameters ecc_bc_spec; public final ECKeyPairGenerator ecc_key_pair_generator; public final ECFieldElement ecc_gx_fieldelement; public final ECFieldElement ecc_gy_fieldelement; public SM2() &#123; this.ecc_p = new BigInteger(ECC_PARAM[0], 16); this.ecc_a = new BigInteger(ECC_PARAM[1], 16); this.ecc_b = new BigInteger(ECC_PARAM[2], 16); this.ecc_n = new BigInteger(ECC_PARAM[3], 16); this.ecc_gx = new BigInteger(ECC_PARAM[4], 16); this.ecc_gy = new BigInteger(ECC_PARAM[5], 16); this.ecc_gx_fieldelement = new Fp(this.ecc_p, this.ecc_gx); this.ecc_gy_fieldelement = new Fp(this.ecc_p, this.ecc_gy); this.ecc_curve = new ECCurve.Fp(this.ecc_p, this.ecc_a, this.ecc_b); this.ecc_point_g = new ECPoint.Fp(this.ecc_curve, this.ecc_gx_fieldelement, this.ecc_gy_fieldelement); this.ecc_bc_spec = new ECDomainParameters(this.ecc_curve, this.ecc_point_g, this.ecc_n); ECKeyGenerationParameters ecc_ecgenparam; ecc_ecgenparam = new ECKeyGenerationParameters(this.ecc_bc_spec, new SecureRandom()); this.ecc_key_pair_generator = new ECKeyPairGenerator(); this.ecc_key_pair_generator.init(ecc_ecgenparam); &#125; public static SM2 Instance() &#123; return new SM2(); &#125;&#125; SM2Utils代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class SM2Utils &#123; //生成随机秘钥对 public static void generateKeyPair() &#123; SM2 sm2 = SM2.Instance(); AsymmetricCipherKeyPair key = sm2.ecc_key_pair_generator.generateKeyPair(); ECPrivateKeyParameters ecpriv = (ECPrivateKeyParameters) key.getPrivate(); ECPublicKeyParameters ecpub = (ECPublicKeyParameters) key.getPublic(); BigInteger privateKey = ecpriv.getD(); ECPoint publicKey = ecpub.getQ(); System.out.println(\"公钥: \" + ByteUtils.toHexString(publicKey.getEncoded())); System.out.println(\"私钥: \" + ByteUtils.toHexString(privateKey.toByteArray())); &#125; //数据加密 public static String encrypt(String publicKey, String plainText) &#123; if (StringUtils.isBlank(publicKey) || StringUtils.isBlank(plainText)) &#123; return null; &#125; byte[] publicKeyBytes = ByteUtils.fromHexString(publicKey); byte[] plainTextBytes = ByteUtils.fromHexString(plainText); byte[] source = new byte[plainTextBytes.length]; System.arraycopy(plainTextBytes, 0, source, 0, plainTextBytes.length); Cipher cipher = new Cipher(); SM2 sm2 = SM2.Instance(); ECPoint userKey = sm2.ecc_curve.decodePoint(publicKeyBytes); ECPoint c1 = cipher.Init_enc(sm2, userKey); cipher.Encrypt(source); byte[] c3 = new byte[32]; cipher.Dofinal(c3); //C1 C2 C3拼装成加密字串 return ByteUtils.toHexString(c1.getEncoded()) + ByteUtils.toHexString(source) + ByteUtils.toHexString(c3); &#125; //数据解密 public static byte[] decrypt(String privateKey, String cipherText) &#123; if (StringUtils.isBlank(privateKey) || StringUtils.isBlank(cipherText)) &#123; return null; &#125; byte[] privateKeyBytes = ByteUtils.fromHexString(privateKey); byte[] cipherTextBytes = ByteUtils.fromHexString(cipherText); //加密字节数组转换为十六进制的字符串 长度变为encryptedData.length * 2 String data = ByteUtils.toHexString(cipherTextBytes); /***分解加密字串 * （C1 = C1标志位2位 + C1实体部分128位 = 130） * （C3 = C3实体部分64位 = 64） * （C2 = encryptedData.length * 2 - C1长度 - C2长度） */ byte[] c1Bytes = ByteUtils.fromHexString(data.substring(0, 130)); int c2Len = cipherTextBytes.length - 97; byte[] c2 = ByteUtils.fromHexString(data.substring(130, 130 + 2 * c2Len)); byte[] c3 = ByteUtils.fromHexString(data.substring(130 + 2 * c2Len, 194 + 2 * c2Len)); SM2 sm2 = SM2.Instance(); BigInteger userD = new BigInteger(1, privateKeyBytes); //通过C1实体字节来生成ECPoint ECPoint c1 = sm2.ecc_curve.decodePoint(c1Bytes); Cipher cipher = new Cipher(); cipher.Init_dec(userD, c1); cipher.Decrypt(c2); cipher.Dofinal(c3); //返回解密结果 return c2; &#125;&#125;","tags":[{"name":"国密","slug":"国密","permalink":"https://yaoyinglong.github.io/tags/国密/"},{"name":"SM2","slug":"SM2","permalink":"https://yaoyinglong.github.io/tags/SM2/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://yaoyinglong.github.io/categories/Java/工具/"}]},{"title":"国密SM4","date":"2019-10-27T16:00:00.000Z","path":"Blog/Java/工具/国密SM4/","text":"SM4 无线局域网标准的分组数据算法。对称加密，密钥长度和分组长度均为128位。 分组密码常用得五种模式，这里主要讲SM4的ECB模式： EBC-电码本模式 CBC-密码分组链接模式 CTR-计算器模式 CFB-密码反馈模式 OFB-输出反馈模式 Maven配置： 1234&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt;&lt;/dependency&gt; 特别关注SM4加解密最需要注意，也是最容易出错的地方是填充模式的处理。而且对数据的填充方式是高度自由的。这里介绍两种填充方式。当然也可以不填充，但一般都会要求使用填充。 进行加密得时候会进行填充，在进行解密时会去填充。若填充方式不匹配，解密得数据将会不正确。 填充方式可以为：数据得长度 + 数据 + 填充，还可以为：数据 + 填充位长度 + 填充，且填充可以在转HEX前也可以在转HEX之后，所以说填充是高度自由的。 相关代码SM4Context代码： 12345678910public class SM4Context &#123; public int mode; public long[] sk; public boolean isPadding; public SM4Context() &#123; this.mode = 1; this.isPadding = true; this.sk = new long[32]; &#125;&#125; SM4代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245public class SM4 &#123; public static final int SM4_ENCRYPT = 1; public static final int SM4_DECRYPT = 0; public static final byte[] SBOX_TABLE = &#123; (byte) 0xd6, (byte) 0x90, (byte) 0xe9, (byte) 0xfe, (byte) 0xcc, (byte) 0xe1, 0x3d, (byte) 0xb7, 0x16, (byte) 0xb6, 0x14, (byte) 0xc2, 0x28, (byte) 0xfb, 0x2c, 0x05, 0x2b, 0x67, (byte) 0x9a, 0x76, 0x2a, (byte) 0xbe, 0x04, (byte) 0xc3, (byte) 0xaa, 0x44, 0x13, 0x26, 0x49, (byte) 0x86, 0x06, (byte) 0x99, (byte) 0x9c, 0x42, 0x50, (byte) 0xf4, (byte) 0x91, (byte) 0xef, (byte) 0x98, 0x7a, 0x33, 0x54, 0x0b, 0x43, (byte) 0xed, (byte) 0xcf, (byte) 0xac, 0x62, (byte) 0xe4, (byte) 0xb3, 0x1c, (byte) 0xa9, (byte) 0xc9, 0x08, (byte) 0xe8, (byte) 0x95, (byte) 0x80, (byte) 0xdf, (byte) 0x94, (byte) 0xfa, 0x75, (byte) 0x8f, 0x3f, (byte) 0xa6, 0x47, 0x07, (byte) 0xa7, (byte) 0xfc, (byte) 0xf3, 0x73, 0x17, (byte) 0xba, (byte) 0x83, 0x59, 0x3c, 0x19, (byte) 0xe6, (byte) 0x85, 0x4f, (byte) 0xa8, 0x68, 0x6b, (byte) 0x81, (byte) 0xb2, 0x71, 0x64, (byte) 0xda, (byte) 0x8b, (byte) 0xf8, (byte) 0xeb, 0x0f, 0x4b, 0x70, 0x56, (byte) 0x9d, 0x35, 0x1e, 0x24, 0x0e, 0x5e, 0x63, 0x58, (byte) 0xd1, (byte) 0xa2, 0x25, 0x22, 0x7c, 0x3b, 0x01, 0x21, 0x78, (byte) 0x87, (byte) 0xd4, 0x00, 0x46, 0x57, (byte) 0x9f, (byte) 0xd3, 0x27, 0x52, 0x4c, 0x36, 0x02, (byte) 0xe7, (byte) 0xa0, (byte) 0xc4, (byte) 0xc8, (byte) 0x9e, (byte) 0xea, (byte) 0xbf, (byte) 0x8a, (byte) 0xd2, 0x40, (byte) 0xc7, 0x38, (byte) 0xb5, (byte) 0xa3, (byte) 0xf7, (byte) 0xf2, (byte) 0xce, (byte) 0xf9, 0x61, 0x15, (byte) 0xa1, (byte) 0xe0, (byte) 0xae, 0x5d, (byte) 0xa4, (byte) 0x9b, 0x34, 0x1a, 0x55, (byte) 0xad, (byte) 0x93, 0x32, 0x30, (byte) 0xf5, (byte) 0x8c, (byte) 0xb1, (byte) 0xe3, 0x1d, (byte) 0xf6, (byte) 0xe2, 0x2e, (byte) 0x82, 0x66, (byte) 0xca, 0x60, (byte) 0xc0, 0x29, 0x23, (byte) 0xab, 0x0d, 0x53, 0x4e, 0x6f, (byte) 0xd5, (byte) 0xdb, 0x37, 0x45, (byte) 0xde, (byte) 0xfd, (byte) 0x8e, 0x2f, 0x03, (byte) 0xff, 0x6a, 0x72, 0x6d, 0x6c, 0x5b, 0x51, (byte) 0x8d, 0x1b, (byte) 0xaf, (byte) 0x92, (byte) 0xbb, (byte) 0xdd, (byte) 0xbc, 0x7f, 0x11, (byte) 0xd9, 0x5c, 0x41, 0x1f, 0x10, 0x5a, (byte) 0xd8, 0x0a, (byte) 0xc1, 0x31, (byte) 0x88, (byte) 0xa5, (byte) 0xcd, 0x7b, (byte) 0xbd, 0x2d, 0x74, (byte) 0xd0, 0x12, (byte) 0xb8, (byte) 0xe5, (byte) 0xb4, (byte) 0xb0, (byte) 0x89, 0x69, (byte) 0x97, 0x4a, 0x0c, (byte) 0x96, 0x77, 0x7e, 0x65, (byte) 0xb9, (byte) 0xf1, 0x09, (byte) 0xc5, 0x6e, (byte) 0xc6, (byte) 0x84, 0x18, (byte) 0xf0, 0x7d, (byte) 0xec, 0x3a, (byte) 0xdc, 0x4d, 0x20, 0x79, (byte) 0xee, 0x5f, 0x3e, (byte) 0xd7, (byte) 0xcb, 0x39, 0x48 &#125;; public static final int[] FK = &#123;0xa3b1bac6, 0x56aa3350, 0x677d9197, 0xb27022dc&#125;; public static final int[] CK = &#123; 0x00070e15, 0x1c232a31, 0x383f464d, 0x545b6269, 0x70777e85, 0x8c939aa1, 0xa8afb6bd, 0xc4cbd2d9, 0xe0e7eef5, 0xfc030a11, 0x181f262d, 0x343b4249, 0x50575e65, 0x6c737a81, 0x888f969d, 0xa4abb2b9, 0xc0c7ced5, 0xdce3eaf1, 0xf8ff060d, 0x141b2229, 0x30373e45, 0x4c535a61, 0x686f767d, 0x848b9299, 0xa0a7aeb5, 0xbcc3cad1, 0xd8dfe6ed, 0xf4fb0209, 0x10171e25, 0x2c333a41, 0x484f565d, 0x646b7279 &#125;; private long GET_ULONG_BE(byte[] b, int i) &#123; long n = (long) (b[i] &amp; 0xff) &lt;&lt; 24 | (long) ((b[i + 1] &amp; 0xff) &lt;&lt; 16) | (long) ((b[i + 2] &amp; 0xff) &lt;&lt; 8) | (long) (b[i + 3] &amp; 0xff) &amp; 0xffffffffL; return n; &#125; private void PUT_ULONG_BE(long n, byte[] b, int i) &#123; b[i] = (byte) (int) (0xFF &amp; n &gt;&gt; 24); b[i + 1] = (byte) (int) (0xFF &amp; n &gt;&gt; 16); b[i + 2] = (byte) (int) (0xFF &amp; n &gt;&gt; 8); b[i + 3] = (byte) (int) (0xFF &amp; n); &#125; private long SHL(long x, int n) &#123; return (x &amp; 0xFFFFFFFF) &lt;&lt; n; &#125; private long ROTL(long x, int n) &#123; return SHL(x, n) | x &gt;&gt; 32 - n; &#125; private void SWAP(long[] sk, int i) &#123; long t = sk[i]; sk[i] = sk[31 - i]; sk[31 - i] = t; &#125; private byte sm4Sbox(byte inch) &#123; int i = inch &amp; 0xFF; byte retVal = SBOX_TABLE[i]; return retVal; &#125; private long sm4Lt(long ka) &#123; long bb = 0L; long c = 0L; byte[] a = new byte[4]; byte[] b = new byte[4]; PUT_ULONG_BE(ka, a, 0); b[0] = sm4Sbox(a[0]); b[1] = sm4Sbox(a[1]); b[2] = sm4Sbox(a[2]); b[3] = sm4Sbox(a[3]); bb = GET_ULONG_BE(b, 0); c = bb ^ ROTL(bb, 2) ^ ROTL(bb, 10) ^ ROTL(bb, 18) ^ ROTL(bb, 24); return c; &#125; private long sm4F(long x0, long x1, long x2, long x3, long rk) &#123; return x0 ^ sm4Lt(x1 ^ x2 ^ x3 ^ rk); &#125; private long sm4CalciRK(long ka) &#123; long bb = 0L; long rk = 0L; byte[] a = new byte[4]; byte[] b = new byte[4]; PUT_ULONG_BE(ka, a, 0); b[0] = sm4Sbox(a[0]); b[1] = sm4Sbox(a[1]); b[2] = sm4Sbox(a[2]); b[3] = sm4Sbox(a[3]); bb = GET_ULONG_BE(b, 0); rk = bb ^ ROTL(bb, 13) ^ ROTL(bb, 23); return rk; &#125; private void sm4_setkey(long[] SK, byte[] key) &#123; long[] MK = new long[4]; long[] k = new long[36]; int i = 0; MK[0] = GET_ULONG_BE(key, 0); MK[1] = GET_ULONG_BE(key, 4); MK[2] = GET_ULONG_BE(key, 8); MK[3] = GET_ULONG_BE(key, 12); k[0] = MK[0] ^ (long) FK[0]; k[1] = MK[1] ^ (long) FK[1]; k[2] = MK[2] ^ (long) FK[2]; k[3] = MK[3] ^ (long) FK[3]; for (; i &lt; 32; i++) &#123; k[i + 4] = k[i] ^ sm4CalciRK(k[i + 1] ^ k[i + 2] ^ k[i + 3] ^ (long) CK[i]); SK[i] = k[i + 4]; &#125; &#125; private void sm4_one_round(long[] sk, byte[] input, byte[] output) &#123; int i = 0; long[] ulbuf = new long[36]; ulbuf[0] = GET_ULONG_BE(input, 0); ulbuf[1] = GET_ULONG_BE(input, 4); ulbuf[2] = GET_ULONG_BE(input, 8); ulbuf[3] = GET_ULONG_BE(input, 12); while (i &lt; 32) &#123; ulbuf[i + 4] = sm4F(ulbuf[i], ulbuf[i + 1], ulbuf[i + 2], ulbuf[i + 3], sk[i]); i++; &#125; PUT_ULONG_BE(ulbuf[35], output, 0); PUT_ULONG_BE(ulbuf[34], output, 4); PUT_ULONG_BE(ulbuf[33], output, 8); PUT_ULONG_BE(ulbuf[32], output, 12); &#125; private byte[] padding(byte[] input, int mode) &#123; if (input == null) &#123; return null; &#125; byte[] ret; if (mode == SM4_ENCRYPT) &#123; int inputLength = input.length; String paddingPrefix = String.valueOf(inputLength); int paddingPrefixLength = 4 - paddingPrefix.length(); StringBuffer prefixBuffer = new StringBuffer(); for (int i = 0; i &lt; paddingPrefixLength; i++) &#123; prefixBuffer.append(\"0\"); &#125; paddingPrefix = ByteUtils.toHexString(prefixBuffer.append(paddingPrefix).toString().getBytes()); int paddingLength = 16 - (inputLength + 4) % 16; String inputHex = ByteUtils.toHexString(input); StringBuffer stringBuffer = new StringBuffer(paddingPrefix); stringBuffer.append(inputHex); for (int i = 0; i &lt; paddingLength; i++) &#123; stringBuffer.append(\"00\"); &#125; ret = ByteUtils.fromHexString(stringBuffer.toString()); &#125; else &#123; String inputHex = ByteUtils.toHexString(input); String paddingPrefix = inputHex.substring(0, 8); paddingPrefix = new String(ByteUtils.fromHexString(paddingPrefix)); int dataLength = Integer.valueOf(paddingPrefix); String dataHex = inputHex.substring(8, dataLength * 2 + 8); ret = ByteUtils.fromHexString(dataHex); &#125; return ret; &#125; private byte[] paddingOld(byte[] input, int mode) &#123; if (input == null) &#123; return null; &#125; byte[] ret; if (mode == SM4_ENCRYPT) &#123; String origin = new String(input); int inputLength = origin.length(); String paddingPrefix = String.valueOf(inputLength); int paddingPrefixLength = 4 - paddingPrefix.length(); StringBuffer prefixBuffer = new StringBuffer(); for (int i = 0; i &lt; paddingPrefixLength; i++) &#123; prefixBuffer.append(\"0\"); &#125; paddingPrefix = prefixBuffer.append(paddingPrefix).toString(); int paddingLength = 16 - (inputLength + 4) % 16; StringBuffer stringBuffer = new StringBuffer(paddingPrefix); stringBuffer.append(origin); for (int i = 0; i &lt; paddingLength; i++) &#123; stringBuffer.append(\"0\"); &#125; ret = stringBuffer.toString().getBytes(); &#125; else &#123; String origin = new String(input); String paddingPrefix = origin.substring(0, 4); int dataLength = Integer.valueOf(paddingPrefix); String data = origin.substring(4, dataLength + 4); ret = data.getBytes(); &#125; return ret; &#125; public void sm4_setkey_enc(SM4Context ctx, byte[] key) throws Exception &#123; if (ctx == null) &#123; throw new Exception(\"SM4 sm4_setkey_enc SM4Context is null!\"); &#125; if (key == null || key.length != 16) &#123; throw new Exception(\"SM4 sm4_setkey_enc key byte array error!\"); &#125; ctx.mode = SM4_ENCRYPT; sm4_setkey(ctx.sk, key); &#125; public void sm4_setkey_dec(SM4Context ctx, byte[] key) throws Exception &#123; if (ctx == null) &#123; throw new Exception(\"SM4 sm4_setkey_dec SM4Context is null!\"); &#125; if (key == null || key.length != 16) &#123; throw new Exception(\"SM4 sm4_setkey_dec key byte array error!\"); &#125; int i = 0; ctx.mode = SM4_DECRYPT; sm4_setkey(ctx.sk, key); for (i = 0; i &lt; 16; i++) &#123; SWAP(ctx.sk, i); &#125; &#125; public byte[] sm4_crypt_ecb(SM4Context ctx, byte[] input) throws Exception &#123; if (input == null) &#123; throw new Exception(\"SM4 sm4_crypt_ecb input byte array is null!\"); &#125; if (ctx.isPadding &amp;&amp; ctx.mode == SM4_ENCRYPT) &#123; input = padding(input, SM4_ENCRYPT); &#125; int length = input.length; ByteArrayInputStream bins = new ByteArrayInputStream(input); ByteArrayOutputStream bous = new ByteArrayOutputStream(); for (; length &gt; 0; length -= 16) &#123; byte[] in = new byte[16]; byte[] out = new byte[16]; bins.read(in); sm4_one_round(ctx.sk, in, out); bous.write(out); &#125; byte[] output = bous.toByteArray(); if (ctx.isPadding &amp;&amp; ctx.mode == SM4_DECRYPT) &#123; output = padding(output, SM4_DECRYPT); &#125; bins.close(); bous.close(); return output; &#125;&#125; SM4Utils代码： 123456789101112131415161718192021222324252627282930313233343536public class SM4Utils &#123; public static String encryptDataEcb(String plainText, String sm4Key) throws Exception &#123; SM4Context ctx = new SM4Context(); ctx.isPadding = true; ctx.mode = SM4.SM4_ENCRYPT; SM4 sm4 = new SM4(); byte[] keyBytes = ByteUtils.fromHexString(sm4Key); sm4.sm4_setkey_enc(ctx, keyBytes); byte[] encrypted = sm4.sm4_crypt_ecb(ctx, ByteUtils.fromHexString(plainText)); return ByteUtils.toHexString(encrypted); &#125; public static String decryptDataEcb(String cipherText, String sm4Key) throws Exception &#123; SM4Context ctx = new SM4Context(); ctx.isPadding = true; ctx.mode = SM4.SM4_DECRYPT; byte[] keyBytes = ByteUtils.fromHexString(sm4Key); SM4 sm4 = new SM4(); sm4.sm4_setkey_dec(ctx, keyBytes); byte[] decrypted = sm4.sm4_crypt_ecb(ctx, Base64.decodeBase64(cipherTextTransform(cipherText))); return ByteUtils.toHexString(decrypted); &#125; private static String cipherTextTransform(String cipherText) throws Exception &#123; byte[] encrypted = ByteUtils.fromHexString(cipherText); cipherText = Base64.encodeBase64String(encrypted); if (StringUtils.isNotBlank(cipherText)) &#123; Pattern p = Pattern.compile(\"\\\\s*|\\t|\\r|\\n\"); Matcher m = p.matcher(cipherText); cipherText = m.replaceAll(\"\"); &#125; return cipherText; &#125;&#125;","tags":[{"name":"国密","slug":"国密","permalink":"https://yaoyinglong.github.io/tags/国密/"},{"name":"SM4","slug":"SM4","permalink":"https://yaoyinglong.github.io/tags/SM4/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://yaoyinglong.github.io/categories/Java/工具/"}]},{"title":"Spring线程池跨线程数据共享","date":"2019-10-23T16:00:00.000Z","path":"Blog/Spring/Spring线程池跨线程数据共享/","text":"在Spring Cloud中可能会用到sleuth做链路追踪，以及内部链路中需要用到Header中得一些数据，在单线程是没有问题得，但是在某些场景下就会有问题，比如上层业务系统得一个请求需要同时并发去调用基础服务得多个产品，这样请求到其他服务得链路追踪信息就不一样了等。 为了实现多线程并发情况下主线程和线程池的线程共享ThreadLocal变量，如MDC、RequestAttributes中的数据，需要自定义线程池及线程实现。 自定义线程池继承ThreadPoolTaskExecutor类重写execute和submit方法即可，Spring的ExecutorMethodInterceptor会拦截使用LazyTraceThreadPoolTaskExecutor装饰实际执行的task然后调用当前executor执行。代码如下： 1234567891011121314151617public class CusThreadPoolExecutor extends ThreadPoolTaskExecutor &#123; @Override public void execute(Runnable task) &#123; ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); Map&lt;String, String&gt; contextOfMDC = MDC.getCopyOfContextMap(); Runnable cusTask = new CusInheritThreadVarRunnable(servletRequestAttributes, contextOfMDC, task); super.execute(cusTask); &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); Map&lt;String, String&gt; contextOfMDC = MDC.getCopyOfContextMap(); Callable&lt;T&gt; cusTask = new CusInheritThreadVarCallable&lt;T&gt;(servletRequestAttributes, contextOfMDC, task); return super.submit(cusTask); &#125;&#125; 该线程池的使用和普通的线程池使用是一样。 只是在在提交到真正的线程池之前，会获取主线程中需要共享的ThreadLocal相关变量。然后将任务包装成一个新的Runnable或Callable，在子线程中执行任务之前，将ThreadLocal相关变量设置到子线程的ThreadLocalMap中，执行结束之前清空设置的ThreadLocal相关变量，防止不同线程中串数据。 Callable实现： 12345678910111213141516171819202122232425262728public class CusInheritThreadVarCallable&lt;V&gt; implements Callable&lt;V&gt; &#123; private Callable&lt;V&gt; delegate; private Map&lt;String, String&gt; contextOfMDC; private ServletRequestAttributes servletRequestAttributes; public CusInheritThreadVarCallable(ServletRequestAttributes servletRequestAttributes, Map&lt;String, String&gt; contextOfMDC, Callable&lt;V&gt; delegate) &#123; this.contextOfMDC = contextOfMDC; this.servletRequestAttributes = servletRequestAttributes; this.delegate = delegate; &#125; @Override public V call() throws Exception &#123; RestStrategyContext.clearCurrentContext(); //设置当前线程servletRequestAttributes RequestContextHolder.setRequestAttributes(servletRequestAttributes); //设置当前线程MDC MDC.setContextMap(contextOfMDC); V result; try &#123; result = delegate.call(); &#125; finally &#123; MDC.clear(); RequestContextHolder.resetRequestAttributes(); &#125; return result; &#125;&#125; Runnable实现： 12345678910111213141516171819202122232425262728public class CusInheritThreadVarRunnable implements Runnable &#123; private Runnable delegate; private Map&lt;String, String&gt; contextOfMDC; private ServletRequestAttributes servletRequestAttributes; public CusInheritThreadVarRunnable(ServletRequestAttributes servletRequestAttributes, Map&lt;String, String&gt; contextOfMDC, Runnable delegate) &#123; this.contextOfMDC = contextOfMDC; this.servletRequestAttributes = servletRequestAttributes; this.delegate = delegate; &#125; @Override public void run() &#123; RestStrategyContext.clearCurrentContext(); //设置当前线程servletRequestAttributes RequestContextHolder.setRequestAttributes(servletRequestAttributes); //设置当前线程MDC MDC.setContextMap(contextOfMDC); try &#123; // 执行 delegate.run(); &#125; finally &#123; // 清空 MDC.clear(); RequestContextHolder.resetRequestAttributes(); &#125; &#125;&#125; 线程池的配置如下： 1234567891011121314@Bean(name = \"processorExecutor\")public ThreadPoolTaskExecutor taskProcessorExecutor() &#123; CusThreadPoolExecutor executor = new CusThreadPoolExecutor(); executor.setCorePoolSize(taskPoolConfig.getCorePoolSize()); executor.setMaxPoolSize(taskPoolConfig.getMaxPoolSize()); executor.setQueueCapacity(taskPoolConfig.getQueueCapacity()); executor.setKeepAliveSeconds(taskPoolConfig.getKeepAliveSeconds()); executor.setThreadNamePrefix(\"CusTask-\"); executor.setRejectedExecutionHandler(cusCallerRunsPolicy); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(taskPoolConfig.getAwaitTerminationSeconds()); executor.initialize(); return executor;&#125; 对于线程池的配置需要注意的是，拒绝策略不要使用CallerRunsPolicy拒绝策略，该拒绝策略会在任务添加到线程池被拒绝时使用主线程执行该任务。在并发较高的情况下，拒绝策略生效，导致很多任务由主线程执行了，从而导致主线程中的MDC数据被清空了，从而导致一些trace信息丢失。可以自定义拒绝策略将任务丢回队列： 123456789101112public class CusCallerRunsPolicy implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; if (!executor.isShutdown()) &#123; try &#123; executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; log.error(\"Reject policy interrupted exception \", e); &#125; &#125; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"线程池","slug":"线程池","permalink":"https://yaoyinglong.github.io/tags/线程池/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"Win实用工具","date":"2019-07-29T16:00:00.000Z","path":"Blog/杂记/工具/Win实用工具/","text":"PotPlayer非常好用的视频播放器。 Typora轻便简洁的Markdown编辑器，支持即时渲染 TeamViewer用于远程控制的应用程序 Notepad++文本编辑器","tags":[{"name":"工具","slug":"工具","permalink":"https://yaoyinglong.github.io/tags/工具/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"工具","slug":"杂记/工具","permalink":"https://yaoyinglong.github.io/categories/杂记/工具/"}]},{"title":"JAVA实用工具","date":"2019-05-31T16:00:00.000Z","path":"Blog/Java/工具/JAVA实用工具/","text":"ArthasJava 线上诊断工具 EasyExcel用来对 Java 进行解析、生成 Excel 的框架，它重写了 poi 对 07 版 Excel 的解析，原本一个 3M 的 Excel 用 POI sax 需要 100M 左右内存，EasyExcel 可降低到 KB 级别，并且再大的 excel 也不会出现内存溢出的情况。03 版依赖 POI 的 sax 模式。在上层做了模型转换的封装，让使用者更加简单方便。 Postman接口调试工具 LoadRunner压测工具 jvisualvm给jdk自带的jvisualvm安装Visual GC插件，经常遇到We’re sorry the java.net site has closed。解决方法是找到jvisualvm新的(更新地址)[https://visualvm.github.io/index.html]，找到进入到Download页面，进入Download按钮下面有个Plugins，找到对应的自己的JDK版本的更新地址。进入jvisualvm的**插件管理-&gt;工具-&gt;插件-&gt;设置-&gt;编辑**，设置最新的更新地址。 ScriptEngineManager脚本引擎JDK自带的脚本引擎 12345678910public Integer calc(String exp) &#123; try &#123; ScriptEngineManager manager = new ScriptEngineManager(); ScriptEngine engine = manager.getEngineByName(\"JavaScript\"); return (Integer)engine.eval(exp); &#125;catch(Exception e) &#123; e.printStackTrace(); return null; &#125;&#125; Tess4j开源的OCR识别 12345&lt;dependency&gt; &lt;groupId&gt;net.sourceforge.tess4j&lt;/groupId&gt; &lt;artifactId&gt;tess4j&lt;/artifactId&gt; &lt;version&gt;4.5.4&lt;/version&gt;&lt;/dependency&gt; 123456789101112public class Tess4jDemo &#123; public static void main(String[] args) throws TesseractException &#123; final ITesseract instance = new Tesseract(); instance.setDatapath(\"D:\\\\tessdata\"); instance.setLanguage(\"chi_sim\"); File imageLocation = new File(\"D:\\\\verifyImg\"); for(File image : imageLocation.listFiles())&#123; System.out.println(image.getName()+\" --&gt;\"+instance.doOCR(image)); &#125; &#125;&#125; Aviator表达式引擎Java表达式引擎，Aviator支持三种类型计算：Boolean，字符串，和数字类型，数字类型只支持结果为Long 12345&lt;dependency&gt; &lt;groupId&gt;com.googlecode.aviator&lt;/groupId&gt; &lt;artifactId&gt;aviator&lt;/artifactId&gt; &lt;version&gt;5.2.6&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718public class AviatorDemo &#123; public static void main(String[] args) &#123; // 字型计算 System.out.println(AviatorEvaluator.execute(\"1+2+3\")); // 符型计算 String exp1 = \"'Hello '+ name\"; Map&lt;String,Object&gt; env1 = new HashMap&lt;&gt;(); env1.put(\"name\",\"tony\"); System.out.println(AviatorEvaluator.execute(exp1, env1)); // 断型计算 String exp2 = \"a+b&gt;c\"; Map&lt;String,Object&gt; env2 = new HashMap&lt;&gt;(); env2.put(\"a\",5); env2.put(\"b\",6); env2.put(\"c\",7); System.out.println(AviatorEvaluator.execute(exp2, env2)); &#125;&#125; 验证码123456789101112131415161718192021222324&lt;!-- Happy-Captcha验证码 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.ramostear&lt;/groupId&gt; &lt;artifactId&gt;Happy-Captcha&lt;/artifactId&gt; &lt;version&gt;1.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- anji验证码 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.anji-plus&lt;/groupId&gt; &lt;artifactId&gt;captcha-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.7&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jcaptcha验证码 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.octo.captcha&lt;/groupId&gt; &lt;artifactId&gt;jcaptcha&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- kaptcha验证码 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;kaptcha-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency&gt; drools规则引擎12345678910&lt;dependency&gt; &lt;groupId&gt;org.kie&lt;/groupId&gt; &lt;artifactId&gt;kie-ci&lt;/artifactId&gt; &lt;version&gt;7.6.0.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-core&lt;/artifactId&gt; &lt;version&gt;7.6.0.Final&lt;/version&gt;&lt;/dependency&gt;","tags":[{"name":"工具","slug":"工具","permalink":"https://yaoyinglong.github.io/tags/工具/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://yaoyinglong.github.io/categories/Java/工具/"}]},{"title":"Hystrix总结","date":"2019-05-25T16:00:00.000Z","path":"Blog/Spring/Hystrix总结/","text":"在项目中需要对某些接口进行限流和熔断处理，防止由于某些接口资源消耗过大影响到整个的所有接口，防止单独的依赖耗尽资源；对一些依赖服务进行隔离，防止当依赖服务不可用或者响应非常缓慢导致整个应用不可用，阻止故障的连锁反应。过载立即切断并快速失败防止排队。 Hystrix有4种参数配置，优先级由低到高分别为：内置全局默认值、动态全局默认属性、内置实例默认值、动态配置实例属性。 基于编程式基于编程式使用Hystrix，只需继承HystrixCommand或HystrixObservableCommand，区别在于HystrixCommand命令逻辑卸载run()方法中，且由新创建线程执行，一个实例只能向调用程序发送单条数据。HystrixObservableCommand命令逻辑写在construct()方法中，由调用程序线程执行，一个实例可以顺序发送多条数据。 HystrixCommand命令有execute()、queue()、observe()、toObservable()4个方法来触发执行run()方法。HystrixObservableCommand命令只有observe()、toObservable()2个方法来触发执行construct()方法。 execute() 以同步堵塞方式执行 queue() 以异步非堵塞方式执行，通过Future.get()获取run()返回结果 observe() 事件注册前执行run()或construct()方法 toObservable() 事件注册后执行run()或construct()方法 继承HystrixCommand实现自己的Command，在构造方法中配置需要的参数，后续章节对具体配置进行详细描述。 123456789101112131415161718192021222324252627282930313233public class HelloWorldCommand extends HystrixCommand&lt;JSONObject&gt; &#123; private DataRequest request; protected HelloWorldCommand(DataRequest request) &#123; HystrixCommandProperties.Setter propertiesSetter = HystrixCommandProperties.Setter() .withCircuitBreakerEnabled(true) .withRequestCacheEnabled(false) .withRequestLogEnabled(false) .withExecutionIsolationStrategy() .withExecutionIsolationSemaphoreMaxConcurrentRequests(80) .withFallbackIsolationSemaphoreMaxConcurrentRequests(80) .withCircuitBreakerRequestVolumeThreshold(30) .withCircuitBreakerSleepWindowInMilliseconds(5000) .withExecutionTimeoutInMilliseconds(timeOut); HystrixCommandGroupKey groupKey = HystrixCommandGroupKey.Factory.asKey(\"requestData\"); HystrixCommand.Setter setter = HystrixCommand.Setter.withGroupKey(groupKey) .andCommandKey(HystrixCommandKey.Factory.asKey(\"data-\"+ Id)) .andCommandPropertiesDefaults(propertiesSetter) .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(\"requestData\")); super(setter); this.request = request; &#125; @Override protected JSONObject run() &#123; return request.executeRequest(); &#125; @Override protected JSONObject getFallback() &#123;&#125;&#125; 调用HystrixCommand的执行方法发起实际请求，execute()方法同步调用： 12HelloWorldCommand command = new HelloWorldCommand(request);JSONObject result = command.execute(); queue()方法异步调用： 123HelloWorldCommand command = new HelloWorldCommand(request);Future&lt;JSONObject&gt; future = command.queue();JSONObject result = future.get(10000, TimeUnit.MILLISECONDS); observe()方法，注册观察者事件订阅，事件注册前执行： 12Observable&lt;JSONObject&gt; observable = new HelloWorldCommand(request).observe();observable.subscribe(result1 -&gt; System.out.println(\"Observable call--&gt; \" + result1)); observe()方法，注册完整执行生命周期事件，事件注册前执行： 1234567891011121314Observable&lt;JSONObject&gt; observable = new HelloWorldCommand(request).observe();observable.subscribe(new Observer&lt;JSONObject&gt;() &#123; //onNext/onError完成之后最后回调 @Override public void onCompleted() &#123;&#125; // 当产生异常时回调 @Override public void onError(Throwable throwable) &#123;&#125; // 获取结果后回调 @Override public void onNext(JSONObject s) &#123;&#125;&#125;); toObservable()方法，注册观察者事件订阅，事件注册后执行： 1234567891011121314Observable&lt;JSONObject&gt; toObservable = new HelloWorldCommand(request).toObservable();toObservable.subscribe(new Observer&lt;JSONObject&gt;() &#123; //onNext/onError完成之后最后回调 @Override public void onCompleted() &#123;&#125; // 当产生异常时回调 @Override public void onError(Throwable throwable) &#123;&#125; // 获取结果后回调 @Override public void onNext(JSONObject s) &#123;&#125;&#125;); 基于注解式注解使用方式和编程式大致相同，只是属性参数配置都注解化了。三个核心注解分别为@HystrixCommand、@HystrixProperty和@HystrixCollapser。 注解同步执行： 123456789101112131415public class HelloWorldHystrixAnnotation &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = \"helloWorldHystrixAnnotation\", commandKey = \"helloWorldHystrixAnnotationSync\", fallbackMethod = \"fallback\") public JSONObject executeRequest(String param) &#123; return dataClient.retrieveData(param); &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 注解异步执行： 1234567891011121314151617181920public class HelloWorldHystrixAnnotationAsync &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = \"helloWorldHystrixAnnotation\", commandKey = \"helloWorldHystrixAnnotationAsync\", fallbackMethod = \"fallback\") public Future&lt;JSONObject&gt; run(String param) &#123; return new AsyncResult&lt;JSONObject&gt;() &#123; @Override public JSONObject invoke() &#123; return dataClient.retrieveData(param); &#125; &#125;; &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 注解订阅执行： 123456789101112131415161718192021222324public class HelloWorldHystrixAnnotationObervable &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = \"helloWorldHystrixAnnotation\", commandKey = \"helloWorldHystrixAnnotationObervable\", fallbackMethod = \"fallback\") public Observable&lt;JSONObject&gt; run(String param) &#123; return Observable.create(subscriber -&gt; &#123; try &#123; if (!subscriber.isUnsubscribed()) &#123; subscriber.onNext(dataClient.retrieveData(param)); subscriber.onCompleted(); &#125; &#125; catch (Exception e) &#123; subscriber.onError(e); &#125; &#125;); &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 触发fallback方法的情况 执行抛出异常 执行超时 断路器打开，不尝试执行 线程池拒绝，不尝试执行 信号量拒绝，不尝试执行 Hystrix监控界面参数 基础属性配置CommandGroup：每个命令最少配置的必选参数，不指定ThreadPoolKey的情况下，用于指定线程池的隔离。 实例配置：HystrixCommand.Setter().withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;groupKey&quot;)); 注解配置：@HystrixCommand(groupKey = &quot;groupKey&quot;） CommandKey：依赖命名，一般每个CommandKey代表一个依赖抽象，相同依赖使用相同CommandKey名称，依赖隔离的根本就是对相同CommandKey的依赖做隔离，不同的依赖隔离最好使用不同的线程池。 实例配置：HystrixCommand.Setter().andCommandKey(HystrixCommandKey.Factory.asKey(&quot;commandKey&quot;)); 注解配置：@HystrixCommand(commandKey = &quot;commandKey&quot;) ThreadPoolKey：依赖隔离使用的线程池的键值，对同一业务依赖隔离用CommandGroup做区分，对同一依赖的不同远程调用，使用ThreadPoolKey做隔离区分，业务相同的组，需要在资源上做隔离时，使用ThreadPoolKey区分。不同的ThreadPoolKey建议使用不同的CommandKey。 实例配置：HystrixCommand.Setter().andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;threadPoolKey&quot;)) 注解配置：@HystrixCommand(threadPoolKey = &quot;threadPoolKey&quot;) 命令属性配置execution.isolation.strategy：用于设置HystrixCommand执行的隔离策略，支持THREAD线程池隔离单独线程执行并发数受限于线程池大小和SEMAPHORE信号量隔离在调用线程中执行通过信号量来限制并发数。 实例配置：HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.THREAD) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.strategy&quot;,value = &quot;SEMAPHORE&quot;)}) 默认值：THREAD execution.timeout.enabled：是否启用超时限制。 实例配置：HystrixCommandProperties.Setter().withExecutionTimeoutEnabled(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.timeout.enabled&quot;, value = &quot;true&quot;)}) 默认值：true execution.isolation.thread.timeoutInMilliseconds：执行超时时间，超时会作用在HystrixCommand.queue()，即使没有调用get()获得Future对象。 实例配置：HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(2000) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;2000&quot;)}) 默认值：1000ms execution.isolation.thread.interruptOnTimeout：使用线程隔离时，对执行超时的线程是否被中断。 实例配置：HystrixCommandProperties.Setter().withExecutionIsolationThreadInterruptOnTimeout(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.thread.interruptOnTimeout&quot;, value = &quot;true&quot;)}) 默认值：true（THREAD模式有效） execution.isolation.semaphore.maxConcurrentRequests：使用信号量策略时，允许的最大并发请求数。 实例配置：HystrixCommandProperties.Setter().withExecutionIsolationSemaphoreMaxConcurrentRequests(50) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.semaphore.maxConcurrentRequests&quot;, value = &quot;50&quot;)}) 默认值：10（SEMAPHORE模式有效） Fallbackfallback.enabled：当接口异常或者拒绝时，是否调用Fallback方法处理，线程池和信号量策略都支持。 实例配置：HystrixCommandProperties.Setter().withFallbackEnabled(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;fallback.enabled&quot;, value = &quot;true&quot;)}) 默认值：true fallback.isolation.semaphore.maxConcurrentRequests：Fallback方法最大并发数。超过该配置的请求将被拒绝，若没有实现回退，则抛出异常。线程池和信号量策略都支持。 实例配置：HystrixCommandProperties.Setter().withFallbackIsolationSemaphoreMaxConcurrentRequests(20) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;fallback.isolation.semaphore.maxConcurrentRequests&quot;, value = &quot;20&quot;)}) 默认值：10（SEMAPHORE模式有效） circuitBreaker.enabled：断路器是否生效。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerEnabled(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.enabled&quot;, value = &quot;true&quot;)}) 默认值：true 断路器circuitBreaker.requestVolumeThreshold：滚动窗口中，打开断路器的最少请求数。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerRequestVolumeThreshold(20) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;,value = &quot;20&quot;)}) 默认值：20 circuitBreaker.sleepWindowInMilliseconds：拒绝请求到再次不被拒绝的请求时间间隔。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerSleepWindowInMilliseconds(10) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.sleepWindowInMilliseconds&quot;, value = &quot;5000&quot;)}) 默认值：5000ms circuitBreaker.errorThresholdPercentage：断路器启动回退逻辑的错误比率。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerErrorThresholdPercentage(50) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.errorThresholdPercentage&quot;, value = &quot;50&quot;)}) 默认值：50 circuitBreaker.forceClosed：强制断路器进入关闭状态，将允许所有的请求，无视错误率。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerForceClosed(false) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.forceClosed&quot;, value = &quot;false&quot;)}) 默认值：false circuitBreaker.forceOpen：强制断路器进入打开状态，将会拒绝所有的请求。优先级比circuitBreaker.forceClosed高。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerForceOpen(false) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.forceOpen&quot;, value = &quot;false&quot;)}) 默认值：false 线程池hystrix.threadpool.default.coreSize：设置核心线程池大小，与ThreadPoolExecutor的coreSize的含义不一样 实例配置：HystrixThreadPoolProperties.Setter().withCoreSize(10) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;coreSize&quot;, value = &quot;10&quot;)}) 默认值：10 hystrix.threadpool.default.maximumSize：设置线程池最大值，不开始拒绝HystrixCommand的情况下支持的最大并发数，设置allowMaximumSizeToDrivergeFromCoreSize后生效。 实例配置：HystrixThreadPoolProperties.Setter().withMaximumSize(10) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;maximumSize&quot;, value = &quot;10&quot;)}) 默认值：10 hystrix.threadpool.default.maxQueueSize：最大的队列值，若设置为-1使用SynchronousQueue，否则使用LinkedBlockingQueue。 实例配置：HystrixThreadPoolProperties.Setter().withMaxQueueSize(10) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;maxQueueSize&quot;, value = &quot;10&quot;)}) 默认值：-1 hystrix.threadpool.default.queueSizeRejectionThreshold：设置队列拒绝的阈值，maxQueueSize值为-1时，该属性不生效。 实例配置：HystrixThreadPoolProperties.Setter().withQueueSizeRejectionThreshold(5) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;queueSizeRejectionThreshold&quot;, value = &quot;5&quot;)}) 默认值：5 hystrix.threadpool.default.keepAliveTimeMinutes：设置存活时间，单位分钟，如果coreSize小于maximumSize，则该属性控制一个线程从使用完成到被释放的时间。 实例配置：HystrixThreadPoolProperties.Setter().withKeepAliveTimeMinutes(1) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;keepAliveTimeMinutes&quot;, value = &quot;1&quot;)}) 默认值：1 hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize ：允许maximumSize起作用。 实例配置：HystrixThreadPoolProperties.Setter().withAllowMaximumSizeToDivergeFromCoreSize(false) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;allowMaximumSizeToDivergeFromCoreSize&quot;, value = &quot;false&quot;)}) 默认值：false","tags":[{"name":"Hystrix","slug":"Hystrix","permalink":"https://yaoyinglong.github.io/tags/Hystrix/"},{"name":"限流","slug":"限流","permalink":"https://yaoyinglong.github.io/tags/限流/"},{"name":"熔断","slug":"熔断","permalink":"https://yaoyinglong.github.io/tags/熔断/"},{"name":"降级","slug":"降级","permalink":"https://yaoyinglong.github.io/tags/降级/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"Java8时间及日期","date":"2019-05-21T16:00:00.000Z","path":"Blog/Java/基础/时间及日期总结/","text":"旧的日期类是可变且线程不安全的，Java8中引入了一套全新的日期API，java.time包中的类是不可变且线程安全。 LocalDatejava.time.LocalDate是用来表示日期的，不包含具体的时间，默认按照yyyy-MM-dd格式。 获取当前日期：LocalDate.now() 根据年月日构建日期：LocalDate.of(2018, 01, 30) 字符串转换日期：LocalDate.parse(&quot;2018-01-30&quot;)，也可以自定义格式，如：LocalDate.parse(&quot;2018年01月30日&quot;, DateTimeFormatter.ofPattern(&quot;uuuu年MM月dd日&quot;)) 本月第一天：localDate.with(TemporalAdjusters.firstDayOfMonth()) 本月第二天：localDate.withDayOfMonth(2) 本月最后一天：localDate.with(TemporalAdjusters.lastDayOfMonth()) 明天：localDate.plusDays(1L) 昨天：localDate.minusDays(1L) 获取本年第120天：localDate.withDayOfYear(120) 计算两个日期间的天数：localDate.until(localDate1, ChronoUnit.DAYS) 计算两个日期间的周数：localDate.until(localDate1, ChronoUnit.WEEKS) LocalTimeLocalTime与LocalDate相反，其仅表示时间，不包含日期。 获取当前时间（包含毫秒数）：LocalTime.now() 构建指定时间：LocalTime.of(12, 15, 30) 获取指定时间（不包含毫秒数）：localTime.withNano(0) 字符串转为时间 LocalTime.parse(&quot;12:15:30&quot;) LocalTime.parse(&quot;12:15:30.233&quot;) LocalTime.parse(&quot;12:15&quot;) LocalTime.parse(&quot;12时15分30秒&quot;, DateTimeFormatter.ofPattern(&quot;HH时mm分ss秒&quot;)) LocalDateTimeLocalDateTime和旧的java.util.Date类是，既包含日期，又包含时间，且经常与DateTimeFormatter一起使用。 获取当前年月日时分秒：LocalDateTime.now() 通过LocalDate和LocalTime构建：LocalDateTime.of(LocalDate.now(), LocalTime.now()) 时间差计算相差的天数： 123456789101112public static long getDaysBetween(LocalDate firstDate, LocalDate secondDate) &#123; if (firstDate == secondDate) &#123; return 0; &#125; if (firstDate == null) &#123; firstDate = LocalDate.now(); &#125; if (secondDate == null) &#123; secondDate = LocalDate.now(); &#125; return Math.abs(firstDate.toEpochDay() - secondDate.toEpochDay());&#125; 计算相差的小时数： 12345678910111213public static long getHoursBetween(LocalDateTime firstDate, LocalDateTime secondDate) &#123; if (firstDate == secondDate) &#123; return 0; &#125; if (firstDate == null) &#123; firstDate = LocalDateTime.now(); &#125; if (secondDate == null) &#123; secondDate = LocalDateTime.now(); &#125; Long diffHours = Math.abs(Duration.between(firstDate, secondDate).toHours()); return diffHours;&#125; Date与JAVA8时间类互转12345678910111213141516171819//Date与Instant的相互转化Instant instant = Instant.now();Date date = Date.from(instant);Instant instant2 = date.toInstant(); //Date转为LocalDateTimeDate date2 = new Date();LocalDateTime localDateTime2 = LocalDateTime.ofInstant(date2.toInstant(), ZoneId.systemDefault()); //LocalDateTime转DateLocalDateTime localDateTime3 = LocalDateTime.now();Instant instant3 = localDateTime3.atZone(ZoneId.systemDefault()).toInstant();Date date3 = Date.from(instant);//LocalDate转Date//因为LocalDate不包含时间，所以转Date时，会默认转为当天的起始时间，00:00:00LocalDate localDate4 = LocalDate.now();Instant instant4 = localDate4.atStartOfDay().atZone(ZoneId.systemDefault()).toInstant();Date date4 = Date.from(instant);","tags":[{"name":"Java8","slug":"Java8","permalink":"https://yaoyinglong.github.io/tags/Java8/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"方法调用","date":"2019-03-13T16:00:00.000Z","path":"Blog/Java/VM/方法调用/","text":"方法调用并不等同于方法执行，方法调用阶段唯一任务是确定被调用方法的版本，暂时不涉及方法内部具体运行过程。程序运行时，进行方法调用是最普遍最频繁的操作。 Class文件编译过程中不包含传统编译中的连接步骤，一切方法的调用在Class文件中存储的都只是符号引用，而非方法在实际运行内存布局中的入口地址（直接引用）。该特性带来了强大的动态扩展性，但同时使得方法调用过程变得相对复杂，需要在类加载期间、甚至运行期间才能确定目标方法的直接引用。 解析调用所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载的解析阶段，会将其中在编译期可知，运行期不可变的方法的符号引用转化为直接引用。 编译器可知，运行期不可变的方法主要包括：静态方法、私有方法、实例构造器、父类方法、final修饰的方法。这类方法被称为非虚方法，其他方法称为虚方法。 虚拟机提供5条方法调用字节码指令，前四条指令的分派逻辑是固化在Java虚拟机内部的，而invokedynamic的分派逻辑是由用户所设定的引导方法决定的： invokestatic：调用静态方法 invokespecial：调用实例构造器&lt;init&gt;方法、私有方法、父类方法 invokevirtual：调用所有的虚方法，以及final修饰的方法。 invokeinterface：调用接口方法，在运行时再确定一个实现此接口的对象 invokedynamic：在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法 只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段确定唯一的调用版本，包括了静态方法、私有方法、实例构造器、父类方法4类。 解析调用一定是一个静态过程，编译器就可以完全确定，在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用，不会延迟到运行期去完成。 分派调用分派调用可能是静态的也可能是动态的，根据宗量（方法的接收者和方法的参数统称为方法的宗量）分为单分派和多分派，两类分派方式两两组合就构成了：静态单分派、静态多分派、动态单分派、动态多分派。 分派的调用过程其实就是Java多态的实现原理，如重写和重载在Java虚拟机中是如何实现的。 静态分派说到静态分派，首先先说一下变量的静态类型或者叫外观类型，以及变量的实际类型。假设有抽象类Human和其实现类Man、Woman，若Human man = new Man();,则Human是man的静态类型，Man是其实际类型。 静态类型和实际类型在程序中都可能发生一些变化，静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，且最终的静态类型是在编译器可知的；实际类型的变化结果在运行期才可以确定，编译器在编译程序时并不知道对象的实际类型是什么。 123456// 实际类型的变化Human man = new Man();man = Woman();// 静态类型的变化sr.sayHello((Man) man);sr.sayHello((Woman) man); 虚拟机（编译器）在调用重载（Overload）时是通过参数的静态类型而不是实际类型作为判定依据，在编译阶段Javac编译器会根据参数的静态类型来确定具体调用哪个重载版本的方法。 所有依赖 静态类型来定位方法执行版本的分派动作称为静态分派，静态分派的典型应用是方法重载。 静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的，编译器虽然能确定方法的重载版本，但很多情况下这个重载版本并不唯一，往往只能确定一个更加合适的版本，主要原因是字面量不需要定义，所以字面量是没有显式的静态类型，其静态类型只能通过语言上的规则去理解和推断。 动态分派动态分派与多态的另一个重要体现重写（Override）有着密切的关联。 动态分派其实就是invokevirtual指令的多态查找的过程。由于该指令第一步就是在运行其确定接收者的实际类型，所以对于不同的调用，该指令会将常量池中的类方法符号引用解析到不同的直接引用上，该过程就是Java中方法重写的本质。 我们将这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。 解析和分派这两者之间的关系并不是二选一的排他关系，它们是在不同层次上去筛选、确定目标方法的过程。 单分派与多分派单分派是根据一个宗量对目标方法进行选择，多分派是根据多个宗量对目标方法进行选择。到目前为止可以说Java语言是一门静态多分派、动态单分派的语言。 虚拟机动态分派的实现由于动态分派是非常频繁的动作，而且动态分派的方法版本的选择过程需要运行时在类的方法元数据中搜索合适的目标方法，在虚拟机的实际实现中基于性能考虑会对其进行一些优化，最常用的稳定优化手段是为类在方法区中建立一个虚方法表或接口方法表，使用虚方法表索引来代替元数据查找提高性能。 虚方法表中存放着各个方法的实际入口地址。具有相同签名的方法，在之类和父类的虚方法表中都应当具有相同的索引序号，在类型变换时便于查找。 虚拟机除了使用方法表之外，在条件允许下，还会使用内联缓存和基于类型继承关系分析技术的守护内联两种非稳定的优化手段来获取更高的性能。 动态类型语言支持动态类型语言的关键特征是它的类型检查的主体过程是在运行期而不是编译期。变量无类型而变量值才有类型这也是动态语言的一个重要特征。 静态类型语言在编译期确定类型，可以提供严谨的类型检查，与类型相关的问题在编码时就能及时发现，利于稳定性及代码达到更大规模； 动态类型语言在运行期确定类型，为开发人员提供更大的灵活性，代码会更加清晰简单，也意味着高效的开发效率。 Reflection与MethodHandlerJDK7提供了java.lang.invoke包，其主要目的是用于提供一种新的动态确定目标方法的机制，称为MethodHandler。 1234567891011121314static class ClassA &#123; public void println(String string) &#123; System.out.println(string); &#125;&#125;public static void main(String[] args) throws Throwable &#123; Object obj = System.currentTimeMillis() % 2 == 0 ? System.out : new ClassA(); MethodType methodType = MethodType.methodType(void.class, String.class); MethodHandle methodHandle = MethodHandles.lookup().findVirtual(obj.getClass(), \"println\", methodType).bindTo(obj); methodHandle.invokeExact(\"param\");&#125; MethodHandler的使用方法与Reflection有众多相似之处，以及以下区别： 本质上MethodHandler和Reflection都是在模拟方法调用，Reflection是在模拟Java层次的方法调用，MethodHandler是在模拟字节码层次的方法调用。 Reflection中的Method对象远比MethodHandler中的MethodHandler对象所包含的信息多。Method包含了方法签名、描述符、方法属性表中各种属性、以及执行权限等运行期信息。而MethodHandler仅包含与执行该方法相关的信息。 MethodHandler理论上可以采用类似虚拟机在字节码上做的各种优化思路。而Reflection不行。 Reflection仅支持Java语言，MethodHandler支持所有语言。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"运行时栈帧结构","date":"2019-03-10T16:00:00.000Z","path":"Blog/Java/VM/运行时栈帧结构/","text":"栈帧是用于支持虚拟机进行方法调用和方法执行的数据结构，是虚拟机运行时数据区中的虚拟机栈的栈元素。每个方法从调用开始至执行完成的过程，都对应一个栈帧在虚拟机栈中从入栈到出栈的过程。 栈帧存储了方法的局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。在编译程序代码时，栈帧中需要多大的局部变量表、多深的操作数栈都已完全确定，并写入到方法表的Code属性中了。因此栈帧需要分配多少内存，不受运行期变量数据影响，仅取决于具体的虚拟机实现。 对于执行引擎来说，在活动线程中，只有当前栈帧（位于栈顶的栈帧）才有效，与该栈帧关联的方法称为当前方法。执行引擎运行的所有字节码指令都是针对当前栈帧进行操作。 局部变量表局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。在程序被编译成Class文件时，就在方法区的Code属性的max_locals数据项中确定了该方法所需要分配的局部变量表的最大容量。 局部变量表容量以变量槽Slot为最小单位，一个Slot可存放一个32位以内的数据类型，Java中占用32位以内的数据类型有boolean、byte、char、short、int、float、reference、returnAddress 8种类型，64位的数据类型只有long和double两种。 reference类型表示对一个对象实例的引用，一是从此引用中直接或间接地查找到对象在Java堆中的数据存放的起始地址索引，二是此引用中直接或间接地查找到对象所属数据类型在方法区中存储的类型信息。 局部变量表建立在线程的堆栈上，是线程私有的数据，无论读写的Slot是否为原子操作，都不会引起数据安全问题。 方法在执行时，虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程，若执行的是实例方法，局部变量表中第0位索引默认是用于传递方法所属对象实例的引用，可通过this关键字来访问该隐含参数。 类变量有两次赋初始值的过程，在准备阶段赋系统初始值，在初始化阶段赋定义初始值。但局部变量没有赋初始值就不能使用。 操作数栈Java虚拟机解释执行引擎称为基于栈的执行引擎，其中的栈就是操作数栈，操作数栈也称为操作栈，是一个后入先出栈，最大深度在编译时写入Code属性的max_stacks数据项中。操作数栈的每个元素可以是任意Java数据类型，包括long和double，32位数据类型占1个栈容量，64位数据类型占2个栈容量。操作数栈中元素的数据类型必须与字节码指令序列严格匹配。 方法开始执行时，该方法的操作数栈为空，方法在执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是入栈和出栈操作。在算数运算时通过字节码指令将最接近栈顶的两个元素出栈并进行计算，然后将计算结果入栈，在调用其他方法时通过操作数栈来进行参数传递。 概念模型中两个栈帧作为虚拟机的元素是完全独立的，但大多数虚拟机都进行了一些优化，令两个栈帧出现部分重叠，在进行方法调用时可共享一部分数据。 动态连接每个栈帧都包含了一个指向运行时常量池中该栈帧所属方法的引用，持有该引用是为了支持方法调用过程中的动态连接。Class文件常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用作为参数， 这些符号引用的一部分会在类加载阶段或者第一次使用时转化为直接引用，这种转化称为静态解析。另一部分将在每一次运行期间转化为直接引用，这部分称为动态连接。 方法返回地址当方法开始执行后，只有两种方式可以推出该方法，方式一执行引擎遇到任意一个方法返回的字节码指令，可能有返回值传递给上层方法调用者，是否有返回值和返回值类型将根据遇到何种方法返回指令来决定。方式二方法在执行过程中遇到异常，且该异常在方法体中没得到处理。 无论哪种方式退出，都需要返回到方法被调用的位置，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。方法正常退出时，调用者的PC计数器的值可作为返回地址，栈帧中很可能会保存该PC计数器值；方法异常退出时，返回地址要通过异常处理器来确定，栈帧中一般不会保存这部分信息。 方法退出过程实际上等同于当前栈帧出栈，退出可能执行的操作有，恢复上层方法的局部变量表和操作数栈，若有返回值把返回值压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。 附加信息虚拟机规范允许具体的虚拟机实现增加一些规范种没有描述的信息到栈帧中，例如调试相关的信息。实际开发中一般会把动态连接、方法的返回地址、与其他附加信息全部归类为一类，称为栈帧信息。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"},{"name":"栈帧","slug":"栈帧","permalink":"https://yaoyinglong.github.io/tags/栈帧/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Maven插件编写","date":"2019-03-02T16:00:00.000Z","path":"Blog/Maven/Maven插件编写/","text":"一般步骤 创建maven-plugin项目，打包方式必须为maven-plugin，可使用maven-archetype-plugin快速创建 编写插件目标，每个插件必须包含一个或多个目标，必须提供一个或多个继承自AbstractMojo的类 为目标提供配置点，编写Mojo时提供可配置的参数。 编写代码实现目标行为，根据实际需要实现Mojo 错误处理及日志，当Mojo异常时，根据情况控制Maven的运行状态 测试插件，编写自动化测试代码测试行为，再实际运行插件验证其行为 案例每个插件目标即Mojo都必须继承AbstractMojo并实现execute()方法，这样Maven才能识别该插件，并执行execute()方法中的行为。当在execute()方法捕获的其他异常时，使用MojoExecutionException对其简单包装后再抛出，Maven执行插件目标时遇到MojoExecutionException会在命令行显示BUILD ERROR. 标注实现方式maven-plugin-api该依赖中包含了插件开发所必需的类。 12345678910111213&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-maven-plugin&lt;/artifactId&gt;&lt;packaging&gt;maven-plugin&lt;/packaging&gt;&lt;name&gt;Maven Mojo&lt;/name&gt;&lt;url&gt;http://maven.apache.org&lt;/url&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 默认使用的是Java1.4风格的标注 12345678910111213141516171819/** * @goal touch * @phase process-sources */public class MyMojo extends AbstractMojo &#123; /** * @parameter expression=\"$&#123;project.build.directory&#125;\" * @required */ private File outputDirectory; /** * @parameter */ private String[] includes; public void execute() throws MojoExecutionException &#123; &#125;&#125; 注解实现方式1234567891011121314151617181920&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-maven-plugin&lt;/artifactId&gt;&lt;packaging&gt;maven-plugin&lt;/packaging&gt;&lt;name&gt;Maven Mojo&lt;/name&gt;&lt;url&gt;http://maven.apache.org&lt;/url&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-core&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugin-tools&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-annotations&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 使用注解的方式，具体实现代码示例 12345678910111213@Mojo(name = \"touch\", defaultPhase = LifecyclePhase.PROCESS_SOURCES)@Execute(goal = \"\", phase = \"\", lifecycle = \"\")public class MyMojo extends AbstractMojo &#123; @Parameter(defaultValue = \"$&#123;project.build.directory&#125;\", required = true) private File outputDirectory; @parameter private String[] includes; public void execute() throws MojoExecutionException &#123; &#125;&#125; 使用插件12345678910&lt;plugin&gt; &lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt; &lt;artifactId&gt;account-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;&lt;/include&gt; &lt;include&gt;&lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt;&lt;/plugin&gt; Mojo标注 @goal &lt;name&gt; 每个Mojo都必须使用该标注注明目标名称，对应注解方式@Mojo(name = &quot;&quot;） @phase &lt;phase&gt; 将目标绑定至Default生命周期的某个阶段 @requiresDependencyResolution &lt;scope&gt; 运行该Mojo前必须解析所有指定范围的依赖，默认为runtime @requiresProject &lt;true/false&gt; 该目标是否必须在Maven项目中运行 @requiresDirectInvocation &lt;true/false&gt; 是否只能通过命令行调用 @requiresOnline &lt;true/false&gt; 是否要求Maven必须是在线状态，默认false @requiresReports &lt;true/false&gt; 是否要求项目报告已经生成，默认false @aggregator 在多模块项目中，表示只会在顶层模块中运行 @execute goal = &quot;&lt;goal&gt;&quot; 运行该目标前先运行另一个目标，本插件目标直接使用目标名，否则使用prefix:goal @execute phase= &quot;&lt;phase&gt;&quot; 运行该目标前线运行一个并行的生命周期到指定阶段 @execute lifecycle= &quot;&lt;lifecycle&gt;&quot; 运行该目标前线运行一个自定义生命周期到指定阶段 Mojo参数可以使用@parameter将Mojo的某个字段标注为可配置的参数即Mojo参数。Maven支持Boolean、Integer、Float、String、Date、File、URL、多值数组、Collection、Map、Properties等多种Mojo参数。 Boolean1234@parameter private boolean sampleBoolean;// 对应配置&lt;sampleBoolean&gt;true&lt;/sampleBoolean&gt; Integer1234@parameter private int sampleInt;// 对应配置&lt;sampleInt&gt;6&lt;/sampleInt&gt; Float1234@parameter private int sampleFloat;// 对应配置&lt;sampleFloat&gt;6.5&lt;/sampleFloat&gt; String1234@parameter private int sampleString;// 对应配置&lt;sampleString&gt;HW&lt;/sampleString&gt; Date12345@parameter private int sampleDate;// 对应配置,格式为yyyy-MM-dd HH:mm:ss.Sa或yyyy-MM-dd HH:mm:ssa&lt;sampleDate&gt;2019-03-03 11:28:55.1 PM&lt;/sampleDate&gt; &lt;sampleDate&gt;2019-03-03 11:28:55PM&lt;/sampleDate&gt; File1234@parameter private int sampleFile;// 对应配置&lt;sampleFile&gt;c:\\tmp&lt;/sampleFile&gt; URL1234@parameter private int sampleURL;// 对应配置&lt;sampleURL&gt;https://yaoyinglong.github.io&lt;/sampleURL&gt; 数组1234567@parameter private String[] includes;// 对应配置&lt;includes&gt; &lt;include&gt;&lt;/include&gt; &lt;include&gt;&lt;/include&gt;&lt;/includes&gt; Collection1234567@parameter private List includes;// 对应配置&lt;includes&gt; &lt;include&gt;&lt;/include&gt; &lt;include&gt;&lt;/include&gt;&lt;/includes&gt; Map1234567@parameter private Map sampleMap;// 对应配置&lt;sampleMap&gt; &lt;key1&gt;&lt;/key1&gt; &lt;key2&gt;&lt;/key2&gt;&lt;/sampleMap&gt; Properties12345678910111213@parameter private Properties sampleProperties;// 对应配置&lt;sampleProperties&gt; &lt;properties&gt; &lt;name&gt;&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;/properties&gt; &lt;properties&gt; &lt;name&gt;&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;/properties&gt;&lt;/sampleProperties&gt; 除此之外@parameter还提供一些额外的属性 @parameter alias = &quot;&quot;给参数配置别名 @parameter expression= &quot;${aSystemProperty}&quot;使用系统属性表达式给参数赋值 @parameter default-value= &quot;aValue/${anExpression}&quot;若未配置才参数，就提供一个默认值 @readonly 参数只读 @required 必须参数","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven属性","date":"2019-02-24T16:00:00.000Z","path":"Blog/Maven/Maven属性/","text":"Maven为了支持构建的灵活性，内置了属性、Profile、资源过滤三大特性。 Maven属性Maven共有6类属性，分别为内置属性、POM属性、自定义属性、Settings属性、Java系统属性、环境变量属性。正确使用这些属性可以帮助简化POM配置和维护工作。 内置属性主要有两个常用内置属性： ${basedir}：包含pom.xml文件的目录。即项目的根目录。 ${version}：项目的版本号 POM属性用户可以使用POM属性引用POM文件中对应的元素值。常用POM属性： ${project.build.sourceDirectory}：项目主源码目录，默认为src/main/java/ ${project.build.testScoreDirectory}：项目测试源码目录，默认为src/test/java/ ${project.build.directory}：项目构建输出目录，默认target/ ${project.outputDirectory}：项目代码编译输出目录，默认/target/classes/ ${project.testOutputDirectory}：项目测试代码编译输出目录，默认/target/test-classes/ ${project.groupId}：项目groupId ${project.artifactId}：项目artifactId ${project.version}：项目version，与${version}等价 ${project.build.finalName}：项目打包输出文件名称，默认为${project.artifactId}-${project.version} 自定义属性在POM文件中的properties元素下定义的Maven属性。 Setting属性与POM属性同理，使用setting.开头的属性引用setting.xml文件中XML元素的值。例如${setting.localRepository}引用本地仓库地址 Java系统属性所有Java系统属性都可以使用Maven属性引用。例如${user.home}引用用户目录。 可以使用mvn help:system命令查看所有的Java系统属性 环境变量属性所有环节变量都可以使用以env.开头的Maven属性引用。例如${env.JAVA_HOME}引用JAVA_HOMR环境变量的值。 可以使用mvn help:system命令查看所有的环境变量 Profile为了应对环境的变化，Maven属性可以将变化的部分提取出来。针对不同环境设置不同的属性或插件。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;release.file&gt;test&lt;/release.file&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;excludes&gt; &lt;exclude&gt;com.long.model.IT.**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;properties&gt; &lt;release.file&gt;product&lt;/release.file&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt;&lt;/profiles&gt; Maven3支持pom.xml、用户setting.xml、全局setting.xml三种Profile。pom.xml中声明的Profile只对当前项目有效，用户setting.xml对本机上该用户的所有项目有效，全局setting.xml对本机上所有项目有效。 Maven支持多种方式激活Profile，可以通过mvn clean install -Pdev, test激活dev和test两个Profile；可以在setting文件或者POM中通过如下配置显示激活。 123&lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;&lt;/activation&gt; 通过系统属性激活，当系统属性test存在且值等于x时激活，value可以没有，用户也可以通过命令行设置系统属性mvn clean install -Dtest=x从而激活配置。 12345678910&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;test&lt;/name&gt; &lt;value&gt;x&lt;/value&gt; &lt;/property&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 操作系统环境激活，name、arch、version可以通过查看环境中的系统属性获取。 123456789101112&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;os&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 文件存在与否激活，如下所示当x文件不存在y文件存在时激活。 12345678910&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;file&gt; &lt;missing&gt;x.properties&lt;/missing&gt; &lt;exists&gt;x.properties&lt;/exists&gt; &lt;/file&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 若项目中有很多profile，其激活方式各异，用户可以通过mvn help:active-profiles命令查看当前激活的profile，也可以通过mvn help:all-profiles列出当前所有的profile。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"IT测试总结","date":"2019-02-23T16:00:00.000Z","path":"Blog/Test/IT测试总结/","text":"IT测试主要测试模块之间的接口和接口数据传递关系，以及模块组合后的整体功能。 在做集成测试时，若涉及到数据库的数据变更的，最好在测试过后将数据还原，可以先构建一条新的数据测试完成后删除，防止印象到数据库中原有的数据。 Controller层测试对于SpringBoot项目，Controller层的IT测试可以通过在类上加@AutoConfigureMockMvc注解并直接注入MockMvc的方式进行测试。 若对于一些特殊的测试，需要使用不同的配置的可使用@TestPropertySource(locations=&quot;classpath:test.application.properties&quot;)注解指定特定的配置文件。 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class DashboardControllerTest &#123; @Autowired private MockMvc mockMvc; @Test public void get_method_test() throws Exception &#123; this.mockMvc.perform(get(\"/test//v1\") .param(\"param1\", \"value1\") .param(\"param2\", \"value2\") .header(\"uid\", \"123456\")) .andExpect(status().isOk()) .andExpect(content().string(containsString(\"&#123;\\\"response_code\\\":\\\"00\\\"\"))); &#125;&#125; 对于MockMvc的使用还可以通过如下方式，这样可以不用在类上添加@AutoConfigureMockMvc注解： 12345678910@Autowiredprivate WebApplicationContext context;private MockMvc mvc;@Beforepublic void setUp() throws Exception &#123; mvc = MockMvcBuilders.webAppContextSetup(context) .addFilter(new BaseParamCheckFilter()).build();&#125; mockMvc.perform需要传入的是一个RequestBuilder，可以将其封装好了再传入，需要放入RequestBody中的参数可以通过content进行参数构造： 12345678910HttpHeaders httpHeaders = new HttpHeaders();httpHeaders.add(\"uuid\", \"68A\");httpHeaders.add(\"Content-Type\", \"application/json\");RequestBuilder request = post(\"/test/v1\") .headers(httpHeaders) .content(\"&#123;\\\"uuid\\\": \\\"68A\\\",\\\"param1\\\":\\\"aa\\\"&#125;\") .accept(MediaType.APPLICATION_JSON);mockMvc.perform(request).andExpect(status().isOk()).andDo(print()).andExpect( content().string(containsString(\"&#123;\\\"response_code\\\":\\\"02\\\",\\\"message\\\":\\\"请求参数缺失\\\"\"))); 对于返回结果的严重可以使用上面的示例通过MockMvcResultMatchers结合Matchers中的方法进行验证，也可以通过以下方式获取到具体结果后进行验证。 123String responseString = mvc.perform(request) .andExpect(status().isOk()) .andReturn().getResponse().getContentAsString(); perform：执行一个RequestBuilder请求，会自动执行SpringMVC的流程并映射到相应的控制器执行处理； andExpect：添加ResultMatcher验证规则，验证控制器执行完成后结果是否正确； andDo：添加ResultHandler结果处理器，比如调试时打印结果到控制台； andReturn：最后返回相应的MvcResult；然后进行自定义验证/进行下一步的异步处理； 测试文件上传对于文件大小限制的测试可以直接构建一个指定大小的byte数组。 1234567MockMultipartFile xmlFile = new MockMultipartFile(\"xmlFile\", \"emptyModel.xml\", \"text/plain\", new byte[1024 * 1024 * 200 + 1]);this.mockMvc.perform(MockMvcRequestBuilders.fileUpload(\"/test/config/add\") .file(xmlFile).param(\"mid\", mid).param(\"status\", \"1\")) .andExpect(status().isOk()) .andExpect(content().string(containsString(\"&#123;\\\"message\\\":\\\"上传文件异常\\\"\"))); 如果对于真实的文件上传测试可以读取真实的文件传输： 12345678910111213141516171819URL url = this.getClass().getClassLoader().getResource(\"test/errorFileType.txt\");File file = new File(url.getPath());MockMultipartFile xmlFile = new MockMultipartFile(\"xmlFile\", \"errorFileType.txt\", \"text/plain\", getByte(file));private byte[] getByte(File file) throws IOException &#123; FileInputStream fis = new FileInputStream(file); ByteArrayOutputStream bos = new ByteArrayOutputStream(); byte[] b = new byte[1000]; int n; while ((n = fis.read(b)) != -1) &#123; bos.write(b, 0, n); &#125; fis.close(); bos.close(); return bos.toByteArray(); &#125;&#125; 使用TestRestTemplate 对象测试12345678910@Autowiredprivate TestRestTemplate template;@Testpublic void testController()&#123; // template.getForObject() 会得到 controller 返回的 json 值 String content = template.getForObject(\"/show/100\", String.class); // 使用断言测试，使用正确的断言 Assert.assertEquals(\"show100\", content);&#125; 非Controller层测试对于非Controller测试一般更简单一些，只需要注入相关的类构造入参进行具体的方法调用测试，输出结果进行严重即可。 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = NONE)public class ITConfigServiceTest &#123; @Autowired private TestBusiConfigMapper testBuisConfigMapper; @Autowired private otherConfigService otherConfigService; @Test public void getConfigTest() &#123; List&lt;Config&gt; configList = testBuisConfigMapper.getAllConfigs(); assertNotNull(configList); assertEquals(true, configList.size() &gt; 0); for (Config config : configList) &#123; Config config = otherConfigService.getConfig(config.getId()); assertNotNull(config); &#125; &#125;&#125;","tags":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"UT测试总结","date":"2019-02-23T16:00:00.000Z","path":"Blog/Test/UT测试总结/","text":"UT测试主要测试单元内部的数据结构、逻辑控制、异常处理等。单元测试实现容易、运行速度快、能完全控制被测试的单元不包含外部依赖、测试用例相互独立无依赖关系。能够帮助发现代码缺陷、修改或者重构代码时确保没有影响现有功能。 对于一些对Bean没有依赖的类的测试（例如一些工具类），仅使用JUnit即可完成单元测试。 对于一些依赖Bean的类进行测试，若其复杂度低，在上层一两个IT测试即可覆盖掉，可以使用IT测试；若其复杂度比较高，可以使用JUnit加Mockito来完成单元测试，通过使用Mock技术测试可以无视代码依赖关系去测试代码的有效性，mock技术的目的和作用就是模拟一些在应用中不容易构造或者比较复杂的对象，从而把测试与测试边界以外的对象隔离开，对于依赖的Bean进行Mock处理，模拟构造各种Bean的输出来以及待测试方法的输入来覆盖当前方法的所有分支。 Mockito基础必须使用@RunWith(MockitoJUnitRunner.class)注解，否则Mock的依赖Bean将为空。@Mock将创建一个Mock，@InjectMocks创建一个实例且自动实例化，mockito会自动注入mock或spy成员。UserBaseServiceImpl中通过@Autowired注解或者构造方法等方式注入了IUserBaseDao，就可以通过如下方式使用。 12345678@RunWith(MockitoJUnitRunner.class)public class UserBaseServiceTest &#123; @Mock private IUserBaseDao userBaseDao; @InjectMocks private UserBaseServiceImpl userBaseService;&#125; @Mock与@Spy的区别使用@Mock生成的类，所有方法都不是真实的方法，而且返回值都是NULL。通常在设置测试桩时通过如下方式设置，对于多次调用返回不同值，可以通过多次设置thenReturn： 123456LinkedList mockedList = mock(LinkedList.class);mockedList.add(11);assertEquals(null, mockedList.get(0));when(mockedList.get(0)).thenReturn(\"first\").thenReturn(\"second\");assertEquals(\"first\", mockedList.get(0)); 使用@Spy生成的类，所有方法都是真实方法，返回值都是和真实方法一样的。测试桩设置与@Mock方式有所区别： 123456LinkedList mockedList = spy(LinkedList.class);mockedList.add(11);assertEquals(11, mockedList.get(0));doReturn(\"foo\").when(spy).get(0);assertEquals(\"foo\", mockedList.get(0)); Redis测试有时在进行Mock测试时会遇到redisTemplate，通常在应用中会使用redisTemplate.boundValueOps或者redisTemplate.boundHashOps生成一个BoundValueOperations或者BoundHashOperations对象，再来继续调用具体的处理方法。在设置测试桩时，需要进行两次设置。 12when(redisTemplate.boundValueOps(redisKey)).thenReturn(mock(BoundValueOperations.class));when(redisTemplate.boundValueOps(redisKey).increment(anyLong())).thenReturn(10L); 参数捕捉有时会出现一大串复杂的逻辑处理后生成一个或几个参数，用于调用其他的依赖Bean，这时可以通过参数捕捉来验证逻辑中各种情况下生产的参数是否满足预期。若简单参数也可以通过verify直接验证。 123456789BoundHashOperations boundHashOperations = mock(BoundHashOperations.class);when(redisTemplate.boundHashOps(anyString())).thenReturn(boundHashOperations);ArgumentCaptor&lt;Map&gt; argument = ArgumentCaptor.forClass(Map.class); verify(boundHashOperations, times(2)).putAll(argument.capture());Map&lt;String, CaseFlow&gt; map = new HashMap&lt;&gt;();assertEquals(map, argument.getValue()); 方法调用次数验证当验证的方法中存在循环、或者复杂度比较高等，导致方法在不同条件下可能存在多次调用的情况，最好验证一下方法的调用次数。或者是用于验证某个逻辑没有被执行或方法没有别调用。 12345verify(mock, times(1)).someMethod();// 至少调用2次verify(mock, atLeast(2)).someMethod();// 至多调用5次verify(mock, atMost(5)).someMethod(); 异常处理在进行一些会抛出异常的测试时，可以通过捕获异常在进行后续校验，可以使用@Test(expected = Exception.class)，若有多个地方抛出相同异常但异常信息不同时，该测试方法就不适用了，可以通过如下方式进行异常捕获后进行相关的验证。 1234567891011doThrow(new RuntimeException()).when(mockedList).clear();when(redisTemplate.boundValueOps(any())).thenThrow(new RuntimeException());Exception error = null;try &#123; baselineModelHandler.output(segment, modelData);&#125; catch (Exception e) &#123; error = e;&#125;assertNotNull(error);assertEquals(\"\", error.getMessage()); 验证调用顺序123456789101112List firstMock = mock(List.class);List secondMock = mock(List.class);firstMock.add(\"was called first\");secondMock.add(\"was called second\");//创建多个mock对象的inOrderInOrder inOrder = inOrder(firstMock, secondMock);//验证firstMock先于secondMock调用inOrder.verify(firstMock).add(\"was called first\");inOrder.verify(secondMock).add(\"was called second\"); 实现ApplicationContextAware接口的类测试1234Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();map.put(\"outputServiceImpl\", new OutputServiceImpl(requestService, updateCache, mock(ICache.class)));when(applicationContext.getBeansWithAnnotation(InvokeListener.class)).thenReturn(map);dataInvokeService.setApplicationContext(applicationContext);","tags":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"SonarQube配置总结","date":"2019-02-19T16:00:00.000Z","path":"Blog/杂记/工具/SonarQube配置总结/","text":"SonarQube的安装很简单，这里不做赘述。主要总结一下SonarQube的一些实际应用。 SonarQube Jenkins配置安装并配置好SonarQube后，在Jenkins插件管理中添加SonarQube Scanner for Jenkins插件，然后在Jenkins系统设置中设置SonarQube servers信息。 最后在具体的项目配置中的Post Steps中添加Execute SonarQube Scanner： 这样配置后在Jenkins上构建项目时会自动执行SonarQube代码扫描，但是由于很多时候Jenkins上Build中都配置-Dmaven.test.skip=true跳过测试，这样就统计不出测试覆盖率。 SonarQube本地化由于Jenkins上配置扫描不出测试覆盖率，最后考虑直接在POM中配置插件，通过开发人员自己来进行代码扫描。首先需要配置sonar-maven-plugin插件，这里将插件的sonar目标绑定到Maven的default生命周期的post-integration-test阶段，是为了方便代码扫描，也可以不进行绑定直接执行mvn sonar:sonar。 1234567891011121314&lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.0.1398&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;sonar-scan&lt;/id&gt; &lt;phase&gt;post-integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sonar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 这里使用的jacoco-maven-plugin来进行代码测试覆盖率的统计，该插件的report目标也是绑定在Maven的default生命周期的test阶段，将该插件声明在sonar-maven-plugin的前面，让其先执行覆盖率统计工作，以便sonar-maven-plugin插件使用覆盖率统报告。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;plugin&gt; &lt;groupId&gt;org.jacoco&lt;/groupId&gt; &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.8.3&lt;/version&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt;**/support/xml/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!-- Prepares the property pointing to the JaCoCo runtime agent which is passed as VM argument when Maven the Surefire plugin is executed. --&gt; &lt;execution&gt; &lt;id&gt;pre-unit-test&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;prepare-agent&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;destFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-ut.exec&lt;/destFile&gt; &lt;!-- Sets the name of the property containing the settings for JaCoCo runtime agent. --&gt; &lt;propertyName&gt;surefireArgLine&lt;/propertyName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Ensures that the code coverage report for unit tests is created after unit tests have been run. --&gt; &lt;execution&gt; &lt;id&gt;post-unit-test&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;report&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;dataFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-ut.exec&lt;/dataFile&gt; &lt;!-- Sets the output directory for the code coverage report. --&gt; &lt;outputDirectory&gt;$&#123;project.reporting.outputDirectory&#125;/jacoco-ut&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Prepares the property pointing to the JaCoCo runtime agent which is passed as VM argument when Maven the Failsafe plugin is executed. --&gt; &lt;execution&gt; &lt;id&gt;pre-integration-test&lt;/id&gt; &lt;phase&gt;pre-integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;prepare-agent&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;destFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-it.exec&lt;/destFile&gt; &lt;!-- Sets the name of the property containing the settings for JaCoCo runtime agent. --&gt; &lt;propertyName&gt;failsafeArgLine&lt;/propertyName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Ensures that the code coverage report for integration tests after integration tests have been run. --&gt; &lt;execution&gt; &lt;id&gt;post-integration-test&lt;/id&gt; &lt;phase&gt;post-integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;report&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;dataFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-it.exec&lt;/dataFile&gt; &lt;!-- Sets the output directory for the code coverage report. --&gt; &lt;outputDirectory&gt;$&#123;project.reporting.outputDirectory&#125;/jacoco-it&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 使用maven-surefire-plugin来执行单元测试。 将surefireArgLine赋值给argLine参数，以保证在测试执行时Jacoco agent处于运行状态。 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;configuration&gt; &lt;argLine&gt;$&#123;surefireArgLine&#125;&lt;/argLine&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;excludes&gt; &lt;exclude&gt;com.long.model.IT.**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 使用maven-failsafe-plugin来执行集成测试。 将failsafeArgLine赋值给argLine参数，以保证在测试执行时Jacoco agent处于运行状态。若集成测试用例和单元测试用例放在同一个项目里，必须在单元测试的surefire中exclude所有集成测试用例。 通过additionalClasspathElements标签将/target/classes添加为一个额外的classpath元素，因为在classes文件夹中一些资源没有添加到jar中，但是测试使用了这些资源，若不加这个额外的classpath，则maven-failsafe-plugin插件的integration-test将不能正常执行。 12345678910111213141516171819202122232425&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt; &lt;version&gt;2.19.1&lt;/version&gt; &lt;configuration&gt; &lt;!-- Sets the VM argument line used when integration tests are run. --&gt; &lt;argLine&gt;$&#123;failsafeArgLine&#125;&lt;/argLine&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;additionalClasspathElements&gt; &lt;additionalClasspathElement&gt;$&#123;basedir&#125;/target/classes&lt;/additionalClasspathElement&gt; &lt;/additionalClasspathElements&gt; &lt;parallel&gt;none&lt;/parallel&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;integration-test&lt;/id&gt; &lt;phase&gt;integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;integration-test&lt;/goal&gt; &lt;goal&gt;verify&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 最后需要配置SonarQube配置信息，可以配置在Maven的setting.xml配置文件中，也可以配置在项目的中，当然可以不用profiles直接配置在properties中。 1234567891011121314151617181920212223242526&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.jdbc.url&gt;jdbc:mysql://192.168.3.113:3306/sonar&lt;/sonar.jdbc.url&gt; &lt;sonar.jdbc.driver&gt;com.mysql.jdbc.Driver&lt;/sonar.jdbc.driver&gt; &lt;sonar.jdbc.username&gt;yao_yinglong&lt;/sonar.jdbc.username&gt; &lt;sonar.jdbc.password&gt;yao_yinglong_passwd&lt;/sonar.jdbc.password&gt; &lt;sonar.host.url&gt;http://172.16.21.200:9000&lt;/sonar.host.url&gt; &lt;sonar.binaries&gt;src/main/java&lt;/sonar.binaries&gt; &lt;sonar.sources&gt;src/main/java&lt;/sonar.sources&gt; &lt;sonar.tests&gt;src/test/java&lt;/sonar.tests&gt; &lt;sonar.language&gt;java&lt;/sonar.language&gt; &lt;sonar.coverage.exclusions&gt;**/support/xml/**, **/entity/**&lt;/sonar.coverage.exclusions&gt; &lt;sonar.cpd.exclusions&gt;**/support/xml/**&lt;/sonar.cpd.exclusions&gt; &lt;sonar.dynamicAnalysis&gt;reuseReports&lt;/sonar.dynamicAnalysis&gt; &lt;sonar.junit.reportsPath&gt;src/test/java&lt;/sonar.junit.reportsPath&gt; &lt;sonar.java.coveragePlugin&gt;jacoco&lt;/sonar.java.coveragePlugin&gt; &lt;sonar.jacoco.reportPaths&gt;target/coverage-reports/jacoco-ut.exec&lt;/sonar.jacoco.reportPaths&gt; &lt;sonar.jacoco.itReportPath&gt;target/coverage-reports/jacoco-it.exec&lt;/sonar.jacoco.itReportPath&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 当然为了简化配置可以不配置jacoco-maven-plugin的集成测试相关执行目标，也没有必要配置maven-failsafe-plugin插件，去掉maven-surefire-plugin插件中排除的集成测试，同时可以将sonar.jacoco.itReportPath配置为target/coverage-reports/jacoco-ut.exec甚至不配。 但是即使这样以上的配置还是过于庞杂，如果很多项目使用该类容，可以创建一个超级POM，将这些内容放在超级POM中，用到的项目集成该超级POM即可极大的简化配置。 但是这样配置，项目在测试环境、预发布环境、生产环境或者一些其他的不需要使用导SonarQube的环境，也会执行SonarQube扫描。有可能这些环境与搭建的SonarQube的服务网络不通，导致项目不能正常构建。在构建参数中添加-Dsonar.skip=true命令即可跳过SonarQube正常构建项目。如果使用Jenkins可以在Build的Goals and options中进行添加该命令。","tags":[{"name":"SonarQube","slug":"SonarQube","permalink":"https://yaoyinglong.github.io/tags/SonarQube/"},{"name":"jacoco","slug":"jacoco","permalink":"https://yaoyinglong.github.io/tags/jacoco/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"工具","slug":"杂记/工具","permalink":"https://yaoyinglong.github.io/categories/杂记/工具/"}]},{"title":"Maven聚合与继承","date":"2019-02-18T16:00:00.000Z","path":"Blog/Maven/Maven聚合与继承/","text":"聚合Maven聚合又称为多模块，该特性是为了一次构件多个项目，而不用到每个项目下分别执行mvn命令。且聚合模块其打包方式packaging必须为pom否则无法构建。 modules元素是实现聚合最核心的配置，用户可以通过在一个打包方式为pom的Maven项目中声明任意数量的module元素来实现模块的聚合。且每一个module的值都是一个当前POM的相对目录。为了方便快速定位内容，模块所处目录名称应当与其artifactId一致。 为了方便构建项目，通常将聚合模块放在项目目录最顶层，其他模块作为聚合模块的子目录，聚合模块仅仅是帮助聚合其他模块构件的工具，其本身并无实质内容。 Maven在构件聚合项目时，首先会解析聚合模块的POM、分析要构建的模块、并计算出一个反应堆构建顺序，然后根据这个顺序依次构建各个模块，反应堆是所有模块组成的一个构建结构。 1234567891011&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-aggregator&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;Account Aggregator&lt;/name&gt;&lt;modules&gt; &lt;module&gt;account-email&lt;/module&gt; &lt;module&gt;account-persist&lt;/module&gt;&lt;/modules&gt; 继承继承是为了抽取出重复的配置，需要创建POM的父子结构，在父POM中声明一些配置供子POM继承，以实现一处声明多处使用。 与聚合一样父模块的POM其打包类型packaging必须为pom，父模块只是为了消除配置的重复，因此其本身不包含除POM以外的项目文件。 123456&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-aggregator&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;Account Aggregator&lt;/name&gt; 在子模块中使用parent元素声明父模块，groupId、artifactId和version指定了父模块的坐标，且这三个元素是必须的，元素relativePath表示父模块POM的相对路径，当构建时Maven首先会根据relativePath检查父POM，若找不到则从本地仓库查找，relativePath默认值是../pom.xml。 123456&lt;parent&gt; &lt;artifactId&gt;account-aggregator&lt;/artifactId&gt; &lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt;&lt;/parent&gt; 可继承的POM元素： groupId：项目组ID，项目坐标的核心元素 version：项目版本号，项目坐标的核心元素 description：项目描述信息 organization：项目组织信息 inceptionYear：项目创始年份 url：项目url地址 developers：项目开发者信息 contributors：项目贡献者信息 distributionManagement：项目部署配置 issueManagement：项目缺陷跟踪系统信息 ciManagement：项目持续集成系统信息 scm：项目的版本控制系统信息 mailingLists：项目的邮件列表信息 properties：自定义的Maven属性 dependencies：项目的依赖配置 dependencyManagement：项目的依赖管理配置， repositories：项目的仓库配置 build：包括项目的源码目录、输出目录、插件配置、插件管理配置等 reporting：包括项目的报告输出目录配置、报告插件配置等 依赖管理dependencyManagement既能让子模块继承到父类模块的依赖配置，又能保证子模块依赖使用的灵活性，该元素下的依赖声明不会引入实际的依赖，不过能约束dependencies下的依赖使用。 123456789101112131415161718&lt;!-- 父模快account-parent中声明 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 子模块account-email中使用 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; dependencies中的依赖配置比原来简单了，junit依赖省去了version和scope，这样能统一项目范围中依赖的版本，当依赖版本在父POM中声明之后，子模块使用依赖时无需声明版本号，也不会发生多个子模块使用依赖版本不一致的情况。子模块不声明依赖的使用，即使该依赖已经在父POM的dependencyManagement中声明，也不会产生任何实际效果。 import依赖范围的依赖只在dependencyManagement元素下有效，使用该范围的依赖通常指向一个POM，作用是将目标POM中的dependencyManagement配置导入并合并到当前POM的dependencyManagement元素中。 若多个项目使用的依赖版本一致，则可以定义一个使用dependencyManagement专门管理依赖的POM，然后在各个项目中导入这些依赖管理配置。 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt; &lt;artifactId&gt;account-parent&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 插件管理Maven提供了pluginManagement元素来帮助管理插件，在该元素中配置的依赖不会造成实际的插件调用行为，当POM中配置了真正的plugin元素，且其groupId和artifactId与pluginManagement中配置的插件匹配时，pluginManagement才会影响实际的插件行为。 123456789101112131415161718192021222324252627282930&lt;!-- 父模快account-parent中声明 --&gt;&lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.0.1398&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;sonar-scan&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sonar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt;&lt;/build&gt;&lt;!-- 子模块account-email中使用 --&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 若子模块需要不同的插件配置，可以自行配置以覆盖父模块的pluginManagement配置，当项目中多个模块有相同的插件配置时，应当将配置移到父POM的pluginManagement元素中。 聚合与继承的关系对于聚合模块，它知道被聚合的模块，但被聚合的模块不知道这个聚合模块的存在。 对于继承关系的父POM，它不知道哪些子模块继承了它，但子模块都必须知道自己的父POM。 聚合POM与继承关系中的父POM的packaging都必须时pom，且都是除POM之外没有实际的内容。 约定优于配置Maven提倡约定优于配置，使用约定可以大量减少配置，遵循约定虽然损失一定的灵活性，但却能减少配置，且能帮助遵守构建标准。 任何一个Maven项目都隐式地继承超级POM，Maven 3中超级POM文件在$MAVEN_HOME/lib/maven-model-builder-x.x.x.jar中的org/apache/maven/model/pom-4.0.0.xml路径下。Maven 2中超级POM文件在$MAVEN_HOME/lib/maven-x.x.x-uber.jar中的org/apache/maven/project/pom-4.0.0.xml路径下。 超级POM定义了仓库及插件仓库，都关闭了SNAPSHOT的支持。 反应堆在一个多模块的Maven项目中，反应堆时指所有模块组成的一个构建结构，对于单模块项目，反应堆就是该模块本身，多模块的项目，反应堆就包括了各个模块之间的继承与依赖关系，从而能自动计算出合理的模块构建顺序。 Maven按序读取POM，若该POM没有依赖模块，则构建该模块，否则先构建依赖模块，若该依赖模块还依赖其他模块，则进一步先构建依赖的依赖。 模块间的依赖关系会将反应堆构成一个有向非循环图，各个模块是该图的节点，依赖关系构成了有向边，且该图不允许出现循环，当出现A模块依赖于B，B又依赖于A时，Maven会报错。 若仅仅构建完整反应堆中的某些模块，则需要实时的裁剪反应堆。Maven提供很多命令行选项支持裁剪反应堆: -am, --also-make 同时构建所列模块的依赖模块 -amd -also-make-dependents 同时构建依赖于所列模块的模块 -pl, --project &lt; arg &gt; 构建指定的模块，模块间用逗号隔开 -rf -resume-from &lt;args&gt; 从指定模块回复反应堆","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven插件基础","date":"2019-01-02T16:00:00.000Z","path":"Blog/Maven/Maven插件基础/","text":"Maven核心仅仅定义了抽象的生命周期，具体任务交给插件来完成，插件以独立的构件形式存在，Maven核心分发包不到3M大小，Maven会在需要时下载并使用插件。如maven-dependency-plugin能分析项目依赖，找出潜在无用依赖，列出项目依赖树，分析依赖来源等 生命周期的阶段与插件的目标相互绑定，来完成某个具体的构建任务，例如项目编译任务对应了default生命周期的compile阶段，而maven-compiler-plugin插件的compile目标能完成该任务，将其绑定能实现项目编译目的 插件的每个目标都对应一个功能，如dependency:analyze、dependency:tree、dependency:list，冒号前面是插件前缀，冒号后面是插件目标 插件绑定Maven核心默认为一些主要的生命周期阶段内置绑定了很多插件目标，当调用生命周期阶段时，对应的插件目标就会执行相应的任务。 生命周期阶段 插件目标 执行任务 pre-clean - - clean maven-clean-plugin:clean 删除项目输出目录 post-clean - - pre-site - - site maven-site-plugin:site 生成项目站点 post-site - - site-deploy maven-site-plugin:deploy 将项目站点部署到远程服务器 pro-resources maven-resources-plugin:resources 复制主资源文件至主输出目录 compile maven-compiler-plugin:compile 编译主代码至主输出目录 process-test-resources maven-resources-plugin:testResources 复制测试资源文件至测试输出目录 test-compile maven-compiler-plugin:testCompile 编译测试代码至测试输出目录 test maven-surefire-plugin:test 执行测试用例 package maven-jar-plugin:jar 创建项目jar包 install maven-install-plugin:install 将项目输出构件安装到本地仓库 deploy maven-deploy-plugin:deploy 将项目输出构件部署到远程仓库 上表只列出了clean和site生命周期插件绑定关系，以及default生命周期拥有插件绑定关系的阶段，default生命周期还有很多其他阶段，默认没有绑定任何插件，故无任何实际行为。 还可以自定义将某个插件目标绑定到生命周期的某个阶段上，可以通过phrase标签将goals标签中指定的插件目标绑定到具体的生命周期阶段上。 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;xml-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xslt-generate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;transform&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; executions下每一个execution都可以用来配置执行一个任务，通过phase将xml-maven-plugin的transform目标绑定到default生命周期的compile阶段上。goals用于配置指定要执行的插件目标。 很多插件目标在编写时已定义了默认绑定阶段，即使不通过phase元素配置生命周期阶段，也能绑定到生命周期中去。 当多个插件目标绑定到同一个生命周期阶段时，插件声明的先后顺序决定了目标执行的顺序。 插件配置完成插件目标和声明周期阶段绑定后，还能配置插件目标参数，几乎所有插件目标都有一些可配置的参数，可通过命令行和POM配置等方式来配置。 Maven命令行中可以使用：-D参数键=参数值，来配置插件目标参数。例如：mvn install -Dmaven.test.skip=true 并非所有插件参数都适合命令行配置，可以在插件声明时，对插件进行全局配置，所有基于该插件的目标任务都会使用全局配置。还可以为插件的某个目标配置特定的参数。 1234567891011121314151617181920212223&lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2.maven2&lt;/groupId&gt; &lt;artifactId&gt;maven-jaxb2-plugin&lt;/artifactId&gt; &lt;!-- 全局配置 --&gt; &lt;configuration&gt; &lt;schemaDirectory&gt;src/main/resources/xsd&lt;/schemaDirectory&gt; &lt;generateDirectory&gt;src/main/java/&lt;/generateDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xsd1-generate&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;!-- 特定目标任务配置 --&gt; &lt;configuration&gt; &lt;schemaIncludes&gt; &lt;include&gt;test.xsd&lt;/include&gt; &lt;/schemaIncludes&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 获取插件信息主要的插件都来自Apache和Codehaus，文档链接分别为 http://maven.apache.org/plugin/index.html 和 http://mojo.codehaus.org/plugins.html，下载地址分别为 http://repo1.maven.org/maven2/org/apache/maven/plugins 和 http://repository.codehaus.org/org/codehuas/mojo 可以使用maven-help-plugin查看插件详细信息。查看插件目标默认绑定阶段：mvn help:目标-DgroupId:artifactId:version，例如：mvn help:describe-Dplugin = org.apache.maven.plugins:maven-source-plugin:2.1.1，可以省去版本信息，可以使用插件目标前缀替换坐标，加上goal参数仅查询描述插件目标信息，加上detail参数查询详细信息，例如：mvn help:describe-Dplugin=compiler[-Dgoal=compiler][-Ddetail] 明显可以发现命令行传入参数不同于该插件目标参数名称，命令行参数是由插件参数表达式（Expression）决定的，例如surefire:test skip参数表达式为${maven.test.skip}。并非所有插件目标都有表达式，一些插件目标参数只能在POM中配置。 插件解析机制与依赖构件一样，插件构件同样基于坐标存储在Maven仓库中。需要时，Maven会从本地仓库寻找插件，若不存在，则从远程仓库查找，找到后下载到本地仓库使用。 1234567891011121314&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 所有子元素表达含义与依赖远程仓库配置完全一样。 若插件的groupId为org.apache.maven.plugins表示为官方插件，在配置插件信息时可以省略groupId，不推荐使用。 插件版本的解析与依赖版本解析类似，未提供版本会自动解析版本，Maven在超级POM中为所有核心插件设定了版本，在使用核心插件时即使不做任何配置，其版本已经确定了。 若某个插件未设定版本，又不是核心插件，Maven会检查所有仓库中可用版本，然后做出选择，选择版本方式与依赖类似，都是到归并后的元数据文件中确定版本。 插件解析元数据时，会默认使用org.apache.maven.plugins和org.codehaus.mojo两个groupId，也可以通过settings配置让Maven检查其他groupId上的插件仓库元数据。 123&lt;pluginGroups&gt; &lt;pluginGroup&gt;com.your.plugins&lt;/pluginGroup&gt;&lt;/pluginGroups&gt; 基于该配置Maven不仅会检查org/apache/maven/plugins/maven-metadata.xml 和 org/codehaus/mojo/maven-metadata.xml 还会检查 com/your/plugins/maven-metadata.xml 1234567891011121314&lt;metadata&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;name&gt;Apache Maven ACR Plugin&lt;/name&gt; &lt;prefix&gt;acr&lt;/prefix&gt; &lt;artifactId&gt;maven-acr-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;name&gt;Apache Maven Ant Plugin&lt;/name&gt; &lt;prefix&gt;ant&lt;/prefix&gt; &lt;artifactId&gt;maven-ant-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/metadata&gt; prefix表示插件前缀，当Maven解析到类似dependency:tree命令时，先基于默认groupId归并所有插件仓库元数据，再检查归并后的元数据，根据prefix找到对应的artifactId，然后结合当前元数据的groupId解析得到version，就得到了完整的坐标。若org/apache/maven/plugins/maven-metadata.xml没有记录该插件前缀，则接着检查剩下的两个元数据。若所有元数据都不包含该前缀则报错。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven仓库","date":"2018-12-31T16:00:00.000Z","path":"Blog/Maven/Maven仓库/","text":"坐标和依赖是任何一个构件在Maven世界中的逻辑表示方式，任何一个构件都有一组坐标唯一标识，而构件的物理表示方式是文件，Maven通过仓库来统一管理这些文件。 仓库布局任何一个构件都有其唯一的坐标，根据这个坐标可以定义其在仓库中的唯一存储路径，且存储路径大致对应关系为groupId/artifactId/version/artifactId-version[-classifier].packaging，这便是Maven的仓库布局。 Maven仓库是基于简单的文件系统存储的，当遇到一些仓库问题时，能很方便地查找相关文件，方便问题定位。 仓库分类仓库只分为本地仓库和远程仓库两类。Maven根据坐标寻找构件时，先查看本地仓库，若存在直接使用；若不存在或需要查看是否有更新的构件版本，再去远程仓库查找，发现后下载到本地仓库再使用。若本地仓库和远程仓库都没有Maven就会报错。 中央远程仓库是Maven核心的自带的远程仓库，其包含了绝大部分开源构件。默认使用中央仓库。 私服是另一种特殊的远程仓库，为了节省带宽和时间，应在局域网内架设一个私有的仓库服务器，使其代理所有外部远程仓库，且内部项目还能部署到私服上供其他项目使用。 除中央仓库和私服外还有很多其他公开的远程仓库，Java.net Maven库 和 JBoss Maven库 中央仓库Maven安装文件自带中央仓库的配置，在$M2_HOME/lib/maven-model-builder-3.3.9.jar/org/apache/maven/pom-4.0.0.xml中，且这段配置的文件是所有Maven项目都会继承的超级POM： 12345678910111213141516171819202122232425262728&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;!-- 不从中央仓库下载快照版本的构件 --&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;!-- 不从中央仓库下载快照版本的构件 --&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 私服私服代理广域网上的远程仓库，下载构件时从私服请求，若不存在则从外部远程仓库下载，缓存到私服后再提供下载服务，一些无法从外部下载的构件也能从本地上传到私服共大家使用。 降低中央仓库负荷 节省外网带宽：私服能消除大量对外部仓库的重复请求，从而节省带宽 加速Maven构件：Maven快照更新检查等机制要求在执行构件时不停检查远程仓库数据，若配置了很多外部远程仓库，由于不停的连接请求外部远程仓库非常耗时，导致构件速度大大降低，使用私服只需要检查局域网私服的数据 部署第三方构件：如一些组织内部私有构件无法从外部仓库获取，但又不能发布到公共仓库，可以发布到私服中，供内部的Maven项目使用 提高稳定性增强控制：Maven构建高度依赖远程仓库，当网络不稳定时，Maven构建会非常不稳定，甚至无法构建 远程仓库配置若默认中央仓库无法满足项目需求，需配置其他远程仓库： 12345678910111213141516&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;bintray&lt;/id&gt; &lt;url&gt;http://dl.bintray.com/andsel/maven/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; repositories元素下，可以使用repository子元素声明一个或多个远程仓库，且任何一个仓库声明的id必须唯一，且Maven自带中央仓库id为central，若其它仓库声明也使用该id，会覆盖中央仓库的配置。 url指仓库地址，一般都基于http协议。 releases和snapshots元素用来控制Maven对于发布版本构件和快照版本构件的下载，releases的enabled值为true表示开启仓库发布版本下载支持，snapshots的enabled值为false表示关闭仓库快照版本下载支持。 updatePolicy元素用来配置Maven从远程仓库检查更新的频率，默认daily每天检查更新一次，never表示从不检查更新，always表示每次构件都检查更新，interval：X表示每隔X分钟检查更新一次（X为任意整数） checksumPolicy元素用来配置Maven检查检验和文件的策略，当构件部署到Maven仓库时，会同时部署对应的检验和文件，下载构件时会验证校验和文件。checksumPolicy默认值为warn表示校验和文件验证失败在执行构建时输出警告信息，fail表示让构建失败，ignore表示完全忽略校验和错误。 远程仓库认证配置认证信息与配置仓库信息不同，仓库信息可直接配置在项目的POM文件中，但认证信息必须配置在setting.xml文件中，这样更为安全。 1234567&lt;servers&gt; &lt;server&gt; &lt;id&gt;deploymentRepo&lt;/id&gt; &lt;username&gt;repouser&lt;/username&gt; &lt;password&gt;repopwd&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; servers元素下同样可以配置多个server，这里的id元素必须与POM中需要认证的repository元素的id完全一致。 部署至远程仓库要将项目生成的构件部署到仓库，需要在项目pom.xml中配置distributionManagement元素 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;company-deploy&lt;/id&gt; &lt;name&gt;company-deploy&lt;/name&gt; &lt;url&gt;https://nexus.company.com/repository/company-deploy/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;company-snapshot-deploy&lt;/id&gt; &lt;name&gt;company-snapshot-deploy&lt;/name&gt; &lt;url&gt;https://nexus.company.com/repository/company-snapshot-deploy/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; distributionManagement元素包含repository发布版本构件仓库和snapshotRepository快照版本仓库，id为该仓库的唯一标识，name为了方便阅读，url为该仓库地址。 命令行运行mvn clean deploy，Maven就会将项目构建输出的构件部署到配置对应的远程仓库，若当前版本是快照版本，则部署到快照版本仓库地址，反之部署到发布版本仓库地址。 快照版本任何一个项目或构件都必须有自己的版本，版本的值可能是1.0.0、1.3-alpha-4、3.0、2.1-SNAPSHOT或2.1-20091216.221212-13。1.0.0、1.3-alpha-4和3.0是稳定发布版本，2.1-SNAPSHOT和2.1-20091216.221212-13是不稳定快照版本。 使用快照版本，避免了在协同开发多个相互依赖的模块时，各个模块频繁更新POM，以及频繁代码更新造成的版本好滥用。 当构件A的版本好设置为快照版本如2.1-SNAPSHOT时，在发布私服过程中，Maven会自动为构件打上时间戳，若构件B依赖与构件A的2.1-SNAPSHOT版本，当构建模块B时Maven会自动从远程仓库检查模块A的2.1-SNAPSHOT的最新构件，当发现更新时下载。默认每天检查一次，也可通过命令mvn clean install-U强制让Maven检查更新。 快照版本只应该在组织内部的项目或模块间依赖使用，项目不应该依赖与任何组织外部的快照版本依赖，因为快照版本不稳定可能造成潜在风险。 仓库解析依赖机制依赖范围是system时，Maven直接从本地文件系统解析构件。 根据依赖坐标计算仓库路径后，尝试直接从本地仓库寻找构件，若发现构件，则解析成功。 本地仓库不存在，若依赖版本是显示的发布版本构件，遍历所有远程仓库，发现后下载并解析使用。 若依赖版本是RELEASE或LATEST，则基于更新策略读取所有远程仓库的元数据groupId/artifactId/maven-metadata.xml，将其与本地仓库对应的元数据合并后，计算出RELEASE或LATEST真实值，然后基于该真实值检查本地仓库和远程仓库。 若依赖版本是SNAPSHOT，则基于更新策略读取所有远程仓库元数据groupId/artifactId/version/maven-metadata-snapshot.xml，将其与本地仓库对应的元数据合并，得到最新快照版本值，然后基于该值检查本地仓库和远程仓库。 若最后解析得到的构件版本是时间戳格式的快照，则复制其时间戳格式的文件至非时间戳格式，并使用非时间戳格式的构件。 若当前版本不明晰的，如RELEASE、LATEST和SNAPSHOT，Maven需要基于更新远程仓库的更新策略来检查更新。还可以使用-U参数强制检查更新，此时会忽略&lt;updatePolicy&gt;配置。 当Maven检查完更新策略，并决定检查依赖更新时，就需要检查仓库元数据maven-metadata.xml。LATEST指向了元数据中最新的那个版本，RELEASE指向了元数据中最新的发布版本。Maven通过合并多个远程仓库及本地仓库的元数据，就能计算出基于所有仓库的LATEST和RELEASE，然后再解析具体的构件。 不推荐在依赖声明中使用LATEST和RELEASE，因为Maven随时都可能解析到不同的构件。Maven3不再支持在插件配置中使用LATEST和RELEASE。 若不设置插件版本，其效果就和RELEASE一样，Maven会解析最新的发布版本构件。 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;metadata modelVersion=\"1.1.0\"&gt; &lt;groupId&gt;com.test&lt;/groupId&gt; &lt;artifactId&gt;web-core&lt;/artifactId&gt; &lt;version&gt;3.1.0-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;timestamp&gt;20180831.035005&lt;/timestamp&gt; &lt;buildNumber&gt;11&lt;/buildNumber&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20180831035005&lt;/lastUpdated&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;3.1.0-20180831.035005-11&lt;/value&gt; &lt;updated&gt;20180831035005&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/snapshotVersions&gt; &lt;/versioning&gt;&lt;/metadata&gt; timestamp和buildNumber分别代表了这一快照的时间戳和构件号。 仓库元数据并不是永远正确的，若无法解析或解析错误，可能出现了元数据错误，可以手工或使用工具修复。 镜像若仓库A能提供仓库B存储的所有内容，则A就是B的一个镜像，任何一个能从B仓库获得的构件都能从镜像中获取。http://maven.net.cn/content/groups/public/ 是中央仓库 http://repo1.maven.org/maven2 在中国的镜像。 12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; mirrorOf的值为central，表示该配置为中央仓库的镜像，任何对于中央仓库的请求都会转至该镜像。id、name、url与一般仓库配置无异，表示该镜像仓库的唯一标识符、名称以及地址。若需要认证也可以基于该id配置仓库认证。 镜像的一个更常见的用法是结合私服，私服就是所有仓库的镜像。 &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;：匹配所有远程仓库 &lt;mirrorOf&gt;external: *&lt;/mirrorOf&gt;：匹配所有远程仓库，使用localhost的除外，使用file://协议的除外。匹配所有不在本机上的远程仓库。 &lt;mirrorOf&gt;repo1, repo2&lt;/mirrorOf&gt;：匹配仓库repo1、repo2，使用逗号分隔多个远程仓库。 &lt;mirrorOf&gt;*, !repo1&lt;/mirrorOf&gt;：匹配所有远程仓库，repo1 除外，使用感叹号将仓库从匹配中排除。 镜像仓库会完全屏蔽被镜像仓库，当镜像仓库不稳定或停止服务时，Maven无法访问被镜像仓库，因而将无法下载构件。 仓库搜索服务Sonatype Nexus：提供的关键字搜索、类名搜索、坐标搜索、校验和搜索等功能。 Jarvana：提供基于关键字、类名的搜索，构件下载、依赖声明片段等功能。 Mvnbrowser：只提供关键字搜索，能告知用户构件依赖于哪些构件，以及该构件被哪些其他构件依赖。 MVNrepository：界面清新，提供关键字搜索、依赖声明代码片段、构件下载、依赖与被依赖关系信息、构件所包含信息等功能，提供一个简单图标，显示某个构件各个版本间的大小变化。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven生命周期","date":"2018-12-31T16:00:00.000Z","path":"Blog/Maven/Maven生命周期/","text":"Maven的生命周期是抽象的，生命周期本身不做任何实际的工作，其实际行为都由插件来完成，生命周期和插件两者协同工作，密不可分。每个生命周期步骤都可以绑定一个或多个插件行为，且Maven为大多数构建步骤编写并绑定了默认插件。 Maven拥有三套相互独立的生命周期，分别为clean、default和site。clean的目的是清理项目，default的目的是构建项目，site的目的是建立项目站点。每个生命周期包含一些有序的阶段，且后面的阶段依赖于前面的阶段，用户和Maven最直接的交互方式就是调用这些生命周期阶段。三套生命周期本身是相互独立的，可单独调用任何一个生命周期的任何一个阶段。 clean生命周期 阶段 描述 pre-clean 执行一些清理前需要完成的工作 clean 清理上一次构建生成的文件 post-clean 执行一些清理后需要完成的工作 default生命周期 阶段 描述 validate 验证项目是否正确，并提供所有必要信息 initialize 初始化构建状态，例如设置属性或创建目录 generate-sources 生成任何包含在编译中的源代码 process-sources 处理项目主资源文件，例如变量替换等 generate-resources 生成包含在包中的资源 process-resources 将资源复制并处理到目标目录，准备打包 compile 编译项目的源代码 process-classes 从编译中对生成的文件进行后续处理，例如对Java类进行字节码增强 generate-test-sources 生成任何包含在编译中的测试源代码 process-test-sources 处理测试源代码，例如过滤某些值 generate-test-resources 创建用于测试的资源 process-test-resources 将资源复制并处理到测试目标目录中 test-compile 将测试源代码编译到测试目标目录中 process-test-classes 对来自测试编译的生成文件进行后续处理，例如对Java类进行字节码增强 test 使用合适的单元测试框架运行测试 prepare-package 在实际包装之前执行准备包装所需的任何操作。例如解包，版本处理 package 获取已编译的代码并将其打包为可分发的格式，例如JAR、WAR pre-integration-test 执行集成测试之前执行所需操作。例如设置所需环境。 integration-test 如有必要，将程序包处理并部署到可以运行集成测试的环境中 post-integration-test 执行集成测试后执行所需的操作。例如清理环境 verify 运行检查以验证包是否有效并符合质量标准 install 将软件包安装到本地存储库中，以便在本地用作其他项目的依赖项 deploy 将最终包复制到远程存储库以与其他开发人员和项目共享 site生命周期 阶段 描述 pre-site 在实际项目站点生成之前执行所需的过程 site 生成项目的站点文档 post-site 执行完成站点生成所需的进程，并准备站点部署 site-deploy 将生成的站点文档部署到指定的Web服务器 命令行与生命周期从命令行执行Maven任务最主要方式就是调用Maven生命周期。 mvn clean：调用clean生命周期的per-clean和clean阶段 mvn test：调用default生命周期的validate到test的所有阶段 mvn clean install：调用clean生命周期的per-clean和clean阶段和default生命周期的validate到install的所有阶段","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"XSD实用总结","date":"2018-12-31T16:00:00.000Z","path":"Blog/杂记/工具/XSD使用总结/","text":"类生成插件配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;!-- 将XSD文件自动生成POJO对象，每次变更用Maven重新编译一下 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2.maven2&lt;/groupId&gt; &lt;artifactId&gt;maven-jaxb2-plugin&lt;/artifactId&gt; &lt;version&gt;0.14.0&lt;/version&gt; &lt;configuration&gt; &lt;schemaDirectory&gt;src/main/resources/xsd&lt;/schemaDirectory&gt; &lt;generateDirectory&gt;src/main/java/&lt;/generateDirectory&gt; &lt;packageLevelAnnotations&gt;false&lt;/packageLevelAnnotations&gt; &lt;noFileHeader&gt;true&lt;/noFileHeader&gt; &lt;episode&gt;false&lt;/episode&gt; &lt;readOnly&gt;true&lt;/readOnly&gt; &lt;!-- 如果不加生成的类注释会中文乱码 --&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;!-- 设置生成的类的注解语言en为英文 --&gt; &lt;locale&gt;en&lt;/locale&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xsd1-generate&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;args&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;arg&gt;-Xannotate&lt;/arg&gt; &lt;!-- 使用XJC给生成Java类添加父类 --&gt; &lt;arg&gt;-Xinheritance&lt;/arg&gt; &lt;!-- 给生成Java类添加equals方法 --&gt; &lt;arg&gt;-Xequals&lt;/arg&gt; &lt;!-- 给生成Java类添加hashCode方法 --&gt; &lt;arg&gt;-XhashCode&lt;/arg&gt; &lt;arg&gt;-Xvalue-constructor&lt;/arg&gt; &lt;arg&gt;-nv&lt;/arg&gt; &lt;/args&gt; &lt;extension&gt;true&lt;/extension&gt; &lt;schemaIncludes&gt; &lt;include&gt;test.xsd&lt;/include&gt; &lt;/schemaIncludes&gt; &lt;bindingIncludes&gt; &lt;include&gt;test.xjb&lt;/include&gt; &lt;/bindingIncludes&gt; &lt;generatePackage&gt;com.test.support.xml&lt;/generatePackage&gt; &lt;plugins&gt; &lt;!-- 基础插件依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics&lt;/artifactId&gt; &lt;version&gt;1.11.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- -Xequals和-XhashCode参数用于生成equals和hashcode方法使用 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-value-constructor&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics-annotate&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 用于生成equals和hashcode方法的依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics-runtime&lt;/artifactId&gt; &lt;version&gt;1.11.1&lt;/version&gt;&lt;/dependency&gt; 用于实现生成的类中加注解和实现继承等关系 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?&gt;&lt;jaxb:bindings xmlns:jaxb=\"http://java.sun.com/xml/ns/jaxb\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\" xmlns:xjc=\"http://java.sun.com/xml/ns/jaxb/xjc\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:annox=\"http://annox.dev.java.net\" xmlns:inheritance=\"http://jaxb2-commons.dev.java.net/basic/inheritance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/jaxb http://java.sun.com/xml/ns/jaxb/bindingschema_2_0.xsd\" jaxb:extensionBindingPrefixes=\"xjc annox inheritance\" version=\"2.1\"&gt; &lt;jaxb:bindings schemaLocation=\"test.xsd\" node=\"/xs:schema\"&gt; &lt;!-- 给生成的类添加serialVersionUID --&gt; &lt;jaxb:globalBindings&gt; &lt;jaxb:serializable uid=\"3710395777932380425\"/&gt; &lt;/jaxb:globalBindings&gt; &lt;!-- 给匹配的类添加注解 --&gt; &lt;jaxb:bindings node=\"//xs:complexType\" multiple=\"true\"&gt; &lt;annox:annotateClass&gt;@lombok.Data&lt;/annox:annotateClass&gt; &lt;annox:annotateClass&gt;@lombok.EqualsAndHashCode&lt;/annox:annotateClass&gt; &lt;/jaxb:bindings&gt; &lt;jaxb:bindings node=\"//xs:element\" multiple=\"true\"&gt; &lt;annox:annotateClass&gt;@lombok.Data&lt;/annox:annotateClass&gt; &lt;annox:annotateClass&gt;@lombok.EqualsAndHashCode&lt;/annox:annotateClass&gt; &lt;/jaxb:bindings&gt; &lt;!-- 给匹配的类添加父类 --&gt; &lt;jaxb:bindings node=\"//xs:element[@name='BaselineModel']/xs:complexType\"&gt; &lt;inheritance:extends&gt;com.test.support.AbstractModel&lt;/inheritance:extends&gt; &lt;/jaxb:bindings&gt; &lt;jaxb:bindings node=\"//xs:element[@name='RuleModel']/xs:complexType\"&gt; &lt;inheritance:extends&gt;com.test.support.AbstractModel&lt;/inheritance:extends&gt; &lt;/jaxb:bindings&gt; &lt;/jaxb:bindings&gt;&lt;/jaxb:bindings&gt; 如果schema文件和binding文件有变动只需要通过maven编译一下","tags":[{"name":"XSD","slug":"XSD","permalink":"https://yaoyinglong.github.io/tags/XSD/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"工具","slug":"杂记/工具","permalink":"https://yaoyinglong.github.io/categories/杂记/工具/"}]},{"title":"Maven基础","date":"2018-12-07T16:00:00.000Z","path":"Blog/Maven/Maven基础/","text":"Maven坐标详解groupId：定义当前Maven项目隶属的实际项目，不应该对应隶属的组织或公司，表示方式与Java包名表示方式类是。 artifactId：定义实际项目中的一个Maven项目（模块），推荐使用实际项目名称作为前缀。 version：项目当前版本号。 type：依赖类型，默认为jar。 scope：依赖范围。 optional：标记依赖是否可选。 exclusions：排除传递性依赖。 packaging：项目打包方式，默认为jar。 classifier：用来帮助定义构建输出的一些附属构件。不能直接定义项目classifier，附属构件不是项目直接默认生成，而是由附加插件帮组生成。附属构件名称一般规则artifactId-version[-classifier].packaging 123456&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;version&gt;2.1&lt;/version&gt;&lt;/dependency&gt; 依赖范围Maven在编译项目主代码时需使用一套classpath，在编译执行测试时会使用另一套classpath，实际运行项目时又会使用另一套classpath。依赖范围就是用来控制依赖与这三种classpath(编译classpath、测试classpath、运行classpath)的关系，依赖范围还对传递性依赖产生影响。 compile：编译依赖范围，依赖默认值，使用此依赖范围的Maven依赖，对于编译、测试、运行三种classpath都有效。 test：测试依赖范围，只对测试classpath有校，编译和运行时均无效。 provided：以提供依赖范围，对编译和测试classpath有效，运行时无效。 runtime：运行时依赖范围，测试和运行时有效，编译主代码时无效。 system：系统依赖范围，该依赖与三种classpath的关系和provided依赖范围完全一致。但使用该依赖范围必须通过systemPath显示指定依赖文件路径，此依赖不通过Maven仓库解析，往往与本机绑定，可能造成构建的不可移植，且可引用环境变量。 1234567&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;rt&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/rt.jar&lt;/systemPath&gt;&lt;/dependency&gt; import：导入依赖范围，不会对三种classpath产生实际影响。 依赖范围(scope) 对编译classpath有效 对测试classpath有效 对运行时classpath有效 compile √ √ √ test × √ × provided √ √ × runtime × √ √ system √ √ × 传递性依赖Maven传递性依赖能很好的解决引入的依赖包依赖于其他开源类库的情况，大大简化和方便了依赖声明，大部分情况下只需要关心项目直接依赖，Maven会解析各个直接依赖的POM，将必要的间接依赖以传递性依赖的形式引入到当前项目。 A有一个compile范围的B依赖，而B有一个compile范围的C依赖，则C就成了A的compile范围依赖，即C是A的传递性依赖。A对于B是第一直接依赖，B对于C是第二直接依赖，下表种左边第一列表示第一直接依赖范围，第一行表示第二直接依赖范围，中间交叉单元格表示传递性依赖范围。 compile test provided runtime compile compile — — runtime test test — — test provided provided — provided provided runtime runtime — — runtime 当第二直接依赖范围是compile时，传递性依赖范围与第一直接依赖范围一致，当第二传递性依赖范围是test时，依赖不会传递，当第二直接依赖是provided时，只传递第一直接依赖范围为provided的依赖，且传递性依赖范围同样为provided，当第二直接依赖范围是runtime时，传递性依赖范围与第一直接依赖范围一致，但compile例外。 依赖调解当传递性依赖造成问题时，需要清楚的知道该传递性依赖时从哪条依赖路径引入，若项目A有这样的依赖关系：A —&gt; B —&gt; C —&gt; X(1.0)、A —&gt; D —&gt; X(2.0)。X是A的传递性依赖，但两条路径上有两个版本的X，这时Maven的依赖调解就会起作用。这时会用到依赖调解的第一原则：路径最近者优先。 但第一原则不能解决类似：A —&gt; B —&gt; Y(1.0)、A —&gt; C —&gt; Y(2.0)依赖路径长度一样的情况。从Maven 2.0.9开始定义的第二原则：第一声明者优先。 可选依赖若存在A —&gt; B、B —&gt; X(可选)、B —&gt; Y(可选)，由于传递性依赖的定义，X、Y是可选依赖，依赖将不会得以传递。 但为什么要使用可选依赖呢？可能项目B实现了两个互斥特性X和Y，用户不可能同时使用这两个特性。理想情况下不应该使用可选依赖。 排除依赖传递性依赖会给项目隐式地引入很多依赖，极大的简化项目依赖管理的同时也会带来一些问题。若项目A依赖于B，而B又依赖于另一个类库的SNAPSHOP版本，但由于SNAPSHOP的不稳定直接影响到当前项目，这时就需要排除SNAPSHOP引入一个正式版。在依赖冲突时，也需要排除冲突的依赖。 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.jvnet.jaxb2-commons&lt;/groupId&gt; &lt;artifactId&gt;property-listener-injector&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; exclusions元素可以包含一个或多个exclusion子元素，声明exclusion时只需要groupId和artifactId不需要version元素，因为Maven解析后的依赖中，不可能存在groupId和artifactId相同version不同的两个依赖。 依赖归类引入的同一项目中的不同模块，这些依赖的版本应该是相同的，最好使用properties元素定义Maven属性，使用美元符号和大括弧环绕的方式引用Maven属性。 依赖优化mvn dependency:list 查看当前项目的已解析依赖 mvn dependency:tree 查看当前项目的依赖树 mvn dependency:analyze 分析当前项目的依赖。Used undeclared dependencies表示使用到了但未显示声明依赖，意味着存在潜在风险，当直接依赖升级相关依赖发生版本变化可能导致当前项目出错。Unused declared dependencies表示未使用但显示声明的依赖。 在IDEA中可以直接使用Maven Helper工具来完成依赖的优化。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven常用工具","date":"2018-12-07T16:00:00.000Z","path":"Blog/Maven/Maven常用工具/","text":"Lombok1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; Mybatis Plus12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-plus.version&#125;&lt;/version&gt;&lt;/dependency&gt; Mybatis 增强工具，在 Mybatis 的基础上只做增强不做改变，简化开发、提高效率。 Okhttp12345&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;$&#123;okhttp.version&#125;&lt;/version&gt;&lt;/dependency&gt; 高效的HTTP客户端，默认特性： 支持HTTP/2，允许所有同一个主机地址的请求共享同一个socket连接 连接池减少请求延时 透明的GZIP压缩减少响应数据的大小 缓存响应内容，避免一些完全重复的请求 Java工具包12345&lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;$&#123;hutool.version&#125;&lt;/version&gt;&lt;/dependency&gt; Hutool是一个Java工具包类库，对文件、流、加密解密、转码、正则、线程、XML等JDK方法进行封装，组成各种Util工具类，文档地址：https://www.hutool.cn/ 分页插件1234&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"原子性、可见性、有序性","date":"2018-09-20T16:00:00.000Z","path":"Blog/Java/并发/原子性、可见性、有序性/","text":"Java内存模型是围绕着在并发过程中如何处理原子性、可见性、和有序性这三个特征来建立的。 原子性Java内存模型要求lock、unlock、read、load、assign、use、store、write这八个操作都具有原子性。 Java内存模型直接保存的原子性变量操作有read、load、assign、use、store、write；大致可认为基本数据类型（除long和double）的访问读写具备原子性。 Java内存模型还提供了lock和unlock操作来保证更大范围的原子操作，虚拟机未把lock和unlock操作直接开放给用户使用，但提供了更高层次的字节码指令monitorenter和monitorexit来隐式使用这个操作，这两个字节码指令反映到Java代码中就是同步块synchronized关键字。 可见性当一个线程修改了共享变量值，其他线程能够立即得知这个修改。Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式类实现可见性，普通变量和volatile变量都是如此。 普通变量与volatile变量区别：volatile保证了新值能立即同步到主内存，每次使用前立即从主内存刷新，保证了多线程操作时变量的可见性； 除volatile外，Java还可以通过synchronized和final关键字来实现可见性；同步块的可见性是在一个变量执行unlock操作之前，必须先把此变量同步回主内存中；final可见性是指，被final修饰的字段在构造器中一旦初始化完成，并且构造器没有this引用逃逸，在其他线程中能看见final字段的值。 有序性如果在同一线程中所有操作都是有序的，如果在一个线程中观察另一个线程所有操作都是无序的，前半句是指线程内表现为串行语义，后半句指指令重排序现象和工作内存与主内存同步延迟现象。 volatile和synchronized都能保证线程之间操作的有序性，volatile关键字本身包含了禁止指令重排序语义，而synchronized则是由一个变量在同一个时刻只允许一条线程对其进行lock操作，保证了持有同一个锁的两个同步块只能串行进入。 long和double变量的特殊规则虚拟机允许将没有被volatile修饰的64位数据的续写操作划分为两次32位操作，即允许虚拟机实现选择可以不保证64位数据类型的load、store、read、write四个操作的原子性。 若多个线程共享一个未被声明为volatile的long或double类是变量，并行读取修改，某些线程可能读取到一个既非原值，但这种情况非常罕见，且商用Java虚拟机中不会出现，Java内存模型虽然允许虚拟机不把long和double变量的读写实现为原子操作，但允许虚拟机选择把这些操作实现为具有原子性的操作。","tags":[{"name":"多线程","slug":"多线程","permalink":"https://yaoyinglong.github.io/tags/多线程/"},{"name":"Thread","slug":"Thread","permalink":"https://yaoyinglong.github.io/tags/Thread/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"线程安全实现方式","date":"2018-09-20T16:00:00.000Z","path":"Blog/Java/并发/线程安全实现方式/","text":"互斥同步同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个线程使用（或者是一些，使用信号量的时候），互斥是实行同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。互斥是因，同步是果，互斥是方法，同步是目的。 Java中最基本的互斥同步手段是使用synchronized关键字，synchronized关键字编译后，会在同步代码块前后分别形成monitorenter和monitorexit字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。若synchronized明确指定了对象参数，那就是这个对象的reference，若没有明确指定，就根据synchronized修饰的是实例方法还是类方法，则取对应的对象实例或Class对象来作为锁对象。 虚拟机规范要求，执行monitorenter指令时，首先尝试获取对象的锁，若对象没有被锁定或当前线程已经拥有这个对象的锁，将锁的计数器加一，执行monitorexit指令时将锁计数器减一，当计数器为零时锁被释放。若获取对象锁失败，当前线程阻塞等待，直到对象锁被另一个线程释放。 synchronized同步块对同一条线程是可重入的，不会将自己死锁。同步块在已进入的线程执行完成之前，会阻塞后面其他线程的进入。Java线程是映射到操作系统原生线程上的，阻塞或唤醒线程都需要操作系统帮忙，需要从用户状态转换到核心态中，因此转态转换需要耗费很多处理器时间。 虚拟机自身进行了一些优化，在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁地切入到核心态。 除了synchronized关键字外还可以使用java.lang.concurrent包中的重入锁ReentrantLock来实现同步，基本用法上ReentrantLock与synchronized类似都具备一样的线程重入特性，只是写法上有些许区别，ReentrantLock表现为API层面的互斥锁（lock()和unlock()方法配合try/finally语句来完成），而synchronized表现为原生语法层面的互斥锁。相比synchronized，ReentrantLock增加了等待可中断、公平锁和锁绑定多个条件。 等待可中断：指当持有锁的线程长期不释放时，正在等待的线程可选择放弃等待，改为处理其他事情； 公平锁：指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁，反之则为非公平锁；synchronized是非公平锁，ReentrantLock默认也是非公平锁，但可通过带布尔值构造函数要求使用公平锁。 锁绑定多个条件：指ReentrantLock对象能同时绑定多个Condition对象，在synchronized中所对象的wait()和notify()或notifyAll()方法能实现一个隐含条件，若与多于一个关联条件需要额外添加锁，而ReentrantLock只需要多次调用newCondition()方法。 JDK1.5下synchronized吞吐量下降非常严重，而ReentrantLock能基本保持在用一个比较稳定的水平。JDK1.6及之后synchronized与ReentrantLock性能基本上完全持平，提倡优先考虑使用synchronized进行同步。 互斥同步最主要的问题是进行线程阻塞和唤醒所带来的性能问题，因此也称为阻塞同步，互斥同步属于一种悲观并发策略。 非阻塞同步非阻塞同步是一种基于冲突检测的乐观并发策略，先进行操作，若没有其他线程争用共享数据操作成功，若共享数据有争用产生了冲突，再采取其他补偿措施，最常见的补偿措施就是不断重试直到成功。但乐观并发策略需要硬件指令集的发展才能进行，因为操作和冲突检测两个步骤具备原子性需要硬件来保证。常用硬件指令有： 测试并设置（Test-and-Set） 获取并增加（Fetch-and-Increment） 交换（Swap） 比较并交换（Compare-and-Swap，CAS） 加载链接/条件存储（Load-Linked/Store-Conditional，LL/SC） CAS指令需要三个操作，分别是内存位置、旧预期值和新值。CAS指令在执行时，当且仅当内存位置符合旧预期值时，处理器用新值更新内存位置的值，否则不执行更新，但无论是否更新内存位置，都返回内存位置的旧值，该处理过程是一个原子操作。 在JDK1.5后才能使用CAS操作，该操作由sun.misc.Unsafe类中的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供，虚拟机内部对这些方法做了特殊处理，即时编译出来的结果是一条平台相关的处理器CAS指令，没有方法调用过程。 但Unsafe类不提供给用户程序调用，若不采用反射只能通过其他Java API间接使用，如J.U.C包中的整数原子类，其中的compareAndSet()和compareAndIncrement()等方法都使用了Unsafe类的CAS操作。 CAS并不完美，存在一个ABA问题的逻辑漏洞，J.U.C包为了解决该问题，提供了一个带标记的原子引用类AtomicStampedReference通过控制变量值的版本来保证CAS正确性。但比较鸡肋，ABA问题大部分情况不会影响正确性，若要解决ABA问题用互斥同步可能更高效。 无同步方案要保证线程安全，并不是一定要进行同步，两者没有因果关系。 可重入代码也加纯代码，能在代码执行的任何时刻中断，转而执行另一段代码，包括递归调用其本身，在控制权返回后原来的程序不会出现任何错误。所有的可重入代码都是线程安全的，相对线程安全来说，可重入性是更根本的特性，但并非所有线程安全的代码都是可重入的。 可重入代码共性：不依赖存储在堆上的数据和公用的系统资源、用到的状态量都是由参数传入、不调用非可重入方法等。 可重入性简单判定原则：若一个方法返回结果可预测，输入相同的数据就能返回相同的结果。 线程本地存储，一段代码所需要的数据必须与其他代码共享，且共享数据的代码能保证在同一个线程中执行，能把共享数据的可见范围限制在同一个线程内。 常见的符合线程本地存储的条件的有：大部分使用消费队列的架构模式、web交互模型中的一个请求对应一个服务器线程。 若变量要被多个线程访问，可使用volatile关键字声明为易变的，若只被某个线程独享，可使用java.lang.ThreadLocal类来实现线程本地存储功能，每个线程的Thread对象中都有一个ThreadLocalMap对象。","tags":[{"name":"多线程","slug":"多线程","permalink":"https://yaoyinglong.github.io/tags/多线程/"},{"name":"Thread","slug":"Thread","permalink":"https://yaoyinglong.github.io/tags/Thread/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"线程安全","date":"2018-09-20T16:00:00.000Z","path":"Blog/Java/并发/线程安全/","text":"Java中各种操作共享数据按照线程安全的安全程度由强至弱分为不可变、绝对线程安全、相对线程安全、线程兼容、线程对立； 不可变不可变的对象一定是线程安全的，只要一个不可变对象被正确构建，没有this引用逃逸，其外部可见状态永远不会改变；Java中符合不可变要求的类型：java.lang.String、枚举类型、java.lang.Number的部分子类（如Long和Double等数值包装类型，BigInteger和BigDecimal等大数据类型），同为Number子类型的原子类AtomicInteger和AtomicLong并非不可变； 若共享数据是基本数据类型，只要在定义时使用final关键字修饰就可以保证是不可变的； 若共享数据是一个对象，保证对象的行为不会对其状态产生任何影响，保证对象行为不影响自己状态的途径有很多种，最简单的方式是将对象中带有状态的变量声明为final； 绝对线程安全一个类要达到不管运行时环境如何，调用者不需要任何额外同步措施通常需要付出很大的代价；Java中标注自己是线程安全的类大多数都不是绝对线程安全的。 代码示例待补充…… 相对线程安全通常意义上的线程安全，它保证对这个对象单独操作是线程安全的，调用时不需要做额外的保障措施，但对一些特定顺序的连续操作，就可能需要在调用端使用额外的同步手段来保证调用的正确性。大部分线程安全的类属于这种类型，例如：Vector、HashTable、Collections的synchronizedCollection()方法包装的集合等； 线程兼容指对象本身不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。 线程对立指无论调用端是否采取同步措施，都无法再多线程环境中并发使用的代码。例：Thread类的suspend()和resume()方法，两个线程同时持有一个线程对象，一个尝试中断一个尝试恢复，并发时无论是否进行同步，目标线程都存在死锁风险。常见还有System.setIn()、System.setOut()和System.runFinalizersOnExit()等","tags":[{"name":"多线程","slug":"多线程","permalink":"https://yaoyinglong.github.io/tags/多线程/"},{"name":"Thread","slug":"Thread","permalink":"https://yaoyinglong.github.io/tags/Thread/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"SpringMvc异步原理及实现","date":"2018-08-05T16:00:00.000Z","path":"Blog/Spring/SpringMvc异步/","text":"在实际的项目中，可能会用到HTTP异步请求方式来提高系统的吞吐量。 同步请求客户端发起同步HTTP请求时，线程进入等待状态，直到接受到一个response对象或者请求超时状态 ，往返WEB服务器的过程： HTTP请求在经过DNS服务器的域名解析，到Nginx反向代理转发到我们的WEB服务器（servlet容器，Tomcat），WEB服务器会启动一个请求处理线程来处理请求，完成资源分配处理之后，线程起调后端的处理线程，同时WEB服务器的线程将会进入阻塞状态，直到后端的线程处理完毕，WEB服务器释放请求处理线程的资源，同时返回response对象，客户端接收到response对象，整个请求完成。 若后端处理服务器中进行了大量的IO操作，数据库操作，或者跨网调用等耗时操作，导致请求处理线程进入长时间的阻塞。因为WEB服务器的请求处理线程条个数是有限的，如果同时大量的请求阻塞在WEB服务器中，新的请求将会处于等待状态，甚至服务不可用，connection refused。 异步请求Servlet3的异步web机制的引入，改造接口服务，可以让请求线程(IO线程)和业务处理线程分开，进而对业务进行线程池隔离。 解决tomcat线程池资源消耗，频繁gc，高io，堆内存上升 。还可以根据业务重要性进行业务分级，然后再把线程池分级 。还可以根据这些分级做其它操作比如监控和降级处理。 请求处理线程对后台处理的调用使用了invoke的方式，调invoke方法后直接返回不等待，请求处理线程就释放了，它可以接着去处理别的请求，当后端处理完成后，会钩起一个回调处理线程来处理调用的结果，这个回调处理线程跟请求处理线程也许都是线程池中的某个线程，相互间可以完全没有关系，由这个回调处理线程向浏览器返回内容。 带来的改进是显而易见的，请求处理线程不需要阻塞了，它的能力得到了更充分的使用，带来了服务器吞吐能力的提升。下图是异步请求过程图： Servlet3异步流程 接收到request请求之后，由Tomcat工作线程从HttpServletRequest中获得一个异步上下文AsyncContext对象，然后由Tomcat工作线程把AsyncContext对象传递给业务处理线程，同时Tomcat工作线程归还到工作线程池，这一步就是异步开始。在业务处理线程中完成业务逻辑的处理，生成response返回给客户端。在Servlet3.0中虽然处理请求可以实现异步，但是InputStream和OutputStream的IO操作还是阻塞的，当数据量大的request body 或者 response body的时候，就会导致不必要的等待。从Servlet3.1以后增加了非阻塞IO，需要tomcat8.x支持。 Servlet3的异步使用步骤： 声明Servlet，增加asyncSupported属性，开启异步支持。@WebServlet(urlPatterns = &quot;/simpleAsync&quot;, asyncSupported = true) 通过request获取异步上下文AsyncContext。AsyncContext asyncCtx = request.startAsync(); 开启业务逻辑处理线程，并将AsyncContext 传递给业务线程。executor.execute(new AsyncRequestProcessor(asyncCtx, secs)); 在异步业务逻辑处理线程中，通过asyncContext获取request和response，处理对应的业务。 业务逻辑处理线程处理完成逻辑之后，调用AsyncContext 的complete方法。asyncContext.complete();从而结束该次异步线程处理。 同步异步对比实际写了一个固定延时10秒的Demo，Tomcat的参数设置如下： 1234tomcat: max-threads: 5 accept-count: 10 max-connections: 1000 在500的并发下分别对同步和异步请求进行了测试，通过MBean对Tomcat参数进行监控 同步情况下currentThreadsBusy参数始终是与最大线程数一致，说明线程一致未释放，会导致请求一致阻塞 异步情况由于后台是异步处理的线程马上就释放了，故currentThreadsBusy基本上都是0。在某些情况下能够极大的提升系统吞吐量。 将Tomcat业务线程池的压力转移到系统自定义线程池中。使得更加可控，即使变更应用服务器系统任然兼容。 Spring异步Spring MVC 3.2开始引入了基于Servlet 3的异步请求处理。相比以前，控制器方法已经不一定需要返回一个值，而是可以返回一个java.util.concurrent.Callable对象，并通过Spring MVC所管理的线程来产生返回值。 同时Servlet容器的主线程则可以退出并释放其资源了，同时也允许容器去处理其他的请求。通过一个TaskExecutor，Spring MVC可以在另外的线程中调用Callable。当Callable返回时，请求再携带Callable返回的值，再次被分配到Servlet容器中恢复处理流程。 另一个选择，是让控制器方法返回一个DeferredResult实例。该场景下，返回值可由任何一个线程产生，也包括那些不是由Spring MVC管理的线程。 返回值可能是为了响应某些外部事件所产生的，比如一条JMS的消息，一个计划任务 。 Callable异步请求 控制器先返回一个Callable对象 Spring MVC开始进行异步处理，并把该Callable对象提交给另一个独立线程的执行器TaskExecutor处理 DispatcherServlet和所有过滤器都退出Servlet容器线程，但此时方法的响应对象仍未返回 Callable对象最终产生一个返回结果，此时Spring MVC会重新把请求分派回Servlet容器，恢复处理 DispatcherServlet再次被调用，恢复对Callable异步处理所返回结果的处理 DeferredResult异步请求 控制器先返回一个DeferredResult对象，并把它存取在内存（队列或列表等）中以便存取 Spring MVC开始进行异步处理 DispatcherServlet和所有过滤器都退出Servlet容器线程，但此时方法的响应对象仍未返回 由处理该请求的线程对 DeferredResult进行设值，然后Spring MVC会重新把请求分派回Servlet容器，恢复处理 DispatcherServlet再次被调用，恢复对该异步返回结果的处理 SpringMvc异步实现方式一： 12345678910111213141516171819202122public Callable&lt;String&gt; process(HttpServletResponse response) &#123; return () -&gt; &#123; response.setContentType(\"text/plain;charset=utf-8\"); response.getWriter().write(\"响应内容\"); response.getWriter().close(); return null; &#125;;&#125;// taskService是一个@Service注解类public Callable&lt;Map&lt;String, Object&gt;&gt; process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return callable;&#125;// taskService是一个@Service注解类public Callable&lt;Map&lt;String, Object&gt;&gt; process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = () -&gt; &#123; return taskService.execute(); &#125;; return callable;&#125; SpringMvc异步实现方式二： 1234567891011// taskService是一个@Service注解类public WebAsyncTask process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return new WebAsyncTask&lt;&gt;(20000, callable);&#125;// taskService是一个@Service注解类public WebAsyncTask process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return new WebAsyncTask&lt;&gt;(callable);&#125; SpringMvc异步实现方式三： 123456public DeferredResult&lt;Map&lt;String, Object&gt;&gt; process() &#123; DeferredResult&lt;Map&lt;String, Object&gt;&gt; deferredResult = new DeferredResult&lt;&gt;(); CompletableFuture.supplyAsync(taskService::execute) .whenCompleteAsync((result, throwable) -&gt; deferredResult.setResult(result)); return deferredResult;&#125; 方式一和方式二Spring返回的Callable被RequestMappingHandlerAdapter拦截，使用SimpleAsyncTaskExecutor线程池处理，每当任务被提交到此线程池时，线程池产生一个新的线程去执行Callable中的代码， 每次都产生新的线程而且没有上上限(默认没有上限的，可以设置concurrencyLimit属性来设置线程数的大小) 但：SimpleAsyncTaskExecutor 线程池性能不好，可使用自定义的线程池来代替。 方式三使用的是CompletableFuture.supplyAsync，在completablefuture的supplyasync方法将在ForkJoinPool池运行任务。也可以使用任何其他的线程池来执行。 若不自定线程池，MvcAsync线程数会飙涨： 自定义MVC Callable线程池： 123456789101112131415161718192021222324252627282930313233@Bean@ConfigurationProperties(prefix = \"spring.task.mvcPool\")public TaskPoolConfig mvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Beanpublic AsyncTaskExecutor mvcTaskExecutor(TaskPoolConfig mvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(mvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(mvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(mvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(mvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( mvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(mvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Mvc-Thread-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic WebMvcConfigurerAdapter webMvcConfigurerAdapter(AsyncTaskExecutor mvcTaskExecutor) &#123; return new WebMvcConfigurerAdapter() &#123; @Override public void configureAsyncSupport(AsyncSupportConfigurer configurer) &#123; configurer.setTaskExecutor(mvcTaskExecutor); super.configureAsyncSupport(configurer); &#125; &#125;;&#125; 请求由Tomcat业务线程池转移到系统自定义线程池中，从下面的示例中可以明显得看出Tomcat的处理线程非常快的就结束了，而由自定义线程池中的线程去处理任务，等任务结束后再由Tomcat线程响应给用户： 1234567891011121314151617[nio-8011-exec-4] c.i.ent.controller.DashboardController : async start[nio-8011-exec-4] c.i.ent.controller.DashboardController : async end[nio-8011-exec-3] c.i.ent.controller.DashboardController : async start[nio-8011-exec-3] c.i.ent.controller.DashboardController : async end[nio-8011-exec-5] c.i.ent.controller.DashboardController : async start[nio-8011-exec-5] c.i.ent.controller.DashboardController : async end[nio-8011-exec-2] c.i.ent.controller.DashboardController : async start[nio-8011-exec-2] c.i.ent.controller.DashboardController : async end[ Mvc-Thread-4] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-4执行进度:task：0/10[ Mvc-Thread-2] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-2执行进度:task：0/10[ Mvc-Thread-7] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-7执行进度:task：0/10[ Mvc-Thread-5] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-5执行进度:task：0/10[ Mvc-Thread-3] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-3执行进度:task：0/10[ Mvc-Thread-1] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-1执行进度:task：0/10[ Mvc-Thread-6] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-6执行进度:task：0/10[ Mvc-Thread-8] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-8执行进度:task：0/10[ Mvc-Thread-9] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-9执行进度:task：0/10 异步多线程池在实际中可能会用到不同的异步接口使用不同的线程池，以下代码是自定义多个线程池给不同的接口使用的示例代码： 多线程池的配置如下，这里做了快、中、慢三个线程池： 1234567891011121314151617181920spring: task: slowMvcPool: corePoolSize: 10 maxPoolSize: 20 queueCapacity: 125 keepAliveSeconds: 60 allowCoreThreadTimeOut: true middleMvcPool: corePoolSize: 20 maxPoolSize: 40 queueCapacity: 250 keepAliveSeconds: 60 allowCoreThreadTimeOut: true fastMvcPool: corePoolSize: 40 maxPoolSize: 80 queueCapacity: 500 keepAliveSeconds: 60 allowCoreThreadTimeOut: true 通过@Bean方式将各个线程池的参数注入到Spring中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Bean@ConfigurationProperties(prefix = \"spring.task.fastMvcPool\")public TaskPoolConfig fastMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Bean@ConfigurationProperties(prefix = \"spring.task.middleMvcPool\")public TaskPoolConfig middleMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Bean@ConfigurationProperties(prefix = \"spring.task.slowMvcPool\")public TaskPoolConfig slowMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Beanpublic AsyncTaskExecutor slowMvcTaskExecutor(TaskPoolConfig slowMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(slowMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(slowMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(slowMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(slowMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( slowMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(slowMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Slow-Mvc-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic AsyncTaskExecutor middleMvcTaskExecutor(TaskPoolConfig middleMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(middleMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(middleMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(middleMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(middleMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( middleMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(middleMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Middle-Mvc-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic AsyncTaskExecutor fastMvcTaskExecutor(TaskPoolConfig fastMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(fastMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(fastMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(fastMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(fastMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( fastMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(fastMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Fast-Mvc-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125; 在Controller层中使用自定义的线程池，WebAsyncTask支持多种方式的自定义线程池的使用，可以通过下线程池在Spring中的Bean的名称，也可以直接注入线程池Bean，WebAsyncTask可以设置Timeout以及通过onTimeout方法在超时时响应内容，在使用时最好设置，如不设置如果接口超时会抛出AsyncRequestTimeoutException异常该异常比较难处理： 1234567891011121314151617181920212223242526272829303132333435@GetMapping(\"/slowAsyncTask\")public WebAsyncTask slowAsyncTask(HttpServletResponse response, AsyncTaskExecutor slowMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, slowMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(\"/middleAsyncTask\")public WebAsyncTask middleAsyncTask(HttpServletResponse response, AsyncTaskExecutor middleMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, middleMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(\"/fastAsyncTask\")public WebAsyncTask fastAsyncTask(HttpServletResponse response, AsyncTaskExecutor fastMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, fastMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(\"/fastAsyncTask\")public WebAsyncTask fastAsyncTask(HttpServletResponse response) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, \"fastMvcTaskExecutor\", callable); return asyncTask;&#125; Servlet3非阻塞IOServlet3.1以后增加了非阻塞IO实现，需要Tomcat8.x以上支持。 非阻塞 IO 仅对在 Servlet 中的异步处理请求有效，否则当调用 ServletInputStream.setReadListener或ServletOutputStream.setWriteListener方法时将抛出IllegalStateException。Servlet3的非阻塞IO是对Servlet3异步的增强。Servlet3的非阻塞是利用java.util.EventListener的事件驱动机制来实现的。 Servlet3.1的非阻塞IO从下面图中可以看出是面对InputStream 和 OutPutStream流的，这里的非阻塞IO跟我们常说的JDK NIO不是一个概念，Servlet3.1的非阻塞是同jdk的事件驱动机制来实现。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"Servlet3.x","slug":"Servlet3-x","permalink":"https://yaoyinglong.github.io/tags/Servlet3-x/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"Tomcat工作原理","date":"2018-08-01T16:00:00.000Z","path":"Blog/中间件/Tomcat/Tomcat工作原理/","text":"Tomcat 的总体结构： Connector 和 Container 是Tomcat 两个核心组件。Connector 主要负责对外交流 ，Container 主要处理 Connector 接受的请求，主要是处理内部事务 。Service 只是在 Connector 和 Container 外面多包一层，把它们组装在一起，向外面提供服务，一个 Service 可以设置多个 Connector，但是只能有一个 Container 容器。 在使用tomcat时，经常会遇到连接数、线程数之类的配置问题 ，在此之前必须先了解Tomcat的连接器Connector。 Connector的主要功能是接收客户端发送的TCP连接请求，创建Request和Response对象用于和请求端交换数据；然后产生一个线程来处理这个请求并把产生的 Request 和 Response 对象传给处理这个请求的线程，处理这个请求的线程就是 Container 组件要做的事了。 可以说，Servlet容器处理请求，是需要Connector进行调度和控制的，Connector是Tomcat处理请求的主干，因此Connector的配置和使用对Tomcat的性能有着重要的影响 。 Connector在处理HTTP请求时，会使用不同的protocol。 典型的protocol包括BIO、NIO和APR （Tomcat7中支持这3种，Tomcat8增加了对NIO2的支持，而到了Tomcat8.5和Tomcat9.0，则去掉了对BIO的支持）BIO是Blocking IO，顾名思义是阻塞的IO；NIO是Non-blocking IO，则是非阻塞的IO。而APR是Apache Portable Runtime，是Apache可移植运行库，利用本地库可以实现高可扩展性、高性能；Apr是在Tomcat上运行高并发应用的首选模式，但是需要安装apr、apr-utils、tomcat-native等包。 Connector使用哪种protocol，可以通过connector元素中的protocol属性进行指定 ，指定的protocol取值及对应的协议如下： HTTP/1.1：默认值，使用的协议与Tomcat版本有关 org.apache.coyote.http11.Http11Protocol：BIO org.apache.coyote.http11.Http11NioProtocol：NIO org.apache.coyote.http11.Http11Nio2Protocol：NIO2 org.apache.coyote.http11.Http11AprProtocol：APR Tomcat7自动选取使用BIO或APR（如果找到APR需要的本地库，则使用APR，否则使用BIO） ，Tomcat8自动选取使用NIO或APR（如果找到APR需要的本地库，则使用APR，否则使用NIO），在SpringBoot中可以通过如下方式制定Protocol： 12345678@Beanpublic EmbeddedServletContainerFactory embeddedServletContainerFactory() &#123; TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory = new TomcatEmbeddedServletContainerFactory(); tomcatEmbeddedServletContainerFactory .setProtocol(\"org.apache.coyote.http11.Http11Nio2Protocol\"); return tomcatEmbeddedServletContainerFactory;&#125; BIO与NIO无论是BIO，还是NIO，Connector处理请求的大致流程是一样的： 当客户端向服务器发送请求时，如果客户端与OS完成三次握手建立了连接，则OS将该连接放入accept队列，Connector在accept队列中接收连接，在连接中获取请求的数据生成request；调用servlet容器处理请求；返回response。 在BIO实现的Connector中，处理请求的主要实体是JIoEndpoint对象。JIoEndpoint维护了Acceptor和Worker：Acceptor接收socket，然后从Worker线程池中找出空闲的线程处理socket，如果worker线程池没有空闲线程，则Acceptor将阻塞。其中Worker是Tomcat自带的线程池，如果通过Executor配置了其他线程池，原理与Worker类似。 在NIO实现的Connector中，处理请求的主要实体是NIoEndpoint对象。NIoEndpoint中除了包含Acceptor和Worker外，还是用了Poller，处理流程如下： Acceptor接收socket后，不是直接使用Worker中的线程处理请求，而是先将请求发送给了Poller，而Poller是实现NIO的关键。Acceptor向Poller发送请求通过队列实现，使用了典型的生产者-消费者模式。在Poller中，维护了一个Selector对象；当Poller从队列中取出socket后，注册到该Selector中；然后通过遍历Selector，找出其中可读的socket，并使用Worker中的线程处理相应请求。与BIO类似，Worker也可以被自定义的线程池代替。 通过上述过程可以看出，在NIoEndpoint处理请求的过程中，无论是Acceptor接收socket，还是线程处理请求，使用的仍然是阻塞方式；但在“读取socket并交给Worker中的线程”的这个过程中，使用非阻塞的NIO实现，这是NIO模式与BIO模式的最主要区别。 关键参数acceptCount、maxConnections、maxThreadsacceptCountaccept队列的长度；当accept队列中连接的个数达到acceptCount时，队列满，进来的请求一律被拒绝。默认值是100。 maxConnectionsTomcat在任意时刻接收和处理的最大连接数。当Tomcat接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomcat接收的连接数小于maxConnections。如果设置为-1，则连接数不受限制。 虽然tomcat同时可以处理的连接数目是maxConnections，但服务器中可以同时接收的连接数为maxConnections + acceptCount 默认值与连接器使用的协议有关：NIO的默认值是10000，APR/native的默认值是8192，而BIO的默认值为maxThreads（如果配置了Executor，则默认值是Executor的maxThreads）。 maxThreads请求处理线程的最大数量，Tomcat7和8默认值都是200。如果该Connector绑定了Executor，这个值会被忽略，因为该Connector将使用绑定的Executor，而不是内置的线程池来执行任务。 实测数据下面是对这几个参数的实测数据，测试的是同一个接口，接口固定sleep 10秒，最后两列是接口的平均响应时间（这里说所的同步异步是指在Controller层中接口是否使用Servlet3.0提供的异步HTTP请求）： acceptCount maxConnections maxThreads 并发 同时处理线程数 同步结果 异步结果 1 9 1 10 1 55263 11130 1 9 2 10 2 30044 11611 1 9 3 10 3 22329 11207 1 9 4 10 4 18027 11303 1 9 5 10 5 15412 11111 9 1 1 10 1线程1请求 55087 55324 9 1 2 10 2线程1请求 50261 55151 9 1 3 10 3线程1请求 55082 45471 9 1 4 10 4线程1请求 55276 55156 9 1 5 10 5线程1请求 55074 55314 9 3 1 10 同步1，异步1线程3请求 55289 22082 9 3 2 10 同步2，异步2线程3请求 30046 22266 9 3 3 10 3线程3请求 22235 22089 9 3 4 10 4线程3请求 22292 22034 9 3 5 10 5线程3请求 22249 22083 以上测试出的结果，可以很明显的看出当maxConnections设置为1时，accept队列中的线程会一直阻塞着，通过控制台也可以很明显得看出不论时同步还是异步请求，不论maxThreads设置为几个，处理请求的线程始终为一个。由此可看出tomcat中能够同时被处理的请求数是maxThreads和maxConnections中的较小者。 当正在被处理的请求数量达到maxConnections时，再过来的请求会被接受（TCP连接建立成功），但是没有被处理，被阻塞到serversocket上，接受并被阻塞的socket请求数的最大值为acceptCount；当阻塞达到acceptCount的最大数目时，在发送过来的请求会建立连接refuse，对客户端而言，返回连接被拒绝的错误。 tomcat能接受的最大请求数量为maxConnections，加上acceptCount的数量，其中maxThreads和maxConnections中的较小者是正在被处理的请求数量，acceptCount为等待被处理的请求数量，超过这两者之和的请求会被拒绝。 对数据进行了Mbean监控发现，并发请求进来时先使用maxConnections缓冲队列，当maxConnections队列满了后，再使用acceptCount队列，当acceptCount队列满了后，则多的请求全部拒绝。 该使用的Tomcat配置如下，使用Jmeter做并发测试工具，并发量为300： 1234tomcat: max-threads: 200 accept-count: 100 max-connections: 10000","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://yaoyinglong.github.io/categories/中间件/"},{"name":"Tomcat","slug":"中间件/Tomcat","permalink":"https://yaoyinglong.github.io/categories/中间件/Tomcat/"}]},{"title":"Spring Gzip压缩","date":"2018-07-15T16:00:00.000Z","path":"Blog/Spring/Spring Gzip压缩/","text":"输出Gzip压缩在SpringBoot项目中启用输出Gzip压缩，需要添加如下配置。 123456789101112server: compression: enabled: true min-response-size: 2048 mime-types: - application/json - application/x-www-form-urlencoded - application/xml - text/html - text/xml - text/plain - application/javascript 是否压缩取决于数据大小是否达到min-response-size配置的值且请求方在request header中是否添加Accept-Encoding:gzip,deflate, 一般浏览器会在请求头中默认添加该header。 若提供接口给外部服务，若有使用Nginx，可以通过Nginx反向代理转发到我们的WEB服务器时在请求头中添加Accept-Encoding:gzip,deflate。 验证GZIP是否生效 通过HttpClient的方法验证 12345678910111213141516HttpClient httpClient = new DefaultHttpClient();HttpGet get = new HttpGet(uri);ResponseHandler&lt;String&gt; responseHandler = new BasicResponseHandler();try &#123; get.setHeader(\"Accept-Encoding\", \"gzip,deflate\"); String content = httpClient.execute(get, responseHandler); System.out.println(content); // 如果gzip生效，会打印出乱码 HttpResponse response = httpClient.execute(get); long cLen = response.getEntity().getContentLength(); System.out.println(cLen); // 如果gzip生效，长度值为-1或比原始大小小很多的值&#125; catch(Exception e) &#123; // ignore ...&#125; finally &#123; httpClient.getConnectionManager().shutdown();&#125; 通过浏览器调试工具对比Network中请求的Size 输入Gzip压缩对于请求体比较大的接口，通常会采用压缩的方式进行传输。这里对Gzip踩坑进行一下总结。 对于即支持Gzip压缩调用，也支持非压缩调用的接口，通常做法是在请求头中放入一个字段来判断该字段的值来确定所走流程。通常做法可能很多人会采用标准的请求头参数Content-Encoding，在直接调用不仅过zuul的服务中是没有问题的。但是在有zuul的服务中，zuul默认会将请求头中的Content-Encoding移除，从而导致获取不到Content-Encoding该字段，从而走非Gzip的流程导致bug，在该种情况下最好使用自定义的请头代替标准的请去头。StackOverFlow参考 其次对于程序对Gzip的处理，可能对于很多接口一般都可能是使用@RequestBody将请求体中的内容直接取出来，客户端使用如下方式进行压缩，再将压缩后的内容通过StringEntity放入HttpPost的请求体中： 12345678910public static String compress(String param) throws IOException &#123; if (null == param || param.length() &lt;= 0) &#123; return param; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(param.getBytes(\"utf-8\")); gzip.close(); return out.toString(\"ISO-8859-1\");&#125; 在服务端将通过@RequestBody获取到的请求体通过如下方式解压出来使用。 12345678910111213141516public static String unCompress(String paramGzip) throws IOException &#123; if (null == paramGzip || paramGzip.length() &lt;= 0) &#123; return paramGzip; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(paramGzip.getBytes(\"ISO-8859-1\")); GZIPInputStream gzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n = 0; while ((n = gzip.read(buffer)) &gt;= 0)&#123; out.write(buffer, 0, n); &#125; return out.toString(\"utf-8\");&#125; 以上方式的问题在于不通用，如果说使用Python或者其他语言来，或者说如JMeter和LoadRunner之类的工具请求，基本上百分之百会乱码导致请求失败。 优化方案，直接从HttpServletRequest中获取InputStream从而获取到字节数组。并将字节数组解压缩，最后将解压缩后的字节数组转成字符串进行处理。 123456789101112131415public static byte[] unCompressBytes(byte[] bytes) throws IOException &#123; if (null == bytes || bytes.length &lt;= 0) &#123; return bytes; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); GZIPInputStream gzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n = 0; while ((n = gzip.read(buffer)) &gt;= 0) &#123; out.write(buffer, 0, n); &#125; gzip.close(); return out.toByteArray();&#125; 对于Java客户端的请求，可以直接使用GzipCompressingEntity标准的请求方式来调用： 12345678HttpPost httpPost = new HttpPost(url);httpPost.setHeader(\"Content-Type\", \"application/json;charset=UTF-8\");httpPost.setHeader(\"AA-Content-Encoding\", \"gzip\");StringEntity entity = new StringEntity(param, \"UTF-8\");httpPost.setEntity(new GzipCompressingEntity(entity));HttpResponse httpResponse = httpClient.execute(httpPost); 当然也可以自己来压缩调用，通过compressByte方法将数据压缩成字节流，再将字节流直接放入到HttpPost的请求体中，中间不要做任何转码： 1234567891011121314151617181920public static byte[] compressByte(String param) throws IOException &#123; if (null == param || param.length() &lt;= 0) &#123; return new byte[0]; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(param.getBytes(StandardCharsets.UTF_8)); gzip.close(); return out.toByteArray();&#125;HttpPost httpPost = new HttpPost(url);httpPost.setHeader(\"Content-Type\", \"application/json;charset=UTF-8\");httpPost.setHeader(\"AA-Content-Encoding\", \"gzip\");ByteArrayEntity entity = new ByteArrayEntity(bytes);httpPost.setEntity(new GzipCompressingEntity(entity));HttpResponse httpResponse = httpClient.execute(httpPost); 对于Python的调用也很简单： 12345678headers = &#123; \"Content-Type\": \"application/json;charset=utf-8\", \"AA-Content-Encoding\": \"gzip\"&#125;dataGzip = gzip.compress(json.dumps(data).encode(\"utf-8\"))response = requests.post(url=url, headers=headers, data=dataGzip, params=params)","tags":[{"name":"Gzip，Spring","slug":"Gzip，Spring","permalink":"https://yaoyinglong.github.io/tags/Gzip，Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/categories/Spring/"}]},{"title":"MySQL常用SQL总结","date":"2018-06-12T16:00:00.000Z","path":"Blog/DB/MySQL常用SQL总结/","text":"查看索引1show index from compliance_page_info; 创建联合唯一性索引1234567alter table compliance_page_info add unique index unique_index_name(uuid, type);alter table compliance_page_info add unique unique_index_name(uuid, type);alter table compliance_page_info add unique key unique_index_name(uuid, type);alter table compliance_page_info add primary key unique_index_name(uuid, type);create unique index unique_index_name on compliance_page_info(uuid, type);# 创建唯一性索引时表中存在重复记录，删除重复记录后创建唯一性索引alter ignore table compliance_page_info add unique unique_index_name(uuid, type); 创建全文索引1alter table compliance_page_info add fulltext(uuid); 删除索引123alter table compliance_page_info drop index table_unique_index;drop index unique_index_name on compliance_page_info;alter table compliance_page_info drop primary key; 当记录不存在时Insert，存在时update1234insert into compliance_page_info (uuid, total_page, total_count, type) values ('d60bc0d38b7a36fba07b2b9e4177d9cf', 1, 10, 'OVERVIEW-JUDGEMENT')ON DUPLICATE KEY UPDATE total_page = values(total_page), total_count = values(total_count);# 使用replace，记录存在先删除再插入（故受影响的列为2条），不存在直接插入replace into compliance_page_info (uuid, total_page, total_count, type) values ('d60bc0d38b7a36fba07b2b9e4177d9cf', 1, 10, 'OVERVIEW-JUDGEMENT') 查询数据库表结构1234select column_name, column_type, is_nullable, column_key, column_default, extra, column_commentfrom information_schema.columnswhere table_schema = 'ent_compliance' #表所在数据库 and table_name = 'third_page_info' ; #你要查的表 删除重复数据1234# 必须多嵌套一层select否则MySQL报错delete from update_log where id not in ( select * from (select min(id) from update_log group by uuid, did_or_page, type) b); 正则&amp;字符长度查询1delete from update_log where LENGTH(did_or_page) &gt; 30 or did_or_page REGEXP '[0-9]+'; 将一个表中的字段更新到另一表中1234update asset_certificate a, base_static_data b set a.certificate_type = b.code_value, a.certificate_authority = b.extend_valuewhere a.certificate_type_code = b.code_name and a.certificate_type in ('null', '-', '') or a.certificate_type is null; 关联更新123update old_product op, new_product np set np.category = op categorywhere op.name = np.name 分组查询最大ID数据12345select a.* from component a, ( select component_id, max(version) as version from component group by component_id) bwhere a.component_id = b.component_id and a.version = b.version","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"Linux常用命令","date":"2018-05-25T16:00:00.000Z","path":"Blog/杂记/Linux/Linux常用命令/","text":"source /etc/profile： 使配置文件生效ps -aux | grep java：查看进程jstat -gcutil 30996 3000 ：每3秒显示一次进程号为30996的Java进程GC情况 压缩&amp;解压tar -cvf jpg.tar *.jpg：将文件打成tar包tar -czf jpg.tar.gz *.jpg： 将文件打成tar包，并将其压缩成gziptar -cjf jpg.tar.bz2 *.jpg：将文件打成tar包，并将其压缩成bzip2tar -cZf jpg.tar.Z *.jpg：将文件打成tar包，并将其压缩成compressrar a jpg.rar *.jpg：rar格式的压缩zip jpg.zip *.jpg：zip格式的压缩 tar zxvf target.gz -C /opt：将压缩包解压到指定目录tar -xvf file.tar：解压tar包tar -xzvf file.tar.gz：解压tar.gz包tar -xjvf file.tar.bz2：解压tar.bz2包tar -xzvf file.tar.Z：解压tar.Z包unrar e file.rar：解压rar包unzip file.zip：解压zip包 问题排查倒数300行并进入实时监听文件写入模式 1tail -300f shopbase.log grep123456789101112131415161718// 文件查找grep forest f.txt // 多文件查找grep forest f.txt cpf.txt // 目录下查找所有符合关键字的文件grep 'log' /home/admin -r -n cat f.txt | grep -i shopbase // 指定文件后缀grep 'shopbase' /home/admin -r -n --include *.&#123;vm,java&#125; // 反匹配grep 'shopbase' /home/admin -r -n --exclude *.&#123;vm,java&#125; // 上匹配seq 10 | grep 5 -A 3 // 下匹配seq 10 | grep 5 -B 3 // 上下匹配，平时用这个就妥了seq 10 | grep 5 -C 3 cat f.txt | grep -c 'SHOPBASE' find1234567891011121314151617181920212223242526// 多个目录查找sudo -u admin find /home/admin /tmp /usr -name \\*.log// 大小写都匹配find . -iname \\*.txt// 当前目录下的所有子目录find . -type d// 当前目录下所有的符号链接find /usr -type l// 符号链接的详细信息 eg:inode,目录find /usr -type l -name \"z*\" -ls// 超过250000k的文件，当然+改成-就是小于了find /home/admin -size +250000k// 按照权限查询文件find /home/admin f -perm 777 -exec ls -l &#123;&#125; \\; // 1天内访问过的文件find /home/admin -atime -1 // 1天内状态改变过的文件 find /home/admin -ctime -1 // 1天内修改过的文件find /home/admin -mtime -1 // 1分钟内访问过的文件find /home/admin -amin -1 // 1分钟内状态改变过的文件 find /home/admin -cmin -1 // 1分钟内修改过的文件find /home/admin -mmin -1 查看端口被那个进程占用12345# 查看16808端口被那个进程占用lsof -i:16808 -tnetstat -tunlp|grep 16808# 干掉使用16808端口的进程kill -9 $(lsof -i:16808 -t) 查看进程占用的句柄数Too many open files问题主要指进程企图打开一个文件，或者叫句柄，但是现在进程打开的句柄已达到上限，无法打开新句柄了。 1lsof -n|awk '&#123;print $2&#125;'|sort|uniq -c|sort -nr|more","tags":[{"name":"Linux","slug":"Linux","permalink":"https://yaoyinglong.github.io/tags/Linux/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"Linux","slug":"杂记/Linux","permalink":"https://yaoyinglong.github.io/categories/杂记/Linux/"}]},{"title":"lambda常用总结","date":"2018-05-19T16:00:00.000Z","path":"Blog/Java/基础/lambda常用总结/","text":"排序在用到Stream做排序时，如果数据存在null值就会抛出空指针异常，可能最理想的方式排除空值的内容进行排序，最后将空值的内容排在最后或者最前面。 下面的示例是使用对象的时间进行排序，如果时间为空则将其排在列表最后面： 1234List&lt;Change&gt; changes = changeList.stream() .sorted(Comparator.comparing( Change::getDate, Comparator.nullsFirst(Date::compareTo)).reversed()) .collect(Collectors.toList()); 去重在很多时候会用到去重，对于实体列表的去重，在没有重写equals和hashCode方法时，要通过Lambda去重比较麻烦和不友好，因为Stream的distinct()方法不支持形如distinct(Change::getDid)这种形式的去重，我自己总结论一个稍微好一点的方式： 1234567List&lt;Change&gt; uniqueList = opList .stream() .collect(Collectors.groupingBy(Change::getDid)) .values() .stream() .flatMap(list -&gt; list.stream().limit(1)) .collect(Collectors.toList()); distinctdistinct是基于hashCode和equals工作的，且不提供按照属性对对象列表进行去重的直接实现。若想要按照对象的属性，若对对象去重需要重写对象的hashCode方法和equals方法； 若对对象列表进行去重，可以通过以下方法来实现，distinctByKey()方法返回一个使用ConcurrentHashMap来维护先前所见状态的 Predicate实例，结合filter来进行去重： 123456static &lt;T&gt; Predicate&lt;T&gt; distinctByKey(Function&lt;? super T, ?&gt; keyExtractor) &#123; Map&lt;Object,Boolean&gt; seen = new ConcurrentHashMap&lt;&gt;(); return t -&gt; seen.putIfAbsent(keyExtractor.apply(t), Boolean.TRUE) == null;&#125;list.stream().filter(distinctByKey(b -&gt; b.getName()));","tags":[{"name":"lambda","slug":"lambda","permalink":"https://yaoyinglong.github.io/tags/lambda/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"JMeter日常总结","date":"2018-04-11T16:00:00.000Z","path":"Blog/Test/JMeter日常总结/","text":"断言在对接口进行测试时，通常需要对接口调用结果进行断言，以确定接口调用是否达到预期，同时也可以在结果数中看到接口是否调用成功。响应断言和jp@gc - JSON Path Assertion是比较简单和常用的两个断言器。 在HTTP请求下添加断言 -&gt; 响应断言，可以通过不同的模式匹配规则进行匹配断言。 在HTTP请求下添加断言 -&gt; jp@gc - JSON Path Assertion。目前看来该断言器只能断言其中一个字段。 一般来说以上两种断言器已经基本够用了，如果遇到比较复杂的可以使用BeanShell断言来通过脚本进行断言。 变量提取使用通常在测试时接口需要进行鉴权，这是通过调用登录接口获取到token_id然后在调用具体接口时将token_id作为参数或者放在header中传入。这里就需要将token_id从鉴权接口的响应中提取出来，然后再使用时传入。 对于鉴权接口在JMeter中可以通过在测试计划中添加setUp Thread Group，并将线程数和循环次数设置成1，并在该线程组中添加鉴权接口的HTTP请求。可以添加常规的断言和察看结果树。也可以在线程组中添加逻辑控制器 -&gt; 仅一次控制器将鉴权接口相关类容添加至该逻辑控制器下。 目前我用到的变量提取有JSON Extractor和正则表达式提取器两种。当然还有其他的提取器，目前这两种提取器基本够用了。 JSON Extractor其实是通过XPath从JSON串中取出目标值。 正则表达式提取器当然是通过正则表达式的方式从字符串中提取目标值。 虽然将变量从响应结果中提取出来了，但是并不能直接使用。可以通过BeanShell PostProcessor将参数设置为全局变量，也可以将其存储到本地文件中使用时通过CSV Data Set Config来读取并使用。 设置成全局变量相对简单，只需要在BeanShell PostProcessor中配置${__setProperty(token_id, ${token_id},)}脚本即可。这里的print会将提取到的变量打印到cmd窗口中。在使用变量时通过${__property(token_id)}进行获取。 将变量存储到本地文件中，也是通过BeanShell PostProcessor脚本实现的，只是相对于设置全局变量复杂得多。 1234567891011121314151617181920212223242526272829import java.util.regex.Matcher; import java.util.regex.Pattern; //JMeter的内置API：prev.getResponseData()获取请求的响应内容 byte[] responseData = prev.getResponseData();//定义正则表达式需要匹配的模式提取相关变量Pattern pattern = Pattern.compile(\"\\\"token_id\\\":\\\"(.+?)\\\"\"); Matcher result = pattern.matcher(new String(responseData)); //boolean java.util.regex.Matcher.find()只要找到符合条件的就返回trueif(result.find())&#123; String tokenId += result.group(1)+\"\\r\\n\"; //导出的csv存放位置 String filePath = \"D:/test/token.txt\"; BufferedOutputStream bos = null; FileOutputStream fos = null; try &#123; File file = new File(filePath); fos = new FileOutputStream(file); bos = new BufferedOutputStream(fos); bos.write(tokenId.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (bos != null) &#123; bos.close(); &#125; if (fos != null) &#123; fos.close(); &#125; &#125;&#125; 使用时通过CSV Data Set Config来读取到配置中。 JMeter压测的坑在JMeter中通过线程组的方式进行并发压测，但是实际测试中发现，JMeter其实实际上是一个同步的方式去发送请求的，当我们同时压测几个接口时，通过聚合报告很明显的看出JMeter会等到前一个接口结束后才会请求下一个接口。 在单个接口做并发测试时，当我们的并发设置为150时，JMeter的并发请求数确实是150，但是JMeter会等到其中某个请求结束然后再补充一个请求，通俗的将若你的接口延时1分钟，JMeter在这1分钟内只会发150个请求，当其中有请求结束再往里面补充一致维持150个请求。并不能完全模拟真实场景下的高并发。 通过MBean监控Tomcat的collectionCount参数也可以明显的看出这一点： JMeter BindExecption：Address already in use：connect在Windows10环境下，通过JMeter对接口进行压测时，在100的并发下聚合报告中会出现百分之三点几的错误率，在150的并发下出现了百分之三十几的错误率，当然在不同的环境和接口响应速率下这个错误率可能会不一样。 具体原因是由于端口被占用，Windows提供给TCP/IP连接的端口为1024-5000，并且要四分钟来循环回收他们。就导致我们在短时间内跑大量的请求时将端口占满了。 解决方案： cmd中，用regedit打开注册表 在 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters下 右击parameters，添加一个新的DWORD，名字为MaxUserPort 然后双击MaxUserPort，输入数值数据为65534，基数选择十进制。 然后重启电脑！重启电脑！重启电脑！ Gzip压缩请求对于Gzip压缩请求，通常做法是添加JSR223 PreProcessor预处理程序，将请求内容进行压缩。 123456789101112import org.apache.commons.io.IOUtils;import java.util.zip.GZIPOutputStream;String bodyString = sampler.getArguments().getArgument(0).getValue();byte [] requestBody = bodyString.getBytes(\"utf-8\");ByteArrayOutputStream out = new ByteArrayOutputStream(requestBody.length);GZIPOutputStream gzip = new GZIPOutputStream(out);gzip.write(requestBody);gzip.close();sampler.getArguments().getArgument(0).setValue(out.toString(0)); 在上述代码中的getBytes(&quot;utf-8&quot;)最好加上utf-8的编码格式，否正日志可能乱码。 值得注意的是，在HTTP Request中的Content encoding中的编码方式一定不要填，否正很有可能导致乱码，从而导致请求失败。","tags":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/tags/Test/"},{"name":"JMeter","slug":"JMeter","permalink":"https://yaoyinglong.github.io/tags/JMeter/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"LoadRunner日常总结","date":"2018-04-11T16:00:00.000Z","path":"Blog/Test/LoadRunner日常总结/","text":"HTTPS请求LoadRunner对HTTPS接口进行测试时，最好加上web_set_sockets_option(&quot;SSL_VERSION&quot;,&quot;TLS&quot;)。 LoadRunner在对HTTPS接口进行请求时，可能出现Error -27778: SSL protocol error when attempting to connect with host &quot;XXX&quot; [MsgId: MERR-27778]错误。 设置Vuser -&gt; Run-time Setting找到Internet Protocol -&gt; Preferences -&gt; Advanced勾选winlnet replay instead of sockets(windows only)选项。 日志中文打印通常在请求时想看到请求参数、返回结果等数据，可以在Vuser -&gt; run-time setting -&gt; general -&gt; log勾选extended log且勾选其下的三个选项。但是这种方式不能解决中文乱码问题。 可以将中文数据通过web_reg_save_param单独提取出来lr_convert_string_encoding转码后通过lr_output_message或lr_log_message打印： 1234web_reg_save_param(\"result\", \"LB=message\\\":\\\"\", \"RB=\\\"\", LAST);// web_custom_request请求lr_convert_string_encoding(lr_eval_string(\"&#123;result&#125;\"), \"utf-8\", NULL, \"msg\");lr_output_message(\"message--------%s\",lr_eval_string(\"&#123;msg&#125;\")); 中文参数乱码通常在通过LoadRunner请求接口时，若请求参数中存在中文参数，虽然在Replay Log中打印的内容可能并没有乱码，但是请求到服务器可能就乱码了，从而导致接口请求失败。 为了解决中文参数导致的中文乱码，可以将中文参数提取出来通过lr_convert_string_encoding进行转码后使用。首先通过通过lr_save_string将中文参数参数化，也可以到Parameter List进行设置。然后将参数转成UTF-8，最后将参数转成URL编码。 123456lr_save_string(\"奚姝\",\"name\");lr_convert_string_encoding(lr_eval_string(\"&#123;name&#125;\"), LR_ENC_SYSTEM_LOCALE, LR_ENC_UTF8, \"encode_name\");lr_save_string(lr_eval_string(\"&#123;encode_name&#125;\"),\"name\");web_convert_param(\"name\", \"SourceEncoding=PLAIN\", \"TargetEncoding=URL\", LAST);lr_log_message(\"参数化结果name：%s\", lr_eval_string(\"&#123;name&#125;\")); Web请求LR可以通过web_custom_request函数发送POST或者GET请求。对于普通POST请求，未将请求参数放到RequestBody中的，可以将参数在Body中通过&amp;符号进行拼接。 12345web_custom_request(\"web_custom_request\",\"URL=&#123;url&#125;\",\"Method=POST\", \"Resource=0\",\"RecContentType=Application/json\",\"Referer=\",\"Mode=HTML\", \"EncType=application/x-www-form-urlencoded;charset=UTF-8\", //\"EncType=application/json;charset=UTF-8\", \"Body=name=&#123;name&#125;&amp;phone=&#123;phone&#125;\",LAST); 对于请求参数放到RequestBody中的，可以直接将请求参数转成字符串放到Body中。或者放到RAW_BODY_START和RAW_BODY_END之间，其中200指代参数长度。 123456789web_custom_request(\"web_custom_request\",\"URL=&#123;url&#125;\",\"Method=POST\",\"Resource=0\", \"RecContentType=application/json\",\"Referer=\",\"Mode=HTTP\", \"EncType=application/json;charset=UTF-8\", //RAW_BODY_START, //\"&#123;\\\"id\\\":\\\"&#123;id&#125;\\\",\\\"name\\\":\\\"&#123;name&#125;\\\",\\\"mobile\\\":\\\"&#123;mobile&#125;\\\"&#125;\", //200, //RAW_BODY_END, \"Body=&#123;\\\"id\\\":\\\"&#123;id&#125;\\\",\\\"name\\\":\\\"&#123;name&#125;\\\",\\\"mobile\\\":\\\"&#123;mobile&#125;\\\"&#125;\", LAST); 对于响应结果的提取通过web_reg_save_param(&quot;code&quot;,&quot;LB=response_code\\&quot;:\\&quot;&quot;,&quot;RB=\\&quot;&quot;,LAST);提取出来，用来进行事务成功与否判断。 12345678910111213lr_start_transaction (\"接口A\");web_reg_save_param(\"code\",\"LB=response_code\\\":\\\"\",\"RB=\\\",\\\"\",LAST);web_custom_request(\"web_custom_request\",\"URL=&#123;url&#125;\",\"Method=POST\",\"Resource=0\", \"RecContentType=application/json\",\"Referer=\",\"Mode=HTTP\", \"EncType=application/json;charset=UTF-8\", \"Body=&#123;\\\"id\\\":\\\"&#123;id&#125;\\\",\\\"name\\\":\\\"&#123;name&#125;\\\"&#125;\",LAST);if (strcmp(lr_eval_string(\"&#123;coke&#125;\"), \"00\") == 0)&#123; lr_end_transaction(\"接口A\", LR_PASS);&#125;else&#123; lr_end_transaction(\"接口A\", LR_FAIL);&#125;","tags":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/tags/Test/"},{"name":"LoadRunner","slug":"LoadRunner","permalink":"https://yaoyinglong.github.io/tags/LoadRunner/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"类加载器","date":"2018-03-19T16:00:00.000Z","path":"Blog/Java/VM/类加载器/","text":"把类加载阶段中通过类的全限定名来获取描述此类的二进制字节流的动作放到Java虚拟机外部去实现，以便让程序自己决定如何去获取所需的类，实现该动作的代码模块称为类加载器。 类加载器是Java技术体系的重要基石，是Java语言的一项创新，也是Java语言流行的重要原因之一，最初是为了满足Java Applet需求而开发的，但目前Java Applet基本上已经死掉，但类加载器却在类层次划分、OSGi、热部署、代码加密等领域大放异彩。 类与类加载器虽然类加载器只用于实现类的加载动作，但在Java程序中的作用远远不限于类加载阶段。 任意一个类都需要由加载它的类加载器和该类本身一同确立其在Java虚拟机中的唯一性，每个类加载器都有一个独立的类名称空间。 比较两个类是否相等，只有两个类是由同一个类加载器加载的前提下才有意义，即使两个类源于同一个Class文件，被同一个虚拟机加载，若加载它们的类加载器不同，这两个类就一定不相等，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果、instanceof关键字做对象所属关系判定等情况。 类加载器初始化过程 sun.misc.Launcher初始化使用单例模式设计，在Launcher构造方法内创建了sun.misc.Launcher.ExtClassLoader扩展类加载器和sun.misc.Launcher.AppClassLoader应用类加载器，Launcher的getClassLoader()方法默认返回的类加载器AppClassLoader的实例加载开发人员写的应用程序。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private static URLStreamHandlerFactory factory = new Launcher.Factory();private static Launcher launcher = new Launcher();private static String bootClassPath = System.getProperty(\"sun.boot.class.path\");private ClassLoader loader;private static URLStreamHandler fileHandler;public static Launcher getLauncher() &#123; return launcher;&#125;public Launcher() &#123; Launcher.ExtClassLoader var1; try &#123; // 构造扩展类加载器，在构造过程中将其父加载器设置为null var1 = Launcher.ExtClassLoader.getExtClassLoader(); &#125; catch (IOException var10) &#123; throw new InternalError(\"Could not create extension class loader\", var10); &#125; try &#123; // 构造应用类加载器，在构造过程中将其父加载器设置为ExtClassLoader // Launcher的loader属性值是AppClassLoader，一般用这个类加载器来加载自己写的应用程序 this.loader = Launcher.AppClassLoader.getAppClassLoader(var1); &#125; catch (IOException var9) &#123; throw new InternalError(\"Could not create application class loader\", var9); &#125; Thread.currentThread().setContextClassLoader(this.loader); String var2 = System.getProperty(\"java.security.manager\"); if (var2 != null) &#123; SecurityManager var3 = null; if (!\"\".equals(var2) &amp;&amp; !\"default\".equals(var2)) &#123; try &#123; var3 = (SecurityManager)this.loader.loadClass(var2).newInstance(); &#125; catch (IllegalAccessException var5) &#123; &#125; catch (InstantiationException var6) &#123; &#125; catch (ClassNotFoundException var7) &#123; &#125; catch (ClassCastException var8) &#123; &#125; &#125; else &#123; var3 = new SecurityManager(); &#125; if (var3 == null) &#123; throw new InternalError(\"Could not create SecurityManager: \" + var2); &#125; System.setSecurityManager(var3); &#125;&#125;public ClassLoader getClassLoader() &#123; return this.loader;&#125; 双亲委派模型从Java虚拟机的角度讲，只存在两种不同的类加载器： 启动类加载器Bootstrap ClassLoader，该类加载器使用C++语言实现，是虚拟机自身的一部分 所有的其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，其全都继承自抽象类java.lang.ClassLoader 类加载器还可以划分得跟细致一点，一共有三种系统提供的类加载器： 启动类加载器Bootstrap ClassLoader，负责将&lt;JAVA_HOME&gt;\\lib目录中或被-Xbootclasspath参数所指定的路径中的，且是虚拟机识别仅按照文件名识别的类库加载到虚拟机内存中。无法被Java程序直接引用，自定类加载器时，若需把加载请求委派给引导类加载器，直接用null代替。 扩展类加载器Extension ClassLoader由sun.misc.Launcher$ExtClassLoader实现，负责加载&lt;Java_Home&gt;/lib/ext或被java.ext.dir系统变量所指定路径中的所有类库，开发者可直接使用扩展类加载器。 应用程序类加载器Application ClassLoader由sun.misc.Launcher$AppClassLoader实现。该类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，一般称为系统类加载器，负责加载用户类路径ClassPath上所指定的类库，开发者可直接使用这个类加载器，若应用程序中未自定义自己的类加载器，一般情况作为程序中默认的类加载器。 应用程序都是由这3种类加载器互相配合进行加载的，若有必要可加入自定义类加载器。如下图所示，类加载器之间的这种层次关系，称为类加载器的双亲委派模型。 双亲委派模型要求除顶层启动类加载器外，其余类加载器都应当有自己的父类加载器。这里的父子关系一般不会以继承关系来实现，而是使用组合关系来复用父类加载器的代码。并不是强制性的约束模型，是设计者推荐的一种类加载实现方式。 若类加载器收到类加载请求，首先不会自己尝试加载该类，而是把该请求委派给父类加载器去完成，每个层次的类加载器都是如此。所有的类加载请求最终都应该传送到顶层的启动类加载器中，只有父类加载器反馈自己无法完成该加载请求时，即其搜索范围中没找到所需的类，子加载器才会尝试自己加载。 双亲委派模型可以使Java类随其类加载器一起具备一种带有优先级关系的层次关系。如java.lang.Object无论哪个类加载器加载，最终都会委派给处于模型顶端的启动类加载器进行加载，因此Object在各种类加载器环境中都是同一个类。 双亲委派模型实现代码集中在java.lang.ClassLoader的loadClass()方法中，实现简单，其对于保证Java程序稳定运作很重要。 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 检查当前类加载器是否已经加载了该类 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; // 如果当前加载器父加载器不为空则委托父加载器加载该类 c = parent.loadClass(name, false); &#125; else &#123; // 如果当前加载器父加载器为空则委托引导类加载器加载该类 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); // 调用URLClassLoader的findClass方法在加载器的类路径里查找并加载该类 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 全盘负责委托机制当一个ClassLoder装载一个类时，除非显示的使用另外一个ClassLoder，该类依赖及引用类也由该ClassLoder载入。 设计双亲委派机制的目的 沙箱安全机制：自己写的java.lang.String.class类不会被加载，这样便可以防止核心API库被随意篡改 避免类的重复加载：当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次，保证被加载类的唯一性 破坏双亲委派模型第一次破坏双亲委派模型是在JDK1.2之后引入的，而类加载器和抽象类java.lang.ClassLoader则在JDK1.0已经存在，为了向前兼容，JDK1.2之后的java.lang.ClassLoader添加了一个protected方法findClass() 在此之前，用户继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法，虚拟机在进行类加载时会调用加载器的私有方法loadClassInternal()，该方法仅仅去调用自己的loadClass()方法。 JDK1.2之后不提倡覆盖loadClass()方法，提倡将类加载逻辑写到findClass()中，在loadClass()中若父类加载失败，再调用findClass()中自己的逻辑完成加载。这样即可保证新写的类加载器符合双亲委派规则。 第二次破坏双亲委派模型对于越基础的类由越上层的加载器进行加载，从而很好的解决了各个类加载器的基础类的统一问题，但有一个缺陷，双亲委派模型并不能解决基础类又需要回调用户代码的情况。 如JNDI服务现已经是Java标准服务，其代码由启动类加载器加载，但JNDI的目的是对资源进行集中管理和查找，需要调用独立厂商实现并部署在应用程序中ClassPath下JNDI接口提供者的代码。 为了解决该问题，引入了一个不太优雅的设计：线程上下文类加载器（Thread Context ClassLoader）。 该类加载器可通过java.lang.Thread类的setContextClassLoader()方法进行设置线程上下文类加载器，若创建线程时未设置，将会从父线程中继承一个，若应用程序全局范围内都未设置线程上下文类加载器，则线程上下文类加载器默认为应用程序类加载器。 JNDI服务使用线程上下文类加载器去加载所需的JNDI接口提供者的代码，其实就是通过父类加载器请求子类加载器去完成类加载。该方式打通了双亲委派模型的层次结构来逆向使用类加载器，违背了双亲委派模型一般原则。 Java中所有涉及SPI的加载基本都采用此种方式，如JNDI、JDBC、JCE、JAXB、JBI。 第三次破坏由于用户对程序动态性（代码热替换、模块热部署）的追求，目前OSGi是业界事实上的模块化标准，OSGi实现模块化热部署的关键在于其自定义的类加载器机制的实现，每个模块（OSGi称为Bundle）都有一个自己的类加载器，更换模块时连同类加载器一起替换以实现代码热替换。 OSGi环境下，类加载器不再是双亲委派模型中的树状结构，而进一步发展成了网状结构。OSGi类搜索顺序如下： 将java.*开头的类委派给父类加载器加载 否则，将委派列表名单中的类委派给父类加载器加载 否则，将Import列表中的类委派给Export类的Bundle的类加载器加载 否则，查找当前Bundle的ClassPath，使用自己的类加载器加载 否则，查找类是否在自己的Fragment Bundle中，在，则委派给Fragment Bundle的类加载器加载 否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载 否则，类查找失败 查找顺序中，只有第一二两条符合双亲委派规则，其余都是在平级的类加载器中进行。 自定义类加载器自定义类加载器只需要继承java.lang.ClassLoader类，该类有两个核心方法，一个是loadClass(String, boolean)，实现了双亲委派机制，还有一个方法是findClass，默认实现是空方法，所以我们自定义类加载器主要是重写findClass方法。 123456789101112131415161718192021222324252627282930313233343536373839public class ElevenClassLoader extends ClassLoader &#123; private String classPath; public ElevenClassLoader(String classPath) &#123; this.classPath = classPath; &#125; private byte[] loadByte(String name) throws Exception &#123; name = name.replaceAll(\"\\\\.\", \"/\"); FileInputStream fis = new FileInputStream(classPath + \"/\" + name + \".class\"); int len = fis.available(); byte[] bytes = new byte[len]; fis.read(bytes); fis.close(); return bytes; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; byte[] data = loadByte(name); return defineClass(name, data, 0, data.length); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new ClassNotFoundException(); &#125; &#125; public static void main(String[] args) throws Exception &#123; ElevenClassLoader classLoader = new ElevenClassLoader(\"E:\\\\IData\"); Class clazz = classLoader.loadClass(\"com.eleven.icode.jvm.entity.User\"); Object obj = clazz.newInstance(); Method method = clazz.getDeclaredMethod(\"sout\", null); method.invoke(obj, null); System.out.println(clazz.getClassLoader().getClass().getName()); &#125;&#125; 上面代码仅仅是自定义了自己的类加载器，仅当类AppClassLoader类加载器在项目中找不到User的字节码时，才会使用ElevenClassLoader加载User类。为了打破这种双亲委派机制，还必须重写loadClass方法。 123456789101112131415161718192021222324252627282930313233343536@Overrideprotected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (!name.startsWith(\"com.eleven.icode.jvm\")) &#123; c = this.getParent().loadClass(name); &#125; else &#123; c = findClass(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 由于所有的类都是继承自Object类，故if (!name.startsWith(&quot;com.eleven.icode.jvm&quot;))判断尤为重要，若去掉该类，会报java.io.FileNotFoundException: E:\\IData\\java\\lang\\Object.class (系统找不到指定的文件。)异常。若将rt.jar中的Object.class拷贝到该路径，会触发上面说的沙箱安全机制：java.lang.SecurityException: Prohibited package name: java.lang。 Tomcat打破双亲委派机制Tomcat是个web容器，一个web容器可能需要部署两个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，不能要求同一个类库在同一个服务器只有一份，因此要保证每个应用程序的类库都是独立的，要保证相互隔离。还要保证部署在同一个web容器中相同的类库相同的版本可以共享。否则若服务器有10个应用程序，则要有10份相同类库加载进虚拟机。 web容器也有自己依赖的类库，不能与应用程序的类库混淆。基于安全考虑，应该让容器的类库和程序的类库隔离开来。web容器要支持jsp的修改，而jsp文件最终也是要编译成class文件才能在虚拟机中运行，但程序运行后修改jsp已经是司空见惯的事情， web容器需要支持 jsp 修改后不用重启，每个jsp文件对应一个唯一的类加载器，当一个jsp文件修改了，就直接卸载这个jsp类加载器，重新创建类加载器，重新加载jsp文件。 CommonLoader：Tomcat最基本的类加载器，加载路径中的class可以被Tomcat容器本身以及各个Webapp访问CatalinaLoader：Tomcat容器私有的类加载器，加载路径中的class对于Webapp不可见SharedLoader：各个Webapp共享的类加载器，加载路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见WebappClassLoader：各个Webapp私有的类加载器，加载路径中的class只对当前Webapp可见，比如加载war包里相关的类，每个war包应用都有自己的，WebappClassLoader实现相互隔离，比如不同war包应用引入了不同的spring版本，这样实现就能加载各自的spring版本；每个WebappClassLoader加载自己的目录下的class文件，不会传递给父类加载器，打破了双亲委派机制JspClassLoader：加载范围仅仅是这个JSP文件所编译出来的那一个.Class文件，出现目的就是为了被丢弃：当Web容器检测到JSP文件被修改时，会替换掉目前的JspClassLoader实例，再建立一个新的Jsp类加载器来实现JSP文件的热加载功能","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"类加载过程","date":"2018-03-15T16:00:00.000Z","path":"Blog/Java/VM/类加载过程/","text":"Class文件中描述的各种信息最终都需要加载到虚拟机中之后才能运行和使用，虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可被虚拟机直接使用的Java类型。 类型的加载、连接和初始化过程都是在程序运行期间完成的，这虽然会令类加载时稍微增加一些性能开销，但能够提供高度的灵活性，其天生的动态扩展性就是依赖运行期动态加载和动态连接。面向接口的应用程序可以等到运行时再指定其实际的实现类，用户可以通过预定义的和自定义类加载器，让一个本地应用程序可以在运行时从网络或其他地方加载一个二进制流作为程序代码的一部份，如Applet、JSP、OSGi等技术。 类加载的时机类从被加载到虚拟机内存中开始，到卸载出内存的整个生命周期为加载、验证、准备、解析、初始化、使用、卸载7个阶段,验证、准备、解析3个部分统称为连接。 加载、验证、准备、初始化、卸载这5个阶段的顺序是确定的，但解析阶段在某些情况下可以在初始阶段之后，这是为了支持运行时绑定即动态绑定。 初始化阶段虚拟机规范严格规定了有且只有5种情况必须立即对类进行初始化： 遇到new、getstatic、putstatic、invokestatic这4条字节码指令时，若类未进行初始化需先触发其初始化。 使用java.lang.reflect包的方法对类进行反射调用时，若类未进行初始化需先触发其初始化。 当初始化类时其父类未初始化，需先触发其父类初始化。 当虚拟机启动时，用户指定一个执行主类即包含main方法的类，虚拟机会先初始化该类。 若一个java.lang.invoke.MethodHandle实例最后的解析结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，且该方法句柄所对应的类未进行过初始化需先触发其初始化。 以上5种场景称为对一个类的主动引用，除此之外所有引用类的方式都不会触发初始化，称为被动引用，被动引用的几种情况： 对于静态字段，只有直接定义该字段的类才会被初始化，其子类来引用父类的中定义的静态字段只会触发父类的初始化而不会触发子类的初始化。 通过数组定义来引用类 常量的引用，常量在编译阶段会存入调用类的常量池种，本质上并没有直接引用到定义常量的类 接口的加载过程与类的加载过程稍微有些不同，接口中也有初始化过程，类中可以使用静态语句块static{}，但是接口中不能使用static{}语句块，但编译器任然会为接口生成&lt;clinit&gt;类构造器，用于初始化接口中定义的成员变量；接口与类的真正区别是，当类在初始化时，其父类都已经完成初始化，但接口在初始化时，并不要求其父类接口全部都完成初始化，只有在真正使用到父类接口的时候才会初始化，例如引用父类接口中定义的常量。 加载加载阶段虚拟机要完成3件事：通过类的全限定名来获取定义此类的二进制字节流；将字节流所代表的静态存储结构转化为方法区的运行时数据；在内存中生成一个代表该类的java.lang.Class对象，作为方法区该类的各种数据访问入口； 虚拟机没有明确规定二进制字节流要从哪里获取，怎样获取，相对于类加载过程的其他阶段，一个非数组类加载阶段中获取类二进制字节流的动作是开发人员可控性最强的，加载阶段既可以使用系统提供的引导类加载器来完成，也可以由自定义的类加载器来控制字节流的获取方式。一些典型的使用场景如下： 从ZIP包中读取，JAR、EAR、WAR格式的基础 从网络中获取，例：Applet 动态代理，java.lang.reflect.Proxy 由其他文件生成，例：由JSP生成对应的Class类 从数据库中读取，例：中间件服务器可选择把程序安装到数据库中来完成在集群间的发布 但数组类有所不同，数组类本身不通过类加载器创建，而是由虚拟机直接创建，但数组类与类加载器任然关系很密切，数组类的元素类型最终是要靠类加载器去创建。数组类的创建过程遵循以下规则： 若数组的组件类型是引用类型，则递归采用加载过程加载该组件类型，数组在加载该组件类型的类加载器的类名称空间上被标识 若数组的组件类型不是引用类型，虚拟机会将数组标记为与引导类加载器关联 数组类的可见性与其组件类型一致，若组件类型不是引用类型，数组类的可见性默认为public 虚拟机外部二进制字节流在加载阶段完成后按照虚拟机所需的格式存储在方法区，然后在内存中实例化一个java.lang.Class类的对象，但并没有明确规定是在Java堆中，对于HotSpot虚拟机而言，Class对象虽然是对象，但存储在方法区中，该对象将作为程序访问方法区中的这些类型数据的外部接口。 加载阶段与连接阶段的部分内容是交叉进行的，例如一部分字节码文件格式校验，加载阶段尚未完成，连接阶段可能就已经开始，但这些夹在加载阶段之中进行的动作任然属于连接阶段内容，两个阶段的开始时间任然保持着固定的先后顺序。 验证验证是连接阶段的第一步，目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机要求，且不会危害虚拟机自身安全。 Class文件并不一定要求用Java源码编译而来，可以使用任何途径产生，甚至包括十六进制编辑器直接编写来产生Class文件，虚拟机如果不检测输入的字节流，很可能会载入有害的字节流而导致系统崩溃。 验证阶段的工作量在虚拟机的类加载子系统中占了相当大的一部分，若验证到输入的字节流不符合Class文件格式的约束，虚拟机会抛出一个java.lang.VerifyError异常或其子类异常，验证阶段大致会完成4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。 对虚拟机类加载机制来说，验证阶段是一个非常重要但不是一定必要的阶段，对程序运行期没有影响，若所运行的全部代码都已被反复使用和验证过，在实施阶段可以使用-XVerify:none参数来关闭大部分类验证措施，以缩短虚拟机类加载的时间。 文件格式验证验证字节流是否符合Class文件格式的规范，且能被当前版本的虚拟机处理，包括是否以魔数0xCAFEBABE开头，主次版本号是否在当前虚拟机处理范围内，检查常量池常量tag标志的是否有不被支持的常量类型，指向常量的各种索引值中是否有指向不存在常量或不符合类型的常量，CONSTANT_Utf8_info型常量中是否有不符合UTF8编码的数据，Class文件中各个部分及文件本身是否有被删除的或附加的其他信息，等等。 该阶段主要目的是保证输入的字节流能正确地解析并存储于方法区中，格式上符合描述一个Java类型信息的要求，该阶段的验证时基于二进制字节流进行的，只有通过了该阶段的验证，字节流才会进入内存的方法区进行存储，后面的3个验证阶段都是基于方法区的存储结构进行的，不会再直接操作字节流。 元数据验证该阶段对字节码描述的信息进行语义分析，包括验证类是否有父类，类的父类是否继承了不允许被继承的类，类是不是抽象类、是否实现了其父类或接口中要求实现的所有方法，类的字段、方法是否与父类产生矛盾。 该阶段的主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。 字节码验证字节码验证是整个验证阶段过程中最复杂的阶段，主要目的是通过数据流和控制流分析，确定程序语义是否合法且符合逻辑，在元数据验证阶段对元数据信息中的数据类型做完校验后，字节码验证阶段将对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件，保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，不会出现在操作栈放置int类型的数据，使用时按long类型来加载入本地变量表；保证跳转指令不会跳转到方法体以外的字节码指令上；保证方法体中类型转换是有效的； 即使方法体通过了字节码验证，也不能明确其一定就是安全的，通过程序去校验程序逻辑是无法做到绝对准确的，不能通过程序准确地检测出程序是否能在有限时间内结束运行。 数据流验证复杂性高，为了避免过多的时间消耗在字节码验证阶段，JDK1.6之后Javac编译器和Java虚拟机中进行了优化，给方法体的Code属性的属性表中增加了一项名为StackMapTable属性，StackMapTable属性描述了方法体中所有基本块开始时本地变量表和操作栈应有的状态，在字节码验证期间，就不需要根据程序推导这些状态的合法性，只需要检查StackMapTable属性中的记录是否合法。 理论上StackMapTable属性也存在错误或被篡改的可能，在JDK1.6的HotSpot虚拟机中提供-XX:-UseSplitVerifier选项类关闭这项优化，或使用-XX:+FailOverToOldVerifier参数来要求在类型校验失败时退回到旧的类型推导方式进行校验，JDK1.7后对于主版本号大于50的Class文件，只能使用类型检查来完成数据流分析校验，不允许退回到类型推导的校验方式。 符号引用验证符号引用验证发生在虚拟机将符号引用转化为直接引用的时候，该转化动作将在连接的第三阶段——解析阶段中发生，符号引用验证可看做是对类自身以外的信息进行匹配性校验，包括符号引用中通过字符串来描述的全限定名是否能找到对应的类，在指定的类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段，符号引用中的类、字段、方法的访问权限是否可被当前类访问。 符号引用验证的目的是确保解析动作能正常执行，若无法通过符号引用验证，将抛出java.lang.IncompatibleClassChangeError异常的子类， 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，类变量使用的内存都在方法区中进行分配。这个时候进行内存分配的仅包括被static修饰的类变量，不包括实例变量，实例变量将会在对象实例化时随对象一起分配在堆中，且这里所说的初始值通常情况下是数据类型的零值，例如一个类变量定义为：public static int value = 123;则变量在准备阶段后的初始值为0而不是123,把value赋值为123的putstatic指令是程序被编译后，存放于类构造器&lt;clinit&gt;()方法中，把value赋值为123的动作将在初始化阶段执行。 若类字段属性表中存在ConstantValue属性，在准备阶段变量value会被初始化为ConstantValue属性所指定的值，如public static final int value = 123;编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性的设置将value赋值为123。 数据类型 零值 数据类型 零值 数据类型 零值 int 0 boolean false char ‘\\u0000’ long 0L float 0.0f reference null short (short)0 double 0.0d byte (byte)0 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用在Class文件中以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现，符号引用以一组符号来描述所引用的目标，符号可以是任意形式的字面量，只要使用时能无歧义定位到目标，符号引用与虚拟机实现的内存布局无关，引用目标并不一定已经加载到内存中，各种虚拟机实现的内存布局各不相同，但能接受的符号引用必须一致，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以直接指向目标的指针、相对偏移量或是能间接定位到目标的句柄。直接引用与虚拟机实现内存布局相关，如果存在直接引用，则引用的目标必定已存在内存中。 虚拟机规范中并未规定解析阶段发生的具体时间，只要求在执行anewarray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invokespecial、invokestatic、invokevirtual、ldc、ldc_w、multianewarray、new、putstatic这16条用于操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析，虚拟机实现可以根据需求来判断是在类加载器加载时对常量池中的符号引用解析，还是等到符号引用将要被使用前才去解析。 对同一个符号引用进行多次解析，除invokedynamic指令外，虚拟机可以对第一次解析的结果进行缓存，在运行时常量池中记录直接引用，并把常量标识为已解析状态，从而避免解析动作重复进行，无论是否真正执行多次解析动作，虚拟机需要保证在同一实体中，若一个符号引用之前已经被成功解析过，则后续的引用解析请求应当一直成功，反之亦然。 而invokedynamic指令目的是用于动态语言支持，其所对应的引用称为动态调用点限定符，动态的含义是指必须等到程序实际运行到这条指令的时候，解析动作才进行，且其解析结果对于其他invokedynamic指令并不生效。其余可触发解析指令都是静态的。 类或接口的解析将从未解析过的符号引用解析为类或接口的直接引用，虚拟机完成整个解析过程需要三个步骤： 若符号引用所指向的类或接口为非数组类型，则虚拟机将会将符号引用的全限定名传递给当前类的类加载器去加载这个类或接口，加载过程中，由于元数据验证、字节码验证的需要，可能触发其他相关类的加载，如加载该类的父类或实现的接口。若加载过程出现任何异常，解析过程将失败。 若符号引用所指向的类或接口为数组类型，且数组元素类型为对象，即符号引用的描述符类似[Ljava.lang.Integer的形式，将按照上面的规则加载数组元素类型，若符号引用的描述符为[Ljava.lang.Integer，则加载元素的类型为java.lang.Integer，接着由虚拟机生成一个代表此数组维度和元素的数组对象。 若前面的步骤未出现任何异常，则符号引用所指向的类或接口在虚拟机中实际上已经成为一个有效的类或接口，在解析完成之前需要进行符号引用验证，确认当前类是否具有对符号引用所指向的类或接口的访问权限。若不具备将抛出java.lang.IllegalAccessError异常。 字段解析解析一个未被解析过的字段符号引用，将对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析，也就是字段所属的类或接口的符号引用。若解析该类或接口符号引用的过程出现任何异常，都将导致字段符号引用解析失败。 若解析成功，虚拟机将按照以下步骤对该字段所属的类或接口进行字段搜索。若查找过程返回直接引用成功，还将对字段进行权限验证，若不具备访问权限，将抛出java.lang.IllegalAccessError异常。 若字段所属的类或接口本身包含的简单名称和字段描述符都与目标字段匹配，则返回该字段的直接引用，查找结束。 若字段所属的类或接口中实现了接口，将按照继承关系从下往上递归搜索各个接口和它的父接口，若接口中包含的简单名称和字段描述符都与目标字段匹配，则返回该字段的直接引用，查找结束。 若字段所属的类或接口非java.lang.Object，将按照继承关系从下往上递归搜索其父类，若父类中包含的简单名称和字段描述符都与目标字段匹配，则返回该字段的直接引用，查找结束。 否则查找失败，抛出java.lang.NoSuchFieldError异常 实际应用中，虚拟机编译器实现比上述规范要求更加严格，若有同名字段同时出现在字段所属的类或接口的接口和父类中，或同时出现在自己和父类的多个接口中，编译器将拒绝编译。 类方法解析类方法解析需先解析出类方法表的class_index项中索引的方法所属的类或接口的符号引用，若解析成功将按照如下步骤进行类方法搜索： 类方法和接口方法符号引用的常量类型定义是分开的，若在类方法表中发现class_index中索引的方法所属为接口，将抛出java.lang.IncompatibleClassChangeError异常。 在类方法所属的类或接口中查找是否有简单名称和描述符都与目标相匹配的方法，若有则返回该方法的直接引用，查找结束。 在类方法所属的类或接口实现的列表及它们的父类接口中递归查找是否有简单名称和描述符都与目标相匹配的方法，若存在匹配的方法则说明该类是一个抽象类，查找结束，抛出java.lang.AbstractMethodError异常。 否则，方法查找失败，抛出java.lang.NoSuchMethodError异常。 若查找过程成功返回了直接引用，将会对该方法进行权限验证，若不具备访问权限，将抛出java.lang.IllegalAccessError异常。 接口方法解析接口方法解析需先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用，若解析成功将按照如下步骤进行类方法搜索： 若在接口方法中发现class_index中的索引的方法所属为类而非接口，将抛出java.lang.IncompatibleClassChangeError异常。 在接口方法所属的类或接口中查找是否有简单名称和描述符都与目标相匹配的方法，若有则返回该方法的直接引用，查找结束。 在接口方法所属的类或接口的父接口中递归查找，直到查找完java.lang.Object类为止，看是否有简单名称和描述符都与目标相匹配的方法，若有则返回该方法的直接引用，查找结束。 否则，方法查找失败，抛出java.lang.NoSuchMethodError异常。 接口中所有方法默认都是public，故不存在访问权限问题，故接口方法符号解析应该不会抛出java.lang.IllegalAccessError异常。 初始化初始化阶段才真正开始执行类中定义的Java程序代码或者说是字节码，除加载阶段用户应用程序能通过自定义类加载器参与外，其余动作完全由虚拟机主导和控制。 在准备阶段变量已经赋值系统要求的初始值，在初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程，主观计划去初始化类变量和其他资源。 &lt;clinit&gt;()方法是由编译器自动收集类中所有变量的赋值动作和静态语句块static{}中的语句合并产生的，编译器收集顺序是由语句在源文件中出现顺序决定的，静态语句块只能访问到定义在静态语句块之前的变量，定义在其后的变量，在静态语句块可以赋值，但不能访问。 &lt;clinit&gt;()方法与实例构造器不同，它不需要显示调用父类构造器，虚拟机会保证子类&lt;clinit&gt;()方法执行前，父类&lt;clinit&gt;()方法已执行完毕。故虚拟机中第一个被执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object。 由于父类的&lt;clinit&gt;()方法先执行，故父类中定义的静态语句块要优先于子类的变量赋值操作。 &lt;clinit&gt;()方法对于类或接口并非是必需的，若类中无静态语句块，也无对变量的赋值操作，编译器将不会为该类生成&lt;clinit&gt;()方法。 接口中不能使用静态语句块，但任然有变量初始化的赋值操作，故接口和类一样都会生成&lt;clinit&gt;()方法，但执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法，只有父接口中定义的变量使用时才会初始化。接口的实现类在初始化时也不会执行接口的&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确枷锁、同步，若多个线程同时去初始化一个类，只会有一个线程去执行该类的&lt;clinit&gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法方法完毕。 组件类型：数组去掉一个维度得类型类必须与类加载器一起确定唯一性不允许被继承的类：被fianl修饰的类类的字段、方法是否与父类产生矛盾：覆盖了父类的final字段，或者出现不符合规则的方法重载类自身以外的信息：例如常量池中各种符号引用","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"字节码指令","date":"2018-02-07T16:00:00.000Z","path":"Blog/Java/VM/字节码指令/","text":"Java虚拟机指令是由一个字节长度、代表某种特定操作含义的数字操作码Opcode以及跟随其后的零至多个代表此操作所需参数操作数Operands而构成。但由于Java虚拟机采用面向操作数栈而不是寄存器的架构，所以大多数指令只有一个操作码。 字节码指令集是一种具有鲜明特点、优劣势突出的指令集架构，由于操作码长度为一个字节即0~255，故指令的操作码总数不超过256条； Class文件格式放弃了编译后代码的操作数长度对齐，虚拟机处理超过一个字节的数据时，需在运行时从字节中重建具体数据的结构，如果将16位长度的无符号整数使用两个无符号字节byte1、byte1存储，其值为(byte1 &lt;&lt; 8) | byte2。放弃操作数长度对齐，可以省略很多填充和间隔符号，但在某种程度上会导致解释执行字节码时损失一些性能。 不考虑异常处理的情况下，Java虚拟机的解释器可使用一下伪代码为最基本的执行模型来理解：123456do &#123; 自动计算PC寄存器的值加1; 根据PC寄存器指示位置，从字节码流中取出操作码; if ( 字节码存在操作数 ) 从字节码流中取出操作数; 执行操作码所定义的操作;&#125; where ( 字节码流长度 &gt; 0 ); 字节码与数据类型Java虚拟机指令集中，大多数指令都包含其基本操作所对应的数据类型信息。大部分与数据类型相关的字节码指令，它们的操作码助记符中有特殊字符表示服务的数据类型：i代表int、l代表long、s代表short、b代表byte、c代表char、f代表float、d代表double、a代表reference；但也有指令助记符种没有指名操作类型字母，如arraylength操作数为数组类型的对象、goto无条件跳转指令。 虚拟机指令集对于特定操作只提供了有限的类型相关指令去支持，指令集将会被设计成非完全独立的，即并非每种数据类型和每一种操作都有对应的指令。有一些单独的指令可以在必要的时候用来将一些不支撑的数据类型转换为可被支撑的类型。 大部分指令都没有支撑整数类型byte、char、short甚至没有任何指令支撑boolean类型。编译器会在编译期或运行期将byte和short类型的数据带符号扩展为相应的int类型数据，在c处理boolean、byte、short、char类型的数组时，也会转换为使用对应的int类型字节码指令来处理。 加载和存储指令加载和存储指令用于将数据在栈帧中的局部变量表和操作数栈之间来回传输，存储数据的操作数栈和局部变量表主要由加载和存储指令进行操作，少数访问对象字段或数组元素指令也会向操作数栈传输数据。 将局部变量加载到操作栈：iload、iload_&lt;n&gt;、lload、lload_&lt;n&gt;、fload、fload_&lt;n&gt;、dload、dload_&lt;n&gt;、aload、aload_&lt;n&gt; 将数据从操作数栈存储到局部变量表：istore、istore_&lt;n&gt;、lstore、lstore_&lt;n&gt;、fstore、fstore_&lt;n&gt;、dstore、dstore_&lt;n&gt;、astore、astore_&lt;n&gt; 将常量加载到操作数栈：bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconst_m1、iconst_&lt;i&gt;、lconst_&lt;l&gt;、fconst_&lt;f&gt;、dconst_&lt;d&gt; 扩充局部变量表访问索引：wide。 带有尖括号结尾的指令，指令助记符代表一组指令。 运算指令运算指令用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入操作数栈顶。大体上算数指令分整型数据运算指令和浮点数据运算指令，整数与浮点数的算术指令在溢出和被零除时有各自不同的行为表现。 加法指令：iadd、ladd、fadd、dadd 减法指令：isub、lsub、fsub、dsub 乘法指令：imul、lmul、fmul、dmul 除法指令：idiv、ldiv、fdiv、ddiv 求余指令：irem、lrem、frem、drem 取反指令：ineg、lneg、fneg、dneg 位移指令：ishl、ishr、iushr、lshl、lshr、lushr 按位或指令：ior、lor 按位与指令：iand、land 按位异或指令：ixor、lxor 局部变量自增指令：iinc 比较指令：dcmpg、dcmpl、fcmpg、fcmpl、lcmp 数据运算可能会导致溢出，虚拟机规范没有明确定义整数数据溢出的具体运算结果，仅规定了在处理整数数据时，只有除法指令和求余指令中出现除数为零时会抛出ArithmeticException异常，其余任何整型数运算场景都不应该抛出运行时异常。 Java虚拟机处理浮点数时必须完全支持IEEE 754中定义的非正规浮点数值和逐级下溢的运算规则，所有运算结果都必须舍入到适当精度，非精确的结果必须舍入为可被表示的最接近的精确值，若两种可表示形式与该值一样接近，将优先选择最低有效位为零的。将浮点数转换成整数时，使用的向零舍入模式，舍入结果会导致数字被截断，小数部分有效字节都会被丢弃掉。Java虚拟机在处理浮点数运算时不会抛出任何运行时异常。 对long类型的数值进行比较时，虚拟机采用带符号的比较方式，而浮点数值比较采用无符号比较方法。 类型转换指令类型转换指令能将两种不同数值类型进行相互转换，一般用于实现用户代码中显示类型转换操作，或用来处理字节码指令集中数据类型相关指令无法与数据类型一一对应的问题。 虚拟机直接支持以下数值类型的宽化类型转换，即小范围类型向大范围类型的安全转换，转换时无需显示的转换指令。 int类型到long、float、double类型 long类型到float、double类型 float类型到double类型 处理窄化类型转换时，必须显示使用转换指令来完成，转换指令包括i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l、d2f。窄化类型转换可能导致类型转换结果产生不同正负号、不同数量级、精度丢失等情况。 int或long类型窄化转换为整数类型T时，仅仅简单地丢弃除最低位N个字节以外的内容，但这也将导致转换结果与输入值有不同正负号。 将浮点值窄化转换为整数类型T时，将遵循以下转换规则： 若浮点值为NaN，转换结果为int或long类型的0 若浮点值非无穷大，浮点值使用向零舍入模式取整，若获得整数值在目标类型int或long的表示范围内，转换结果就是该值 否则，将根据该值的符号，转换为int或long所能表示的最大或最小正数 double类型到float类型的窄化转换，向最接近数舍入模式舍入得到一个可使用float类型表示的数字，若转换结果绝对值太小，返回float类型的正负零；若绝对值太大，将返回float类型的正负无穷大；double类型NoN将按规定转换为float类型的NaN值。 尽管数据类型窄化转换可能发生上限溢出、下限溢出、精度丢失等情况，但虚拟机规范中规定数值类型窄化转换指令永远不可能导致虚拟机抛出运行时异常。 操作数栈管理指令虚拟机提供了以下用于直接操作操作数栈的指令： 将操作数栈栈顶一个或两个元素出栈：pop、pop2 复制栈顶一个或两个数值并将复制值或双份复制值重新压入栈顶：dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2 将栈顶两个数值互换：swap 控制转移指令控制转移指令可以让Java虚拟机有条件或无条件从指定位置指令继续执行程序，而不是控制转移指令的下一条指令，可以认为控制转移指令就是在有条件或无条件地修改PC寄存器的值。 条件分支：ifeq、iflt、ifle、ifgt、ifge、ifnull、ifnonull、if_icmpeg、if_icmpne、if_icmplt、if_icmpgt、if_icmple、if_acmpeg、if_acmpne 复合条件分支：tableswitch、lookupswitch 无条件分支：goto、goto_w、jsr、jsr_w、ret 虚拟机有专门的指令集用来处理int和reference类型的条件分支比较操作，也有专门的指令用来检测null值。 对于boolean、byte、char、short等类型的条件分支比较操作，都使用int类型的比较指令来完成，而long、float、double类型的条件分支比较操作，则执行相应类型的比较运算指令，运算指令会返回一个整型值到操作数栈中，随后再执行int类型的条件分支比较操作来完成整个分支跳转。各种类型的比较最终都会转化为int类型的比较操作，所以虚拟机提供的int类型的条件分支指令最丰富最强大。 方法调用和返回指令 invokevirtual指令用于调用对象的实例方法，根据对象实际类型进行分派（虚方法分派） invokeinterface指令用于调用接口方法，运行时搜索一个实现了这个接口方法的对象，找出最合适的方法进行调用 invokespecial指令用于调用一些特殊处理的实例方法，包括实例初始化方法、私有方法、父类方法 invokestatic指令用于调用类方法，即static方法 invokedynamic指令用于在运行时动态解析出调用点限定符所引用的方法，并执行该方法 前4条调用指令分派逻辑都固化在虚拟机内部，而invokedynamic指令分派逻辑是由用户所设定的引导方法决定的。 方法调用指令与数据类型无关，而方法返回指令是根据返回值的类型区分的，包括ireturn（返回值是boolean、byte、char、short、int类型时使用）、lreturn、freturn、dreturn、areturn，以及return指令供void方法、实例初始化方法、类和接口的类初始化方法使用。 异常处理指令程序中通过throw语句显示抛出异常的操作都由athrow指令来实现，除throw显示抛出异常外，虚拟机规范还规定了许多运行时异常会在其他Java虚拟机指令检测到异状况时自动抛出。虚拟机中catch语句处理异常不是由字节码指令来实现的，而是采用异常表来完成的。 同步指令虚拟机支持方法级的同步和方法内部一段指令序列的同步，两种同步都使用管程Monitor来支持的。 方法级的同步是隐式的，无须通过字节码指令来控制，它实现在方法调用和返回操作之中。虚拟机可以从方法常量池的方法结构中的ACC_SYNCHRONIZED访问标志得知方法是否声明未同步方法。当方法调用时，调用的指令将会检查方法的ACC_SYNCHRONIZED访问标志是否被设置，若被设置，执行线程就要求先成功持有管程Monitor，然后才能执行方法，最后当方法执行完成，无论是否正常完成都释放管程Monitor，方法执行期间，执行线程持有了管程Monitor，其他任何线程都无法再获得同一个管程Monitor。若同步方法执行期间抛出异常，且方法内部无法处理异常，同步方法所持有的管程Monitor将在异常抛到同步方法外时自动释放。 同步一段指令集序列通常是通过synchronized语句块来完成，虚拟机的指令集使用monitorenter和monitorexit两条指令来支持synchronized关键字的语义，正确实现synchronized关键字需要Javac编译器和Java虚拟机共同协作支持，编译器必须保证方法通过任何方式完成，方法中调用过的每条monitorenter指令都必须执行其对应的monitorexit指令，无论该方法是否正常结束。 为了保证方法异常完成时monitorenter和monitorexit指令能正确配对执行，编译器会自动产生一个异常处理器，且声明可处理的所有异常，来执行monitorexit指令。 虚拟机两种主要的实现方式： 将输入的Java虚拟机代码在加载或执行时翻译成另一种虚拟机指令集 将输入的Java虚拟机代码在加载或执行时翻译成宿主机CPU的本地指令集，即JIT代码生成技术","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"属性表集合","date":"2018-02-03T16:00:00.000Z","path":"Blog/Java/VM/属性表集合/","text":"在Class文件、字段表、方法表都可以携带自己的属性表集合，属性表集合不要求各个属性表具有严格顺序。 属性名称 使用位置 含义 Code 方法表 Java代码编译成的字节码指令 ConstantValue 字段表 final关键字定义的常量池 Deprecated 类，方法，字段表 被声明为deprecated的方法和字段 Exceptions 方法表 方法抛出的异常 EnclosingMethod 类文件 仅当一个类为局部类或者匿名类时才能拥有该属性，该属性用于标识该类所在的外围方法 InnerClass 类文件 内部类列表 LineNumberTable Code属性 Java源码的行号与字节码指令的对应关系 LocalVariableTable Code属性 方法的局部变量描述 StackMapTable Code属性 JDK1.6新增，供新的类型检查验证器检查和处理目标方法的局部变量和操作数有所需要的类是否匹配 Signature 类，方法表，字段表 用于支持泛型情况下的方法签名 SourceFile 类文件 记录源文件名称 SourceDebugExtension 类文件 用于存储额外的调试信息 Synthetic 类，方法表，字段表 标志方法或字段为编译器自动生成的 LocalVariableTypeTable 类 使用特征签名代替描述符，为了引入泛型语法之后能描述泛型参数化类型而添加 RuntimeVisibleAnnotations 类，方法表，字段表 为动态注解提供支持 RuntimeInvisibleAnnotations 表，方法表，字段表 用于指明哪些注解是运行时不可见的 RuntimeVisibleParameterAnnotation 方法表 作用与RuntimeVisibleAnnotations属性类似，作用对象方法 RuntimeInvisibleParameterAnnotation 方法表 作用与RuntimeInvisibleAnnotations属性类似，作用对象方法参数 AnnotationDefault 方法表 用于记录注解类元素的默认值 BootstrapMethods 类文件 用于保存invokeddynamic指令引用的引导方法限定符 每个属性名称都需要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，属性值的结构完全自定义的，只需要通过一个u4长度属性去说明属性值所占用的位数即可。 类型 名称 数量 u2 attribute_name_index 1 u2 attribute_length 1 u1 info attribute_length Code属性Java方法体中代码经过Javac编译器处理后，最终变为字节码指令存储在Code属性内。Code属性出现在方法表的属性集合中，接口和抽象类中的抽象方法不存在Code属性。 Code属性是Class文件中最重要的一个属性，如果把一个Java程序中的信息分为代码（方法体中的代码）和元数据（类、字段、方法定义及其他信息），那整个Class文件中，Code属性用于描述代码，其他数据项目都有于描述元数据。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 max_stack 1 u2 max_locals 1 u4 code_length 1 u1 code code_length u2 exception_table_length 1 exception_info exception_table exception_length u2 attributes_count 1 attribute_info attributes attributes_count attribute_name_index是指向CONSTANT_Utf8_info型常量的索引，其值固定为Code，代表该属性的属性名称，attribute_length表示属性值长度，属性名称索引与属性长度共6字节。 max_stack代表操作数栈最大深度，虚拟机运行时需要根据该值来分配栈帧中的操作数栈深度。 max_locals代表局部变量表所需内存空间，单位Slot，是虚拟机为局部变量表分配内存所使用的最小单位。byte、char、float、int、short、boolean、returnAddress等长度不超过32位的数据类型，每个局部变量占用1个Slot，而double和long这两种64位的数据类型则占用2个Slot。方法参数包括实例方法中的隐藏参数this、显式异常处理器的参数就是try-catch语句中catch块所定义的异常、方法体中定义的局部变量，都需要使用局部变量表来存放。局部变量中的Slot可以重用，当代码执行超出一个局部变量的作用域时，这个局部变量所占的Slot可以被其他局部变量所使用，Javac编译器会根据变量的作用域来分配Slot给各个变量使用，然后计算出max_locals的大小。 code_length和code用来存储Java源程序编译后生成的字节码指令。code_length代表字节码长度，code用于存储字节码指令的一系列字节流。每个字节码指令都是u1类型的数据，当虚拟机读取code中的字节码时，能够对应找出这个字节码代表的指令，指令后面是否需要跟随参数，参数应该如何理解。u1数据类型取值范围为0x00~0xFF，一共可表达256条指令，目前虚拟机规范定义了约200条编码值对应的指令含义。 code_length虽然是一个u4类型的数据，但虚拟机限制方法不允许超过65535条字节码指令，即它实际上只使用了u2的长度，如果超过限制Javac编译器会拒绝编译。在编译一个很浮渣的JSP文件时，某些JSP编译器会把JSP内容和页面输出信息归并于一个方法，可能因方法生成字节码超长导致编译失败。 123456789101112public com.coms.jvm.ClassFileConstantPool.TestClassA(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 3: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/coms/jvm/ClassFileConstantPool/TestClassA; 从上面的代码可以看到，实例方法明显没有参数，但locals和args_size的值却为1，这是Java程序一个很重要的访问机制，在任何实例方法中，都可以通过this关键字访问到此方法的所属的对象，Javac编译器编译时把对this关键字的访问转变为对一个普通方法参数的访问，在虚拟机调用实例方法时自动传入此参数。 在字节码指令之后是方法的显示异常处理表集合exception_table，它对应Code属性来说并不是必须存在的。 123456Exception table: from to target type 0 4 8 Class java/lang/Exception 0 4 17 any 8 13 17 any 17 19 17 any Exceptions属性Exceptions属性是在方法表中于Code属性平级的属性，区别于前面的Code属性中的异常表。其作用是列举方法中可能抛出的受检查的异常，也就是方法描述时在throws关键字后面列举的异常。 12Exceptions: throws java.lang.Exception, java.sql.SQLException 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 attribute_of_exceptions 1 u2 exception_index_table number_of_exceptions attribute_of_exceptions表示方法可能抛出attribute_of_exceptions种异常，每一种受查异常使用一个exception_index_table项表示，exception_index_table时一个指向常量池种CONSTANT_Class_info型常量索引，代表了该受查异常的类型。 LineNumberTable属性LineNumberTable属性用于描述Java源码行号与字节码行号（字节码偏移量）之间的对应关系。并非运行时必需属性，默认会生成到Class文件中，可以在Javac种使用-g:none或-g:line选项来取消或要求生成该项信息。如果选择不生成该属性，当程序抛出异常时，堆栈中将不会显示出错的行号，在调试程序时也无法按照源码行来设置断点。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 line_number_table_length 1 line_number_info line_number_table line_number_table_length line_number_table是一个数量为line_number_table_length、类型为line_number_info的集合，line_number_info包括了字节码行号start_pc和Java源码行号line_number两个u2类型的数据。 LocalVeriableTable属性LocalVeriableTable属性用于描述栈帧中局部变量表中的变量与Java源码中定义的变量之间的关系，非运行时必需属性，默认生成到Class文件中，可以在Javac种使用-g:none或-g:vars选项来取消或要求生成该项信息。如果不生成该属性，当其他人引用该方法时，所有参数名称都将丢失，IDE将会使用诸如arg0、arg1之类的占位符代替原有的参数名，虽对程序运行无影响，但对代码编写带来较大不便，且在调试时无法根据参数名称从上下文中获得参数值。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 local_veriable_table_length 1 local_veriable_info local_veriable_table local_veriable_table_length local_veriable_info代表一个栈帧与源码中局部变量的关联。下表是local_veriable_info项目结构。 类型 名称 数量 u2 start_pc 1 u2 length 1 u2 name_index 1 u2 descriptor_index 1 u2 index 1 start_pc和length属性分别代表这个局部变量的生命周期开始字节码偏移量及其作用范围覆盖长度，两者结合就是该局部变量在字节码之中的作用范围。 name_index和descriptor_index都是指向常量池中CONSTANT_UTF8_info型常量索引，分别代表局部变量名称以及该局部变量的描述符。 index是该局部变量在栈帧局部变量表中Slot位置，当该变量数据类型是64位类型是，它占用的Slot位index和index+1。 LocalVeriableTypeTable属性LocalVeriableTypeTable属性是LocalVeriableTable属性的姐妹属性，其结构与LocalVeriableTable非常相似，仅仅把记录字段描述符的descriptor_index替换成了字段的特征签名，对于非泛型类型来说，描述符和特征签名能描述的信息基本上一致，但泛型中，描述符中泛型的参数化类型被擦除，描述符不能准确描述泛型类型。 SourceFile属性SourceFile属性用于记录生成这个Class文件的源码文件名称，定长属性，非运行时必需属性，默认生成到Class文件中，可以在Javac种使用-g:none或-g:source选项来取消或要求生成该项信息。Java中大多数类的类名和文件名一致，但内部类列外，如果不生成该属性，当抛异常时，堆栈中将不会显示出错误代码所属的文件名。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 sourcefile_index 1 sourcefile_index数据项是指向常量池中CONSTANT_UTF8_info型常量索引，常量值是源文件的文件名。 ConstantValue属性ConstantValue属性的作用是通知虚拟机自动为静态变量赋值，定长属性，只有被final关键字修饰的变量才可以使用这项属性。对于非static类型的变量赋值时在实例构造器&lt;init&gt;方法中进行的，而static类型变量，有两种方式可以选择，在类构造器&lt;clinit&gt;方法中或者使用ConstantValue属性。目前在Sun Javac编译器中，如果同时使用final和static修饰变量，且该变量数据类型是基本数据类型或者java.lang.String，就生成ConstantValue属性类进行初始化，如果这个变量没有别final修饰或者并非基本类型及字符串，则会在&lt;clinit&gt;方法中进行初始化。 虚拟机规范中只要求了有ConstantValue属性的字段必须设置ACC_STATIC标志，并没有强制要求设置ACC_FINAL标志，对final关键字的要求是Javac编译器自己加入的限制。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 constantvalue_index 1 constantvalue_index数据项代表了常量池中一个字面量常量的引用，根据字段类型不同，字面量可以是CONSTANT_Long_info、CONSTANT_Float_info、CONSTANT_Double_info、CONSTANT_Integer_info、CONSTANT_String_info InnerClasses属性InnerClasses属性用于记录内部类与宿主类之间的关联，如果类中定义了内部类，编译器将会为它以及它所包含的内部类生成InnerClasses属性。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_classes 1 inner_classes_info inner_classes number_of_classes 数据项inner_classes_info代表需要记录多少个内部类信息，每个内部类信息都由一个inner_classes_info表进行描述。 类型 名称 数量 u2 inner_class_info_index 1 u2 other_class_info_index 1 u2 inner_name_index 1 u2 inner_class_access_flags 1 inner_class_info_index和other_class_info_index都是指向常量池中CONSTANT_Class_info型常量索引，分别代表内部类和宿主类的符号引用；inner_name_index是指向常量池中CONSTANT_UTF8_info型常量索引，代表这个内部类的名称，如果是匿名内部类该项值为0；inner_class_access_flags是内部类的访问标志，类似于类的access_flags。 Deprecated &amp; Synthetic属性Deprecated和Synthetic两个属性都属于标志类型的布尔属性，只存在有和没有的区别，没有属性值的概念。 Deprecated属性用于表示某个类、字段、方法，已经被程序作者定为不再推荐使用，通过在代码中使用@deprecated注解进行设置。 Synthetic属性代表此字段或者方法并不是由Java源代码直接生成的，而是由编译器自行添加的，标识一个类、字段或者方法是编译器自动产生的，也可以设置访问标志中的ACC_SYNTHETIC标志位。所有由非用户代码产生的类、方法及字段都应当至少设置Synthetic属性和ACC_SYNTHETIC标志位中的一项，唯一例外是实例构造器&lt;init&gt;和类构造器&lt;clinit&gt;。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 attribute_length的值必须为0x00000000，因为没有任何属性值需要设置。 StackMapTable属性StackMapTable属性JDK1.6增加到Class文件规范中，在JDK1.7中强制代替原本基于类型推断的字节码验证器，它是一个复杂的变长属性，位于Code属性的attributes属性表中，该属性会在虚拟机类加载的字节码验证阶段被新类型检查验证器使用，目的在于替代以前比较消耗性能的基于数据流分析的类型推导验证器。 新验证器在同样能保证Class文件合法性的前提下，省略了在运行期通过数据流分析去确认字节码的行为逻辑合法性的步骤，而是在编译阶段将一系列的验证类型直接记录在Class文件中，通过检查这些验证类型代替了类型推导过程，从而大幅度提升了字节码验证的性能。 StackMapTable属性中包含0至多个栈映射帧，每个栈映射帧都显式或隐式地代表了一个字节码偏移量，用于表示该执行到该字节码时局部变量表和操作数栈的验证类型。类型检查验证器会通过检查目标方法的局部变量和操作数栈所需要的类型来确定一段字节码指令是否符合逻辑约束。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_entries 1 stack_map_frame stack_map_frame_entries number_of_entries 在版本号大于或等于50.0的Class文件中，如果方法的Code属性中没有附带StackMapTable属性，意味着它带有一个隐式的StackMap属性，起作用等同于number_of_entries值为0的StackMapTable属性。一个方法的Code属性最多只能有一个StackMapTable属性，否则将抛出ClassFormatError异常。 Signature属性Signature属性在JDK1.5增加到Class文件规范中，可选定长属性，可以出现于类、字段表和方法表结构的属性表中。任何类、接口、初始化方法或成员的泛型签名如果包含了类型变量或参数化类型，则Signature属性会为它记录泛型签名信息，之所以这样是由于Java的泛型采用的是擦除法实现的伪泛型，在字节码中，泛型信息编译之后类型变量和参数化类型都被擦除了，运行期做反射时无法获得泛型信息。Signature属性就是为了弥补这个缺陷，现在Java的反射API能获取泛型类型，最终的数据类来源为Signature属性。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 signature_index 1 signature_index值必须时一个对常量池的有效索引，参量池在该索引处必须是CONSTANT_UTF8_info结构，表示类签名、方法类型签名或字段类型签名。Signature属性是类文件属性该结构表示类签名，Signature属性是方法表的属性该结构表示方法类型签名，Signature属性是字段表的属性该结构表示字段类型签名。 BootstrapMethods属性BootstrapMethods属性在JDK1.7增加到Class文件规范中，复杂变长属性，位于类文件属性表中。该属性用于保存invokedynamic指令引用的引导方法限定符。如果某个类文件结构的常量池中曾经出现过CONSTANT_InvokeDynamic_info类型的常量，那该类文件的属性表中必须存在一个明确的BootstrapMethods属性，即使出现多次也最多也只能有一个。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 num_bootstrap_methods 1 bootstrap_method bootstrap_methods num_bootstrap_methods num_bootstrap_methods值为bootstrap_methods[]数组中的引导方法限定符的数量，bootstrap_methods[]数组的每个成员都包含一个指向常量池CONSTANT_MethodHandle结构的索引值，它代表示一个引导方法，还包含了该引导方法静态参数的序列。其中num_bootstrap_method表结构如下所示： 类型 名称 数量 u2 bootstrap_method_ref 1 u4 num_bootstrap_arguments 1 u2 bootstrap_arguments num_bootstrap_arguments bootstrap_method_ref值必须是一个对常量池的有效索引，且该索引值必须是一个CONSTANT_MethodHandle_info结构；num_bootstrap_arguments表示bootstrap_arguments[]数组成员的数量；bootstrap_arguments[]数组成员必须是一个对常量池有效的索引，且必须是一下结构之一：CONSTANT_String_info、CONSTANT_Class_info、CONSTANT_Integer_info、CONSTANT_Long_info、CONSTANT_Float_info、CONSTANT_Double_info、CONSTANT_MethodHandle_info、CONSTANT_MothodType_info。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Maven标签全解","date":"2018-01-21T16:00:00.000Z","path":"Blog/Maven/Maven标签全解/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641&lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd \"&gt; &lt;!-- 父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。 --&gt; &lt;parent&gt; &lt;!-- 被继承的父项目的构件标识符 --&gt; &lt;artifactId/&gt; &lt;!-- 被继承的父项目的全球唯一标识符 --&gt; &lt;groupId/&gt; &lt;!-- 被继承的父项目的版本 --&gt; &lt;version/&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 --&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!-- 声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app --&gt; &lt;groupId&gt;asia.banseon&lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源码，二进制发布和WARs等。 --&gt; &lt;artifactId&gt;banseon-maven2&lt;/artifactId&gt; &lt;!-- 项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型 --&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- 项目当前版本，格式为:主版本.次版本.增量版本-限定版本号 --&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- 项目的名称, Maven产生的文档用 --&gt; &lt;name&gt;banseon-maven&lt;/name&gt; &lt;!-- 项目主页的URL, Maven产生的文档用 --&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。 --&gt; &lt;description&gt;A maven project to study maven.&lt;/description&gt; &lt;!-- 描述了这个项目构建环境中的前提条件。 --&gt; &lt;prerequisites&gt; &lt;!-- 构建该项目或使用该插件所需要的Maven的最低版本 --&gt; &lt;maven/&gt; &lt;/prerequisites&gt; &lt;!-- 项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira --&gt; &lt;issueManagement&gt; &lt;!-- 问题管理系统（例如jira）的名字， --&gt; &lt;system&gt;jira&lt;/system&gt; &lt;!-- 该项目使用的问题管理系统的URL --&gt; &lt;url&gt;http://jira.baidu.com/banseon&lt;/url&gt; &lt;/issueManagement&gt; &lt;!-- 项目持续集成信息 --&gt; &lt;ciManagement&gt; &lt;!-- 持续集成系统的名字，例如continuum --&gt; &lt;system/&gt; &lt;!-- 该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。 --&gt; &lt;url/&gt; &lt;!-- 构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） --&gt; &lt;notifiers&gt; &lt;!-- 配置一种方式，当构建中断时，以该方式通知用户/开发者 --&gt; &lt;notifier&gt; &lt;!-- 传送通知的途径 --&gt; &lt;type/&gt; &lt;!-- 发生错误时是否通知 --&gt; &lt;sendOnError/&gt; &lt;!-- 构建失败时是否通知 --&gt; &lt;sendOnFailure/&gt; &lt;!-- 构建成功时是否通知 --&gt; &lt;sendOnSuccess/&gt; &lt;!-- 发生警告时是否通知 --&gt; &lt;sendOnWarning/&gt; &lt;!-- 不赞成使用。通知发送到哪里 --&gt; &lt;address/&gt; &lt;!-- 扩展配置项 --&gt; &lt;configuration/&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!-- 项目创建年份，4位数字。当产生版权信息时需要使用这个值。 --&gt; &lt;inceptionYear/&gt; &lt;!-- 项目相关邮件列表信息 --&gt; &lt;mailingLists&gt; &lt;!-- 该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。 --&gt; &lt;mailingList&gt; &lt;!-- 邮件的名称 --&gt; &lt;name&gt;Demo&lt;/name&gt; &lt;!-- 发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;post&gt;banseon@126.com&lt;/post&gt; &lt;!-- 订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;subscribe&gt;banseon@126.com&lt;/subscribe&gt; &lt;!-- 取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;unsubscribe&gt;banseon@126.com&lt;/unsubscribe&gt; &lt;!-- 你可以浏览邮件信息的URL --&gt; &lt;archive&gt;http:/hi.baidu.com/banseon/demo/dev/&lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!-- 项目开发者列表 --&gt; &lt;developers&gt; &lt;!-- 某个项目开发者的信息 --&gt; &lt;developer&gt; &lt;!-- SCM里项目开发者的唯一标识符 --&gt; &lt;id&gt;HELLO WORLD&lt;/id&gt; &lt;!-- 项目开发者的全名 --&gt; &lt;name&gt;banseon&lt;/name&gt; &lt;!-- 项目开发者的email --&gt; &lt;email&gt;banseon@126.com&lt;/email&gt; &lt;!-- 项目开发者的主页的URL --&gt; &lt;url/&gt; &lt;!-- 项目开发者在项目中扮演的角色，角色元素描述了各种角色 --&gt; &lt;roles&gt; &lt;role&gt;Project Manager&lt;/role&gt; &lt;role&gt;Architect&lt;/role&gt; &lt;/roles&gt; &lt;!-- 项目开发者所属组织 --&gt; &lt;organization&gt;demo&lt;/organization&gt; &lt;!-- 项目开发者所属组织的URL --&gt; &lt;organizationUrl&gt;http://hi.baidu.com/banseon&lt;/organizationUrl&gt; &lt;!-- 项目开发者属性，如即时消息如何处理等 --&gt; &lt;properties&gt; &lt;dept&gt;No&lt;/dept&gt; &lt;/properties&gt; &lt;!-- 项目开发者所在时区， -11到12范围内的整数。 --&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!-- 项目的其他贡献者列表 --&gt; &lt;contributors&gt; &lt;!-- 项目的其他贡献者。参见developers/developer元素 --&gt; &lt;contributor&gt; &lt;name/&gt; &lt;email/&gt; &lt;url/&gt; &lt;organization/&gt; &lt;organizationUrl/&gt; &lt;roles/&gt; &lt;timezone/&gt; &lt;properties/&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!-- 该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。 --&gt; &lt;licenses&gt; &lt;!-- 描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。 --&gt; &lt;license&gt; &lt;!-- license用于法律上的名称 --&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;!-- 官方的license正文页面的URL --&gt; &lt;url&gt;http://www.baidu.com/banseon/LICENSE-2.0.txt&lt;/url&gt; &lt;!-- 项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖 --&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!-- 关于license的补充信息 --&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!-- SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。 --&gt; &lt;scm&gt; &lt;!-- SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。 --&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!-- 给开发者使用的，类似connection元素。即该连接不仅仅只读 --&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!-- 当前代码的标签，在开发阶段默认为HEAD --&gt; &lt;tag/&gt; &lt;!-- 指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。 --&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!-- 描述项目所属组织的各种属性。Maven产生的文档用 --&gt; &lt;organization&gt; &lt;!-- 组织的全名 --&gt; &lt;name&gt;demo&lt;/name&gt; &lt;!-- 组织主页的URL --&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;/organization&gt; &lt;!-- 构建项目需要的信息 --&gt; &lt;build&gt; &lt;!-- 该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;sourceDirectory/&gt; &lt;!-- 该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。 --&gt; &lt;scriptSourceDirectory/&gt; &lt;!-- 该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;testSourceDirectory/&gt; &lt;!-- 被编译过的应用程序class文件存放的目录。 --&gt; &lt;outputDirectory/&gt; &lt;!-- 被编译过的测试class文件存放的目录。 --&gt; &lt;testOutputDirectory/&gt; &lt;!-- 使用来自该项目的一系列构建扩展 --&gt; &lt;extensions&gt; &lt;!-- 描述使用到的构建扩展。 --&gt; &lt;extension&gt; &lt;!-- 构建扩展的groupId --&gt; &lt;groupId/&gt; &lt;!-- 构建扩展的artifactId --&gt; &lt;artifactId/&gt; &lt;!-- 构建扩展的版本 --&gt; &lt;version/&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!-- 当项目没有规定目标（Maven2 叫做阶段）时的默认值 --&gt; &lt;defaultGoal/&gt; &lt;!-- 这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。 --&gt; &lt;resources&gt; &lt;!-- 这个元素描述了项目相关或测试相关的所有资源路径 --&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven/messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。 --&gt; &lt;targetPath/&gt; &lt;!-- 是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。 --&gt; &lt;filtering/&gt; &lt;!-- 描述存放资源的目录，该路径相对POM路径 --&gt; &lt;directory/&gt; &lt;!-- 包含的模式列表，例如**/*.xml. --&gt; &lt;includes/&gt; &lt;!-- 排除的模式列表，例如**/*.xml --&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- 这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。 --&gt; &lt;testResources&gt; &lt;!-- 这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明 --&gt; &lt;testResource&gt; &lt;targetPath/&gt; &lt;filtering/&gt; &lt;directory/&gt; &lt;includes/&gt; &lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!-- 构建产生的所有文件存放的目录 --&gt; &lt;directory/&gt; &lt;!-- 产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。 --&gt; &lt;finalName/&gt; &lt;!-- 当filtering开关打开时，使用到的过滤器属性文件列表 --&gt; &lt;filters/&gt; &lt;!-- 子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置 --&gt; &lt;pluginManagement&gt; &lt;!-- 使用的插件列表 。 --&gt; &lt;plugins&gt; &lt;!-- plugin元素包含描述插件所需要的信息。 --&gt; &lt;plugin&gt; &lt;!-- 插件在仓库里的group ID --&gt; &lt;groupId/&gt; &lt;!-- 插件在仓库里的artifact ID --&gt; &lt;artifactId/&gt; &lt;!-- 被使用的插件的版本（或版本范围） --&gt; &lt;version/&gt; &lt;!-- 是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。 --&gt; &lt;extensions/&gt; &lt;!-- 在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。 --&gt; &lt;executions&gt; &lt;!-- execution元素包含了插件执行需要的信息 --&gt; &lt;execution&gt; &lt;!-- 执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标 --&gt; &lt;id/&gt; &lt;!-- 绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段 --&gt; &lt;phase/&gt; &lt;!-- 配置的执行目标 --&gt; &lt;goals/&gt; &lt;!-- 配置是否被传播到子POM --&gt; &lt;inherited/&gt; &lt;!-- 作为DOM对象的配置 --&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!-- 项目引入插件所需要的额外依赖 --&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 任何配置是否被传播到子项目 --&gt; &lt;inherited/&gt; &lt;!-- 作为DOM对象的配置 --&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 使用的插件列表 --&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt; &lt;phase/&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 在列的项目构建profile，如果被激活，会修改构建处理 --&gt; &lt;profiles&gt; &lt;!-- 根据环境参数或命令行参数激活某个构建处理 --&gt; &lt;profile&gt; &lt;!-- 构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。 --&gt; &lt;id/&gt; &lt;!-- 自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。 --&gt; &lt;activation&gt; &lt;!-- profile默认是否激活的标志 --&gt; &lt;activeByDefault/&gt; &lt;!-- 当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --&gt; &lt;jdk/&gt; &lt;!-- 当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt; &lt;os&gt; &lt;!-- 激活profile的操作系统的名字 --&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!-- 激活profile的操作系统所属家族(如 'windows') --&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!-- 激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!-- 激活profile的操作系统版本 --&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!-- 如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt; &lt;property&gt; &lt;!-- 激活profile的属性的名称 --&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!-- 激活profile的属性的值 --&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!-- 提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt; &lt;file&gt; &lt;!-- 如果指定的文件存在，则激活profile。 --&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists&gt; &lt;!-- 如果指定的文件不存在，则激活profile。 --&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!-- 构建项目所需要的信息。参见build元素 --&gt; &lt;build&gt; &lt;defaultGoal/&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath/&gt; &lt;filtering/&gt; &lt;directory/&gt; &lt;includes/&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath/&gt; &lt;filtering/&gt; &lt;directory/&gt; &lt;includes/&gt; &lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory/&gt; &lt;finalName/&gt; &lt;filters/&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt; &lt;phase/&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt; &lt;phase/&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules/&gt; &lt;!-- 发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!-- 参见repositories/repository元素 --&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt; &lt;name/&gt; &lt;url/&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt; &lt;name/&gt; &lt;url/&gt; &lt;layout/&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports/&gt; &lt;!-- 该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素 --&gt; &lt;reporting&gt; &lt;/reporting&gt; &lt;!-- 参见dependencyManagement元素 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 参见distributionManagement元素 --&gt; &lt;distributionManagement&gt; &lt;/distributionManagement&gt; &lt;!-- 参见properties元素 --&gt; &lt;properties/&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules/&gt; &lt;!-- 发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!-- 包含需要连接到远程仓库的信息 --&gt; &lt;repository&gt; &lt;!-- 如何处理远程仓库里发布版本的下载 --&gt; &lt;releases&gt; &lt;!-- true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled/&gt; &lt;!-- 该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt; &lt;updatePolicy/&gt; &lt;!-- 当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。 --&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;!-- 远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库 --&gt; &lt;id&gt;banseon-repository-proxy&lt;/id&gt; &lt;!-- 远程仓库名称 --&gt; &lt;name&gt;banseon-repository-proxy&lt;/name&gt; &lt;!-- 远程仓库URL，按protocol://hostname/path形式 --&gt; &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- 依赖的group ID --&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!-- 依赖的artifact ID --&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!-- 依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。 --&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应，尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在plugin里定义新的类型。所以前面的类型的例子不完整。 --&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。 --&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!-- 依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用 --&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!-- 仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。 --&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!-- 当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!-- 可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。 --&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!-- 该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 --&gt; &lt;reporting&gt; &lt;!-- true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。 --&gt; &lt;excludeDefaults/&gt; &lt;!-- 所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。 --&gt; &lt;outputDirectory/&gt; &lt;!-- 使用的报表插件和他们的配置。 --&gt; &lt;plugins&gt; &lt;!-- plugin元素包含描述报表插件需要的信息 --&gt; &lt;plugin&gt; &lt;!-- 报表插件在仓库里的group ID --&gt; &lt;groupId/&gt; &lt;!-- 报表插件在仓库里的artifact ID --&gt; &lt;artifactId/&gt; &lt;!-- 被使用的报表插件的版本（或版本范围） --&gt; &lt;version/&gt; &lt;!-- 任何配置是否被传播到子项目 --&gt; &lt;inherited/&gt; &lt;!-- 报表插件的配置 --&gt; &lt;configuration/&gt; &lt;!-- 一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标 --&gt; &lt;reportSets&gt; &lt;!-- 表示报表的一个集合，以及产生该集合的配置 --&gt; &lt;reportSet&gt; &lt;!-- 报表集合的唯一标识符，POM继承时用到 --&gt; &lt;id/&gt; &lt;!-- 产生报表集合时，被使用的报表的配置 --&gt; &lt;configuration/&gt; &lt;!-- 配置是否被继承到子POMs --&gt; &lt;inherited/&gt; &lt;!-- 这个集合里使用到哪些报表 --&gt; &lt;reports/&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID匹配到这里的依赖，并使用这里的依赖信息。 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。 --&gt; &lt;distributionManagement&gt; &lt;!-- 部署项目产生的构件到远程仓库需要的信息 --&gt; &lt;repository&gt; &lt;!-- 是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素 --&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;!-- 构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout/&gt; &lt;/snapshotRepository&gt; &lt;!-- 部署项目的网站需要的信息 --&gt; &lt;site&gt; &lt;!-- 部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置 --&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!-- 部署位置的名称 --&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!-- 部署位置的URL，按protocol://hostname/path形式 --&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!-- 项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。 --&gt; &lt;downloadUrl/&gt; &lt;!-- 如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。 --&gt; &lt;relocation&gt; &lt;!-- 构件新的group ID --&gt; &lt;groupId/&gt; &lt;!-- 构件新的artifact ID --&gt; &lt;artifactId/&gt; &lt;!-- 构件新的版本号 --&gt; &lt;version/&gt; &lt;!-- 显示给用户的，关于移动的额外信息，例如原因。 --&gt; &lt;message/&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部署），verified（被核实时正确的和最终的）。 --&gt; &lt;status/&gt; &lt;/distributionManagement&gt; &lt;!-- 以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。 --&gt; &lt;properties/&gt;&lt;/project&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven常用","date":"2018-01-19T16:00:00.000Z","path":"Blog/Maven/Maven常用/","text":"本地Jar包发布将本地的jar包发布到本地的Maven仓库中，-Dfile是需要上传的jar包的绝对路径,-DgroupId构成该jar包在pom.xml的坐标对应&lt;groupId&gt;标签的内容，-DartifactId构成该jar包在pom.xml的坐标对应&lt;artifactId&gt;标签的内容，-Dversion依赖包的版本对应&lt;version&gt;标签的内容，-Dpackaging安装文件的种类。 123456mvn install:install-file -Dfile=E:\\activation-1.0.2.jar -DgroupId=javax.activation -DartifactId=activation -Dversion=1.0.2 -Dpackaging=jar 在项目中使用搭建的私服123456789101112131415161718192021222324252627&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;nexus&lt;/name&gt; &lt;url&gt;http://192.168.100.10/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;nexus&lt;/name&gt; &lt;url&gt;http://192.168.100.10/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; Maven打包时跳过测试12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.18.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt; mvn install -DskipTests mvn install -Dmaven.test.skip=true 使用本地依赖1234567&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;rt&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/rt.jar&lt;/systemPath&gt;&lt;/dependency&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven常用插件","date":"2018-01-19T16:00:00.000Z","path":"Blog/Maven/Maven常用插件/","text":"IDEA中POM变更IDEA中由于POM中未配置maven-compiler-plugin插件可能导致每次POM发生变更时，Language level变成5，从而导致编译时不成功。 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; 打jar包插件Maven提供了三种打包插件： maven-jar-plugin：Maven默认打包插件，用来创建Project JAR maven-shade-plugin：用来打可执行包，fat Jar maven-assembly-plugin：定制化打包 12345678910111213141516&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- 指定添加项目中使用的外部jar的classpath项 --&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!-- 指定外部jar所在的路径 --&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;!-- 指定本项目jar包的Main-Class --&gt; &lt;mainClass&gt;com.long.ent.DemoApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt;&lt;/plugin&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.springframework.boot.maven.PropertiesMergingResourceTransformer\"&gt; &lt;resource&gt;META-INF/spring.factories&lt;/resource&gt; &lt;/transformer&gt; &lt;!--&lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ComponentsXmlResourceTransformer\"/&gt;--&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\"/&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"&gt; &lt;mainClass&gt;com.icloud.DemoApplication&lt;/mainClass&gt; &lt;/transformer&gt; &lt;transformer implementation=\"com.github.edwgiz.mavenShadePlugin.log4j2CacheTransformer.PluginsCacheFileTransformer\" /&gt; &lt;/transformers&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.edwgiz&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin.log4j2-cachefile-transformer&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;com.icloud.DemoApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!--执行器 mvn assembly:assembly--&gt; &lt;execution&gt; &lt;id&gt;make-jar&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;ex-$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;assembly.descriptor1&#125;&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;assembly.outputDirectory&#125;&lt;/outputDirectory&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;make-tar&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/common_tar.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;assembly.outputDirectory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 将依赖打入jar包123456789101112131415161718192021222324&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.icloud.ICloudApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 打war包插件12345678910111213141516171819202122&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;warName&gt;project_name&lt;/warName&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/spring/config/$&#123;config&#125;&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/classes/spring/config&lt;/targetPath&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 编译源代码插件123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt; 测试插件JUnit可以通过@Ignore注解标记忽略测试方法。Java中主流的单元测试框架为JUnit和TestNG。maven-surefire-plugin插件时测试运行器，它所作的只是在构建执行到特定声明周期阶段时，来执行JUnit或者TestNG的测试用例。 default生命周期中的test阶段被定义为使用单元测试框架运行测试。maven-surefire-plugin插件的test目标的内置绑定就是test阶段。 默认情况下，maven-surefire-plugin插件的test目标会自动执行测试源码路径下（默认为src/test/java/）所有符合一组命名模式的测试类: **Test*.java : 任何子目录下所有命名以Test开头的Java类 **/*Test.java：任何子目录下所有命名以Test结尾的Java类 **/*TestCase.java：任何子目录下所有命名以TestCase结尾的Java类 以Tests结尾的测试类时不会得以自动执行的。 mvn package -DskipTests命令或者配置maven-surefire-plugin插件的&lt;skipTests&gt;true&lt;/skipTests&gt;可以跳过测试，但不会跳过测试代码的编译。 mvn package -Dmaven.test.skip=true命令不仅会跳过测试，还会跳过测试代码的编译。maven.test.skip参数同时控制了maven-compiler-plugin和maven-surefire-plugin两个插件的行为。 还可以通过mvn test -Dtest = Random*Test,AccountTest命令指定执行的测试文件。 123456789101112131415161718&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- Sets the VM argument line used when unit tests are run. --&gt; &lt;argLine&gt;$&#123;surefireArgLine&#125;&lt;/argLine&gt; &lt;!-- Maven打包时跳过测试 --&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;excludes&gt; &lt;exclude&gt;com.proto.core.services.it.**&lt;/exclude&gt; &lt;/excludes&gt; &lt;includes&gt; &lt;include&gt;com.proto.core.services.ut.*&lt;/include&gt; &lt;include&gt;com.proto.core.services.ut.web.*&lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 依赖复制插件1234567891011121314151617&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.10&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; Tomcat插件1234567891011&lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;uriEncoding&gt;utf-8&lt;/uriEncoding&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;/configuration&gt;&lt;/plugin&gt; Jetty插件12345678910111213141516&lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.2.21.v20170120&lt;/version&gt; &lt;configuration&gt; &lt;webApp&gt; &lt;contextPath&gt;/ccps&lt;/contextPath&gt; &lt;/webApp&gt; &lt;stopKey&gt;exit&lt;/stopKey&gt; &lt;stopPort&gt;9090&lt;/stopPort&gt; &lt;scanIntervalSeconds&gt;1&lt;/scanIntervalSeconds&gt; &lt;httpConnector&gt; &lt;port&gt;28074&lt;/port&gt; &lt;/httpConnector&gt; &lt;/configuration&gt;&lt;/plugin&gt; 资源文件处理插件123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;!-- @符号为结束符号,遇到就表示结束过滤 --&gt; &lt;delimiter&gt;@&lt;/delimiter&gt; &lt;/delimiters&gt; &lt;useDefaultDelimiters&gt;false&lt;/useDefaultDelimiters&gt; &lt;/configuration&gt;&lt;/plugin&gt; 默认主资源文件目录为src/main/resources，需要添加额外的资源文件目录，可通过配置maven-resources-plugin插件来实现 XSD到Java文件的自动生成插件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;!-- 将XSD文件自动生成POJO对象，每次变更用Maven重新编译一下 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2.maven2&lt;/groupId&gt; &lt;artifactId&gt;maven-jaxb2-plugin&lt;/artifactId&gt; &lt;version&gt;0.14.0&lt;/version&gt; &lt;configuration&gt; &lt;schemaDirectory&gt;src/main/resources/xsd&lt;/schemaDirectory&gt; &lt;generateDirectory&gt;src/main/java/&lt;/generateDirectory&gt; &lt;packageLevelAnnotations&gt;false&lt;/packageLevelAnnotations&gt; &lt;noFileHeader&gt;true&lt;/noFileHeader&gt; &lt;episode&gt;false&lt;/episode&gt; &lt;readOnly&gt;true&lt;/readOnly&gt; &lt;!-- 如果不加生成的类注释会中文乱码 --&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;!-- 设置生成的类的注解语言en为英文 --&gt; &lt;locale&gt;en&lt;/locale&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xsd1-generate&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;args&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;arg&gt;-Xannotate&lt;/arg&gt; &lt;!-- 使用XJC给生成Java类添加父类 --&gt; &lt;arg&gt;-Xinheritance&lt;/arg&gt; &lt;!-- 给生成Java类添加equals方法 --&gt; &lt;arg&gt;-Xequals&lt;/arg&gt; &lt;!-- 给生成Java类添加hashCode方法 --&gt; &lt;arg&gt;-XhashCode&lt;/arg&gt; &lt;arg&gt;-Xvalue-constructor&lt;/arg&gt; &lt;arg&gt;-nv&lt;/arg&gt; &lt;/args&gt; &lt;extension&gt;true&lt;/extension&gt; &lt;schemaIncludes&gt; &lt;include&gt;test.xsd&lt;/include&gt; &lt;/schemaIncludes&gt; &lt;bindingIncludes&gt; &lt;include&gt;test.xjb&lt;/include&gt; &lt;/bindingIncludes&gt; &lt;generatePackage&gt;com.test.support.xml&lt;/generatePackage&gt; &lt;plugins&gt; &lt;!-- 基础插件依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics&lt;/artifactId&gt; &lt;version&gt;1.11.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- -Xequals和-XhashCode参数用于生成equals和hashcode方法使用 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-value-constructor&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics-annotate&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 每次变更Schema后通过Maven编译一下即可，若有多个Schema文件且需要将生成的POJO放置不同的目录下，只需要添加多个execution即可。 XSLT转换插件12345678910111213141516171819202122232425262728293031&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;xml-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;configuration&gt; &lt;transformationSets&gt; &lt;transformationSet&gt; &lt;dir&gt;src/main/resources/xsd&lt;/dir&gt; &lt;includes&gt;test.xsd&lt;/includes&gt; &lt;outputDir&gt;target/transformed-schema&lt;/outputDir&gt; &lt;stylesheet&gt;src/main/resources/xsl/test.xsl&lt;/stylesheet&gt; &lt;/transformationSet&gt; &lt;transformationSet&gt; &lt;dir&gt;src/main/resources/xsd&lt;/dir&gt; &lt;includes&gt;test.xjb&lt;/includes&gt; &lt;outputDir&gt;target/transformed-jaxb-schema&lt;/outputDir&gt; &lt;stylesheet&gt;src/main/resources/xsl/test-jaxb.xsl&lt;/stylesheet&gt; &lt;/transformationSet&gt; &lt;/transformationSets&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xslt-generate&lt;/id&gt; &lt;!-- 将该插件的生命周期绑定到compile上 --&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;transform&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Class文件结构","date":"2018-01-19T16:00:00.000Z","path":"Blog/Java/VM/Class文件结构/","text":"各种不同平台的虚拟机与平台都统一使用的程序存储格式——字节码是构成平台无关性的基石。 虚拟机也是语言无关的，实现语言无关性的基础任然是虚拟机和字节码存储格式。Java虚拟机不和包括Java在内的任何语言绑定，它只与Class文件这种特定的二进制文件格式所关联，Class文件中包含Java虚拟机指令集和符号表以及若干其他辅助信息。 基于安全考虑Java虚拟机规范要求在Class文件中使用许多强制性的语法和结构化约束，任何一门功能性语言都可以表示为一个能被Java虚拟机所接受的有校Class文件。 Java语言中的各种变量、关键字和运算符号的语义最终都是由多条字节码命令组合而成的，因此字节码命令所能提供的语义描述能力肯定会比Java语言本身更强大。 Class类文件的结构任何一个Class文件都对应着唯一一个类或接口的定义信息，但类或接口并不一定都定义在文件中，也可以通过类加载器直接生成。 Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在Class文件中无任何分割符，Class文件中存储的内容几乎全部是程序运行的必要数据，当遇到需要占用8位字节以上空间的数据项时，按照高位在前的方式分割成若干8位字节进程存储。 Class文件格式采用一种类似C语言结构体的伪结构来存储数据，这种伪结构中只有无符号数和表两种数据类型。 无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1、2、4、8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。 表是由多个无符号数或者其他表作为数据项构成的符合数据类型，所有表都习惯地以_info结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表。 无论无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常会使用一个前置容量计数器加若干个连续数据项的形式，这时称这一系列连续的某一类型的数据为某一类型的集合。 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attribute_count 1 attribute_info attributes attributes_count 魔数与Class文件版本每个Class文件的头4个字节magic称为魔数，它唯一的作用是确定这个文件是否是一个能被虚拟机接受的Class文件。很多文件存储标准中都使用魔数来进行身份识别，譬如图片格式。Class文件的魔数值为0xCAFEBABE。 紧接着的魔数的4个字节minor_version和major_version存储的是Class文件的次版本号和主版本号。Java版本号是从45开始的，每个JDK大版本发布主版本号向上加1，高版本的JDK能向下兼容，但不能运行以后版本的Class文件，即使文件格式未发生变化，虚拟机也拒绝执行超过器版本号的Class文件。 123456public class com.coms.jvm.ClassFileConstantPool.ClassTest SourceFile: \"ClassTest.java\" minor version: 0 major version: 51 flags: ACC_PUBLIC, ACC_SUPERConstant pool: 静态常量池紧接着主次版本号之后的constant_pool_count和constant_pool是常量池入口，常量池可也理解为Class文件中的资源仓库，是Class文件结构中与其他项目关联最多的数据类型，也是Class文件中占用空间最大的数据项目之一，同时它还是在Class文件中第一个出现表类型数据的项目。 常量池中常量不是固定的，所以常量池的入口需要用一个u2类型的constant_pool_count来表示常量池容量计数值。容量计数是从1开始，目的在于满足后面某些指向常量池的索引值的数据在特定情况下需要表达不引用任何常量池项目时可以把索引值设置为0。Class文件结构中只有常量池的容量计数时从1开始，其他集合类型接口索引集合、字段表集合、方法表集合等容量计数都是从0开始。 常量池中主要存放字面量和符号引用两大类常量。字面量比较接近Java层面的常量，如文本字符串、声明为fianl的常量值等。符号引用属于编译原理方面的概念，包括类和接口的全限定名、字段和名称和描述符、方法的名称和描述符三类常量。 如果将ClassTest类放到com.jvm包下，则ClassTest类的全限定名为com.jvm.ClassTest。JVM编译器将类编译成class文件后，此全限定名在class文件中是以二进制形式存储的，它会把全限定符.换成/，即在class文件中存储的ClassTest类的全限定名是com/louis/jvm/ClassTest。 Java代码在进行Javac编译时，在Class文件中不会保存各个方法、字段的内存布局信息，这些字段、方法的符号引用不经过运行期转换无法得到真正的内存入口地址，也无法直接被虚拟机使用，在虚拟机加载Class文件的时候进行动态连接。虚拟机运行时需要从常量池获得对应的符号引用，在类创建时或运行时解析、翻译到具体的内存地址中。 常量池中每一项常量都是一个表，JDK1.7中共14种表，且这14种表各自均有自己的结构，这14种表有一个共同特点开始的第一位是一个u1类型的标志位tag，代表当前常量属于哪种常量类型。下表是14种常量类型所代表的具体含义： 类型 标志 描述 CONSTANT_Utf8_info 1 UTF-8编码的字符串 CONSTANT_Integer_info 3 整形字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整型字面量 CONSTANT_Double_info 6 双精度浮点型字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的部分符号引用 CONSTANT_MethodHandle_info 15 表示方法句柄 CONSTANT_MothodType_info 16 标识方法类型 CONSTANT_InvokeDynamic_info 18 表示一个动态方法调用点 CONSTANT_Class_info型常量的结构如下表所示，tag是标志位用于区分常量类型，name_index是一个索引值，它指向常量池中一个CONSTANT_Utf8_info类型常量，代表该类或接口的全局限定名。 类型 名称 数量 u1 tag 1 u2 name_index 1 CONSTANT_Utf8_info型常量的结构如下表所示，tag是标志位用于区分常量类型，length值表示UTF-8编码的字符串长度的字节数，紧跟着的长度位length字节的连续数据是一个使用UTF-8缩略编码表示的字符串。 UTF-8缩略编码与普通编码的区别是从\\u0001到\\u007f之间的字符的缩略编码使用一个字节表示，从\\u0080到\\u00ff之间的字符的缩略编码使用两个字节表示，从\\u0800到\\uffff之间的字符的缩略编码按照普通UTF-8编码规则使用三个字节表示。 Class文件中方法、字段等都需要引用CONSTANT_Utf8_info型常量来描述名称，所以CONSTANT_Utf8_info型常量的最大长度就是Java中方法、字段名的最大长度，这里的长度就是length的最大值，即u2类型能表达的最大值65535，故Java程序中变量、方法名的定义不能超过64KB英文字符，否则将无法被编译。 类型 名称 数量 u1 tag 1 u2 length 1 u1 bytes length 123456789101112131415161718Constant pool: #1 = Methodref #3.#15 // java/lang/Object.\"&lt;init&gt;\":()V #2 = Class #16 // com/coms/jvm/ClassFileConstantPool/ClassTest #3 = Class #17 // java/lang/Object #4 = Utf8 date #5 = Utf8 Ljava/util/Date; #6 = Utf8 &lt;init&gt; #7 = Utf8 ()V #8 = Utf8 Code #9 = Utf8 LineNumberTable #10 = Utf8 LocalVariableTable #11 = Utf8 this #12 = Utf8 Lcom/coms/jvm/ClassFileConstantPool/ClassTest; #13 = Utf8 SourceFile #14 = Utf8 ClassTest.java #15 = NameAndType #6:#7 // \"&lt;init&gt;\":()V #16 = Utf8 com/coms/jvm/ClassFileConstantPool/ClassTest #17 = Utf8 java/lang/Object 其中&lt;init&gt;为编译器添加的实例构造器。 访问标志紧接着常量池之后的u2类型的access_flags是访问标志，用于识别一些类或接口层次的访问信息，包括该Class是类还是接口，是否定义为public类型，是否定义位abstract类型，如果是类是否被修饰为final等。 标志名 标志值 标志含义 针对的对像 ACC_PUBLIC 0x0001 是否为public类型 所有类型 ACC_FINAL 0x0010 是否为final类型 类 ACC_SUPER 0x0020 是否允许使用invokespecial字节码指令的新语义 类和接口 ACC_INTERFACE 0x0200 标识为接口类型 接口 ACC_ABSTRACT 0x0400 是否为抽象类型 类和接口 ACC_SYNTHETIC 0x1000 标识该类不由用户代码生成 所有类型 ACC_ANNOTATION 0x2000 标识为注解类型 注解 ACC_ENUM 0x4000 标识为枚举类型 枚举 access_flags中一共有16个标志位可以使用，当前只定义了其中8个，没有使用到的标志位要求一律为0。当JVM在编译某个类或者接口的源代码时，JVM会解析出这个类或者接口的访问标志信息，然后将这些标志设置到访问标志。 123456public class com.coms.jvm.ClassFileConstantPool.ClassTest SourceFile: \"ClassTest.java\" minor version: 0 major version: 51 flags: ACC_PUBLIC, ACC_SUPERConstant pool: 索引在Class文件中的索引包括类索引、父类索引、接口索引集合,Class文件中由这三项数据来确定该类的继承关系。类索引和父类索引都是u2类型的数据，接口索引集合是一组u2类型的数据集合。 类索引用于确定该类的全限定名，父类索引用于确定该类的父类的全限定名,接口索引集合用于描述该类实现了哪些接口。 类索引、父类索引和接口索引集合都按顺序排列在访问标志之后，类索引和父类索引他们各自指向一个CONSTANT_Class_info型常量，通过CONSTANT_Class_info类型的常量中的name_index索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。 对于接口索引集合，入口的u2类型的数据为接口计数器interfaces_count，表示索引表的容量。如果该类没有实现任何接口，则该计数器值为0，后面接口的索引表不再占用任何字节。 字段表集合字段表用于描述接口或类中声明的变量，包括字段的作用域public、private、protected、是实例变量还是类变量static、可变性final、并发可见性volatile、可否被序列化transient、字段数据类型（基本数据类型、数组、对象）、字段名称，字段包括类变量、实例变量，但是不包括方法内部声明的局部变量。 修饰符都是布尔值使用标志位来表示，放在access_flags项目中，字段名字被定义为什么数据类型引用常量池中的常量来描述，name_index和descriptor_index都是对常量池的引用，分别代表着字段的简单名称以及字段和方法的描述符。简单名称是指没有类型和参数的修饰的方法或字段名称，描述符是用来描述字段的数据类型、方法的参数列表，包括数量、类型、顺序和返回值。 类型 名称 数量 ｕ2 access_flags 1 ｕ2 name_index 1 ｕ2 descriptor_index 1 ｕ2 attributes_count 1 attribute_info attributes attributes_count ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED三个标志最多只能选择其一，ACC_FINAL、ACC_VOLATILE不能同时选择，接口中必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标志。 标志名称 标志值 含义 ACC_PUBLIC 0x0001 字段是否为public ACC_PRIVATE 0x0002 字段是否为private ACC_PROTECTED 0x0004 字段是否为protected ACC_STATIC 0x0008 字段是否为static ACC_FINAL 0x0010 字段是否为final ACC_VOLATILE 0x0040 字段是否为volatile ACC_TRANSTENT 0x0080 字段是否为transient ACC_SYNCHETIC 0x1000 字段是否为由编译器自动产生 ACC_ENUM 0x4000 字段是否为enum 基本数据类型byte、char、double、float、int、long、short、boolean以及代表无返回值的void类型都用一个大写字符来表示，对象类型用字符L加对象的全限定名来表示。 数组类型每个维度将使用一个前置的[字符来描述，如果定义一个java.lang.String[][]类型的二维数组，将被记录为[[Ljava.lang.String,整形的int[]将被记为[I。用描述符来描述方法时，按照先参数列表后放回值的顺序描述，参数列表按照参数的严格顺序放在一个小括号()内，如方法String desc(char[] a, int b,long[] c)的描述符为([CI[J)Ljava/lang/String;。 标志符 含义 B 基本数据类型byte C 基本数据类型char D 基本数据类型double F 基本数据类型float I 基本数据类型int J 基本数据类型long S 基本数据类型short Z 基本数据类型boolean V 基本数据类型void L 对象类型 字段表集合中不会列出从超类或者父接口中继承而来的字段，但有可能列出Java代码中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。 Java语言字段是无法重载的，两个字段的数据类型、修饰符不管是否相同，都必须使用不一样的名称，但对字节码来说，两个字段的描述符不一致字段的重名是合法的。 方法表集合Class文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法，方法表的结构如同字段表一样，依次是访问标志、名称索引、描述符索引、属性表集合。这些数据项目含义非常类似，仅访问标志和属性表集合的可选项中所有区别。 类型 名称 数量 ｕ2 access_flags 1 ｕ2 name_index 1 ｕ2 descriptor_index 1 ｕ2 attributes_count 1 attribute_info attributes attributes_count 方法里的Java代码经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为Code的属性里，属性表作为Class文件格式中最具扩展性的一种数据项目。 标志名称 标志值 含义 ACC_PUBLIC 0x0001 方法是否为public ACC_PRIVATE 0x0002 方法是否为private ACC_PROTECTED 0x0004 方法是否为protected ACC_STATIC 0x0008 方法是否为static ACC_FINAL 0x0010 方法是否为final ACC_SYHCHRONRIZED 0x0020 方法是否为synchronized ACC_BRIDGE 0x0040 方法是否是有编译器产生的方法 ACC_VARARGS 0x0080 方法是否接受参数 ACC_NATIVE 0x0100 方法是否为native ACC_ABSTRACT 0x0400 方法是否为abstract ACC_STRICTFP 0x0800 方法是否为strictfp ACC_SYNTHETIC 0x1000 方法是否是有编译器自动产生的 如果父类方法在子类中没有被重写，方法表集合中就不会出现来自父类的方法信息，但有可能会出现由编译器自动添加的方法，最典型的就是类构造器&lt;clinit&gt;方法和实例构造器&lt;init&gt;方法。 在Java中要重载一个方法，除了要与原方法具有相同的简单名称之外，还要求必须拥有一个与原方法不同的特征签名，特征签名就是一个方法中各个参数在常量池中字段符号引用的集合，由于返回值不包含在特征签名中，故Java中无法仅仅依靠返回值来重载方法。但在Class文件中，特征签名范围更大，只要描述符不完全一致的两个方法也可以共存，两个方法有相同名称和特征值但返回值不同，就可以合法共存一个Class文件中。 属性表集合","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"内存分配与回收策略","date":"2018-01-16T16:00:00.000Z","path":"Blog/Java/VM/内存非配与回收策略/","text":"Java体系技术中所提倡的自动内存管理最终可以归结为自动化地解决两个问题：给对象分配内存以及回收分配给对象的内存。 对象的内存分配，往大的方向讲就是在堆上分配，但也可能经过JIT编译后被拆散为标量类型并间接地在栈上分配，对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，就按线程优先在TLAB上分配，少数情况下可能直接分配在老年代中。 大对象直接进入老年代一般对象在新生代Eden区中分配，当Eden区没有足够空间时虚拟机将发起一次Minor GC。 -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:+UseSerialGC -XX:SurvivorRatio=8通过该参数限制Java堆大小为20M且不可扩展，10M为新生代10M为老年代，Eden空间和Survivor空间比例时8：1，Eden空间大小为8192K、From Survivor空间大小为1024K、To Survivor空间大小为1024K，新生代是Eden区加From Survivor区的总容量为9216K。12345678private static final int _1MB = 1024 * 1024;public static void main(String[] args) &#123; byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB];&#125; 程序在给allocation4对象分配内存时，发现Eden空间已经被占用了6M，剩余空间已经不足分配给allocation4所需的内存，因此发生了Minor GC，在GC期间发现allocation1、allocation2、allocation3都无法放入Survivor空间，只能通过分配担保机制提前转移到老年代中。所以GC结束后Eden空间被占用4M、Survivor空间空闲、老年代被占用6M。 1234567891011[GC[DefNew: 7669K-&gt;547K(9216K), 0.0048823 secs] 7669K-&gt;6691K(19456K), 0.0049234 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 5136K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 56% used [0x00000000f9a00000, 0x00000000f9e7b610, 0x00000000fa200000) from space 1024K, 53% used [0x00000000fa300000, 0x00000000fa388d40, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2987K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 14% used [0x00000000fae00000, 0x00000000fb0eb120, 0x00000000fb0eb200, 0x00000000fc2c0000)No shared spaces configured. 大对象对虚拟机内存分配来说是一个坏消息，经常出现大对象容易导致还有部分内存就提前触发垃圾收集以获得足够的连续空间。 虚拟机可以通过-XX:PretenureSizeThreshold参数设置，大于该参数值的对象直接在老年代中分配内存，目的是为了避免在Eden区和两个Survivor区之间发生大量内存复制。但是该参数只对Serial和ParNew有效。 长期存活的对象将进入老年代虚拟机是通过给每个对象定义一个对象年龄计数器来是被新生代和老年代。 如果对象在Eden出生并经过一次Minor GC后任然存活且能被To Survivor容纳对象年龄将会被设置为1，每熬过一次Minor GC年龄就增加1，当年龄增加到一定程度（默认15岁），对象就会被晋升到老年代中。 对象晋升老年代的年龄法制可以通过-XX:MaxTenuringThreshold参数设置。 动态对象年龄判断虚拟机并不是永远地要求对象的年龄必须到达MaxTenuringThreshold才能晋升老年代，如果Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 空间分配担保在发生Minor GC之前，虚拟机会先检查老年代最大可用连续空间是否大于新生代所有对象总空间，如果成立Minor GC确保安全。 如果不成立虚拟机会查看HandlePromotionFailure设置是否允许担保失败。 如果允许会继续检查老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，如果大于尝试进行一次Minor GC，如果小于或HandlePromotionFailure设置不允许冒险，这时将进行一次Full GC。 当然如果担保失败，也将在失败后重新发起一次Full GC。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"理解GC日志","date":"2018-01-16T16:00:00.000Z","path":"Blog/Java/VM/理解GC日志/","text":"对于Java应用可以通过一些配置把程序运行过程中的GC日志全部打印出来，然后分析GC日志得到关键性指标，分析GC原因，调优JVM参数。打印GC日志方法，在JVM参数里增加参数，%t 代表时间，最多生成10个日志文件，每个文件最大100M，滚动刷新；Tomcat则直接加在JAVA_OPTS变量里： 1-Xloggc:./gc‐%t.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M 但若GC日志非常多，很难凭肉眼分析，可以借助一些功能来帮助分析，这里推荐一个gceasy，上传GC文件，可以利用可视化的界面来展现GC情况。 阅读GC日志是处理Java虚拟机内存问题的基础技能，每一种收集器的日志形式都是由他们自身的实现所决定的，所以每个收集器的日志格式都可以不一样，但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性。下面是一段GC日志： 1234567[GC [PSYoungGen: 23552K-&gt;3581K(27136K)] 23552K-&gt;16249K(88576K), 0.0185611 secs] [Times: user=0.08 sys=0.02, real=0.02 secs] [GC [PSYoungGen: 27133K-&gt;3560K(27136K)] 39801K-&gt;31030K(88576K), 0.0323523 secs] [Times: user=0.11 sys=0.01, real=0.03 secs] [GC [PSYoungGen: 27112K-&gt;3568K(27136K)] 54582K-&gt;54585K(88576K), 0.0363496 secs] [Times: user=0.16 sys=0.02, real=0.04 secs] [Full GC [PSYoungGen: 3568K-&gt;0K(27136K)] [ParOldGen: 51017K-&gt;47268K(61440K)] 54585K-&gt;47268K(88576K) [PSPermGen: 3169K-&gt;3168K(21504K)], 0.5726540 secs] [Times: user=1.78 sys=0.01, real=0.57 secs] [Full GC [PSYoungGen: 23552K-&gt;0K(27136K)] [ParOldGen: 47268K-&gt;60136K(61440K)] 70820K-&gt;60136K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.3987444 secs] [Times: user=1.41 sys=0.02, real=0.40 secs] [Full GC [PSYoungGen: 20624K-&gt;19567K(27136K)] [ParOldGen: 60136K-&gt;61132K(61440K)] 80761K-&gt;80700K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.8462723 secs] [Times: user=3.38 sys=0.05, real=0.85 secs] [Full GC [PSYoungGen: 19567K-&gt;19567K(27136K)] [ParOldGen: 61132K-&gt;61116K(61440K)] 80700K-&gt;80684K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.4721533 secs] [Times: user=2.83 sys=0.03, real=0.47 secs] GC日志开头的[GC和[Full GC说明这次垃圾收集的停顿类型，而不是用来区分新生代GC还是老年代GC。如果是调用System.gc()方法所触发的收集，这里就将显示[Full GC（System）。 接下来的[PSYoungGen、[ParOldGen、[PSPermGen表是GC发生的区域，区域名称与使用的GC收集器是密切相关的。 后面方括号内的23552K-&gt;3581K(27136K)表示GC前该内存区域已使用容量-&gt;GC后该内存区域已使用容量（该内存区域总容量） 方括号外的23552K-&gt;16249K(88576K)表示GC前Java堆已使用容量-&gt;GC后Java堆已使用容量（Java堆总容量） 0.0185611 secs表示该内存区域GC所占用的时间，单位秒。[Times: user=0.08 sys=0.02, real=0.02 secs]更具体的时间数据，这里的user、sys和real与Linux的time命令所输出的时间含义一致，分别代表CPU时间、内核态消耗的CPU事件和操作从开始到结束所经过的墙钟时间。 JVM参数汇总查看命令java -XX:+PrintFlagsInitial：打印出所有参数选项的默认值java -XX:+PrintFlagsFinal：打印出所有参数选项在运行程序时生效的值 Serial &amp; Serial Old GC日志123456[GC[DefNew: 24234K-&gt;3072K(27648K), 0.0279728 secs] 24234K-&gt;16411K(89088K), 0.0280186 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [GC[DefNew: 27648K-&gt;3072K(27648K), 0.0348831 secs] 40987K-&gt;35255K(89088K), 0.0349111 secs] [Times: user=0.03 sys=0.00, real=0.04 secs] [GC[DefNew: 27648K-&gt;3072K(27648K), 0.0420056 secs] 59831K-&gt;59830K(89088K), 0.0420333 secs] [Times: user=0.05 sys=0.00, real=0.04 secs] [GC[DefNew: 27648K-&gt;27648K(27648K), 0.0000186 secs][Tenured: 56758K-&gt;61440K(61440K), 0.1322486 secs] 84406K-&gt;63429K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1323137 secs] [Times: user=0.14 sys=0.00, real=0.13 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1457481 secs] 80851K-&gt;80700K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1457820 secs] [Times: user=0.16 sys=0.00, real=0.14 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1661660 secs] 80700K-&gt;80684K(89088K), [Perm : 3169K-&gt;3168K(21248K)], 0.1661913 secs] [Times: user=0.16 sys=0.00, real=0.17 secs] [DefNew、[Tenured、[Perm分别表示年轻代、老年代和永久代。 ParNew &amp; serial Old GC日志123456[GC[ParNew: 24234K-&gt;3072K(27648K), 0.0240967 secs] 24234K-&gt;16475K(89088K), 0.0241453 secs] [Times: user=0.11 sys=0.00, real=0.02 secs] [GC[ParNew: 27648K-&gt;3072K(27648K), 0.0361463 secs] 41051K-&gt;35736K(89088K), 0.0362102 secs] [Times: user=0.19 sys=0.00, real=0.04 secs] [GC[ParNew: 27648K-&gt;3072K(27648K), 0.0369859 secs] 60312K-&gt;60003K(89088K), 0.0370325 secs] [Times: user=0.23 sys=0.00, real=0.04 secs] [GC[ParNew: 27648K-&gt;27648K(27648K), 0.0000158 secs][Tenured: 56931K-&gt;61440K(61440K), 0.1430511 secs] 84579K-&gt;63429K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1431067 secs] [Times: user=0.14 sys=0.00, real=0.14 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1444908 secs] 80851K-&gt;80700K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1445358 secs] [Times: user=0.14 sys=0.00, real=0.14 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1710500 secs] 80700K-&gt;80684K(89088K), [Perm : 3169K-&gt;3168K(21248K)], 0.1710760 secs] [Times: user=0.17 sys=0.00, real=0.17 secs] [ParNew、[Tenured、[Perm分别表示年轻代、老年代和永久代。 ParNew &amp; CMS（serial old为替补）GC日志1-Xloggc:d:/gc‐cms‐%t.log -Xms50M -Xmx50M -‐XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 1234567[GC[ParNew: 23938K-&gt;3072K(27648K), 0.0849733 secs] 23938K-&gt;21528K(89088K), 0.0850416 secs] [Times: user=0.53 sys=0.02, real=0.09 secs] [GC[ParNew: 27648K-&gt;3072K(27648K), 0.0363515 secs] 46104K-&gt;45931K(89088K), 0.0363863 secs] [Times: user=0.22 sys=0.05, real=0.04 secs] [GC [1 CMS-initial-mark: 42859K(61440K)] 46267K(89088K), 0.0020835 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC[ParNew: 27648K-&gt;27648K(27648K), 0.0000146 secs][CMS[CMS-concurrent-mark: 0.132/0.133 secs] [Times: user=0.17 sys=0.06, real=0.13 secs] (concurrent mode failure): 42859K-&gt;61439K(61440K), 0.2594182 secs] 70507K-&gt;66264K(89088K), [CMS Perm : 3170K-&gt;3169K(21248K)], 0.2594711 secs] [Times: user=0.31 sys=0.06, real=0.26 secs] [Full GC[CMS: 61439K-&gt;61439K(61440K), 0.1218246 secs] 71016K-&gt;70720K(89088K), [CMS Perm : 3169K-&gt;3169K(21248K)], 0.1218598 secs] [Times: user=0.13 sys=0.00, real=0.12 secs] [Full GC[CMS: 61439K-&gt;61440K(61440K), 0.1510773 secs] 70720K-&gt;70709K(89088K), [CMS Perm : 3169K-&gt;3169K(21248K)], 0.1511120 secs] [Times: user=0.14 sys=0.00, real=0.15 secs] [ParNew、[CMS、[Perm分别表示年轻代、老年代和永久代。其中(concurrent mode failure)表示CMS收集器无法处理浮动垃圾，出现了Concurrent Mode Failure失败而导致另一次Full GC产生，这时虚拟机就会启动后备预案，临时使用Serial Old收集器来重新进行老年代的垃圾收集。 Parallel Scavenge &amp; Parallel Old GC日志1234567[GC [PSYoungGen: 23552K-&gt;3581K(27136K)] 23552K-&gt;16249K(88576K), 0.0185611 secs] [Times: user=0.08 sys=0.02, real=0.02 secs] [GC [PSYoungGen: 27133K-&gt;3560K(27136K)] 39801K-&gt;31030K(88576K), 0.0323523 secs] [Times: user=0.11 sys=0.01, real=0.03 secs] [GC [PSYoungGen: 27112K-&gt;3568K(27136K)] 54582K-&gt;54585K(88576K), 0.0363496 secs] [Times: user=0.16 sys=0.02, real=0.04 secs] [Full GC [PSYoungGen: 3568K-&gt;0K(27136K)] [ParOldGen: 51017K-&gt;47268K(61440K)] 54585K-&gt;47268K(88576K) [PSPermGen: 3169K-&gt;3168K(21504K)], 0.5726540 secs] [Times: user=1.78 sys=0.01, real=0.57 secs] [Full GC [PSYoungGen: 23552K-&gt;0K(27136K)] [ParOldGen: 47268K-&gt;60136K(61440K)] 70820K-&gt;60136K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.3987444 secs] [Times: user=1.41 sys=0.02, real=0.40 secs] [Full GC [PSYoungGen: 20624K-&gt;19567K(27136K)] [ParOldGen: 60136K-&gt;61132K(61440K)] 80761K-&gt;80700K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.8462723 secs] [Times: user=3.38 sys=0.05, real=0.85 secs] [Full GC [PSYoungGen: 19567K-&gt;19567K(27136K)] [ParOldGen: 61132K-&gt;61116K(61440K)] 80700K-&gt;80684K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.4721533 secs] [Times: user=2.83 sys=0.03, real=0.47 secs] [PSYoungGen、[ParOldGen、[PSPermGen分别表示年轻代、老年代和永久代。 G1 收集器1-Xloggc:d:/gc‐g1‐%t.log -Xms50M -Xmx50M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -XX:+UseG1GC 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[GC pause (young) (initial-mark), 0.0089815 secs] [Parallel Time: 8.7 ms, GC Workers: 8] [GC Worker Start (ms): Min: 1992.2, Avg: 1992.3, Max: 1992.3, Diff: 0.1] [Ext Root Scanning (ms): Min: 0.3, Avg: 0.3, Max: 0.3, Diff: 0.1, Sum: 2.5] [Update RS (ms): Min: 2.2, Avg: 2.8, Max: 3.8, Diff: 1.6, Sum: 22.8] [Processed Buffers: Min: 4, Avg: 4.9, Max: 6, Diff: 2, Sum: 39] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Object Copy (ms): Min: 4.5, Avg: 5.4, Max: 6.0, Diff: 1.6, Sum: 43.0] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Total (ms): Min: 8.6, Avg: 8.6, Max: 8.6, Diff: 0.1, Sum: 68.7] [GC Worker End (ms): Min: 2000.8, Avg: 2000.8, Max: 2000.8, Diff: 0.0] [Code Root Fixup: 0.0 ms] [Clear CT: 0.2 ms] [Other: 0.1 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.1 ms] [Ref Enq: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 1024.0K(3072.0K)-&gt;0.0B(3072.0K) Survivors: 1024.0K-&gt;1024.0K Heap: 79.0M(90.0M)-&gt;81.8M(90.0M)] [Times: user=0.13 sys=0.00, real=0.01 secs] [GC concurrent-root-region-scan-start][GC pause (young)[GC concurrent-root-region-scan-end, 0.0001366 secs][GC concurrent-mark-start], 0.0030254 secs] [Root Region Scan Waiting: 0.1 ms] [Parallel Time: 2.7 ms, GC Workers: 8] [GC Worker Start (ms): Min: 2001.5, Avg: 2001.5, Max: 2001.5, Diff: 0.0] [Ext Root Scanning (ms): Min: 0.3, Avg: 0.3, Max: 0.4, Diff: 0.1, Sum: 2.7] [SATB Filtering (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Update RS (ms): Min: 1.1, Avg: 1.3, Max: 1.9, Diff: 0.8, Sum: 10.6] [Processed Buffers: Min: 2, Avg: 2.8, Max: 4, Diff: 2, Sum: 22] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Object Copy (ms): Min: 0.3, Avg: 0.8, Max: 1.1, Diff: 0.8, Sum: 6.7] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Total (ms): Min: 2.5, Avg: 2.5, Max: 2.6, Diff: 0.0, Sum: 20.3] [GC Worker End (ms): Min: 2004.0, Avg: 2004.0, Max: 2004.0, Diff: 0.0] [Code Root Fixup: 0.0 ms] [Clear CT: 0.1 ms] [Other: 0.2 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.1 ms] [Ref Enq: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 0.0B(3072.0K)-&gt;0.0B(4096.0K) Survivors: 1024.0K-&gt;0.0B Heap: 81.8M(90.0M)-&gt;81.6M(90.0M)] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC 81M-&gt;78M(90M), 0.1786909 secs] [Eden: 0.0B(4096.0K)-&gt;0.0B(4096.0K) Survivors: 0.0B-&gt;0.0B Heap: 81.6M(90.0M)-&gt;78.8M(90.0M)] [Times: user=0.28 sys=0.00, real=0.18 secs] [Full GC 78M-&gt;78M(90M), 0.1693387 secs] [Eden: 0.0B(4096.0K)-&gt;0.0B(4096.0K) Survivors: 0.0B-&gt;0.0B Heap: 78.8M(90.0M)-&gt;78.8M(90.0M)] [Times: user=0.17 sys=0.00, real=0.17 secs] 垃圾收集器参数 参数 描述 UseSerialGC 使用Serial &amp; Serial Old收集器（client模式默认值） UseParNewGC 使用ParNew &amp; Serial Old收集器（不推荐） UseConcMarkSweepGC 使用ParNew &amp; CMS（Serial Old为替补）收集器 UseParallelGC 使用Parallel Scavenge &amp; Parallel Old收集器（Server模式默认值） UseParallelOldGC 在年老代使用Parallel Old收集器 UseG1GC 使用G1收集器","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Git基本概念","date":"2018-01-15T16:00:00.000Z","path":"Blog/杂记/Git/GIt基本概念/","text":"Git文件状态变化周期工作目录下每个文件都只有两种状态：已跟踪和未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，既不存在于上次快照的记录中，也没有放入暂存区。初次克隆某个仓库的时，工作目录中所有文件都属于已跟踪文件，并处于未修改状态。 编辑处于未修改状态的文件后，Git将它们标记为已修改文件。将这些修改过的文件放入暂存区，然后提交所有暂存了的修改，如此反复。","tags":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/tags/Git/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"Git","slug":"杂记/Git","permalink":"https://yaoyinglong.github.io/categories/杂记/Git/"}]},{"title":"Git常用命令","date":"2018-01-15T16:00:00.000Z","path":"Blog/杂记/Git/GIt常用命令/","text":"git checkout -b localbranch remotebranch 基于远程分支创建本地分支git reset --head commit_id 撤回提交git push origin HEAD --force 远程提交回退git push origin localbranch:remotebranch 将本地代码提交到远程的指定分支git branch --set-upstream-to=origin/Release_v1.6.4_20170831 将本地分支关联到远程分支上git branch --set-upstream-to=origin/Release_v1.6.4_20170831 localBranchName 切换本地分支关联的远程分支git branch -vv 查看本地分支关联的远程分支之间的对应关系git merge dev 合并指定分支到当前分支(将dev分支合并到当前分支)git branch -d dev 删除本地dev分支git push origin --delete remotebranch 删除远程分支git log --graph 查看分支合并图git clone -b remotebranch https://github.com/apache/struts-examples.git 克隆远程指定的分支git branch -a 查看远程分支git remote -v 查看远程仓库地址git rm test.txt 删除文件git reset HEAD readme.txt 把暂存区的修改撤销掉（unstage），重新放回工作区git checkout -- readme.txt 让这个文件回到最近一次git commit或git add时的状态,没有-- ，就变成了切换分支的命令git reflog 查看所有分支的所有操作记录 git init 初始化本地仓库git pull https://github.com/youraccount/yourproject.git 将远程仓库代码拉取到本地git remote add origin https://github.com/youraccount/yourproject.git 为版本库添加名为origin的远程版本库git push -u origin master -u参数，在推送成功后自动建立本地分支与远程版本库分支的追踪 git remote update origin --prune 更新远程分支列表 git config --system core.longpaths true 提交代码文件名过长无法提交问题 强制覆盖本地文件git fetch –allgit reset –hard origin/mastergit pull","tags":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/tags/Git/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"Git","slug":"杂记/Git","permalink":"https://yaoyinglong.github.io/categories/杂记/Git/"}]},{"title":"Minor&Major&Full GC","date":"2018-01-14T16:00:00.000Z","path":"Blog/Java/VM/Minor&Major&Full GC/","text":"Minor GC新生代通常存活时间比较短，是基于复制算法进行回收的。从年轻代空间（包括Eden和两个Survivor区域）回收内存被称为Minor GC。 当JVM无法为一个新的对象分配空间时会触发Minor GC，比如当Eden区满了。所以分配率越高，越频繁执行Minor GC。 内存池被填满的时候，其中的内容全部会被复制，指针会从0开始跟踪空闲内存。Eden 和 Survivor 区进行了标记和复制操作，取代了经典的标记、扫描、压缩、清理操作。所以 Eden 和 Survivor 区不存在内存碎片。写指针总是停留在所使用内存池的顶部。 执行Minor GC操作时，不会影响到永久代。从永久代到年轻代的引用被当成GC Roots，从年轻代到永久代的引用在标记阶段被直接忽略掉。 所有的Minor GC都会触发Stop-The-World，这个过程非常短暂。大部分Eden区中的对象都能被认为是垃圾，永远也不会被复制到Survivor区或者老年代空间。如果正好相反，Eden区大部分新生对象不符合GC条件，Minor GC执行时暂停的时间将会长很多。 Major GC &amp; Full GC老年代与新生代不同，老年代对象存活的时间比较长、比较稳定，因此一般采用标记整理算法来进行回收，当然这也跟垃圾收集器相关。 Major GC是清理老年代。Full GC是清理整个堆空间包括年轻代和老年代。出现Major GC经常会伴随至少一次的Minor GC，且Major GC的速度一般会比Minor GC慢10倍以上。 许多Major GC是由Minor GC触发的，所以很多情况下将这两种GC分离是不太可能的。另一方面，许多现代垃圾收集机制会清理部分永久代空间。 Full GC触发条件： 调用System.gc()时，系统建议执行Full GC，但是不必然执行。 老年代空间不足。 方法去空间不足。 通过Minor GC后进入老年代的平均大小大于老年代的可用内存。 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"JVM内存池","date":"2018-01-05T16:00:00.000Z","path":"Blog/Java/VM/JVM内存池/","text":"JVM内存池JVM共享内存区域或者叫内存池分堆和方法区或者称为永久代（Permgen）两块，其中堆内存分为年轻代（Young）和老年代（Tenured），而年轻代又被划分为三个区域Eden、Survivor 1、Survivor 2。 Eden空间对象被创建时通常被分配到Eden空间。为了解决对象分配内存时的线程安全问题，为每个线程在Eden空间中预先分配一小块内存TLAB（本地线程分配缓冲），线程给对像分配内存时在TLAB上分配，当TLAB中没有足够的内存时会将数据同步到Common Area中，如果Common Area中也没有足够的内存那么Minor GC将会被触发释放内存空间，如果任然没有足够的内存对象将会被直接通过分配担保机制进入老年代。 是否使用TLAB可以通过-XX:+/-UseTLAB参数来控制。 Survivor空间当每次Minor GC时JVM会将还存活的对象进行标记，标记完成后在Eden空间和From Survivor空间中所有存活的对象将会被复制到To Survivor空间中，当然第一次Minor GC时From Survivor应该是空的，之后To Survivor空间和From Survivor空间角色互换，该过程就是使用的复制算法。在对象头中的运行时数据中存放了对象的GC分代年龄，每一次对象从GC中存活下来后都将会对GC分代年龄加一，当GC分代年龄超过一定的阈值时，该对象将会将不会复制到To Survivor空间中而是直接复制到Tenured（老年代）中，直到该对象变为不可达被回收。 JVM内存池实际工作监控情况由于我的JDK是1.8所以该图中显示是的Mataspace空间，如果是用的JDK1.7该处应该是PermGen。 由此图可以明显的看出每当一个Eden空间达到某个值时，就会触发一次GC将Eden空间中的部分存活对象复制到To Survivor中，并将Eden清空。还可以明显的看出Survivor 1 和 Survivor 2 是交替作为From Survivor和To Survivor空间角色。 HotSpot虚拟机默认Eden：From Survivor：To Survivor的大小比例是8：1：1实际的阈值可以通过JVM参数-XX:MaxTenuringThreshold动态指定，HotSpot中默认的阀值为15个GC周期","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"垃圾收集器","date":"2018-01-02T16:00:00.000Z","path":"Blog/Java/VM/垃圾收集器/","text":"垃圾收集器是内存回收的具体实现。Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定。 两者之间存在连线的收集器可以相互搭配使用，收集器所处区域表示其属于新生代收集器还是老年代收集器。 Serial收集器Serial收集器是最基本、发展历史最有悠久、基于复制算法、单线程的新生代收集器。单线程的意义并不仅仅是使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在垃圾收集时必须暂停其他所有工作线程。Serial收集器到目前为止，依然是JAVA虚拟机运行在Client模式下的默认新生代收集器。与其他收集器的单线程比Serial收集器简单高效，对于限定单个CPU的环境来说，Serial收集器由于没有线程交互开销，可以获得最高的单线程收集效率。可能会产生较长时间的停顿。使用-XX:+UseSerialGC参数指定虚拟机使用Serial收集器。 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop-The-World、对象分配规整、回收策略等都与Serial收集器完全一样，两者也共用了相当多的代码。 ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器，除了Serial收集外，目前只有ParNew收集器能与CMS收集器配合工作。但ParNew收集器在单CPU环境中绝对不会比Serial收集器效果好，甚至由于存在线程交互开销，两个CPU环境中都不能百分百保证可以超越Serial收集器。 ParNew收集器也是使用-XX:+UseConcMarkSweepGC选项后默认的新生代收集器，也可以使用-XX:+UseParNewGC选项来强制指定它。 Parallel Scavenge收集器Parallel Scavenge是一个使用复制算法、并行的多线程的新生代收集器。CMS等收集器关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目的是达到一个可控的吞吐量。自适应调节策略是Parallel Scavenge与ParNew收集器的一个重要区别。 Parallel Scavenge收集器通过使用-XX:UseAdaptiveSizePolicy开关参数来设置是否使用自适应调节策略，当该参数打开时，就不需要手工通过-Xmn参数指定新生代的大小、-XX:SurvivorRatio参数指定Eden与Servivor区的比例、-XX:PretenureSizeThreshold参数直接晋升到老年代的对象大小（大于这个参数的对象将直接在老年代分配）等细节，虚拟机会根据当前系统运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大吞吐量。只需要把基本的最大堆内存设置好，然后使用-XX:MaxGCPauseMillis参数或者-XX:GCTimeRatio参数给虚拟机设立一个优化目标，具体细节参数调节工作就由虚拟机自动完成了。 -XX:MaxGCPauseMillis控制最大垃圾收集停顿时间。该参数允许的值是一个大于0的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值，但并不是把该参数设置得小就能使得系统的垃圾收集速度变快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的（e.g.把新生代调小，原来10秒收集一次，每次停顿100毫秒，现在5秒收集一次，每次停顿70毫秒）； -XX:GCTimeRatio垃圾收集时间占总时间的比率，相当于吞吐量的倒数，该参数允许的值是一个大于0且小于100的整数，默认为99允许最大1%的垃圾收集时间。 吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间） 也就是CPU用于运行用户代码的时间与CPU总消耗时间的比值。 Serial Old收集器Serial Old是Serial收集器的老年代版本，它是一个使用标记整理算法的单线程的收集器，主要也是给Client模式下的虚拟机使用。 如果在Service模式下，主要有两种用途：一是在JDK1.5之前版本中与Parallel Scavenge收集器搭配使用，二是作为CMS收集器的后备预案，在CMS发生Concurrent Mode Failure时使用。 Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，它是一个使用标记整理算法的多线程的收集器。 该收集器在JDK1.6中提供，在此之前如果新生代选择了Parallel Scavenge收集器老年代只能选择Serial Old收集器。由于Serial Old收集器是单线程的即使使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化，在老年代很大且硬件条件比较高级的环境中，这种组合吞吐量甚至还不一定有ParNew加CMS的组合好。 在注重吞吐量以及CPU资源敏感的场合，优先考虑Parallel Scavenge加Parallel Old收集器的组合。 CMS收集器CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的且基于标记清除算法的收集器。且它是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程基本上同时工作。 CMS收集器运作过程相对于前面几种收集器来说更复杂一些，整个过程分为初始标记、并发标记、重新标记、并发清除4个步骤。其中初始标记、重新标记两个步骤需要Stop-The-world。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，整个阶段停顿时间一般比初始标记稍长但比并发标记时间短。整个过程耗时最长的是并发标记和并发清理过程收集器线程都可以与用户线程一起工作，总体上CMS收集器的内存回收过程是与用户线程一起并发执行的。CMS垃圾收集整个过程分为一下几个步骤： 初始标记： 暂停所有的其他线程，并记录下GC Roots直接能引用的对象，速度很快。 并发标记： 从GC Roots的直接关联对象开始遍历整个对象图的过程， 该过程耗时较长但不停顿用户线程， 可与垃圾收集线程并发运行。因为用户程序继续运行，可能会有导致已经标记过的对象状态发生改变。 重新标记： 为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那部分对象标记记录，该阶段停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。主要用到三色标记里的增量更新算法重新标记。 并发清理： GC线程对未标记区域做清扫，该阶段若有新增对象会被标记为黑色不做任何处理，与用户线程并发执行。 并发重置：重置本次GC过程中的标记数据。 CMS收集器对CPU资源非常敏感。在并发阶段它虽然不会导致用户线程停顿，但会占用一部分线程而导致应用程序变慢，总吞吐量降低。CMS默认启动的回收线程数是：（CPU数量 + 3）/ 4。当CPU不足4个时CMS对用户程序的影响可能变得很大。为了应付这种情况虚拟机提供了一种称为增量式并发收集器，和使用抢占式来模拟多任务机制的思想一样，在并发标记、整理时让GC线程与用户线程交替运行，尽量减少GC线程的独占资源的时间，垃圾收集过程会更长，但对用户程序影响会显得少一些，但实践证明这种方式效果一般目前已经不提倡使用。 CMS收集器无法处理浮动垃圾，可能出现Concurrent Mode Failure失败而导致另一次Full GC产生。由于垃圾收集阶段用户线程还在运行，也就需要留有足够内存空间给用户线程使用，因此CMS收集器不能像其他收集器等到老年代几乎完全被填满再进行收集。当CMS运行期间预留内存无法满足程序需要，就会出现一次Concurrent Mode Failure失败，这时虚拟机就会启动后备预案，临时使用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长。可以通过参数-XX:CMSInitiatingOccupancyFraction来设置触发百分比。 CMS收集器是基于标记清除算法，会产生大量空间碎片。空间碎片过多时，在老年代还有很大空间剩余时，给大对象分配内存空间时无法找到足够大的连续的内存空间，而不得不提前触发Full GC。为了解决该问题CMS提供-XX:+UseCMSCompactAtFullCollection开关参数默认开启，用于Full GC时开启内存碎片合并整理，但内存整理过程无法并发故停顿时间将变长。还提供-XX:CMSFullGCsBeforeCompaction参数来设置执行多少次不压缩Full GC后执行一次压缩的GC，默认为0。 浮动垃圾是指由于CMS并发清理阶段用户线程还在运行故会产生新的垃圾，但这部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉他们，只好留待下一次GC时再清理。 G1收集器G1时一款面向服务端应用的垃圾收集器，其他收集器收集的范围都是整个新生代或者老年代，而G1收集器将整个Java堆划分为多个大小相等的独立区域（Region），虽然保留了老年代和新生代的概念，但老年代和新生代不再被物理隔离，它们都是一部分Region（不需要连续）的集合。 JVM最多可以有2048个Region，一般Region大小等于堆大小除以2048，可以用参数-XX:G1HeapRegionSize手动指定Region大小，但推荐默认计算方式。 默认年轻代对堆内存的占比是5% ，可以通过-XX:G1NewSizePercent设置新生代初始占比，在系统运行中会不停的给年轻代增加更多的Region，但最多新生代占比不会超过60%，可通过-XX:G1MaxNewSizePercent调整。年轻代中的Eden和Survivor对应的region比例默认还是8:1:1。 G1有专门分配大对象的Humongous区，而非让大对象直接进入老年代Region中。对象大小超过一个Region大小的50%就是大对象，且若大对象太大，可能会横跨多个Region存放，Humongous区专门存放短期巨型对象，不用直接进老年代，可节约老年代的空间，避免因老年代空间不够的GC开销。Full GC时也会将Humongous区一并回收。 G1收集器会跟踪各个Region里面的垃圾堆积的价值大小，即回收所获得的空间大小以及回收所需时间经验值，在后台维护一个优先列表，每次根据允许收集的时间，优先回收价值最大的Region，这也是Garbage-First名称的由来。 与其他收集器相比G1收集器具备并行与并发、分代收集、空间整合、可预测停顿4个特点： G1收集器可以使用并行的方式来缩短Stop-The-World停顿时间，且可以通过并发的方式让Java程序继续执行。 G1收集器可以不用其他收集器的配合独立管理整个GC堆，任然保留分代的概念，采用不用的方式去处理新建的对象和已经存活了一段时间、熬过多次GC的旧对象以获得更好的收集效果。 G1收集器整体来看是基于标记整理算法实现的收集器，从局部（两个Region之间）来看是基于复制算法来实现的，这意味着G1运作期间不会产生内存碎片。 G1收集器除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定一个长度为M毫秒的时间片段内，消耗再垃圾收集上的时间不得超过N毫秒。之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。可用-XX:MaxGCPauseMillis参数指定期望的GC停顿时间，默认的停顿目标为两百毫秒。 一个对象分配在某个Region中，它并非只能被本Region中的其他对象引用，而是可以与整个Java堆任意的对象发生引用关系。在G1收集器中Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，都是使用记忆集来避免全堆扫描。每个Region都有一个与之对应的记忆集，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个写屏障暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中，在分代中就检查是否老年代中的对象引用了新生代中的对象，如果是便通过卡表把相关引用信息记录到被引用对象所属的Region的记忆集中，当进行内存回收时，在进行GC根节点枚举范围中加入记忆集即可保证不对全堆扫描也不会遗漏。 G1收集器的的运作大致分为初始标记、并发标记、最终标记、筛选回收4个步骤。 初始标记阶段仅仅标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建对象，需要停顿线程，但耗时很短。 并发标记阶段是从GC Roots开始对堆中对象进行可达性分析找出存活对象，耗时较长但可与用户程序并发执行。 最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Rememberd Set Logs里面，最终标记阶段需要把Rememberd Set Logs的数据合并到Rememberd Set中，这个阶段需要停顿线程但可并行执行。 筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段也可以做到与用户程序并发执行，但因为只回收一部分Region时间是用户可控的，，而且停顿用户线程将大幅提高收集效率。 不要将停顿目标时间设置太短， 否则可能导致每次选出来的回收集只占堆内存很小一部分， 收集器收集速度逐渐跟不上分配器分配的速度，导致垃圾堆积，很可能一开始收集器还能从空闲的堆内存中获得一些喘息的时间，但时间一长最终占满堆引发Full GC反而降低性能， 故通常把期望停顿时间设置为一两百毫秒或两三百毫秒会是比较合理的。 G1垃圾收集分类YoungGC并非现有的Eden区放满了立刻触发，G1会计算现在Eden区回收大概要多久时间，若回收时间远远小于参数-XX:MaxGCPauseMills设定值，则增加年轻代region，继续给新对象存放，直到下一次Eden区放满，G1计算回收时间接近参数-XX:MaxGCPauseMills设定的值，则会触发Young GC。 MixedGC老年代的堆占有率达到参数-XX:InitiatingHeapOccupancyPercent设定值时触发，根据期望的GC停顿时间确定old区垃圾收集的优先顺序回收所有Young和部分Old以及大对象区，正常情况G1的垃圾收集是先做MixedGC，主要使用复制算法，把存活的对象拷贝到别的region中，拷贝过程中若发现没有足够空region能够承载拷贝对象就会触发一次Full GC。 Full GC停止系统程序，采用单线程进行标记、清理和压缩整理，好空闲出来一批Region来供下一次MixedGC使用，该过程是非常耗时，Shenandoah优化成多线程收集了。 G1收集器参数设置-XX:+UseG1GC：使用G1收集器-XX:ParallelGCThreads：指定GC工作的线程数量-XX:G1HeapRegionSize：指定分区大小1MB~32MB，且必须是2的N次幂，默认将整堆划分为2048个分区-XX:MaxGCPauseMillis：目标暂停时间，默认200ms-XX:G1NewSizePercent：新生代内存初始空间，默认整堆5%-XX:G1MaxNewSizePercent：新生代内存最大空间-XX:TargetSurvivorRatio：Survivor区的填充容量，默认50%，Survivor区域里的一批对象(年龄1+年龄2+年龄n的多个年龄对象)总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代-XX:MaxTenuringThreshold：最大年龄阈值，默认15-XX:InitiatingHeapOccupancyPercent：老年代占用空间达到整堆内存阈值，默认45%，则执行新生代和老年代的混合收集MixedGC -XX:G1MixedGCLiveThresholdPercent：region中存活对象低于该值则回收该region，默认85%，若超过该值，存活对象过多回收意义不大。-XX:G1MixedGCCountTarget：在一次回收过程中指定做几次筛选回收，默认8次，在最后一个筛选回收阶段可以回收一会，然后暂停回收，恢复系统运行，一会再开始回收，这样可以让系统不至于单次停顿时间过长。-XX:G1HeapWastePercent： GC过程空出来的region是否充足阈值，混合回收时对Region回收是基于复制算法，把要回收的Region里存活对象放入其他Region，然后该Region中垃圾对象全部清理，在回收过程就会不断空出新的Region，一旦空闲出来的Region数量达到了堆内存的5%，会立即停止混合回收，意味着本次混合回收结束。 优化建议若-XX:MaxGCPauseMills设置很大，导致系统运行很久，年轻代可能都占用了堆内存的60%，此时才触发年轻代GC，存活下来的对象可能会很多，此时会导致Survivor区域放不下那么多对象，就会进入老年代中。或年轻代GC后，存活下来的对象过多，导致进入Survivor区域后触发了动态年龄判定规则，达到了Survivor区域的50%，也会快速导致一些对象进入老年代中。故核心在于调节-XX:MaxGCPauseMills参数的值，在保证年轻代GC不太频繁的同时，还得考虑每次GC后存活对象有多少，避免存活对象太多快速进入老年代，频繁触发Mixed GC。 适合场景G1天生就适合这种大内存机器的JVM运行，可以比较完美的解决大内存垃圾回收时间过长的问题。 50%以上的堆被存活对象占用 对象分配和晋升的速度变化非常大 垃圾回收时间特别长，超过1秒 8GB以上的堆内存 停顿时间是500ms以内 ZGC收集器JDK11中新加入，是一款基于Region内存布局的， 暂时不分代的， 使用了读屏障、 颜色指针等技术来实现可并发的标记-整理算法的， 以低延迟为首要目标的实验性质一款垃圾收集器。有四大目标： 支持TB量级的堆 最大GC停顿时间不超10ms 奠定未来GC特性的基础 最糟糕的情况下吞吐量会降低15% 为大、 中、 小三类容量，小型Region容量固定为2MB， 用于放置小于256KB的小对象；中型Region容量固定为32MB，用于放置大于等于256KB但小于4MB的对象；大型Region容量不固定可以动态变化，但必须为2MB的整数倍， 用于放置4MB或以上的大对象。 每个大型Region中只会存放一个大对象， 也预示着虽然名字叫作大型Region， 但实际容量完全有可能小于中型Region，最小容量可低至4MB。 大型Region在ZGC的实现中是不会被重分配，重分配是ZGC的一种处理动作，用于复制对象的收集器阶段， 因为复制一个大对象的代价非常高昂。 NUMA-awareNUMA对应UMA。UMA表示内存只有一块，所有CPU都去访问这一块内存，则会存在竞争问题，争夺内存总线访问权，有竞争就会有锁，有锁效率就会受到影响，而且CPU核心数越多，竞争就越激烈。NUMA为每个CPU对应一块内存，且这块内存在主板上离这个CPU是最近的，每个CPU优先访问这块内存： 服务器NUMA架构在中大型系统上一直非常盛行，也是高性能的解决方案，尤其在系统延迟方面表现都很优秀。ZGC是能自动感知NUMA架构并充分利用NUMA架构特性。 颜色指针ZGC的核心设计之一。以前的垃圾回收器的GC信息都保存在对象头中，而ZGC的GC信息保存在指针中： 每个对象有一个64位指针，这64位被分为：18位：预留给以后使用1位：Finalizable标识，此位与并发引用处理有关，表示该对象只能通过finalizer才能访问1位：Remapped标识，设置此位的值后，对象未指向需要GC的Region集合中1位：Marked1标识，标记对象用于辅助GC1位：Marked0标识，标记对象用于辅助GC42位：对象的地址，故它可以支持2^42=4T内存 2个mark标记每个GC周期开始时，会交换使用标记位，使上次GC周期中修正的已标记状态失效，所有引用都变成未标记。 GC周期1：使用mark0, 则周期结束所有引用mark标记都会成为01。 GC周期2：使用mark1, 则期待的mark标记10，所有引用都能被重新标记。 对象指针必须是64位，ZGC无法支持32位操作系统，同样的也就无法支持压缩指针 三大优势 一旦某个Region存活对象被移走后，该Region立即就能被释放和重用，不必等待整个堆中所有指向该Region的引用都被修正后才能清理，使得理论上只要还有一个空闲Region，ZGC就能完成收集。 颜色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量，ZGC只使用了读屏障。 颜色指针具备强大的扩展性，它可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能。 ZGC最大的问题是浮动垃圾，ZGC停顿时间在10ms以下，但ZGC执行时间远远大于该时间。若ZGC全过程需要执行10分钟，在该期间由于对象分配速率很高，将创建大量新对象，这些对象很难进入当次GC，只能在下次GC时进行回收，这些只能等到下次GC才能回收的对象就是浮动垃圾。 读屏障之前的GC都是采用Write Barrier，ZGC采用完全不同的方案读屏障，在标记和移动对象的阶段，每次从堆里对象的引用类型中读取一个指针的时候，都需要加上一个Load Barriers。 尝试读取堆中的一个对象引用obj.fieldA并赋给引用，若这时候对象在GC时被移动了，接下来JVM就会加上一个读屏障，该屏障会把读出的指针更新到对象的新地址上，并且把堆里的这个指针修正到原本的字段里。这样就算GC把对象移动了，读屏障也会发现并修正指针，应用代码就永远都会持有更新后的有效指针，而且不需要STW。JVM是利用颜色指针，如果指针是Bad Color，那么程序还不能往下执行，需要修正指针；如果指针是Good Color，那么正常往下执行即可： ZGC运作过程 并发标记Concurrent Mark：与G1一样并发标记是遍历对象图做可达性分析的阶段，它的初始标记Mark Start和最终标记Mark End也会出现短暂的停顿，与G1不同的是 ZGC的标记是在指针上而不是在对象上， 标记阶段会更新染色指针中的Marked 0、 Marked 1标志位。 并发预备重分配Concurrent Prepare for Relocate：该阶段需要根据特定查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集Relocation Set。每次回收都会扫描所有Region，用范围更大的扫描成本换取省去G1中记忆集的维护成本。 并发重分配Concurrent Relocate：重分配是ZGC执行过程中的核心阶段，这个过程要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表Forward Table，记录从旧对象到新对象的转向关系。ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集中，若用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障读屏障截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的自愈能力。 并发重映射Concurrent Remap：修正整个堆中指向重分配集中旧对象的所有引用，但对象引用存在自愈功能，故该重映射操作并不是很迫切。ZGC很巧妙地把并发重映射阶段要做的工作，合并到了下一次垃圾收集循环中的并发标记阶段里中完成，反正它们都是要遍历所有对象的，合并后节省了一次遍历对象图的开销。一旦所有指针都被修正之后， 原来记录新旧对象关系的转发表就可以释放掉了。 ZGC的颜色指针因为自愈Self‐Healing能力，所以只有第一次访问旧对象会变慢， 一旦重分配集中某个Region的存活对象都复制完毕后， 该Region就可以立即释放用于新对象的分配，但转发表还得留着不能释放掉， 因为可能还有访问在使用这个转发表。 ZGC触发时机ZGC目前有4中机制触发GC： 定时触发，默认为不使用，可通过ZCollectionInterval参数配置。 预热触发，最多三次，在堆内存达到10%、20%、30%时触发 分配速率，基于正态分布统计，计算内存99.9%可能的最大分配速率，以及此速率下内存将要耗尽的时间点，在耗尽之前触发GC，耗尽时间 - 一次GC最大持续时间 - 一次GC检测周期时间。 主动触发，默认开启，可通过ZProactive参数配置，距上次GC堆内存增长10%，或超过5分钟时，对比距上 次GC的间隔时间跟49 * 一次GC的最大持续时间，超过则触发。 总结 收集器 串并行/并发 新生代/老年代 算法 目标 适用场景 Serial 串行 新生代 复制算法 响应速度优先 单CPU环境Client模式 Serial Old 串行 老年代 标记-整理 响应速度优先 单CPU环境Client模式、CMS后备预案 ParNew 并行 新生代 复制算法 响应速度优先 多CPU环境Server模式与CMS配合 Parallel Scavenge 并行 新生代 复制算法 吞吐量优先 在后台运算而不需要太多交互的任务 Parallel Old 并行 老年代 标记-整理 吞吐量优先 在后台运算而不需要太多交互的任务 CMS 并发 老年代 标记-清除 响应速度优先 互联网站或B/S系统服务端 G1 并发 新生代&amp;老年代 标记-整理复制算法 响应速度优先 面向服务端应用，将来替换CMS 选择垃圾收集器 优先调整堆的大小让服务器自己来选择 如果内存小于100M，使用串行收集器 如果是单核，并且没有停顿时间的要求，串行或JVM自己选择 如果允许停顿时间超过1秒，选择并行或者JVM自己选 如果响应时间最重要，并且不能超过1秒，使用并发收集器 4G以下可以用parallel，4-8G可以用ParNew+CMS，8G以上可以用G1，几百G以上用ZGC 三色标记在并发标记过程中，标记期间应用线程还在继续跑，对象间的引用可能发生变化，多标和漏标的情况就有可能发生。 把Gc Roots可达性分析遍历对象过程中遇到的对象， 按照是否访问过这个条件标记成以下三种颜色： 黑色： 对象已经被垃圾收集器访问过， 且该对象的所有引用都已经扫描过。 黑色对象代表已经扫描过是安全存活的， 若有其他对象引用指向了黑色对象， 无须重新扫描。 黑色对象不可能不经过灰色对象直接指向某个白色对象。 灰色： 表示对象已经被垃圾收集器访问过， 但该对象上至少存在一个引用还没有被扫描过。 白色： 表示对象尚未被垃圾收集器访问过。 显然在可达性分析刚刚开始的阶段， 所有的对象都是白色的， 若在分析结束的阶段， 仍然是白色的对象， 即代表不可达 123456789101112131415161718192021public class ThreeColorRemark &#123; public static void main(String[] args) &#123; A a = new A(); //开始做并发标记 D d = a.b.d; // 1.读 a.b.d = null; // 2.写 a.d = d; // 3.写 &#125;&#125;class A &#123; B b = new B(); D d = null;&#125;class B &#123; C c = new C(); D d = new D();&#125;class C &#123;&#125;class D &#123;&#125; 多标在并发标记过程中，若由于方法运行结束导致部分局部变量即GC Root被销毁，该GC Root引用的对象被扫描过，已被标记为非垃圾对象，本轮GC不会回收这部分内存。这部分本应该回收但是没有回收到的内存，被称之为浮动垃圾。 浮动垃圾并不影响垃圾回收的正确性，只是需要等到下一轮垃圾回收中才被清除。针对并发标记和并发清理开始后产生的新对象，通常的做法是直接全部当成黑色，本轮不会进行清除。这部分对象期间可能也会变为垃圾，这也算是浮动垃圾的一部分。 漏标漏标会导致被引用的对象被当成垃圾误删除，这是严重bug必须解决，有两种解决方案： 增量更新Incremental Update和原始快照Snapshot At The Beginning，SATB。 增量更新：当黑色对象插入新的指向白色对象的引用关系时， 就将新插入的引用记录下来， 等并发扫描结束之后， 再将这些记录过的引用关系中的黑色对象为根， 重新扫描一次。 可以简化理解为黑色对象一旦新插入指向白色对象引用之后， 它就变回灰色对象。 原始快照：当灰色对象要删除指向白色对象的引用关系时， 就将要删除的引用记录下来， 在并发扫描结束后再将这些记录过的引用关系中的灰色对象为根， 重新扫描一次，这样就能扫描到白色的对象，将白色对象直接标记为黑色，目的是让这种对象在本轮GC清理中能存活下来，待下一轮GC时候重新扫描，这个对象也有可能是浮动垃圾。 无论是对引用关系记录的插入还是删除， 虚拟机的记录操作都是通过写屏障实现的。 写屏障所谓的写屏障，其实就是指在赋值操作前后，加入一些处理： 1234567void oop_field_store(oop* field, oop new_value) &#123; // 写屏障‐写前操作 pre_write_barrier(field); *field = new_value; // 写屏障‐写后操作 post_write_barrier(field, value); &#125; 写屏障实现SATB当对象B的成员变量的引用发生变化时，如引用消失a.b.d = null，可以利用写屏障，将B原来成员变量的引用对象D记录下来： 123456void pre_write_barrier(oop* field) &#123; // 获取旧值 oop old_value = *field; // 记录原来的引用对象 remark_set.add(old_value); &#125; 写屏障实现增量更新当对象A的成员变量的引用发生变化时，如新增引用a.d = d，我们可以利用写屏障，将A新的成员变量引用对象D记录下来： 1234void post_write_barrier(oop* field, oop new_value) &#123; // 记录新引用的对象 remark_set.add(new_value); &#125; 读屏障读屏障是直接针对第一步：D d = a.b.d，当读取成员变量时，一律记录下来： 1234567891011oop oop_field_load(oop* field) &#123; // 读屏障‐读取前操作 pre_load_barrier(field); return *field;&#125;void pre_load_barrier(oop* field) &#123; oop old_value = *field; // 记录读取到的对象 remark_set.add(old_value); &#125; 使用可达性分析算法的垃圾回收器几乎都借鉴了三色标记的算法思想，尽管实现的方式不尽相同：比如白色/黑色集合一般都不会出现，但是有其他体现颜色的地方、灰色集合可以通过栈/队列/缓存日志等方式进行实现、遍历方式可以是广度/深度遍历等等。 写屏障可以用于记录跨代/区引用的变化，读屏障可以用于支持移动对象的并发执行等 ，对于读写屏障，以HotSpot为例，其并发标记时对漏标的处理方案如下： CMS：写屏障 + 增量更新 G1，Shenandoah：写屏障 + SATB ZGC：读屏障 SATB相对增量更新效率会高，当然SATB可能造成更多的浮动垃圾，因为不需要在重新标记阶段再次深度扫描被删除引用对象，CMS对增量引用的根对象会做深度扫描，G1因为很多对象都位于不同的region，CMS就一块老年代区域，重新深度扫描对象的话G1的代价会比CMS高，所以G1选择SATB不深度扫描对象，只是简单标记，等到下一轮GC再深度扫描。 记忆集与卡表新生代做GC Roots可达性扫描过程中可能会碰到跨代引用的对象，若又对老年代再扫描效率太低，在新生代引入记录集Remember Set数据结构，记录从非收集区到收集区的指针集合，避免把整个老年代加入GC Roots扫描。并不只是新生代、 老年代之间才有跨代引用的问题， 所有涉及部分区域收集行为的垃圾收集器，典型的如G1、 ZGC和Shenandoah收集器， 都会面临相同的问题。 收集器只需通过记忆集判断出某一块非收集区域是否存在指向收集区域的指针即可，无需了解跨代引用指针的全部细节。hotspot使用一种叫做卡表cardtable的方式实现记忆集，也是目前最常用的一种方式。卡表与记忆集的关系，可以类比HashMap与Map的关系。 卡表是使用一个字节数组CARD_TABLE[]实现，每个元素对应一个卡页，其标识的内存区域内一块特定大小的内存块。hotSpot的卡页是2^9即512字节，一个卡页可包含多个对象，只要有一个对象的字段存在跨代指针，其对应的卡表的元素标识就变成1，表示该元素变脏，否则为0；GC时只筛选出本收集区卡表中变脏的元素加入GC Roots里。Hotspot在发生引用字段赋值时，使用写屏障维护卡表状态。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"垃圾收集算法及实现","date":"2018-01-02T16:00:00.000Z","path":"Blog/Java/VM/垃圾收集算法/","text":"标记清除算法标记清除算法是最基础的收集算法，分为标记和清除两个阶段，标记阶段标记出所有需要回收的对象，清除阶段统一回收所有被标记的对象。之所以说标记清除算法是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 标记清除算法主要有两个不足，一是效率问题，标记和清除两个过程的效率都不高；二是空间问题，标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后再程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发垃圾收集动作。 复制算法复制算法的出现是为了解决效率问题，它将可用内存按容量划分为大小相等的两块，每次只使用其中一块。当这一块使用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。每次都是对整个半区进行内存回收，内存分配时不用考虑内存碎片等复杂情况，只要移动堆顶指针按顺序分配内存即可，实现简单运行高效。但是代价是将内存缩小为原来的一半。 现在商用虚拟机都采用复制算法来回收新生代，因为新生代对象98%是朝生夕死，所以不需要按1：1来划分内存空间。而是将内存空间分为一块较大的Eden空间和两块较小的Survivor空间（From Survior和To Survovor），HotSpot虚拟机默认Eden：From Survivor：To Survivor的大小比例是8：1：1，每次使用Eden和From Survivor空间。当Eden空间执行Minor GC时会将Eden和From Survivor空间中还存活的对象复制到To Survivor空间中（如果To Survivor空间没有足够空间存放上一次新生代收集下来存活的对象时，这些对象将直接通过分配担保机制进入老年代。），然后清理掉Eden和From Survivor空间，最后将To Survivor空间和From Survivor空间角色互换。 复制算法在对象存活率较高时就要进行较多的复制操作，效率将会变低，老年代一般不能直接选用复制算法。 标记整理算法根据老年代的特点，提出了标记整理算法，标记过程任然与标记清除算法一样，整理阶段让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存。 分代收集算法目前商业虚拟机的垃圾收集都采用分代收集算法，这种算法并没有新思想，只是根据对象存活周期将内存分为几块，一般把堆内存分为新生代和老年代，新生代采用复制算法，老年代采用标记清除算法或标记整理算法进行回收。 注：标记-清除或标记-整理算法会比复制算法慢10倍以上 枚举根节点主流的Java虚拟机都是采用可达性分析算法来管理内存的。在可达性分析法中对象能被回收的条件是对象到GC Roots是否存在引用链，可作为GC Roots的节点主要是在全局性引用（e.g.常量或静态属性）和执行上下文（e.g.栈帧中本地变量表）。现在很多应用方法区都很大，如果逐个检查非常耗费时间。 而可达性分析算法的分析工作必须在一个能确保一致性的快照中进行，整个分析期间整个执行系统对象引用关系必须保持不变，就像被冻结在某个时间点上。这是导致GC执行时必须停顿所有Java执行线程的一个重要原因，Sun将该事件称为Stop-The-World。在枚举根节点的过程中耗费的时间越多GC停顿时间越长。 目前主流的Java虚拟机使用的都是准确式GC，当执行系统停顿后，并不需要一个不漏地检查完所有执行上下文和全局变量的引用位置，在HotSpot虚拟机实现中，使用一组称为OopMap的数据结构来记录所有执行上下文和全局变量的引用位置，在类加载完成时HotSpot就把对象内偏移量上对应的类型数据计算出来，在JIT编译过程中，也会在特定位置记录下栈和寄存器中哪些位置时引用。 安全点在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但是可能导致引用关系变化或者说OopMap内容变化的指令非常多，如果每条命令都生成对应的OopMap，将会需要大量额外空间，GC空间成本将会变得很高。 HotSpot只是在特定的位置记录生成的OopMap信息，这些位置称为安全点（Safepoint），程序执行时并非在所有地方都能停顿下来开始GC，只有在达到安全点时才能暂停。安全点的选定既不能太少以至于让GC等待时间太长，也不能过于频繁以至于过分增大运行时的负荷。安全点的选定基本上是以程序是否具有让程序长时间执行的特征为标准进行选定的，但是程序不太可能因为指令流太长而过长时间运行，这里的长时间执行实际上是指指令序列复用，例如方法调用、循环跳转、异常跳转等功能的指令才会产生安全点。 如何让所有线程（除执行JNI调用的线程）在GC发生时都运行到最近的安全点停顿下来。有抢占式中断和主动式中断两种方案可供选择。 抢占式中断——GC发生时，首先中断所有线程，如果发现有线程中断地方不在安全点上，就恢复线程让其运行到安全点。抢占式中断不需要线程的执行代码主动区配合，但是目前几乎没有虚拟机实现采用抢占式中断来暂停线程从而响应GC事件。 主动式中断——当GC需要中断线程的时候，不直接对线程操作，仅简单地设置一个轮询标志，各个线程执行时主动轮询整个标志，发现中断标志为真时就自己中断挂起。轮询标志、安全点和创建对象需要分配的内存三个地方是重合的。 安全区域安全点保证了程序执行时，在不太长时间内就会遇到可进入GC的安全点，但是程序不执行时（没有分配到CPU时间），例如线程处于Sleep状态或Blocked状态时，线程无法响应JVM中断请求并运行到安全的地方中断挂起，针对这种情况就需要安全区来解决。 安全区域时指在一段代码片段中，引用关系不会发生变化，整个区域中的任意地方开始GC都是安全的。线程在执行到安全区域中的代码时，首先标识自己进入了安全区域，当在这段时间里JVM要发起GC时，就不用管标识自己进入安全区域状态的线程了。在线程要离开安全区域时，先检查系统是否已经完成根节点枚举或是整个GC过程，如果没完成就必须等待直到收到可以安全离开安全区域的信号为止。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"对象是否存活","date":"2017-12-31T16:00:00.000Z","path":"Blog/Java/VM/对象是否存活/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 了解GC和内存非配的目的是：当需要排查各种内存溢出、内存泄露问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，为了更好的对这些自动化技术实施必要的监控和调节。 程序计数器、虚拟机栈、本地方法栈这三个区域是线程私有的方法结束或线程结束内存就跟着回收了；但在堆和方法区中，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，只有在程序处于运行期间才会知道会创建哪些对象，这部分的内存是动态的，也是垃圾收集器所关注的。 堆里面存放了几乎所有的对象实例，垃圾收集器在对堆进行回收前，首先确定对象是否存活（是否还有可能再被任何途径使用）。而判断对象是否存活的算法有引用计数算法和可达性分析算法两种，但目前主流的实现是通过可达性分析来判断对象是否存活的。 引用计数算法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器值为0的对象就是不可能再被使用的。 引用计数算法实现简单，判定效率很高，在大部分情况下它都是一个不错的算法，Python就是是使用的引用计数算法进行的内存管理。但是主流的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互引用的问题。 可达性分析算法通过一系列的称为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象时不可用的。 在Java中可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的局部变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（本地方法）引用的对象。 引用无论时通过引用计数算法还是通过可达性分析算法判断对象是否存都与引用有关。 在JDK 1.2以前，如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用；在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，这4种引用强度依次逐渐减弱。 强引用在程序代码中普遍存在的，类似Object obj = new Object()这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用是用来描述一些还有用但并非必要的对象。软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行二次回收。JDK提供了SoftReference类来实现软引用。 弱引用也是用来描述非必要对象，且比软引用更弱，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。JDK提供了WeakReference类来实现弱引用。 虚引用最弱的一种引用关系，也被称为幽灵引用或幻影引用。一个对象是否有虚引用存在完全不影响其生存时间，也无法通过虚引用来获取对象的实例。为一个对象设置虚引用关联的唯一目的是能在这个对象被收集器回收时收到一个系统通知。JDK提供了Phantomeference类来实现虚引用。 finalize方法即使对象不可达，也并非立即将该对象GC掉，真正宣告一个对象死亡至少需要经历两次标记过程，若果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选条件是此对象是否有必要执行finalize()方法。 如果对象没有覆盖finalize()方法或者finalize()方法已经被虚拟机调用过了，虚拟机将这两种情况视为没有必要执行，那么在下一个回收周期对象将会被回收。 如果对象被判定为有必要执行finalize()方法，该对象会被放置在一个叫做F-Queue的队列中，并在稍后由一个虚拟机自动建立的、低优先级的Finalizer线程去执行。虚拟机会触发这个方法但是不会等待它运行结束，因为如果有的finalize()方法执行缓慢甚至发送死循环，很可能导致F-Queue队列中其他对象永远处于等待，从而导致整个内存回收系统奔溃。稍后GC将对F-Queue中的对象进行二次小规模标记，被二次标记的对象在下一个回收周期将会被回收。 如果对象在finalize()方法中重新与引用链上的任何对象建立关联，在二次标记时它将被移除即将回收的集合。且任何对象的finalize()方法只会被系统自动调用一次。 有很多地方说finalize()方法适合做关闭外部资源之类的工作，但是finalize()方法运行的代价高昂、不确定性大，无法保证各个对象的调用顺序。且finalize()方法能做的所有工作，使用try-finally或者其他方式都可以做到而且可以做得更好跟及时，所以尽量不要使用finalize()方法。 回收方法区很多人认为方法区（HotSpot中的永久代）没有垃圾收集，虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，且方法区垃圾收集性价比很低，是否对方法区进行垃圾收集HotSpot通过-Xnoclassgc参数来控制。 方法区的垃圾收集主要回收废弃的常量和无用的类两部分。回收废弃的常量与回收堆中的对象非常类似。判断一个类是否是无用的类的条件非常苛刻，需要同时满足下面3个条件： 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 通常在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景需要虚拟机具备类卸载功能，以保证方法区不会溢出。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"OOM异常实验","date":"2017-12-23T16:00:00.000Z","path":"Blog/Java/VM/OutOfMemoryError异常/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 堆溢出堆中存储的是对象的实例，只要不断的创建对象，并保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，当对象数量达到最大堆的通量限制后就会产生内存溢出异常。本次测试中通过限制堆内存的大小且将其限制为不可扩展（将堆的最小值-Xms和最大值-Xmx参数设置为一样）来进行堆内存溢出测试。 测试使用的示例代码：123456789101112public class HeapOOM &#123; static class OOMObject&#123;&#125; public static void main(String[] args)&#123; List&lt;OOMObject&gt; list = new ArrayList&lt;OOMObject&gt;(); while(true)&#123; list.add(new OOMObject()); &#125; &#125;&#125; 使用的VM Args：-Xms50m -Xmx50m -XX:+HeapDumpOnOutOfMemoryError；我使用的IDEA通过Edit Configurations在VM options对虚拟机参数进行设置。 在测试过程中发现一个非常有趣的问题，当将堆内存大小限制为50m、80m时（是否还有其他的数值会导致该现象就没有具体去深究了），运行的程序会被一直Full GC导致Stop-the-world从而导致程序一直不会被执行结束，而且发现当前使用的是Parallel Scavenge收集器。更有趣的是当使用其他的收集器时不会出现这样的问题，目前还未找到具体的原因。 正常情况下Java堆内存溢出时，溢出堆栈信息java.lang.OutOfMemoryError: Java heap space如下图： 栈溢出12345678910111213141516171819public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLack()&#123; stackLength++; stackLack(); &#125; public static void main(String[] args) throws Exception &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLack(); &#125; catch (Exception e) &#123; System.out.println(\"stack length:\" + oom.stackLength); throw e; &#125; &#125;&#125; 方法区和运行时常量池溢出本地直接内存溢出","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Java内存区域","date":"2017-12-23T16:00:00.000Z","path":"Blog/Java/VM/Java内存区域/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。 程序计数器程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机概念模型里，字节码解释器工作时就是通过改变程序计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，是线程私有的内存区域。 如果线程正在执行一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。 程序计数器的内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈Java虚拟机栈也是线程私有的，它的生命周期与线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法从调用到执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，尽管在运行期会由JIT编译器进行一些优化，但大体上可以认为时编译期可知的。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象的引用（reference类型，它可能是一个指向对象的起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈中如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分虚拟机都可以动态扩展，只是虚拟机规范中允许固定长度的虚拟机栈），如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。 本地方法栈本地方法栈与虚拟机栈所发挥的作用非常相似，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。本地方法栈与虚拟机栈一样也会抛出StackOverflowError和OutOfMemoryError异常。 注：HotSpot虚拟机直接把本地方法栈和虚拟机栈合二为一 Java堆对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。Java虚拟机规范中的描述是：所有的对象实例和数组都要在堆上分配，但是随着JIT（Just In Time，即时编译）编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术导致所有对象都在堆上分配逐渐变得不那么绝对。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做GC堆。从内存回收的角度来看，现在的收集器基本都采用分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点有Eden空间、From Survior空间、To Survovor空间等。 Java堆可以处于物理上不连续的内存空间中，只要逻辑上连续即可。主流的虚拟机都是按照可扩展来实现的，通过-Xmx（JVM最大允许分配的堆内存）和-Xms（JVM初始分配堆内存）来控制。如果堆中没有内存完成实例分配，且堆也无法再扩展时，将抛出OutOfMemoryError异常。 方法区和Java堆一样是线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。Java虚拟机规范把方法区描述为堆的一个逻辑部分。 对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人把方法区称为永久代，但是本质上两者并不等价，仅仅因为HotSpot的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已，这样HotSpot的垃圾收集器可以像管理Java堆一样管理方法区内存，能节省为方法区编写内存管理代码，但对于其他虚拟机来说并不存在永久代的概念。使用永久代来实现方法区并非是一个好主意，这样更容易遇到内存溢出问题，因为永久代有-XX:MaxPermSize的设置上限，现在HotSpot也有放弃永久代并逐步采用Native Memory来实现方法区的规划，在HotSpot的JDK1.7中，已经把原本放在永久代的字符串常量池移除。 方法区不需要连续内存、可选择固定大小、可扩展、可选择不实现垃圾收集。方法区内存回收的目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池。运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，常量并非只有编译期才能产生，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 直接内存直接内存并不是虚拟机运行时数据区域的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁使用，也可能导致OutOfMemoryError异常。本地直接内存的分配不会受Java堆大小的限制，但既然是内存，肯定受本地主机总内存和处理器寻址空间限制。再配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"堆中对象分配&布局&访问","date":"2017-12-23T16:00:00.000Z","path":"Blog/Java/VM/堆中对象分配&布局&访问/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 对象的创建Java中创建对象（例如克隆、反序列化）通常仅仅是一个new关键字。当虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在运行时常量池中定位到一个类的符号引用，并检查这个符号引用代表的类是否已被加载、解析、和初始化过。如果没有必须先执行相应的类加载过程。 在类加载检查通过后，虚拟机将为新生对象分配内存，对象所需内存的大小在类加载完成后便可完全确定。对象内存的分配方式有指针碰撞和空闲列表两种，选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定，或者说所采用的垃圾收集器采用的哪种或哪几种垃圾收集算法决定。 指针碰撞，假设堆内存绝对规整，使用过的内存放在一边空闲内存放在另一边，中间放着一个指针作为分界点的指示器，给对象分配内存时将该指针向空闲空间那边挪一段与对象大小相等的距离。 空闲列表，堆内存不规则，已使用的内存和空闲内存相互交错，这时虚拟机就必须维护一个列表，用于记录哪些内存是可用的，在分配内存时从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。 对象的创建在虚拟机中是非常频繁的行为，在并发情况下是非线程安全的。解决线程安全问题有两种方案： 对分配内存空间的动作进行同步处理——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性。 把内存分配的动作按照线程划分在不同的空间中进行，为每个线程在堆中预先分配一小块内存TLAB（本地线程分配缓冲），线程分配内存时在TLAB上分配，当TLAB用完并分配新的TLAB时才需要进行同步锁定。虚拟机通过-XX:+/-UseTLAB参数来设置是否使用TLAB。 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值，但不包括对象头。如果使用TLAB该过程可以提前至TLAB分配时进行。该操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用。接下来虚拟机要对对象进行必要的设置，类如对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄、是否使用偏向锁等这些存在对象头中的信息。执行new指令后会接着执行&lt;init&gt;方法，把对象按照开发着的意愿进行初始化。 对象的内存布局在HotSpot虚拟机中对象在内存中存储布局分为对象头、实例数据和对齐填充3块区域。 对象头包括用于存储对象自身的运行时数据和类型指针。运行时数据包括哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳；类型指针——对象指向它的类元数据的指针，虚拟机通过该指针来确定这个对象是哪个类的实例。但并不是所有虚拟机在对象数据上保留类型指针，或者做查找对象的元数据信息不一定要经过对象本身。另外如果对象是一个数组，在对象头中必须有一块用于记录数组长度的数据，这样虚拟机可以通过对象元数据信息确定Java对象大小，但从数组的元数据中却无法确定数组的大小。 对象头在hotspot的C++源码里的注释如下： 1234567891011121314151617181920Bit‐format of an object header (most significant first, big endian layout below)://// 32 bits:// ‐‐‐‐‐‐‐‐// hash:25 ‐‐‐‐‐‐‐‐‐‐‐‐&gt;| age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object)// size:32 ‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐&gt;| (CMS free block)// PromotedObject*:29 ‐‐‐‐‐‐‐‐‐‐&gt;| promo_bits:3 ‐‐‐‐‐&gt;| (CMS promoted object)//// 64 bits:// ‐‐‐‐‐‐‐‐// unused:25 hash:31 ‐‐&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object)// PromotedObject*:61 ‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐&gt;| promo_bits:3 ‐‐‐‐‐&gt;| (CMS promoted object)// size:64 ‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐&gt;| (CMS free block)//// unused:25 hash:31 ‐‐&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)// JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)// narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 ‐‐‐‐‐&gt;| (COOPs &amp;&amp; CMS promoted object)// unused:21 size:35 ‐‐&gt;| cms_free:1 unused:7 ‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐&gt;| (COOPs &amp;&amp; CMS free block) 实例数据是对象真正存储有效信息，也是程序代码中所定义的各种类型的字段内容。从父类继承的和在子类中定义的都需要记录。存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中的定义顺序影响。HotSpot默认分配策略是相同宽度的字段总是被分到一起。在满足该条件的情况下父类中定义的变量会出现在子类之前。如果CompactFields参数值为true，子类中较窄的变量也可能会插入到父类变量的空隙之中。 对齐填充并不是必然存在的，仅仅起占位符的作用。HotSpot VM自动内存管理系统要求对象的起始地址必须是8字节的整倍数，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 对象的访问定位对象的访问需要通过栈上的引用对象（reference）数据来操作堆上的具体对象。由于reference类型在虚拟机规范中只定义了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，对象的访问方式由虚拟机实现而定，目前主要的访问方式有使用句柄和直接指针两种。 使用句柄访问的话，在堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。 使用直接指针访问的话，堆中对象的布局就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象的地址。 两种对象访问方式各有优势，使用句柄访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而reference本身不需要修改；使用直接指针访问方式的最大好处就是速度更快，节省了一次指针定位的时间开销，HotSpot虚拟机使用的直接指针方式进行对象的访问； 暂时理解为上一节对象的内存布局中讲的对象头中的类型指针就是对象类型数据的指针，当然这是使用直接指针访问对象的情况；在通过句柄访问对象的情况下就不存在对象头中的类型指针了。 对象大小与指针压缩对象大小可以用jol-­core包查看，引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728public class JOLSample &#123; public static void main(String[] args) &#123; &#123; Object obj = new Object(); System.out.println(ClassLayout.parseInstance(obj).toPrintable()); synchronized (obj) &#123; System.out.println(ClassLayout.parseInstance(obj).toPrintable()); &#125; &#125; &#123; System.out.println(\"***********************\"); ClassLayout layout = ClassLayout.parseInstance(new int[]&#123;&#125;); System.out.println(layout.toPrintable()); &#125; &#123; System.out.println(\"***********************\"); ClassLayout layout = ClassLayout.parseInstance(new A()); System.out.println(layout.toPrintable()); &#125; &#125; public static class A &#123; int id; // 4B String name; // 4B 如果关闭压缩‐XX:‐UseCompressedOops，则占用8B byte aByte; // 1B Object object; // 4B 如果关闭压缩‐XX:‐UseCompressedOops，则占用8B &#125;&#125; 在执行时设置VM参数，‐XX:+UseCompressedOops默认开启的压缩所有指针，‐XX:+UseCompressedClassPointers默认开启压缩对象头里类型指针Klass Pointer。运行结果如下，VALUE打印的是对象头的信息，且由于计算机是小端模式，所以先打印的低位再打印的高位，所以要颠倒过来看，故对于第一个obj的对象头信息00000000 00000000 00000000 00000001，可明显看出是无锁状态，对于用synchronized (obj)加锁的第二个打印的obj对象头信息00000011 00100111 11110101 11101000，可明显看出是轻量级锁，虽然通常说锁是先从偏向锁再到轻量级锁，但JVM做了优化进行了锁的推迟，默认推迟大概4s多一点，为了避免无谓的大量的偏向锁向轻量级锁转换的开销，可通过-XX:BiasedLockingStartupDelay=0来禁用延迟： 12345678910111213141516171819202122232425262728293031323334353637383940414243java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) e8 f5 27 03 (11101000 11110101 00100111 00000011) (52950504) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total***********************[I object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 6d 01 00 f8 (01101101 00000001 00000000 11111000) (-134217363) 12 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 16 0 int [I.&lt;elements&gt; N/AInstance size: 16 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total***********************com.eleven.icode.jvm.JOLSample$A object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 63 cc 00 f8 (01100011 11001100 00000000 11111000) (-134165405) 12 4 int A.id 0 16 1 byte A.aByte 0 17 3 (alignment/padding gap) 20 4 java.lang.String A.name null 24 4 java.lang.Object A.object null 28 4 (loss due to the next object alignment)Instance size: 32 bytesSpace losses: 3 bytes internal + 4 bytes external = 7 bytes total 在64位平台的HotSpot中使用32位指针，内存使用会多出1.5倍左右，使用较大指针在主内存和缓存之间移动数据，占用较大宽带，同时GC也会承受较大压力。为了减少64位平台下内存的消耗，所以启用指针压缩功能； JVM中32位地址最大支持4G内存(2的32次方)，可通过对对象指针压缩编码、解码方式进行优化，使得jvm只用32位地址就可以支持更大的内存配置(小于等于32G) 。 堆内存小于4G时，不需要启用指针压缩，jvm会直接去除高32位地址，即使用低虚拟地址空间；堆内存大于32G时，压缩指针会失效，会强制使用64位(即8字节)来对java对象寻址； 123456789public static void main(String[] args) throws InterruptedException &#123; TimeUnit.SECONDS.sleep(5); Object obj = new Object(); System.out.println(ClassLayout.parseInstance(obj).toPrintable()); synchronized (obj) &#123; System.out.println(ClassLayout.parseInstance(obj).toPrintable()); &#125; System.out.println(ClassLayout.parseInstance(obj).toPrintable());&#125; 进行延时后，很明显看到第一个打印的obj对象头为：00000000 00000000 00000000 00000101，这里为什么第一个obj也变成了偏向锁呢，且无偏向信息，此时对象是处于匿名偏向，可偏向状态，第二个打印的obj对象头：00000010 10010001 01001000 00000101，加上锁后再打印对象头信息，发现马上就有偏向信息了，当退出同步块后对象头中锁标记依然是偏向锁。 1234567891011121314151617181920212223242526java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 58 59 03 (00000101 01011000 01011001 00000011) (56186885) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 58 59 03 (00000101 01011000 01011001 00000011) (56186885) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total hashCode对锁的影响当一个对象已经计算过identity hash code它就无法进入偏向锁状态；当一个对象当前正处于偏向锁状态，并且需要计算其identity hash code的则它的偏向锁会被撤销，且锁会膨胀为重量锁； Identity hash code是未被覆写的java.lang.Object.hashCode()或java.lang.System.identityHashCode(Object)返回的值。若一个对象覆盖了hashCode方法，仍想获得它的内存地址计算的Hash值可调用identityHashCode方法。 12345678910public static void main(String[] args) throws InterruptedException &#123; TimeUnit.SECONDS.sleep(5); Object obj = new Object(); System.out.println(ClassLayout.parseInstance(obj).toPrintable()); obj.hashCode(); System.out.println(ClassLayout.parseInstance(obj).toPrintable()); synchronized (obj) &#123; System.out.println(ClassLayout.parseInstance(obj).toPrintable()); &#125;&#125; 开始锁是处于偏向锁的状态，当调用锁对象obj的hashCode方法后，锁从偏向锁退出变为无锁状态，当通过synchronized对obj加锁时，锁变直接为了轻量级锁，即使退出了同步块对象头中锁标志变成无锁状态，而非偏向锁。 1234567891011121314151617181920212223242526272829303132333435java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 db ec 2d (00000001 11011011 11101100 00101101) (770497281) 4 4 (object header) 18 00 00 00 (00011000 00000000 00000000 00000000) (24) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) c8 f0 96 02 (11001000 11110000 10010110 00000010) (43446472) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 db ec 2d (00000001 11011011 11101100 00101101) (770497281) 4 4 (object header) 18 00 00 00 (00011000 00000000 00000000 00000000) (24) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 当hashCode调用在synchronized代码块中执行时，锁直接从偏向锁变成了重量级锁，退出同步块后锁状态还是处于重量级锁的状态。 1234567891011public static void main(String[] args) throws InterruptedException &#123; TimeUnit.SECONDS.sleep(5); Object obj = new Object(); System.out.println(ClassLayout.parseInstance(obj).toPrintable()); synchronized (obj) &#123; System.out.println(ClassLayout.parseInstance(obj).toPrintable()); obj.hashCode(); System.out.println(ClassLayout.parseInstance(obj).toPrintable()); &#125; System.out.println(ClassLayout.parseInstance(obj).toPrintable());&#125; 1234567891011121314151617181920212223242526272829303132333435java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 58 7d 03 (00000101 01011000 01111101 00000011) (58546181) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 0a cd 3e 26 (00001010 11001101 00111110 00100110) (641649930) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 0a cd 3e 26 (00001010 11001101 00111110 00100110) (641649930) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 对象内存分配 对象栈上分配JAVA中对象都是在堆上分配，当对象没有被引用时，需要依靠GC进行回收，若对象数量较多时，会给GC带来较大压力，也间接影响了应用的性能。为了减少临时对象在堆内分配的数量，JVM通过逃逸分析确定该对象不会被外部访问。若不会逃逸可以将该对象在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。 JDK7之后默认开启逃逸分析，可以通过-XX:+/-DoEscapeAnalysis开启或关闭逃逸分析来优化对象内存分配位置，使其通过标量替换优先分配在栈上； 标量替换：通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该对象成员变量分解若干个被该方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就不会因为没有一大块连续空间导致对象内存不够分配。通过-XX:+EliminateAllocations参数开启标量替换，JDK7之后默认开启； 标量即不可被进一步分解的量，如int，long等基本数据类型以及reference类型等，聚合量是可以被进一步分解的量，也可以使用jmap -histo查看创建对象的数量加以验证； 1234567891011121314151617181920212223242526/** * 栈上分配，标量替换 * 代码调用了1亿次alloc()，如果是分配到堆上，大概需要1GB以上堆空间，如果堆空间小于该值，必然会触发GC。 * &lt;p&gt; * 使用如下参数不会发生GC * -Xmx15m -Xms15m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations * 使用如下参数都会发生大量GC * -Xmx15m -Xms15m -XX:-DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations * -Xmx15m -Xms15m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:-EliminateAllocations */public class AllotOnStack &#123; public static void main(String[] args) &#123; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 100000000; i++) &#123; alloc(); &#125; long end = System.currentTimeMillis(); System.out.println(\"耗时：\" + (end - start)); &#125; private static void alloc() &#123; User user = new User(); user.setName(\"Test User\"); user.setAge(15); &#125;&#125; 在Eden区分配对象大多数情况下对象在新生代中Eden区分配，当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。 Minor GC/Young GC：指发生新生代的的垃圾收集动作，Minor GC非常频繁，回收速度一般也比较快 Major GC/Full GC：一般会回收老年代 ，年轻代，方法区的垃圾，Major GC的速度一般会比Minor GC的慢10倍以上 Eden区满了会触发minor gc，99%以上的对象可能都会成为垃圾被回收掉，剩余存活对象会被挪到空的那块survivor区，下次Eden区满了后又会触发minor gc，把Eden区和survivor区垃圾对象回收，把剩余存活对象一次性挪动到另外一块空的survivor区。 新生代的对象都是朝生夕死存活时间很短，故JVM默认的8:1:1的比例是很合适的，让eden区尽量的大，survivor区够用即可，JVM默认开启-XX:+UseAdaptiveSizePolicy参数，会导致这个8:1:1比例自动变化。 通过-XX:+PrintGCDetails参数打赢GC日志详情，一下代码可以看到即使程序什么也不做，eden区内存也几乎已经被分配完全。 12345678910111213public static void main(String[] args) &#123; byte[] allocation = new byte[60000 * 1024];&#125;Heap PSYoungGen total 76288K, used 65245K [0x000000076b180000, 0x0000000770680000, 0x00000007c0000000) eden space 65536K, 99% used [0x000000076b180000,0x000000076f137638,0x000000076f180000) from space 10752K, 0% used [0x000000076fc00000,0x000000076fc00000,0x0000000770680000) to space 10752K, 0% used [0x000000076f180000,0x000000076f180000,0x000000076fc00000) ParOldGen total 175104K, used 0K [0x00000006c1400000, 0x00000006cbf00000, 0x000000076b180000) object space 175104K, 0% used [0x00000006c1400000,0x00000006c1400000,0x00000006cbf00000) Metaspace used 3445K, capacity 4496K, committed 4864K, reserved 1056768K class space used 376K, capacity 388K, committed 512K, reserved 1048576K 若再分配一个8M的内存，Eden区没有足够空间进行分配，明显的看到进行了一次Minor GC，由于survivor空间只有10752K明显不足以放下allocation1，只好把新生代的对象提前转移到老年代中去，老年代上的空间足够存放allocation1，故不会出现Full GC； 1234567891011121314public static void main(String[] args) &#123; byte[] allocation = new byte[60000 * 1024]; byte[] allocation2 = new byte[8000 * 1024];&#125;[GC (Allocation Failure) [PSYoungGen: 63934K-&gt;776K(76288K)] 63934K-&gt;60784K(251392K), 0.0312953 secs] [Times: user=0.11 sys=0.00, real=0.03 secs] Heap PSYoungGen total 76288K, used 9431K [0x000000076b180000, 0x0000000774680000, 0x00000007c0000000) eden space 65536K, 13% used [0x000000076b180000,0x000000076b9f3ef8,0x000000076f180000) from space 10752K, 7% used [0x000000076f180000,0x000000076f242020,0x000000076fc00000) to space 10752K, 0% used [0x0000000773c00000,0x0000000773c00000,0x0000000774680000) ParOldGen total 175104K, used 60008K [0x00000006c1400000, 0x00000006cbf00000, 0x000000076b180000) object space 175104K, 34% used [0x00000006c1400000,0x00000006c4e9a010,0x00000006cbf00000) Metaspace used 3446K, capacity 4496K, committed 4864K, reserved 1056768K class space used 376K, capacity 388K, committed 512K, reserved 1048576K 执行Minor GC后，后面分配的对象如果能够存在eden区的话，还是会在eden区分配内存，如下代码所示： 12345678910111213141516171819public static void main(String[] args) &#123; byte[] allocation1 = new byte[60000 * 1024]; byte[] allocation2 = new byte[8000 * 1024]; byte[] allocation3 = new byte[8000 * 1024]; byte[] allocation4 = new byte[8000 * 1024]; byte[] allocation5 = new byte[8000 * 1024]; byte[] allocation6 = new byte[8000 * 1024];&#125;[GC (Allocation Failure) [PSYoungGen: 63934K-&gt;776K(76288K)] 63934K-&gt;60784K(251392K), 0.0255463 secs] [Times: user=0.09 sys=0.05, real=0.03 secs] Heap PSYoungGen total 76288K, used 42715K [0x000000076b180000, 0x0000000774680000, 0x00000007c0000000) eden space 65536K, 63% used [0x000000076b180000,0x000000076da74e78,0x000000076f180000) from space 10752K, 7% used [0x000000076f180000,0x000000076f242020,0x000000076fc00000) to space 10752K, 0% used [0x0000000773c00000,0x0000000773c00000,0x0000000774680000) ParOldGen total 175104K, used 60008K [0x00000006c1400000, 0x00000006cbf00000, 0x000000076b180000) object space 175104K, 34% used [0x00000006c1400000,0x00000006c4e9a010,0x00000006cbf00000) Metaspace used 3446K, capacity 4496K, committed 4864K, reserved 1056768K class space used 376K, capacity 388K, committed 512K, reserved 1048576K 大对象直接进入老年代大对象直接分配到老年代的目的是为了避免大对象分配内存时的复制操作而降低效率，JVM参数-XX:PretenureSizeThreshold单位字节，可以设置大对象的大小，若对象超过设置大小会直接进入老年代，该参数只在Serial和ParNew两个收集器下有效。 12345678910111213141516171819202122232425/** * -XX:+PrintGCDetails * 通过如下参数让大对象直接分配在老年代 * -XX:PretenureSizeThreshold=1000000 (单位是字节) -XX:+UseSerialGC */public class GCTest &#123; public static void main(String[] args) &#123; byte[] allocation1 = new byte[60000 * 1024]; byte[] allocation2 = new byte[8000 * 1024]; byte[] allocation3 = new byte[8000 * 1024]; byte[] allocation4 = new byte[8000 * 1024]; byte[] allocation5 = new byte[8000 * 1024]; byte[] allocation6 = new byte[8000 * 1024]; &#125;&#125;Heap def new generation total 78656K, used 5596K [0x00000006c1400000, 0x00000006c6950000, 0x00000007162a0000) eden space 69952K, 8% used [0x00000006c1400000, 0x00000006c19772a8, 0x00000006c5850000) from space 8704K, 0% used [0x00000006c5850000, 0x00000006c5850000, 0x00000006c60d0000) to space 8704K, 0% used [0x00000006c60d0000, 0x00000006c60d0000, 0x00000006c6950000) tenured generation total 174784K, used 100000K [0x00000007162a0000, 0x0000000720d50000, 0x00000007c0000000) the space 174784K, 57% used [0x00000007162a0000, 0x000000071c448060, 0x000000071c448200, 0x0000000720d50000) Metaspace used 3446K, capacity 4496K, committed 4864K, reserved 1056768K class space used 376K, capacity 388K, committed 512K, reserved 1048576K 对象动态年龄判断一批对象的总大小大于这块Survivor区域内存大小的50%，可以通过-XX:TargetSurvivorRatio参数指定，则此时大于等于这批对象年龄最大值的对象，直接进入老年代，例：Survivor区域里现在有一批对象，年龄1+年龄2+年龄n多个年龄对象总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代。这个规则其实是希望那些可能是长期存活的对象，尽早进入老年代。对象动态年龄判断机制一般是在Minor GC之后触发。 老年代空间分配担保机制年轻代每次Minor GC之前JVM都会计算老年代剩余可用空间，若可用空间小于年轻代里现有的所有对象大小之和，包括垃圾对象，就会检查-XX:-HandlePromotionFailure参数是否设置，jdk1.8默认设置，若已设置则检查老年代可用内存大小，判断是否大于之前每一次Minor GC后进入老年代的对象的平均大小。若小于或参数未设置，则触发一次Full GC，若回收完还是没有足够空间存放新的对象则发生OOM，若Minor GC之后剩余存活的需要挪动到老年代的对象大小还是大于老年代可用空间，也会触发Full GC，Full GC完之后如果还是没有空间放Minor GC之后的存活对象，则也会发生OOM。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"地址解析协议ARP","date":"2017-12-19T16:00:00.000Z","path":"Blog/杂记/协议族/地址解析协议/","text":"对于TCP/IP网络在网络通信过程中，通常数据从应用层到数据链路层会被层层封装加上各层的报头，在数据链路层会加上以太网的报头，而以太网的报头中包含目标MAC地址、源MAC地址等数据。其中的目标MAC地址就是通过地址解析协议ARP来获取的。 ARP基础ARP仅用于IPv4，IPv6使用邻居发现协议。 地址解析是发现两个地址之间的映射关系的过程。 ARP高效运行的关键是维护每个主机和路由器上的ARP缓存，该缓存使用地址解析为每个接口维护从网络层到硬件地址的最新映射。 ARP地址解析过程当主机A向主机B发送数据时，首先将主机B的地址跟主机A的地址进行一个与运算来确认两主机是否处于同一个网段（通过网络地址来区分）。 当确认处于同一网段时，首先主机A会查自己的ARP高速缓存表中是否存在主机B的IP地址和其MAC地址的映射关系。如果存在，就直接把IP数据封装成帧进行通信，如果不存在，则先缓存该数据报文，然后主机A就使用链路层广播帧向在同一个共享链路层网段上的所有主机广播ARP请求。该网段上的所以主机都会收到该ARP请求广播包，所有收到ARP请求的主机先比较自己IP地址跟请求中的目的IP地址是否匹配，如果不匹配主动丢弃该ARP查询。如果匹配，把该ARP请求中的源IP地址和源MAC地址存入自己的ARP高速缓存表中，然后填充自己的MAC地址，将两个发送方地址和接收方地址互换，然后向主机A发送生成的应答，应答通常不是广播，而是仅直接发送给请求的发送方。当主机A收到该ARP应答后后，把主机B的IP地址和MAC地址添加到ARP高速缓存表中，然后把IP数据封装成帧与主机B进行通信。 当两主机处于不同网段时。主机A先向网关发送ARP请求报文，当收到网关ARP应答时，先把网关的MAC地址和IP地址记录的ARP高速缓存表中，然后把IP数据包封装成帧发送给网关，然后网关再查看自己的ARP高速缓存表中有没有主机B的IP地址和其MAC地址的映射关系，如果有，就直接封装再发送，如果没有就发送广播，再获取主机B的MAC地址，再封装发送。 ARP帧格式 DST：目的MAC地址，对于ARP请求目的MAC地址全为1为广播地址。SRC：源MANC地址，MAC地址为48位即6个字节。长度或类型：在以太网帧中，对于ARP请求或应答，2字节的长度或类型字段必须为0x0806硬件类型：指硬件地址类型，对于以太网该值为1协议类型：指映射的协议地址类型，对于IPv4地址改值为0x0800。硬件大小：硬件地址的字节数协议大小：协议地址的字节数Op：指ARP请求类型。 1：ARP请求；2：ARP应答；3：RARP请求；4：RARP应答 ARP请求或ARP应答的大小是42字节（ARP消息为28字节，以太网头部为14字节） 对于一个ARP请求，除了目的硬件地址设为0之外，其他字段都需要填充。当一个系统接收到一个ARP请求，它填充自己的硬件地址，将两个发送方地址和接收方地址互换，将Op字段设置为2，然后发送生成的应答。 ARP命令1arp -a # 显示ARP缓存中的所有条目 通过该命令能够查出动态和静态的映射关系条目。 在大多数实现中，完整条目的超时未20分钟，而不完整的条目的超为3分钟（例如：强迫执行一次到不存在主机的ARP请求）。","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"协议族","slug":"杂记/协议族","permalink":"https://yaoyinglong.github.io/categories/杂记/协议族/"}]},{"title":"分支管理理解","date":"2017-11-29T16:00:00.000Z","path":"Blog/杂记/Git/分支管理理解/","text":"在经历了持续不断的需求，通常多个需求会同时开发，以及发布情况复杂很多时候需求上不了，需要回退代码且版本管理混乱后，通过别人的建议和自己的思考，总结了一些自己觉得对版本管理比较安全的方式方法。 一般的项目种都有主分支master、开发分支develop、上线分支Release。通常我们是在develop分支上进行开发，当要上线时会从develop分支上拉取上线分支Release，当上线完成后将Release分支合并到master和develop分支上。 每一个需求都拉一个新的分支，且根据需求的复杂程度以及周期长短决定从哪一个分支上进行新分支的拉取，建议所有需求都从master分支上拉取新分支。以及是否有必要新建立一个对应的远程分支。建议分支名称最好是以自己的名字/需求编号的形式进行命名。 当开发一个简单且周期短的的需求时，可以直接从master分支上拉取新分支，也可以从develop分支上拉取，可以不必建立对应的远程分支。当开发完成时直接push到develop分支上，如果是需要上线直接push到Release分支上。即使需求上不了线，将关键代码存下来，等上线完成合完分支很快就能恢复代码。 当开发一个比较复杂的需求时，从master或develop分支上拉取新分支1，并创建对应的远程分支2，开发过程中提交到对应的远程分支2上。当开发完成需要联调或者上线时，从联调分或者上线分支上拉一个新分支3，在分支3上拉取远程分支2进行merge。后面调试过程中的调整可以直接在分支3上进行，并直接提交到联调或上线分支。这样即使你的需求不上线了，打开分支1将分支1该需求对应的代码compare with联调或上线分支,将修改的部分写入分支1并push到远程分支2。然后打开分支3与compare with master分支删掉该需求对应的代码。等上线完成Release分支合并master分支后直接在master分支上拉一个新分支4compare with远程分支2，将需求代码快速写入分支4，然后直接将分支4push到develop或者新的上线分支上。所有的push操作之前必须进行pull操作。","tags":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/tags/Git/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"Git","slug":"杂记/Git","permalink":"https://yaoyinglong.github.io/categories/杂记/Git/"}]},{"title":"以太网","date":"2017-11-29T16:00:00.000Z","path":"Blog/杂记/协议族/以太网/","text":"以太网属于TCP/IP协议族四层概念模型的最底层数据链路层，以太网网络通信信号的基本单元是以太网帧，帧的最小长度是64字节。以太网帧的基本机构如下图所示： 前导码表示一个以太网帧的开始，其作用是使目的主机接收器时钟与源主机发送器时钟同步。以太网帧是不含前导码的，以太网帧是由以太网首部、数据、以太网尾部FCS（帧检验序列）组成。 以太网首部包含目标MAC地址、源MAC地址以及类型组成，MAC地址的长度是48比特，类型占2字节，故以太网的首部总共占14个字节，类型用于存储帧数据字段的协议。 数据最小长度为46字节，不足46字节填充至46字节，数据是由IP首部、TCP首部和应用数据组成。","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"协议族","slug":"杂记/协议族","permalink":"https://yaoyinglong.github.io/categories/杂记/协议族/"}]},{"title":"网络基础知识","date":"2017-11-27T16:00:00.000Z","path":"Blog/杂记/协议族/网络基础知识/","text":"搭建网络的主要设备及其作用 设备 作用 网卡 使计算机联网的设备 中继器 从物理层上延长网络的设备 网桥/2层交换机 从数据链路层上延长网络的设备 路由器/3层交换机 通过网络层转发分组数据的设备 4~7层交换机 处理传输层以上各层网络传输的设备 网关 转换协议的设备 各种数据链路：以太网、无线、ATM、FDDI、帧中继、ISDN 中继器 中继器是对减弱信号进行放大和发送的设备 中继器是通过物理层的连接延长网络 即使数据链路层出现某些错误，中继器仍然转发数据 中继器无法改变传输速度 通过中继器进行网路延长并非无线延长，10Mbps的以太网最多可用四个中继器，100Mbps以太网最多只能连两个中继器","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"协议族","slug":"杂记/协议族","permalink":"https://yaoyinglong.github.io/categories/杂记/协议族/"}]},{"title":"TCP/IP四层&五层模型","date":"2017-11-24T16:00:00.000Z","path":"Blog/杂记/协议族/TCPIP四层&五层模型/","text":"再看一些书或者是在一些博客时，会发现有的地方将TCP/IP协议族定义为一个四层参考模型，而有的地方又将其定义为五层参考模型。 四层参考模型主要包括：应用层、传输层、网际层、网络接口层。 五层参考模型主要包括：应用层、传输层、网络层、数据链路层、物理层。 这里不得不说一下OSI的七层参考模型，这里讲的TCP/IP的四层参考模型和五层参考模型都是会与OSI的七层参考模型对应起来的。 OSI七层协议模型主要是：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。 他们的对应关系如表所示： OSI七层网络模型TCPIP四层概念模型TCPIP五层概念模型应用层应用层应用层表示层会话层传输层传输层传输层网络层网际层网络层数据链路层网络接口层数据链路层物理层物理层 理想化的交换机（网桥）实现实现数据链路层和物理层，而理想化的路由器则实现网络层、数据链路层和物理层","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"协议族","slug":"杂记/协议族","permalink":"https://yaoyinglong.github.io/categories/杂记/协议族/"}]},{"title":"IDEA的快捷使用","date":"2017-11-23T16:00:00.000Z","path":"Blog/杂记/工具/IDEA快捷的使用/","text":"基本快捷键Ctrl + C 快速复制当前行Ctrl + D 复制当前行到下一行Ctrl + E 最近的文件Ctrl + G 定位行和列，很多时候通过行号找东西非常方便Ctrl + I 打开选择实现方法列表CTRL + J 自动代码，打开模板代码提示CTRL + K 版本管理提交代码CTRL + T 版本管理更新代码Ctrl + N 查找类Ctrl + O 打开选择重写方法列表CTRL + P 方法参数提示，当调用一个方法忘记参数该怎么填，不必打开具体的实现地方CTRL + Q 查看当前字段的文档详情Ctrl + R 当前文件替换特定内容Ctrl + W 扩展选择Ctrl + X 剪切当前行Ctrl + Z 撤销Ctrl + Y 移除整行代码Ctrl + F4 关闭活动的编辑标签Ctrl + F7 高亮显示，按F3可以选择Ctrl + F12 可以显示当前文件的结构Ctrl + Tab 打开Switcher界面，选择切换页面Ctrl + &#39;+/-&#39; 当前方法展开、折叠Ctrl + [/] 移动光标到块的初/末括号地方Ctrl + Backspace 按单词删除Ctrl + Insert 快速复制当前行 Ctrl + Alt + B 跳到具体的实现方法，查找抽象方法的具体实现很好用CTRL + ALT + I 自动缩进CTRL + ALT + L 格式化代码Ctrl + Alt + O 优化导入类和包Ctrl + Alt + T Live Templete模板提示，代码环绕Ctrl + Alt + V 提取变量Ctrl + Alt + 鼠标左键 直接打开实现类中的方法，而不是打开接口中的方法Ctrl + Alt + Left/Right 在访问历史中进行导航 Ctrl + Shift + A 搜索功能和操作Ctrl + Shift + E 最近修改的文件Ctrl + Shift + J 整合两行为一行Ctrl + Shift + U 大小写转化Ctrl + Shift + Z 取消撤销Ctrl + Shift + R 当前项目替换特定内容Ctrl + Shift + F 当前项目查找包含特定内容的文件Ctrl + Shift + N 查找文件Ctrl + Shift + V 访问历史粘贴板Ctrl + Shift + W 缩小扩展选择Ctrl + Shift + Up/Down 上下移动整块代码Ctrl + Shift + &#39;+/-&#39; 全部展开、折叠Ctrl + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失。Ctrl + Shift + Del 删除环绕的标签Ctrl + Shift + [/] 选中从光标所在位置到它的父级区域Ctrl + Shift + Enter 完成表达式，例如：语句最后加上分号 双击Shift 在项目的所有目录查找 Shift + Enter 另起一行Shift + F6可以重命名你的类、方法、变量等等，而且这个重命名甚至可以选择替换掉注释中的内容Shift + Esc 把焦点移到编辑器上，而且隐藏当前（或最后活动的）工具窗口Shift + Click，可以关闭文件Shift + Insert 快速粘贴 Alt + 1 切换Project栏的打开和关闭Alt + 4 切换Run栏的打开和关闭Alt + 5 切换Debug栏的打开和关闭Alt + F3 逐个往下查找相同文本，并高亮显示Alt + F7 找到函数或者变量或者类的所有引用到的地方Alt + Insert 在类中使用自动生成构造器、getter/setter等方法,在项目目录上使用新建各种文件Alt + Left/Right 切换打开标签上的文件,切换代码视图Alt + Up/Down 在方法间快速移动定位Alt + Q 可以看到当前方法的声明Alt + Shift + Up/Down 上/下移一行代码Alt + 鼠标选取 可以直接方块区域选择（很有用）,列选取Alt + Enter 选择Inject language or reference后回车选择语言（例如，选择正则表达式，有测试正则表达式的能力）Alt + Home 打开快速导航，定位到指定文件 批操作Ctrl + F3 从光标开始查找下一个出现的地方，包括变量和字符串Alt + J 添加选择下一个出现的字符串或变量Ctrl + Alt + Shift + J 选择字符串或变量所有出现的地方Alt + Shift + J 反选字符串或变量 常规操作Ctrl + Tab 选择两个打开的标签或工具窗口Ctrl + Shift + A 查找功能Alt + Shift + F 将方法或某一行添加到收藏夹Ctrl + Shift + F12 切换最大编辑窗口 重构Alt + Delete 安全删除Shift + F6可以重命名你的类、方法、变量等等，而且这个重命名甚至可以选择替换掉注释中的内容Ctrl + F6 改变方法的参数Ctrl + Alt + N 内联Ctrl + Alt + M 抽取方法Ctrl + Alt + V 抽取局部变量Ctrl + Alt + F 抽取成员变量Ctrl + Alt + C 抽取常量Ctrl + Alt + P 抽取为当前方法参数 F12 把焦点从编辑器移到最近使用的工具窗口 常用插件Alibaba Java Coding Guidelines《阿里巴巴Java开发规约》扫描插件 MyBatis plugin将Mybatis中的Mapper文件中的方法和XML中对应的方法相互关联 Lombok通过注解减少很多重复代码的书写，比如说getter/setter/toString等方法的编写 Maven Helper包含的Maven使用命令，以及引入插件的命令，可以通过按钮直接操作，且包含强大Dependency Analyzer功能 String Manipulation把字符串处理成编程时常用的格式 Translation一个牛逼好用翻译插件，不用来回切换翻译软件，直接就能在IDE中使用 iedisredis客户端可视化插件 GsonFormat根据JSON生成POJO GenerateSerialVersionUID生成serialVersionUID的小插件 VisualVM LauncherJava性能分析插件 Cloud Toolkit帮助开发者更高效地开发、测试、诊断并部署应用。通过 Cloud Toolkit，开发者能够方便地将本地应用一键部署到任意机器（本地或云端），并内置 Arthas 诊断、高效执行终端命令和 SQL 等 Mybatis Log Plugin对Mybatis打印的SQL日志进行优化，能直接拷贝使用。 RestfulToolkitRESTful 服务开发辅助工具集，URL 直接跳转到对应的方法定义 ，提供了一个 Services tree 的显示窗口，一个简单的 http 请求工具 Rainbow Brackets彩虹颜色的括号，清除分清括号个数，防止括号错乱。 jclasslibe常用设置优化自动导包 双斜杠注释紧跟代码头 版本控制目录颜色展示 代码模板apr 取消匹配大小写 自动生成作者和时间信息","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yaoyinglong.github.io/tags/IDEA/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"},{"name":"工具","slug":"杂记/工具","permalink":"https://yaoyinglong.github.io/categories/杂记/工具/"}]}]}